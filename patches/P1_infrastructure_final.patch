diff --git a/scripts/collectors_dry_run.py b/scripts/collectors_dry_run.py
new file mode 100644
index 000000000..6a20403d6
--- /dev/null
+++ b/scripts/collectors_dry_run.py
@@ -0,0 +1,590 @@
+#!/usr/bin/env python3
+"""
+é‡‡é›†å™¨å…¨é“¾è·¯é›†æˆæµ‹è¯• (Dry-Run)
+Collectors Full-Chain Integration Test (Dry-Run)
+
+è¯¥è„šæœ¬æ‰§è¡Œä»å·¥å‚åˆ›å»ºå®¢æˆ·ç«¯åˆ°é‡‡é›†æ•°æ®çš„å®Œæ•´æµç¨‹éªŒè¯ï¼š
+1. ä½¿ç”¨ HttpClientFactory åˆ›å»º FotMob é‡‡é›†å™¨å®ä¾‹
+2. æ‰§è¡ŒçœŸå®çš„é‡‡é›†ä»»åŠ¡ï¼ˆé™åˆ¶æ•°é‡ï¼‰
+3. éªŒè¯è¯·æ±‚æˆåŠŸç‡ã€é€Ÿç‡é™åˆ¶ã€Tokenåˆ·æ–°æœºåˆ¶
+4. ç”Ÿæˆè¯¦ç»†çš„è¿è¡ŒæŠ¥å‘Š
+
+ä½¿ç”¨ç¤ºä¾‹:
+    python scripts/collectors_dry_run.py --source fotmob --max-fixtures 5
+    python scripts/collectors_dry_run.py --source fotmob --test-health --verbose
+    python scripts/collectors_dry_run.py --source fotmob --test-rate-limiting
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 1.0.0
+"""
+
+import argparse
+import asyncio
+import json
+import sys
+import time
+from pathlib import Path
+from typing import Any, Dict, List, Optional
+
+# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
+project_root = Path(__file__).parent.parent
+sys.path.insert(0, str(project_root))
+
+from src.collectors.http_client_factory import get_http_client_factory, FotMobConfig
+from src.collectors.interface import (
+    AuthenticationError,
+    RateLimitError,
+    NetworkError,
+    DataNotFoundError,
+)
+
+
+class DryRunTester:
+    """Dry-Run æµ‹è¯•å™¨"""
+
+    def __init__(self, args):
+        self.args = args
+        self.source = getattr(args, 'source', 'fotmob')
+        self.verbose = getattr(args, 'verbose', False)
+        self.max_fixtures = getattr(args, 'max_fixtures', 5)
+        self.max_matches = getattr(args, 'max_matches', 10)
+        self.test_health = getattr(args, 'test_health', False)
+        self.test_rate_limiting = getattr(args, 'test_rate_limiting', False)
+        self.use_proxies = getattr(args, 'use_proxies', False)
+
+        # æµ‹è¯•ç»“æœ
+        self.test_results = {
+            "test_start_time": time.time(),
+            "test_end_time": None,
+            "total_duration": 0.0,
+            "fixtures_collected": 0,
+            "matches_collected": 0,
+            "teams_collected": 0,
+            "health_checks": 0,
+            "errors": [],
+            "monitoring_stats": {},
+        }
+
+    async def setup(self) -> None:
+        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
+        print("ğŸ­ è®¾ç½® Dry-Run æµ‹è¯•ç¯å¢ƒ...")
+
+        try:
+            # è·å–å·¥å‚å®ä¾‹
+            self.factory = get_http_client_factory()
+            print(f"   âœ… HTTPå®¢æˆ·ç«¯å·¥å‚è·å–å®Œæˆ")
+
+            # é…ç½®æ•°æ®æº
+            if self.source == "fotmob":
+                config = FotMobConfig()
+
+                # æ ¹æ®å‚æ•°è°ƒæ•´é…ç½®
+                if self.use_proxies:
+                    print("   ğŸŒ å¯ç”¨ä»£ç†é…ç½®")
+                    # ä»£ç†é…ç½®å·²åœ¨é»˜è®¤é…ç½®ä¸­
+                else:
+                    print("   âš ï¸ ç¦ç”¨ä»£ç†é…ç½®")
+                    config.proxy_config = None
+
+                # è‡ªå®šä¹‰é…ç½®ç”¨äºæµ‹è¯•
+                if self.test_rate_limiting:
+                    print("   ğŸš¦ è°ƒæ•´é€Ÿç‡é™åˆ¶ç”¨äºæµ‹è¯•")
+                    config.rate_limit_config = {
+                        "rate": 1.0,        # 1 QPS - ç”¨äºæµ‹è¯•é€Ÿç‡é™åˆ¶
+                        "burst": 2,         # çªå‘å®¹é‡
+                        "max_wait_time": 15.0,
+                    }
+
+                self.factory.register_config(self.source, config)
+                print(f"   âœ… {self.source} é…ç½®æ³¨å†Œå®Œæˆ")
+
+            else:
+                raise ValueError(f"Unsupported data source: {self.source}")
+
+            print("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
+
+        except Exception as e:
+            print(f"âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
+            raise
+
+    async def teardown(self) -> None:
+        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
+        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
+
+        try:
+            # è®°å½•æµ‹è¯•ç»“æŸæ—¶é—´
+            self.test_results["test_end_time"] = time.time()
+            self.test_results["total_duration"] = (
+                self.test_results["test_end_time"] - self.test_results["test_start_time"]
+            )
+
+            # è·å–ç›‘æ§ç»Ÿè®¡
+            monitor = self.factory.get_monitor()
+            self.test_results["monitoring_stats"] = monitor.get_stats()
+
+            print("   âœ… ç»Ÿè®¡ä¿¡æ¯å·²æ”¶é›†")
+
+        except Exception as e:
+            print(f"âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
+
+    async def run_health_check(self) -> bool:
+        """è¿è¡Œå¥åº·æ£€æŸ¥æµ‹è¯•"""
+        print("\nğŸ¥ è¿è¡Œå¥åº·æ£€æŸ¥æµ‹è¯•...")
+
+        try:
+            # åˆ›å»ºé‡‡é›†å™¨
+            collector = await self.factory.create_collector(self.source)
+
+            # æ‰§è¡Œå¥åº·æ£€æŸ¥
+            health_result = await collector.check_health()
+
+            print(f"   ğŸ“Š å¥åº·çŠ¶æ€: {health_result['status']}")
+            print(f"   ğŸ“Š å“åº”æ—¶é—´: {health_result['response_time_ms']:.2f}ms")
+
+            if 'details' in health_result:
+                details = health_result['details']
+                if 'api_connectivity' in details:
+                    print(f"   ğŸ“Š APIè¿é€šæ€§: {'âœ… æ­£å¸¸' if details['api_connectivity'] else 'âŒ å¼‚å¸¸'}")
+                if 'token_stats' in details:
+                    token_stats = details['token_stats']
+                    print(f"   ğŸ“Š TokençŠ¶æ€: æœ‰æ•ˆ={token_stats['valid_tokens']}, ä½¿ç”¨æ¬¡æ•°={token_stats['total_usage']}")
+
+            # æ¸…ç†
+            await collector.close()
+            self.test_results["health_checks"] += 1
+
+            print("   âœ… å¥åº·æ£€æŸ¥å®Œæˆ")
+            return True
+
+        except Exception as e:
+            error_msg = f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}"
+            print(f"   âŒ {error_msg}")
+            self.test_results["errors"].append(error_msg)
+            return False
+
+    async def test_fixture_collection(self) -> bool:
+        """æµ‹è¯•èµ›ç¨‹æ•°æ®é‡‡é›†"""
+        print(f"\nâš½ æµ‹è¯•èµ›ç¨‹æ•°æ®é‡‡é›† (æœ€å¤š {self.max_fixtures} åœºæ¯”èµ›)...")
+
+        try:
+            # åˆ›å»ºé‡‡é›†å™¨
+            collector = await self.factory.create_collector(self.source)
+
+            # é‡‡é›†è‹±è¶…è”èµ›èµ›ç¨‹ (league_id=47)
+            print(f"   ğŸ“‹ å¼€å§‹é‡‡é›†è‹±è¶…èµ›ç¨‹æ•°æ®...")
+
+            fixtures = await collector.collect_fixtures(47, "2024-2025")
+
+            if not fixtures:
+                print("   âš ï¸ æœªè·å–åˆ°èµ›ç¨‹æ•°æ®")
+                self.test_results["errors"].append("æœªè·å–åˆ°èµ›ç¨‹æ•°æ®")
+                return False
+
+            print(f"   âœ… æˆåŠŸé‡‡é›† {len(fixtures)} åœºæ¯”èµ›èµ›ç¨‹")
+
+            # æ˜¾ç¤ºå‰å‡ åœºæ¯”èµ›ä¿¡æ¯
+            for i, fixture in enumerate(fixtures[:3], 1):
+                print(f"      {i}. {fixture['home_team']} vs {fixture['away_team']} "
+                      f"({fixture.get('status', 'N/A')})")
+
+            if len(fixtures) > self.max_fixtures:
+                fixtures = fixtures[:self.max_fixtures]
+                print(f"   ğŸ“‹ é™åˆ¶ä¸º {self.max_fixtures} åœºæ¯”èµ›è¿›è¡Œåç»­æµ‹è¯•")
+
+            self.test_results["fixtures_collected"] = len(fixtures)
+
+            # æ¸…ç†
+            await collector.close()
+
+            return True
+
+        except Exception as e:
+            error_msg = f"èµ›ç¨‹é‡‡é›†å¤±è´¥: {e}"
+            print(f"   âŒ {error_msg}")
+            self.test_results["errors"].append(error_msg)
+            return False
+
+    async def test_match_details_collection(self) -> bool:
+        """æµ‹è¯•æ¯”èµ›è¯¦æƒ…é‡‡é›†"""
+        print(f"\nğŸ“Š æµ‹è¯•æ¯”èµ›è¯¦æƒ…é‡‡é›† (æœ€å¤š {self.max_matches} åœºæ¯”èµ›)...")
+
+        try:
+            # å…ˆè·å–èµ›ç¨‹æ•°æ®
+            collector = await self.factory.create_collector(self.source)
+            fixtures = await collector.collect_fixtures(47, "2024-2025")
+            await collector.close()
+
+            if not fixtures:
+                print("   âš ï¸ æ— æ³•è·å–èµ›ç¨‹æ•°æ®ï¼Œè·³è¿‡æ¯”èµ›è¯¦æƒ…æµ‹è¯•")
+                return False
+
+            # é€‰æ‹©æ¯”èµ›è¿›è¡Œè¯¦æƒ…é‡‡é›†
+            test_matches = fixtures[:self.max_matches]
+            print(f"   ğŸ“‹ å¼€å§‹é‡‡é›† {len(test_matches)} åœºæ¯”èµ›è¯¦æƒ…...")
+
+            successful_matches = 0
+            for i, fixture in enumerate(test_matches, 1):
+                match_id = fixture.get('match_id')
+                if not match_id:
+                    continue
+
+                try:
+                    print(f"   ğŸ“Š {i}/{len(test_matches)} é‡‡é›†æ¯”èµ›è¯¦æƒ…: {fixture['home_team']} vs {fixture['away_team']}")
+
+                    details = await collector.collect_match_details(match_id)
+
+                    # éªŒè¯å…³é”®å­—æ®µ
+                    if 'home_team' in details and 'away_team' in details:
+                        successful_matches += 1
+                        print(f"      âœ… æˆåŠŸ - æ¯”åˆ†: {details.get('home_score', 'N/A')}-{details.get('away_score', 'N/A')}")
+                    else:
+                        print(f"      âš ï¸ æ•°æ®ä¸å®Œæ•´")
+
+                except Exception as e:
+                    print(f"      âŒ å¤±è´¥: {e}")
+
+            self.test_results["matches_collected"] = successful_matches
+            print(f"   âœ… æˆåŠŸé‡‡é›† {successful_matches}/{len(test_matches)} åœºæ¯”èµ›è¯¦æƒ…")
+
+            # æ¸…ç†
+            await collector.close()
+
+            return successful_matches > 0
+
+        except Exception as e:
+            error_msg = f"æ¯”èµ›è¯¦æƒ…é‡‡é›†å¤±è´¥: {e}"
+            print(f"   âŒ {error_msg}")
+            self.test_results["errors"].append(error_msg)
+            return False
+
+    async def test_rate_limiting(self) -> bool:
+        """æµ‹è¯•é€Ÿç‡é™åˆ¶"""
+        if not self.test_rate_limiting:
+            return True
+
+        print(f"\nğŸš¦ æµ‹è¯•é€Ÿç‡é™åˆ¶æœºåˆ¶...")
+
+        try:
+            # åˆ›å»ºé‡‡é›†å™¨
+            collector = await self.factory.create_collector(self.source)
+
+            # å¹¶å‘æ‰§è¡Œå¤šä¸ªå¥åº·æ£€æŸ¥æ¥æµ‹è¯•é€Ÿç‡é™åˆ¶
+            start_time = time.monotonic()
+
+            tasks = []
+            for i in range(5):  # 5ä¸ªå¹¶å‘è¯·æ±‚
+                task = asyncio.create_task(collector.check_health())
+                tasks.append(task)
+
+            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
+            results = await asyncio.gather(*tasks, return_exceptions=True)
+
+            elapsed = time.monotonic() - start_time
+            successful = sum(1 for r in results if not isinstance(r, Exception))
+
+            print(f"   ğŸ“Š 5ä¸ªå¹¶å‘è¯·æ±‚è€—æ—¶: {elapsed:.3f}s")
+            print(f"   ğŸ“Š æˆåŠŸè¯·æ±‚: {successful}/5")
+
+            # éªŒè¯é€Ÿç‡é™åˆ¶æ˜¯å¦ç”Ÿæ•ˆ
+            if elapsed >= 3.0:  # åº”è¯¥è¢«é€Ÿç‡é™åˆ¶å»¶è¿Ÿ
+                print(f"   âœ… é€Ÿç‡é™åˆ¶ç”Ÿæ•ˆ")
+                rate_limit_test_passed = True
+            else:
+                print(f"   âš ï¸ é€Ÿç‡é™åˆ¶å¯èƒ½æœªç”Ÿæ•ˆ")
+                rate_limit_test_passed = False
+
+            # æ¸…ç†
+            await collector.close()
+
+            return rate_limit_test_passed
+
+        except Exception as e:
+            error_msg = f"é€Ÿç‡é™åˆ¶æµ‹è¯•å¤±è´¥: {e}"
+            print(f"   âŒ {error_msg}")
+            self.test_results["errors"].append(error_msg)
+            return False
+
+    async def run_concurrent_test(self) -> bool:
+        """è¿è¡Œå¹¶å‘æµ‹è¯•"""
+        print(f"\nğŸ”„ è¿è¡Œå¹¶å‘æµ‹è¯•...")
+
+        try:
+            # åˆ›å»ºé‡‡é›†å™¨
+            collector = await self.factory.create_collector(self.source)
+
+            # å¹¶å‘æ‰§è¡Œå¤šä¸ªä¸åŒç±»å‹çš„è¯·æ±‚
+            async def task_health():
+                return await collector.check_health()
+
+            async def task_fixtures():
+                return await collector.collect_fixtures(47, "2024-2025")
+
+            async def task_team_info():
+                return await collector.collect_team_info("8456")  # Arsenal team ID
+
+            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
+            tasks = [
+                asyncio.create_task(task_health()),
+                asyncio.create_task(task_fixtures()),
+                asyncio.create_task(task_team_info()),
+            ]
+
+            # æ‰§è¡Œå¹¶å‘ä»»åŠ¡
+            start_time = time.monotonic()
+            results = await asyncio.gather(*tasks, return_exceptions=True)
+            elapsed = time.monotonic() - start_time
+
+            # åˆ†æç»“æœ
+            successful = sum(1 for r in results if not isinstance(r, Exception))
+
+            print(f"   ğŸ“Š å¹¶å‘æµ‹è¯•è€—æ—¶: {elapsed:.3f}s")
+            print(f"   ğŸ“Š æˆåŠŸä»»åŠ¡: {successful}/{len(tasks)}")
+
+            # æ¸…ç†
+            await collector.close()
+
+            return successful >= len(tasks) // 2  # è‡³å°‘ä¸€åŠæˆåŠŸ
+
+        except Exception as e:
+            error_msg = f"å¹¶å‘æµ‹è¯•å¤±è´¥: {e}"
+            print(f"   âŒ {error_msg}")
+            self.test_results["errors"].append(error_msg)
+            return False
+
+    async def generate_report(self) -> None:
+        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
+        print(f"\nğŸ“„ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
+
+        # åˆ›å»ºæŠ¥å‘Šç›®å½•
+        reports_dir = Path("reports")
+        reports_dir.mkdir(exist_ok=True)
+
+        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
+        report = {
+            "test_summary": {
+                "test_source": self.source,
+                "test_duration": round(self.test_results["total_duration"], 2),
+                "test_start": time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime(self.test_results["test_start_time"])),
+                "test_end": time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime(self.test_results["test_end_time"])) if self.test_results["test_end_time"] else None,
+            },
+            "collection_results": {
+                "fixtures_collected": self.test_results["fixtures_collected"],
+                "matches_collected": self.test_results["matches_collected"],
+                "teams_collected": self.test_results["teams_collected"],
+                "health_checks": self.test_results["health_checks"],
+            },
+            "monitoring_statistics": self.test_results.get("monitoring_stats", {}),
+            "errors": self.test_results["errors"],
+        }
+
+        # å†™å…¥MarkdownæŠ¥å‘Š
+        report_file = reports_dir / "dry_run_results.md"
+
+        with open(report_file, 'w', encoding='utf-8') as f:
+            f.write("# é‡‡é›†å™¨ Dry-Run æµ‹è¯•æŠ¥å‘Š\n\n")
+            f.write(f"## æµ‹è¯•æ¦‚è§ˆ\n")
+            f.write(f"- **æ•°æ®æº**: {report['test_summary']['test_source']}\n")
+            f.write(f"- **æµ‹è¯•æ—¶é•¿**: {report['test_summary']['test_duration']:.2f}ç§’\n")
+            f.write(f"- **æµ‹è¯•å¼€å§‹**: {report['test_summary']['test_start']}\n")
+            if report['test_summary']['test_end']:
+                f.write(f"- **æµ‹è¯•ç»“æŸ**: {report['test_summary']['test_end']}\n")
+            f.write(f"\n")
+
+            f.write(f"## é‡‡é›†ç»“æœ\n")
+            f.write(f"- **èµ›ç¨‹æ•°æ®é‡‡é›†**: {report['collection_results']['fixtures_collected']} åœº\n")
+            f.write(f"- **æ¯”èµ›è¯¦æƒ…é‡‡é›†**: {report['collection_results']['matches_collected']} åœº\n")
+            f.write(f"- **çƒé˜Ÿä¿¡æ¯é‡‡é›†**: {report['collection_results']['teams_collected']} ä¸ª\n")
+            f.write(f"- **å¥åº·æ£€æŸ¥æ¬¡æ•°**: {report['collection_results']['health_checks']} æ¬¡\n")
+            f.write(f"\n")
+
+            f.write(f"## ç›‘æ§ç»Ÿè®¡\n")
+            monitor_stats = report.get("monitoring_statistics", {})
+            if monitor_stats:
+                f.write(f"- **æ€»è¯·æ±‚æ•°**: {monitor_stats.get('total_requests', 0)}\n")
+                f.write(f"- **æˆåŠŸè¯·æ±‚æ•°**: {monitor_stats.get('successful_requests', 0)}\n")
+                f.write(f"- **å¤±è´¥è¯·æ±‚æ•°**: {monitor_stats.get('failed_requests', 0)}\n")
+                f.write(f"- **æˆåŠŸç‡**: {monitor_stats.get('success_rate', 0):.1f}%\n")
+                f.write(f"- **å¹³å‡å“åº”æ—¶é—´**: {monitor_stats.get('avg_response_time_ms', 0):.2f}ms\n")
+                f.write(f"- **Tokenåˆ·æ–°æ¬¡æ•°**: {monitor_stats.get('token_refreshes', 0)}\n")
+                f.write(f"- **ä»£ç†è½®æ¢æ¬¡æ•°**: {monitor_stats.get('proxy_rotations', 0)}\n")
+            f.write(f"\n")
+
+            if report["errors"]:
+                f.write(f"## é”™è¯¯ä¿¡æ¯\n")
+                for i, error in enumerate(report["errors"], 1):
+                    f.write(f"{i}. {error}\n")
+                f.write(f"\n")
+
+            f.write(f"## æµ‹è¯•é…ç½®\n")
+            f.write(f"- **æ•°æ®æº**: {self.source}\n")
+            f.write(f"- **æœ€å¤§èµ›ç¨‹æ•°**: {self.max_fixtures}\n")
+            f.write(f"- **æœ€å¤§æ¯”èµ›æ•°**: {self.max_matches}\n")
+            f.write(f"- **å¥åº·æ£€æŸ¥**: {'å¯ç”¨' if self.test_health else 'ç¦ç”¨'}\n")
+            f.write(f"- **é€Ÿç‡é™åˆ¶æµ‹è¯•**: {'å¯ç”¨' if self.test_rate_limiting else 'ç¦ç”¨'}\n")
+            f.write(f"- **ä»£ç†ä½¿ç”¨**: {'å¯ç”¨' if self.use_proxies else 'ç¦ç”¨'}\n")
+            f.write(f"- **è¯¦ç»†è¾“å‡º**: {'å¯ç”¨' if self.verbose else 'ç¦ç”¨'}\n")
+
+        # å†™å…¥JSONæŠ¥å‘Š
+        json_report_file = reports_dir / "dry_run_results.json"
+        with open(json_report_file, 'w', encoding='utf-8') as f:
+            json.dump(report, f, indent=2, ensure_ascii=False)
+
+        print(f"   âœ… æŠ¥å‘Šå·²ä¿å­˜:")
+        print(f"      ğŸ“„ Markdown: {report_file}")
+        print(f"      ğŸ“Š JSON: {json_report_file}")
+
+    async def run_all_tests(self) -> None:
+        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
+        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {self.source} é‡‡é›†å™¨ Dry-Run æµ‹è¯•...")
+        print(f"   é…ç½®: æœ€å¤§èµ›ç¨‹={self.max_fixtures}, æœ€å¤§æ¯”èµ›={self.max_matches}")
+        print(f"   é…ç½®: å¥åº·æ£€æŸ¥={'å¯ç”¨' if self.test_health else 'ç¦ç”¨'}")
+        print(f"   é…ç½®: é€Ÿç‡é™åˆ¶æµ‹è¯•={'å¯ç”¨' if self.test_rate_limiting else 'ç¦ç”¨'}")
+        print(f"   é…ç½®: ä»£ç†={'å¯ç”¨' if self.use_proxies else 'ç¦ç”¨'}")
+
+        # å®šä¹‰æµ‹è¯•åˆ—è¡¨
+        tests = []
+
+        if self.test_health:
+            tests.append(("å¥åº·æ£€æŸ¥æµ‹è¯•", self.run_health_check))
+
+        tests.append(("èµ›ç¨‹æ•°æ®é‡‡é›†æµ‹è¯•", self.test_fixture_collection))
+        tests.append(("æ¯”èµ›è¯¦æƒ…é‡‡é›†æµ‹è¯•", self.test_match_details_collection))
+
+        if self.test_rate_limiting:
+            tests.append(("é€Ÿç‡é™åˆ¶æµ‹è¯•", self.test_rate_limiting))
+
+        tests.append(("å¹¶å‘æµ‹è¯•", self.run_concurrent_test))
+
+        # è¿è¡Œæµ‹è¯•
+        passed_tests = 0
+        total_tests = len(tests)
+
+        for test_name, test_func in tests:
+            try:
+                result = await test_func()
+                if result:
+                    passed_tests += 1
+                    print(f"âœ… {test_name}: é€šè¿‡")
+                else:
+                    print(f"âŒ {test_name}: å¤±è´¥")
+            except Exception as e:
+                print(f"ğŸ’¥ {test_name}: å¼‚å¸¸ - {e}")
+                self.test_results["errors"].append(f"{test_name} å¼‚å¸¸: {e}")
+
+        # ç”Ÿæˆæµ‹è¯•ç»“æœæ‘˜è¦
+        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
+
+        print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
+        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
+        print(f"   é€šè¿‡æµ‹è¯•: {passed_tests} ({success_rate:.1f}%)")
+        print(f"   å¤±è´¥æµ‹è¯•: {total_tests - passed_tests} ({100 - success_rate:.1f}%)")
+
+        if self.test_results["errors"]:
+            print(f"\nâŒ é”™è¯¯è¯¦æƒ…:")
+            for i, error in enumerate(self.test_results["errors"], 1):
+                print(f"   {i}. {error}")
+
+        # ç»“æœè¯„ä¼°
+        if success_rate >= 80:
+            print(f"\nğŸ‰ æµ‹è¯•ç»“æœ: ä¼˜ç§€ (æˆåŠŸç‡ >= 80%)")
+        elif success_rate >= 60:
+            print(f"\nâœ… æµ‹è¯•ç»“æœ: è‰¯å¥½ (æˆåŠŸç‡ >= 60%)")
+        else:
+            print(f"\nâš ï¸ æµ‹è¯•ç»“æœ: éœ€è¦æ”¹è¿› (æˆåŠŸç‡ < 60%)")
+
+        # ç”ŸæˆæŠ¥å‘Š
+        await self.generate_report()
+
+
+def parse_args():
+    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
+    parser = argparse.ArgumentParser(
+        description="é‡‡é›†å™¨å…¨é“¾è·¯é›†æˆæµ‹è¯• (Dry-Run)",
+        formatter_class=argparse.RawDescriptionHelpFormatter,
+        epilog="""
+ç¤ºä¾‹ç”¨æ³•:
+  # åŸºç¡€æµ‹è¯•
+  python scripts/collectors_dry_run.py --source fotmob --max-fixtures 5
+
+  # åŒ…å«å¥åº·æ£€æŸ¥çš„å®Œæ•´æµ‹è¯•
+  python scripts/collectors_dry_run.py --source fotmob --test-health --max-fixtures 10
+
+  # æµ‹è¯•é€Ÿç‡é™åˆ¶
+  python scripts/collectors_dry_run.py --source fotmob --test-rate-limiting
+
+  # ä½¿ç”¨ä»£ç†çš„æµ‹è¯•
+  python scripts/collectors_dry_run.py --source fotmob --use-proxies --verbose
+        """
+    )
+
+    parser.add_argument(
+        "--source",
+        default="fotmob",
+        choices=["fotmob"],
+        help="æ•°æ®æº (é»˜è®¤: fotmob)"
+    )
+
+    parser.add_argument(
+        "--max-fixtures",
+        type=int,
+        default=5,
+        help="æœ€å¤§é‡‡é›†èµ›ç¨‹æ•°é‡ (é»˜è®¤: 5)"
+    )
+
+    parser.add_argument(
+        "--max-matches",
+        type=int,
+        default=10,
+        help="æœ€å¤§é‡‡é›†æ¯”èµ›è¯¦æƒ…æ•°é‡ (é»˜è®¤: 10)"
+    )
+
+    parser.add_argument(
+        "--test-health",
+        action="store_true",
+        help="åŒ…å«å¥åº·æ£€æŸ¥æµ‹è¯•"
+    )
+
+    parser.add_argument(
+        "--test-rate-limiting",
+        action="store_true",
+        help="æµ‹è¯•é€Ÿç‡é™åˆ¶æœºåˆ¶"
+    )
+
+    parser.add_argument(
+        "--use-proxies",
+        action="store_true",
+        help="ä½¿ç”¨ä»£ç†è¿›è¡Œæµ‹è¯•"
+    )
+
+    parser.add_argument(
+        "--verbose", "-v",
+        action="store_true",
+        help="è¯¦ç»†è¾“å‡º"
+    )
+
+    return parser.parse_args()
+
+
+async def main():
+    """ä¸»å‡½æ•°"""
+    args = parse_args()
+
+    try:
+        tester = DryRunTester(args)
+        await tester.setup()
+        await tester.run_all_tests()
+        await tester.teardown()
+
+    except KeyboardInterrupt:
+        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
+    except Exception as e:
+        print(f"âŒ é”™è¯¯: {e}")
+        if args.verbose:
+            import traceback
+            traceback.print_exc()
+        sys.exit(1)
+
+
+if __name__ == "__main__":
+    asyncio.run(main())
\ No newline at end of file
diff --git a/src/collectors/auth/__init__.py b/src/collectors/auth/__init__.py
new file mode 100644
index 000000000..de05fa999
--- /dev/null
+++ b/src/collectors/auth/__init__.py
@@ -0,0 +1,45 @@
+"""
+è®¤è¯æ¨¡å—
+Authentication Module
+
+è¯¥æ¨¡å—æä¾›åŠ¨æ€è®¤è¯åŠŸèƒ½ï¼ŒåŒ…æ‹¬ä»¤ç‰Œç®¡ç†ã€ç¼“å­˜å’Œè‡ªåŠ¨åˆ·æ–°ã€‚
+
+ä¸»è¦ç»„ä»¶:
+- TokenManager: ä»¤ç‰Œç®¡ç†å™¨
+- AuthProvider: è®¤è¯æä¾›è€…åè®®
+- FotMobAuthProvider: FotMob è®¤è¯å®ç°
+"""
+
+from .token_manager import (
+    Token,
+    TokenType,
+    AuthProvider,
+    TokenManager,
+    FotMobAuthProvider,
+    MockAuthProvider,
+    AuthenticationError,
+    TokenExpiredError,
+    TokenRefreshError,
+    get_token_manager,
+    close_token_manager,
+    create_token_manager,
+    create_fotmob_provider,
+    create_mock_provider,
+)
+
+__all__ = [
+    'Token',
+    'TokenType',
+    'AuthProvider',
+    'TokenManager',
+    'FotMobAuthProvider',
+    'MockAuthProvider',
+    'AuthenticationError',
+    'TokenExpiredError',
+    'TokenRefreshError',
+    'get_token_manager',
+    'close_token_manager',
+    'create_token_manager',
+    'create_fotmob_provider',
+    'create_mock_provider',
+]
\ No newline at end of file
diff --git a/src/collectors/auth/token_manager.py b/src/collectors/auth/token_manager.py
new file mode 100644
index 000000000..0ffd8fbdd
--- /dev/null
+++ b/src/collectors/auth/token_manager.py
@@ -0,0 +1,702 @@
+"""
+åŠ¨æ€è®¤è¯æ¨¡å— - Token Manager
+Dynamic Authentication Module - Token Manager
+
+è¯¥æ¨¡å—å®ç°äº†åŠ¨æ€è®¤è¯ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒï¼š
+1. å¤šç§è®¤è¯æä¾›è€… (AuthProvider Protocol)
+2. Token ç¼“å­˜å’Œè‡ªåŠ¨åˆ·æ–°æœºåˆ¶
+3. FotMob è®¤è¯å®ç°
+4. TTL è¿‡æœŸå¤„ç†
+5. çº¿ç¨‹å®‰å…¨çš„å¹¶å‘è®¿é—®
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 1.0.0
+"""
+
+import asyncio
+import re
+import time
+from abc import abstractmethod
+from dataclasses import dataclass, field
+from enum import Enum
+from typing import Any, Dict, Optional, Protocol, runtime_checkable
+
+import aiohttp
+
+
+class TokenType(Enum):
+    """Token ç±»å‹"""
+    BEARER = "bearer"
+    API_KEY = "api_key"
+    CUSTOM_HEADER = "custom_header"
+
+
+@dataclass
+class Token:
+    """
+    è®¤è¯ä»¤ç‰Œæ•°æ®ç±»
+
+    Attributes:
+        value: ä»¤ç‰Œå€¼
+        token_type: ä»¤ç‰Œç±»å‹
+        headers: å…³è”çš„HTTPå¤´éƒ¨
+        expires_at: è¿‡æœŸæ—¶é—´æˆ³
+        created_at: åˆ›å»ºæ—¶é—´æˆ³
+        usage_count: ä½¿ç”¨æ¬¡æ•°
+        provider: æä¾›è€…åç§°
+    """
+    value: str
+    token_type: TokenType
+    headers: Dict[str, str] = field(default_factory=dict)
+    expires_at: Optional[float] = None
+    created_at: float = field(default_factory=time.monotonic)
+    usage_count: int = 0
+    provider: str = "unknown"
+
+    def __post_init__(self) -> None:
+        """åˆå§‹åŒ–åå¤„ç†"""
+        if isinstance(self.token_type, str):
+            self.token_type = TokenType(self.token_type.lower())
+
+    @property
+    def is_expired(self) -> bool:
+        """æ£€æŸ¥ä»¤ç‰Œæ˜¯å¦è¿‡æœŸ"""
+        if self.expires_at is None:
+            return False
+        return time.monotonic() >= self.expires_at
+
+    @property
+    def is_valid(self) -> bool:
+        """æ£€æŸ¥ä»¤ç‰Œæ˜¯å¦æœ‰æ•ˆï¼ˆæœªè¿‡æœŸä¸”å€¼ä¸ä¸ºç©ºï¼‰"""
+        return not self.is_expired and bool(self.value)
+
+    @property
+    def ttl(self) -> Optional[float]:
+        """è·å–å‰©ä½™ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰"""
+        if self.expires_at is None:
+            return None
+        return max(0.0, self.expires_at - time.monotonic())
+
+    def record_usage(self) -> None:
+        """è®°å½•ä»¤ç‰Œä½¿ç”¨"""
+        self.usage_count += 1
+
+    def to_dict(self) -> Dict[str, Any]:
+        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
+        return {
+            'value': self.value[:20] + "..." if len(self.value) > 20 else self.value,  # éšè—å®Œæ•´token
+            'token_type': self.token_type.value,
+            'headers': self.headers,
+            'expires_at': self.expires_at,
+            'created_at': self.created_at,
+            'usage_count': self.usage_count,
+            'provider': self.provider,
+            'is_expired': self.is_expired,
+            'is_valid': self.is_valid,
+            'ttl': self.ttl,
+        }
+
+    def __str__(self) -> str:
+        return f"Token({self.provider}, {self.token_type.value}, valid={self.is_valid})"
+
+    def __repr__(self) -> str:
+        return self.__str__()
+
+
+@runtime_checkable
+class AuthProvider(Protocol):
+    """
+    è®¤è¯æä¾›è€…åè®®
+
+    å®šä¹‰äº†è·å–è®¤è¯ä»¤ç‰Œçš„æ ‡å‡†æ¥å£
+    """
+
+    @abstractmethod
+    async def get_token(self) -> Token:
+        """
+        è·å–è®¤è¯ä»¤ç‰Œ
+
+        Returns:
+            Token: è®¤è¯ä»¤ç‰Œå¯¹è±¡
+
+        Raises:
+            AuthenticationError: è®¤è¯å¤±è´¥
+        """
+        ...
+
+    @abstractmethod
+    async def refresh_token(self, old_token: Optional[Token] = None) -> Token:
+        """
+        åˆ·æ–°è®¤è¯ä»¤ç‰Œ
+
+        Args:
+            old_token: æ—§çš„ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
+
+        Returns:
+            Token: æ–°çš„è®¤è¯ä»¤ç‰Œ
+
+        Raises:
+            AuthenticationError: è®¤è¯å¤±è´¥
+        """
+        ...
+
+    @property
+    @abstractmethod
+    def provider_name(self) -> str:
+        """è·å–æä¾›è€…åç§°"""
+        ...
+
+
+class AuthenticationError(Exception):
+    """è®¤è¯é”™è¯¯åŸºç±»"""
+    pass
+
+
+class TokenExpiredError(AuthenticationError):
+    """ä»¤ç‰Œè¿‡æœŸé”™è¯¯"""
+    pass
+
+
+class TokenRefreshError(AuthenticationError):
+    """ä»¤ç‰Œåˆ·æ–°é”™è¯¯"""
+    pass
+
+
+class TokenManager:
+    """
+    ä»¤ç‰Œç®¡ç†å™¨
+
+    è´Ÿè´£ç®¡ç†ä¸åŒçš„è®¤è¯æä¾›è€…ï¼Œå¤„ç†ä»¤ç‰Œçš„ç¼“å­˜å’Œè‡ªåŠ¨åˆ·æ–°
+    """
+
+    def __init__(
+        self,
+        default_ttl: float = 3600.0,  # 1å°æ—¶
+        cache_refresh_threshold: float = 300.0,  # 5åˆ†é’Ÿå†…è¿‡æœŸæ—¶åˆ·æ–°
+        max_retry_attempts: int = 3,
+        retry_delay: float = 1.0,
+    ):
+        """
+        åˆå§‹åŒ–ä»¤ç‰Œç®¡ç†å™¨
+
+        Args:
+            default_ttl: é»˜è®¤ä»¤ç‰Œç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
+            cache_refresh_threshold: ç¼“å­˜åˆ·æ–°é˜ˆå€¼ï¼ˆç§’ï¼‰
+            max_retry_attempts: æœ€å¤§é‡è¯•æ¬¡æ•°
+            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
+        """
+        self.default_ttl = default_ttl
+        self.cache_refresh_threshold = cache_refresh_threshold
+        self.max_retry_attempts = max_retry_attempts
+        self.retry_delay = retry_delay
+
+        # ä»¤ç‰Œç¼“å­˜: {provider_name: Token}
+        self.token_cache: Dict[str, Token] = {}
+        # æä¾›è€…ç¼“å­˜: {provider_name: AuthProvider}
+        self.provider_cache: Dict[str, AuthProvider] = {}
+        self.lock = asyncio.Lock()
+
+    async def register_provider(self, provider: AuthProvider) -> None:
+        """
+        æ³¨å†Œè®¤è¯æä¾›è€…
+
+        Args:
+            provider: è®¤è¯æä¾›è€…å®ä¾‹
+        """
+        async with self.lock:
+            provider_name = provider.provider_name
+            if provider_name not in self.token_cache:
+                # å­˜å‚¨providerå¼•ç”¨
+                self.provider_cache[provider_name] = provider
+
+                # é¢„å…ˆè·å–ä¸€ä¸ªä»¤ç‰Œ
+                try:
+                    token = await provider.get_token()
+                    self.token_cache[provider_name] = token
+                    print(f"ğŸ”‘ Registered provider: {provider_name}")
+                except Exception as e:
+                    print(f"âŒ Failed to register provider {provider_name}: {e}")
+                    raise AuthenticationError(f"Failed to register provider {provider_name}: {e}")
+
+    async def get_token(self, provider_name: str, force_refresh: bool = False) -> Token:
+        """
+        è·å–è®¤è¯ä»¤ç‰Œ
+
+        Args:
+            provider_name: æä¾›è€…åç§°
+            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
+
+        Returns:
+            Token: è®¤è¯ä»¤ç‰Œ
+
+        Raises:
+            AuthenticationError: è®¤è¯å¤±è´¥
+            TokenRefreshError: ä»¤ç‰Œåˆ·æ–°å¤±è´¥
+        """
+        async with self.lock:
+            if provider_name not in self.token_cache:
+                raise AuthenticationError(f"Provider {provider_name} not registered")
+
+            cached_token = self.token_cache[provider_name]
+
+            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
+            should_refresh = (
+                force_refresh or
+                not cached_token.is_valid or
+                (cached_token.ttl and cached_token.ttl < self.cache_refresh_threshold)
+            )
+
+            if should_refresh:
+                print(f"ğŸ”„ Refreshing token for provider: {provider_name}")
+                # è¿™é‡Œéœ€è¦é‡æ–°è·å–providerå®ä¾‹è¿›è¡Œåˆ·æ–°
+                # å®é™…å®ç°ä¸­åº”è¯¥ä¿å­˜providerå¼•ç”¨
+                provider = self._get_provider_by_name(provider_name)
+                if not provider:
+                    raise AuthenticationError(f"Provider {provider_name} not found for refresh")
+
+                try:
+                    new_token = await self._retry_token_refresh(provider, cached_token)
+                    self.token_cache[provider_name] = new_token
+                    print(f"âœ… Token refreshed for provider: {provider_name}")
+                    return new_token
+                except Exception as e:
+                    print(f"âŒ Failed to refresh token for {provider_name}: {e}")
+                    if not cached_token.is_valid:
+                        # ç¼“å­˜çš„tokenä¹Ÿæ— æ•ˆäº†ï¼ŒæŠ›å‡ºå¼‚å¸¸
+                        raise TokenRefreshError(f"Failed to refresh token for {provider_name}: {e}")
+                    # è¿”å›æ—§tokenï¼ˆè™½ç„¶å¿«è¿‡æœŸä½†ä»ç„¶æœ‰æ•ˆï¼‰
+                    print(f"âš ï¸ Using old token for {provider_name} (will expire soon)")
+                    return cached_token
+            else:
+                cached_token.record_usage()
+                if cached_token.usage_count % 10 == 0:  # æ¯10æ¬¡ä½¿ç”¨æ‰“å°ä¸€æ¬¡
+                    print(f"ğŸ“Š Token usage for {provider_name}: {cached_token.usage_count} times")
+                return cached_token
+
+    def _get_provider_by_name(self, provider_name: str) -> Optional[AuthProvider]:
+        """
+        æ ¹æ®åç§°è·å–æä¾›è€…å®ä¾‹
+
+        Args:
+            provider_name: æä¾›è€…åç§°
+
+        Returns:
+            Optional[AuthProvider]: æä¾›è€…å®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
+        """
+        return self.provider_cache.get(provider_name)
+
+    async def _retry_token_refresh(self, provider: AuthProvider, old_token: Optional[Token] = None) -> Token:
+        """
+        é‡è¯•ä»¤ç‰Œåˆ·æ–°
+
+        Args:
+            provider: è®¤è¯æä¾›è€…
+            old_token: æ—§ä»¤ç‰Œ
+
+        Returns:
+            Token: æ–°ä»¤ç‰Œ
+
+        Raises:
+            TokenRefreshError: åˆ·æ–°å¤±è´¥
+        """
+        last_error = None
+
+        for attempt in range(self.max_retry_attempts):
+            try:
+                new_token = await provider.refresh_token(old_token)
+                return new_token
+            except Exception as e:
+                last_error = e
+                print(f"âš ï¸ Token refresh attempt {attempt + 1} failed: {e}")
+                if attempt < self.max_retry_attempts - 1:
+                    await asyncio.sleep(self.retry_delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
+
+        raise TokenRefreshError(f"Token refresh failed after {self.max_retry_attempts} attempts: {last_error}")
+
+    async def invalidate_token(self, provider_name: str) -> None:
+        """
+        ä½¿ä»¤ç‰Œå¤±æ•ˆ
+
+        Args:
+            provider_name: æä¾›è€…åç§°
+        """
+        async with self.lock:
+            if provider_name in self.token_cache:
+                del self.token_cache[provider_name]
+                print(f"ğŸ—‘ï¸ Invalidated token for provider: {provider_name}")
+
+    async def get_token_info(self, provider_name: Optional[str] = None) -> Dict[str, Any]:
+        """
+        è·å–ä»¤ç‰Œä¿¡æ¯
+
+        Args:
+            provider_name: æä¾›è€…åç§°ï¼ŒNoneè¡¨ç¤ºè·å–æ‰€æœ‰
+
+        Returns:
+            Dict[str, Any]: ä»¤ç‰Œä¿¡æ¯
+        """
+        async with self.lock:
+            if provider_name:
+                if provider_name in self.token_cache:
+                    return self.token_cache[provider_name].to_dict()
+                else:
+                    return {"error": f"Provider {provider_name} not found"}
+            else:
+                return {
+                    name: token.to_dict()
+                    for name, token in self.token_cache.items()
+                }
+
+    async def get_stats(self) -> Dict[str, Any]:
+        """
+        è·å–ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯
+
+        Returns:
+            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
+        """
+        async with self.lock:
+            total_providers = len(self.token_cache)
+            valid_tokens = sum(1 for token in self.token_cache.values() if token.is_valid)
+            expired_tokens = total_providers - valid_tokens
+
+            total_usage = sum(token.usage_count for token in self.token_cache.values())
+
+            return {
+                'total_providers': total_providers,
+                'valid_tokens': valid_tokens,
+                'expired_tokens': expired_tokens,
+                'total_usage': total_usage,
+                'cache_refresh_threshold': self.cache_refresh_threshold,
+                'default_ttl': self.default_ttl,
+            }
+
+
+class FotMobAuthProvider:
+    """
+    FotMob è®¤è¯æä¾›è€…
+
+    æ¨¡æ‹Ÿä» FotMob é¦–é¡µ HTML ä¸­æå–è®¤è¯ç­¾åçš„é€»è¾‘
+    """
+
+    def __init__(
+        self,
+        base_url: str = "https://www.fotmob.com",
+        timeout: float = 10.0,
+        token_ttl: float = 3600.0,  # 1å°æ—¶
+        user_agent: str = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
+    ):
+        """
+        åˆå§‹åŒ– FotMob è®¤è¯æä¾›è€…
+
+        Args:
+            base_url: FotMob åŸºç¡€URL
+            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
+            token_ttl: ä»¤ç‰Œç”Ÿå­˜æ—¶é—´
+            user_agent: ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²
+        """
+        self.base_url = base_url
+        self.timeout = timeout
+        self.token_ttl = token_ttl
+        self.user_agent = user_agent
+
+    @property
+    def provider_name(self) -> str:
+        """è·å–æä¾›è€…åç§°"""
+        return "fotmob"
+
+    async def get_token(self) -> Token:
+        """
+        è·å– FotMob è®¤è¯ä»¤ç‰Œ
+
+        Returns:
+            Token: è®¤è¯ä»¤ç‰Œ
+
+        Raises:
+            AuthenticationError: è®¤è¯å¤±è´¥
+        """
+        try:
+            # æ¨¡æ‹Ÿä» FotMob é¦–é¡µæå– token
+            html_content = await self._fetch_fotmob_homepage()
+            token_data = self._extract_token_from_html(html_content)
+
+            if not token_data:
+                raise AuthenticationError("Failed to extract token from FotMob homepage")
+
+            token = Token(
+                value=token_data['value'],
+                token_type=TokenType.CUSTOM_HEADER,
+                headers=token_data['headers'],
+                expires_at=time.monotonic() + self.token_ttl,
+                provider=self.provider_name
+            )
+
+            print(f"ğŸ”‘ Obtained FotMob token: {token.value[:20]}...")
+            return token
+
+        except Exception as e:
+            print(f"âŒ Failed to get FotMob token: {e}")
+            raise AuthenticationError(f"Failed to get FotMob token: {e}")
+
+    async def refresh_token(self, old_token: Optional[Token] = None) -> Token:
+        """
+        åˆ·æ–° FotMob è®¤è¯ä»¤ç‰Œ
+
+        Args:
+            old_token: æ—§ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
+
+        Returns:
+            Token: æ–°çš„è®¤è¯ä»¤ç‰Œ
+
+        Raises:
+            TokenRefreshError: åˆ·æ–°å¤±è´¥
+        """
+        try:
+            print("ğŸ”„ Refreshing FotMob token...")
+            new_token = await self.get_token()
+            print(f"âœ… FotMob token refreshed successfully")
+            return new_token
+        except Exception as e:
+            print(f"âŒ Failed to refresh FotMob token: {e}")
+            raise TokenRefreshError(f"Failed to refresh FotMob token: {e}")
+
+    async def _fetch_fotmob_homepage(self) -> str:
+        """
+        è·å– FotMob é¦–é¡µ HTML
+
+        Returns:
+            str: HTML å†…å®¹
+
+        Raises:
+            AuthenticationError: è·å–å¤±è´¥
+        """
+        try:
+            timeout = aiohttp.ClientTimeout(total=self.timeout)
+
+            headers = {
+                'User-Agent': self.user_agent,
+                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
+                'Accept-Language': 'en-US,en;q=0.5',
+                'Accept-Encoding': 'gzip, deflate',
+                'Connection': 'keep-alive',
+                'Upgrade-Insecure-Requests': '1',
+            }
+
+            async with aiohttp.ClientSession(timeout=timeout) as session:
+                async with session.get(self.base_url, headers=headers) as response:
+                    if response.status == 200:
+                        return await response.text()
+                    else:
+                        raise AuthenticationError(f"HTTP {response.status}: Failed to fetch FotMob homepage")
+
+        except aiohttp.ClientError as e:
+            raise AuthenticationError(f"Network error while fetching FotMob homepage: {e}")
+
+    def _extract_token_from_html(self, html_content: str) -> Optional[Dict[str, Any]]:
+        """
+        ä» HTML å†…å®¹ä¸­æå–è®¤è¯ä»¤ç‰Œ
+
+        Args:
+            html_content: HTML å†…å®¹
+
+        Returns:
+            Optional[Dict[str, Any]]: ä»¤ç‰Œæ•°æ®ï¼Œå¦‚æœæå–å¤±è´¥è¿”å›None
+        """
+        try:
+            # æ¨¡æ‹Ÿä» HTML ä¸­æå–è®¤è¯ä¿¡æ¯
+            # å®é™…å®ç°ä¸­ï¼Œè¿™äº›å€¼ä¼šä» HTML çš„ JavaScript æˆ– meta æ ‡ç­¾ä¸­æå–
+
+            # æ¨¡æ‹Ÿæå– x-mas header
+            x_mas_match = re.search(r'"x-mas":"([^"]+)"', html_content)
+            x_mas_value = x_mas_match.group(1) if x_mas_match else self._generate_mock_x_mas()
+
+            # æ¨¡æ‹Ÿæå– x-foo signature
+            x_foo_match = re.search(r'"x-foo":"([^"]+)"', html_content)
+            x_foo_value = x_foo_match.group(1) if x_foo_match else self._generate_mock_x_foo()
+
+            # æ¨¡æ‹Ÿæå– client version
+            version_match = re.search(r'"clientVersion":"([^"]+)"', html_content)
+            client_version = version_match.group(1) if version_match else "production:mock_version"
+
+            if not x_mas_value or not x_foo_value:
+                print("âš ï¸ Token extraction incomplete, using mock values")
+
+            token_data = {
+                'value': f"{x_mas_value}:{x_foo_value}",
+                'headers': {
+                    'x-mas': x_mas_value,
+                    'x-foo': x_foo_value,
+                    'x-client-version': client_version,
+                }
+            }
+
+            return token_data
+
+        except Exception as e:
+            print(f"âš ï¸ Token extraction failed, using mock values: {e}")
+            return self._generate_mock_token_data()
+
+    def _generate_mock_x_mas(self) -> str:
+        """ç”Ÿæˆæ¨¡æ‹Ÿçš„ x-mas å€¼"""
+        import hashlib
+        import random
+
+        timestamp = int(time.time())
+        random_str = f"fotmob_{timestamp}_{random.randint(1000, 9999)}"
+        return hashlib.sha256(random_str.encode()).hexdigest()[:32]
+
+    def _generate_mock_x_foo(self) -> str:
+        """ç”Ÿæˆæ¨¡æ‹Ÿçš„ x-foo ç­¾å"""
+        import hashlib
+        import base64
+
+        payload = f"fotmob_auth_{int(time.time())}".encode()
+        signature = hashlib.sha256(payload).digest()
+        return base64.b64encode(signature).decode()[:40]
+
+    def _generate_mock_token_data(self) -> Dict[str, Any]:
+        """ç”Ÿæˆæ¨¡æ‹Ÿä»¤ç‰Œæ•°æ®"""
+        x_mas = self._generate_mock_x_mas()
+        x_foo = self._generate_mock_x_foo()
+
+        return {
+            'value': f"{x_mas}:{x_foo}",
+            'headers': {
+                'x-mas': x_mas,
+                'x-foo': x_foo,
+                'x-client-version': "production:mock_version",
+            }
+        }
+
+
+class MockAuthProvider:
+    """
+    æ¨¡æ‹Ÿè®¤è¯æä¾›è€…ï¼ˆç”¨äºæµ‹è¯•ï¼‰
+    """
+
+    def __init__(self, provider_name: str, token_value: str = "mock_token", ttl: float = 300.0):
+        """
+        åˆå§‹åŒ–æ¨¡æ‹Ÿè®¤è¯æä¾›è€…
+
+        Args:
+            provider_name: æä¾›è€…åç§°
+            token_value: ä»¤ç‰Œå€¼
+            ttl: ç”Ÿå­˜æ—¶é—´
+        """
+        self._provider_name = provider_name
+        self.token_value = token_value
+        self.ttl = ttl
+
+    @property
+    def provider_name(self) -> str:
+        """è·å–æä¾›è€…åç§°"""
+        return self._provider_name
+
+    async def get_token(self) -> Token:
+        """è·å–æ¨¡æ‹Ÿä»¤ç‰Œ"""
+        return Token(
+            value=self.token_value,
+            token_type=TokenType.BEARER,
+            expires_at=time.monotonic() + self.ttl,
+            provider=self.provider_name
+        )
+
+    async def refresh_token(self, old_token: Optional[Token] = None) -> Token:
+        """åˆ·æ–°æ¨¡æ‹Ÿä»¤ç‰Œ"""
+        new_value = f"{self.token_value}_refreshed_{int(time.time())}"
+        return Token(
+            value=new_value,
+            token_type=TokenType.BEARER,
+            expires_at=time.monotonic() + self.ttl,
+            provider=self.provider_name
+        )
+
+
+# å…¨å±€ä»¤ç‰Œç®¡ç†å™¨å®ä¾‹
+_token_manager: Optional[TokenManager] = None
+
+
+async def get_token_manager() -> TokenManager:
+    """
+    è·å–å…¨å±€ä»¤ç‰Œç®¡ç†å™¨å®ä¾‹
+
+    Returns:
+        TokenManager: ä»¤ç‰Œç®¡ç†å™¨å®ä¾‹
+    """
+    global _token_manager
+    if _token_manager is None:
+        _token_manager = TokenManager()
+    return _token_manager
+
+
+async def close_token_manager():
+    """å…³é—­ä»¤ç‰Œç®¡ç†å™¨"""
+    global _token_manager
+    if _token_manager:
+        _token_manager = None
+
+
+# ä¾¿åˆ©å‡½æ•°
+def create_token_manager(
+    default_ttl: float = 3600.0,
+    cache_refresh_threshold: float = 300.0,
+    **kwargs
+) -> TokenManager:
+    """
+    åˆ›å»ºä»¤ç‰Œç®¡ç†å™¨çš„ä¾¿åˆ©å‡½æ•°
+
+    Args:
+        default_ttl: é»˜è®¤ä»¤ç‰Œç”Ÿå­˜æ—¶é—´
+        cache_refresh_threshold: ç¼“å­˜åˆ·æ–°é˜ˆå€¼
+        **kwargs: å…¶ä»–å‚æ•°
+
+    Returns:
+        TokenManager: ä»¤ç‰Œç®¡ç†å™¨å®ä¾‹
+    """
+    return TokenManager(default_ttl, cache_refresh_threshold, **kwargs)
+
+
+def create_fotmob_provider(**kwargs) -> FotMobAuthProvider:
+    """
+    åˆ›å»º FotMob è®¤è¯æä¾›è€…çš„ä¾¿åˆ©å‡½æ•°
+
+    Args:
+        **kwargs: FotMobAuthProvider å‚æ•°
+
+    Returns:
+        FotMobAuthProvider: FotMob è®¤è¯æä¾›è€…å®ä¾‹
+    """
+    return FotMobAuthProvider(**kwargs)
+
+
+def create_mock_provider(provider_name: str, **kwargs) -> MockAuthProvider:
+    """
+    åˆ›å»ºæ¨¡æ‹Ÿè®¤è¯æä¾›è€…çš„ä¾¿åˆ©å‡½æ•°
+
+    Args:
+        provider_name: æä¾›è€…åç§°
+        **kwargs: MockAuthProvider å‚æ•°
+
+    Returns:
+        MockAuthProvider: æ¨¡æ‹Ÿè®¤è¯æä¾›è€…å®ä¾‹
+    """
+    return MockAuthProvider(provider_name, **kwargs)
+
+
+# æ¨¡å—å¯¼å‡º
+__all__ = [
+    'Token',
+    'TokenType',
+    'AuthProvider',
+    'TokenManager',
+    'FotMobAuthProvider',
+    'MockAuthProvider',
+    'AuthenticationError',
+    'TokenExpiredError',
+    'TokenRefreshError',
+    'get_token_manager',
+    'close_token_manager',
+    'create_token_manager',
+    'create_fotmob_provider',
+    'create_mock_provider',
+]
\ No newline at end of file
diff --git a/src/collectors/fotmob/collector_v2.py b/src/collectors/fotmob/collector_v2.py
new file mode 100644
index 000000000..78a49b2e0
--- /dev/null
+++ b/src/collectors/fotmob/collector_v2.py
@@ -0,0 +1,602 @@
+"""
+FotMob é‡‡é›†å™¨ V2 - ç”Ÿäº§çº§æŠ—å°é”å®ç°
+FotMob Collector V2 - Production-Grade Anti-Blocking Implementation
+
+åŸºäºå·²å»ºç«‹çš„åŸºç¡€è®¾æ–½ï¼ˆæ¥å£ã€é™æµã€ä»£ç†ã€è®¤è¯ï¼‰ï¼Œé‡æ„ FotMob é‡‡é›†å™¨ï¼Œ
+å®ç°ä¸€ä¸ªç”Ÿäº§çº§ã€æŠ—å°é”çš„æ–°ç‰ˆé‡‡é›†å™¨ã€‚
+
+æ ¸å¿ƒç‰¹æ€§:
+1. å®ç° BaseCollectorProtocol æ¥å£
+2. ä¾èµ–æ³¨å…¥è®¾è®¡ (RateLimiter, ProxyPool, TokenManager)
+3. åŠ¨æ€ä»£ç†é…ç½®å’ŒTokenæ³¨å…¥
+4. æ™ºèƒ½é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
+5. 401/403 è‡ªåŠ¨Tokenåˆ·æ–°
+6. ä»£ç†å¥åº·çŠ¶æ€ç®¡ç†
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 2.0.0
+"""
+
+import asyncio
+import json
+import time
+from typing import Any, Dict, List, Optional, Union
+from urllib.parse import urljoin
+
+import httpx
+
+from ..auth import TokenManager
+from ..interface import (
+    BaseCollectorProtocol,
+    CollectorError,
+    AuthenticationError,
+    RateLimitError,
+    NetworkError,
+    DataNotFoundError,
+    FixtureData,
+    MatchDetailData,
+    TeamInfoData,
+    HealthStatus,
+)
+from ..proxy_pool import Proxy, ProxyPool
+from ..rate_limiter import RateLimiter
+
+
+class FotMobCollectorV2:
+    """
+    FotMob é‡‡é›†å™¨ V2 ç‰ˆæœ¬
+
+    åŸºäºå·²å»ºç«‹çš„åŸºç¡€è®¾æ–½å®ç°çš„ç”Ÿäº§çº§é‡‡é›†å™¨ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹æ€§ï¼š
+    - å®Œå…¨ç¬¦åˆ BaseCollectorProtocol æ¥å£
+    - ä¾èµ–æ³¨å…¥è®¾è®¡ï¼Œä¾¿äºæµ‹è¯•å’Œæ‰©å±•
+    - æ™ºèƒ½ä»£ç†ç®¡ç†å’ŒTokenæ³¨å…¥
+    - å¥å£®çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
+    - 401/403 è‡ªåŠ¨Tokenåˆ·æ–°
+    """
+
+    def __init__(
+        self,
+        rate_limiter: RateLimiter,
+        proxy_pool: ProxyPool,
+        token_manager: TokenManager,
+        base_url: str = "https://www.fotmob.com",
+        timeout: float = 30.0,
+        max_retries: int = 3,
+        retry_delay: float = 1.0,
+    ):
+        """
+        åˆå§‹åŒ– FotMob é‡‡é›†å™¨
+
+        Args:
+            rate_limiter: é€Ÿç‡é™åˆ¶å™¨å®ä¾‹
+            proxy_pool: ä»£ç†æ± å®ä¾‹
+            token_manager: Tokenç®¡ç†å™¨å®ä¾‹
+            base_url: FotMob APIåŸºç¡€URL
+            timeout: HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
+            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
+            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
+        """
+        self.rate_limiter = rate_limiter
+        self.proxy_pool = proxy_pool
+        self.token_manager = token_manager
+        self.base_url = base_url.rstrip("/")
+        self.timeout = timeout
+        self.max_retries = max_retries
+        self.retry_delay = retry_delay
+
+        # å†…éƒ¨çŠ¶æ€
+        self._error_count = 0
+        self._last_error: Optional[str] = None
+        self._closed = False
+
+        # ç»Ÿè®¡ä¿¡æ¯
+        self.stats = {
+            "total_requests": 0,
+            "successful_requests": 0,
+            "failed_requests": 0,
+            "token_refreshes": 0,
+            "proxy_rotations": 0,
+            "rate_limited_requests": 0,
+        }
+
+    async def _get_client(self, proxy: Optional[Proxy] = None) -> httpx.AsyncClient:
+        """
+        åŠ¨æ€æ„å»º HTTP å®¢æˆ·ç«¯
+
+        Args:
+            proxy: å¯é€‰çš„ä»£ç†é…ç½®
+
+        Returns:
+            httpx.AsyncClient: é…ç½®å¥½çš„HTTPå®¢æˆ·ç«¯
+        """
+        # åŸºç¡€é…ç½®
+        client_config = {
+            "timeout": httpx.Timeout(self.timeout),
+            "headers": {
+                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
+                "Accept": "application/json, text/plain, */*",
+                "Accept-Language": "en-US,en;q=0.9",
+                "Accept-Encoding": "gzip, deflate, br",
+                "Connection": "keep-alive",
+                "Upgrade-Insecure-Requests": "1",
+            },
+            "follow_redirects": True,
+        }
+
+        # é…ç½®ä»£ç†
+        if proxy:
+            if proxy.protocol == "socks5":
+                client_config["proxies"] = {
+                    "http://": f"socks5://{proxy.host}:{proxy.port}",
+                    "https://": f"socks5://{proxy.host}:{proxy.port}",
+                }
+            else:
+                proxy_url = proxy.url
+                client_config["proxies"] = {
+                    "http://": proxy_url,
+                    "https://": proxy_url,
+                }
+
+            # æ·»åŠ ä»£ç†è®¤è¯
+            if proxy.username and proxy.password:
+                client_config["auth"] = (proxy.username, proxy.password)
+
+        return httpx.AsyncClient(**client_config)
+
+    async def _inject_auth_headers(
+        self, headers: Dict[str, str], provider_name: str = "fotmob"
+    ) -> Dict[str, str]:
+        """
+        æ³¨å…¥è®¤è¯å¤´éƒ¨
+
+        Args:
+            headers: åŸå§‹è¯·æ±‚å¤´
+            provider_name: Tokenæä¾›è€…åç§°
+
+        Returns:
+            Dict[str, str]: åŒ…å«è®¤è¯ä¿¡æ¯çš„è¯·æ±‚å¤´
+        """
+        try:
+            token = await self.token_manager.get_token(provider_name)
+            if token.token_type.value == "custom_header":
+                # FotMobä½¿ç”¨è‡ªå®šä¹‰å¤´éƒ¨
+                headers.update(token.headers)
+            elif token.token_type.value == "bearer":
+                headers["Authorization"] = f"Bearer {token.value}"
+            elif token.token_type.value == "api_key":
+                headers["X-API-Key"] = token.value
+
+            return headers
+        except Exception as e:
+            raise AuthenticationError(f"Failed to inject authentication headers: {e}")
+
+    async def _make_request(
+        self,
+        method: str,
+        url: str,
+        *,
+        params: Optional[Dict[str, Any]] = None,
+        headers: Optional[Dict[str, str]] = None,
+        provider_name: str = "fotmob",
+    ) -> httpx.Response:
+        """
+        å‘èµ·HTTPè¯·æ±‚ï¼ŒåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
+
+        Args:
+            method: HTTPæ–¹æ³•
+            url: è¯·æ±‚URL
+            params: URLå‚æ•°
+            headers: è¯·æ±‚å¤´
+            provider_name: Tokenæä¾›è€…åç§°
+
+        Returns:
+            httpx.Response: HTTPå“åº”
+
+        Raises:
+            NetworkError: ç½‘ç»œé”™è¯¯
+            AuthenticationError: è®¤è¯å¤±è´¥
+            CollectorError: å…¶ä»–é‡‡é›†é”™è¯¯
+        """
+        if self._closed:
+            raise CollectorError("Collector has been closed")
+
+        # å‡†å¤‡è¯·æ±‚å¤´
+        request_headers = headers or {}
+        request_headers = await self._inject_auth_headers(request_headers, provider_name)
+
+        # è®°å½•è¯·æ±‚å¼€å§‹
+        self.stats["total_requests"] += 1
+        start_time = time.monotonic()
+
+        for attempt in range(self.max_retries + 1):
+            proxy = None
+
+            try:
+                # åº”ç”¨é€Ÿç‡é™åˆ¶
+                async with self.rate_limiter.acquire("fotmob_api"):
+                    self.stats["rate_limited_requests"] += 1 if attempt > 0 else 0
+
+                    # è·å–ä»£ç†ï¼ˆå¦‚æœé…ç½®äº†ä»£ç†æ± ï¼‰
+                    if self.proxy_pool:
+                        proxy = await self.proxy_pool.get_proxy()
+                        if proxy:
+                            self.stats["proxy_rotations"] += 1
+
+                    # æ„å»ºå®¢æˆ·ç«¯å¹¶å‘èµ·è¯·æ±‚
+                    async with await self._get_client(proxy) as client:
+                        response = await client.request(
+                            method=method,
+                            url=url,
+                            params=params,
+                            headers=request_headers,
+                        )
+
+                    # å¤„ç†è®¤è¯é”™è¯¯
+                    if response.status_code in (401, 403):
+                        if attempt < self.max_retries:
+                            # å¼ºåˆ¶åˆ·æ–°Tokenå¹¶é‡è¯•
+                            await self.token_manager.get_token(provider_name, force_refresh=True)
+                            self.stats["token_refreshes"] += 1
+                            await asyncio.sleep(self.retry_delay * (2 ** attempt))
+                            continue
+                        else:
+                            raise AuthenticationError(
+                                f"Authentication failed after {self.max_retries} retries"
+                            )
+
+                    # å¤„ç†å…¶ä»–HTTPé”™è¯¯
+                    if response.status_code >= 400:
+                        if response.status_code == 404:
+                            raise DataNotFoundError(f"Resource not found: {url}")
+                        elif response.status_code == 429:
+                            if attempt < self.max_retries:
+                                await asyncio.sleep(self.retry_delay * (2 ** attempt))
+                                continue
+                            raise RateLimitError("Rate limit exceeded")
+                        elif response.status_code >= 500:
+                            raise NetworkError(f"Server error: {response.status_code}")
+                        else:
+                            raise CollectorError(f"HTTP error: {response.status_code}")
+
+                    # è®°å½•æˆåŠŸ
+                    self.stats["successful_requests"] += 1
+                    if proxy:
+                        await self.proxy_pool.record_proxy_result(
+                            proxy, True, (time.monotonic() - start_time) * 1000
+                        )
+
+                    return response
+
+            except httpx.TimeoutException:
+                error_msg = f"Request timeout after {self.timeout}s"
+                if proxy:
+                    await self.proxy_pool.record_proxy_result(proxy, False, self.timeout * 1000)
+            except httpx.NetworkError as e:
+                error_msg = f"Network error: {e}"
+                if proxy:
+                    await self.proxy_pool.record_proxy_result(proxy, False, self.timeout * 1000)
+            except httpx.HTTPError as e:
+                error_msg = f"HTTP error: {e}"
+            except (AuthenticationError, RateLimitError, DataNotFoundError):
+                # è¿™äº›æ˜¯æˆ‘ä»¬å·²çŸ¥çš„ä¸šåŠ¡é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
+                self.stats["failed_requests"] += 1
+                raise
+            except Exception as e:
+                error_msg = f"Unexpected error: {e}"
+                if proxy:
+                    await self.proxy_pool.record_proxy_result(proxy, False, self.timeout * 1000)
+
+            # é‡è¯•é€»è¾‘
+            if attempt < self.max_retries:
+                await asyncio.sleep(self.retry_delay * (2 ** attempt))
+            else:
+                # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
+                self.stats["failed_requests"] += 1
+                self._error_count += 1
+                self._last_error = error_msg
+                raise NetworkError(f"Request failed after {self.max_retries} retries: {error_msg}")
+
+    async def collect_fixtures(
+        self, league_id: int, season_id: Optional[str] = None
+    ) -> List[Dict[str, Any]]:
+        """
+        é‡‡é›†è”èµ›èµ›ç¨‹æ•°æ®
+
+        Args:
+            league_id: è”èµ›ID (å¦‚: 47 for Premier League)
+            season_id: èµ›å­£ID (å¯é€‰ï¼Œå¦‚: "2024-2025")
+
+        Returns:
+            List[Dict[str, Any]]: èµ›ç¨‹æ•°æ®åˆ—è¡¨
+
+        Raises:
+            CollectorError: é‡‡é›†è¿‡ç¨‹ä¸­çš„é€šç”¨é”™è¯¯
+            AuthenticationError: è®¤è¯å¤±è´¥
+            RateLimitError: é€Ÿç‡é™åˆ¶
+            NetworkError: ç½‘ç»œè¿æ¥é—®é¢˜
+        """
+        url = f"{self.base_url}/api/matches"
+        params = {"leagueId": league_id}
+        if season_id:
+            params["seasonId"] = season_id
+
+        try:
+            response = await self._make_request("GET", url, params=params)
+            data = response.json()
+
+            # è§£æèµ›ç¨‹æ•°æ®
+            fixtures = []
+            matches = data.get("matches", [])
+
+            for match in matches:
+                fixture = {
+                    "match_id": str(match.get("id", "")),
+                    "home_team": match.get("home", {}).get("name", ""),
+                    "away_team": match.get("away", {}).get("name", ""),
+                    "kickoff_time": match.get("status", {}).get("utcTime", ""),
+                    "venue": match.get("venue", {}).get("name"),
+                    "status": match.get("status", {}).get("statusCode", ""),
+                    "league_id": league_id,
+                    "season_id": season_id,
+                }
+                fixtures.append(fixture)
+
+            return fixtures
+
+        except json.JSONDecodeError as e:
+            raise CollectorError(f"Failed to parse JSON response: {e}")
+        except Exception as e:
+            if isinstance(e, (AuthenticationError, RateLimitError, NetworkError)):
+                raise
+            raise CollectorError(f"Failed to collect fixtures: {e}")
+
+    async def collect_match_details(self, match_id: str) -> Dict[str, Any]:
+        """
+        é‡‡é›†æ¯”èµ›è¯¦æƒ…æ•°æ®
+
+        Args:
+            match_id: æ¯”èµ›å”¯ä¸€æ ‡è¯†
+
+        Returns:
+            Dict[str, Any]: æ¯”èµ›è¯¦æƒ…æ•°æ®
+
+        Raises:
+            CollectorError: é‡‡é›†è¿‡ç¨‹ä¸­çš„é€šç”¨é”™è¯¯
+            DataNotFoundError: æ¯”èµ›æ•°æ®ä¸å­˜åœ¨
+            AuthenticationError: è®¤è¯å¤±è´¥
+            RateLimitError: é€Ÿç‡é™åˆ¶
+            NetworkError: ç½‘ç»œè¿æ¥é—®é¢˜
+        """
+        url = f"{self.base_url}/api/matchDetails"
+        params = {"matchId": match_id}
+
+        try:
+            response = await self._make_request("GET", url, params=params)
+            data = response.json()
+
+            if not data:
+                raise DataNotFoundError(f"No data found for match {match_id}")
+
+            # è§£ææ¯”èµ›è¯¦æƒ…
+            match_data = data.get("match", {})
+            content = data.get("content", {})
+
+            details = {
+                "match_id": match_id,
+                "home_team": match_data.get("home", {}).get("name", ""),
+                "away_team": match_data.get("away", {}).get("name", ""),
+                "home_score": match_data.get("home", {}).get("score"),
+                "away_score": match_data.get("away", {}).get("score"),
+                "status": match_data.get("status", {}).get("statusCode", ""),
+                "kickoff_time": match_data.get("status", {}).get("utcTime", ""),
+            }
+
+            # æ·»åŠ æœŸæœ›è¿›çƒæ•°
+            xg_data = content.get("expectedGoals", {})
+            if xg_data:
+                details["home_xg"] = xg_data.get("home")
+                details["away_xg"] = xg_data.get("away")
+
+            # æ·»åŠ å°„é—¨æ•°æ®
+            shot_stats = content.get("shotmap", {}).get("stats", {})
+            if shot_stats:
+                details["shots"] = {
+                    "home": shot_stats.get("home", {}).get("total", 0),
+                    "away": shot_stats.get("away", {}).get("total", 0),
+                }
+
+            # æ·»åŠ æ§çƒç‡
+            possession_stats = content.get("possession", {})
+            if possession_stats:
+                details["possession"] = {
+                    "home": possession_stats.get("home", 0),
+                    "away": possession_stats.get("away", 0),
+                }
+
+            # æ·»åŠ æ¯”èµ›äº‹ä»¶
+            events = content.get("lineUp", {}).get("lineups", [])
+            details["events"] = events
+
+            # æ·»åŠ é˜µå®¹ä¿¡æ¯
+            lineups = content.get("lineUp", {})
+            details["lineups"] = {
+                "home": lineups.get("home", []),
+                "away": lineups.get("away", []),
+            }
+
+            # æ·»åŠ èµ”ç‡æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
+            odds_data = content.get("matchStats", {}).get("odds", {})
+            if odds_data:
+                details["odds"] = odds_data
+
+            return details
+
+        except json.JSONDecodeError as e:
+            raise CollectorError(f"Failed to parse JSON response: {e}")
+        except Exception as e:
+            if isinstance(e, (DataNotFoundError, AuthenticationError, RateLimitError, NetworkError)):
+                raise
+            raise CollectorError(f"Failed to collect match details: {e}")
+
+    async def collect_team_info(self, team_id: str) -> Dict[str, Any]:
+        """
+        é‡‡é›†çƒé˜Ÿä¿¡æ¯
+
+        Args:
+            team_id: çƒé˜Ÿå”¯ä¸€æ ‡è¯†
+
+        Returns:
+            Dict[str, Any]: çƒé˜Ÿä¿¡æ¯
+
+        Raises:
+            CollectorError: é‡‡é›†è¿‡ç¨‹ä¸­çš„é€šç”¨é”™è¯¯
+            DataNotFoundError: çƒé˜Ÿæ•°æ®ä¸å­˜åœ¨
+        """
+        url = f"{self.base_url}/api/teamDetails"
+        params = {"teamId": team_id}
+
+        try:
+            response = await self._make_request("GET", url, params=params)
+            data = response.json()
+
+            if not data:
+                raise DataNotFoundError(f"No data found for team {team_id}")
+
+            team_data = data.get("teamDetails", {}).get("team", {})
+
+            info = {
+                "team_id": team_id,
+                "name": team_data.get("name", ""),
+                "country": team_data.get("country", ""),
+                "founded": team_data.get("founded"),
+                "stadium": team_data.get("venue", {}).get("name"),
+                "logo_url": team_data.get("logoUrl"),
+            }
+
+            return info
+
+        except json.JSONDecodeError as e:
+            raise CollectorError(f"Failed to parse JSON response: {e}")
+        except Exception as e:
+            if isinstance(e, (DataNotFoundError, AuthenticationError, RateLimitError, NetworkError)):
+                raise
+            raise CollectorError(f"Failed to collect team info: {e}")
+
+    async def check_health(self) -> Dict[str, Any]:
+        """
+        æ£€æŸ¥é‡‡é›†å™¨å¥åº·çŠ¶æ€
+
+        Returns:
+            Dict[str, Any]: å¥åº·çŠ¶æ€ä¿¡æ¯
+
+        Raises:
+            CollectorError: å¥åº·æ£€æŸ¥å¤±è´¥
+        """
+        start_time = time.monotonic()
+        status = "healthy"
+        details = {}
+
+        try:
+            # 1. æ£€æŸ¥APIè¿é€šæ€§
+            url = f"{self.base_url}/api/matches"
+            await self._make_request("GET", url, params={"leagueId": 47})  # Test with Premier League
+            details["api_connectivity"] = True
+        except Exception as e:
+            status = "unhealthy"
+            details["api_connectivity"] = False
+            details["api_error"] = str(e)
+
+        try:
+            # 2. æ£€æŸ¥TokençŠ¶æ€
+            token_stats = await self.token_manager.get_stats()
+            details["token_stats"] = token_stats
+            if token_stats["valid_tokens"] == 0:
+                status = "unhealthy"
+        except Exception as e:
+            details["token_error"] = str(e)
+
+        try:
+            # 3. æ£€æŸ¥ä»£ç†æ± çŠ¶æ€
+            if self.proxy_pool:
+                proxy_stats = self.proxy_pool.get_stats()
+                details["proxy_stats"] = proxy_stats
+                if proxy_stats["active"] == 0:
+                    status = "degraded"
+        except Exception as e:
+            details["proxy_error"] = str(e)
+
+        # è®¡ç®—å“åº”æ—¶é—´
+        response_time_ms = (time.monotonic() - start_time) * 1000
+        if response_time_ms > 5000:  # 5ç§’é˜ˆå€¼
+            if status == "healthy":
+                status = "degraded"
+
+        return {
+            "status": status,
+            "response_time_ms": round(response_time_ms, 2),
+            "last_check": time.strftime("%Y-%m-%d %H:%M:%S UTC"),
+            "error_count": self._error_count,
+            "last_error": self._last_error,
+            "stats": self.stats.copy(),
+            "details": details,
+        }
+
+    async def close(self) -> None:
+        """æ¸…ç†èµ„æºå¹¶å…³é—­é‡‡é›†å™¨"""
+        if self._closed:
+            return
+
+        self._closed = True
+
+        # ä¿å­˜æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
+        final_stats = {
+            "total_requests": self.stats["total_requests"],
+            "successful_requests": self.stats["successful_requests"],
+            "failed_requests": self.stats["failed_requests"],
+            "success_rate": (
+                self.stats["successful_requests"] / max(self.stats["total_requests"], 1) * 100
+            ),
+            "token_refreshes": self.stats["token_refreshes"],
+            "proxy_rotations": self.stats["proxy_rotations"],
+            "rate_limited_requests": self.stats["rate_limited_requests"],
+            "error_count": self._error_count,
+        }
+
+        print(f"ğŸ“Š FotMobCollectorV2 å…³é—­ç»Ÿè®¡: {final_stats}")
+        self.stats = final_stats
+
+    def __del__(self):
+        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºè¢«æ¸…ç†"""
+        if not self._closed:
+            # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ä½¿ç”¨awaitï¼Œå› ä¸ºææ„å‡½æ•°æ˜¯åŒæ­¥çš„
+            print("âš ï¸ FotMobCollectorV2 æ²¡æœ‰è¢«æ­£ç¡®å…³é—­ï¼Œè¯·ç¡®ä¿è°ƒç”¨ close() æ–¹æ³•")
+
+
+# ä¾¿åˆ©å‡½æ•°ï¼Œç”¨äºåˆ›å»ºé‡‡é›†å™¨å®ä¾‹
+def create_fotmob_collector_v2(
+    rate_limiter: RateLimiter,
+    proxy_pool: ProxyPool,
+    token_manager: TokenManager,
+    **kwargs
+) -> FotMobCollectorV2:
+    """
+    åˆ›å»º FotMob é‡‡é›†å™¨ V2 å®ä¾‹çš„ä¾¿åˆ©å‡½æ•°
+
+    Args:
+        rate_limiter: é€Ÿç‡é™åˆ¶å™¨
+        proxy_pool: ä»£ç†æ± 
+        token_manager: Tokenç®¡ç†å™¨
+        **kwargs: å…¶ä»–ä¼ é€’ç»™é‡‡é›†å™¨çš„å‚æ•°
+
+    Returns:
+        FotMobCollectorV2: é‡‡é›†å™¨å®ä¾‹
+    """
+    return FotMobCollectorV2(rate_limiter, proxy_pool, token_manager, **kwargs)
+
+
+# å¯¼å‡º
+__all__ = [
+    "FotMobCollectorV2",
+    "create_fotmob_collector_v2",
+]
\ No newline at end of file
diff --git a/src/collectors/http_client_factory.py b/src/collectors/http_client_factory.py
new file mode 100644
index 000000000..5953bd105
--- /dev/null
+++ b/src/collectors/http_client_factory.py
@@ -0,0 +1,601 @@
+"""
+ç»Ÿä¸€ HTTP å®¢æˆ·ç«¯å·¥å‚
+Unified HTTP Client Factory
+
+è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ªç»Ÿä¸€çš„HTTPå®¢æˆ·ç«¯å·¥å‚ï¼Œç”¨äºï¼š
+1. è‡ªåŠ¨è£…é…é‡‡é›†å™¨ç»„ä»¶ï¼ˆRateLimiterã€TokenManagerã€ProxyPoolï¼‰
+2. ç®€åŒ–é‡‡é›†å™¨çš„å®ä¾‹åŒ–è¿‡ç¨‹
+3. æä¾›ç»Ÿä¸€çš„é…ç½®å’Œç›‘æ§æ¥å£
+4. æ”¯æŒå¤šç§æ•°æ®æºçš„å®¢æˆ·ç«¯åˆ›å»º
+
+è®¾è®¡æ¨¡å¼ï¼š
+- Factory Pattern: ç»Ÿä¸€åˆ›å»ºHTTPå®¢æˆ·ç«¯
+- Dependency Injection: ç»„ä»¶å¤–éƒ¨æ³¨å…¥
+- Builder Pattern: çµæ´»çš„é…ç½®æ„å»º
+- Observer Pattern: ç›‘æ§å’Œäº‹ä»¶é€šçŸ¥
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 1.0.0
+"""
+
+import asyncio
+import json
+import time
+from abc import ABC, abstractmethod
+from dataclasses import dataclass, field
+from typing import Any, Dict, List, Optional, Protocol, runtime_checkable
+from pathlib import Path
+
+import httpx
+
+from .auth import TokenManager, create_token_manager, create_fotmob_provider
+from .fotmob.collector_v2 import FotMobCollectorV2
+from .interface import BaseCollectorProtocol
+from .proxy_pool import ProxyPool, create_proxy_pool, RotationStrategy
+from .rate_limiter import RateLimiter, create_rate_limiter
+
+
+@runtime_checkable
+class CollectorConfig(Protocol):
+    """é‡‡é›†å™¨é…ç½®åè®®"""
+
+    @property
+    def source_name(self) -> str:
+        """æ•°æ®æºåç§°"""
+        ...
+
+    @property
+    def base_url(self) -> str:
+        """åŸºç¡€URL"""
+        ...
+
+    @property
+    def rate_limit_config(self) -> Dict[str, Any]:
+        """é€Ÿç‡é™åˆ¶é…ç½®"""
+        ...
+
+    @property
+    def token_manager_config(self) -> Dict[str, Any]:
+        """Tokenç®¡ç†å™¨é…ç½®"""
+        ...
+
+    @property
+    def proxy_config(self) -> Optional[Dict[str, Any]]:
+        """ä»£ç†é…ç½®"""
+        ...
+
+
+@dataclass
+class FotMobConfig:
+    """FotMob æ•°æ®æºé…ç½®"""
+    source_name: str = "fotmob"
+    base_url: str = "https://www.fotmob.com"
+
+    # é€Ÿç‡é™åˆ¶é…ç½®
+    rate_limit_config: Dict[str, Any] = field(default_factory=lambda: {
+        "rate": 3.0,        # 3 QPS (ä¿å®ˆé€Ÿç‡)
+        "burst": 8,         # çªå‘å®¹é‡
+        "max_wait_time": 30.0,  # æœ€å¤§ç­‰å¾…æ—¶é—´
+    })
+
+    # Tokenç®¡ç†å™¨é…ç½®
+    token_manager_config: Dict[str, Any] = field(default_factory=lambda: {
+        "default_ttl": 3600.0,          # 1å°æ—¶TTL
+        "cache_refresh_threshold": 300.0,  # 5åˆ†é’Ÿåˆ·æ–°é˜ˆå€¼
+        "max_retry_attempts": 3,
+        "retry_delay": 1.0,
+    })
+
+    # ä»£ç†é…ç½®
+    proxy_config: Optional[Dict[str, Any]] = field(default_factory=lambda: {
+        "urls": [
+            "http://127.0.0.1:8080",
+            "http://127.0.0.1:8081",
+            "socks5://127.0.0.1:1080"
+        ],
+        "strategy": "weighted_random",
+        "auto_health_check": True,
+        "max_fail_count": 5,
+        "min_score_threshold": 30.0,
+    })
+
+    # HTTPå®¢æˆ·ç«¯é…ç½®
+    timeout: float = 30.0
+    max_retries: int = 3
+    retry_delay: float = 1.0
+    user_agent: str = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
+
+
+class RequestEvent:
+    """è¯·æ±‚äº‹ä»¶æ•°æ®ç±»"""
+
+    def __init__(
+        self,
+        source: str,
+        method: str,
+        url: str,
+        status_code: Optional[int] = None,
+        response_time_ms: Optional[float] = None,
+        error: Optional[str] = None,
+        proxy_used: Optional[str] = None,
+        token_refreshed: bool = False,
+    ):
+        self.source = source
+        self.method = method
+        self.url = url
+        self.status_code = status_code
+        self.response_time_ms = response_time_ms
+        self.error = error
+        self.proxy_used = proxy_used
+        self.token_refreshed = token_refreshed
+        self.timestamp = time.monotonic()
+
+    def to_dict(self) -> Dict[str, Any]:
+        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
+        return {
+            "source": self.source,
+            "method": self.method,
+            "url": self.url,
+            "status_code": self.status_code,
+            "response_time_ms": self.response_time_ms,
+            "error": self.error,
+            "proxy_used": self.proxy_used,
+            "token_refreshed": self.token_refreshed,
+            "timestamp": self.timestamp,
+        }
+
+
+class RequestMonitor:
+    """è¯·æ±‚ç›‘æ§å™¨"""
+
+    def __init__(self):
+        self.events: List[RequestEvent] = []
+        self.stats: Dict[str, Any] = {
+            "total_requests": 0,
+            "successful_requests": 0,
+            "failed_requests": 0,
+            "total_response_time_ms": 0.0,
+            "token_refreshes": 0,
+            "proxy_rotations": 0,
+        }
+
+    def record_event(self, event: RequestEvent) -> None:
+        """è®°å½•è¯·æ±‚äº‹ä»¶"""
+        self.events.append(event)
+
+        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
+        self.stats["total_requests"] += 1
+
+        if event.status_code and 200 <= event.status_code < 400:
+            self.stats["successful_requests"] += 1
+        else:
+            self.stats["failed_requests"] += 1
+
+        if event.response_time_ms:
+            self.stats["total_response_time_ms"] += event.response_time_ms
+
+        if event.token_refreshed:
+            self.stats["token_refreshes"] += 1
+
+        if event.proxy_used:
+            self.stats["proxy_rotations"] += 1
+
+    def get_stats(self) -> Dict[str, Any]:
+        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
+        total_requests = self.stats["total_requests"]
+        avg_response_time = (
+            self.stats["total_response_time_ms"] / total_requests
+            if total_requests > 0 else 0.0
+        )
+
+        return {
+            **self.stats,
+            "avg_response_time_ms": round(avg_response_time, 2),
+            "success_rate": (
+                self.stats["successful_requests"] / total_requests * 100
+                if total_requests > 0 else 0.0
+            ),
+            "error_rate": (
+                self.stats["failed_requests"] / total_requests * 100
+                if total_requests > 0 else 0.0
+            ),
+        }
+
+    def get_events(self, source: Optional[str] = None, limit: Optional[int] = None) -> List[RequestEvent]:
+        """è·å–äº‹ä»¶åˆ—è¡¨"""
+        events = self.events
+        if source:
+            events = [e for e in events if e.source == source]
+        if limit:
+            events = events[-limit:]
+        return events
+
+    def clear(self) -> None:
+        """æ¸…é™¤æ‰€æœ‰äº‹ä»¶å’Œç»Ÿè®¡"""
+        self.events.clear()
+        self.stats = {
+            "total_requests": 0,
+            "successful_requests": 0,
+            "failed_requests": 0,
+            "total_response_time_ms": 0.0,
+            "token_refreshes": 0,
+            "proxy_rotations": 0,
+        }
+
+
+class HttpClientFactory:
+    """
+    ç»Ÿä¸€HTTPå®¢æˆ·ç«¯å·¥å‚
+
+    è´Ÿè´£åˆ›å»ºå’Œé…ç½®ä¸åŒæ•°æ®æºçš„HTTPå®¢æˆ·ç«¯ï¼Œæä¾›ï¼š
+    1. ç»„ä»¶è‡ªåŠ¨è£…é…ï¼ˆRateLimiterã€TokenManagerã€ProxyPoolï¼‰
+    2. ç»Ÿä¸€çš„é…ç½®ç®¡ç†
+    3. ç›‘æ§å’Œäº‹ä»¶è®°å½•
+    4. å¯æµ‹è¯•çš„ä¾èµ–æ³¨å…¥æ”¯æŒ
+    """
+
+    def __init__(self):
+        self._components: Dict[str, Any] = {}
+        self._monitor = RequestMonitor()
+
+        # é¢„å®šä¹‰çš„æ•°æ®æºé…ç½®
+        self._configs: Dict[str, CollectorConfig] = {
+            "fotmob": FotMobConfig(),
+        }
+
+    def register_config(self, source: str, config: CollectorConfig) -> None:
+        """æ³¨å†Œæ•°æ®æºé…ç½®"""
+        self._configs[source] = config
+
+    def register_component(self, name: str, component: Any) -> None:
+        """æ³¨å†Œç»„ä»¶ï¼ˆç”¨äºä¾èµ–æ³¨å…¥ï¼‰"""
+        self._components[name] = component
+
+    def get_monitor(self) -> RequestMonitor:
+        """è·å–è¯·æ±‚ç›‘æ§å™¨"""
+        return self._monitor
+
+    async def create_rate_limiter(self, source: str, config: CollectorConfig) -> RateLimiter:
+        """åˆ›å»ºé€Ÿç‡é™åˆ¶å™¨"""
+        if f"{source}_rate_limiter" in self._components:
+            return self._components[f"{source}_rate_limiter"]
+
+        return create_rate_limiter({
+            f"{source}_api": config.rate_limit_config
+        })
+
+    async def create_proxy_pool(self, source: str, config: CollectorConfig) -> ProxyPool:
+        """åˆ›å»ºä»£ç†æ± """
+        if f"{source}_proxy_pool" in self._components:
+            return self._components[f"{source}_proxy_pool"]
+
+        proxy_config = config.proxy_config
+        if not proxy_config:
+            # è¿”å›ç©ºçš„ä»£ç†æ± 
+            return ProxyPool([])
+
+        return create_proxy_pool(
+            proxy_config["urls"],
+            strategy=RotationStrategy(proxy_config["strategy"]),
+            auto_health_check=proxy_config["auto_health_check"],
+            max_fail_count=proxy_config["max_fail_count"],
+            min_score_threshold=proxy_config["min_score_threshold"],
+        )
+
+    async def create_token_manager(self, source: str, config: CollectorConfig) -> TokenManager:
+        """åˆ›å»ºTokenç®¡ç†å™¨"""
+        if f"{source}_token_manager" in self._components:
+            return self._components[f"{source}_token_manager"]
+
+        token_manager = create_token_manager(**config.token_manager_config)
+
+        # ä¸ºç‰¹å®šæ•°æ®æºæ³¨å†ŒToken Provider
+        if source == "fotmob":
+            from .auth import create_fotmob_provider
+            fotmob_provider = create_fotmob_provider()
+            await token_manager.register_provider(fotmob_provider)
+
+        return token_manager
+
+    async def create_collector(self, source: str) -> BaseCollectorProtocol:
+        """
+        åˆ›å»ºé‡‡é›†å™¨å®ä¾‹
+
+        Args:
+            source: æ•°æ®æºåç§° (å¦‚: "fotmob")
+
+        Returns:
+            BaseCollectorProtocol: é…ç½®å¥½çš„é‡‡é›†å™¨å®ä¾‹
+
+        Raises:
+            ValueError: ä¸æ”¯æŒçš„æ•°æ®æº
+        """
+        if source not in self._configs:
+            raise ValueError(f"Unsupported data source: {source}")
+
+        config = self._configs[source]
+
+        print(f"ğŸ­ åˆ›å»º {source} é‡‡é›†å™¨...")
+
+        # åˆ›å»ºç»„ä»¶
+        rate_limiter = await self.create_rate_limiter(source, config)
+        proxy_pool = await self.create_proxy_pool(source, config)
+        token_manager = await self.create_token_manager(source, config)
+
+        print(f"   âœ… RateLimiter: {config.rate_limit_config['rate']} QPS")
+        print(f"   âœ… ProxyPool: {len(proxy_pool.proxies) if proxy_pool else 0} ä¸ªä»£ç†")
+        print(f"   âœ… TokenManager: {len(token_manager.token_cache)} ä¸ªæä¾›è€…")
+
+        # åˆ›å»ºé‡‡é›†å™¨
+        if source == "fotmob":
+            collector = FotMobCollectorV2(
+                rate_limiter=rate_limiter,
+                proxy_pool=proxy_pool,
+                token_manager=token_manager,
+                base_url=config.base_url,
+                timeout=config.timeout,
+                max_retries=config.max_retries,
+                retry_delay=config.retry_delay,
+            )
+        else:
+            raise ValueError(f"No collector implementation for source: {source}")
+
+        # åŒ…è£…é‡‡é›†å™¨ä»¥æ·»åŠ ç›‘æ§
+        monitored_collector = MonitoredCollector(collector, source, self._monitor)
+
+        print(f"   âœ… {source} é‡‡é›†å™¨åˆ›å»ºå®Œæˆ")
+        return monitored_collector
+
+    async def create_client(self, source: str) -> httpx.AsyncClient:
+        """
+        åˆ›å»ºHTTPå®¢æˆ·ç«¯
+
+        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ä¸»è¦æä¾›HTTPå®¢æˆ·ç«¯çš„åŸºç¡€é…ç½®ï¼Œ
+        å¯¹äºå®Œæ•´çš„é‡‡é›†åŠŸèƒ½ï¼Œå»ºè®®ä½¿ç”¨ create_collector() æ–¹æ³•ã€‚
+
+        Args:
+            source: æ•°æ®æºåç§°
+
+        Returns:
+            httpx.AsyncClient: é…ç½®å¥½çš„HTTPå®¢æˆ·ç«¯
+        """
+        if source not in self._configs:
+            raise ValueError(f"Unsupported data source: {source}")
+
+        config = self._configs[source]
+
+        # åˆ›å»ºHTTPå®¢æˆ·ç«¯é…ç½®
+        client_config = {
+            "timeout": httpx.Timeout(config.timeout),
+            "headers": {
+                "User-Agent": config.user_agent,
+                "Accept": "application/json, text/plain, */*",
+                "Accept-Language": "en-US,en;q=0.9",
+                "Accept-Encoding": "gzip, deflate, br",
+                "Connection": "keep-alive",
+                "Upgrade-Insecure-Requests": "1",
+            },
+            "follow_redirects": True,
+        }
+
+        # æ³¨å…¥Tokenï¼ˆå¦‚æœé…ç½®äº†TokenManagerï¼‰
+        if f"{source}_token_manager" in self._components:
+            token_manager = self._components[f"{source}_token_manager"]
+            try:
+                token = await token_manager.get_token(source)
+                if token.token_type.value == "custom_header":
+                    client_config["headers"].update(token.headers)
+                elif token.token_type.value == "bearer":
+                    client_config["headers"]["Authorization"] = f"Bearer {token.value}"
+                elif token.token_type.value == "api_key":
+                    client_config["headers"]["X-API-Key"] = token.value
+            except Exception as e:
+                print(f"âš ï¸ Failed to inject token for {source}: {e}")
+
+        # é…ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
+        if f"{source}_proxy_pool" in self._components:
+            proxy_pool = self._components[f"{source}_proxy_pool"]
+            if proxy_pool.proxies:
+                proxy = proxy_pool.proxies[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªä»£ç†
+                if proxy.protocol == "socks5":
+                    client_config["proxies"] = {
+                        "http://": f"socks5://{proxy.host}:{proxy.port}",
+                        "https://": f"socks5://{proxy.host}:{proxy.port}",
+                    }
+                else:
+                    proxy_url = proxy.url
+                    client_config["proxies"] = {
+                        "http://": proxy_url,
+                        "https://": proxy_url,
+                    }
+
+                # æ·»åŠ ä»£ç†è®¤è¯
+                if proxy.username and proxy.password:
+                    client_config["auth"] = (proxy.username, proxy.password)
+
+        return httpx.AsyncClient(**client_config)
+
+    def get_available_sources(self) -> List[str]:
+        """è·å–å¯ç”¨çš„æ•°æ®æºåˆ—è¡¨"""
+        return list(self._configs.keys())
+
+    def get_config(self, source: str) -> Optional[CollectorConfig]:
+        """è·å–æ•°æ®æºé…ç½®"""
+        return self._configs.get(source)
+
+
+class MonitoredCollector:
+    """å¸¦ç›‘æ§åŠŸèƒ½çš„é‡‡é›†å™¨åŒ…è£…å™¨"""
+
+    def __init__(
+        self,
+        collector: BaseCollectorProtocol,
+        source: str,
+        monitor: RequestMonitor
+    ):
+        self.collector = collector
+        self.source = source
+        self.monitor = monitor
+
+    async def collect_fixtures(self, league_id: int, season_id: Optional[str] = None) -> List[Dict[str, Any]]:
+        """é‡‡é›†èµ›ç¨‹æ•°æ®ï¼ˆå¸¦ç›‘æ§ï¼‰"""
+        start_time = time.monotonic()
+        try:
+            result = await self.collector.collect_fixtures(league_id, season_id)
+
+            # è®°å½•æˆåŠŸäº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="collect_fixtures",
+                url=f"{self.source}://api/matches?leagueId={league_id}",
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+
+            return result
+
+        except Exception as e:
+            # è®°å½•å¤±è´¥äº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="collect_fixtures",
+                url=f"{self.source}://api/matches?leagueId={league_id}",
+                error=str(e),
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+            raise
+
+    async def collect_match_details(self, match_id: str) -> Dict[str, Any]:
+        """é‡‡é›†æ¯”èµ›è¯¦æƒ…ï¼ˆå¸¦ç›‘æ§ï¼‰"""
+        start_time = time.monotonic()
+        try:
+            result = await self.collector.collect_match_details(match_id)
+
+            # è®°å½•æˆåŠŸäº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="collect_match_details",
+                url=f"{self.source}://api/matchDetails?matchId={match_id}",
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+
+            return result
+
+        except Exception as e:
+            # è®°å½•å¤±è´¥äº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="collect_match_details",
+                url=f"{self.source}://api/matchDetails?matchId={match_id}",
+                error=str(e),
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+            raise
+
+    async def collect_team_info(self, team_id: str) -> Dict[str, Any]:
+        """é‡‡é›†çƒé˜Ÿä¿¡æ¯ï¼ˆå¸¦ç›‘æ§ï¼‰"""
+        start_time = time.monotonic()
+        try:
+            result = await self.collector.collect_team_info(team_id)
+
+            # è®°å½•æˆåŠŸäº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="collect_team_info",
+                url=f"{self.source}://api/teamDetails?teamId={team_id}",
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+
+            return result
+
+        except Exception as e:
+            # è®°å½•å¤±è´¥äº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="collect_team_info",
+                url=f"{self.source}://api/teamDetails?teamId={team_id}",
+                error=str(e),
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+            raise
+
+    async def check_health(self) -> Dict[str, Any]:
+        """å¥åº·æ£€æŸ¥ï¼ˆå¸¦ç›‘æ§ï¼‰"""
+        start_time = time.monotonic()
+        try:
+            result = await self.collector.check_health()
+
+            # è®°å½•æˆåŠŸäº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="check_health",
+                url=f"{self.source}://health",
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+
+            return result
+
+        except Exception as e:
+            # è®°å½•å¤±è´¥äº‹ä»¶
+            event = RequestEvent(
+                source=self.source,
+                method="check_health",
+                url=f"{self.source}://health",
+                error=str(e),
+                response_time_ms=(time.monotonic() - start_time) * 1000,
+            )
+            self.monitor.record_event(event)
+            raise
+
+    async def close(self) -> None:
+        """å…³é—­é‡‡é›†å™¨"""
+        await self.collector.close()
+
+    def __getattr__(self, name):
+        """è½¬å‘å…¶ä»–å±æ€§è°ƒç”¨åˆ°åŸå§‹é‡‡é›†å™¨"""
+        return getattr(self.collector, name)
+
+
+# å…¨å±€å·¥å‚å®ä¾‹
+_global_factory: Optional[HttpClientFactory] = None
+
+
+def get_http_client_factory() -> HttpClientFactory:
+    """è·å–å…¨å±€HTTPå®¢æˆ·ç«¯å·¥å‚å®ä¾‹"""
+    global _global_factory
+    if _global_factory is None:
+        _global_factory = HttpClientFactory()
+    return _global_factory
+
+
+async def create_collector(source: str) -> BaseCollectorProtocol:
+    """åˆ›å»ºé‡‡é›†å™¨çš„ä¾¿åˆ©å‡½æ•°"""
+    factory = get_http_client_factory()
+    return await factory.create_collector(source)
+
+
+async def create_http_client(source: str) -> httpx.AsyncClient:
+    """åˆ›å»ºHTTPå®¢æˆ·ç«¯çš„ä¾¿åˆ©å‡½æ•°"""
+    factory = get_http_client_factory()
+    return await factory.create_client(source)
+
+
+# å¯¼å‡º
+__all__ = [
+    "CollectorConfig",
+    "FotMobConfig",
+    "RequestEvent",
+    "RequestMonitor",
+    "HttpClientFactory",
+    "MonitoredCollector",
+    "get_http_client_factory",
+    "create_collector",
+    "create_http_client",
+]
\ No newline at end of file
diff --git a/src/collectors/interface.py b/src/collectors/interface.py
new file mode 100644
index 000000000..48798abc3
--- /dev/null
+++ b/src/collectors/interface.py
@@ -0,0 +1,269 @@
+"""
+ç»Ÿä¸€é‡‡é›†å™¨æ¥å£åè®®å®šä¹‰
+Base Collector Protocol Definition
+
+è¯¥æ¨¡å—å®šä¹‰äº†æ‰€æœ‰æ•°æ®é‡‡é›†å™¨å¿…é¡»å®ç°çš„æ ‡å‡†æ¥å£ï¼Œç¡®ä¿ï¼š
+1. ç»Ÿä¸€çš„æ–¹æ³•ç­¾åå’Œè¿”å›ç±»å‹
+2. æ ‡å‡†åŒ–çš„é”™è¯¯å¤„ç†çº¦å®š
+3. å¯æ’æ‹”çš„é‡‡é›†å™¨æ¶æ„
+4. ç±»å‹å®‰å…¨çš„å¼‚æ­¥æ“ä½œ
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 1.0.0
+"""
+
+from abc import abstractmethod
+from typing import Any, Dict, List, Optional, Protocol, runtime_checkable
+
+
+@runtime_checkable
+class BaseCollectorProtocol(Protocol):
+    """
+    åŸºç¡€é‡‡é›†å™¨åè®®æ¥å£
+
+    æ‰€æœ‰æ•°æ®é‡‡é›†å™¨éƒ½å¿…é¡»å®ç°æ­¤åè®®ï¼Œç¡®ä¿ç»Ÿä¸€çš„è¡Œä¸ºå¥‘çº¦ã€‚
+    ä½¿ç”¨ Python çš„ Structural Subtyping (Protocol) è€Œéç»§æ‰¿ï¼Œ
+    æä¾›æ›´å¤§çš„çµæ´»æ€§å’Œ Pythonic çš„å®ç°æ–¹å¼ã€‚
+
+    æ ¸å¿ƒè®¾è®¡åŸåˆ™:
+    1. æ‰€æœ‰ç½‘ç»œIOæ“ä½œå¿…é¡»æ˜¯å¼‚æ­¥çš„
+    2. ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•ç­–ç•¥
+    3. æ ‡å‡†åŒ–çš„æ•°æ®æ ¼å¼
+    4. èµ„æºç®¡ç†å’Œæ¸…ç†æœºåˆ¶
+    """
+
+    @abstractmethod
+    async def collect_fixtures(
+        self,
+        league_id: int,
+        season_id: Optional[str] = None
+    ) -> List[Dict[str, Any]]:
+        """
+        é‡‡é›†è”èµ›èµ›ç¨‹æ•°æ®
+
+        Args:
+            league_id: è”èµ›ID (å¦‚: 47 for Premier League)
+            season_id: èµ›å­£ID (å¯é€‰ï¼Œå¦‚: "2024-2025")
+
+        Returns:
+            List[Dict[str, Any]]: èµ›ç¨‹æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«:
+                - match_id: str - æ¯”èµ›å”¯ä¸€æ ‡è¯†
+                - home_team: str - ä¸»é˜Ÿåç§°
+                - away_team: str - å®¢é˜Ÿåç§°
+                - kickoff_time: str - å¼€èµ›æ—¶é—´ (ISO 8601)
+                - venue: Optional[str] - åœºåœ°ä¿¡æ¯
+                - status: str - æ¯”èµ›çŠ¶æ€
+
+        Raises:
+            CollectorError: é‡‡é›†è¿‡ç¨‹ä¸­çš„é€šç”¨é”™è¯¯
+            AuthenticationError: è®¤è¯å¤±è´¥
+            RateLimitError: é€Ÿç‡é™åˆ¶
+            NetworkError: ç½‘ç»œè¿æ¥é—®é¢˜
+        """
+        ...
+
+    @abstractmethod
+    async def collect_match_details(
+        self,
+        match_id: str
+    ) -> Dict[str, Any]:
+        """
+        é‡‡é›†æ¯”èµ›è¯¦æƒ…æ•°æ®
+
+        Args:
+            match_id: æ¯”èµ›å”¯ä¸€æ ‡è¯†
+
+        Returns:
+            Dict[str, Any]: æ¯”èµ›è¯¦æƒ…æ•°æ®ï¼ŒåŒ…å«:
+                - match_id: str - æ¯”èµ›ID
+                - home_score: Optional[int] - ä¸»é˜Ÿå¾—åˆ†
+                - away_score: Optional[int] - å®¢é˜Ÿå¾—åˆ†
+                - home_xg: Optional[float] - ä¸»é˜ŸæœŸæœ›è¿›çƒæ•°
+                - away_xg: Optional[float] - å®¢é˜ŸæœŸæœ›è¿›çƒæ•°
+                - shots: Dict[str, int] - å°„é—¨æ•°æ®
+                - possession: Dict[str, float] - æ§çƒç‡
+                - events: List[Dict] - æ¯”èµ›äº‹ä»¶åˆ—è¡¨
+                - lineups: Dict[str, List] - é˜µå®¹ä¿¡æ¯
+                - odds: Optional[Dict] - èµ”ç‡æ•°æ®
+
+        Raises:
+            CollectorError: é‡‡é›†è¿‡ç¨‹ä¸­çš„é€šç”¨é”™è¯¯
+            DataNotFoundError: æ¯”èµ›æ•°æ®ä¸å­˜åœ¨
+            AuthenticationError: è®¤è¯å¤±è´¥
+            RateLimitError: é€Ÿç‡é™åˆ¶
+            NetworkError: ç½‘ç»œè¿æ¥é—®é¢˜
+        """
+        ...
+
+    @abstractmethod
+    async def collect_team_info(
+        self,
+        team_id: str
+    ) -> Dict[str, Any]:
+        """
+        é‡‡é›†çƒé˜Ÿä¿¡æ¯
+
+        Args:
+            team_id: çƒé˜Ÿå”¯ä¸€æ ‡è¯†
+
+        Returns:
+            Dict[str, Any]: çƒé˜Ÿä¿¡æ¯ï¼ŒåŒ…å«:
+                - team_id: str - çƒé˜ŸID
+                - name: str - çƒé˜Ÿåç§°
+                - country: str - å›½å®¶
+                - founded: Optional[int] - æˆç«‹å¹´ä»½
+                - stadium: Optional[str] - ä¸»åœº
+                - logo_url: Optional[str] - çƒé˜Ÿå¾½æ ‡URL
+
+        Raises:
+            CollectorError: é‡‡é›†è¿‡ç¨‹ä¸­çš„é€šç”¨é”™è¯¯
+            DataNotFoundError: çƒé˜Ÿæ•°æ®ä¸å­˜åœ¨
+        """
+        ...
+
+    @abstractmethod
+    async def check_health(self) -> Dict[str, Any]:
+        """
+        æ£€æŸ¥é‡‡é›†å™¨å¥åº·çŠ¶æ€
+
+        æ­¤æ–¹æ³•ç”¨äºï¼š
+        1. ä»£ç†æ± å¥åº·æ£€æŸ¥
+        2. APIè¿é€šæ€§éªŒè¯
+        3. è®¤è¯çŠ¶æ€æ£€æŸ¥
+        4. é€Ÿç‡é™åˆ¶çŠ¶æ€æŸ¥è¯¢
+
+        Returns:
+            Dict[str, Any]: å¥åº·çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…å«:
+                - status: str - "healthy" | "degraded" | "unhealthy"
+                - response_time_ms: float - å“åº”æ—¶é—´(æ¯«ç§’)
+                - last_check: str - æœ€åæ£€æŸ¥æ—¶é—´
+                - error_count: int - é”™è¯¯è®¡æ•°
+                - details: Dict[str, Any] - é¢å¤–è¯¦æƒ…
+
+        Example:
+            >>> health = await collector.check_health()
+            >>> if health["status"] == "healthy":
+            ...     print("é‡‡é›†å™¨è¿è¡Œæ­£å¸¸")
+        """
+        ...
+
+    @abstractmethod
+    async def close(self) -> None:
+        """
+        æ¸…ç†èµ„æºå¹¶å…³é—­é‡‡é›†å™¨
+
+        æ­¤æ–¹æ³•è´Ÿè´£ï¼š
+        1. å…³é—­HTTPå®¢æˆ·ç«¯è¿æ¥
+        2. æ¸…ç†ä»£ç†æ± èµ„æº
+        3. ä¿å­˜ç¼“å­˜æ•°æ®
+        4. å–æ¶ˆè¿›è¡Œä¸­çš„ä»»åŠ¡
+
+        æ³¨æ„:
+        - å¿…é¡»åœ¨ç¨‹åºé€€å‡ºå‰è°ƒç”¨
+        - æ”¯æŒå¤šæ¬¡è°ƒç”¨è€Œæ— å‰¯ä½œç”¨
+        - åº”è¯¥ä¼˜é›…åœ°å¤„ç†æ¸…ç†å¤±è´¥
+        """
+        ...
+
+
+@runtime_checkable
+class ExtendedCollectorProtocol(BaseCollectorProtocol, Protocol):
+    """
+    æ‰©å±•é‡‡é›†å™¨åè®®æ¥å£
+
+    ä¸ºé«˜çº§é‡‡é›†å™¨æä¾›é¢å¤–çš„åŠŸèƒ½ï¼Œå¦‚ï¼š
+    - æ‰¹é‡æ“ä½œæ”¯æŒ
+    - æµå¼æ•°æ®å¤„ç†
+    - è‡ªå®šä¹‰é…ç½®ç®¡ç†
+    """
+
+    @abstractmethod
+    async def collect_batch_fixtures(
+        self,
+        league_ids: List[int],
+        season_id: Optional[str] = None
+    ) -> Dict[int, List[Dict[str, Any]]]:
+        """
+        æ‰¹é‡é‡‡é›†å¤šä¸ªè”èµ›çš„èµ›ç¨‹æ•°æ®
+
+        Args:
+            league_ids: è”èµ›IDåˆ—è¡¨
+            season_id: èµ›å­£ID
+
+        Returns:
+            Dict[int, List[Dict]]: æŒ‰è”èµ›IDåˆ†ç»„çš„èµ›ç¨‹æ•°æ®
+        """
+        ...
+
+    @abstractmethod
+    async def stream_fixtures(
+        self,
+        league_id: int,
+        season_id: Optional[str] = None
+    ):
+        """
+        æµå¼é‡‡é›†èµ›ç¨‹æ•°æ®
+
+        Args:
+            league_id: è”èµ›ID
+            season_id: èµ›å­£ID
+
+        Yields:
+            Dict[str, Any]: å•ä¸ªèµ›ç¨‹æ•°æ®
+        """
+        ...
+
+
+# é‡‡é›†å™¨å¼‚å¸¸ç±»å‹å®šä¹‰
+class CollectorError(Exception):
+    """é‡‡é›†å™¨åŸºç¡€å¼‚å¸¸ç±»"""
+    pass
+
+
+class AuthenticationError(CollectorError):
+    """è®¤è¯å¤±è´¥å¼‚å¸¸"""
+    pass
+
+
+class RateLimitError(CollectorError):
+    """é€Ÿç‡é™åˆ¶å¼‚å¸¸"""
+    pass
+
+
+class NetworkError(CollectorError):
+    """ç½‘ç»œè¿æ¥å¼‚å¸¸"""
+    pass
+
+
+class DataNotFoundError(CollectorError):
+    """æ•°æ®æœªæ‰¾åˆ°å¼‚å¸¸"""
+    pass
+
+
+class ConfigurationError(CollectorError):
+    """é…ç½®é”™è¯¯å¼‚å¸¸"""
+    pass
+
+
+# ç±»å‹åˆ«åï¼Œæé«˜ä»£ç å¯è¯»æ€§
+FixtureData = Dict[str, Any]
+MatchDetailData = Dict[str, Any]
+TeamInfoData = Dict[str, Any]
+HealthStatus = Dict[str, Any]
+
+# å¯¼å‡ºçš„å…¬å…±æ¥å£
+__all__ = [
+    "BaseCollectorProtocol",
+    "ExtendedCollectorProtocol",
+    "CollectorError",
+    "AuthenticationError",
+    "RateLimitError",
+    "NetworkError",
+    "DataNotFoundError",
+    "ConfigurationError",
+    "FixtureData",
+    "MatchDetailData",
+    "TeamInfoData",
+    "HealthStatus",
+]
\ No newline at end of file
diff --git a/src/collectors/proxy_pool.py b/src/collectors/proxy_pool.py
index 30de1caff..50ad39b6b 100644
--- a/src/collectors/proxy_pool.py
+++ b/src/collectors/proxy_pool.py
@@ -1,392 +1,708 @@
-"""ä»£ç†æ± ç®¡ç†å™¨ - åçˆ¬å¯¹æŠ—æ ¸å¿ƒç»„ä»¶
-Proxy Pool Manager - Anti-Scraping Core Component.
-
-æä¾›æ™ºèƒ½ä»£ç†è½®æ¢ã€å¥åº·æ£€æŸ¥ã€æ€§èƒ½ç›‘æ§ç­‰åŠŸèƒ½ã€‚
+"""
+ä»£ç†æ±  (ProxyPool) å®ç°
+Proxy Pool Implementation
+
+è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ªé«˜å¯ç”¨ã€å¯æ‰©å±•çš„ä»£ç†æ± ç³»ç»Ÿï¼Œæ”¯æŒï¼š
+1. å¤šç§ä»£ç†æ¥æºï¼ˆæ–‡ä»¶/API/ç¯å¢ƒå˜é‡ï¼‰
+2. ä»£ç†å¥åº·è¯„åˆ†å’Œé»‘åå•æœºåˆ¶
+3. å¤šç­–ç•¥è½®è¯¢ï¼ˆéšæœº/è½®è¯¢ï¼‰
+4. è‡ªåŠ¨å‰”é™¤å¤±æ•ˆä»£ç†
+5. å¼‚æ­¥æ¥å£è®¾è®¡
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 1.0.0
 """
 
 import asyncio
 import random
 import time
-from dataclasses import dataclass
+from abc import abstractmethod
+from dataclasses import dataclass, field
 from enum import Enum
-from typing import Set
-from urllib.parse import urlparse
+from pathlib import Path
+from typing import Any, Dict, List, Optional, Protocol, runtime_checkable
 
 import aiohttp
-import backoff
-from src.core.logging import get_logger
 
-logger = get_logger(__name__)
 
+class ProxyProtocol(Enum):
+    """ä»£ç†åè®®ç±»å‹"""
+    HTTP = "http"
+    HTTPS = "https"
+    SOCKS4 = "socks4"
+    SOCKS5 = "socks5"
 
-class ProxyStatus(Enum):
-    """ä»£ç†çŠ¶æ€æšä¸¾."""
 
-    ACTIVE = "active"
-    FAILED = "failed"
-    TESTING = "testing"
-    BANNED = "banned"
+class ProxyStatus(Enum):
+    """ä»£ç†çŠ¶æ€"""
+    ACTIVE = "active"      # æ´»è·ƒå¯ç”¨
+    BANNED = "banned"      # å·²è¢«ç¦ç”¨
+    TESTING = "testing"    # æµ‹è¯•ä¸­
 
 
 @dataclass
-class ProxyConfig:
-    """ä»£ç†é…ç½®."""
-
+class Proxy:
+    """
+    ä»£ç†ä¿¡æ¯æ•°æ®ç±»
+
+    Attributes:
+        url: ä»£ç†å®Œæ•´URL (å¦‚: http://127.0.0.1:8080)
+        protocol: ä»£ç†åè®®ç±»å‹
+        host: ä»£ç†ä¸»æœºåœ°å€
+        port: ä»£ç†ç«¯å£
+        username: ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
+        password: å¯†ç ï¼ˆå¯é€‰ï¼‰
+        score: ä¿¡èª‰åˆ†æ•° (0-100)
+        fail_count: è¿ç»­å¤±è´¥æ¬¡æ•°
+        success_count: è¿ç»­æˆåŠŸæ¬¡æ•°
+        last_used: æœ€åä½¿ç”¨æ—¶é—´
+        last_check: æœ€åæ£€æŸ¥æ—¶é—´
+        status: ä»£ç†çŠ¶æ€
+        response_time: å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
+    """
+    url: str
+    protocol: ProxyProtocol
     host: str
     port: int
     username: Optional[str] = None
     password: Optional[str] = None
-    proxy_type: str = "http"  # http, https, socks5
+    score: float = 100.0
+    fail_count: int = 0
+    success_count: int = 0
+    last_used: Optional[float] = field(default_factory=time.monotonic)
+    last_check: Optional[float] = field(default_factory=time.monotonic)
+    status: ProxyStatus = ProxyStatus.ACTIVE
+    response_time: Optional[float] = None
+
+    def __post_init__(self) -> None:
+        """åˆå§‹åŒ–åå¤„ç†"""
+        if isinstance(self.protocol, str):
+            self.protocol = ProxyProtocol(self.protocol.lower())
+        if isinstance(self.status, str):
+            self.status = ProxyStatus(self.status.lower())
+
+    @classmethod
+    def from_url(cls, url: str, **kwargs) -> 'Proxy':
+        """
+        ä»URLåˆ›å»ºä»£ç†å¯¹è±¡
+
+        Args:
+            url: ä»£ç†URL (å¦‚: http://127.0.0.1:8080)
+            **kwargs: å…¶ä»–å±æ€§
+
+        Returns:
+            Proxy: ä»£ç†å¯¹è±¡
+        """
+        if not url.startswith(('http://', 'https://', 'socks4://', 'socks5://')):
+            url = f'http://{url}'
+
+        # è§£æURL
+        if '://' in url:
+            protocol_str, rest = url.split('://', 1)
+            protocol = ProxyProtocol(protocol_str.lower())
+
+            # å¤„ç†è®¤è¯ä¿¡æ¯
+            credentials = None
+            if '@' in rest:
+                credentials, rest = rest.split('@', 1)
+                if ':' in credentials:
+                    username, password = credentials.split(':', 1)
+                else:
+                    username, password = credentials, None
+            else:
+                username, password = None, None
+
+            # å¤„ç†ä¸»æœºå’Œç«¯å£
+            if ':' in rest:
+                host, port_str = rest.rsplit(':', 1)
+                try:
+                    port = int(port_str)
+                except ValueError:
+                    # å¦‚æœç«¯å£ä¸æ˜¯æ•°å­—ï¼Œå¯èƒ½æ˜¯IPv6åœ°å€
+                    if '[' in rest and ']' in rest:
+                        host = rest.split(']')[0][1:]
+                        port_part = rest.split(']:')
+                        port = int(port_part[1]) if len(port_part) > 1 else 80
+                    else:
+                        raise ValueError(f"Invalid proxy URL: {url}")
+            else:
+                host = rest
+                port = 80
+        else:
+            raise ValueError(f"Invalid proxy URL: {url}")
+
+        return cls(
+            url=url,
+            protocol=protocol,
+            host=host,
+            port=port,
+            username=username,
+            password=password,
+            **kwargs
+        )
+
+    @property
+    def is_active(self) -> bool:
+        """æ£€æŸ¥ä»£ç†æ˜¯å¦æ´»è·ƒ"""
+        return self.status == ProxyStatus.ACTIVE
 
     @property
-    def url(self) -> str:
-        """ç”Ÿæˆä»£ç†URL."""
-        if self.username and self.password:
-            return f"{self.proxy_type}://{self.username}:{self.password}@{self.host}:{self.port}"
-        return f"{self.proxy_type}://{self.host}:{self.port}"
+    def is_banned(self) -> bool:
+        """æ£€æŸ¥ä»£ç†æ˜¯å¦è¢«ç¦ç”¨"""
+        return self.status == ProxyStatus.BANNED
+
+    @property
+    def is_healthy(self) -> bool:
+        """æ£€æŸ¥ä»£ç†æ˜¯å¦å¥åº·ï¼ˆåˆ†æ•°>50ä¸”æœªè¢«ç¦ç”¨ï¼‰"""
+        return self.score > 50.0 and not self.is_banned
+
+    def record_success(self, response_time: Optional[float] = None) -> None:
+        """
+        è®°å½•æˆåŠŸä½¿ç”¨
+
+        Args:
+            response_time: å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
+        """
+        self.success_count += 1
+        self.fail_count = 0  # é‡ç½®å¤±è´¥è®¡æ•°
+        self.last_used = time.monotonic()
+
+        if response_time is not None:
+            self.response_time = response_time
+
+        # å¢åŠ åˆ†æ•°ï¼Œæœ€é«˜100
+        if self.score < 100.0:
+            self.score = min(100.0, self.score + 5.0)
+
+    def record_failure(self) -> None:
+        """è®°å½•å¤±è´¥ä½¿ç”¨"""
+        self.fail_count += 1
+        self.last_used = time.monotonic()
+
+        # å‡å°‘åˆ†æ•°ï¼Œæœ€ä½0
+        if self.score > 0.0:
+            self.score = max(0.0, self.score - 10.0)
+
+    def ban(self) -> None:
+        """ç¦ç”¨ä»£ç†"""
+        self.status = ProxyStatus.BANNED
+        self.score = 0.0
+
+    def reactivate(self) -> None:
+        """é‡æ–°æ¿€æ´»ä»£ç†"""
+        self.status = ProxyStatus.ACTIVE
+        self.fail_count = 0
+        self.score = max(50.0, self.score)  # æ¢å¤åˆ°æœ€ä½50åˆ†
+
+    def to_dict(self) -> Dict[str, Any]:
+        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
+        return {
+            'url': self.url,
+            'protocol': self.protocol.value,
+            'host': self.host,
+            'port': self.port,
+            'username': self.username,
+            'password': '***' if self.password else None,
+            'score': self.score,
+            'fail_count': self.fail_count,
+            'success_count': self.success_count,
+            'last_used': self.last_used,
+            'last_check': self.last_check,
+            'status': self.status.value,
+            'response_time': self.response_time,
+            'is_active': self.is_active,
+            'is_banned': self.is_banned,
+            'is_healthy': self.is_healthy,
+        }
 
     def __str__(self) -> str:
-        return f"{self.host}:{self.port}"
+        return f"Proxy({self.url}, score={self.score:.1f}, status={self.status.value})"
 
+    def __repr__(self) -> str:
+        return self.__str__()
 
-@dataclass
-class ProxyStats:
-    """ä»£ç†ç»Ÿè®¡ä¿¡æ¯."""
 
-    success_count: int = 0
-    failure_count: int = 0
-    total_response_time: float = 0.0
-    last_used: Optional[float] = None
-    last_success: Optional[float] = None
-    ban_count: int = 0
+class RotationStrategy(Enum):
+    """è½®è¯¢ç­–ç•¥"""
+    RANDOM = "random"
+    ROUND_ROBIN = "round_robin"
+    WEIGHTED_RANDOM = "weighted_random"
+    HEALTH_FIRST = "health_first"
+
 
-    @property
-    def success_rate(self) -> float:
-        """æˆåŠŸç‡."""
-        total = self.success_count + self.failure_count
-        return self.success_count / total if total > 0 else 0.0
+@runtime_checkable
+class ProxyProvider(Protocol):
+    """
+    ä»£ç†æä¾›è€…åè®®
 
-    @property
-    def avg_response_time(self) -> float:
-        """å¹³å‡å“åº”æ—¶é—´."""
-        return self.total_response_time / max(self.success_count, 1)
+    å®šä¹‰äº†ä»ä¸åŒæ¥æºè·å–ä»£ç†çš„æ ‡å‡†æ¥å£
+    """
+
+    @abstractmethod
+    async def load_proxies(self) -> List[Proxy]:
+        """
+        åŠ è½½ä»£ç†åˆ—è¡¨
+
+        Returns:
+            List[Proxy]: ä»£ç†åˆ—è¡¨
+        """
+        ...
+
+    @abstractmethod
+    async def refresh_proxies(self) -> List[Proxy]:
+        """
+        åˆ·æ–°ä»£ç†åˆ—è¡¨
+
+        Returns:
+            List[Proxy]: æ›´æ–°åçš„ä»£ç†åˆ—è¡¨
+        """
+        ...
+
+
+class StaticProxyProvider:
+    """
+    é™æ€ä»£ç†æä¾›è€…
+
+    ç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºï¼Œæä¾›å›ºå®šçš„ä»£ç†åˆ—è¡¨
+    """
+
+    def __init__(self, proxies: List[str]):
+        """
+        åˆå§‹åŒ–é™æ€ä»£ç†æä¾›è€…
+
+        Args:
+            proxies: ä»£ç†URLåˆ—è¡¨
+        """
+        self.proxies = [Proxy.from_url(url) for url in proxies]
+
+    async def load_proxies(self) -> List[Proxy]:
+        """åŠ è½½é™æ€ä»£ç†åˆ—è¡¨"""
+        return self.proxies.copy()
+
+    async def refresh_proxies(self) -> List[Proxy]:
+        """åˆ·æ–°ä»£ç†åˆ—è¡¨ï¼ˆé™æ€æä¾›è€…è¿”å›ç›¸åŒåˆ—è¡¨ï¼‰"""
+        return self.proxies.copy()
+
+
+class FileProxyProvider:
+    """
+    æ–‡ä»¶ä»£ç†æä¾›è€…
+
+    ä»æ–‡ä»¶ä¸­è¯»å–ä»£ç†åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼
+    """
+
+    def __init__(self, file_path: str, encoding: str = 'utf-8'):
+        """
+        åˆå§‹åŒ–æ–‡ä»¶ä»£ç†æä¾›è€…
+
+        Args:
+            file_path: ä»£ç†æ–‡ä»¶è·¯å¾„
+            encoding: æ–‡ä»¶ç¼–ç 
+        """
+        self.file_path = Path(file_path)
+        self.encoding = encoding
+        self._cached_proxies: Optional[List[Proxy]] = None
+        self._last_modified: Optional[float] = None
+
+    async def load_proxies(self) -> List[Proxy]:
+        """åŠ è½½ä»£ç†æ–‡ä»¶"""
+        if not self.file_path.exists():
+            raise FileNotFoundError(f"Proxy file not found: {self.file_path}")
+
+        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ä¿®æ”¹
+        current_mtime = self.file_path.stat().st_mtime
+
+        if (self._cached_proxies is None or
+            self._last_modified is None or
+            current_mtime > self._last_modified):
+
+            proxies = []
+            with open(self.file_path, 'r', encoding=self.encoding) as f:
+                for line_num, line in enumerate(f, 1):
+                    line = line.strip()
+                    if not line or line.startswith('#'):
+                        continue
+
+                    try:
+                        proxy = Proxy.from_url(line)
+                        proxies.append(proxy)
+                    except ValueError as e:
+                        print(f"Warning: Invalid proxy format at line {line_num}: {line} - {e}")
+                        continue
+
+            self._cached_proxies = proxies
+            self._last_modified = current_mtime
+
+        return self._cached_proxies.copy() if self._cached_proxies else []
+
+    async def refresh_proxies(self) -> List[Proxy]:
+        """åˆ·æ–°ä»£ç†åˆ—è¡¨ï¼ˆå¼ºåˆ¶é‡æ–°åŠ è½½æ–‡ä»¶ï¼‰"""
+        self._cached_proxies = None
+        self._last_modified = None
+        return await self.load_proxies()
 
 
 class ProxyPool:
-    """æ™ºèƒ½ä»£ç†æ± ç®¡ç†å™¨."""
+    """
+    ä»£ç†æ± ç®¡ç†å™¨
+
+    è´Ÿè´£ä»£ç†çš„è·å–ã€è½®è¯¢ã€å¥åº·è¯„åˆ†å’Œé»‘åå•ç®¡ç†
+    """
 
     def __init__(
-        self
-        proxy_list: list[ProxyConfig]
-        max_retries: int = 3
-        test_timeout: int = 10
-        health_check_interval: int = 300,  # 5åˆ†é’Ÿ
-        ban_threshold: int = 5,  # è¿ç»­å¤±è´¥5æ¬¡è§†ä¸ºè¢«å°
-        cooldown_time: int = 3600,  # å†·å´æ—¶é—´1å°æ—¶
+        self,
+        provider: ProxyProvider,
+        strategy: RotationStrategy = RotationStrategy.WEIGHTED_RANDOM,
+        max_fail_count: int = 5,
+        min_score_threshold: float = 30.0,
+        health_check_url: str = "http://httpbin.org/ip",
+        health_check_timeout: float = 10.0,
+        auto_health_check: bool = True,
+        health_check_interval: float = 300.0,  # 5åˆ†é’Ÿ
     ):
-        self.proxies: dict[ProxyConfig, ProxyStats] = {
-            proxy: ProxyStats() for proxy in proxy_list
-        }
-        self.active_proxies: set[ProxyConfig] = set(proxy_list)
-        self.failed_proxies: set[ProxyConfig] = set()
-        self.banned_proxies: set[ProxyConfig] = set()
-
-        self.max_retries = max_retries
-        self.test_timeout = test_timeout
+        """
+        åˆå§‹åŒ–ä»£ç†æ± 
+
+        Args:
+            provider: ä»£ç†æä¾›è€…
+            strategy: è½®è¯¢ç­–ç•¥
+            max_fail_count: æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
+            min_score_threshold: æœ€å°åˆ†æ•°é˜ˆå€¼
+            health_check_url: å¥åº·æ£€æŸ¥URL
+            health_check_timeout: å¥åº·æ£€æŸ¥è¶…æ—¶æ—¶é—´
+            auto_health_check: æ˜¯å¦è‡ªåŠ¨å¥åº·æ£€æŸ¥
+            health_check_interval: å¥åº·æ£€æŸ¥é—´éš”
+        """
+        self.provider = provider
+        self.strategy = strategy
+        self.max_fail_count = max_fail_count
+        self.min_score_threshold = min_score_threshold
+        self.health_check_url = health_check_url
+        self.health_check_timeout = health_check_timeout
+        self.auto_health_check = auto_health_check
         self.health_check_interval = health_check_interval
-        self.ban_threshold = ban_threshold
-        self.cooldown_time = cooldown_time
 
-        self._lock = asyncio.Lock()
+        # ä»£ç†åˆ—è¡¨å’ŒçŠ¶æ€
+        self.proxies: List[Proxy] = []
+        self.current_index = 0  # ç”¨äºè½®è¯¢ç­–ç•¥
+        self.lock = asyncio.Lock()
+
+        # å¥åº·æ£€æŸ¥ä»»åŠ¡
         self._health_check_task: Optional[asyncio.Task] = None
+        self._last_health_check = 0.0
 
-        logger.info(f"ä»£ç†æ± åˆå§‹åŒ–å®Œæˆï¼Œå…±{len(proxy_list)}ä¸ªä»£ç†")
+    async def initialize(self) -> None:
+        """åˆå§‹åŒ–ä»£ç†æ± """
+        async with self.lock:
+            self.proxies = await self.provider.load_proxies()
+            print(f"ğŸ“‹ Loaded {len(self.proxies)} proxies from provider")
 
-    async def start_health_check(self):
-        """å¯åŠ¨å¥åº·æ£€æŸ¥ä»»åŠ¡."""
-        if self._health_check_task is None or self._health_check_task.done():
-            self._health_check_task = asyncio.create_task(self._health_check_loop())
-            logger.info("ä»£ç†æ± å¥åº·æ£€æŸ¥ä»»åŠ¡å·²å¯åŠ¨")
+            # å¯åŠ¨å¥åº·æ£€æŸ¥ä»»åŠ¡
+            if self.auto_health_check:
+                self._health_check_task = asyncio.create_task(self._health_check_loop())
 
-    async def stop_health_check(self):
-        """åœæ­¢å¥åº·æ£€æŸ¥ä»»åŠ¡."""
-        if self._health_check_task and not self._health_check_task.done():
+    async def close(self) -> None:
+        """å…³é—­ä»£ç†æ± """
+        if self._health_check_task:
             self._health_check_task.cancel()
-            logger.info("ä»£ç†æ± å¥åº·æ£€æŸ¥ä»»åŠ¡å·²åœæ­¢")
+            try:
+                await self._health_check_task
+            except asyncio.CancelledError:
+                pass
+
+    async def get_proxy(self) -> Optional[Proxy]:
+        """
+        è·å–ä¸€ä¸ªå¯ç”¨ä»£ç†
+
+        Returns:
+            Optional[Proxy]: å¯ç”¨ä»£ç†ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
+        """
+        async with self.lock:
+            if not self.proxies:
+                return None
 
-    async def _health_check_loop(self):
-        """å¥åº·æ£€æŸ¥å¾ªç¯."""
+            # è¿‡æ»¤æ´»è·ƒä¸”å¥åº·çš„ä»£ç†
+            available_proxies = [
+                proxy for proxy in self.proxies
+                if proxy.is_active and proxy.is_healthy
+            ]
+
+            if not available_proxies:
+                # å¦‚æœæ²¡æœ‰å¥åº·çš„ä»£ç†ï¼Œå°è¯•æ¿€æ´»ä¸€äº›è¢«ç¦ç”¨çš„ä»£ç†
+                await self._reactivate_banned_proxies()
+                available_proxies = [
+                    proxy for proxy in self.proxies
+                    if proxy.is_active and proxy.is_healthy
+                ]
+
+                if not available_proxies:
+                    return None
+
+            # æ ¹æ®ç­–ç•¥é€‰æ‹©ä»£ç†
+            proxy = await self._select_proxy(available_proxies)
+            return proxy
+
+    async def _select_proxy(self, available_proxies: List[Proxy]) -> Proxy:
+        """æ ¹æ®ç­–ç•¥é€‰æ‹©ä»£ç†"""
+        if self.strategy == RotationStrategy.RANDOM:
+            return random.choice(available_proxies)
+
+        elif self.strategy == RotationStrategy.ROUND_ROBIN:
+            proxy = available_proxies[self.current_index % len(available_proxies)]
+            self.current_index += 1
+            return proxy
+
+        elif self.strategy == RotationStrategy.WEIGHTED_RANDOM:
+            # æ ¹æ®åˆ†æ•°è¿›è¡ŒåŠ æƒéšæœºé€‰æ‹©
+            total_score = sum(proxy.score for proxy in available_proxies)
+            if total_score == 0:
+                return random.choice(available_proxies)
+
+            rand = random.uniform(0, total_score)
+            current_score = 0.0
+
+            for proxy in available_proxies:
+                current_score += proxy.score
+                if rand <= current_score:
+                    return proxy
+
+            return available_proxies[-1]  # fallback
+
+        elif self.strategy == RotationStrategy.HEALTH_FIRST:
+            # ä¼˜å…ˆé€‰æ‹©åˆ†æ•°æœ€é«˜çš„ä»£ç†
+            return max(available_proxies, key=lambda p: p.score)
+
+        else:
+            return random.choice(available_proxies)
+
+    async def record_proxy_result(self, proxy: Proxy, success: bool, response_time: Optional[float] = None) -> None:
+        """
+        è®°å½•ä»£ç†ä½¿ç”¨ç»“æœ
+
+        Args:
+            proxy: ä½¿ç”¨çš„ä»£ç†
+            success: æ˜¯å¦æˆåŠŸ
+            response_time: å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
+        """
+        async with self.lock:
+            if success:
+                proxy.record_success(response_time)
+            else:
+                proxy.record_failure()
+                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¦ç”¨ä»£ç†
+                if proxy.fail_count >= self.max_fail_count or proxy.score < self.min_score_threshold:
+                    proxy.ban()
+                    print(f"ğŸš« Proxy banned: {proxy.url} (fail_count={proxy.fail_count}, score={proxy.score:.1f})")
+
+    async def _reactivate_banned_proxies(self) -> None:
+        """é‡æ–°æ¿€æ´»éƒ¨åˆ†è¢«ç¦ç”¨çš„ä»£ç†"""
+        banned_proxies = [proxy for proxy in self.proxies if proxy.is_banned]
+
+        # éšæœºé€‰æ‹©ä¸€äº›ä»£ç†è¿›è¡Œé‡æ–°æ¿€æ´»
+        if banned_proxies:
+            reactivate_count = min(3, len(banned_proxies))  # æœ€å¤šé‡æ–°æ¿€æ´»3ä¸ª
+            selected_proxies = random.sample(banned_proxies, reactivate_count)
+
+            for proxy in selected_proxies:
+                proxy.reactivate()
+                print(f"ğŸ”„ Proxy reactivated: {proxy.url}")
+
+    async def _health_check_loop(self) -> None:
+        """å¥åº·æ£€æŸ¥å¾ªç¯"""
         while True:
             try:
-                await self._check_all_proxies()
                 await asyncio.sleep(self.health_check_interval)
+                await self._perform_health_check()
             except asyncio.CancelledError:
                 break
             except Exception as e:
-                logger.error(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
-                await asyncio.sleep(60)  # å‡ºé”™æ—¶ç­‰å¾…1åˆ†é’Ÿ
+                print(f"âŒ Health check error: {e}")
 
-    async def _check_all_proxies(self):
-        """æ£€æŸ¥æ‰€æœ‰ä»£ç†çš„å¥åº·çŠ¶æ€."""
-        logger.info("å¼€å§‹ä»£ç†å¥åº·æ£€æŸ¥...")
+    async def _perform_health_check(self) -> None:
+        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
+        current_time = time.monotonic()
 
-        tasks = []
-        for proxy in list(self.proxies.keys()):
-            if proxy not in self.banned_proxies:
-                tasks.append(self._test_proxy(proxy))
+        # é¿å…é¢‘ç¹æ£€æŸ¥
+        if current_time - self._last_health_check < self.health_check_interval:
+            return
 
-        if tasks:
-            await asyncio.gather(*tasks, return_exceptions=True)
+        async with self.lock:
+            self._last_health_check = current_time
 
-        active_count = len(self.active_proxies)
-        failed_count = len(self.failed_proxies)
-        banned_count = len(self.banned_proxies)
+            if not self.proxies:
+                return
 
-        logger.info(
-            f"ä»£ç†å¥åº·æ£€æŸ¥å®Œæˆ: æ´»è·ƒ={active_count}, å¤±è´¥={failed_count}, å°ç¦={banned_count}"
-        )
+            print(f"ğŸ” Starting health check for {len(self.proxies)} proxies...")
 
-    @backoff.on_exception(
-        backoff.expo
-        (aiohttp.ClientError, asyncio.TimeoutError)
-        max_tries=2
-        base=1
-        max_value=10
-    )
-    async def _test_proxy(self, proxy: ProxyConfig) -> bool:
-        """æµ‹è¯•ä»£ç†æ˜¯å¦å¯ç”¨."""
-        stats = self.proxies[proxy]
+            # å¹¶å‘æ£€æŸ¥æ‰€æœ‰ä»£ç†
+            tasks = [
+                self._check_single_proxy(proxy)
+                for proxy in self.proxies
+                if proxy.is_active
+            ]
 
-        try:
-            start_time = time.time()
+            if tasks:
+                results = await asyncio.gather(*tasks, return_exceptions=True)
 
-            # ä½¿ç”¨httpbin.orgæµ‹è¯•ä»£ç†
-            test_url = "http://httpbin.org/ip"
+                # ç»Ÿè®¡ç»“æœ
+                healthy_count = 0
+                for i, result in enumerate(results):
+                    proxy = self.proxies[i]
+                    if isinstance(result, Exception):
+                        print(f"âŒ Health check failed for {proxy.url}: {result}")
+                        self.record_proxy_result(proxy, False)
+                    elif result:
+                        healthy_count += 1
+                        print(f"âœ… Health check passed for {proxy.url}")
 
-            async with aiohttp.ClientSession(
-                timeout=aiohttp.ClientTimeout(total=self.test_timeout)
-            ) as session:
-                async with session.get(test_url, proxy=proxy.url) as response:
+                print(f"ğŸ“Š Health check completed: {healthy_count}/{len(tasks)} proxies healthy")
+
+    async def _check_single_proxy(self, proxy: Proxy) -> bool:
+        """æ£€æŸ¥å•ä¸ªä»£ç†çš„å¥åº·çŠ¶å†µ"""
+        try:
+            proxy_url = proxy.url
+            if proxy.username and proxy.password:
+                # æ·»åŠ è®¤è¯ä¿¡æ¯
+                from urllib.parse import quote
+                auth_string = f"{quote(proxy.username)}:{quote(proxy.password)}"
+                proxy_url = proxy_url.replace('://', f'://{auth_string}@')
+
+            timeout = aiohttp.ClientTimeout(total=self.health_check_timeout)
+
+            async with aiohttp.ClientSession(timeout=timeout) as session:
+                async with session.get(
+                    self.health_check_url,
+                    proxy=proxy_url,
+                    ssl=False  # å¿½ç•¥SSLè¯ä¹¦éªŒè¯
+                ) as response:
                     if response.status == 200:
-                        await response.json()
-                        response_time = time.time() - start_time
-
-                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
-                        async with self._lock:
-                            stats.success_count += 1
-                            stats.total_response_time += response_time
-                            stats.last_success = time.time()
-                            stats.last_used = time.time()
-
-                            # é‡ç½®å¤±è´¥è®¡æ•°
-                            stats.failure_count = 0
-
-                            # å¦‚æœä»£ç†ä¹‹å‰å¤±è´¥ï¼Œç°åœ¨æ¢å¤
-                            if proxy in self.failed_proxies:
-                                self.failed_proxies.remove(proxy)
-                                self.active_proxies.add(proxy)
-                                logger.info(f"ä»£ç† {proxy} å·²æ¢å¤")
-
-                        logger.debug(
-                            f"ä»£ç† {proxy} æµ‹è¯•æˆåŠŸï¼Œå“åº”æ—¶é—´: {response_time:.2f}s"
-                        )
+                        start_time = time.monotonic()
+                        content = await response.text()
+                        end_time = time.monotonic()
+
+                        response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
+                        proxy.record_success(response_time)
                         return True
                     else:
-                        raise aiohttp.ClientError(f"HTTP {response.status}")
+                        proxy.record_failure()
+                        return False
 
         except Exception as e:
-            async with self._lock:
-                stats.failure_count += 1
-                stats.last_used = time.time()
-
-                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å°ç¦é˜ˆå€¼
-                if stats.failure_count >= self.ban_threshold:
-                    stats.ban_count += 1
-                    self.banned_proxies.add(proxy)
-                    if proxy in self.active_proxies:
-                        self.active_proxies.remove(proxy)
-                    if proxy in self.failed_proxies:
-                        self.failed_proxies.remove(proxy)
-                    logger.warning(
-                        f"ä»£ç† {proxy} è¿ç»­å¤±è´¥{stats.failure_count}æ¬¡ï¼Œæ ‡è®°ä¸ºå°ç¦"
-                    )
-                else:
-                    if proxy not in self.failed_proxies:
-                        self.failed_proxies.add(proxy)
-                        if proxy in self.active_proxies:
-                            self.active_proxies.remove(proxy)
-                    logger.warning(
-                        f"ä»£ç† {proxy} æµ‹è¯•å¤±è´¥ ({stats.failure_count}/{self.ban_threshold}): {e}"
-                    )
-
+            proxy.record_failure()
             return False
 
-    async def get_proxy(self) -> Optional[ProxyConfig]:
-        """è·å–æœ€ä½³ä»£ç†."""
-        async with self._lock:
-            # å¦‚æœæ²¡æœ‰æ´»è·ƒä»£ç†ï¼Œå°è¯•æ¢å¤ä¸€äº›å¤±è´¥ä»£ç†
-            if not self.active_proxies:
-                if self.failed_proxies:
-                    # éšæœºé€‰æ‹©ä¸€ä¸ªå¤±è´¥ä»£ç†è¿›è¡Œæµ‹è¯•
-                    proxy = random.choice(list(self.failed_proxies))
-                    if await self._test_proxy(proxy):
-                        return proxy
-
-                logger.error("æ²¡æœ‰å¯ç”¨çš„ä»£ç†")
-                return None
-
-            # é€‰æ‹©å“åº”æ—¶é—´æœ€çŸ­çš„æ´»è·ƒä»£ç†
-            best_proxy = min(
-                self.active_proxies, key=lambda p: self.proxies[p].avg_response_time
-            )
-
-            # æ›´æ–°ä½¿ç”¨æ—¶é—´
-            self.proxies[best_proxy].last_used = time.time()
-
-            return best_proxy
-
-    async def mark_proxy_failed(self, proxy: ProxyConfig, error: Exception):
-        """æ ‡è®°ä»£ç†å¤±è´¥."""
-        async with self._lock:
-            stats = self.proxies[proxy]
-            stats.failure_count += 1
-
-            # æ£€æŸ¥æ˜¯å¦éœ€è¦å°ç¦
-            if stats.failure_count >= self.ban_threshold:
-                stats.ban_count += 1
-                self.banned_proxies.add(proxy)
-                if proxy in self.active_proxies:
-                    self.active_proxies.remove(proxy)
-                if proxy in self.failed_proxies:
-                    self.failed_proxies.remove(proxy)
-                logger.error(f"ä»£ç† {proxy} è¢«æ ‡è®°ä¸ºå°ç¦ï¼Œé”™è¯¯: {error}")
-            else:
-                if proxy not in self.failed_proxies:
-                    self.failed_proxies.add(proxy)
-                    if proxy in self.active_proxies:
-                        self.active_proxies.remove(proxy)
-                logger.warning(f"ä»£ç† {proxy} æ ‡è®°ä¸ºå¤±è´¥ï¼Œé”™è¯¯: {error}")
-
-    async def mark_proxy_success(self, proxy: ProxyConfig, response_time: float):
-        """æ ‡è®°ä»£ç†æˆåŠŸ."""
-        async with self._lock:
-            stats = self.proxies[proxy]
-            stats.success_count += 1
-            stats.total_response_time += response_time
-            stats.last_success = time.time()
-            stats.last_used = time.time()
-
-            # é‡ç½®å¤±è´¥è®¡æ•°
-            stats.failure_count = 0
-
-            # ç¡®ä¿ä»£ç†åœ¨æ´»è·ƒé›†åˆä¸­
-            if proxy not in self.active_proxies:
-                self.active_proxies.add(proxy)
-            if proxy in self.failed_proxies:
-                self.failed_proxies.remove(proxy)
-            if proxy in self.banned_proxies:
-                # æ£€æŸ¥æ˜¯å¦å¯ä»¥è§£å°ï¼ˆå†·å´æ—¶é—´ï¼‰
-                if (
-                    stats.last_success
-                    and (time.time() - stats.last_success) > self.cooldown_time
-                ):
-                    self.banned_proxies.remove(proxy)
-                    logger.info(f"ä»£ç† {proxy} å†·å´æ—¶é—´å·²è¿‡ï¼Œè§£å°")
-
-    def get_stats(self) -> dict:
-        """è·å–ä»£ç†æ± ç»Ÿè®¡ä¿¡æ¯."""
-        total_proxies = len(self.proxies)
-        active_count = len(self.active_proxies)
-        failed_count = len(self.failed_proxies)
-        banned_count = len(self.banned_proxies)
-
-        # è®¡ç®—å¹³å‡æˆåŠŸç‡
-        total_success_rate = 0.0
-        total_response_time = 0.0
-        proxy_count = 0
-
-        for stats in self.proxies.values():
-            if stats.success_count > 0:
-                total_success_rate += stats.success_rate
-                total_response_time += stats.avg_response_time
-                proxy_count += 1
-
-        avg_success_rate = total_success_rate / max(proxy_count, 1)
-        avg_response_time = total_response_time / max(proxy_count, 1)
-
-        return {
-            "total_proxies": total_proxies
-            "active_proxies": active_count
-            "failed_proxies": failed_count
-            "banned_proxies": banned_count
-            "availability_rate": (
-                active_count / total_proxies if total_proxies > 0 else 0
-            )
-            "avg_success_rate": avg_success_rate
-            "avg_response_time": avg_response_time
-            "health_check_interval": self.health_check_interval
-        }
-
-    @classmethod
-    def from_env(cls) -> "ProxyPool":
-        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºä»£ç†æ± ."""
-        import os
-
-        proxy_configs = []
-
-        # ä»ç¯å¢ƒå˜é‡è¯»å–ä»£ç†åˆ—è¡¨
-        proxy_list_str = os.getenv("PROXY_LIST", "")
-        if proxy_list_str:
-            for proxy_str in proxy_list_str.split(","):
-                proxy_str = proxy_str.strip()
-                if proxy_str:
-                    # æ”¯æŒæ ¼å¼: host:port æˆ– username:password@host:port
-                    if "@" in proxy_str:
-                        auth_part, addr_part = proxy_str.split("@", 1)
-                        if ":" in auth_part:
-                            username, password = auth_part.split(":", 1)
-                        else:
-                            username, password = auth_part, None
-                    else:
-                        username, password = None, None
-                        addr_part = proxy_str
-
-                    if ":" in addr_part:
-                        host, port_str = addr_part.split(":", 1)
-                        port = int(port_str)
-
-                        proxy_configs.append(
-                            ProxyConfig(
-                                host=host.strip()
-                                port=port
-                                username=username
-                                password=password
-                            )
-                        )
-
-        # å¦‚æœæ²¡æœ‰é…ç½®ä»£ç†ï¼Œè¿”å›ç©ºä»£ç†æ± 
-        if not proxy_configs:
-            logger.warning("æœªé…ç½®ä»£ç†åˆ—è¡¨ï¼Œä»£ç†æ± å°†ä¸ºç©º")
+    async def refresh_proxies(self) -> None:
+        """åˆ·æ–°ä»£ç†åˆ—è¡¨"""
+        async with self.lock:
+            try:
+                new_proxies = await self.provider.refresh_proxies()
+                old_urls = {proxy.url for proxy in self.proxies}
+                new_urls = {proxy.url for proxy in new_proxies}
 
-        return cls(proxy_configs)
+                # åˆå¹¶ä»£ç†åˆ—è¡¨ï¼Œä¿ç•™å·²æœ‰çš„åˆ†æ•°å’Œç»Ÿè®¡ä¿¡æ¯
+                merged_proxies = []
 
+                # ä¿ç•™å·²æœ‰çš„ä»£ç†
+                for old_proxy in self.proxies:
+                    if old_proxy.url in new_urls:
+                        merged_proxies.append(old_proxy)
 
-# å…¨å±€ä»£ç†æ± å®ä¾‹
-_proxy_pool: Optional[ProxyPool] = None
+                # æ·»åŠ æ–°çš„ä»£ç†
+                for new_proxy in new_proxies:
+                    if new_proxy.url not in old_urls:
+                        merged_proxies.append(new_proxy)
 
+                self.proxies = merged_proxies
+                print(f"ğŸ”„ Proxies refreshed: {len(self.proxies)} total")
 
-async def get_proxy_pool() -> ProxyPool:
-    """è·å–å…¨å±€ä»£ç†æ± å®ä¾‹."""
-    global _proxy_pool
-    if _proxy_pool is None:
-        _proxy_pool = ProxyPool.from_env()
-        await _proxy_pool.start_health_check()
-    return _proxy_pool
+            except Exception as e:
+                print(f"âŒ Failed to refresh proxies: {e}")
+
+    def get_stats(self) -> Dict[str, Any]:
+        """è·å–ä»£ç†æ± ç»Ÿè®¡ä¿¡æ¯"""
+        if not self.proxies:
+            return {
+                'total': 0,
+                'active': 0,
+                'banned': 0,
+                'healthy': 0,
+                'avg_score': 0.0,
+                'avg_response_time': None,
+            }
+
+        active_proxies = [p for p in self.proxies if p.is_active]
+        healthy_proxies = [p for p in self.proxies if p.is_healthy]
+        avg_score = sum(p.score for p in self.proxies) / len(self.proxies)
+
+        response_times = [p.response_time for p in self.proxies if p.response_time is not None]
+        avg_response_time = sum(response_times) / len(response_times) if response_times else None
 
+        return {
+            'total': len(self.proxies),
+            'active': len(active_proxies),
+            'banned': len(self.proxies) - len(active_proxies),
+            'healthy': len(healthy_proxies),
+            'avg_score': round(avg_score, 2),
+            'avg_response_time': round(avg_response_time, 2) if avg_response_time else None,
+        }
 
-async def close_proxy_pool():
-    """å…³é—­ä»£ç†æ± ."""
-    global _proxy_pool
-    if _proxy_pool:
-        await _proxy_pool.stop_health_check()
-        _proxy_pool = None
+    def get_proxies_info(self) -> List[Dict[str, Any]]:
+        """è·å–æ‰€æœ‰ä»£ç†çš„è¯¦ç»†ä¿¡æ¯"""
+        return [proxy.to_dict() for proxy in self.proxies]
+
+
+# ä¾¿åˆ©å‡½æ•°
+def create_proxy_pool(
+    proxies: List[str],
+    strategy: RotationStrategy = RotationStrategy.WEIGHTED_RANDOM,
+    **kwargs
+) -> ProxyPool:
+    """
+    åˆ›å»ºä»£ç†æ± çš„ä¾¿åˆ©å‡½æ•°
+
+    Args:
+        proxies: ä»£ç†URLåˆ—è¡¨
+        strategy: è½®è¯¢ç­–ç•¥
+        **kwargs: å…¶ä»–ProxyPoolå‚æ•°
+
+    Returns:
+        ProxyPool: ä»£ç†æ± å®ä¾‹
+    """
+    provider = StaticProxyProvider(proxies)
+    return ProxyPool(provider, strategy, **kwargs)
+
+
+def create_file_proxy_pool(
+    file_path: str,
+    strategy: RotationStrategy = RotationStrategy.WEIGHTED_RANDOM,
+    **kwargs
+) -> ProxyPool:
+    """
+    åˆ›å»ºåŸºäºæ–‡ä»¶çš„ä»£ç†æ± 
+
+    Args:
+        file_path: ä»£ç†æ–‡ä»¶è·¯å¾„
+        strategy: è½®è¯¢ç­–ç•¥
+        **kwargs: å…¶ä»–ProxyPoolå‚æ•°
+
+    Returns:
+        ProxyPool: ä»£ç†æ± å®ä¾‹
+    """
+    provider = FileProxyProvider(file_path)
+    return ProxyPool(provider, strategy, **kwargs)
+
+
+# æ¨¡å—å¯¼å‡º
+__all__ = [
+    'Proxy',
+    'ProxyProtocol',
+    'ProxyStatus',
+    'RotationStrategy',
+    'ProxyProvider',
+    'StaticProxyProvider',
+    'FileProxyProvider',
+    'ProxyPool',
+    'create_proxy_pool',
+    'create_file_proxy_pool',
+]
\ No newline at end of file
diff --git a/src/collectors/rate_limiter.py b/src/collectors/rate_limiter.py
index 4922ac084..8472540ed 100644
--- a/src/collectors/rate_limiter.py
+++ b/src/collectors/rate_limiter.py
@@ -1,354 +1,419 @@
-"""æ™ºèƒ½è¯·æ±‚é¢‘ç‡æ§åˆ¶å™¨ - åçˆ¬å¯¹æŠ—ç»„ä»¶
-Intelligent Rate Limiter - Anti-Scraping Component.
-
-æä¾›è‡ªé€‚åº”è¯·æ±‚é¢‘ç‡æ§åˆ¶ã€æ™ºèƒ½å»¶è¿Ÿè°ƒèŠ‚ç­‰åŠŸèƒ½ã€‚
+"""
+ç»Ÿä¸€é€Ÿç‡é™åˆ¶å™¨å®ç° (åŸºäºToken Bucketç®—æ³•)
+Unified Rate Limiter Implementation (Token Bucket Algorithm)
+
+åŸºäº Token Bucket (ä»¤ç‰Œæ¡¶) ç®—æ³•çš„å¼‚æ­¥é€Ÿç‡é™åˆ¶å™¨ï¼Œæ”¯æŒï¼š
+1. åˆ†åŸŸåç‹¬ç«‹é™æµ
+2. é…ç½®é©±åŠ¨çš„åŠ¨æ€ç­–ç•¥
+3. Async Context Manager æ¥å£
+4. å¹¶å‘å®‰å…¨çš„ä»¤ç‰Œæ“ä½œ
+
+ç®—æ³•åŸç†ï¼š
+- ä»¤ç‰Œæ¡¶ä»¥æ’å®šé€Ÿç‡å¡«å……ä»¤ç‰Œ
+- æ¯ä¸ªè¯·æ±‚æ¶ˆè€—ä¸€ä¸ªä»¤ç‰Œ
+- æ¡¶å®¹é‡é™åˆ¶äº†çªå‘æµé‡çš„å¤§å°
+- æ— ä»¤ç‰Œæ—¶è¯·æ±‚éœ€è¦ç­‰å¾…
+
+ä½œè€…: Lead Collector Engineer
+åˆ›å»ºæ—¶é—´: 2025-12-06
+ç‰ˆæœ¬: 1.0.0
 """
 
 import asyncio
-import random
 import time
+from contextlib import asynccontextmanager
 from dataclasses import dataclass, field
-from enum import Enum
-from src.core.logging import get_logger
-
-logger = get_logger(__name__)
-
-
-class RateLimitStrategy(Enum):
-    """é¢‘ç‡é™åˆ¶ç­–ç•¥."""
-
-    CONSERVATIVE = "conservative"  # ä¿å®ˆç­–ç•¥ï¼šè¾ƒé•¿å»¶è¿Ÿ
-    NORMAL = "normal"  # æ­£å¸¸ç­–ç•¥ï¼šæ ‡å‡†å»¶è¿Ÿ
-    AGGRESSIVE = "aggressive"  # æ¿€è¿›ç­–ç•¥ï¼šè¾ƒçŸ­å»¶è¿Ÿ
-    ADAPTIVE = "adaptive"  # è‡ªé€‚åº”ç­–ç•¥ï¼šæ ¹æ®å“åº”è°ƒæ•´
+from typing import Any, Dict, Optional
 
 
 @dataclass
-class RequestConfig:
-    """è¯·æ±‚é…ç½®."""
-
-    min_delay: float = 1.0  # æœ€å°å»¶è¿Ÿï¼ˆç§’ï¼‰
-    max_delay: float = 10.0  # æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰
-    base_delay: float = 2.0  # åŸºç¡€å»¶è¿Ÿï¼ˆç§’ï¼‰
-    burst_limit: int = 5  # çªå‘è¯·æ±‚é™åˆ¶
-    recovery_time: float = 30.0  # æ¢å¤æ—¶é—´ï¼ˆç§’ï¼‰
-
-    # å»¶è¿Ÿå¢åŠ å› å­
-    error_delay_multiplier: float = 2.0  # é”™è¯¯æ—¶å»¶è¿Ÿå€æ•°
-    success_delay_reduction: float = 0.9  # æˆåŠŸæ—¶å»¶è¿Ÿç¼©å‡å› å­
+class RateLimitConfig:
+    """
+    é€Ÿç‡é™åˆ¶é…ç½®ç±»
+
+    Args:
+        rate: æ¯ç§’è¡¥å……çš„ä»¤ç‰Œæ•° (QPS)
+        burst: æ¡¶çš„æœ€å¤§å®¹é‡ (çªå‘ä»¤ç‰Œæ•°)
+        max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ (ç§’)ï¼ŒNoneè¡¨ç¤ºæ— é™ç­‰å¾…
+    """
+    rate: float
+    burst: int
+    max_wait_time: Optional[float] = None
+
+    def __post_init__(self) -> None:
+        """éªŒè¯é…ç½®å‚æ•°"""
+        if self.rate <= 0:
+            raise ValueError("Rate must be positive")
+        if self.burst <= 0:
+            raise ValueError("Burst must be positive")
+        if self.max_wait_time is not None and self.max_wait_time < 0:
+            raise ValueError("max_wait_time must be non-negative")
 
 
 @dataclass
-class DomainStats:
-    """åŸŸåç»Ÿè®¡ä¿¡æ¯."""
-
-    domain: str
-    request_count: int = 0
-    success_count: int = 0
-    error_count: int = 0
-    last_request_time: float = 0.0
-    last_success_time: float = 0.0
-    last_error_time: float = 0.0
-    current_delay: float = 2.0
-    consecutive_errors: int = 0
-    consecutive_successes: int = 0
-    total_response_time: float = 0.0
-    avg_response_time: float = 0.0
-
-    @property
-    def success_rate(self) -> float:
-        """æˆåŠŸç‡."""
-        if self.request_count == 0:
-            return 0.0
-        return self.success_count / self.request_count
-
-    @property
-    def error_rate(self) -> float:
-        """é”™è¯¯ç‡."""
-        if self.request_count == 0:
-            return 0.0
-        return self.error_count / self.request_count
+class TokenBucket:
+    """
+    ä»¤ç‰Œæ¡¶å®ç°
+
+    ä½¿ç”¨ asyncio.Lock ä¿è¯å¹¶å‘å®‰å…¨
+    """
+    tokens: float
+    capacity: float
+    refill_rate: float
+    last_refill: float = field(default_factory=lambda: time.monotonic())
+    lock: asyncio.Lock = field(default_factory=asyncio.Lock)
+
+    def __post_init__(self) -> None:
+        """åˆå§‹åŒ–ä»¤ç‰Œæ¡¶"""
+        if self.tokens > self.capacity:
+            self.tokens = self.capacity
+
+    async def consume(self, tokens: int = 1) -> bool:
+        """
+        æ¶ˆè€—ä»¤ç‰Œ
+
+        Args:
+            tokens: è¦æ¶ˆè€—çš„ä»¤ç‰Œæ•°
+
+        Returns:
+            bool: æ˜¯å¦æˆåŠŸæ¶ˆè€—ä»¤ç‰Œ
+        """
+        async with self.lock:
+            self._refill()
+            if self.tokens >= tokens:
+                self.tokens -= tokens
+                return True
+            return False
+
+    async def wait_for_tokens(self, tokens: int = 1, timeout: Optional[float] = None) -> bool:
+        """
+        ç­‰å¾…ç›´åˆ°æœ‰è¶³å¤Ÿçš„ä»¤ç‰Œ
+
+        Args:
+            tokens: éœ€è¦çš„ä»¤ç‰Œæ•°
+            timeout: è¶…æ—¶æ—¶é—´ (ç§’)
+
+        Returns:
+            bool: æ˜¯å¦æˆåŠŸè·å–ä»¤ç‰Œ
+        """
+        start_time = time.monotonic()
+
+        while True:
+            async with self.lock:
+                self._refill()
+
+                if self.tokens >= tokens:
+                    self.tokens -= tokens
+                    return True
+
+                # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
+                tokens_needed = tokens - self.tokens
+                wait_time = tokens_needed / self.refill_rate
+
+                # æ£€æŸ¥è¶…æ—¶
+                if timeout is not None:
+                    elapsed = time.monotonic() - start_time
+                    remaining_time = timeout - elapsed
+
+                    if remaining_time <= 0:
+                        return False
+
+                    wait_time = min(wait_time, remaining_time)
+
+            # ç­‰å¾…ä»¤ç‰Œè¡¥å……
+            await asyncio.sleep(wait_time)
+
+    def _refill(self) -> None:
+        """è¡¥å……ä»¤ç‰Œï¼ˆéçº¿ç¨‹å®‰å…¨ï¼Œéœ€è¦åœ¨é”å†…è°ƒç”¨ï¼‰"""
+        now = time.monotonic()
+        elapsed = now - self.last_refill
+        tokens_to_add = elapsed * self.refill_rate
+
+        self.tokens = min(self.capacity, self.tokens + tokens_to_add)
+        self.last_refill = now
 
 
 class RateLimiter:
-    """æ™ºèƒ½è¯·æ±‚é¢‘ç‡æ§åˆ¶å™¨."""
-
-    def __init__(
-        self
-        strategy: RateLimitStrategy = RateLimitStrategy.ADAPTIVE
-        config: RequestConfig = None
-        max_domains: int = 100
-    ):
-        self.strategy = strategy
-        self.config = config or RequestConfig()
-        self.max_domains = max_domains
-
-        # åŸŸåç»Ÿè®¡ä¿¡æ¯
-        self.domain_stats: dict[str, DomainStats] = {}
-        self._lock = asyncio.Lock()
-
-        # å…¨å±€è¯·æ±‚è®¡æ•°å™¨
-        self.global_request_count = 0
-        self.global_last_request_time = 0.0
-
-        logger.info(f"é¢‘ç‡æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆï¼Œç­–ç•¥: {strategy.value}")
-
-    async def wait_for_slot(self, domain: str) -> float:
-        """ç­‰å¾…è¯·æ±‚æ—¶æœºï¼Œè¿”å›å®é™…å»¶è¿Ÿæ—¶é—´."""
-        async with self._lock:
-            stats = self._get_or_create_stats(domain)
-
-            # è®¡ç®—å»¶è¿Ÿæ—¶é—´
-            delay = await self._calculate_delay(stats)
-
-            # åº”ç”¨å»¶è¿Ÿ
-            if delay > 0:
-                logger.debug(f"åŸŸå {domain} å»¶è¿Ÿ {delay:.2f}s")
-                await asyncio.sleep(delay)
-
-            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
-            stats.last_request_time = time.time()
-            self.global_last_request_time = time.time()
-            self.global_request_count += 1
-
-            return delay
-
-    async def _calculate_delay(self, stats: DomainStats) -> float:
-        """è®¡ç®—å»¶è¿Ÿæ—¶é—´."""
-        current_time = time.time()
-
-        if self.strategy == RateLimitStrategy.CONSERVATIVE:
-            return self._conservative_delay(stats, current_time)
-        elif self.strategy == RateLimitStrategy.NORMAL:
-            return self._normal_delay(stats, current_time)
-        elif self.strategy == RateLimitStrategy.AGGRESSIVE:
-            return self._aggressive_delay(stats, current_time)
-        elif self.strategy == RateLimitStrategy.ADAPTIVE:
-            return await self._adaptive_delay(stats, current_time)
-        else:
-            return self.config.base_delay
-
-    def _conservative_delay(self, stats: DomainStats, current_time: float) -> float:
-        """ä¿å®ˆç­–ç•¥å»¶è¿Ÿè®¡ç®—."""
-        # ä½¿ç”¨è¾ƒé•¿çš„åŸºç¡€å»¶è¿Ÿ
-        base_delay = self.config.base_delay * 2.0
-
-        # è€ƒè™‘è¿ç»­é”™è¯¯
-        if stats.consecutive_errors > 0:
-            base_delay *= 1 + stats.consecutive_errors * 0.5
-
-        # ç¡®ä¿æœ€å°å»¶è¿Ÿ
-        return max(base_delay, self.config.min_delay * 2.0)
-
-    def _normal_delay(self, stats: DomainStats, current_time: float) -> float:
-        """æ­£å¸¸ç­–ç•¥å»¶è¿Ÿè®¡ç®—."""
-        # åŸºç¡€å»¶è¿Ÿ + éšæœºæ³¢åŠ¨
-        delay = self.config.base_delay + random.uniform(-0.5, 0.5)
-
-        # é”™è¯¯æƒ©ç½š
-        if stats.consecutive_errors > 0:
-            delay *= 1 + stats.consecutive_errors * 0.3
-
-        return max(delay, self.config.min_delay)
-
-    def _aggressive_delay(self, stats: DomainStats, current_time: float) -> float:
-        """æ¿€è¿›ç­–ç•¥å»¶è¿Ÿè®¡ç®—."""
-        # è¾ƒçŸ­çš„åŸºç¡€å»¶è¿Ÿ
-        delay = self.config.base_delay * 0.7
-
-        # éšæœºæ³¢åŠ¨è¾ƒå°
-        delay += random.uniform(-0.2, 0.2)
-
-        # é”™è¯¯æƒ©ç½šè¾ƒè½»
-        if stats.consecutive_errors > 0:
-            delay *= 1 + stats.consecutive_errors * 0.2
-
-        return max(delay, self.config.min_delay * 0.5)
-
-    async def _adaptive_delay(self, stats: DomainStats, current_time: float) -> float:
-        """è‡ªé€‚åº”ç­–ç•¥å»¶è¿Ÿè®¡ç®—."""
-        # åŸºäºæˆåŠŸç‡å’Œå“åº”æ—¶é—´åŠ¨æ€è°ƒæ•´
-        delay = stats.current_delay
-
-        # æ ¹æ®æˆåŠŸç‡è°ƒæ•´
-        if stats.request_count > 5:  # æœ‰è¶³å¤Ÿæ ·æœ¬æ—¶æ‰è°ƒæ•´
-            success_rate = stats.success_rate
-
-            if success_rate < 0.8:  # æˆåŠŸç‡ä½ï¼Œå¢åŠ å»¶è¿Ÿ
-                delay *= 1.5
-            elif success_rate > 0.95:  # æˆåŠŸç‡é«˜ï¼Œå‡å°‘å»¶è¿Ÿ
-                delay *= 0.8
-
-        # æ ¹æ®è¿ç»­é”™è¯¯è°ƒæ•´
-        if stats.consecutive_errors > 0:
-            delay *= 1 + stats.consecutive_errors * 0.4
-
-        # æ ¹æ®å“åº”æ—¶é—´è°ƒæ•´
-        if stats.avg_response_time > 5.0:  # å“åº”æ…¢ï¼Œå¢åŠ å»¶è¿Ÿ
-            delay *= 1.2
-
-        # æ·»åŠ éšæœºæ€§é¿å…æ¨¡å¼è¯†åˆ«
-        delay += random.uniform(-delay * 0.1, delay * 0.1)
-
-        # åº”ç”¨é…ç½®é™åˆ¶
-        delay = max(delay, self.config.min_delay)
-        delay = min(delay, self.config.max_delay)
-
-        return delay
-
-    async def record_success(self, domain: str, response_time: float):
-        """è®°å½•æˆåŠŸè¯·æ±‚."""
-        async with self._lock:
-            stats = self._get_or_create_stats(domain)
-
-            stats.request_count += 1
-            stats.success_count += 1
-            stats.last_success_time = time.time()
-            stats.consecutive_errors = 0
-            stats.consecutive_successes += 1
-            stats.total_response_time += response_time
-            stats.avg_response_time = stats.total_response_time / stats.success_count
-
-            # è‡ªé€‚åº”è°ƒæ•´å½“å‰å»¶è¿Ÿ
-            if self.strategy == RateLimitStrategy.ADAPTIVE:
-                # è¿ç»­æˆåŠŸæ—¶é€æ¸å‡å°‘å»¶è¿Ÿ
-                if stats.consecutive_successes >= 3:
-                    stats.current_delay *= self.config.success_delay_reduction
-                    stats.current_delay = max(
-                        stats.current_delay, self.config.min_delay
-                    )
-
-            logger.debug(f"åŸŸå {domain} æˆåŠŸè®°å½•ï¼Œå“åº”æ—¶é—´: {response_time:.2f}s")
-
-    async def record_error(self, domain: str, error_type: str = "unknown"):
-        """è®°å½•é”™è¯¯è¯·æ±‚."""
-        async with self._lock:
-            stats = self._get_or_create_stats(domain)
-
-            stats.request_count += 1
-            stats.error_count += 1
-            stats.last_error_time = time.time()
-            stats.consecutive_errors += 1
-            stats.consecutive_successes = 0
-
-            # è‡ªé€‚åº”è°ƒæ•´å½“å‰å»¶è¿Ÿ
-            if self.strategy == RateLimitStrategy.ADAPTIVE:
-                # é”™è¯¯æ—¶å¢åŠ å»¶è¿Ÿ
-                stats.current_delay *= self.config.error_delay_multiplier
-                stats.current_delay = min(stats.current_delay, self.config.max_delay)
-
-            logger.warning(
-                f"åŸŸå {domain} é”™è¯¯è®°å½• ({error_type})ï¼Œè¿ç»­é”™è¯¯: {stats.consecutive_errors}"
-            )
-
-    def _get_or_create_stats(self, domain: str) -> DomainStats:
-        """è·å–æˆ–åˆ›å»ºåŸŸåç»Ÿè®¡ä¿¡æ¯."""
-        if domain not in self.domain_stats:
-            # é™åˆ¶åŸŸåæ•°é‡
-            if len(self.domain_stats) >= self.max_domains:
-                # ç§»é™¤æœ€æ—§çš„åŸŸå
-                oldest_domain = min(
-                    self.domain_stats.keys()
-                    key=lambda d: self.domain_stats[d].last_request_time
-                )
-                del self.domain_stats[oldest_domain]
-                logger.info(f"ç§»é™¤æœ€æ—§åŸŸåç»Ÿè®¡: {oldest_domain}")
-
-            self.domain_stats[domain] = DomainStats(
-                domain=domain, current_delay=self.config.base_delay
-            )
+    """
+    ç»Ÿä¸€é€Ÿç‡é™åˆ¶å™¨
 
-        return self.domain_stats[domain]
+    åŸºäº Token Bucket ç®—æ³•å®ç°å¤šåŸŸåå¹¶å‘é™æµæ§åˆ¶ã€‚
+    æ”¯æŒé…ç½®é©±åŠ¨çš„åŠ¨æ€ç­–ç•¥å’Œ Async Context Manager æ¥å£ã€‚
 
-    def get_domain_stats(self, domain: str) -> Optional[DomainStats]:
-        """è·å–åŸŸåç»Ÿè®¡ä¿¡æ¯."""
-        return self.domain_stats.get(domain)
+    ä½¿ç”¨ç¤ºä¾‹:
+        config = {
+            "fotmob.com": {"rate": 2.0, "burst": 5},
+            "fbref.com": {"rate": 1.0, "burst": 3},
+            "default": {"rate": 1.0, "burst": 1}
+        }
 
-    def get_all_stats(self) -> dict[str, DomainStats]:
-        """è·å–æ‰€æœ‰åŸŸåç»Ÿè®¡ä¿¡æ¯."""
-        return self.domain_stats.copy()
+        limiter = RateLimiter(config)
 
-    def get_global_stats(self) -> dict:
-        """è·å–å…¨å±€ç»Ÿè®¡ä¿¡æ¯."""
-        total_requests = sum(
-            stats.request_count for stats in self.domain_stats.values()
-        )
-        total_successes = sum(
-            stats.success_count for stats in self.domain_stats.values()
-        )
-        total_errors = sum(stats.error_count for stats in self.domain_stats.values())
+        # ä½¿ç”¨ Async Context Manager
+        async with limiter.acquire("fotmob.com"):
+            # åœ¨æ­¤èŒƒå›´å†…æ‰§è¡Œè¯·æ±‚
+            await some_http_request()
+    """
 
-        avg_success_rate = (
-            total_successes / total_requests if total_requests > 0 else 0.0
+    def __init__(
+        self,
+        config: Optional[Dict[str, Any]] = None,
+        default_config: Optional[RateLimitConfig] = None
+    ) -> None:
+        """
+        åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
+
+        Args:
+            config: åŸŸåé…ç½®å­—å…¸
+            default_config: é»˜è®¤é…ç½®
+        """
+        self.config: Dict[str, RateLimitConfig] = {}
+        self.buckets: Dict[str, TokenBucket] = {}
+        self._default_config = default_config or RateLimitConfig(
+            rate=1.0,
+            burst=1,
+            max_wait_time=30.0
         )
 
-        return {
-            "strategy": self.strategy.value
-            "total_requests": total_requests
-            "global_request_count": self.global_request_count
-            "total_successes": total_successes
-            "total_errors": total_errors
-            "success_rate": avg_success_rate
-            "active_domains": len(self.domain_stats)
-            "config": {
-                "min_delay": self.config.min_delay
-                "max_delay": self.config.max_delay
-                "base_delay": self.config.base_delay
-            }
-        }
-
-    async def reset_stats(self, domain: str = None):
-        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯."""
-        async with self._lock:
-            if domain:
-                if domain in self.domain_stats:
-                    del self.domain_stats[domain]
-                    logger.info(f"é‡ç½®åŸŸåç»Ÿè®¡: {domain}")
+        # è§£æé…ç½®
+        if config:
+            self._parse_config(config)
+
+        # æ·»åŠ é»˜è®¤é…ç½®
+        if "default" not in self.config:
+            self.config["default"] = self._default_config
+
+    def _parse_config(self, config: Dict[str, Any]) -> None:
+        """
+        è§£æé…ç½®å­—å…¸
+
+        Args:
+            config: é…ç½®å­—å…¸ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
+                1. {"domain": {"rate": 2.0, "burst": 5}}
+                2. {"domain": RateLimitConfig(2.0, 5)}
+        """
+        for domain, cfg in config.items():
+            if isinstance(cfg, dict):
+                # å­—å…¸æ ¼å¼é…ç½®
+                rate = cfg.get("rate", 1.0)
+                burst = cfg.get("burst", 1)
+                max_wait_time = cfg.get("max_wait_time")
+                self.config[domain] = RateLimitConfig(
+                    rate=float(rate),
+                    burst=int(burst),
+                    max_wait_time=max_wait_time
+                )
+            elif isinstance(cfg, RateLimitConfig):
+                # ç›´æ¥ä½¿ç”¨ RateLimitConfig å¯¹è±¡
+                self.config[domain] = cfg
             else:
-                self.domain_stats.clear()
-                self.global_request_count = 0
-                self.global_last_request_time = 0.0
-                logger.info("é‡ç½®æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯")
-
-    def set_strategy(self, strategy: RateLimitStrategy):
-        """è®¾ç½®é¢‘ç‡é™åˆ¶ç­–ç•¥."""
-        old_strategy = self.strategy
-        self.strategy = strategy
-        logger.info(f"é¢‘ç‡ç­–ç•¥å˜æ›´: {old_strategy.value} -> {strategy.value}")
-
-    async def adjust_delays(self, factor: float):
-        """æ‰¹é‡è°ƒæ•´æ‰€æœ‰åŸŸåçš„å»¶è¿Ÿ."""
-        async with self._lock:
-            for stats in self.domain_stats.values():
-                stats.current_delay *= factor
-                stats.current_delay = max(stats.current_delay, self.config.min_delay)
-                stats.current_delay = min(stats.current_delay, self.config.max_delay)
-
-            logger.info(f"æ‰€æœ‰åŸŸåå»¶è¿Ÿè°ƒæ•´: {factor:.2f}x")
-
-
-# å…¨å±€é¢‘ç‡æ§åˆ¶å™¨å®ä¾‹
-_rate_limiter: Optional[RateLimiter] = None
-
-
-def get_rate_limiter() -> RateLimiter:
-    """è·å–å…¨å±€é¢‘ç‡æ§åˆ¶å™¨å®ä¾‹."""
-    global _rate_limiter
-    if _rate_limiter is None:
-        _rate_limiter = RateLimiter()
-    return _rate_limiter
-
-
-async def wait_for_request_slot(domain: str) -> float:
-    """ç­‰å¾…è¯·æ±‚æ—¶æœºçš„ä¾¿æ·å‡½æ•°."""
-    return await get_rate_limiter().wait_for_slot(domain)
-
-
-async def record_request_success(domain: str, response_time: float):
-    """è®°å½•æˆåŠŸè¯·æ±‚çš„ä¾¿æ·å‡½æ•°."""
-    await get_rate_limiter().record_success(domain, response_time)
+                raise ValueError(f"Invalid config for domain {domain}: {cfg}")
+
+    def _get_bucket(self, domain: str) -> TokenBucket:
+        """
+        è·å–æˆ–åˆ›å»ºåŸŸåçš„ä»¤ç‰Œæ¡¶
+
+        Args:
+            domain: åŸŸå
+
+        Returns:
+            TokenBucket: ä»¤ç‰Œæ¡¶å®ä¾‹
+        """
+        if domain not in self.buckets:
+            # ä½¿ç”¨åŸŸåç‰¹å®šé…ç½®æˆ–é»˜è®¤é…ç½®
+            config = self.config.get(domain, self.config["default"])
+            self.buckets[domain] = TokenBucket(
+                tokens=config.burst,
+                capacity=config.burst,
+                refill_rate=config.rate
+            )
+        return self.buckets[domain]
+
+    @asynccontextmanager
+    async def acquire(self, domain: str, tokens: int = 1):
+        """
+        è·å–ä»¤ç‰Œçš„ Async Context Manager
+
+        Args:
+            domain: åŸŸå
+            tokens: éœ€è¦çš„ä»¤ç‰Œæ•°
+
+        Yields:
+            None: æˆåŠŸè·å–ä»¤ç‰Œ
+
+        Raises:
+            asyncio.TimeoutError: è¶…æ—¶æœªè·å–ä»¤ç‰Œ
+            RuntimeError: é€Ÿç‡é™åˆ¶é…ç½®é”™è¯¯
+        """
+        bucket = self._get_bucket(domain)
+        config = self.config.get(domain, self.config["default"])
+
+        # å°è¯•ç«‹å³è·å–ä»¤ç‰Œ
+        if await bucket.consume(tokens):
+            yield
+            return
+
+        # éœ€è¦ç­‰å¾…ä»¤ç‰Œ
+        try:
+            success = await bucket.wait_for_tokens(
+                tokens=tokens,
+                timeout=config.max_wait_time
+            )
 
+            if not success:
+                raise asyncio.TimeoutError(
+                    f"Rate limit exceeded for domain {domain}: "
+                    f"waited {config.max_wait_time}s without acquiring {tokens} tokens"
+                )
 
-async def record_request_error(domain: str, error_type: str = "unknown"):
-    """è®°å½•é”™è¯¯è¯·æ±‚çš„ä¾¿æ·å‡½æ•°."""
-    await get_rate_limiter().record_error(domain, error_type)
+            yield
+
+        except asyncio.CancelledError:
+            # ä»»åŠ¡è¢«å–æ¶ˆï¼Œé‡Šæ”¾ä»¤ç‰Œ
+            async with bucket.lock:
+                bucket.tokens = min(bucket.capacity, bucket.tokens + tokens)
+            raise
+
+    async def try_acquire(self, domain: str, tokens: int = 1) -> bool:
+        """
+        å°è¯•ç«‹å³è·å–ä»¤ç‰Œï¼ˆéé˜»å¡ï¼‰
+
+        Args:
+            domain: åŸŸå
+            tokens: éœ€è¦çš„ä»¤ç‰Œæ•°
+
+        Returns:
+            bool: æ˜¯å¦æˆåŠŸè·å–ä»¤ç‰Œ
+        """
+        bucket = self._get_bucket(domain)
+        return await bucket.consume(tokens)
+
+    async def wait_for_available(self, domain: str, tokens: int = 1) -> float:
+        """
+        ç­‰å¾…ä»¤ç‰Œå¯ç”¨å¹¶è¿”å›ç­‰å¾…æ—¶é—´
+
+        Args:
+            domain: åŸŸå
+            tokens: éœ€è¦çš„ä»¤ç‰Œæ•°
+
+        Returns:
+            float: å®é™…ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
+        """
+        start_time = time.monotonic()
+        bucket = self._get_bucket(domain)
+        config = self.config.get(domain, self.config["default"])
+
+        await bucket.wait_for_tokens(tokens, config.max_wait_time)
+        return time.monotonic() - start_time
+
+    def get_status(self, domain: Optional[str] = None) -> Dict[str, Any]:
+        """
+        è·å–é€Ÿç‡é™åˆ¶å™¨çŠ¶æ€
+
+        Args:
+            domain: ç‰¹å®šåŸŸåï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰åŸŸå
+
+        Returns:
+            Dict[str, Any]: çŠ¶æ€ä¿¡æ¯
+        """
+        if domain:
+            if domain not in self.buckets:
+                return {"error": f"No bucket found for domain: {domain}"}
+
+            bucket = self.buckets[domain]
+            config = self.config.get(domain, self.config["default"])
+
+            return {
+                "domain": domain,
+                "available_tokens": bucket.tokens,
+                "capacity": bucket.capacity,
+                "rate": bucket.refill_rate,
+                "config": {
+                    "rate": config.rate,
+                    "burst": config.burst,
+                    "max_wait_time": config.max_wait_time
+                }
+            }
+        else:
+            # è¿”å›æ‰€æœ‰åŸŸåçš„çŠ¶æ€
+            status = {}
+            for d, bucket in self.buckets.items():
+                config = self.config.get(d, self.config["default"])
+                status[d] = {
+                    "available_tokens": bucket.tokens,
+                    "capacity": bucket.capacity,
+                    "rate": bucket.refill_rate,
+                    "config": {
+                        "rate": config.rate,
+                        "burst": config.burst,
+                        "max_wait_time": config.max_wait_time
+                    }
+                }
+            return status
+
+    def update_config(self, domain: str, config: RateLimitConfig) -> None:
+        """
+        æ›´æ–°åŸŸåé…ç½®
+
+        Args:
+            domain: åŸŸå
+            config: æ–°çš„é€Ÿç‡é™åˆ¶é…ç½®
+        """
+        self.config[domain] = config
+
+        # å¦‚æœå·²å­˜åœ¨ä»¤ç‰Œæ¡¶ï¼Œéœ€è¦é‡æ–°åˆ›å»ºä»¥åº”ç”¨æ–°é…ç½®
+        if domain in self.buckets:
+            del self.buckets[domain]
+
+    def remove_domain(self, domain: str) -> None:
+        """
+        ç§»é™¤åŸŸåé…ç½®å’Œä»¤ç‰Œæ¡¶
+
+        Args:
+            domain: è¦ç§»é™¤çš„åŸŸå
+        """
+        if domain in self.config:
+            del self.config[domain]
+        if domain in self.buckets:
+            del self.buckets[domain]
+
+    async def clear_all(self) -> None:
+        """æ¸…ç©ºæ‰€æœ‰ä»¤ç‰Œæ¡¶"""
+        for bucket in self.buckets.values():
+            async with bucket.lock:
+                bucket.tokens = 0.0
+
+
+# ä¾¿åˆ©å‡½æ•°
+def create_rate_limiter(
+    config: Optional[Dict[str, Any]] = None,
+    default_rate: float = 1.0,
+    default_burst: int = 1
+) -> RateLimiter:
+    """
+    åˆ›å»ºé€Ÿç‡é™åˆ¶å™¨çš„ä¾¿åˆ©å‡½æ•°
+
+    Args:
+        config: åŸŸåé…ç½®å­—å…¸
+        default_rate: é»˜è®¤é€Ÿç‡
+        default_burst: é»˜è®¤çªå‘å®¹é‡
+
+    Returns:
+        RateLimiter: é€Ÿç‡é™åˆ¶å™¨å®ä¾‹
+    """
+    default_config = RateLimitConfig(
+        rate=default_rate,
+        burst=default_burst,
+        max_wait_time=30.0
+    )
+
+    return RateLimiter(config, default_config)
+
+
+# æ¨¡å—å¯¼å‡º
+__all__ = [
+    "RateLimiter",
+    "RateLimitConfig",
+    "TokenBucket",
+    "create_rate_limiter",
+]
\ No newline at end of file
