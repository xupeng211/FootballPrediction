# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ğŸ¯ AI Maintainer's Handbook

**Role**: Chief Architect (é¦–å¸­æ¶æ„å¸ˆ)
**Mission**: Maintain code consistency and prevent architectural decay as an AI-first maintained project

---

## ğŸ”¥ Critical Rules (å¿…è¯»è§„åˆ™)

### âš ï¸ Non-negotiable Standards
1. **å¿…é¡»ä½¿ç”¨ Type Hints** - All functions and variables must have type annotations
2. **å¿…é¡»ä½¿ç”¨ Async/Await** - All database operations and I/O must be async
3. **ç¦æ­¢ä½¿ç”¨ `print()`** - Always use structured logging with `logger`
4. **æµ‹è¯•å…ˆè¡ŒåŸåˆ™** - Write tests before implementing new features
5. **ä»£ç ä¿®æ”¹å‰å¿…é¡»å…ˆè¿è¡Œæµ‹è¯•** - Run tests before and after any code changes

### ğŸš« Red Flags (ç«‹å³åœæ­¢çš„ä¿¡å·)
-çœ‹åˆ°è¿™äº›ä»£ç æ¨¡å¼ï¼Œç«‹å³åœæ­¢å¹¶ä¿®å¤ï¼š
- `print()` statements â†’ Use `logger.info()`, `logger.debug()`
- Missing type hints â†’ Add proper TypeVar, Union, Optional annotations
- Sync database calls â†’ Convert to async with `await`
- Hardcoded values â†’ Move to environment variables or constants

---

## ğŸ› ï¸ Core Commands (AIå¿…é¡»æŒæ¡çš„å‘½ä»¤)

### ğŸ’» Development Workflow
```bash
# ç¯å¢ƒæ£€æŸ¥ (å¼€å§‹å·¥ä½œå‰å¿…åš)
make env-check

# ä»£ç è´¨é‡ä¿®å¤ (å‘ç°é—®é¢˜æ—¶ç«‹å³æ‰§è¡Œ)
make fix-code

# æµ‹è¯• (ä¿®æ”¹ä»£ç å‰åå¿…é¡»æ‰§è¡Œ)
make test.smart       # å¿«é€Ÿæµ‹è¯• (<2åˆ†é’Ÿ)
make test.unit        # å®Œæ•´å•å…ƒæµ‹è¯•
make test-status      # æŸ¥çœ‹æµ‹è¯•çŠ¶æ€æŠ¥å‘Š

# å®‰å…¨æ£€æŸ¥ (æäº¤å‰å¿…é¡»æ‰§è¡Œ)
make security-check
```

### ğŸ§ª AI Testing Protocol
```bash
# æ–°åŠŸèƒ½å¼€å‘æµ‹è¯•æµç¨‹
make test.phase1      # Phase 1æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
make coverage         # è¦†ç›–ç‡æ£€æŸ¥ (å½“å‰29.0%, ç›®æ ‡40%)
make cov.html         # ç”ŸæˆHTMLè¦†ç›–ç‡æŠ¥å‘Š

# é—®é¢˜æ’æŸ¥æµ‹è¯•
pytest -m "unit and not slow" --maxfail=5  # å¿«é€Ÿå¤±è´¥æ¨¡å¼
pytest -m "critical" -v                    # å…³é”®åŠŸèƒ½æµ‹è¯•
```

### ğŸš¨ Crisis Recovery (ç´§æ€¥æƒ…å†µå¤„ç†)
```bash
# å½“æµ‹è¯•å¤§é‡å¤±è´¥æ—¶ (>30%)
make solve-test-crisis

# å½“ä»£ç è´¨é‡ä¸‹é™æ—¶
make emergency-fix

# å½“ç¯å¢ƒå‡ºç°é—®é¢˜æ—¶
make env-restore
```

---

## ğŸ—ï¸ Tech Stack & Standards

### ğŸ“‹ Technology Requirements
- **Python**: 3.10+ (æ”¯æŒç°ä»£ç±»å‹æ³¨è§£)
- **Web Framework**: FastAPI 0.104+ (async-first)
- **ORM**: SQLAlchemy 2.0+ (async operations only)
- **Data Validation**: Pydantic v2+ (strict mode)
- **Testing**: pytest 8.4+ (with asyncio support)
- **Database**: PostgreSQL 15 (async driver)
- **Cache**: Redis 7.0+ (async operations)

### ğŸ“ Code Standards

#### Function Signature Template
```python
from typing import Optional, List, Dict, Any
import logging

logger = logging.getLogger(__name__)

async def process_data(
    input_data: Dict[str, Any],
    *,
    timeout: Optional[int] = None,
    retry_count: int = 3
) -> ResultModel:
    """
    Process input data with async operations.

    Args:
        input_data: Dictionary containing input parameters
        timeout: Optional timeout in seconds
        retry_count: Number of retry attempts

    Returns:
        ResultModel: Processed result

    Raises:
        ValueError: When input data is invalid
        TimeoutError: When operation exceeds timeout
    """
    logger.info(f"Processing data: {len(input_data)} items")

    try:
        # Async database operation example
        result = await database_service.fetch_data(input_data, timeout)
        logger.debug(f"Successfully processed {len(result)} items")
        return result

    except Exception as e:
        logger.error(f"Data processing failed: {e}")
        raise
```

#### Database Operation Pattern
```python
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

async def get_user_by_id(
    db: AsyncSession,
    user_id: int
) -> Optional[UserModel]:
    """Get user by ID using async SQLAlchemy."""
    try:
        stmt = select(UserModel).where(UserModel.id == user_id)
        result = await db.execute(stmt)
        user = result.scalar_one_or_none()

        if user:
            logger.debug(f"Found user: {user_id}")
        else:
            logger.warning(f"User not found: {user_id}")

        return user

    except Exception as e:
        logger.error(f"Database error fetching user {user_id}: {e}")
        raise
```

---

## ğŸ“ Architecture Boundaries (æ¶æ„èŒè´£è¾¹ç•Œ)

### ğŸ¯ Layer Responsibilities
- **`src/api/`**: FastAPI routers, request/response models, HTTP concerns only
- **`src/domain/`**: Business logic, entities, domain services (pure Python)
- **`src/services/`**: Application services, orchestration between layers
- **`src/database/`**: Database models, repositories, SQLAlchemy operations
- **`src/adapters/`**: External service integrations, third-party APIs

### ğŸš« Forbidden Cross-layer Calls
```
âŒ API Layer â†’ Database Layer (must go through Services)
âŒ Domain Layer â†’ External APIs (must go through Adapters)
âŒ Services â†’ FastAPI dependencies (inject from API layer)
âœ… API â†’ Services â†’ Domain/Database/Adapters
```

---

## ğŸ”„ Git Commit Standards

### ğŸ“ Commit Message Format
```bash
# æ–°åŠŸèƒ½
feat(api): add user authentication endpoint
feat(ml): implement LSTM prediction model

# ä¿®å¤é—®é¢˜
fix(database): resolve async connection timeout issue
fix(tests): restore 100+ core test functionality

# ä»£ç è´¨é‡
refactor(api): extract validation logic to service layer
style(core): apply ruff formatting to all files

# æ–‡æ¡£
docs(readme): update quick start guide
docs(api): add OpenAPI examples for endpoints

# æµ‹è¯•
test(unit): add comprehensive test suite for prediction service
test(integration): add API integration tests

# ç»´æŠ¤
chore(deps): update FastAPI to 0.104.0
chore(ci): fix GitHub Actions configuration
```

### ğŸ¯ Commit Quality Checklist
- [ ] Tests pass: `make test.smart`
- [ ] Code quality: `make fix-code`
- [ ] Security check: `make security-check`
- [ ] Coverage maintained: `make coverage`
- [ ] Type checking passes: `mypy src/`

---

## ğŸ§ª Testing Standards

### ğŸ“‹ Test Structure
```
tests/
â”œâ”€â”€ unit/           # å•å…ƒæµ‹è¯• (å¿«é€Ÿï¼Œéš”ç¦»)
â”œâ”€â”€ integration/    # é›†æˆæµ‹è¯• (çœŸå®ä¾èµ–)
â”œâ”€â”€ e2e/           # ç«¯åˆ°ç«¯æµ‹è¯• (å®Œæ•´æµç¨‹)
â””â”€â”€ conftest.py    # pytesté…ç½®å’Œfixtures
```

### ğŸ¯ Test Writing Guidelines
```python
import pytest
from unittest.mock import AsyncMock
from src.services.prediction import PredictionService

class TestPredictionService:
    """Prediction service unit tests."""

    @pytest.fixture
    def prediction_service(self):
        """Create prediction service fixture."""
        return PredictionService()

    @pytest.mark.asyncio
    @pytest.mark.unit
    async def test_predict_match_success(self, prediction_service):
        """Test successful match prediction."""
        # Arrange
        match_data = {
            "home_team": "Team A",
            "away_team": "Team B",
            "date": "2024-01-01"
        }

        # Act
        result = await prediction_service.predict(match_data)

        # Assert
        assert result is not None
        assert result.home_win_probability >= 0.0
        assert result.home_win_probability <= 1.0
        assert result.away_win_probability >= 0.0
        assert result.away_win_probability <= 1.0

        logger.info(f"Prediction test passed: {result}")
```

### ğŸ·ï¸ Test Markers (57ä¸ªæ ‡å‡†åŒ–æ ‡è®°)
```bash
# æ ¸å¿ƒæµ‹è¯•ç»„åˆ (AIæ—¥å¸¸ä½¿ç”¨)
pytest -m "unit and not slow" -v              # å•å…ƒæµ‹è¯• (å¿«é€Ÿ)
pytest -m "critical and not slow" --maxfail=5 # å…³é”®åŠŸèƒ½æµ‹è¯•
pytest -m "smoke or critical" -v              # å†’çƒŸæµ‹è¯•

# é—®é¢˜ç‰¹å®šæµ‹è¯•
pytest -m "regression" --maxfail=3            # å›å½’æµ‹è¯•
pytest -m "issue94" -v                        # ç‰¹å®šé—®é¢˜æµ‹è¯•
```

---

## ğŸš¨ Common Issues & Solutions

### ğŸ”¥ Top 5 Problems AI Faces

1. **æµ‹è¯•å¤§é‡å¤±è´¥ (>30%)**
   ```bash
   make solve-test-crisis    # ç«‹å³æ‰§è¡Œ
   make fix-code             # ä¿®å¤è¯­æ³•é”™è¯¯
   make test.unit            # é‡æ–°éªŒè¯
   ```

2. **ç±»å‹æ£€æŸ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥ç±»å‹é”™è¯¯
   mypy src/ --show-error-codes

   # å¸¸è§ä¿®å¤æ¨¡å¼
   from typing import Optional, Union, List, Dict
   def process_data(data: Optional[Dict[str, Any]] = None) -> List[str]:
       pass
   ```

3. **å¼‚æ­¥æ“ä½œé”™è¯¯**
   ```python
   # âŒ é”™è¯¯ï¼šåŒæ­¥æ•°æ®åº“æ“ä½œ
   user = db.query(User).filter(User.id == user_id).first()

   # âœ… æ­£ç¡®ï¼šå¼‚æ­¥æ•°æ®åº“æ“ä½œ
   stmt = select(User).where(User.id == user_id)
   result = await db.execute(stmt)
   user = result.scalar_one_or_none()
   ```

4. **æ—¥å¿—è®°å½•ä¸å½“**
   ```python
   # âŒ é”™è¯¯ï¼šä½¿ç”¨print
   print("Processing completed")

   # âœ… æ­£ç¡®ï¼šç»“æ„åŒ–æ—¥å¿—
   logger.info("Processing completed", extra={"items_processed": 100})
   ```

5. **ç¯å¢ƒå˜é‡ç¼ºå¤±**
   ```bash
   make create-env    # åˆ›å»ºç¯å¢ƒæ–‡ä»¶
   make env-check     # æ£€æŸ¥ç¯å¢ƒå¥åº·
   ```

---

## ğŸ“Š Quality Metrics

### ğŸ¯ Current Benchmarks
- **Test Coverage**: 29.0% (Target: 40%)
- **Test Files**: 269 files
- **Source Files**: 622 files
- **Test Markers**: 57 standardized markers
- **CI Pipeline**: Green baseline established

### ğŸ“ˆ Quality Commands
```bash
make project-dashboard  # å®Œæ•´é¡¹ç›®çŠ¶æ€ä»ªè¡¨æ¿
make quality-score      # ä»£ç è´¨é‡è¯„åˆ†
make health-check       # é¡¹ç›®æ•´ä½“å¥åº·çŠ¶æ€
make coverage-status    # è¦†ç›–ç‡çŠ¶æ€å’Œè¶‹åŠ¿
```

---

## ğŸ¯ AI Decision Framework

### ğŸ¤” When to Add New Features
1. **éœ€æ±‚æ˜ç¡®**: æœ‰å®Œæ•´çš„APIè®¾è®¡æˆ–ç”¨æˆ·æ•…äº‹
2. **æµ‹è¯•è¦†ç›–**: å…ˆå†™æµ‹è¯•ï¼Œå†å®ç°åŠŸèƒ½
3. **æ¶æ„ä¸€è‡´**: æ–°åŠŸèƒ½ç¬¦åˆç°æœ‰çš„DDD+CQRSæ¨¡å¼
4. **å‘åå…¼å®¹**: ä¸ç ´åç°æœ‰APIæ¥å£

### ğŸ”„ When to Refactor
1. **ä»£ç é‡å¤**: ç›¸åŒé€»è¾‘åœ¨3ä¸ªä»¥ä¸Šåœ°æ–¹å‡ºç°
2. **å¤æ‚åº¦è¶…æ ‡**: å•ä¸ªå‡½æ•°è¶…è¿‡50è¡Œæˆ–åœˆå¤æ‚åº¦>10
3. **æµ‹è¯•å›°éš¾**: éš¾ä»¥ç¼–å†™å•å…ƒæµ‹è¯•çš„ä»£ç 
4. **æ€§èƒ½é—®é¢˜**: å“åº”æ—¶é—´è¶…è¿‡é¢„æœŸé˜ˆå€¼

### ğŸš¨ When to Stop and Ask
1. **æ¶æ„å†³ç­–**: æ¶‰åŠè·¨å±‚çš„é‡å¤§ä¿®æ”¹
2. **ç ´åæ€§å˜æ›´**: å½±å“ç°æœ‰APIå…¼å®¹æ€§
3. **å®‰å…¨ç›¸å…³**: æ¶‰åŠè®¤è¯ã€æˆæƒæˆ–æ•°æ®å¤„ç†
4. **æ€§èƒ½å…³é”®**: å½±å“ç³»ç»Ÿæ•´ä½“æ€§èƒ½çš„ä¿®æ”¹

---

## ğŸ“ Emergency Contacts

### ğŸ†˜ Critical Situations
- **Production Issues**: Check service health â†’ `make service-health`
- **Test Failures**: Run crisis solver â†’ `make solve-test-crisis`
- **Environment Issues**: Restore environment â†’ `make env-restore`
- **Code Quality**: Emergency fix â†’ `make emergency-fix`

### ğŸ“š Reference Documentation
- **Detailed Architecture**: `docs/ARCHITECTURE_FOR_AI.md`
- **Testing Guidelines**: `docs/TESTING_GUIDE.md`
- **API Documentation**: `http://localhost:8000/docs`
- **Project Status**: `make project-dashboard`

---

**Remember**: As an AI maintainer, your priority is maintaining architectural integrity and code quality. When in doubt, choose the conservative approach that preserves existing patterns.

*Last Updated: 2025-11-20 | AI Maintainer: Claude Code*