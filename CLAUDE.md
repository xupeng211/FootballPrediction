# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**é‡è¦æé†’**: è¯·å§‹ç»ˆä½¿ç”¨ç®€ä½“ä¸­æ–‡å›žå¤ç”¨æˆ·é—®é¢˜å’Œäº¤æµã€‚

**é¡¹ç›®ç±»åž‹**: ä¼ä¸šçº§è¶³çƒé¢„æµ‹ç³»ç»Ÿ (Enterprise Football Prediction System)
**æž¶æž„æ¨¡å¼**: DDD + CQRS + Event-Driven + Async-First
**æŠ€æœ¯æ ˆ**: FastAPI 0.104+ + SQLAlchemy 2.0+ + Redis 5.0+ + PostgreSQL 15 + React 19.2.0 + TypeScript 4.9.5 + XGBoost 2.0+

## ðŸ› ï¸ Core Development Commands

### Environment Setup
```bash
# Dockerå¼€å‘çŽ¯å¢ƒ (ä¸»è¦å¼€å‘æ–¹å¼)
make dev                # å¯åŠ¨å®Œæ•´å¼€å‘çŽ¯å¢ƒ (app + db + redis + frontend + nginx + worker + beat)
make dev-rebuild        # é‡æ–°æž„å»ºé•œåƒå¹¶å¯åŠ¨å¼€å‘çŽ¯å¢ƒ
make dev-logs           # æŸ¥çœ‹å¼€å‘çŽ¯å¢ƒæ—¥å¿—
make dev-stop           # åœæ­¢å¼€å‘çŽ¯å¢ƒ
make down               # åœæ­¢æ‰€æœ‰æœåŠ¡

# ç”Ÿäº§çŽ¯å¢ƒ
make prod               # å¯åŠ¨ç”Ÿäº§çŽ¯å¢ƒ (ä½¿ç”¨ docker-compose.prod.yml)
make prod-rebuild       # é‡æ–°æž„å»ºç”Ÿäº§çŽ¯å¢ƒ

# çŽ¯å¢ƒç®¡ç†
make clean              # æ¸…ç†Dockerèµ„æºå’Œç¼“å­˜
make clean-all          # å½»åº•æ¸…ç†æ‰€æœ‰ç›¸å…³èµ„æº
make status             # æŸ¥çœ‹æ‰€æœ‰æœåŠ¡çŠ¶æ€

# å¿«æ·å‘½ä»¤
make quick-start        # å¿«é€Ÿå¯åŠ¨å¼€å‘çŽ¯å¢ƒ (åˆ«å: dev)
make quick-stop         # å¿«é€Ÿåœæ­¢å¼€å‘çŽ¯å¢ƒ (åˆ«å: dev-stop)
```

### Code Quality & Testing
```bash
# ä»£ç è´¨é‡æ£€æŸ¥å’Œä¿®å¤ (åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ)
make test               # åœ¨å®¹å™¨ä¸­è¿è¡Œæ‰€æœ‰æµ‹è¯•
make lint               # åœ¨å®¹å™¨ä¸­è¿è¡Œä»£ç æ£€æŸ¥ (Ruff + MyPy)
make format             # åœ¨å®¹å™¨ä¸­è¿è¡Œä»£ç æ ¼å¼åŒ– (ruff format)
make fix-code           # åœ¨å®¹å™¨ä¸­è¿è¡Œä»£ç è‡ªåŠ¨ä¿®å¤
make type-check         # åœ¨å®¹å™¨ä¸­è¿è¡Œç±»åž‹æ£€æŸ¥
make security-check     # åœ¨å®¹å™¨ä¸­è¿è¡Œå®‰å…¨æ‰«æ
make coverage           # åœ¨å®¹å™¨ä¸­ç”Ÿæˆè¦†ç›–çŽ‡æŠ¥å‘Š

# æµ‹è¯•åˆ†ç±»æ‰§è¡Œ
make test.unit          # åœ¨å®¹å™¨ä¸­è¿è¡Œå•å…ƒæµ‹è¯•
make test.integration   # åœ¨å®¹å™¨ä¸­è¿è¡Œé›†æˆæµ‹è¯•
make test.all           # åœ¨å®¹å™¨ä¸­è¿è¡Œæ‰€æœ‰æµ‹è¯•

# å¿«é€Ÿä¼˜åŒ–è„šæœ¬
./quick_optimize.sh     # å¿«é€Ÿä¼˜åŒ–ä»£ç è´¨é‡ (ä¸€é”®ä¿®å¤æ‰€æœ‰é—®é¢˜)

# æœ¬åœ°æµ‹è¯•æ‰§è¡Œ (å¯é€‰ï¼Œéœ€è¦æœ¬åœ°çŽ¯å¢ƒ)
pytest tests/unit/test_specific.py::test_function -v        # è¿è¡Œå•ä¸ªæµ‹è¯•
pytest tests/unit/test_module.py -k "test_keyword" -v        # å…³é”®è¯è¿‡æ»¤æµ‹è¯•
pytest tests/unit/ -m "unit and not slow" -v                # æ ‡è®°ç»„åˆæµ‹è¯•
pytest tests/unit/ --maxfail=3 -x                           # å¤±è´¥æ—¶å¿«é€Ÿåœæ­¢

# è¦†ç›–çŽ‡åˆ†æž
pytest --cov=src --cov-report=html --cov-report=term-missing

# CI è¦†ç›–çŽ‡é—¨æ§›éªŒè¯ (è¦æ±‚31%)
pytest --cov=src --cov-fail-under=31 --cov-report=term-missing
```

### Container Management & Access
```bash
# å®¹å™¨ç®¡ç†å’Œè®¿é—®
make shell              # è¿›å…¥åŽç«¯å®¹å™¨ç»ˆç«¯
make shell-db           # è¿›å…¥æ•°æ®åº“å®¹å™¨
make db-shell           # è¿žæŽ¥PostgreSQLæ•°æ®åº“
make redis-shell        # è¿žæŽ¥Redis
make logs               # æŸ¥çœ‹åº”ç”¨æ—¥å¿—
make logs-db            # æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
make logs-redis         # æŸ¥çœ‹Redisæ—¥å¿—
make status             # æŸ¥çœ‹æ‰€æœ‰æœåŠ¡çŠ¶æ€

# Docker å®¹å™¨ç®¡ç† (åŽŸç”Ÿå‘½ä»¤)
docker-compose up -d            # å¯åŠ¨å®Œæ•´å¼€å‘çŽ¯å¢ƒ
docker-compose down             # åœæ­¢å¼€å‘çŽ¯å¢ƒ
docker-compose logs -f app      # æŸ¥çœ‹åº”ç”¨æ—¥å¿—
docker-compose exec app bash     # è¿›å…¥åº”ç”¨å®¹å™¨
docker-compose exec db psql      # è¿žæŽ¥PostgreSQLæ•°æ®åº“

# ç›‘æŽ§å’Œè°ƒè¯•
make monitor            # å®žæ—¶ç›‘æŽ§åº”ç”¨èµ„æºä½¿ç”¨
make monitor-all        # ç›‘æŽ§æ‰€æœ‰å®¹å™¨èµ„æºä½¿ç”¨

# æ•°æ®åº“ç®¡ç†
make db-reset           # é‡ç½®æ•°æ®åº“
make db-migrate         # è¿è¡Œæ•°æ®åº“è¿ç§»
```

### Security & Validation
```bash
make security-check     # Banditå®‰å…¨æ‰«æ
make audit              # ä¾èµ–å®‰å…¨å®¡è®¡
make ci-check          # å®Œæ•´CIéªŒè¯
```

## ðŸ—ï¸ Architecture Overview

### Technology Stack
- **Backend**: FastAPI 0.104+, SQLAlchemy 2.0+, Pydantic v2+, Redis 5.0+, PostgreSQL 15
- **Frontend**: React 19.2.0, TypeScript 4.9.5, Ant Design 5.27.6, Redux Toolkit 2.9.2
- **Machine Learning**: XGBoost 2.0+, scikit-learn 1.3+, pandas 2.1+, MLflow 2.22.2+
- **Testing**: pytest 8.4+ with asyncio support (4597 test functions across 274 test files)
- **Code Quality**: Ruff 0.14+, MyPy 1.18+, Bandit 1.8.6+

### Clean Architecture Pattern
```
src/
â”œâ”€â”€ api/           # FastAPI routers, HTTP concerns only
â”œâ”€â”€ domain/        # Business logic, entities (pure Python)
â”œâ”€â”€ services/      # Application services, orchestration
â”œâ”€â”€ database/      # SQLAlchemy models, repositories
â”œâ”€â”€ adapters/      # External API integrations
â”œâ”€â”€ ml/           # Machine learning models and pipelines
â”œâ”€â”€ cache/        # Redis caching layer
â””â”€â”€ utils/        # Shared utilities
```

### Key Integration Points
- **Main Application**: `src/main.py` with 40+ API endpoints
- **ML Prediction Engine**: XGBoost models for match predictions
- **Real-time Features**: WebSocket support at `/api/v1/realtime/ws`
- **Caching**: Redis-based performance optimization
- **Database**: Async PostgreSQL with SQLAlchemy 2.0

### API Endpoints Structure
- **Health Checks**: `/health`, `/health/system`, `/health/database`
- **Predictions**: `/api/v1/predictions/`, `/api/v2/predictions/`
- **Data Management**: `/api/v1/data_management/`
- **System**: `/api/v1/system/`
- **Adapters**: `/api/v1/adapters/`
- **Monitoring**: `/metrics`

## ðŸ§ª Testing Architecture

### Test Structure (4597 test functions across 274 test files)
- **Unit Tests** (85%): Fast, isolated component testing
- **Integration Tests** (12%): Real dependency testing
- **E2E Tests** (2%): Complete user workflow testing
- **Performance Tests** (1%): Load and stress testing

### Standardized Test Markers
```python
# Core test types
@pytest.mark.unit           # Unit tests (85% of tests)
@pytest.mark.integration    # Integration tests (12% of tests)
@pytest.mark.e2e           # End-to-end tests (2% of tests)
@pytest.mark.performance   # Performance tests (1% of tests)

# Execution characteristics
@pytest.mark.critical       # Must-pass core functionality
@pytest.mark.smoke         # Basic functionality validation
@pytest.mark.slow          # Long-running tests (>30s)
@pytest.mark.regression    # Regression testing

# Functional domain
@pytest.mark.api           # HTTP endpoint testing
@pytest.mark.database      # Database connection tests
@pytest.mark.ml            # Machine learning tests
@pytest.mark.cache         # Redis and caching logic
@pytest.mark.auth          # Authentication and authorization
@pytest.mark.monitoring    # Metrics and health checks

# Development dependencies
@pytest.mark.external_api  # Requires external API calls
@pytest.mark.docker        # Requires Docker container environment
@pytest.mark.network       # Requires network connection
```

### Recommended Testing Workflow
```bash
# æ—¥å¸¸å¼€å‘ - å¿«é€ŸéªŒè¯
make test              # Run all tests with fast feedback

# åŠŸèƒ½å¼€å‘å®Œæˆ - å®Œæ•´æµ‹è¯•
make test.unit          # Full unit test suite with coverage
make coverage           # Generate HTML coverage report

# å‘å¸ƒå‰éªŒè¯ - å…¨é¢æ£€æŸ¥
make test.all           # Complete test suite (unit + integration + e2e)
make lint && make test  # Code quality + full testing
```

## ðŸ”§ Development Standards

### Code Style Requirements
- **Type Hints**: All functions must have complete type annotations
- **Async/Await**: All I/O operations must be async (database, external APIs)
- **Logging**: Use structured logging with `logger` (never use `print()`)
- **Error Handling**: Comprehensive exception handling with proper logging

### Function Template
```python
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

async def process_data(
    input_data: Dict[str, Any],
    *,
    timeout: Optional[int] = None,
    retry_count: int = 3
) -> ResultModel:
    """Process input data with async operations.

    Args:
        input_data: Dictionary containing input parameters
        timeout: Optional timeout in seconds
        retry_count: Number of retry attempts

    Returns:
        ResultModel: Processed result

    Raises:
        ValueError: When input data is invalid
        TimeoutError: When operation exceeds timeout
    """
    logger.info(f"Processing data: {len(input_data)} items")

    try:
        result = await database_service.fetch_data(input_data, timeout)
        logger.debug(f"Successfully processed {len(result)} items")
        return result
    except Exception as e:
        logger.error(f"Data processing failed: {e}")
        raise
```

## ðŸ³ Docker Development

### Multi-Environment Support
- **Development**: `docker-compose.yml` (å®Œæ•´å¼€å‘æ ˆ - app + db + redis + frontend + nginx + worker + beat)
- **Production**: `docker-compose.prod.yml` (ç”Ÿäº§ä¼˜åŒ–æ ˆ - app + db + redis + nginx + monitoring + logging)

### Service Stack
#### Development Environment
- **app**: FastAPI application (port: 8000)
- **frontend**: React application (ports: 3000, 3001)
- **db**: PostgreSQL 15 (port: 5432)
- **redis**: Redis 7.0 (port: 6379)
- **nginx**: Reverse proxy (port: 80)
- **worker**: Celery worker (å¼‚æ­¥ä»»åŠ¡å¤„ç†)
- **beat**: Celery beat (å®šæ—¶ä»»åŠ¡è°ƒåº¦)

#### Production Environment (Additional Services)
- **prometheus**: æŒ‡æ ‡æ”¶é›†å’Œå­˜å‚¨ (port: 9090)
- **grafana**: å¯è§†åŒ–ä»ªè¡¨æ¿ (port: 3000)
- **loki**: æ—¥å¿—èšåˆ (port: 3100)

### Container Development Features
- Hot reload with volume mounting
- Health checks for all services
- Environment-specific configurations
- Multi-stage builds for optimized images
- Development vs production targets

## ðŸ¤– Machine Learning Pipeline

### ML Architecture
- **Prediction Engine**: XGBoost 2.0+ gradient boosting models with hyperparameter optimization
- **Feature Engineering**: pandas 2.1+ and numpy 1.25+ data preprocessing with automated pipelines
- **Model Training**: scikit-learn 1.3+ training pipelines with cross-validation
- **Model Management**: MLflow 2.22.2+ version control with security patches and experiment tracking
- **Model Ensemble**: Multiple prediction strategies (LSTM, Poisson, Ensemble) with performance comparison

### ML Service Integration
```python
# Inference service usage
from src.services.inference_service import inference_service

prediction_result = await inference_service.predict_match(match_id)
# Returns: PredictionResult with confidence scores and probabilities

# Batch prediction
batch_results = await inference_service.batch_predict_match(match_ids)
```

### Model Lifecycle
- **Training**: `src/ml/train_model.py` - Automated model training with hyperparameter tuning
- **Validation**: `src/ml/model_validation.py` - Cross-validation and performance evaluation
- **Deployment**: `src/ml/model_deployment.py` - Model packaging and API deployment
- **Monitoring**: `src/ml/model_monitoring.py` - Real-time performance tracking and drift detection
- **Feature Store**: `src/ml/feature_store.py` - Centralized feature management
- **Experiments**: `src/ml/experiments/` - A/B testing and model comparison

### ML Model Management
```bash
# ML model operations
python -m src.ml.train_model --config configs/ml/xgboost_v2.yaml
python -m src.ml.model_validation --model-version latest
python -m src.ml.batch_predict --date-range 2024-01-01:2024-01-31

# MLflow UI (when running)
mlflow ui --port 5000  # Access experiment tracking
```

## ðŸš¨ Crisis Management Tools

### Test Crisis Recovery
```bash
# When tests are failing (>30%)
make test               # Run tests to identify issues
make fix-code           # Auto-fix code quality issues
make lint              # Run full code quality check
make coverage          # Check coverage impact

# Manual test recovery
pytest tests/unit/ --maxfail=5 -x  # Run tests with fast failure
pytest tests/unit/ -k "not slow"   # Exclude slow tests
pytest --cov=src --cov-report=term-missing  # Identify uncovered code
```

### Environment Recovery
```bash
# Environment issues
make clean                    # Clean Docker resources
make status                   # Check project status

# Docker environment recovery
docker-compose down -v        # Stop and remove volumes
docker-compose up -d          # Fresh start
docker-compose logs -f app    # Check startup issues
```

### Code Quality Recovery
```bash
# Quality issues
make fix-code               # Auto-fix most issues
make format                 # Format all code
make lint                  # Identify remaining issues

# Import and dependency issues
pip install --upgrade pip   # Update pip
pip install -e ".[dev]"     # Reinstall development dependencies
```

## ðŸ¤– è‡ªåŠ¨åŒ–è„šæœ¬å·¥å…·

### å¿«é€Ÿä¼˜åŒ–è„šæœ¬
```bash
./quick_optimize.sh     # å¿«é€Ÿä¼˜åŒ–ä»£ç è´¨é‡ (ä¸€é”®ä¿®å¤æ‰€æœ‰é—®é¢˜)
```

### ç»´æŠ¤è„šæœ¬ (scripts/)
```bash
# æ•°æ®åº“ç®¡ç†
scripts/backup_db.sh     # å¤‡ä»½æ•°æ®åº“
scripts/restore_db.sh    # æ¢å¤æ•°æ®åº“
scripts/db-migrate.sh    # è¿è¡Œæ•°æ®åº“è¿ç§»

# è´¨é‡ä¿è¯
scripts/quality/intelligent_quality_analyzer.py        # æ™ºèƒ½è´¨é‡åˆ†æž
scripts/quality/continuous_improvement_engine.py      # æŒç»­æ”¹è¿›å¼•æ“Ž
scripts/maintenance/scheduled_maintenance.py         # å®šæœŸç»´æŠ¤
scripts/maintenance/coverage_trend_analyzer.py        # è¦†ç›–çŽ‡è¶‹åŠ¿åˆ†æž

# éƒ¨ç½²å’ŒéªŒè¯
scripts/deploy.sh         # éƒ¨ç½²è„šæœ¬
scripts/deploy_verify.sh  # éƒ¨ç½²éªŒè¯
scripts/security_check.sh # å®‰å…¨æ£€æŸ¥

# ç›‘æŽ§å’Œæ—¥å¿—
scripts/start_monitoring.sh # å¯åŠ¨ç›‘æŽ§ç³»ç»Ÿ
```

### GitHub Actions CI/CD å·¥ä½œæµ
```yaml
# .github/workflows/
â”œâ”€â”€ ci_pipeline_v2.yml         # CI/CDæµæ°´çº¿
â”œâ”€â”€ production-deploy.yml      # ç”Ÿäº§éƒ¨ç½²
â”œâ”€â”€ smart-fixer-ci.yml          # æ™ºèƒ½ä¿®å¤CI
â”œâ”€â”€ docs.yml                    # æ–‡æ¡£æž„å»º
â”œâ”€â”€ branch-protection.yml       # åˆ†æ”¯ä¿æŠ¤
â”œâ”€â”€ issues-cleanup.yml         # Issueæ¸…ç†
â”œâ”€â”€ ai-feedback.yml            # AIåé¦ˆ
â””â”€â”€ deploy.yml                  # éƒ¨ç½²æµç¨‹
```

### CI/CD æµæ°´çº¿ç‰¹æ€§
- **è‡ªåŠ¨åŒ–æµ‹è¯•**: 4597ä¸ªæµ‹è¯•å‡½æ•°è‡ªåŠ¨æ‰§è¡Œ
- **ä»£ç è´¨é‡æ£€æŸ¥**: Ruff + MyPy + Bandit ä¸‰é‡æ£€æŸ¥
- **å®‰å…¨æ‰«æ**: ä¾èµ–æ¼æ´žæ£€æµ‹å’Œä»£ç å®‰å…¨å®¡è®¡
- **è¦†ç›–çŽ‡é—¨æ§›**: 31%è¦†ç›–çŽ‡åˆšæ€§è¦æ±‚
- **æ™ºèƒ½ä¿®å¤**: è‡ªåŠ¨ä¿®å¤å¸¸è§ä»£ç é—®é¢˜
- **éƒ¨ç½²éªŒè¯**: ç”Ÿäº§éƒ¨ç½²å‰å®Œæ•´æ€§æ£€æŸ¥
- **çŽ¯å¢ƒæ¸…ç†**: å®šæœŸæ¸…ç†ä¸´æ—¶èµ„æºå’Œè¿‡æœŸæ•°æ®

## ðŸ”„ Git Workflow

### Commit Message Format
```bash
# Features
feat(api): add user authentication endpoint
feat(ml): implement XGBoost prediction model

# Fixes
fix(database): resolve async connection timeout issue
fix(tests): restore 100+ core test functionality

# Quality
refactor(api): extract validation logic to service layer
style(core): apply ruff formatting to all files

# Maintenance
chore(deps): update FastAPI to 0.121.2
chore(security): upgrade MLflow to 2.22.2 for security patches
```

### Pre-Commit Checklist
- [ ] Tests pass: `make test`
- [ ] Code quality: `make fix-code`
- [ ] Security check: `make security-check`
- [ ] Coverage maintained: `make coverage`
- [ ] Full validation: `make lint && make test`

## ðŸ“Š Current Project Status

### Quality Metrics
- **Test Coverage**: Use `make test.unit --cov=src --cov-report=term-missing`
- **Test Cases**: 4597 test functions across 274 test files (unit/integration/e2e)
- **Code Quality**: Ruff + Black + Bandit validation passing
- **Security**: No critical vulnerabilities, ECDSA vulnerability patched
- **CI/CD**: Green pipeline with automated recovery

### Health Score
```
Overall Health: 85/100 âœ…
â”œâ”€â”€ Code Quality: 90/100 âœ…
â”œâ”€â”€ Testing: 70/100 âš ï¸
â”œâ”€â”€ Documentation: 95/100 âœ…
â”œâ”€â”€ Security: 95/100 âœ…
â”œâ”€â”€ CI/CD: 90/100 âœ…
â””â”€â”€ Dependencies: 90/100 âœ…
```

## ðŸŽ¨ Frontend Architecture

### React + TypeScript Stack
- **React 19.2.0**: Modern React with concurrent features
- **TypeScript 4.9.5**: Full type safety with strict mode
- **Ant Design 5.27.6**: Enterprise-grade component library
- **Redux Toolkit 2.9.2**: State management with RTK Query
- **React Query**: Server state management and caching
- **Vite**: Fast build tool with HMR

### Frontend Development Commands
```bash
# Frontend development (åœ¨ frontend/ ç›®å½•ä¸­)
cd frontend
npm install              # å®‰è£…ä¾èµ–
npm start               # å¯åŠ¨å¼€å‘æœåŠ¡å™¨ (port 3000)
npm run build           # ç”Ÿäº§æž„å»º
npm test                # è¿è¡Œå‰ç«¯æµ‹è¯•
```

### Frontend Project Structure
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/     # å¯é‡ç”¨UIç»„ä»¶
â”‚   â”œâ”€â”€ pages/         # é¡µé¢ç»„ä»¶
â”‚   â”œâ”€â”€ hooks/         # è‡ªå®šä¹‰React hooks
â”‚   â”œâ”€â”€ store/         # Redux storeé…ç½®
â”‚   â”œâ”€â”€ services/      # APIæœåŠ¡å‡½æ•°
â”‚   â”œâ”€â”€ types/         # TypeScriptç±»åž‹å®šä¹‰
â”‚   â”œâ”€â”€ utils/         # å‰ç«¯å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ styles/        # CSSå’Œæ ·å¼
â”œâ”€â”€ public/            # é™æ€èµ„æº
â””â”€â”€ tests/             # å‰ç«¯æµ‹è¯•æ–‡ä»¶
```

### Frontend State Management
```typescript
// Redux Toolkit store configuration
import { configureStore } from '@reduxjs/toolkit'
import { predictionApi } from './services/predictionApi'

export const store = configureStore({
  reducer: {
    [predictionApi.reducerPath]: predictionApi.reducer,
  },
  middleware: (getDefaultMiddleware) =>
    getDefaultMiddleware().concat(predictionApi.middleware),
})
```

### å‰ç«¯å¼€å‘çŽ¯å¢ƒè®¿é—®
- **Frontend Dev Server**: http://localhost:3000 (Viteå¼€å‘æœåŠ¡å™¨)
- **Backend API**: http://localhost:8000 (FastAPIåº”ç”¨)
- **API Documentation**: http://localhost:8000/docs (äº¤äº’å¼OpenAPI)
- **Frontend in Production**: http://localhost (é€šè¿‡nginxåå‘ä»£ç†)

## ðŸ¤– AI Assistant Configuration

### Claude Code Integration
This project is AI-first maintained with these configurations:

#### Development Workflow
1. **Environment Setup**: `make dev` - Start development environment
2. **Development**: Write code following DDD + CQRS patterns
3. **Quality Validation**: `make lint && make test` - Code quality and testing
4. **Security Check**: `make security-check` - Security scanning
5. **Pre-commit**: `make fix-code && make format` - Code cleanup and validation

#### AI Tool Guidelines
- **Architecture Priority**: Maintain DDD layer separation and CQRS patterns
- **Testing First**: Write tests before implementation (TDD approach)
- **Async Everywhere**: All I/O operations must be async (database, APIs)
- **Type Safety**: Complete type annotations required for all functions
- **Error Handling**: Comprehensive exception handling with proper logging
- **Security First**: Never expose secrets, validate all inputs

#### Preferred Patterns
```python
# âœ… Preferred: Service layer with dependency injection
async def get_prediction_use_case(
    match_id: int,
    prediction_service: PredictionService,
    prediction_repo: PredictionRepository
) -> Dict[str, Any]:
    prediction = await prediction_service.generate_prediction(match_id)
    await prediction_repo.save_prediction(prediction)
    return prediction

# âŒ Avoid: Direct database access in API layer
@app.get("/predictions/{match_id}")
async def get_prediction(match_id: int, db: AsyncSession):
    # Business logic should be in service layer
    result = await db.execute(select(Prediction).where(Prediction.match_id == match_id))
    return result.scalar_one_or_none()
```

## ðŸ“Š ç›‘æŽ§å’Œè¿ç»´

### ç”Ÿäº§çŽ¯å¢ƒç›‘æŽ§æ ˆ
- **Prometheus**: æŒ‡æ ‡æ”¶é›†å’Œå­˜å‚¨ (port: 9090)
- **Grafana**: å¯è§†åŒ–ä»ªè¡¨æ¿ (port: 3000)
- **Loki**: æ—¥å¿—èšåˆ (port: 3100)
- **å¥åº·æ£€æŸ¥**: å¤šå±‚æ¬¡å¥åº·ç›‘æµ‹

### ç›‘æŽ§å‘½ä»¤
```bash
# å®¹å™¨ç›‘æŽ§
make monitor              # å®žæ—¶ç›‘æŽ§åº”ç”¨èµ„æºä½¿ç”¨
make monitor-all          # ç›‘æŽ§æ‰€æœ‰å®¹å™¨èµ„æºä½¿ç”¨

# æ—¥å¿—æŸ¥çœ‹
make logs                 # æŸ¥çœ‹åº”ç”¨æ—¥å¿—
make logs-db             # æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
make logs-redis          # æŸ¥çœ‹Redisæ—¥å¿—

# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health               # åº”ç”¨å¥åº·æ£€æŸ¥
curl http://localhost:8000/health/system          # ç³»ç»Ÿå¥åº·æ£€æŸ¥
curl http://localhost:8000/health/database       # æ•°æ®åº“å¥åº·æ£€æŸ¥
curl http://localhost:8000/api/v1/health/inference # æŽ¨ç†æœåŠ¡å¥åº·æ£€æŸ¥
```

### æ€§èƒ½ç›‘æŽ§
```bash
# Prometheus æŒ‡æ ‡è®¿é—®
curl http://localhost:9090/metrics              # PrometheusæŒ‡æ ‡
curl http://localhost:8000/metrics               # åº”ç”¨æŒ‡æ ‡

# ç³»ç»Ÿèµ„æºç›‘æŽ§
docker stats                                     # æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker-compose ps                               # æ£€æŸ¥æœåŠ¡çŠ¶æ€
```

### è´¨é‡ä¿è¯
- **æµ‹è¯•è¦†ç›–çŽ‡**: 31% CIé—¨æ§›è¦æ±‚
- **ä»£ç è´¨é‡**: Ruff + MyPy + Bandit ä¸‰é‡æ£€æŸ¥
- **å®‰å…¨æ‰«æ**: å®šæœŸå®‰å…¨å®¡è®¡å’Œæ¼æ´žä¿®å¤
- **æ€§èƒ½ç›‘æŽ§**: å®žæ—¶æ€§èƒ½æŒ‡æ ‡å’Œè¶‹åŠ¿åˆ†æž

## ðŸŒ Application URLs

### Development Access
- **Frontend**: http://localhost:3000 (React development server)
- **Backend API**: http://localhost:8000 (FastAPI application)
- **API Documentation**: http://localhost:8000/docs (Interactive OpenAPI)
- **Health Check**: http://localhost:8000/health
- **System Status**: http://localhost:8000/system/status
- **Inference Service**: http://localhost:8000/api/v1/health/inference
- **WebSocket**: ws://localhost:8000/api/v1/realtime/ws
- **MLflow UI**: http://localhost:5000 (ML experiment tracking)

### Production Monitoring Access
- **Grafana Dashboard**: http://localhost:3000 (ç›‘æŽ§ä»ªè¡¨æ¿)
- **Prometheus**: http://localhost:9090 (æŒ‡æ ‡å­˜å‚¨)
- **Loki**: http://localhost:3100 (æ—¥å¿—èšåˆ)
- **Frontend Production**: http://localhost (nginxåå‘ä»£ç†)

### Quality Dashboard
- **Quality Monitor**: http://localhost:3001 (Independent quality monitoring)

## ðŸš€ Quick Start for New Development

### Environment Prerequisites
```bash
# ç¡®ä¿ä»¥ä¸‹å·¥å…·å·²å®‰è£…
docker --version
docker-compose --version
python3 --version  # Python 3.10+
make --version
```

### 5-Minute Setup
```bash
# 1. Environment initialization
make dev                    # å¯åŠ¨å®Œæ•´å¼€å‘çŽ¯å¢ƒ

# 2. Validate setup
make test && make lint      # éªŒè¯çŽ¯å¢ƒå’Œä»£ç è´¨é‡

# 3. Access services
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000/docs
# Database: make db-shell
```

### Quick Development Commands
```bash
# å¿«é€Ÿå¯åŠ¨å®Œæ•´å¼€å‘çŽ¯å¢ƒ (æŽ¨è)
make dev

# å¯åŠ¨ç”Ÿäº§çŽ¯å¢ƒ (å¸¦ç›‘æŽ§)
make prod

# ä»£ç è´¨é‡å¿«é€Ÿä¿®å¤
./quick_optimize.sh

# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡çŠ¶æ€
make status

# åœæ­¢æ‰€æœ‰æœåŠ¡
make down
```

### First Development Tasks
1. Read `src/main.py` to understand the application structure
2. Review `pyproject.toml` for dependencies and tool configurations
3. Check `Makefile` for available development commands
4. Run `make test.smart` to verify the testing environment
5. Access API documentation at http://localhost:8000/docs

## ðŸ” Common Development Patterns

### Database Operations (Async Only)
```python
# âœ… Correct: Async database operations
from sqlalchemy.ext.asyncio import AsyncSession

async def get_user(db: AsyncSession, user_id: int) -> Optional[User]:
    stmt = select(User).where(User.id == user_id)
    result = await db.execute(stmt)
    return result.scalar_one_or_none()

# âŒ Wrong: Sync database operations
user = db.query(User).filter(User.id == user_id).first()
```

### API Response Patterns
```python
from src.api.schemas import PredictionResponse

@app.get("/api/v1/predictions/{match_id}")
async def get_prediction(match_id: int) -> PredictionResponse:
    try:
        prediction = await inference_service.predict_match(match_id)
        return PredictionResponse(success=True, data=prediction)
    except Exception as e:
        logger.error(f"Prediction failed: {e}")
        raise HTTPException(status_code=500, detail="Prediction service unavailable")
```

### Service Layer Integration
```python
# Service injection pattern
from src.services.prediction import PredictionService
from src.database.repositories import PredictionRepository

async def get_prediction_use_case(
    match_id: int,
    prediction_service: PredictionService,
    prediction_repo: PredictionRepository
) -> Dict[str, Any]:
    # Use case orchestration
    prediction = await prediction_service.generate_prediction(match_id)
    await prediction_repo.save_prediction(prediction)
    return prediction
```

## ðŸ”— API Usage Patterns

### Standard API Response Format
```python
from src.api.schemas import PredictionResponse

# Standard success response
{
    "success": True,
    "data": {...},
    "message": "Operation completed successfully",
    "timestamp": "2025-01-01T00:00:00Z"
}

# Error response format
{
    "success": False,
    "error": {
        "code": "VALIDATION_ERROR",
        "message": "Invalid input parameters",
        "details": {...}
    },
    "timestamp": "2025-01-01T00:00:00Z"
}
```

### Common API Endpoints Usage
```python
# Health checks
GET /health                    # Basic health check
GET /health/system             # System health (CPU, memory)
GET /health/database           # Database connectivity

# Predictions API (v1 and v2)
GET /api/v1/predictions/{match_id}              # Single match prediction
POST /api/v1/predictions/batch                  # Batch predictions
GET /api/v2/predictions/{match_id}/analysis      # Enhanced prediction with analysis
GET /predictions/{match_id}                     # Direct prediction endpoint

# Data management
GET /api/v1/data_management/teams               # Get all teams
POST /api/v1/data_management/matches/sync       # Sync match data
GET /api/v1/data_management/leagues/{id}/table  # League table

# System management
GET /api/v1/system/status                       # System status
POST /api/v1/system/cache/clear                 # Clear cache
GET /api/v1/system/metrics                      # Performance metrics

# Adapters and external integrations
GET /api/v1/adapters/{service}/status           # External service status
POST /api/v1/adapters/{service}/sync            # Sync external data

# Monitoring and metrics
GET /metrics                                    # Prometheus metrics
GET /api/v1/monitoring/health                   # Application health monitoring
```

### WebSocket Real-time Communication
```python
# WebSocket connection for real-time updates
import asyncio
import json
import websockets

async def handle_realtime_updates():
    uri = "ws://localhost:8000/api/v1/realtime/ws"
    async with websockets.connect(uri) as websocket:
        async for message in websocket:
            data = json.loads(message)

            if data['type'] == 'prediction_update':
                # Handle real-time prediction updates
                await handle_prediction_update(data['payload'])
            elif data['type'] == 'match_status':
                # Handle match status changes
                await handle_match_status_change(data['payload'])
            elif data['type'] == 'system_metrics':
                # Handle system monitoring data
                await handle_system_metrics(data['payload'])

# Client usage example
import websocket

def on_message(ws, message):
    data = json.loads(message)
    if data['type'] == 'prediction_update':
        handle_prediction_update(data['payload'])

ws = websocket.WebSocketApp(
    "ws://localhost:8000/api/v1/realtime/ws",
    on_message=on_message
)
ws.run_forever()
```

## ðŸ“ž Troubleshooting Guide

### Common Issues
1. **Test Failures**: Run `make solve-test-crisis` immediately
2. **Type Errors**: Check imports and add missing type hints
3. **Database Issues**: Verify connection string and PostgreSQL status
4. **Redis Issues**: Check Redis service status and connection
5. **Import Errors**: Run `make fix-imports` to resolve import problems
6. **Port Conflicts**: Check if ports 8000, 3000, 5432, 6379 are available

### Environment Debugging
```bash
# Check service status
docker-compose ps                    # All containers status
docker-compose logs app              # Application logs
docker-compose logs db               # Database logs
docker-compose logs redis            # Redis logs

# Database debugging
make db-shell                        # Connect to PostgreSQL
\dt                                  # List tables
SELECT COUNT(*) FROM matches;        # Verify data

# Redis debugging
make redis-shell                     # Connect to Redis
KEYS *                               # List all keys
INFO memory                          # Memory usage
```

### Performance Issues
```bash
# Performance monitoring
curl http://localhost:8000/metrics   # Prometheus metrics
curl http://localhost:8000/system/status  # System status

# Load testing (if installed)
ab -n 100 -c 10 http://localhost:8000/health  # Apache bench
```

### Emergency Commands
```bash
# Complete environment reset
make clean && make test

# Health check all services
make status

# Code quality emergency
make fix-code && make format && make lint

# Database recovery
docker-compose down -v && docker-compose up -d

# Dependency issues
pip install --upgrade pip

# Test failures - quick diagnosis
pytest tests/unit/ --tb=short --maxfail=3
pytest tests/unit/ -k "critical or smoke"

# Performance issues
docker stats                    # Check container resource usage
curl http://localhost:8000/metrics  # Check application metrics
```

## ðŸ“š Additional Resources

### Documentation
- **API Documentation**: http://localhost:8000/docs (Interactive OpenAPI)
- **ReDoc**: http://localhost:8000/redoc (Alternative API docs)
- **MLflow Tracking**: http://localhost:5000 (ML experiments)
- **Coverage Report**: `htmlcov/index.html` (Test coverage visualization)

### Development Tools
- **Adminer**: http://localhost:8080 (Database admin, if enabled)
- **Redis Commander**: http://localhost:8081 (Redis admin, if enabled)
- **Prometheus**: http://localhost:9090 (Metrics, if configured)

### Key Configuration Files
- `pyproject.toml` - Python dependencies and tool configuration
- `docker-compose.*.yml` - Container orchestration
- `Makefile` - Development workflow commands
- `.env.*` - Environment configurations

---

**Remember**: This is an AI-first maintained project. Prioritize architectural integrity, code quality, and comprehensive testing. When in doubt, choose the conservative approach that preserves existing patterns and maintains the green CI pipeline.

## ðŸ“‹ Development Environment Reference

### Minimum Requirements
- **Python**: 3.10+ (recommended: 3.11)
- **Docker**: 20.0+ with docker-compose
- **Memory**: 4GB+ RAM for development
- **Storage**: 10GB+ free disk space

### Service Ports
- **Backend API**: http://localhost:8000
- **Frontend**: http://localhost:3000
- **PostgreSQL**: localhost:5432
- **Redis**: localhost:6379
- **API Docs**: http://localhost:8000/docs

### Key File Locations
- **Main App**: `src/main.py` - FastAPI application entry point
- **Config**: `pyproject.toml` - Dependencies and tool configuration
- **Docker**: `docker-compose.yml` - Development environment
- **Makefile**: Development commands and workflows
- **Tests**: `tests/` - 4597 test functions across 274 test files (unit/integration/e2e)

*Last Updated: 2025-11-25 | AI Maintainer: Claude Code | Version: 1.3*