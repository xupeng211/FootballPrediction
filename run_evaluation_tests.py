#!/usr/bin/env python3
"""
è¯„ä¼°æ¨¡å—æµ‹è¯•è¿è¡Œå™¨
è¿è¡Œæ‰€æœ‰è¯„ä¼°æ¨¡å—çš„æ ¸å¿ƒæµ‹è¯•ï¼Œé¿å…pytestä¾èµ–é—®é¢˜
"""

import sys
import traceback
import importlib
from pathlib import Path

def test_module(module_name, tests):
    """æµ‹è¯•ä¸€ä¸ªæ¨¡å—"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•æ¨¡å—: {module_name}")
    print(f"{'='*60}")

    passed = 0
    failed = 0

    for test_name, test_func in tests.items():
        try:
            print(f"è¿è¡Œ {test_name}...", end=" ")
            test_func()
            print("âœ… PASSED")
            passed += 1
        except Exception as e:
            print(f"âŒ FAILED: {e}")
            failed += 1
            traceback.print_exc()

    return passed, failed

def test_metrics():
    """æµ‹è¯•æŒ‡æ ‡æ¨¡å—"""
    from src.evaluation.metrics import Metrics
    import numpy as np

    np.random.seed(42)
    n_samples = 100

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    y_true = np.random.randint(0, 3, n_samples)
    y_pred = np.random.randint(0, 3, n_samples)
    y_proba = np.random.dirichlet([1, 1, 1], n_samples)
    odds = np.random.uniform(1.5, 5.0, (n_samples, 3))

    metrics = Metrics()

    # æµ‹è¯•åˆ†ç±»æŒ‡æ ‡
    result = metrics.classification_metrics(y_true, y_pred, y_proba)
    assert "accuracy" in result
    assert "f1_weighted" in result

    # æµ‹è¯•å®Œæ•´è¯„ä¼°
    result = metrics.evaluate_all(y_true, y_pred, y_proba, odds)
    assert hasattr(result, 'metrics')
    assert hasattr(result, 'metadata')
    assert result.metadata["n_samples"] == n_samples

def test_calibration():
    """æµ‹è¯•æ ¡å‡†æ¨¡å—"""
    from src.evaluation.calibration import IsotonicCalibrator, AutoCalibrator
    import numpy as np

    np.random.seed(42)
    n_samples = 50

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    y_true = np.random.randint(0, 3, n_samples)
    y_proba = np.random.dirichlet([1, 1, 1], n_samples)

    # æµ‹è¯•Isotonicæ ¡å‡†
    calibrator = IsotonicCalibrator(n_classes=3)

    # è®­ç»ƒ
    fitted = calibrator.fit(y_true, y_proba)
    assert fitted is calibrator
    assert calibrator.is_fitted is True

    # é¢„æµ‹
    calibrated_proba = calibrator.transform(y_proba)
    assert calibrated_proba.shape == y_proba.shape

    # éªŒè¯æ¦‚ç‡å’Œä¸º1
    prob_sums = calibrated_proba.sum(axis=1)
    np.testing.assert_allclose(prob_sums, 1.0, rtol=1e-5)

    # æµ‹è¯•è‡ªåŠ¨æ ¡å‡†
    auto_calibrator = AutoCalibrator(n_classes=3)
    result = auto_calibrator.calibrate(y_true, y_proba)
    assert hasattr(result, 'is_calibrated')

def test_backtest():
    """æµ‹è¯•å›æµ‹æ¨¡å—"""
    from src.evaluation.backtest import (
        Backtester, FlatStakingStrategy, KellyStakingStrategy,
        PercentageStakingStrategy, ValueBettingStrategy
    )
    import numpy as np
    import pandas as pd

    np.random.seed(42)
    n_samples = 50

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    predictions = pd.DataFrame({
        'prob_H': np.random.uniform(0.2, 0.7, n_samples),
        'prob_D': np.random.uniform(0.1, 0.4, n_samples),
        'prob_A': np.random.uniform(0.1, 0.5, n_samples),
        'predicted_class': np.random.randint(0, 3, n_samples),
        'actual_result': np.random.randint(0, 3, n_samples),
    })

    # å½’ä¸€åŒ–æ¦‚ç‡
    prob_cols = ['prob_H', 'prob_D', 'prob_A']
    predictions[prob_cols] = predictions[prob_cols].div(
        predictions[prob_cols].sum(axis=1), axis=0
    )

    odds = pd.DataFrame({
        'odds_H': np.random.uniform(1.8, 4.0, n_samples),
        'odds_D': np.random.uniform(2.8, 4.5, n_samples),
        'odds_A': np.random.uniform(2.5, 6.0, n_samples)
    })

    # æµ‹è¯•Backtester
    backtester = Backtester(initial_bankroll=1000.0)

    # æµ‹è¯•å›ºå®šæŠ•æ³¨ç­–ç•¥
    flat_strategy = FlatStakingStrategy(stake_amount=10.0)
    result = backtester.simulate(predictions, odds, flat_strategy)

    assert result.initial_bankroll == 1000.0
    assert result.total_bets >= 0
    assert len(result.equity_curve) >= 1

    # æµ‹è¯•å‡¯åˆ©ç­–ç•¥
    kelly_strategy = KellyStakingStrategy(kelly_fraction=0.25)
    result_kelly = backtester.simulate(predictions, odds, kelly_strategy)

    # æµ‹è¯•ç™¾åˆ†æ¯”æŠ•æ³¨ç­–ç•¥
    percent_strategy = PercentageStakingStrategy(percentage=0.02)
    result_percent = backtester.simulate(predictions, odds, percent_strategy)

    # æµ‹è¯•ä»·å€¼æŠ•æ³¨ç­–ç•¥
    value_strategy = ValueBettingStrategy(min_ev_threshold=0.05)
    result_value = backtester.simulate(predictions, odds, value_strategy)

def test_visualizer():
    """æµ‹è¯•å¯è§†åŒ–æ¨¡å—"""
    from src.evaluation.visualizer import EvaluationVisualizer
    import numpy as np

    np.random.seed(42)
    n_samples = 50

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    y_true = np.random.randint(0, 3, n_samples)
    y_pred = y_true.copy()

    # æ·»åŠ ä¸€äº›é”™è¯¯é¢„æµ‹
    error_indices = np.random.choice(n_samples, size=int(n_samples * 0.3), replace=False)
    y_pred[error_indices] = np.random.randint(0, 3, len(error_indices))

    # ç”Ÿæˆæ¦‚ç‡çŸ©é˜µ
    y_proba = np.random.dirichlet([1, 1, 1], n_samples)
    for i, pred in enumerate(y_pred):
        y_proba[i, pred] = max(y_proba[i, pred], 0.4)
        y_proba[i] = y_proba[i] / y_proba[i].sum()

    visualizer = EvaluationVisualizer()

    # æµ‹è¯•é¢„æµ‹åˆ†å¸ƒå›¾
    try:
        import matplotlib
        matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’åç«¯
        import matplotlib.pyplot as plt

        # æµ‹è¯•ä¿å­˜å›¾è¡¨åŠŸèƒ½
        fig = plt.figure()
        ax = fig.add_subplot(111)
        ax.plot([1, 2, 3], [1, 2, 3])

        saved_paths = visualizer.save_figure(fig, "test_plot", ['png'])
        assert len(saved_paths) == 1

        plt.close(fig)
        print("å¯è§†åŒ–æµ‹è¯•é€šè¿‡ï¼ˆmatplotlibå¯ç”¨ï¼‰")
    except ImportError:
        print("å¯è§†åŒ–æµ‹è¯•è·³è¿‡ï¼ˆmatplotlibä¸å¯ç”¨ï¼‰")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹è¿è¡Œè¯„ä¼°æ¨¡å—æµ‹è¯•...")

    # æµ‹è¯•å¥—ä»¶
    test_suites = {
        "metrics": {
            "test_classification_metrics": test_metrics,
        },
        "calibration": {
            "test_isotonic_calibration": test_calibration,
        },
        "backtest": {
            "test_backtest_strategies": test_backtest,
        },
        "visualizer": {
            "test_visualization": test_visualizer,
        }
    }

    total_passed = 0
    total_failed = 0

    for module_name, tests in test_suites.items():
        passed, failed = test_module(module_name, tests)
        total_passed += passed
        total_failed += failed

    print(f"\n{'='*60}")
    print("æµ‹è¯•æ€»ç»“")
    print(f"{'='*60}")
    print(f"æ€»é€šè¿‡: {total_passed}")
    print(f"æ€»å¤±è´¥: {total_failed}")
    print(f"æ€»è®¡: {total_passed + total_failed}")

    if total_failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("âŒ å­˜åœ¨æµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    sys.exit(main())