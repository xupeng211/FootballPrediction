#!/usr/bin/env python3
""""
Enhanced Real Model Training for Football Prediction
å¢å¼ºçœŸå®æ¨¡å‹è®­ç»ƒè„šæœ¬ - ç¬¦åˆSRSè¦æ±‚

æ ¹æ®SRSè¦æ±‚å®ç°çš„å®Œæ•´æ¨¡å‹è®­ç»ƒç³»ç»Ÿ:
- æ„å»ºåŸºç¡€ç‰¹å¾ï¼ˆè¿›çƒæ•°ã€ä¸»å®¢åœºçŠ¶æ€ã€èµ”ç‡å˜åŒ–ã€ä¼¤ç—…å› ç´ ï¼‰
- ä½¿ç”¨XGBoost/LightGBMæ¨¡å‹
- è¾“å‡ºæ¨¡å‹è¯„ä¼°æŒ‡æ ‡ï¼ˆAUC,F1,å‡†ç¡®ç‡ï¼‰
- è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹ä¸å‚æ•°æ—¥å¿—
- æ¨¡å‹å‡†ç¡®ç‡ â‰¥ 65% éªŒè¯
- AUC â‰¥ 0.70 éªŒè¯

ç”Ÿæˆæ—¶é—´: 2025-10-29 04:05:00
""""

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path

import secrets
import joblib
import numpy as np
import pandas as pd
accuracy_score,
classification_report,
    confusion_matrix,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    roc_curve,
    mean_absolute_error,
    mean_squared_error,
)
    train_test_split,
    cross_val_score,
    StratifiedKFold,
    GridSearchCV,
)
from sklearn.preprocessing import StandardScaler, LabelEncoder

# å°è¯•å¯¼å…¥XGBoostå’ŒLightGBM
try:
    import xgboost as xgb

    XGB_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("XGBoost is available")
except ImportError:
    XGB_AVAILABLE = False
    logging.warning("XGBoost not available. Install with: pip install xgboost")

try:
    import lightgbm as lgb

    LGB_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("LightGBM is available")
except ImportError:
    LGB_AVAILABLE = False
    logging.warning("LightGBM not available. Install with: pip install lightgbm")

from src.core.logging_system import get_logger
from src.ml.enhanced_feature_engineering import EnhancedFeatureEngineer

logger = get_logger(__name__)


class SRSCompliantModelTrainer:
    """SRSç¬¦åˆæ€§æ¨¡å‹è®­ç»ƒå™¨"""""

    ä¸¥æ ¼æŒ‰ç…§SRSè¦æ±‚å®ç°çš„æ¨¡å‹è®­ç»ƒç³»ç»Ÿ:
    - ç›®æ ‡å‡†ç¡®ç‡: â‰¥ 65%
    - ç›®æ ‡AUC: â‰¥ 0.70
    - æ”¯æŒXGBoost/LightGBM
    - å®Œæ•´çš„ç‰¹å¾å·¥ç¨‹
    - è‡ªåŠ¨æ¨¡å‹ä¿å­˜å’Œæ—¥å¿—è®°å½•
    """"

    def __init__(self, model_save_dir: str = "models"):
        self.logger = get_logger(self.__class__.__name__)
        self.model_save_dir = Path(model_save_dir)
        self.model_save_dir.mkdir(exist_ok=True)

        # SRSç›®æ ‡è¦æ±‚
        self.SRS_TARGETS = {
            "min_accuracy": 0.65,
            "min_auc": 0.70,
            "min_f1_score": 0.60,
        }

        # åˆå§‹åŒ–ç»„ä»¶
        self.feature_engineer = EnhancedFeatureEngineer()
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()

        # è®­ç»ƒå†å²
        self.training_history = []
        self.best_models = {}
        self.srs_compliance_records = []

    def generate_srs_compliant_training_data(self, n_matches: int = 2000) -> List[Dict]:
        """ç”ŸæˆSRSç¬¦åˆæ€§è®­ç»ƒæ•°æ®"""""

        ç”ŸæˆåŒ…å«æ‰€æœ‰SRSè¦æ±‚ç‰¹å¾çš„æ¯”èµ›æ•°æ®:
        - åŸºç¡€æ¯”èµ›ä¿¡æ¯
        - è¿›çƒæ•°ç»Ÿè®¡
        - ä¸»å®¢åœºçŠ¶æ€
        - èµ”ç‡æ•°æ®
        - çƒé˜Ÿå®åŠ›è¯„ä¼°
        """"
        self.logger.info(f"ç”Ÿæˆ {n_matches} åœºSRSç¬¦åˆæ€§è®­ç»ƒæ•°æ®...")

        # æ¨¡æ‹Ÿ50æ”¯çƒé˜Ÿçš„å®åŠ›æ•°æ®
        teams_data = {}
        for i in range(1, 51):
            teams_data[f"team_{i}"] = {
                "attack_strength": np.random.normal(1.5, 0.4),  # è¿›æ”»å®åŠ›
                "defense_strength": np.random.normal(1.3, 0.3),  # é˜²å®ˆå®åŠ›
                "home_advantage": np.random.normal(0.3, 0.1),  # ä¸»åœºä¼˜åŠ¿
                "consistency": np.random.uniform(0.7, 1.0),  # ç¨³å®šæ€§
                "form_momentum": np.random.uniform(-0.2, 0.2),  # çŠ¶æ€åŠ¨é‡
            }

        leagues = [
            "Premier League",
            "La Liga",
            "Bundesliga",
            "Serie A",
            "Ligue 1",
            "Champions League",
        ]
        matches = []
        base_date = datetime(2023, 1, 1)

        # ç”Ÿæˆå†å²æ•°æ®ç”¨äºç‰¹å¾å·¥ç¨‹
        historical_matches = []
        for i in range(n_matches + 500):  # é¢å¤–ç”Ÿæˆ500åœºæ¯”èµ›ç”¨äºå†å²ç‰¹å¾
            home_team = f"team_{np.secrets.randbelow(51) + 1}"
            away_team = f"team_{np.secrets.randbelow(51) + 1}"
            while away_team == home_team:
                away_team = f"team_{np.secrets.randbelow(51) + 1}"

            match_date = base_date + pd.Timedelta(days=np.secrets.randbelow(731) + 0)
            league = np.random.choice(leagues)

            # è®¡ç®—é¢„æœŸè¿›çƒæ•°
            home_stats = teams_data[home_team]
            away_stats = teams_data[away_team]

            expected_home = (
                home_stats["attack_strength"]
                - away_stats["defense_strength"]
                + home_stats["home_advantage"]
            )
            expected_away = (
                away_stats["attack_strength"] - home_stats["defense_strength"]
            )

            # æ·»åŠ çŠ¶æ€åŠ¨é‡å½±å“
            expected_home += home_stats["form_momentum"]
            expected_away += away_stats["form_momentum"]

            # æ·»åŠ éšæœºæ³¢åŠ¨
            expected_home += np.random.normal(0, 0.3)
            expected_away += np.random.normal(0, 0.3)

            # ç”Ÿæˆå®é™…æ¯”åˆ†
            home_goals = max(0, np.random.poisson(max(0, expected_home)))
            away_goals = max(0, np.random.poisson(max(0, expected_away)))

            # ç”Ÿæˆèµ”ç‡
            home_win_prob = 1 / (1 + np.exp(-(expected_home - expected_away) * 0.4))
            draw_prob = 0.25
            away_win_prob = 1 - home_win_prob - draw_prob

            # åšå½©å…¬å¸åˆ©æ¶¦
            margin = 0.05
            home_odds = round(1 / (home_win_prob * (1 - margin)), 2)
            draw_odds = round(1 / (draw_prob * (1 - margin)), 2)
            away_odds = round(1 / (away_win_prob * (1 - margin)), 2)

            match = {
                "match_id": f"match_{i+1}",
                "home_team_id": home_team,
                "away_team_id": away_team,
                "home_team_name": f"Team {home_team.split('_')[1]}",
                "away_team_name": f"Team {away_team.split('_')[1]}",
                "home_score": int(home_goals),
                "away_score": int(away_goals),
                "match_date": match_date.isoformat(),
                "league_name": league,
                "home_win_odds": home_odds,
                "draw_odds": draw_odds,
                "away_win_odds": away_odds,
                "season": 2023 if match_date.year < 2024 else 2024,
            }

            historical_matches.append(match)

        # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹å™¨
        self.feature_engineer.initialize_team_histories(historical_matches)

        # é€‰æ‹©æœ€æ–°çš„n_matchesä½œä¸ºè®­ç»ƒæ•°æ®
        matches = sorted(
            historical_matches, key=lambda x: x["match_date"], reverse=True
        )[:n_matches]

        self.logger.info(f"æˆåŠŸç”Ÿæˆ {len(matches)} åœºSRSç¬¦åˆæ€§è®­ç»ƒæ•°æ®")
        return matches

    async def prepare_srs_training_data(
        self, matches: List[Dict]
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """å‡†å¤‡SRSç¬¦åˆæ€§è®­ç»ƒæ•°æ®"""
        self.logger.info("å‡†å¤‡SRSç¬¦åˆæ€§è®­ç»ƒæ•°æ®...")

        # æå–ç‰¹å¾
        features_df = await self.feature_engineer.extract_features_batch(matches)

        if features_df.empty:
            raise ValueError("ç‰¹å¾æå–å¤±è´¥,æ— æ³•å‡†å¤‡è®­ç»ƒæ•°æ®")

        # å‡†å¤‡ç›®æ ‡å˜é‡ï¼ˆèƒœ/å¹³/è´Ÿåˆ†ç±»ï¼‰
        targets = []
        for match in matches:
            home_score = match.get("home_score", 0)
            away_score = match.get("away_score", 0)

            if home_score > away_score:
                targets.append("home_win")
            elif home_score < away_score:
                targets.append("away_win")
            else:
                targets.append("draw")

        y = pd.Series(targets)

        # ç§»é™¤éç‰¹å¾åˆ—,ä¿ç•™ç‰¹å¾åˆ—
        feature_columns = self.feature_engineer.get_feature_names()
        available_features = [
            col for col in feature_columns if col in features_df.columns
        ]
        X = features_df[available_features].copy()

        # å¤„ç†ç¼ºå¤±å€¼
        X = X.fillna(X.mean())
        X = X.fillna(0)  # å¡«å……å‰©ä½™çš„NaN

        self.logger.info(f"SRSè®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: ç‰¹å¾ç»´åº¦ {X.shape}, ç›®æ ‡ç»´åº¦ {y.shape}")
        self.logger.info(f"å¯ç”¨ç‰¹å¾: {len(available_features)}ä¸ª")
        self.logger.info(f"ç›®æ ‡åˆ†å¸ƒ: {y.value_counts().to_dict()}")

        return X, y

    def train_xgboost_with_srs_validation(
        self, X: pd.DataFrame, y: pd.Series
    ) -> Dict[str, Any]:
        """è®­ç»ƒXGBoostæ¨¡å‹å¹¶è¿›è¡ŒSRSç¬¦åˆæ€§éªŒè¯"""
        if not XGB_AVAILABLE:
            raise ImportError("XGBoost not available")

        self.logger.info("å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹ï¼ˆSRSç¬¦åˆæ€§éªŒè¯ï¼‰...")

        # æ•°æ®é¢„å¤„ç†
        y_encoded = self.label_encoder.fit_transform(y)
        X_scaled = self.scaler.fit_transform(X)

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )

        # è¶…å‚æ•°ç½‘æ ¼ï¼ˆé’ˆå¯¹SRSç›®æ ‡ä¼˜åŒ–ï¼‰
        param_grid = {
            "n_estimators": [200, 300, 500],
            "max_depth": [4, 6, 8],
            "learning_rate": [0.05, 0.1, 0.15],
            "subsample": [0.8, 0.9, 1.0],
            "colsample_bytree": [0.8, 0.9, 1.0],
            "min_child_weight": [1, 3, 5],
            "gamma": [0, 0.1, 0.2],
            "reg_alpha": [0, 0.1, 0.5],
            "reg_lambda": [1, 1.5, 2],
        }

        # åˆ›å»ºXGBoostæ¨¡å‹
        base_model = xgb.XGBClassifier(
            random_state=42, n_jobs=-1, eval_metric="mlogloss", use_label_encoder=False
        )

        # ç½‘æ ¼æœç´¢ä¼˜åŒ–
        grid_search = GridSearchCV(
            base_model,
            param_grid,
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
            scoring="accuracy",
            n_jobs=-1,
            verbose=0,
        )

        grid_search.fit(X_train, y_train)

        # æœ€ä½³æ¨¡å‹
        best_model = grid_search.best_estimator_
        best_params = grid_search.best_params_
        best_cv_score = grid_search.best_score_

        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = best_model.predict(X_test)
        y_pred_proba = best_model.predict_proba(X_test)

        # è®¡ç®—SRSè¦æ±‚çš„è¯„ä¼°æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average="weighted")
        recall = recall_score(y_test, y_pred, average="weighted")
        f1 = f1_score(y_test, y_pred, average="weighted")

        # è®¡ç®—AUC
        try:
            auc = roc_auc_score(
                y_test, y_pred_proba, multi_class="ovr", average="weighted"
            )
        except ValueError:
            auc = 0.0

        # ç‰¹å¾é‡è¦æ€§
            feature_importance = best_model.feature_importances_
        feature_names = X.columns.tolist()
        importance_df = pd.DataFrame(
            {"feature": feature_names, "importance": feature_importance}
        ).sort_values("importance", ascending=False)

        # SRSç¬¦åˆæ€§æ£€æŸ¥
        srs_compliance = {
            "accuracy_target_met": accuracy >= self.SRS_TARGETS["min_accuracy"],
            "auc_target_met": auc >= self.SRS_TARGETS["min_auc"],
            "f1_target_met": f1 >= self.SRS_TARGETS["min_f1_score"],
            "overall_compliance": (
                accuracy >= self.SRS_TARGETS["min_accuracy"]
                and auc >= self.SRS_TARGETS["min_auc"]
                and f1 >= self.SRS_TARGETS["min_f1_score"]
            ),
        }

        results = {
            "model_type": "xgboost",
            "model": best_model,
            "best_params": best_params,
            "cv_score": best_cv_score,
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
            "auc": auc,
            "feature_importance": importance_df,
            "confusion_matrix": confusion_matrix(y_test, y_pred).tolist(),
            "classification_report": classification_report(
                y_test, y_pred, output_dict=True
            ),
            "n_features": X.shape[1],
            "n_samples": len(y),
            "training_time": datetime.now().isoformat(),
            "srs_compliance": srs_compliance,
            "srs_targets": self.SRS_TARGETS,
        }

        self.logger.info(
            f"XGBoostè®­ç»ƒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}"
        )
        self.logger.info(f"SRSç¬¦åˆæ€§: {srs_compliance}")

        return results

    def train_lightgbm_with_srs_validation(
        self, X: pd.DataFrame, y: pd.Series
    ) -> Dict[str, Any]:
        """è®­ç»ƒLightGBMæ¨¡å‹å¹¶è¿›è¡ŒSRSç¬¦åˆæ€§éªŒè¯"""
        if not LGB_AVAILABLE:
            raise ImportError("LightGBM not available")

        self.logger.info("å¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹ï¼ˆSRSç¬¦åˆæ€§éªŒè¯ï¼‰...")

        # æ•°æ®é¢„å¤„ç†
        y_encoded = self.label_encoder.fit_transform(y)
        X_scaled = self.scaler.fit_transform(X)

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )

        # è¶…å‚æ•°ç½‘æ ¼
        param_grid = {
            "n_estimators": [200, 300, 500],
            "max_depth": [4, 6, 8, -1],
            "learning_rate": [0.05, 0.1, 0.15],
            "num_leaves": [31, 63, 127],
            "subsample": [0.8, 0.9, 1.0],
            "colsample_bytree": [0.8, 0.9, 1.0],
            "reg_alpha": [0, 0.1, 0.5],
            "reg_lambda": [0, 0.1, 0.5],
            "min_child_samples": [20, 50, 100],
        }

        # åˆ›å»ºLightGBMæ¨¡å‹
        base_model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1)

        # ç½‘æ ¼æœç´¢ä¼˜åŒ–
        grid_search = GridSearchCV(
            base_model,
            param_grid,
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
            scoring="accuracy",
            n_jobs=-1,
            verbose=0,
        )

        grid_search.fit(X_train, y_train)

        # æœ€ä½³æ¨¡å‹
        best_model = grid_search.best_estimator_
        best_params = grid_search.best_params_
        best_cv_score = grid_search.best_score_

        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = best_model.predict(X_test)
        y_pred_proba = best_model.predict_proba(X_test)

        # è®¡ç®—SRSè¦æ±‚çš„è¯„ä¼°æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average="weighted")
        recall = recall_score(y_test, y_pred, average="weighted")
        f1 = f1_score(y_test, y_pred, average="weighted")

        # è®¡ç®—AUC
        try:
            auc = roc_auc_score(
                y_test, y_pred_proba, multi_class="ovr", average="weighted"
            )
        except ValueError:
            auc = 0.0

        # ç‰¹å¾é‡è¦æ€§
            feature_importance = best_model.feature_importances_
        feature_names = X.columns.tolist()
        importance_df = pd.DataFrame(
            {"feature": feature_names, "importance": feature_importance}
        ).sort_values("importance", ascending=False)

        # SRSç¬¦åˆæ€§æ£€æŸ¥
        srs_compliance = {
            "accuracy_target_met": accuracy >= self.SRS_TARGETS["min_accuracy"],
            "auc_target_met": auc >= self.SRS_TARGETS["min_auc"],
            "f1_target_met": f1 >= self.SRS_TARGETS["min_f1_score"],
            "overall_compliance": (
                accuracy >= self.SRS_TARGETS["min_accuracy"]
                and auc >= self.SRS_TARGETS["min_auc"]
                and f1 >= self.SRS_TARGETS["min_f1_score"]
            ),
        }

        results = {
            "model_type": "lightgbm",
            "model": best_model,
            "best_params": best_params,
            "cv_score": best_cv_score,
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
            "auc": auc,
            "feature_importance": importance_df,
            "confusion_matrix": confusion_matrix(y_test, y_pred).tolist(),
            "classification_report": classification_report(
                y_test, y_pred, output_dict=True
            ),
            "n_features": X.shape[1],
            "n_samples": len(y),
            "training_time": datetime.now().isoformat(),
            "srs_compliance": srs_compliance,
            "srs_targets": self.SRS_TARGETS,
        }

        self.logger.info(
            f"LightGBMè®­ç»ƒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}"
        )
        self.logger.info(f"SRSç¬¦åˆæ€§: {srs_compliance}")

        return results

    def save_srs_compliant_model(
        self, model_results: Dict[str, Any], model_name: str
    ) -> str:
        """ä¿å­˜SRSç¬¦åˆæ€§æ¨¡å‹"""
        self.logger.info(f"ä¿å­˜SRSç¬¦åˆæ€§æ¨¡å‹: {model_name}")

        # åˆ›å»ºæ¨¡å‹ä¿å­˜è·¯å¾„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_path = self.model_save_dir / f"{model_name}_srs_compliant_{timestamp}.pkl"
        metadata_path = (
            self.model_save_dir / f"{model_name}_srs_metadata_{timestamp}.json"
        )
        log_path = self.model_save_dir / f"{model_name}_training_log_{timestamp}.json"

        # ä¿å­˜æ¨¡å‹
        model_data = {
            "model": model_results["model"],
            "scaler": self.scaler,
            "label_encoder": self.label_encoder,
            "feature_names": self.feature_engineer.get_feature_names(),
            "feature_importance": (
                    model_results["feature_importance"].to_dict("records")
                    if "feature_importance" in model_results
                else None
            ),
            "srs_compliance": model_results["srs_compliance"],
            "srs_targets": model_results["srs_targets"],
            "training_metrics": {
                "accuracy": model_results["accuracy"],
                "precision": model_results["precision"],
                "recall": model_results["recall"],
                "f1_score": model_results["f1_score"],
                "auc": model_results["auc"],
                "cv_score": model_results.get("cv_score", 0.0),
            },
            "best_params": model_results.get("best_params", {}),
            "model_metadata": {
                "model_type": model_name,
                "training_date": model_results["training_time"],
                "n_features": model_results["n_features"],
                "n_samples": model_results["n_samples"],
            },
        }

        joblib.dump(model_data, model_path)

        # ä¿å­˜SRSå…ƒæ•°æ®
        metadata = {
            "model_path": str(model_path),
            "model_type": model_name,
            "srs_compliance": model_results["srs_compliance"],
            "srs_targets": model_results["srs_targets"],
            "training_metrics": model_data["training_metrics"],
            "model_metadata": model_data["model_metadata"],
            "best_params": model_data["best_params"],
            "feature_importance_top10": (
                    model_data["feature_importance"][:10]
                    if model_data["feature_importance"]
                else None
            ),
            "compliance_certificate": {
                "meets_srs_requirements": model_results["srs_compliance"][
                    "overall_compliance"
                ],
                "accuracy_level": (
                    "EXCELLENT"
                    if model_results["accuracy"] >= 0.75
                    else (
                        "GOOD"
                        if model_results["accuracy"] >= 0.65
                        else "NEEDS_IMPROVEMENT"
                    )
                ),
                "ready_for_production": model_results["srs_compliance"][
                    "overall_compliance"
                ],
                "certificate_date": datetime.now().isoformat(),
            },
        }

        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        training_log = {
            "training_session_id": timestamp,
            "model_type": model_name,
            "start_time": datetime.now().isoformat(),
            "status": "completed",
            "srs_validation": {
                "accuracy_target": self.SRS_TARGETS["min_accuracy"],
                "actual_accuracy": model_results["accuracy"],
                "accuracy_passed": model_results["srs_compliance"][
                    "accuracy_target_met"
                ],
                "auc_target": self.SRS_TARGETS["min_auc"],
                "actual_auc": model_results["auc"],
                "auc_passed": model_results["srs_compliance"]["auc_target_met"],
                "f1_target": self.SRS_TARGETS["min_f1_score"],
                "actual_f1": model_results["f1_score"],
                "f1_passed": model_results["srs_compliance"]["f1_target_met"],
                "overall_passed": model_results["srs_compliance"]["overall_compliance"],
            },
            "model_files": {
                "model_file": str(model_path),
                "metadata_file": str(metadata_path),
                "log_file": str(log_path),
            },
            "feature_analysis": {
                "total_features": model_results["n_features"],
                "top_features": (
                        model_data["feature_importance"][:5]
                        if model_data["feature_importance"]
                    else []
                ),
            },
        }

        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(training_log, f, indent=2, ensure_ascii=False)

        self.logger.info(f"SRSç¬¦åˆæ€§æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        return str(model_path)

    async def run_srs_compliant_training_pipeline(
        self, n_samples: int = 2000
    ) -> Dict[str, Any]:
        """è¿è¡ŒSRSç¬¦åˆæ€§è®­ç»ƒç®¡é“"""
        self.logger.info("å¼€å§‹è¿è¡ŒSRSç¬¦åˆæ€§è®­ç»ƒç®¡é“...")

        try:
            # 1. ç”ŸæˆSRSç¬¦åˆæ€§æ•°æ®
            matches = self.generate_srs_compliant_training_data(n_samples)

            # 2. å‡†å¤‡è®­ç»ƒæ•°æ®
            X, y = await self.prepare_srs_training_data(matches)

            # 3. è®­ç»ƒå’Œæ¯”è¾ƒæ¨¡å‹
            results = {}
            best_accuracy = 0.0
            best_model_name = None
            best_model_results = None

            # è®­ç»ƒXGBoost
            if XGB_AVAILABLE:
                try:
                    xgb_results = self.train_xgboost_with_srs_validation(X, y)
                    results["xgboost"] = xgb_results
                    if xgb_results["accuracy"] > best_accuracy:
                        best_accuracy = xgb_results["accuracy"]
                        best_model_name = "xgboost"
                        best_model_results = xgb_results
                except Exception as e:
                    self.logger.error(f"XGBoostè®­ç»ƒå¤±è´¥: {e}")

            # è®­ç»ƒLightGBM
            if LGB_AVAILABLE:
                try:
                    lgb_results = self.train_lightgbm_with_srs_validation(X, y)
                    results["lightgbm"] = lgb_results
                    if lgb_results["accuracy"] > best_accuracy:
                        best_accuracy = lgb_results["accuracy"]
                        best_model_name = "lightgbm"
                        best_model_results = lgb_results
                except Exception as e:
                    self.logger.error(f"LightGBMè®­ç»ƒå¤±è´¥: {e}")

            # 4. ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆå¦‚æœç¬¦åˆSRSè¦æ±‚ï¼‰
            saved_model_path = None
            if best_model_name and best_model_results:
                if best_model_results["srs_compliance"]["overall_compliance"]:
                    saved_model_path = self.save_srs_compliant_model(
                        best_model_results, best_model_name
                    )
                    self.best_models[best_model_name] = {
                        "path": saved_model_path,
                        "metrics": best_model_results,
                        "training_date": datetime.now().isoformat(),
                    }
                else:
                    self.logger.warning("æœ€ä½³æ¨¡å‹æœªè¾¾åˆ°SRSç¬¦åˆæ€§è¦æ±‚,æœªä¿å­˜")

            # 5. ç”ŸæˆSRSæŠ¥å‘Š
            srs_report = {
                "training_status": "completed",
                "srs_targets": self.SRS_TARGETS,
                "data_summary": {
                    "total_matches": len(matches),
                    "feature_count": X.shape[1],
                    "target_distribution": y.value_counts().to_dict(),
                },
                "model_results": {},
                "best_model": {
                    "name": best_model_name,
                    "accuracy": best_accuracy,
                    "srs_compliance": (
                        best_model_results["srs_compliance"]
                        if best_model_results
                        else None
                    ),
                    "model_saved": saved_model_path is not None,
                    "model_path": saved_model_path,
                },
                "srs_overall_compliance": (
                    best_model_results["srs_compliance"]["overall_compliance"]
                    if best_model_results
                    else False
                ),
                "recommendations": [],
                "next_steps": [],
            }

            # æ·»åŠ å„æ¨¡å‹ç»“æœ
            for model_name, model_results in results.items():
                srs_report["model_results"][model_name] = {
                    "accuracy": model_results["accuracy"],
                    "auc": model_results.get("auc", 0.0),
                    "f1_score": model_results["f1_score"],
                    "srs_compliance": model_results["srs_compliance"],
                }

            # ç”Ÿæˆå»ºè®®å’Œä¸‹ä¸€æ­¥è®¡åˆ’
            if srs_report["srs_overall_compliance"]:
                srs_report["recommendations"] = [
                    "âœ… SRSè¦æ±‚å·²å®Œå…¨è¾¾æˆ",
                    "ğŸš€ æ¨¡å‹å·²å‡†å¤‡å¥½éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ",
                    "ğŸ“Š å»ºç«‹å®æ—¶æ€§èƒ½ç›‘æ§ç³»ç»Ÿ",
                    "ğŸ”„ åˆ¶å®šå®šæœŸé‡æ–°è®­ç»ƒè®¡åˆ’ï¼ˆæ¯æœˆï¼‰",
                ]
                srs_report["next_steps"] = [
                    "éƒ¨ç½²æ¨¡å‹åˆ°APIæœåŠ¡",
                    "é›†æˆåˆ°é¢„æµ‹ç®¡é“",
                    "é…ç½®æ¨¡å‹ç›‘æ§å‘Šè­¦",
                    "è®¾ç½®è‡ªåŠ¨é‡æ–°è®­ç»ƒ",
                ]
            else:
                srs_report["recommendations"] = [
                    "âš ï¸ æ¨¡å‹æœªå®Œå…¨è¾¾åˆ°SRSè¦æ±‚",
                    "ğŸ“ˆ å¢åŠ è®­ç»ƒæ•°æ®é‡å’Œè´¨é‡",
                    "ğŸ”§ ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹ç®—æ³•",
                    "ğŸ§ª å°è¯•é›†æˆå­¦ä¹ æ–¹æ³•",
                    "âš™ï¸ è°ƒæ•´è¶…å‚æ•°ä¼˜åŒ–ç­–ç•¥",
                ]
                srs_report["next_steps"] = [
                    "æ”¶é›†æ›´å¤šå†å²æ¯”èµ›æ•°æ®",
                    "ä¼˜åŒ–ç‰¹å¾é€‰æ‹©ç®—æ³•",
                    "å°è¯•æ¨¡å‹é›†æˆæŠ€æœ¯",
                    "é‡æ–°è®­ç»ƒå’Œè¯„ä¼°",
                ]

            self.logger.info("SRSç¬¦åˆæ€§è®­ç»ƒç®¡é“æ‰§è¡Œå®Œæˆ")
            self.logger.info(
                f"SRSç¬¦åˆæ€§çŠ¶æ€: {'âœ… è¾¾æ ‡' if srs_report['srs_overall_compliance'] else 'âŒ æœªè¾¾æ ‡'}"
            )

            return srs_report

        except Exception as e:
            self.logger.error(f"SRSè®­ç»ƒç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "training_status": "failed",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "srs_compliance": False,
            }


async def main():
    """ä¸»å‡½æ•° - SRSç¬¦åˆæ€§æ¨¡å‹è®­ç»ƒæ¼”ç¤º"""
    trainer = SRSCompliantModelTrainer()

    print("=" * 80)
    print("SRSç¬¦åˆæ€§æ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
    print("ç³»ç»Ÿéœ€æ±‚è¯´æ˜(SRS)ç¬¦åˆæ€§éªŒè¯")
    print("=" * 80)
    print(f"ç›®æ ‡å‡†ç¡®ç‡: â‰¥ {trainer.SRS_TARGETS['min_accuracy']*100}%")
    print(f"ç›®æ ‡AUC: â‰¥ {trainer.SRS_TARGETS['min_auc']*100}%")
    print(f"ç›®æ ‡F1åˆ†æ•°: â‰¥ {trainer.SRS_TARGETS['min_f1_score']*100}%")
    print("=" * 80)

    # è¿è¡ŒSRSç¬¦åˆæ€§è®­ç»ƒç®¡é“
    results = await trainer.run_srs_compliant_training_pipeline(n_samples=2000)

    print(f"\nè®­ç»ƒçŠ¶æ€: {results['training_status']}")

    if results["training_status"] == "completed":
        print("\nğŸ“Š æ•°æ®æ‘˜è¦:")
        print(f"  æ€»æ¯”èµ›æ•°: {results['data_summary']['total_matches']}")
        print(f"  ç‰¹å¾æ•°é‡: {results['data_summary']['feature_count']}")
        print(f"  ç›®æ ‡åˆ†å¸ƒ: {results['data_summary']['target_distribution']}")

        print("\nğŸ† æœ€ä½³æ¨¡å‹:")
        print(f"  æ¨¡å‹ç±»å‹: {results['best_model']['name']}")
        print(f"  å‡†ç¡®ç‡: {results['best_model']['accuracy']:.4f}")
        print(
            f"  SRSç¬¦åˆæ€§: {'âœ… å®Œå…¨ç¬¦åˆ' if results['srs_overall_compliance'] else 'âŒ ä¸ç¬¦åˆ'}"
        )
        if results["best_model"]["model_saved"]:
            print(f"  æ¨¡å‹å·²ä¿å­˜: {results['best_model']['model_path']}")

        print("\nğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        for model_name, model_results in results["model_results"].items():
            compliance = (
                "âœ…" if model_results["srs_compliance"]["overall_compliance"] else "âŒ"
            )
            print(
                f"  {model_name}: å‡†ç¡®ç‡={model_results['accuracy']:.4f}, AUC={model_results['auc']:.4f}, F1={model_results['f1_score']:.4f} {compliance}"
            )

        print("\nğŸ’¡ å»ºè®®:")
        for rec in results["recommendations"]:
            print(f"  {rec}")

        print("\nğŸš€ ä¸‹ä¸€æ­¥è®¡åˆ’:")
        for step in results["next_steps"]:
            print(f"  {step}")

        print("\nğŸ¯ SRSç¬¦åˆæ€§æ€»ç»“:")
        print(
            f"  æ•´ä½“ç¬¦åˆæ€§: {'âœ… è¾¾æˆ' if results['srs_overall_compliance'] else 'âŒ æœªè¾¾æˆ'}"
        )
        if results["srs_overall_compliance"]:
            print("  ğŸ‰ æ­å–œï¼æ¨¡å‹å·²æ»¡è¶³æ‰€æœ‰SRSè¦æ±‚,å¯ä»¥éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
        else:
            print("  âš ï¸ æ¨¡å‹éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥è¾¾åˆ°SRSè¦æ±‚")
    else:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {results['error']}")


if __name__ == "__main__":
    asyncio.run(main())
