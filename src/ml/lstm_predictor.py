#!/usr/bin/env python3
"""
LSTMæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹
LSTM Time Series Prediction Model

åŸºäºé•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„è´¨é‡æŒ‡æ ‡æ—¶é—´åºåˆ—é¢„æµ‹å’Œå¼‚å¸¸æ£€æµ‹
"""

import json
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
from dataclasses import dataclass, asdict

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
except ImportError:
    print("è­¦å‘Š: TensorFlowæœªå®‰è£…ï¼ŒLSTMåŠŸèƒ½å°†ä¸å¯ç”¨")
    tf = None

from src.core.logging_system import get_logger
from src.core.config import get_config
from src.timeseries.influxdb_client import influxdb_manager

logger = get_logger(__name__)


@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœæ•°æ®æ¨¡å‹"""
    timestamp: datetime
    predicted_values: List[float]
    confidence_intervals: List[Tuple[float, float]]  # (lower, upper)
    actual_values: Optional[List[float]] = None
    model_version: str = "1.0"
    prediction_horizon: int = 12  # é¢„æµ‹æœªæ¥12ä¸ªæ—¶é—´ç‚¹
    mae: Optional[float] = None
    rmse: Optional[float] = None
    r2: Optional[float] = None

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        if self.actual_values:
            data['actual_values'] = self.actual_values
        return data


@dataclass
class TrainingConfig:
    """LSTMè®­ç»ƒé…ç½®"""
    sequence_length: int = 24  # ä½¿ç”¨è¿‡å»24ä¸ªæ—¶é—´ç‚¹
    prediction_horizon: int = 12  # é¢„æµ‹æœªæ¥12ä¸ªæ—¶é—´ç‚¹
    lstm_units: List[int] = (64, 32)  # LSTMå±‚å•å…ƒæ•°
    dropout_rate: float = 0.2
    batch_size: int = 32
    epochs: int = 100
    learning_rate: float = 0.001
    validation_split: float = 0.2
    early_stopping_patience: int = 10


class LSTMPredictor:
    """LSTMæ—¶é—´åºåˆ—é¢„æµ‹å™¨"""

    def __init__(self, config: Optional[TrainingConfig] = None):
        self.config = config or TrainingConfig()
        self.logger = get_logger(self.__class__.__name__)

        # æ¨¡å‹ç»„ä»¶
        self.model = None
        self.scaler_X = MinMaxScaler()
        self.scaler_y = MinMaxScaler()
        self.is_trained = False

        # æ•°æ®ç¼“å­˜
        self.training_data = None
        self.validation_data = None
        self.feature_columns = []

        # æ¨¡å‹å­˜å‚¨è·¯å¾„
        self.model_dir = Path("models/lstm")
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.model_path = self.model_dir / "lstm_quality_predictor.h5"
        self.scaler_path = self.model_dir / "scalers.pkl"

    def prepare_data(self, data: List[Dict[str, Any]],
                      target_column: str = "overall_score") -> Tuple[np.ndarray, np.ndarray]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        try:
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data)

            # ç¡®ä¿æ—¶é—´æ’åº
            if 'time' in df.columns:
                df['time'] = pd.to_datetime(df['time'])
                df = df.sort_values('time')

            # é€‰æ‹©ç‰¹å¾åˆ—
            feature_columns = []
            for col in df.columns:
                if col != target_column and df[col].dtype in ['float64', 'int64']:
                    feature_columns.append(col)

            self.feature_columns = feature_columns

            # æå–ç‰¹å¾å’Œç›®æ ‡
            features = df[feature_columns].values
            target = df[target_column].values.reshape(-1, 1)

            # æ•°æ®æ ‡å‡†åŒ–
            features_scaled = self.scaler_X.fit_transform(features)
            target_scaled = self.scaler_y.fit_transform(target)

            # åˆ›å»ºåºåˆ—æ•°æ®
            X, y = self._create_sequences(features_scaled, target_scaled)

            self.logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆ: ç‰¹å¾ç»´åº¦={features.shape}, åºåˆ—æ•°é‡={len(X)}")
            return X, y

        except Exception as e:
            self.logger.error(f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            raise

    def _create_sequences(self, features: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®"""
        X, y = [], []

        for i in range(len(features) - self.config.sequence_length - self.config.prediction_horizon + 1):
            # è¾“å…¥åºåˆ—
            X.append(features[i:i + self.config.sequence_length])
            # ç›®æ ‡åºåˆ—
            y.append(target[i + self.config.sequence_length:i + self.config.sequence_length + self.config.prediction_horizon])

        return np.array(X), np.array(y)

    def build_model(self, input_shape: Tuple[int, int]) -> None:
        """æ„å»ºLSTMæ¨¡å‹"""
        if tf is None:
            raise ImportError("TensorFlowæœªå®‰è£…ï¼Œæ— æ³•æ„å»ºLSTMæ¨¡å‹")

        try:
            self.model = Sequential()

            # ç¬¬ä¸€å±‚LSTM
            self.model.add(LSTM(
                self.config.lstm_units[0],
                return_sequences=True,
                input_shape=input_shape
            ))
            self.model.add(Dropout(self.config.dropout_rate))
            self.model.add(BatchNormalization())

            # ç¬¬äºŒå±‚LSTM
            if len(self.config.lstm_units) > 1:
                self.model.add(LSTM(
                    self.config.lstm_units[1],
                    return_sequences=False
                ))
                self.model.add(Dropout(self.config.dropout_rate))
                self.model.add(BatchNormalization())

            # è¾“å‡ºå±‚
            self.model.add(Dense(self.config.prediction_horizon))

            # ç¼–è¯‘æ¨¡å‹
            self.model.compile(
                optimizer=Adam(learning_rate=self.config.learning_rate),
                loss='mse',
                metrics=['mae']
            )

            self.logger.info(f"LSTMæ¨¡å‹æ„å»ºå®Œæˆ: input_shape={input_shape}")

        except Exception as e:
            self.logger.error(f"æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
            raise

    def train(self, X: np.ndarray, y: np.ndarray,
              validation_data: Optional[Tuple[np.ndarray, np.ndarray]] = None) -> Dict[str, Any]:
        """è®­ç»ƒLSTMæ¨¡å‹"""
        if self.model is None:
            self.build_model(input_shape=(X.shape[1], X.shape[2]))

        try:
            # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯æ•°æ®
            if validation_data is None:
                split_idx = int(len(X) * (1 - self.config.validation_split))
                X_train, X_val = X[:split_idx], X[split_idx:]
                y_train, y_val = y[:split_idx], y[split_idx:]
                validation_data = (X_val, y_val)
            else:
                X_train, y_train = X, y

            # è®¾ç½®å›è°ƒå‡½æ•°
            callbacks = [
                EarlyStopping(
                    monitor='val_loss',
                    patience=self.config.early_stopping_patience,
                    restore_best_weights=True,
                    verbose=1
                ),
                ReduceLROnPlateau(
                    monitor='val_loss',
                    factor=0.5,
                    patience=5,
                    min_lr=1e-7,
                    verbose=1
                )
            ]

            # è®­ç»ƒæ¨¡å‹
            history = self.model.fit(
                X_train, y_train,
                validation_data=validation_data,
                epochs=self.config.epochs,
                batch_size=self.config.batch_size,
                callbacks=callbacks,
                verbose=1
            )

            self.is_trained = True
            self.training_data = (X_train, y_train)
            self.validation_data = validation_data

            # è¯„ä¼°æ¨¡å‹
            train_loss, train_mae = self.model.evaluate(X_train, y_train, verbose=0)
            val_loss, val_mae = self.model.evaluate(validation_data[0], validation_data[1], verbose=0)

            training_stats = {
                'train_loss': train_loss,
                'train_mae': train_mae,
                'val_loss': val_loss,
                'val_mae': val_mae,
                'epochs_trained': len(history.history['loss']),
                'best_epoch': np.argmin(history.history['val_loss']) + 1
            }

            self.logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆ: {training_stats}")
            return training_stats

        except Exception as e:
            self.logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            raise

    def predict(self, input_sequence: np.ndarray,
                 return_confidence: bool = True) -> PredictionResult:
        """è¿›è¡Œé¢„æµ‹"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")

        try:
            # ç¡®ä¿è¾“å…¥å½¢çŠ¶æ­£ç¡®
            if input_sequence.shape[0] != self.config.sequence_length:
                raise ValueError(f"è¾“å…¥åºåˆ—é•¿åº¦å¿…é¡»ä¸º {self.config.sequence_length}")

            # æ ‡å‡†åŒ–è¾“å…¥
            input_scaled = self.scaler_X.transform(input_sequence)

            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            input_batch = np.expand_dims(input_scaled, axis=0)

            # é¢„æµ‹
            prediction_scaled = self.model.predict(input_batch, verbose=0)

            # åæ ‡å‡†åŒ–
            prediction = self.scaler_y.inverse_transform(prediction_scaled)[0]

            # è®¡ç®—ç½®ä¿¡åŒºé—´ (ä½¿ç”¨å†å²é¢„æµ‹è¯¯å·®)
            confidence_intervals = []
            if return_confidence and self.validation_data:
                # åœ¨éªŒè¯é›†ä¸Šè®¡ç®—é¢„æµ‹è¯¯å·®
                val_X, val_y = self.validation_data
                val_pred_scaled = self.model.predict(val_X, verbose=0)
                val_pred = self.scaler_y.inverse_transform(val_pred_scaled)

                # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„é¢„æµ‹è¯¯å·®æ ‡å‡†å·®
                errors = []
                for i in range(self.config.prediction_horizon):
                    error = np.abs(val_pred[:, i] - val_y[:, i])
                    errors.append(np.std(error))

                # ç”Ÿæˆ95%ç½®ä¿¡åŒºé—´
                for i, pred_val in enumerate(prediction):
                    std_error = errors[i] if i < len(errors) else np.mean(errors)
                    margin = 1.96 * std_error  # 95%ç½®ä¿¡åŒºé—´
                    confidence_intervals.append((
                        max(0, pred_val - margin),
                        min(10, pred_val + margin)  # å‡è®¾åˆ†æ•°èŒƒå›´0-10
                    ))
            else:
                # å¦‚æœæ²¡æœ‰éªŒè¯æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åŒºé—´
                for pred_val in prediction:
                    margin = 0.5  # é»˜è®¤ç½®ä¿¡åŒºé—´Â±0.5
                    confidence_intervals.append((
                        max(0, pred_val - margin),
                        min(10, pred_val + margin)
                    ))

            # åˆ›å»ºé¢„æµ‹ç»“æœ
            result = PredictionResult(
                timestamp=datetime.now(),
                predicted_values=prediction.tolist(),
                confidence_intervals=confidence_intervals,
                prediction_horizon=self.config.prediction_horizon
            )

            self.logger.info(f"é¢„æµ‹å®Œæˆ: é¢„æµ‹å€¼={prediction[:3].tolist()}...")
            return result

        except Exception as e:
            self.logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
            raise

    async def predict_future(self, hours_ahead: int = 6) -> PredictionResult:
        """é¢„æµ‹æœªæ¥è´¨é‡æŒ‡æ ‡"""
        try:
            # è·å–æœ€è¿‘çš„å†å²æ•°æ®
            recent_data = await influxdb_manager.get_quality_metrics_history(
                hours=self.config.sequence_length + 24
            )

            if len(recent_data) < self.config.sequence_length:
                raise ValueError(f"å†å²æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {self.config.sequence_length} ä¸ªæ•°æ®ç‚¹")

            # æå–ç‰¹å¾æ•°æ®
            features_data = []
            for point in recent_data:
                feature_vector = [
                    point.get('value', 0) if point.get('field') == 'overall_score' else 0,
                    point.get('cpu_usage', 0) if point.get('field') == 'cpu_usage' else 0,
                    point.get('memory_usage', 0) if point.get('field') == 'memory_usage' else 0,
                    point.get('active_connections', 0) if point.get('field') == 'active_connections' else 0
                ]
                features_data.append(feature_vector)

            # å¦‚æœç‰¹å¾æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤å€¼å¡«å……
            while len(features_data) < self.config.sequence_length:
                features_data.insert(0, [7.0, 50.0, 60.0, 10])  # é»˜è®¤å€¼

            # å–æœ€è¿‘çš„æ•°æ®ç‚¹
            input_sequence = np.array(features_data[-self.config.sequence_length:])

            # è¿›è¡Œé¢„æµ‹
            result = self.predict(input_sequence)

            self.logger.info(f"æœªæ¥é¢„æµ‹å®Œæˆ: {hours_ahead}å°æ—¶")
            return result

        except Exception as e:
            self.logger.error(f"æœªæ¥é¢„æµ‹å¤±è´¥: {e}")
            raise

    def evaluate_model(self, test_X: np.ndarray, test_y: np.ndarray) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        try:
            # é¢„æµ‹
            predictions_scaled = self.model.predict(test_X, verbose=0)
            predictions = self.scaler_y.inverse_transform(predictions_scaled)
            actuals = self.scaler_y.inverse_transform(test_y)

            # è®¡ç®—æŒ‡æ ‡
            mae = mean_absolute_error(actuals, predictions)
            mse = mean_squared_error(actuals, predictions)
            rmse = np.sqrt(mse)
            r2 = r2_score(actuals.flatten(), predictions.flatten())

            metrics = {
                'mae': mae,
                'mse': mse,
                'rmse': rmse,
                'r2': r2
            }

            self.logger.info(f"æ¨¡å‹è¯„ä¼°å®Œæˆ: {metrics}")
            return metrics

        except Exception as e:
            self.logger.error(f"æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return {}

    def save_model(self) -> bool:
        """ä¿å­˜æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨"""
        try:
            if self.model is None:
                self.logger.warning("æ²¡æœ‰å¯ä¿å­˜çš„æ¨¡å‹")
                return False

            # ä¿å­˜Kerasæ¨¡å‹
            self.model.save(self.model_path)

            # ä¿å­˜æ ‡å‡†åŒ–å™¨
            with open(self.scaler_path, 'wb') as f:
                pickle.dump({
                    'scaler_X': self.scaler_X,
                    'scaler_y': self.scaler_y,
                    'feature_columns': self.feature_columns,
                    'config': self.config
                }, f)

            self.logger.info(f"æ¨¡å‹å·²ä¿å­˜: {self.model_path}")
            return True

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            return False

    def load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨"""
        try:
            if not self.model_path.exists():
                self.logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                return False

            # åŠ è½½Kerasæ¨¡å‹
            self.model = tf.keras.models.load_model(self.model_path)

            # åŠ è½½æ ‡å‡†åŒ–å™¨
            with open(self.scaler_path, 'rb') as f:
                scalers_data = pickle.load(f)
                self.scaler_X = scalers_data['scaler_X']
                self.scaler_y = scalers_data['scaler_y']
                self.feature_columns = scalers_data['feature_columns']
                self.config = scalers_data['config']

            self.is_trained = True
            self.logger.info(f"æ¨¡å‹å·²åŠ è½½: {self.model_path}")
            return True

        except Exception as e:
            self.logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False

    async def train_with_historical_data(self, days: int = 30) -> Dict[str, Any]:
        """ä½¿ç”¨å†å²æ•°æ®è®­ç»ƒæ¨¡å‹"""
        try:
            self.logger.info(f"å¼€å§‹ä½¿ç”¨å†å²æ•°æ®è®­ç»ƒæ¨¡å‹ (è¿‡å»{days}å¤©)")

            # è·å–å†å²æ•°æ®
            historical_data = await influxdb_manager.get_quality_metrics_history(hours=days*24)

            if len(historical_data) < 100:
                raise ValueError(f"å†å²æ•°æ®ä¸è¶³ï¼Œåªæœ‰ {len(historical_data)} ä¸ªæ•°æ®ç‚¹")

            # å‡†å¤‡æ•°æ®
            X, y = self.prepare_data(historical_data)

            if len(X) < 50:
                raise ValueError("å‡†å¤‡åçš„è®­ç»ƒæ•°æ®ä¸è¶³")

            # è®­ç»ƒæ¨¡å‹
            training_stats = self.train(X, y)

            # ä¿å­˜æ¨¡å‹
            self.save_model()

            # è¯„ä¼°æ¨¡å‹
            metrics = self.evaluate_model(X, y)
            training_stats.update(metrics)

            self.logger.info(f"å†å²æ•°æ®è®­ç»ƒå®Œæˆ: {training_stats}")
            return training_stats

        except Exception as e:
            self.logger.error(f"å†å²æ•°æ®è®­ç»ƒå¤±è´¥: {e}")
            raise


# å…¨å±€LSTMé¢„æµ‹å™¨å®ä¾‹
lstm_predictor = LSTMPredictor()


# è¾…åŠ©å‡½æ•°
async def train_lstm_model(days: int = 30) -> Dict[str, Any]:
    """è®­ç»ƒLSTMæ¨¡å‹"""
    return await lstm_predictor.train_with_historical_data(days)


async def predict_quality_trend(hours_ahead: int = 6) -> PredictionResult:
    """é¢„æµ‹è´¨é‡è¶‹åŠ¿"""
    return await lstm_predictor.predict_future(hours_ahead)


if __name__ == "__main__":
    import asyncio

    async def test_lstm_predictor():
        """æµ‹è¯•LSTMé¢„æµ‹å™¨"""
        print("ğŸ§ª æµ‹è¯•LSTMæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹...")

        # ç”Ÿæˆæ¨¡æ‹Ÿå†å²æ•°æ®
        np.random.seed(42)
        n_points = 200
        timestamps = [datetime.now() - timedelta(hours=i) for i in range(n_points, 0, -1)]

        mock_data = []
        for i, timestamp in enumerate(timestamps):
            # æ¨¡æ‹Ÿè´¨é‡åˆ†æ•°è¶‹åŠ¿ (å¸¦å™ªå£°)
            base_score = 8.0 + 0.5 * np.sin(i * 0.1) + np.random.normal(0, 0.2)
            base_score = np.clip(base_score, 6.0, 10.0)

            mock_data.append({
                'time': timestamp.isoformat(),
                'value': base_score,
                'field': 'overall_score',
                'cpu_usage': 40 + 20 * np.sin(i * 0.05) + np.random.normal(0, 5),
                'memory_usage': 60 + 15 * np.cos(i * 0.08) + np.random.normal(0, 3),
                'active_connections': 10 + 5 * np.sin(i * 0.03) + np.random.randint(-2, 3)
            })

        print(f"âœ… ç”Ÿæˆäº† {len(mock_data)} ä¸ªæ¨¡æ‹Ÿæ•°æ®ç‚¹")

        # è®­ç»ƒæ¨¡å‹
        lstm_predictor.prepare_data(mock_data)
        X, y = lstm_predictor.prepare_data(mock_data)

        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: X.shape={X.shape}, y.shape={y.shape}")

        # æ„å»ºå’Œè®­ç»ƒæ¨¡å‹
        lstm_predictor.build_model(input_shape=(X.shape[1], X.shape[2]))
        training_stats = lstm_predictor.train(X, y)

        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ: {training_stats}")

        # è¿›è¡Œé¢„æµ‹
        test_sequence = X[-1]  # ä½¿ç”¨æœ€åä¸€ä¸ªåºåˆ—è¿›è¡Œæµ‹è¯•
        prediction_result = lstm_predictor.predict(test_sequence)

        print("âœ… é¢„æµ‹å®Œæˆ:")
        print(f"  é¢„æµ‹å€¼: {prediction_result.predicted_values[:3]}")
        print(f"  ç½®ä¿¡åŒºé—´: {prediction_result.confidence_intervals[:3]}")

        # ä¿å­˜æ¨¡å‹
        lstm_predictor.save_model()
        print("âœ… æ¨¡å‹å·²ä¿å­˜")

        print("ğŸ‰ LSTMé¢„æµ‹å™¨æµ‹è¯•å®Œæˆ!")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_lstm_predictor())