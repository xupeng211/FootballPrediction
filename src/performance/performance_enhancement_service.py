"""
æ€§èƒ½ä¼˜åŒ–å’Œå¹¶å‘å¤„ç†å¢å¼ºæœåŠ¡
Performance Optimization and Concurrency Enhancement Service

æä¾›ä¼ä¸šçº§æ€§èƒ½ä¼˜åŒ–ã€å¹¶å‘å¤„ç†å¢å¼ºã€èµ„æºç®¡ç†ç­‰åŠŸèƒ½ã€‚
"""

import asyncio
import logging
import time
from asyncio import Semaphore
from collections import defaultdict, deque
from collections.abc import Callable
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any

import psutil

logger = logging.getLogger(__name__)

# ============================================================================
# æ€§èƒ½æŒ‡æ ‡å’Œç›‘æ§æ•°æ®ç»“æ„
# ============================================================================


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""

    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    disk_usage: float = 0.0
    network_io: float = 0.0
    active_connections: int = 0
    request_rate: float = 0.0
    response_time: float = 0.0
    throughput: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class ConcurrencyMetrics:
    """å¹¶å‘æŒ‡æ ‡"""

    active_tasks: int = 0
    queued_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    average_task_time: float = 0.0
    max_concurrent_tasks: int = 0
    resource_contention: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


class PerformanceEnhancementService:
    """æ€§èƒ½ä¼˜åŒ–å’Œå¹¶å‘å¤„ç†å¢å¼ºæœåŠ¡"""

    def __init__(self):
        self.performance_metrics: deque[PerformanceMetrics] = deque(maxlen=100)
        self.concurrency_metrics: deque[ConcurrencyMetrics] = deque(maxlen=100)
        self.resource_monitor_active = False
        self.concurrent_limiter: Semaphore | None = None
        self.task_performance_stats: dict[str, list[float]] = defaultdict(list)
        self.optimization_applied = False

    async def start_performance_monitoring(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
        if self.resource_monitor_active:
            return

        self.resource_monitor_active = True

        # å¯åŠ¨èµ„æºç›‘æ§ä»»åŠ¡
        asyncio.create_task(self._monitor_system_resources())

        # å¯åŠ¨æ€§èƒ½æŒ‡æ ‡æ”¶é›†
        asyncio.create_task(self._collect_performance_metrics())

        logger.info("æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")

    async def stop_performance_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.resource_monitor_active = False
        logger.info("æ€§èƒ½ç›‘æ§å·²åœæ­¢")

    async def _monitor_system_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æº"""
        while self.resource_monitor_active:
            try:
                metrics = PerformanceMetrics()

                # CPUä½¿ç”¨ç‡
                metrics.cpu_usage = psutil.cpu_percent(interval=1)

                # å†…å­˜ä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                metrics.memory_usage = memory.percent

                # ç£ç›˜ä½¿ç”¨ç‡
                disk = psutil.disk_usage("/")
                metrics.disk_usage = disk.percent

                # ç½‘ç»œIO
                network = psutil.net_io_counters()
                metrics.network_io = network.bytes_sent + network.bytes_recv

                # æ´»è·ƒè¿æ¥æ•°
                metrics.active_connections = len(psutil.net_connections())

                self.performance_metrics.append(metrics)

            except Exception as e:
                logger.error(f"ç³»ç»Ÿèµ„æºç›‘æ§å¤±è´¥: {e}")

            await asyncio.sleep(10)  # æ¯10ç§’æ”¶é›†ä¸€æ¬¡

    async def _collect_performance_metrics(self):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        while self.resource_monitor_active:
            try:
                concurrency = ConcurrencyMetrics()

                # è·å–å½“å‰ä»»åŠ¡ç»Ÿè®¡
                current_tasks = [
                    task for task in asyncio.all_tasks() if not task.done()
                ]
                concurrency.active_tasks = len(current_tasks)
                concurrency.max_concurrent_tasks = max(
                    concurrency.max_concurrent_tasks, concurrency.active_tasks
                )

                # è®¡ç®—èµ„æºäº‰ç”¨åº¦
                if concurrency.active_tasks > 0:
                    concurrency.resource_contention = min(
                        1.0, (concurrency.active_tasks - 1) / 10.0
                    )  # å‡è®¾10ä¸ªå¹¶å‘ä¸ºé˜ˆå€¼

                # è®¡ç®—å¹³å‡ä»»åŠ¡æ‰§è¡Œæ—¶é—´
                all_task_times = []
                for task_times in self.task_performance_stats.values():
                    all_task_times.extend(task_times[-10:])  # åªè€ƒè™‘æœ€è¿‘10æ¬¡ä»»åŠ¡

                if all_task_times:
                    concurrency.average_task_time = sum(all_task_times) / len(
                        all_task_times
                    )

                self.concurrency_metrics.append(concurrency)

            except Exception as e:
                logger.error(f"æ€§èƒ½æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")

            await asyncio.sleep(5)  # æ¯5ç§’æ”¶é›†ä¸€æ¬¡

    def setup_concurrency_limit(self, max_concurrent_tasks: int = 100):
        """è®¾ç½®å¹¶å‘é™åˆ¶"""
        self.concurrent_limiter = Semaphore(max_concurrent_tasks)
        logger.info(f"å¹¶å‘é™åˆ¶å·²è®¾ç½®: {max_concurrent_tasks}")

    @asynccontextmanager
    async def rate_limit(self, max_concurrent: int = 10):
        """å¹¶å‘æ§åˆ¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.concurrent_limiter is None:
            self.setup_concurrency_limit(max_concurrent)

        async with self.concurrent_limiter:
            yield

    async def execute_with_performance_tracking(
        self, task_func: Callable, task_name: str, *args, **kwargs
    ) -> Any:
        """æ‰§è¡Œä»»åŠ¡å¹¶è·Ÿè¸ªæ€§èƒ½"""
        start_time = time.time()

        try:
            async with self.rate_limit():
                result = await task_func(*args, **kwargs)

            execution_time = time.time() - start_time
            self.task_performance_stats[task_name].append(execution_time)

            # ä¿ç•™æœ€è¿‘100æ¬¡æ‰§è¡Œè®°å½•
            if len(self.task_performance_stats[task_name]) > 100:
                self.task_performance_stats[task_name] = self.task_performance_stats[
                    task_name
                ][-100:]

            return result

        except Exception as e:
            execution_time = time.time() - start_time
            self.task_performance_stats[f"{task_name}_error"].append(execution_time)
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {task_name}: {e}")
            raise

    async def optimize_database_connections(self, connection_pool_size: int = 20):
        """ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            # è¿™é‡Œå¯ä»¥é…ç½®æ•°æ®åº“è¿æ¥æ± 
            # å®é™…å®ç°éœ€è¦æ ¹æ®å…·ä½“æ•°æ®åº“ç±»å‹è°ƒæ•´
            logger.info(f"æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–: {connection_pool_size}")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–å¤±è´¥: {e}")
            return False

    async def optimize_cache_strategy(self):
        """ä¼˜åŒ–ç¼“å­˜ç­–ç•¥"""
        try:
            # å®ç°ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
            optimizations = [
                "å¯ç”¨å¤šçº§ç¼“å­˜",
                "ä¼˜åŒ–TTLé…ç½®",
                "å®ç°ç¼“å­˜é¢„çƒ­",
                "é…ç½®ç¼“å­˜ç©¿é€ä¿æŠ¤",
            ]

            for opt in optimizations:
                logger.info(f"åº”ç”¨ç¼“å­˜ä¼˜åŒ–: {opt}")

            return True
        except Exception as e:
            logger.error(f"ç¼“å­˜ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            return False

    async def enable_async_optimizations(self):
        """å¯ç”¨å¼‚æ­¥ä¼˜åŒ–"""
        try:
            # è®¾ç½®uvloopä½œä¸ºäº‹ä»¶å¾ªç¯
            import uvloop

            asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
            logger.info("uvloopäº‹ä»¶å¾ªç¯å·²å¯ç”¨")

            # å…¶ä»–å¼‚æ­¥ä¼˜åŒ–
            optimizations = [
                "å¯ç”¨HTTPè¿æ¥æ± ",
                "ä¼˜åŒ–å¼‚æ­¥ä»»åŠ¡è°ƒåº¦",
                "é…ç½®å¼‚æ­¥æ•°æ®åº“è¿æ¥",
                "å¯ç”¨å¼‚æ­¥ç¼“å­˜",
            ]

            for opt in optimizations:
                logger.info(f"åº”ç”¨å¼‚æ­¥ä¼˜åŒ–: {opt}")

            self.optimization_applied = True
            return True

        except ImportError:
            logger.warning("uvloopä¸å¯ç”¨ï¼Œè·³è¿‡äº‹ä»¶å¾ªç¯ä¼˜åŒ–")
            self.optimization_applied = True
            return True
        except Exception as e:
            logger.error(f"å¼‚æ­¥ä¼˜åŒ–å¤±è´¥: {e}")
            return False

    def get_performance_report(self) -> dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        if not self.performance_metrics:
            return {"message": "æ²¡æœ‰æ€§èƒ½æ•°æ®å¯ç”¨"}

        latest_metrics = self.performance_metrics[-1]
        latest_concurrency = (
            self.concurrency_metrics[-1] if self.concurrency_metrics else None
        )

        # è®¡ç®—å¹³å‡å€¼
        avg_cpu = sum(m.cpu_usage for m in self.performance_metrics) / len(
            self.performance_metrics
        )
        avg_memory = sum(m.memory_usage for m in self.performance_metrics) / len(
            self.performance_metrics
        )
        avg_active_tasks = (
            sum(m.active_tasks for m in self.concurrency_metrics)
            / len(self.concurrency_metrics)
            if self.concurrency_metrics
            else 0
        )

        report = {
            "system_resources": {
                "cpu_usage": latest_metrics.cpu_usage,
                "memory_usage": latest_metrics.memory_usage,
                "disk_usage": latest_metrics.disk_usage,
                "network_io": latest_metrics.network_io,
                "active_connections": latest_metrics.active_connections,
            },
            "averages": {
                "avg_cpu": round(avg_cpu, 2),
                "avg_memory": round(avg_memory, 2),
                "avg_active_tasks": round(avg_active_tasks, 2),
            },
            "concurrency": {
                "current_active_tasks": (
                    latest_concurrency.active_tasks if latest_concurrency else 0
                ),
                "max_concurrent_tasks": (
                    latest_concurrency.max_concurrent_tasks if latest_concurrency else 0
                ),
                "resource_contention": (
                    latest_concurrency.resource_contention if latest_concurrency else 0
                ),
                "average_task_time": (
                    latest_concurrency.average_task_time if latest_concurrency else 0
                ),
            },
            "optimization_status": {
                "optimizations_applied": self.optimization_applied,
                "concurrency_limiter_active": self.concurrent_limiter is not None,
                "monitoring_active": self.resource_monitor_active,
            },
            "task_performance": {
                task_name: {
                    "avg_execution_time": sum(times) / len(times),
                    "max_execution_time": max(times),
                    "min_execution_time": min(times),
                    "total_executions": len(times),
                }
                for task_name, times in self.task_performance_stats.items()
                if not task_name.endswith("_error") and times
            },
            "timestamp": datetime.now().isoformat(),
        }

        return report

    def get_performance_recommendations(self) -> list[str]:
        """è·å–æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []

        if not self.performance_metrics:
            return ["æ²¡æœ‰æ€§èƒ½æ•°æ®å¯åˆ†æ"]

        self.performance_metrics[-1]
        avg_cpu = sum(m.cpu_usage for m in self.performance_metrics) / len(
            self.performance_metrics
        )
        avg_memory = sum(m.memory_usage for m in self.performance_metrics) / len(
            self.performance_metrics
        )

        # CPUç›¸å…³å»ºè®®
        if avg_cpu > 80:
            recommendations.append("ğŸ”¥ CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œè€ƒè™‘ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ èµ„æº")
        elif avg_cpu > 60:
            recommendations.append("âš ï¸ CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®è¿›è¡Œæ€§èƒ½åˆ†æ")
        else:
            recommendations.append("âœ… CPUä½¿ç”¨ç‡æ­£å¸¸")

        # å†…å­˜ç›¸å…³å»ºè®®
        if avg_memory > 85:
            recommendations.append("ğŸ”¥ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜")
        elif avg_memory > 70:
            recommendations.append("âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼")
        else:
            recommendations.append("âœ… å†…å­˜ä½¿ç”¨ç‡æ­£å¸¸")

        # å¹¶å‘ç›¸å…³å»ºè®®
        if self.concurrency_metrics:
            latest_concurrency = self.concurrency_metrics[-1]
            if latest_concurrency.resource_contention > 0.7:
                recommendations.append("ğŸ”¥ èµ„æºäº‰ç”¨ä¸¥é‡ï¼Œå»ºè®®å‡å°‘å¹¶å‘ä»»åŠ¡æ•°æˆ–ä¼˜åŒ–ä»»åŠ¡")
            elif latest_concurrency.resource_contention > 0.5:
                recommendations.append("âš ï¸ èµ„æºäº‰ç”¨è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–å¹¶å‘æ§åˆ¶")
            else:
                recommendations.append("âœ… å¹¶å‘æ§åˆ¶è‰¯å¥½")

        # ä¼˜åŒ–çŠ¶æ€å»ºè®®
        if not self.optimization_applied:
            recommendations.append("ğŸ“‹ å»ºè®®åº”ç”¨æ€§èƒ½ä¼˜åŒ–é…ç½®")
        else:
            recommendations.append("âœ… æ€§èƒ½ä¼˜åŒ–å·²åº”ç”¨")

        if not self.resource_monitor_active:
            recommendations.append("ğŸ“‹ å»ºè®®å¯ç”¨æ€§èƒ½ç›‘æ§")
        else:
            recommendations.append("âœ… æ€§èƒ½ç›‘æ§å·²å¯ç”¨")

        return recommendations

    async def apply_performance_tuning(
        self, profile: str = "default"
    ) -> dict[str, Any]:
        """åº”ç”¨æ€§èƒ½è°ƒä¼˜é…ç½®"""
        tuning_configs = {
            "development": {
                "concurrency_limit": 50,
                "monitoring_interval": 10,
                "cache_size": 500,
                "connection_pool_size": 10,
            },
            "production": {
                "concurrency_limit": 200,
                "monitoring_interval": 5,
                "cache_size": 5000,
                "connection_pool_size": 50,
            },
            "high_performance": {
                "concurrency_limit": 500,
                "monitoring_interval": 2,
                "cache_size": 10000,
                "connection_pool_size": 100,
            },
            "default": {
                "concurrency_limit": 100,
                "monitoring_interval": 5,
                "cache_size": 1000,
                "connection_pool_size": 20,
            },
        }

        config = tuning_configs.get(profile, tuning_configs["default"])

        try:
            # åº”ç”¨é…ç½®
            self.setup_concurrency_limit(config["concurrency_limit"])
            await self.optimize_database_connections(config["connection_pool_size"])
            await self.optimize_cache_strategy()
            await self.enable_async_optimizations()

            result = {
                "profile": profile,
                "config": config,
                "status": "applied",
                "recommendations": self.get_performance_recommendations(),
            }

            logger.info(f"æ€§èƒ½è°ƒä¼˜é…ç½®å·²åº”ç”¨: {profile}")
            return result

        except Exception as e:
            logger.error(f"æ€§èƒ½è°ƒä¼˜å¤±è´¥: {e}")
            return {
                "profile": profile,
                "config": config,
                "status": "failed",
                "error": str(e),
            }


# å…¨å±€æ€§èƒ½å¢å¼ºæœåŠ¡å®ä¾‹
_performance_enhancement_service: PerformanceEnhancementService | None = None


async def get_performance_enhancement_service() -> PerformanceEnhancementService:
    """è·å–å…¨å±€æ€§èƒ½å¢å¼ºæœåŠ¡å®ä¾‹"""
    global _performance_enhancement_service

    if _performance_enhancement_service is None:
        _performance_enhancement_service = PerformanceEnhancementService()
        await _performance_enhancement_service.start_performance_monitoring()

    return _performance_enhancement_service
