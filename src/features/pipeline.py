#!/usr/bin/env python3
"""
Phase 3 ç‰¹å¾å·¥ç¨‹æµæ°´çº¿
é¦–å¸­ AI ç§‘å­¦å®¶: ç‰¹å¾å·¥ç¨‹ä¸“å®¶

Purpose: æ„å»ºåŸºçº¿XGBoostæ¨¡å‹çš„è®­ç»ƒç‰¹å¾
ä»FBrefæ•°æ®æå–åŸºç¡€ç‰¹å¾å’Œæ—¶åºç‰¹å¾
"""

import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from sqlalchemy import create_engine, text
import json

logger = logging.getLogger(__name__)


class FeaturePipeline:
    """
    Phase 3 ç‰¹å¾å·¥ç¨‹æµæ°´çº¿

    åŠŸèƒ½ï¼š
    1. ä»æ•°æ®åº“åŠ è½½FBrefæ¯”èµ›æ•°æ®
    2. æ„å»ºåŸºç¡€ç‰¹å¾ (xGå·®å¼‚ç­‰)
    3. æ„å»ºæ—¶åºç‰¹å¾ (è¿‡å»5åœºè¡¨ç°)
    4. é˜²æ­¢æœªæ¥æ•°æ®æ³„éœ²
    5. ç”Ÿæˆè®­ç»ƒç›®æ ‡å˜é‡
    """

    def __init__(self, db_url: str = None):
        """åˆå§‹åŒ–ç‰¹å¾æµæ°´çº¿"""
        if db_url is None:
            # ä½¿ç”¨é¡¹ç›®é»˜è®¤æ•°æ®åº“è¿æ¥
            db_url = "postgresql://postgres:postgres-dev-password@localhost:5432/football_prediction"

        self.engine = create_engine(db_url)
        logger.info("âœ… ç‰¹å¾æµæ°´çº¿åˆå§‹åŒ–æˆåŠŸ")

    def load_fbref_matches(self) -> pd.DataFrame:
        """
        ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰FBrefæ¯”èµ›æ•°æ®

        Returns:
            åŒ…å«æ¯”èµ›ä¿¡æ¯çš„DataFrame
        """
        logger.info("ğŸ”„ å¼€å§‹åŠ è½½FBrefæ¯”èµ›æ•°æ®...")

        query = text(
            """
            SELECT
                m.id,
                m.match_date,
                m.home_team_id,
                m.away_team_id,
                m.home_score,
                m.away_score,
                m.stats,
                ht.name as home_team_name,
                at.name as away_team_name
            FROM matches m
            LEFT JOIN teams ht ON m.home_team_id = ht.id
            LEFT JOIN teams at ON m.away_team_id = at.id
            WHERE m.data_source = 'fbref'
            AND m.home_score IS NOT NULL
            AND m.away_score IS NOT NULL
            ORDER BY m.match_date ASC, m.id ASC
        """
        )

        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(query, conn)

            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(df)} åœºFBrefæ¯”èµ›æ•°æ®")
            logger.info(
                f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df['match_date'].min()} åˆ° {df['match_date'].max()}"
            )

            return df

        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            raise

    def extract_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æå–åŸºç¡€ç‰¹å¾

        Args:
            df: åŸå§‹æ¯”èµ›æ•°æ®

        Returns:
            æ·»åŠ åŸºç¡€ç‰¹å¾çš„DataFrame
        """
        logger.info("ğŸ”§ æ„å»ºåŸºç¡€ç‰¹å¾...")

        df = df.copy()

        # è§£æstats JSONå­—æ®µè·å–xGæ•°æ®
        def extract_xg(stats_str):
            try:
                if pd.isna(stats_str):
                    return 0.0
                stats = (
                    json.loads(stats_str) if isinstance(stats_str, str) else stats_str
                )
                return float(stats.get("xg", {}).get("home_xg", 0))
            except (json.JSONDecodeError, TypeError, ValueError):
                return 0.0

        df["home_xg"] = df["stats"].apply(extract_xg)

        # ç”±äºæ•°æ®ä¸­åªæœ‰ä¸»é˜ŸxGï¼Œæˆ‘ä»¬æš‚æ—¶ç”¨ä¸€ä¸ªç®€åŒ–ç­–ç•¥
        # å®¢é˜ŸxGå¯ä»¥ç”¨å†å²å¹³å‡å€¼æ¥ä¼°ç®—ï¼Œè¿™é‡Œå…ˆè®¾ä¸º0
        df["away_xg"] = 0.0  # åç»­å¯ä»¥é€šè¿‡æ—¶åºç‰¹å¾æ¥è¡¥å…¨

        # æ„å»ºåŸºç¡€ç‰¹å¾
        df["xg_diff"] = df["home_xg"] - df["away_xg"]

        logger.info(f"âœ… åŸºç¡€ç‰¹å¾æ„å»ºå®Œæˆ: xg_diffå‡å€¼={df['xg_diff'].mean():.3f}")

        return df

    def build_rolling_features(self, df: pd.DataFrame, window: int = 5) -> pd.DataFrame:
        """
        æ„å»ºæ—¶åºç‰¹å¾ (è¿‡å»Nåœºæ¯”èµ›çš„æ»šåŠ¨ç»Ÿè®¡)

        Args:
            df: åŒ…å«åŸºç¡€ç‰¹å¾çš„DataFrame
            window: æ»šåŠ¨çª—å£å¤§å° (é»˜è®¤5åœº)

        Returns:
            æ·»åŠ æ—¶åºç‰¹å¾çš„DataFrame
        """
        logger.info(f"â³ æ„å»ºæ—¶åºç‰¹å¾ (çª—å£={window}åœº)...")

        df = df.copy()
        df = df.sort_values(["match_date", "id"]).reset_index(drop=True)

        # ä¸ºæ¯æ”¯çƒé˜Ÿè®¡ç®—å†å²ç»Ÿè®¡
        features = []

        for team_type in ["home", "away"]:
            team_id_col = f"{team_type}_team_id"
            team_name_col = f"{team_type}_team_name"
            score_col = f"{team_type}_score"
            xg_col = f"{team_type}_xg"

            logger.info(f"ğŸ“Š è®¡ç®—{team_type}é˜Ÿæ—¶åºç‰¹å¾...")

            # è®¡ç®—æ¯åœºæ¯”èµ›çš„èƒœè´Ÿç»“æœ
            def get_result(row, team_type):
                if team_type == "home":
                    if row["home_score"] > row["away_score"]:
                        return 1  # èƒœ
                    elif row["home_score"] == row["away_score"]:
                        return 0  # å¹³
                    else:
                        return -1  # è´Ÿ
                else:
                    if row["away_score"] > row["home_score"]:
                        return 1  # èƒœ
                    elif row["away_score"] == row["home_score"]:
                        return 0  # å¹³
                    else:
                        return -1  # è´Ÿ

            df[f"{team_type}_result"] = df.apply(get_result, axis=1, args=(team_type,))

            # æŒ‰çƒé˜Ÿåˆ†ç»„è®¡ç®—æ»šåŠ¨ç‰¹å¾ (ä¿®å¤FutureWarning)
            team_stats = (
                df.groupby(team_id_col, group_keys=False)
                .apply(
                    lambda group: self._calculate_team_rolling_stats(
                        group, score_col, xg_col, f"{team_type}_result", window
                    )
                )
                .reset_index()
            )

            features.append(team_stats)

        # åˆå¹¶æ—¶åºç‰¹å¾
        df_with_features = df.merge(
            features[0].merge(features[1], on="id", suffixes=("_home", "_away")),
            on="id",
        )

        logger.info(
            f"âœ… æ—¶åºç‰¹å¾æ„å»ºå®Œæˆï¼Œæ–°å¢ {len([col for col in df_with_features.columns if 'rolling' in col])} ä¸ªç‰¹å¾"
        )

        return df_with_features

    def _calculate_team_rolling_stats(
        self,
        group: pd.DataFrame,
        score_col: str,
        xg_col: str,
        result_col: str,
        window: int,
    ) -> pd.DataFrame:
        """
        è®¡ç®—å•ä¸ªçƒé˜Ÿçš„æ»šåŠ¨ç»Ÿè®¡

        Args:
            group: å•ä¸ªçƒé˜Ÿçš„æ¯”èµ›æ•°æ®
            score_col: è¿›çƒåˆ—å
            xg_col: xGåˆ—å
            result_col: ç»“æœåˆ—å
            window: æ»šåŠ¨çª—å£

        Returns:
            åŒ…å«æ»šåŠ¨ç‰¹å¾çš„DataFrame
        """
        group = group.sort_values("match_date").reset_index(drop=True)

        # ä½¿ç”¨shift(1)é˜²æ­¢æœªæ¥æ•°æ®æ³„éœ²
        goals_scored = group[score_col].shift(1)
        goals_conceded = group[
            score_col.replace("home", "away").replace("away", "home")
        ].shift(1)
        xg_values = group[xg_col].shift(1)
        results = group[result_col].shift(1)

        # è®¡ç®—æ»šåŠ¨ç»Ÿè®¡
        rolling_stats = pd.DataFrame(
            {
                "id": group["id"],
                f"rolling_avg_goals_scored_{window}": goals_scored.rolling(
                    window, min_periods=1
                ).mean(),
                f"rolling_avg_goals_conceded_{window}": goals_conceded.rolling(
                    window, min_periods=1
                ).mean(),
                f"rolling_avg_xg_{window}": xg_values.rolling(
                    window, min_periods=1
                ).mean(),
                f"rolling_win_rate_{window}": (results == 1)
                .rolling(window, min_periods=1)
                .mean(),
                f"rolling_goal_diff_{window}": (goals_scored - goals_conceded)
                .rolling(window, min_periods=1)
                .mean(),
            }
        )

        return rolling_stats

    def create_target_variable(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        åˆ›å»ºç›®æ ‡å˜é‡ (æ¯”èµ›ç»“æœ)

        Args:
            df: ç‰¹å¾DataFrame

        Returns:
            æ·»åŠ ç›®æ ‡å˜é‡çš„DataFrame
        """
        logger.info("ğŸ¯ åˆ›å»ºç›®æ ‡å˜é‡...")

        df = df.copy()

        def get_match_result(row):
            if row["home_score"] > row["away_score"]:
                return 2  # ä¸»èƒœ
            elif row["home_score"] == row["away_score"]:
                return 1  # å¹³å±€
            else:
                return 0  # å®¢èƒœ

        df["result"] = df.apply(get_match_result, axis=1)

        # ç»Ÿè®¡ç»“æœåˆ†å¸ƒ
        result_counts = df["result"].value_counts().sort_index()
        logger.info(
            f"ğŸ“Š ç»“æœåˆ†å¸ƒ: å®¢èƒœ={result_counts.get(0, 0)}, å¹³å±€={result_counts.get(1, 0)}, ä¸»èƒœ={result_counts.get(2, 0)}"
        )

        return df

    def build_features(self, window: int = 5) -> Tuple[pd.DataFrame, List[str]]:
        """
        æ„å»ºå®Œæ•´çš„ç‰¹å¾æ•°æ®é›†

        Args:
            window: æ—¶åºç‰¹å¾çª—å£å¤§å°

        Returns:
            (ç‰¹å¾DataFrame, ç‰¹å¾åˆ—ååˆ—è¡¨)
        """
        logger.info("ğŸš€ å¼€å§‹æ„å»ºå®Œæ•´ç‰¹å¾æ•°æ®é›†...")

        # 1. åŠ è½½æ•°æ®
        df = self.load_fbref_matches()

        # 2. åŸºç¡€ç‰¹å¾
        df = self.extract_basic_features(df)

        # 3. æ—¶åºç‰¹å¾
        df = self.build_rolling_features(df, window)

        # 4. ç›®æ ‡å˜é‡
        df = self.create_target_variable(df)

        # 5. é€‰æ‹©ç‰¹å¾åˆ—
        feature_cols = [col for col in df.columns if self._is_feature_column(col)]

        logger.info(
            f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ! æ€»è®¡ {len(feature_cols)} ä¸ªç‰¹å¾ï¼Œ{len(df)} ä¸ªæ ·æœ¬"
        )

        return df, feature_cols

    def _is_feature_column(self, col_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç‰¹å¾åˆ—"""
        exclude_cols = {
            "id",
            "match_date",
            "home_team_id",
            "away_team_id",
            "home_team_name",
            "away_team_name",
            "home_score",
            "away_score",
            "stats",
            "result",
            "home_result",
            "away_result",
        }
        return col_name not in exclude_cols

    def split_data(
        self, df: pd.DataFrame, train_end_date: str = "2024-05-01"
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        æ—¶é—´åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†

        Args:
            df: å®Œæ•´ç‰¹å¾æ•°æ®
            train_end_date: è®­ç»ƒé›†ç»“æŸæ—¥æœŸ

        Returns:
            (è®­ç»ƒé›†, æµ‹è¯•é›†)
        """
        logger.info(f"ğŸ“… æ—¶é—´åˆ‡åˆ†: è®­ç»ƒé›†æˆªè‡³ {train_end_date}")

        train_cutoff = pd.to_datetime(train_end_date)

        train_df = df[df["match_date"] < train_cutoff].copy()
        test_df = df[df["match_date"] >= train_cutoff].copy()

        logger.info(
            f"ğŸ“Š æ•°æ®åˆ‡åˆ†å®Œæˆ: è®­ç»ƒé›†={len(train_df)}æ ·æœ¬, æµ‹è¯•é›†={len(test_df)}æ ·æœ¬"
        )

        return train_df, test_df


def main():
    """æµ‹è¯•ç‰¹å¾æµæ°´çº¿"""
    logging.basicConfig(
        level=logging.INFO,
        format="ğŸ§  %(asctime)s [%(levelname)8s] %(name)s: %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )

    pipeline = FeaturePipeline()

    try:
        # æ„å»ºç‰¹å¾
        df, feature_cols = pipeline.build_features(window=5)

        # åˆ‡åˆ†æ•°æ®
        train_df, test_df = pipeline.split_data(df)

        print("\n" + "=" * 80)
        print("ğŸ‰ Phase 3 ç‰¹å¾å·¥ç¨‹æµæ°´çº¿æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“Š ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: {len(train_df)}")
        print(f"ğŸ“Š æµ‹è¯•æ ·æœ¬: {len(test_df)}")
        print(f"ğŸ“‹ ç‰¹å¾åˆ—: {feature_cols[:10]}...")
        print("=" * 80)

        return df

    except Exception as e:
        logger.error(f"âŒ ç‰¹å¾æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
