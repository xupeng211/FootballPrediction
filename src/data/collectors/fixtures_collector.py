import os
"""
赛程数据采集器

实现足球比赛赛程数据的采集逻辑。
包含防重复、防丢失策略，确保赛程数据的完整性和一致性。

采集策略：
- 每日凌晨执行全量同步
- 实时增量更新新增赛程
- 基于 match_id + league_id 去重
- 检测缺失比赛并补全

基于 DATA_DESIGN.md 第1.1节设计。
"""

import hashlib
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Set

from .base_collector import CollectionResult, DataCollector


class FixturesCollector(DataCollector):
    """
    赛程数据采集器

    负责从外部API采集足球比赛赛程数据，
    实现防重复、防丢失机制，确保数据质量。
    """

    def __init__(
        self,
        data_source: str = os.getenv("FIXTURES_COLLECTOR_STR_33"),
        api_key: Optional[str] = None,
        base_url: str = "https://api.football-data.org/v4",
        **kwargs,
    ):
        """
        初始化赛程采集器

        Args:
            data_source: 数据源名称
            api_key: API密钥
            base_url: API基础URL
        """
        super().__init__(data_source, **kwargs)
        self.api_key = api_key
        self.base_url = base_url

        # 防重复：记录已处理的比赛ID
        self._processed_matches: Set[str] = set()
        # 防丢失：记录应该存在但缺失的比赛
        self._missing_matches: List[Dict[str, Any]] = []

    async def collect_fixtures(
        self,
        leagues: Optional[List[str]] = None,
        date_from: Optional[datetime] = None,
        date_to: Optional[datetime] = None,
        **kwargs,
    ) -> CollectionResult:
        """
        采集赛程数据

        防重复策略：
        - 基于 external_match_id + league_id 生成唯一键
        - 检查数据库中是否已存在
        - 跳过重复记录

        防丢失策略：
        - 全量获取指定时间范围内的赛程
        - 与数据库现有数据比对
        - 标记缺失的比赛并补全

        Args:
            leagues: 需要采集的联赛列表
            date_from: 开始日期
            date_to: 结束日期

        Returns:
            CollectionResult: 采集结果
        """
        collected_data = []
        success_count = 0
        error_count = 0
        error_messages = []

        try:
            # 设置默认时间范围（未来30天）
            if not date_from:
                date_from = datetime.now()
            if not date_to:
                date_to = date_from + timedelta(days=30)

            # 获取需要采集的联赛列表
            if not leagues:
                leagues = await self._get_active_leagues()

            self.logger.info(
                f"Starting fixtures collection for {len(leagues)} leagues, "
                f"date range: {date_from.date()} to {date_to.date()}"
            )

            # 加载已存在的比赛ID（防重复）
            await self._load_existing_matches(date_from, date_to)

            # 按联赛采集赛程数据
            for league_code in leagues:
                try:
                    league_fixtures = await self._collect_league_fixtures(
                        league_code, date_from, date_to
                    )

                    # 处理每场比赛
                    for fixture_data in league_fixtures:
                        try:
                            # 防重复检查
                            match_key = self._generate_match_key(fixture_data)
                            if match_key in self._processed_matches:
                                self.logger.debug(
                                    f"Skipping duplicate match: {match_key}"
                                )
                                continue

                            # 数据清洗和标准化
                            cleaned_fixture = await self._clean_fixture_data(
                                fixture_data
                            )
                            if cleaned_fixture:
                                collected_data.append(cleaned_fixture)
                                self._processed_matches.add(match_key)
                                success_count += 1
                            else:
                                error_count += 1
                                error_messages.append(
                                    f"Invalid fixture data: {fixture_data}"
                                )

                        except Exception as e:
                            error_count += 1
                            error_messages.append(f"Error processing fixture: {str(e)}")
                            self.logger.error(f"Error processing fixture: {str(e)}")

                except Exception as e:
                    error_count += 1
                    error_messages.append(
                        f"Error collecting league {league_code}: {str(e)}"
                    )
                    self.logger.error(
                        f"Error collecting league {league_code}: {str(e)}"
                    )

            # 检测并处理缺失的比赛（防丢失）
            await self._detect_missing_matches(collected_data, date_from, date_to)

            # 保存到Bronze层原始数据表
            if collected_data:
                await self._save_to_bronze_layer("raw_match_data", collected_data)

            # 确定最终状态
            total_collected = len(collected_data)
            if error_count == 0:
                status = os.getenv("FIXTURES_COLLECTOR_STATUS_162")
            elif success_count > 0:
                status = os.getenv("FIXTURES_COLLECTOR_STATUS_163")
            else:
                status = os.getenv("FIXTURES_COLLECTOR_STATUS_165")

            result = CollectionResult(
                data_source=self.data_source,
                collection_type = os.getenv("FIXTURES_COLLECTOR_COLLECTION_TYPE_167"),
                records_collected=total_collected,
                success_count=success_count,
                error_count=error_count,
                status=status,
                error_message="; ".join(error_messages[:5]) if error_messages else None,
                collected_data=collected_data,
            )

            self.logger.info(
                f"Fixtures collection completed: "
                f"collected={total_collected}, success={success_count}, errors={error_count}"
            )

            return result

        except Exception as e:
            self.logger.error(f"Fixtures collection failed: {str(e)}")
            return CollectionResult(
                data_source=self.data_source,
                collection_type = os.getenv("FIXTURES_COLLECTOR_COLLECTION_TYPE_167"),
                records_collected=0,
                success_count=0,
                error_count=1,
                status = os.getenv("FIXTURES_COLLECTOR_STATUS_190"),
                error_message=str(e),
            )

    async def collect_odds(self, **kwargs) -> CollectionResult:
        """赛程采集器不处理赔率数据"""
        return CollectionResult(
            data_source=self.data_source,
            collection_type="odds",
            records_collected=0,
            success_count=0,
            error_count=0,
            status = os.getenv("FIXTURES_COLLECTOR_STATUS_199"),
        )

    async def collect_live_scores(self, **kwargs) -> CollectionResult:
        """赛程采集器不处理实时比分数据"""
        return CollectionResult(
            data_source=self.data_source,
            collection_type = os.getenv("FIXTURES_COLLECTOR_COLLECTION_TYPE_206"),
            records_collected=0,
            success_count=0,
            error_count=0,
            status = os.getenv("FIXTURES_COLLECTOR_STATUS_199"),
        )

    async def _get_active_leagues(self) -> List[str]:
        """
        获取活跃的联赛列表

        Returns:
            List[str]: 联赛代码列表
        """
        try:
            # 从数据库获取活跃联赛列表
            # 在实际生产环境中，这里会查询数据库获取配置的活跃联赛
            # 目前返回主要联赛作为默认配置
            active_leagues = [
                "PL",  # 英超
                "PD",  # 西甲
                "SA",  # 意甲
                "BL1",  # 德甲
                "FL1",  # 法甲
                "CL",  # 欧冠
                "EL",  # 欧联
            ]

            # 可以通过配置文件或数据库动态调整
            self.logger.info(f"使用活跃联赛列表: {active_leagues}")
            return active_leagues
        except Exception as e:
            self.logger.error(f"Failed to get active leagues: {str(e)}")
            return ["PL", "PD"]  # 默认返回英超和西甲

    async def _load_existing_matches(
        self, date_from: datetime, date_to: datetime
    ) -> None:
        """
        加载已存在的比赛ID（防重复机制）

        Args:
            date_from: 开始日期
            date_to: 结束日期
        """
        try:
            # 查询数据库中已存在的比赛
            # 在实际生产环境中，这里会查询数据库获取指定日期范围内的比赛
            # 目前使用空集合作为占位符，允许重复插入（生产环境需要实现）
            self.logger.info(f"加载 {date_from} 到 {date_to} 的已存在比赛ID")
            self._processed_matches = set()

            # 生产环境实现示例:
            # async with self.db_manager.get_async_session() as session:
            #     query = text("""
            #         SELECT match_id FROM matches
            #         WHERE match_date BETWEEN :date_from AND :date_to
            #     """)
            #     result = await session.execute(query, {"date_from": date_from, "date_to": date_to})
            #     self._processed_matches = {row.match_id for row in result}

        except Exception as e:
            self.logger.error(f"Failed to load existing matches: {str(e)}")
            self._processed_matches = set()

    async def _collect_league_fixtures(
        self, league_code: str, date_from: datetime, date_to: datetime
    ) -> List[Dict[str, Any]]:
        """
        采集指定联赛的赛程数据

        Args:
            league_code: 联赛代码
            date_from: 开始日期
            date_to: 结束日期

        Returns:
            List[Dict]: 赛程数据列表
        """
        try:
            url = f"{self.base_url}/competitions/{league_code}/matches"
            headers = {"X-Auth-Token": self.api_key} if self.api_key else {}

            params = {
                "dateFrom": date_from.strftime("%Y-%m-%d"),
                "dateTo": date_to.strftime("%Y-%m-%d"),
                "status": "SCHEDULED",
            }

            response = await self._make_request(url=url, headers=headers, params=params)

            return response.get("matches", [])

        except Exception as e:
            self.logger.error(
                f"Failed to collect fixtures for league {league_code}: {str(e)}"
            )
            return []

    def _generate_match_key(self, fixture_data: Dict[str, Any]) -> str:
        """
        生成比赛唯一键（防重复）

        Args:
            fixture_data: 比赛原始数据

        Returns:
            str: 比赛唯一键
        """
        # 使用外部ID、主队、客队、比赛时间生成唯一键
        key_components = [
            str(fixture_data.get("id", "")),
            str(fixture_data.get("homeTeam", {}).get("id", "")),
            str(fixture_data.get("awayTeam", {}).get("id", "")),
            str(fixture_data.get("utcDate", "")),
        ]

        key_string = "|".join(key_components)
        return hashlib.md5(key_string.encode(), usedforsecurity=False).hexdigest()

    async def _clean_fixture_data(
        self, raw_fixture: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        清洗和标准化赛程数据

        Args:
            raw_fixture: 原始赛程数据

        Returns:
            Optional[Dict]: 清洗后的数据，无效则返回None
        """
        try:
            # 基础字段验证
            if not all(
                key in raw_fixture for key in ["id", "homeTeam", "awayTeam", "utcDate"]
            ):
                return None

            # 时间标准化为UTC
            match_time = datetime.fromisoformat(
                raw_fixture["utcDate"].replace("Z", "+00:00")
            )

            cleaned_data = {
                "external_match_id": str(raw_fixture["id"]),
                "external_league_id": str(
                    raw_fixture.get("competition", {}).get("id", "")
                ),
                "external_home_team_id": str(raw_fixture["homeTeam"]["id"]),
                "external_away_team_id": str(raw_fixture["awayTeam"]["id"]),
                "match_time": match_time.isoformat(),
                "status": raw_fixture.get("status", "SCHEDULED"),
                "season": raw_fixture.get("season", {}).get("id"),
                "matchday": raw_fixture.get("matchday"),
                "raw_data": raw_fixture,
                "collected_at": datetime.now().isoformat(),
                "processed": False,
            }

            return cleaned_data

        except Exception as e:
            self.logger.error(f"Failed to clean fixture data: {str(e)}")
            return None

    async def _detect_missing_matches(
        self,
        collected_data: List[Dict[str, Any]],
        date_from: datetime,
        date_to: datetime,
    ) -> None:
        """
        检测缺失的比赛（防丢失策略）

        Args:
            collected_data: 本次采集的数据
            date_from: 开始日期
            date_to: 结束日期
        """
        try:
            # TODO: 实现缺失比赛检测逻辑
            # 1. 从数据库查询应该存在的比赛
            # 2. 与本次采集结果比对
            # 3. 标记缺失的比赛
            # 4. 记录到_missing_matches列表

            self.logger.info(
                f"Missing matches detection completed. "
                f"Found {len(self._missing_matches)} missing matches"
            )

        except Exception as e:
            self.logger.error(f"Failed to detect missing matches: {str(e)}")
