"""
ç‰¹å¾ä»“åº“ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è¶³çƒé¢„æµ‹ç³»ç»Ÿçš„ç‰¹å¾ä»“åº“è¿›è¡Œç‰¹å¾å­˜å‚¨ã€æŸ¥è¯¢å’Œæ¨¡å‹è®­ç»ƒã€‚

ä¸»è¦ç¤ºä¾‹ï¼š
- åˆå§‹åŒ–ç‰¹å¾ä»“åº“
- å†™å…¥ç‰¹å¾æ•°æ®
- è·å–åœ¨çº¿ç‰¹å¾ï¼ˆå®æ—¶é¢„æµ‹ï¼‰
- è·å–å†å²ç‰¹å¾ï¼ˆæ¨¡å‹è®­ç»ƒï¼‰
- ç‰¹å¾ç»Ÿè®¡å’Œç®¡ç†

åŸºäº DATA_DESIGN.md ç¬¬6.1èŠ‚ç‰¹å¾ä»“åº“è®¾è®¡ã€‚
"""



    FootballFeatureStore,
    get_feature_store,
    initialize_feature_store,
)

logger = logging.getLogger(__name__)


def example_initialize_feature_store() -> FootballFeatureStore:
    """
    ç¤ºä¾‹ï¼šåˆå§‹åŒ–ç‰¹å¾ä»“åº“

    Returns:
        FootballFeatureStore: ç‰¹å¾ä»“åº“å®ä¾‹
    """
    print("ğŸš€ åˆå§‹åŒ–ç‰¹å¾ä»“åº“...")

    # é…ç½®PostgreSQLç¦»çº¿å­˜å‚¨ - ä½¿ç”¨ç¯å¢ƒå˜é‡
    postgres_config = {
        "host": os.getenv("DB_HOST", "localhost"),
        "port": int(os.getenv("DB_PORT", "5432")),
        "database": os.getenv("DB_NAME", "football_prediction_dev"),
        "user": os.getenv("DB_READER_USER", "football_reader"),
        "password": os.getenv("DB_READER_PASSWORD", ""),
    }

    # é…ç½®Redisåœ¨çº¿å­˜å‚¨
    redis_config = {"connection_string": "redis://localhost:6379/1"}

    # åˆå§‹åŒ–ç‰¹å¾ä»“åº“
    feature_store = initialize_feature_store(
        project_name="football_prediction_demo",
        postgres_config=postgres_config,
        redis_config=redis_config,
    )

    print("âœ… ç‰¹å¾ä»“åº“åˆå§‹åŒ–æˆåŠŸï¼")
    return feature_store


def example_write_team_features(feature_store: FootballFeatureStore) -> None:
    """
    ç¤ºä¾‹ï¼šå†™å…¥çƒé˜Ÿç‰¹å¾æ•°æ®

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹
    """
    print("ğŸ“ å†™å…¥çƒé˜Ÿè¿‘æœŸç»Ÿè®¡ç‰¹å¾...")

    # åˆ›å»ºç¤ºä¾‹çƒé˜Ÿç»Ÿè®¡æ•°æ®
    team_stats_data = [
        {
            "team_id": 1,
            "event_timestamp": datetime(2025, 9, 10),
            "recent_5_wins": 3,
            "recent_5_draws": 1,
            "recent_5_losses": 1,
            "recent_5_goals_for": 8,
            "recent_5_goals_against": 4,
            "recent_5_goal_difference": 4,
            "recent_5_points": 10,
            "recent_5_avg_rating": 7.2,
            "recent_10_wins": 6,
            "recent_10_draws": 2,
            "recent_10_losses": 2,
            "recent_10_goals_for": 15,
            "recent_10_goals_against": 8,
            "recent_10_win_rate": 0.6,
            "home_wins": 8,
            "home_goals_avg": 2.1,
            "away_wins": 4,
            "away_goals_avg": 1.3,
            "team_value_millions": 150.5,
            "avg_player_age": 26.8,
            "league_position": 3,
            "points_per_game": 2.1,
        },
        {
            "team_id": 2,
            "event_timestamp": datetime(2025, 9, 10),
            "recent_5_wins": 2,
            "recent_5_draws": 2,
            "recent_5_losses": 1,
            "recent_5_goals_for": 6,
            "recent_5_goals_against": 5,
            "recent_5_goal_difference": 1,
            "recent_5_points": 8,
            "recent_5_avg_rating": 6.8,
            "recent_10_wins": 5,
            "recent_10_draws": 3,
            "recent_10_losses": 2,
            "recent_10_goals_for": 12,
            "recent_10_goals_against": 10,
            "recent_10_win_rate": 0.5,
            "home_wins": 6,
            "home_goals_avg": 1.8,
            "away_wins": 3,
            "away_goals_avg": 1.1,
            "team_value_millions": 120.3,
            "avg_player_age": 28.2,
            "league_position": 7,
            "points_per_game": 1.7,
        },
    ]

    df = pd.DataFrame(team_stats_data)

    # å†™å…¥ç‰¹å¾æ•°æ®
    feature_store.write_features(feature_view_name="team_recent_stats", df=df)

    print(f"âœ… æˆåŠŸå†™å…¥ {len(df)} æ¡çƒé˜Ÿç»Ÿè®¡ç‰¹å¾ï¼")


def example_write_odds_features(feature_store: FootballFeatureStore) -> None:
    """
    ç¤ºä¾‹ï¼šå†™å…¥èµ”ç‡ç‰¹å¾æ•°æ®

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹
    """
    print("ğŸ“ å†™å…¥èµ”ç‡ç‰¹å¾æ•°æ®...")

    # åˆ›å»ºç¤ºä¾‹èµ”ç‡æ•°æ®
    odds_data = [
        {
            "match_id": 1001,
            "event_timestamp": datetime(2025, 9, 10, 14, 0, 0),
            "home_odds": 1.85,
            "draw_odds": 3.40,
            "away_odds": 4.20,
            "home_implied_prob": 0.541,
            "draw_implied_prob": 0.294,
            "away_implied_prob": 0.238,
            "consensus_home_odds": 1.88,
            "consensus_draw_odds": 3.35,
            "consensus_away_odds": 4.10,
            "home_odds_movement": -0.03,
            "draw_odds_movement": 0.05,
            "away_odds_movement": 0.10,
            "over_under_line": 2.5,
            "over_odds": 1.90,
            "under_odds": 1.95,
            "handicap_line": -0.5,
            "handicap_home_odds": 1.95,
            "handicap_away_odds": 1.90,
            "bookmaker_margin": 0.073,
            "market_efficiency": 0.92,
        },
        {
            "match_id": 1002,
            "event_timestamp": datetime(2025, 9, 10, 16, 30, 0),
            "home_odds": 2.10,
            "draw_odds": 3.20,
            "away_odds": 3.60,
            "home_implied_prob": 0.476,
            "draw_implied_prob": 0.313,
            "away_implied_prob": 0.278,
            "consensus_home_odds": 2.15,
            "consensus_draw_odds": 3.15,
            "consensus_away_odds": 3.55,
            "home_odds_movement": 0.05,
            "draw_odds_movement": -0.05,
            "away_odds_movement": -0.05,
            "over_under_line": 2.5,
            "over_odds": 2.05,
            "under_odds": 1.80,
            "handicap_line": 0.0,
            "handicap_home_odds": 1.85,
            "handicap_away_odds": 2.00,
            "bookmaker_margin": 0.067,
            "market_efficiency": 0.94,
        },
    ]

    df = pd.DataFrame(odds_data)

    # å†™å…¥èµ”ç‡ç‰¹å¾
    feature_store.write_features(feature_view_name="odds_features", df=df)

    print(f"âœ… æˆåŠŸå†™å…¥ {len(df)} æ¡èµ”ç‡ç‰¹å¾ï¼")


def example_get_online_features(feature_store: FootballFeatureStore) -> pd.DataFrame:
    """
    ç¤ºä¾‹ï¼šè·å–åœ¨çº¿ç‰¹å¾ï¼ˆç”¨äºå®æ—¶é¢„æµ‹ï¼‰

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹

    Returns:
        pd.DataFrame: åœ¨çº¿ç‰¹å¾æ•°æ®
    """
    print("ğŸ” è·å–åœ¨çº¿ç‰¹å¾æ•°æ®...")

    # æ„å»ºå®ä½“æ•°æ®ï¼ˆè¦é¢„æµ‹çš„æ¯”èµ›ï¼‰
    entity_data = [{"match_id": 1001}, {"match_id": 1002}]
    entity_df = pd.DataFrame(entity_data)

    # è·å–å®æ—¶é¢„æµ‹ç‰¹å¾
    features_df = feature_store.get_online_features(
        feature_service_name="real_time_prediction_v1", entity_df=entity_df
    )

    print("âœ… æˆåŠŸè·å–åœ¨çº¿ç‰¹å¾ï¼")
    print("\nğŸ“Š åœ¨çº¿ç‰¹å¾æ•°æ®é¢„è§ˆï¼š")
    print(features_df.head())

    return features_df


def example_get_historical_features(
    feature_store: FootballFeatureStore,
) -> pd.DataFrame:
    """
    ç¤ºä¾‹ï¼šè·å–å†å²ç‰¹å¾ï¼ˆç”¨äºæ¨¡å‹è®­ç»ƒï¼‰

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹

    Returns:
        pd.DataFrame: å†å²ç‰¹å¾æ•°æ®
    """
    print("ğŸ“ˆ è·å–å†å²ç‰¹å¾æ•°æ®...")

    # æ„å»ºè®­ç»ƒæ•°æ®å®ä½“ï¼ˆå†å²æ¯”èµ›ï¼‰
    training_entities = []
    base_date = datetime(2025, 8, 1)

    for i in range(10):  # 10åœºå†å²æ¯”èµ›
        training_entities.append(
            {"match_id": 2000 + i, "event_timestamp": base_date + timedelta(days=i * 3)}
        )

    entity_df = pd.DataFrame(training_entities)

    # è·å–å®Œæ•´çš„æ¯”èµ›é¢„æµ‹ç‰¹å¾
    training_df = feature_store.get_historical_features(
        feature_service_name="match_prediction_v1",
        entity_df=entity_df,
        full_feature_names=True,
    )

    print("âœ… æˆåŠŸè·å–å†å²ç‰¹å¾ï¼")
    print(f"\nğŸ“Š è®­ç»ƒæ•°æ®é›†å¤§å°: {training_df.shape}")
    print("\nğŸ” ç‰¹å¾åˆ—é¢„è§ˆï¼š")
    print(list(training_df.columns))

    return training_df


def example_create_training_dataset(
    feature_store: FootballFeatureStore,
) -> pd.DataFrame:
    """
    ç¤ºä¾‹ï¼šåˆ›å»ºæœºå™¨å­¦ä¹ è®­ç»ƒæ•°æ®é›†

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹

    Returns:
        pd.DataFrame: è®­ç»ƒæ•°æ®é›†
    """
    print("ğŸ¯ åˆ›å»ºæœºå™¨å­¦ä¹ è®­ç»ƒæ•°æ®é›†...")

    # æŒ‡å®šè®­ç»ƒæ•°æ®çš„æ—¶é—´èŒƒå›´
    start_date = datetime(2025, 7, 1)
    end_date = datetime(2025, 9, 1)

    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
    training_df = feature_store.create_training_dataset(
        start_date=start_date, end_date=end_date
    )

    print("âœ… è®­ç»ƒæ•°æ®é›†åˆ›å»ºæˆåŠŸï¼")
    print(f"ğŸ“Š æ•°æ®é›†åŒ…å« {len(training_df)} æ¡è®°å½•")
    print(f"ğŸ”¢ ç‰¹å¾æ•°é‡: {len(training_df.columns)}")

    return training_df


def example_feature_statistics(feature_store: FootballFeatureStore) -> None:
    """
    ç¤ºä¾‹ï¼šè·å–ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹
    """
    print("ğŸ“Š è·å–ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯...")

    # è·å–ä¸åŒç‰¹å¾è§†å›¾çš„ç»Ÿè®¡
    feature_views = ["team_recent_stats", "odds_features", "match_features"]

    for fv_name in feature_views:
        try:
            stats = feature_store.get_feature_statistics(fv_name)
            print(f"\nğŸ” ç‰¹å¾è§†å›¾: {fv_name}")
            print(f"  ğŸ“ˆ ç‰¹å¾æ•°é‡: {stats.get(str('num_features'), 'N/A')}")
            print(f"  ğŸ·ï¸  å®ä½“: {', '.join(stats.get(str('entities'), []))}")
            print(f"  â° TTL: {stats.get(str('ttl_days'), 'N/A')} å¤©")
            print(f"  ğŸ·ï¸  æ ‡ç­¾: {stats.get(str('tags'), {})}")
        except Exception as e:
            print(f"âŒ è·å– {fv_name} ç»Ÿè®¡å¤±è´¥: {str(e)}")


def example_list_all_features(feature_store: FootballFeatureStore) -> None:
    """
    ç¤ºä¾‹ï¼šåˆ—å‡ºæ‰€æœ‰ç‰¹å¾

    Args:
        feature_store: ç‰¹å¾ä»“åº“å®ä¾‹
    """
    print("ğŸ“‹ åˆ—å‡ºæ‰€æœ‰ç‰¹å¾...")

    features_list = feature_store.list_features()

    if features_list:
        print(f"âœ… å‘ç° {len(features_list)} ä¸ªç‰¹å¾ï¼š\n")

        for i, feature in enumerate(features_list[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(
                f"{i+1:2d}. {feature['feature_view']:20s} | {feature['feature_name']:25s} | {feature['feature_type']}"
            )

        if len(features_list) > 10:
            print(f"    ... è¿˜æœ‰ {len(features_list) - 10} ä¸ªç‰¹å¾")
    else:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç‰¹å¾")


async def run_complete_example() -> None:
    """
    è¿è¡Œå®Œæ•´çš„ç‰¹å¾ä»“åº“ç¤ºä¾‹
    """
    print("ğŸŒŸ è¶³çƒç‰¹å¾ä»“åº“å®Œæ•´ç¤ºä¾‹")
    print("=" * 50)

    try:
        # 1. åˆå§‹åŒ–ç‰¹å¾ä»“åº“
        feature_store = example_initialize_feature_store()

        # 2. å†™å…¥ç‰¹å¾æ•°æ®
        example_write_team_features(feature_store)
        example_write_odds_features(feature_store)

        print("\n" + "=" * 50)

        # 3. è·å–åœ¨çº¿ç‰¹å¾ï¼ˆå®æ—¶é¢„æµ‹åœºæ™¯ï¼‰
        example_get_online_features(feature_store)

        print("\n" + "=" * 50)

        # 4. è·å–å†å²ç‰¹å¾ï¼ˆæ¨¡å‹è®­ç»ƒåœºæ™¯ï¼‰
        example_get_historical_features(feature_store)

        print("\n" + "=" * 50)

        # 5. åˆ›å»ºè®­ç»ƒæ•°æ®é›†
        example_create_training_dataset(feature_store)

        print("\n" + "=" * 50)

        # 6. ç‰¹å¾ç®¡ç†å’Œç»Ÿè®¡
        example_feature_statistics(feature_store)
        example_list_all_features(feature_store)

        print("\n" + "=" * 50)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")

        # 7. æ¸…ç†èµ„æº
        feature_store.close()
        print("ğŸ”’ èµ„æºæ¸…ç†å®Œæˆ")

    except Exception as e:
        print(f"âŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")
        logger.error(f"Feature store example failed: {str(e)}", exc_info=True)


def example_integration_with_ml_pipeline() -> Dict[str, Any]:
    """
    ç¤ºä¾‹ï¼šä¸æœºå™¨å­¦ä¹ æµæ°´çº¿é›†æˆ

    å±•ç¤ºå¦‚ä½•åœ¨MLè®­ç»ƒå’Œé¢„æµ‹æµç¨‹ä¸­ä½¿ç”¨ç‰¹å¾ä»“åº“ã€‚

    Returns:
        Dict: é›†æˆç¤ºä¾‹ç»“æœ
    """
    print("ğŸ¤– ç‰¹å¾ä»“åº“ä¸MLæµæ°´çº¿é›†æˆç¤ºä¾‹...")

    # æ¨¡æ‹ŸMLè®­ç»ƒæµç¨‹
    def train_model_with_features():
        """æ¨¡æ‹Ÿæ¨¡å‹è®­ç»ƒ"""
        print("  ğŸ¯ ä½¿ç”¨ç‰¹å¾ä»“åº“æ•°æ®è®­ç»ƒæ¨¡å‹...")

        # è·å–ç‰¹å¾ä»“åº“å®ä¾‹
        feature_store = get_feature_store()

        # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
        training_df = feature_store.create_training_dataset(
            start_date=datetime(2025, 6, 1), end_date=datetime(2025, 8, 31)
        )

        print(f"  ğŸ“Š è®­ç»ƒæ•°æ®: {len(training_df)} æ¡è®°å½•")
        return {"model_trained": True, "training_samples": len(training_df)}

    # æ¨¡æ‹Ÿå®æ—¶é¢„æµ‹æµç¨‹
    def predict_with_online_features():
        """æ¨¡æ‹Ÿå®æ—¶é¢„æµ‹"""
        print("  ğŸ”® ä½¿ç”¨åœ¨çº¿ç‰¹å¾è¿›è¡Œå®æ—¶é¢„æµ‹...")

        feature_store = get_feature_store()

        # æ„å»ºé¢„æµ‹è¯·æ±‚
        prediction_entities = pd.DataFrame([{"match_id": 3001}, {"match_id": 3002}])




        # è·å–å®æ—¶ç‰¹å¾
        features_df = feature_store.get_online_features(
            feature_service_name="real_time_prediction_v1",
            entity_df=prediction_entities,
        )

        print(f"  ğŸ“ˆ é¢„æµ‹ç‰¹å¾: {len(features_df)} æ¡è®°å½•")
        return {"predictions_made": len(features_df)}

    # æ‰§è¡Œé›†æˆç¤ºä¾‹
    results = {
        "training_result": train_model_with_features(),
        "prediction_result": predict_with_online_features(),
        "integration_status": "success",
    }

    print("âœ… MLæµæ°´çº¿é›†æˆç¤ºä¾‹å®Œæˆï¼")
    return results


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œå®Œæ•´ç¤ºä¾‹
    asyncio.run(run_complete_example())

    # è¿è¡ŒMLé›†æˆç¤ºä¾‹
    ml_results = example_integration_with_ml_pipeline()
    print(f"\nğŸ‰ MLé›†æˆç»“æœ: {ml_results}")