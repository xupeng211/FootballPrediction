#!/usr/bin/env python3
"""
æ™ºèƒ½Flaky Testæ£€æµ‹å™¨ - åŸºäºå†å²æ•°æ®å’Œé€‰æ‹©æ€§æ£€æµ‹ï¼Œé¿å…è¯¯æŠ¥å’Œæ€§èƒ½å¼€é”€
"""

import subprocess
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional, Set
from dataclasses import dataclass
from collections import defaultdict
import re

logger = logging.getLogger(__name__)

@dataclass
class FlakyDetectionConfig:
    """Flakyæ£€æµ‹é…ç½®"""
    # é€‰æ‹©æ€§æ£€æµ‹ï¼šåªæ£€æµ‹å…³é”®æµ‹è¯•æ–‡ä»¶
    target_test_patterns: List[str] = None

    # è¿è¡Œæ§åˆ¶
    max_runs: int = 3  # å‡å°‘åˆ°3æ¬¡ï¼Œé™ä½å¼€é”€
    timeout_per_run: int = 60  # å•æ¬¡è¿è¡Œè¶…æ—¶
    total_timeout: int = 300    # æ€»è¶…æ—¶æ§åˆ¶

    # å¤–éƒ¨ä¾èµ–æ ‡è®°
    external_service_patterns: Set[str] = None

    # å†å²æ•°æ®è¦æ±‚
    min_historical_runs: int = 3  # è‡³å°‘3æ¬¡å†å²æ•°æ®æ‰åˆ¤å®š

    def __post_init__(self):
        if self.target_test_patterns is None:
            self.target_test_patterns = [
                "tests/test_data_*.py",
                "tests/test_models_*.py",
                "tests/test_services_*.py"
            ]
        if self.external_service_patterns is None:
            self.external_service_patterns = {
                "test_.*database.*",
                "test_.*kafka.*",
                "test_.*redis.*",
                "test_.*api.*",
                "test_.*external.*"
            }

class SmartFlakyTestDetector:
    """æ™ºèƒ½Flaky Testæ£€æµ‹å™¨"""

    def __init__(self, config: Optional[FlakyDetectionConfig] = None):
        self.config = config or FlakyDetectionConfig()
        self.results_dir = Path("docs/_reports/flaky")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        self.history_file = self.results_dir / "test_history.json"
        self.flaky_database = self.results_dir / "flaky_database.json"

    def load_test_history(self) -> Dict:
        """åŠ è½½æµ‹è¯•å†å²æ•°æ®"""
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Failed to load test history: {e}")

        return {}

    def save_test_history(self, history: Dict):
        """ä¿å­˜æµ‹è¯•å†å²æ•°æ®"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Failed to save test history: {e}")

    def get_target_test_files(self) -> List[str]:
        """è·å–ç›®æ ‡æµ‹è¯•æ–‡ä»¶"""
        target_files = []

        # ä½¿ç”¨globåŒ¹é…ç›®æ ‡æµ‹è¯•æ–‡ä»¶
        import glob
        for pattern in self.config.target_test_patterns:
            target_files.extend(glob.glob(pattern))

        # å»é‡å¹¶è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        return list(set(f for f in target_files if Path(f).exists()))

    def is_external_service_test(self, test_file: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¤–éƒ¨æœåŠ¡æµ‹è¯•"""
        filename = Path(test_file).name.lower()
        for pattern in self.config.external_service_patterns:
            if re.match(pattern, filename):
                return True
        return False

    def run_test_multiple_times(self, test_path: str) -> Dict:
        """å¤šæ¬¡è¿è¡Œå•ä¸ªæµ‹è¯•"""
        results = {
            "test_path": test_path,
            "runs": [],
            "passed": 0,
            "failed": 0,
            "execution_times": [],
            "is_flaky": False,
            "is_external_test": self.is_external_service_test(test_path)
        }

        logger.info(f"Running test {test_path} {self.config.max_runs} times...")

        for run in range(self.config.max_runs):
            try:
                start_time = time.time()

                # è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶
                result = subprocess.run(
                    ["python", "-m", "pytest", test_path, "--tb=short", "-v"],
                    capture_output=True,
                    text=True,
                    timeout=self.config.timeout_per_run,
                    cwd="."
                )

                execution_time = time.time() - start_time

                run_result = {
                    "run_number": run + 1,
                    "return_code": result.returncode,
                    "execution_time": execution_time,
                    "passed": result.returncode == 0,
                    "stdout": result.stdout[:1000],  # æˆªæ–­é•¿è¾“å‡º
                    "stderr": result.stderr[:1000]
                }

                results["runs"].append(run_result)
                results["execution_times"].append(execution_time)

                if result.returncode == 0:
                    results["passed"] += 1
                else:
                    results["failed"] += 1

            except subprocess.TimeoutExpired:
                logger.warning(f"Test {test_path} timed out on run {run + 1}")
                results["runs"].append({
                    "run_number": run + 1,
                    "error": "TIMEOUT",
                    "execution_time": self.config.timeout_per_run,
                    "passed": False
                })
                results["failed"] += 1
                results["execution_times"].append(self.config.timeout_per_run)

            except Exception as e:
                logger.error(f"Test {test_path} failed on run {run + 1}: {e}")
                results["runs"].append({
                    "run_number": run + 1,
                    "error": str(e),
                    "execution_time": 0,
                    "passed": False
                })
                results["failed"] += 1
                results["execution_times"].append(0)

        # åŸºäºå¤šæ¬¡è¿è¡Œç»“æœåˆ¤æ–­æ˜¯å¦ä¸ºflaky
        results["is_flaky"] = self._is_flaky_based_on_results(results)

        return results

    def _is_flaky_based_on_results(self, results: Dict) -> bool:
        """åŸºäºè¿è¡Œç»“æœåˆ¤æ–­æ˜¯å¦ä¸ºflaky"""
        # å¤–éƒ¨æœåŠ¡æµ‹è¯•ä¸è®¡å…¥ä¸»flakyæŒ‡æ ‡
        if results.get("is_external_test", False):
            return False

        passed = results["passed"]
        failed = results["failed"]
        total_runs = len(results["runs"])

        # å¦‚æœæœ‰æˆåŠŸä¹Ÿæœ‰å¤±è´¥ï¼Œåˆ™ä¸ºflaky
        if passed > 0 and failed > 0:
            return True

        # å¦‚æœæ‰€æœ‰è¿è¡Œéƒ½å¤±è´¥ï¼Œä½†æ‰§è¡Œæ—¶é—´å·®å¼‚å¾ˆå¤§ï¼Œä¹Ÿå¯èƒ½æ˜¯flaky
        if failed == total_runs and total_runs > 1:
            times = results["execution_times"]
            if max(times) > min(times) * 2:  # æ‰§è¡Œæ—¶é—´å·®å¼‚è¶…è¿‡2å€
                return True

        return False

    def detect_flaky_tests(self, incremental: bool = True) -> Dict:
        """æ£€æµ‹Flakyæµ‹è¯•"""
        start_time = time.time()

        # è·å–ç›®æ ‡æµ‹è¯•æ–‡ä»¶
        target_files = self.get_target_test_files()

        # åŠ è½½å†å²æ•°æ®
        history = self.load_test_history()

        # æ‰§è¡Œæ£€æµ‹
        flaky_results = []
        detection_summary = {
            "total_tests": len(target_files),
            "flaky_tests": 0,
            "external_tests": 0,
            "execution_time": 0,
            "detection_mode": "incremental" if incremental else "full"
        }

        for i, test_file in enumerate(target_files):
            logger.info(f"Processing test {i+1}/{len(target_files)}: {test_file}")

            # æ£€æŸ¥è¶…æ—¶
            if time.time() - start_time > self.config.total_timeout:
                logger.warning(f"Flaky detection timed out after {self.config.total_timeout}s")
                detection_summary["timeout"] = True
                break

            # è·³è¿‡å¤–éƒ¨æœåŠ¡æµ‹è¯•ï¼ˆå•ç‹¬æ ‡è®°ï¼‰
            if self.is_external_service_test(test_file):
                detection_summary["external_tests"] += 1
                continue

            # è¿è¡Œå¤šæ¬¡æ£€æµ‹
            test_results = self.run_test_multiple_times(test_file)

            # æ›´æ–°å†å²æ•°æ®
            if test_file not in history:
                history[test_file] = []
            history[test_file].append({
                "timestamp": time.time(),
                "results": test_results
            })

            # å¦‚æœæ˜¯flakyä¸”æ»¡è¶³å†å²æ•°æ®è¦æ±‚ï¼Œåˆ™è®°å½•
            if test_results["is_flaky"]:
                historical_runs = len(history[test_file])
                if historical_runs >= self.config.min_historical_runs:
                    # æ£€æŸ¥å†å²ä¸€è‡´æ€§
                    flaky_consistency = self._check_flaky_consistency(history[test_file])
                    if flaky_consistency >= 0.5:  # 50%ä»¥ä¸Šçš„å†å²è¿è¡Œéƒ½æ˜¯flaky
                        flaky_results.append(test_results)
                        detection_summary["flaky_tests"] += 1
                        logger.warning(f"Confirmed flaky test: {test_file}")
                else:
                    logger.info(f"Potential flaky test (needs more data): {test_file}")

        # ä¿å­˜å†å²æ•°æ®
        self.save_test_history(history)

        # ä¿å­˜ç»“æœ
        detection_summary["execution_time"] = time.time() - start_time
        final_results = {
            "summary": detection_summary,
            "flaky_tests": flaky_results,
            "timestamp": time.time()
        }

        self._save_flaky_results(final_results)

        return final_results

    def _check_flaky_consistency(self, history: List[Dict]) -> float:
        """æ£€æŸ¥flakyä¸€è‡´æ€§"""
        if not history:
            return 0.0

        flaky_count = sum(1 for record in history if record["results"]["is_flaky"])
        return flaky_count / len(history)

    def _save_flaky_results(self, results: Dict):
        """ä¿å­˜flakyæ£€æµ‹ç»“æœ"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        result_file = self.results_dir / f"flaky_results_{timestamp}.json"

        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        # æ›´æ–°æœ€æ–°ç»“æœ
        latest_file = self.results_dir / "latest_flaky_results.json"
        with open(latest_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        logger.info(f"Flaky detection results saved to {result_file}")

    def generate_flaky_report(self) -> str:
        """ç”ŸæˆFlakyæµ‹è¯•æŠ¥å‘Š"""
        latest_file = self.results_dir / "latest_flaky_results.json"
        if not latest_file.exists():
            return "No flaky test detection results available"

        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                results = json.load(f)

            summary = results["summary"]

            report = f"""
## ğŸ”„ Flaky Test æ£€æµ‹ç»“æœ

### æ‰§è¡Œä¿¡æ¯
- **æ£€æµ‹æ¨¡å¼**: {summary.get('detection_mode', 'unknown')}
- **æ‰§è¡Œæ—¶é—´**: {summary.get('execution_time', 0):.1f}ç§’
- **æ€»æµ‹è¯•æ•°**: {summary.get('total_tests', 0)}
- **è¶…æ—¶è®¾ç½®**: {self.config.total_timeout}ç§’

### æ£€æµ‹ç»“æœ
- **Flakyæµ‹è¯•**: {summary.get('flaky_tests', 0)}ä¸ª âš ï¸
- **å¤–éƒ¨æœåŠ¡æµ‹è¯•**: {summary.get('external_tests', 0)}ä¸ª ğŸ”Œ
- **ç¨³å®šæµ‹è¯•**: {summary.get('total_tests', 0) - summary.get('flaky_tests', 0) - summary.get('external_tests', 0)}ä¸ª âœ…

### é£é™©è¯„ä¼°
- **æ£€æµ‹è¦†ç›–ç‡**: {(summary.get('total_tests', 0) / max(len(self.get_target_test_files()), 1) * 100):.1f}%
- **Flakyæ¯”ä¾‹**: {(summary.get('flaky_tests', 0) / max(summary.get('total_tests', 0), 1) * 100):.1f}%
"""

            if summary.get('timeout', False):
                report += "- **æ‰§è¡Œè¶…æ—¶**: éƒ¨åˆ†æµ‹è¯•å› è¶…æ—¶æœªå®Œæˆæ£€æµ‹ â°\n"

            # æ·»åŠ å…·ä½“flakyæµ‹è¯•ä¿¡æ¯
            if results.get("flaky_tests"):
                report += "\n### ğŸš¨ å…·ä½“Flakyæµ‹è¯•\n"
                for flaky_test in results["flaky_tests"]:
                    test_path = flaky_test["test_path"]
                    failed_runs = flaky_test["failed"]
                    total_runs = len(flaky_test["runs"])
                    avg_time = sum(flaky_test["execution_times"]) / total_runs

                    report += f"- **{test_path}**: {failed_runs}/{total_runs}æ¬¡å¤±è´¥ï¼Œå¹³å‡æ‰§è¡Œæ—¶é—´{avg_time:.1f}ç§’\n"

            report += f"""
### æ”¹è¿›å»ºè®®
{self._generate_flaky_recommendations(summary)}

### ç¯å¢ƒè¯´æ˜
- **æ£€æµ‹é…ç½®**: {self.config.max_runs}æ¬¡è¿è¡Œï¼Œè¦æ±‚{self.config.min_historical_runs}æ¬¡å†å²æ•°æ®
- **å¤–éƒ¨æœåŠ¡æµ‹è¯•**: å·²å•ç‹¬æ ‡è®°ï¼Œä¸è®¡å…¥ä¸»è¦flakyæŒ‡æ ‡
- **è¶…æ—¶æ§åˆ¶**: å•æ¬¡{self.config.timeout_per_run}ç§’ï¼Œæ€»{self.config.total_timeout}ç§’
"""
            return report

        except Exception as e:
            logger.error(f"Failed to generate flaky report: {e}")
            return "Failed to generate flaky report"

    def _generate_flaky_recommendations(self, summary: Dict) -> str:
        """ç”ŸæˆFlakyæµ‹è¯•æ”¹è¿›å»ºè®®"""
        flaky_count = summary.get('flaky_tests', 0)
        total_tests = summary.get('total_tests', 0)

        if flaky_count == 0:
            return "âœ… æœªæ£€æµ‹åˆ°Flakyæµ‹è¯•ï¼Œæµ‹è¯•ç¨³å®šæ€§è‰¯å¥½"
        elif flaky_count <= 2:
            return f"âš ï¸ å‘ç°{flaky_count}ä¸ªFlakyæµ‹è¯•ï¼Œå»ºè®®ä¼˜åŒ–æµ‹è¯•é€»è¾‘ï¼Œæ·»åŠ é€‚å½“çš„ç­‰å¾…æˆ–é‡è¯•æœºåˆ¶"
        else:
            return f"ğŸš¨ å‘ç°{flaky_count}ä¸ªFlakyæµ‹è¯•ï¼Œå æ¯”{(flaky_count/total_tests*100):.1f}%ï¼Œå»ºè®®ä¼˜å…ˆä¿®å¤è¿™äº›æµ‹è¯•çš„ä¸ç¨³å®šæ€§"


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    import argparse

    parser = argparse.ArgumentParser(description="Smart Flaky Test Detection")
    parser.add_argument("--incremental", action="store_true", default=True,
                       help="Run incremental flaky detection (default)")
    parser.add_argument("--full", action="store_true",
                       help="Run full flaky detection")
    parser.add_argument("--report-only", action="store_true",
                       help="Only show flaky test report")

    args = parser.parse_args()

    detector = SmartFlakyTestDetector()

    if args.report_only:
        print(detector.generate_flaky_report())
        return

    incremental_mode = args.incremental and not args.full
    results = detector.detect_flaky_tests(incremental=incremental_mode)

    print(detector.generate_flaky_report())


if __name__ == "__main__":
    main()