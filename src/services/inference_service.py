"""è¶³çƒé¢„æµ‹æ¨ç†æœåŠ¡
Football Prediction Inference Service.

æä¾›åŸºäºXGBoostæ¨¡å‹çš„å®æ—¶æ¨ç†æœåŠ¡ï¼ŒåŒ…æ‹¬ï¼š
- æ¨¡å‹åŠ è½½å’Œç®¡ç†
- ç‰¹å¾æå–å’Œé¢„å¤„ç†
- é¢„æµ‹ç»“æœç”Ÿæˆ
"""

import json
import logging
import os
import pandas as pd
from pathlib import Path
from typing import Optional

# å°è¯•å¯¼å…¥XGBoostï¼Œå¦‚æœå¤±è´¥åˆ™è¿è¡Œåœ¨Mockæ¨¡å¼
try:
    import xgboost as xgb

    HAVE_XGBOOST = True
except ImportError:
    HAVE_XGBOOST = False
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ XGBoost not found. Inference service running in MOCK mode.")

logger = logging.getLogger(__name__)


class InferenceService:
    """è¶³çƒé¢„æµ‹æ¨ç†æœåŠ¡å•ä¾‹ç±»."""

    _instance = None
    _model = None
    _model_metadata = None
    _feature_data = None
    _feature_columns = None

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼å®ç°."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–æ¨ç†æœåŠ¡."""
        if not hasattr(self, "_initialized"):
            self._initialized = False
            self._load_model()
            self._load_feature_data()
            self._initialized = True
            logger.info("âœ… æ¨ç†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„XGBoostæ¨¡å‹."""
        if not HAVE_XGBOOST:
            logger.warning("âš ï¸ XGBoostä¸å¯ç”¨ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½ï¼Œä½¿ç”¨Mockæ¨¡å¼")
            self._model = None
            self._model_metadata = {
                "model_version": "mock_v1",
                "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
            }
            self._feature_columns = [
                "home_team_id",
                "away_team_id",
                "home_last_5_points",
                "away_last_5_points",
                "home_last_5_avg_goals",
                "away_last_5_avg_goals",
                "h2h_last_3_home_wins",
                "home_last_5_goal_diff",
                "away_last_5_goal_diff",
                "home_win_streak",
                "away_win_streak",
                "home_last_5_win_rate",
                "away_last_5_win_rate",
                "home_rest_days",
                "away_rest_days",
            ]
            return

        try:
            # å°è¯•åŠ è½½PKLæ ¼å¼çš„æ¨¡å‹ï¼ˆä¼˜å…ˆï¼‰
            pkl_model_path = Path("models/football_xgboost_v2_best.pkl")
            json_model_path = Path("models/football_model_v1.json")
            metadata_path = Path("models/football_model_v1_metadata.json")

            # ä¼˜å…ˆä½¿ç”¨PKLæ ¼å¼çš„æ¨¡å‹
            if pkl_model_path.exists():
                logger.info(f"ğŸ”„ åŠ è½½PKLæ ¼å¼æ¨¡å‹: {pkl_model_path}")
                import joblib

                self._model = joblib.load(pkl_model_path)
                logger.info("âœ… XGBoost PKLæ¨¡å‹åŠ è½½æˆåŠŸ")

                # å°è¯•åŠ è½½JSONæ ¼å¼çš„å…ƒæ•°æ®
                if metadata_path.exists():
                    with open(metadata_path, encoding="utf-8") as f:
                        self._model_metadata = json.load(f)
                    logger.info("âœ… æ¨¡å‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
                else:
                    # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
                    self._model_metadata = {
                        "model_version": "v2_best",
                        "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
                        "model_type": "xgboost_v2",
                    }
                    logger.warning("âš ï¸ ä½¿ç”¨é»˜è®¤æ¨¡å‹å…ƒæ•°æ®")

            elif json_model_path.exists():
                logger.info(f"ğŸ”„ åŠ è½½JSONæ ¼å¼æ¨¡å‹: {json_model_path}")
                self._model = xgb.XGBClassifier()
                self._model.load_model(str(json_model_path))
                logger.info("âœ… XGBoost JSONæ¨¡å‹åŠ è½½æˆåŠŸ")

                # åŠ è½½æ¨¡å‹å…ƒæ•°æ®
                if not metadata_path.exists():
                    raise FileNotFoundError(f"æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_path}")
                with open(metadata_path, encoding="utf-8") as f:
                    self._model_metadata = json.load(f)
                logger.info("âœ… æ¨¡å‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
            else:
                raise FileNotFoundError("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")

            # å¼ºåˆ¶ä½¿ç”¨æ­£ç¡®çš„ç‰¹å¾åç§°ï¼ˆåŸºäºå®é™…æ¨¡å‹çš„feature_namesï¼‰
            actual_feature_names = (
                self._model.get_booster().feature_names
                if hasattr(self._model.get_booster(), "feature_names")
                else None
            )
            if actual_feature_names:
                self._feature_columns = actual_feature_names
                logger.info(f"âœ… ä½¿ç”¨æ¨¡å‹å®é™…çš„ç‰¹å¾åç§°: {self._feature_columns}")
            else:
                self._feature_columns = [
                    "feature_0",
                    "feature_1",
                    "feature_2",
                    "feature_3",
                    "feature_4",
                ]
                logger.warning(
                    f"âš ï¸ æ— æ³•è·å–æ¨¡å‹ç‰¹å¾åç§°ï¼Œä½¿ç”¨é»˜è®¤å€¼: {self._feature_columns}"
                )

            logger.info(
                f"âœ… æ¨¡å‹è®¾ç½®å®Œæˆï¼Œç‰¹å¾åˆ—: {len(self._feature_columns)}, æ¨¡å‹ç‰ˆæœ¬: {self._model_metadata.get('model_version', 'unknown')}"
            )

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # é™çº§åˆ°Mockæ¨¡å¼
            logger.warning("ğŸ”„ é™çº§åˆ°Mockæ¨¡å¼")
            self._model = None
            self._model_metadata = {
                "model_version": "mock_v1",
                "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
            }
            self._feature_columns = [
                "home_team_id",
                "away_team_id",
                "home_last_5_points",
                "away_last_5_points",
                "home_last_5_avg_goals",
                "away_last_5_avg_goals",
                "h2h_last_3_home_wins",
                "home_last_5_goal_diff",
                "away_last_5_goal_diff",
                "home_win_streak",
                "away_win_streak",
                "home_last_5_win_rate",
                "away_last_5_win_rate",
                "home_rest_days",
                "away_rest_days",
            ]

    def _load_feature_data(self):
        """åŠ è½½ç‰¹å¾æ•°æ®ç”¨äºæ¨ç†."""
        try:
            dataset_path = Path("data/dataset_v1.csv")

            if not dataset_path.exists():
                logger.warning(f"âš ï¸ ç‰¹å¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
                self._feature_data = pd.DataFrame()
                return

            # åŠ è½½ç‰¹å¾æ•°æ®
            self._feature_data = pd.read_csv(dataset_path)

            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
            if "match_date" in self._feature_data.columns:
                self._feature_data["match_date"] = pd.to_datetime(
                    self._feature_data["match_date"]
                )

            logger.info(f"âœ… ç‰¹å¾æ•°æ®åŠ è½½æˆåŠŸ: {len(self._feature_data)} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾æ•°æ®åŠ è½½å¤±è´¥: {e}")
            self._feature_data = pd.DataFrame()

    async def _get_features_for_match(self, match_id: int) -> dict | None:
        """æ ¹æ®æ¯”èµ›IDä»æ•°æ®åº“è·å–ç‰¹å¾æ•°æ®.

        Args:
            match_id: æ¯”èµ›ID

        Returns:
            ç‰¹å¾æ•°æ®å­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        try:
            logger.info(f"ğŸ” Fetching features from DB for match {match_id}")

            # å¯¼å…¥æ•°æ®åº“è¿æ¥ç®¡ç†å™¨
            from src.database.connection import DatabaseManager

            # è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
            db_manager = DatabaseManager()

            # ç¡®ä¿æ•°æ®åº“ç®¡ç†å™¨å·²åˆå§‹åŒ–
            if not hasattr(db_manager, "_initialized") or not db_manager._initialized:
                from src.config.settings import get_settings

                settings = get_settings()
                db_manager.initialize(
                    database_url=settings.database_url,
                    pool_size=settings.db_pool_size,
                    max_overflow=settings.db_max_overflow,
                    pool_timeout=settings.db_pool_timeout,
                )

            # ä½¿ç”¨å¼‚æ­¥ä¼šè¯æŸ¥è¯¢æ•°æ®åº“
            async with db_manager.get_async_session() as session:
                from sqlalchemy import text

                # æ‰§è¡ŒSQLæŸ¥è¯¢
                result = await session.execute(
                    text(
                        "SELECT feature_data FROM features WHERE match_id = :match_id"
                    ),
                    {"match_id": match_id},
                )
                row = result.first()

                if row and row[0]:  # feature_data å­˜åœ¨
                    # row[0] æ˜¯JSONBå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                    features_dict = row[0]
                    logger.info(
                        f"âœ… Successfully fetched features for match {match_id}: {len(features_dict)} features"
                    )
                    return features_dict
                else:
                    logger.warning(f"âš ï¸ No features found for match {match_id}")
                    return None

        except Exception as e:
            logger.error(f"âŒ è·å–ç‰¹å¾å¤±è´¥ (match_id={match_id}): {e}")
            return self._get_default_features()

    def _get_default_features(self) -> dict:
        """è·å–é»˜è®¤ç‰¹å¾æ•°æ®."""
        return {
            "home_team_id": 1,
            "away_team_id": 2,
            "home_last_5_points": 6,
            "away_last_5_points": 7,
            "home_last_5_avg_goals": 1.4,
            "away_last_5_avg_goals": 1.5,
            "h2h_last_3_home_wins": 1,
            "home_last_5_goal_diff": 0,
            "away_last_5_goal_diff": 0,
            "home_win_streak": 0,
            "away_win_streak": 0,
            "home_last_5_win_rate": 0.37,
            "away_last_5_win_rate": 0.38,
            "home_rest_days": 7,
            "away_rest_days": 7,
        }

    async def predict_match(self, match_id: int) -> dict:
        """å¯¹æŒ‡å®šæ¯”èµ›è¿›è¡Œé¢„æµ‹.

        Args:
            match_id: æ¯”èµ›ID

        Returns:
            åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        # å¦‚æœXGBoostä¸å¯ç”¨ï¼Œè¿”å›Mockæ•°æ®
        if not HAVE_XGBOOST:
            logger.info(f"ğŸ”® Mockæ¨¡å¼é¢„æµ‹æ¯”èµ› {match_id}")
            return {
                "match_id": match_id,
                "prediction": "home_win",
                "confidence": 0.60,
                "home_win_prob": 0.6,
                "draw_prob": 0.2,
                "away_win_prob": 0.2,
                "status": "mock_data",
                "note": "XGBoost not installed (Docker lightweight mode)",
                "success": True,
                "model_version": "mock_v1",
                "suggestion": "Mockæ¨¡å¼é¢„æµ‹ï¼Œä¸»é˜Ÿèƒœï¼Œç½®ä¿¡åº¦ä¸­ç­‰(60%)",
            }

        try:
            logger.info(f"ğŸ”® å¼€å§‹é¢„æµ‹æ¯”èµ› {match_id}")

            # è·å–ç‰¹å¾æ•°æ®
            features = await self._get_features_for_match(match_id)
            if features is None:
                return {
                    "match_id": match_id,
                    "error": "æ— æ³•è·å–æ¯”èµ›ç‰¹å¾æ•°æ®",
                    "success": False,
                }

            # å°†ä¸šåŠ¡ç‰¹å¾æ˜ å°„åˆ°æ¨¡å‹çš„ç‰¹å¾æ ¼å¼
            # æ¨¡å‹æœŸæœ› feature_0 åˆ° feature_4 çš„5ä¸ªç‰¹å¾
            try:
                # å¦‚æœæ¨¡å‹ä½¿ç”¨é€šç”¨ç‰¹å¾åï¼Œåˆ›å»ºç‰¹å¾å‘é‡
                if all(col.startswith("feature_") for col in self._feature_columns):
                    # ä½¿ç”¨é€šç”¨ç‰¹å¾æ˜ å°„ï¼Œå°†ä¸šåŠ¡ç‰¹å¾è½¬æ¢ä¸º5ä¸ªç»´åº¦
                    feature_0 = features.get("home_team_id", 1)  # ä¸»é˜ŸID
                    feature_1 = features.get("away_team_id", 2)  # å®¢é˜ŸID
                    feature_2 = features.get("home_last_5_points", 6)  # ä¸»é˜Ÿæœ€è¿‘ç§¯åˆ†
                    feature_3 = features.get("away_last_5_points", 6)  # å®¢é˜Ÿæœ€è¿‘ç§¯åˆ†
                    feature_4 = features.get(
                        "h2h_last_3_home_wins", 1
                    )  # å†å²äº¤é”‹ä¸»é˜Ÿèƒœåœº

                    feature_vector = [
                        feature_0,
                        feature_1,
                        feature_2,
                        feature_3,
                        feature_4,
                    ]
                    self._feature_columns = [
                        "feature_0",
                        "feature_1",
                        "feature_2",
                        "feature_3",
                        "feature_4",
                    ]
                    logger.info(f"âœ… ä½¿ç”¨é€šç”¨ç‰¹å¾æ˜ å°„: {feature_vector}")
                else:
                    # ä½¿ç”¨åŸå§‹ç‰¹å¾åˆ—æ˜ å°„
                    feature_vector = []
                    for col in self._feature_columns:
                        if col in features:
                            feature_vector.append(features[col])
                        else:
                            logger.warning(f"âš ï¸ ç¼ºå¤±ç‰¹å¾åˆ—: {col}ï¼Œä½¿ç”¨é»˜è®¤å€¼0")
                            feature_vector.append(0)
            except Exception as e:
                logger.error(f"âŒ ç‰¹å¾æ˜ å°„å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤ç‰¹å¾å‘é‡
                feature_vector = [1, 2, 6, 6, 1]

            # è½¬æ¢ä¸ºDataFrame
            feature_df = pd.DataFrame([feature_vector], columns=self._feature_columns)

            # è¿›è¡Œé¢„æµ‹
            prediction = self._model.predict(feature_df)[0]
            probabilities = self._model.predict_proba(feature_df)[0]

            # æ ¹æ®æ¨¡å‹ç±»åˆ«æ•°é‡åŠ¨æ€æ˜ å°„ç»“æœ
            model_classes = self._model.classes_
            if len(model_classes) == 2:
                # äºŒåˆ†ç±»æ¨¡å‹ï¼š0=å¹³å±€/å®¢é˜Ÿèƒœ, 1=ä¸»é˜Ÿèƒœ
                result_names = {0: "away_or_draw", 1: "home_win"}
            else:
                # ä¸‰åˆ†ç±»æ¨¡å‹
                result_names = {0: "å¹³å±€", 1: "ä¸»é˜Ÿèƒœ", 2: "å®¢é˜Ÿèƒœ"}

            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆæœ€é«˜æ¦‚ç‡ï¼‰
            confidence = max(probabilities)

            # ç”ŸæˆæŠ•æ³¨å»ºè®®
            if confidence > 0.6:
                suggestion = (
                    f"æ¨¡å‹é¢„æµ‹{result_names[prediction]}ï¼Œç½®ä¿¡åº¦è¾ƒé«˜({confidence:.1%})"
                )
            elif confidence > 0.4:
                suggestion = f"æ¨¡å‹å€¾å‘{result_names[prediction]}ï¼Œä½†ä¸ç¡®å®šæ€§è¾ƒå¤§({confidence:.1%})"
            else:
                suggestion = f"é¢„æµ‹ç»“æœä¸ç¡®å®šæ€§å¾ˆé«˜({confidence:.1%})ï¼Œå»ºè®®è°¨æ…å‚è€ƒ"

            # æ ¹æ®æ¨¡å‹ç±»å‹æ ¼å¼åŒ–æ¦‚ç‡è¾“å‡º
            if len(model_classes) == 2:
                # äºŒåˆ†ç±»æ¨¡å‹ï¼šprobabilities = [P(éä¸»é˜Ÿèƒœ), P(ä¸»é˜Ÿèƒœ)]
                prob_home_win = round(float(probabilities[1]), 3)
                prob_not_home_win = round(float(probabilities[0]), 3)

                # å°†éä¸»é˜Ÿèƒœæ¦‚ç‡åˆ†é…ç»™å¹³å±€å’Œå®¢é˜Ÿèƒœ
                prob_draw = round(prob_not_home_win * 0.3, 3)  # 30% åˆ†é…ç»™å¹³å±€
                prob_away_win = round(prob_not_home_win * 0.7, 3)  # 70% åˆ†é…ç»™å®¢é˜Ÿèƒœ

                predicted_outcome = "home" if prediction == 1 else "away_or_draw"
            else:
                # ä¸‰åˆ†ç±»æ¨¡å‹
                prob_home_win = round(float(probabilities[1]), 3)
                prob_draw = (
                    round(float(probabilities[0]), 3) if len(probabilities) > 2 else 0.0
                )
                prob_away_win = (
                    round(float(probabilities[2]), 3) if len(probabilities) > 2 else 0.0
                )
                predicted_outcome = (
                    "home"
                    if prediction == 1
                    else ("draw" if prediction == 0 else "away")
                )

            result = {
                "match_id": match_id,
                "prediction": result_names[prediction],
                "predicted_outcome": predicted_outcome,
                "home_win_prob": prob_home_win,
                "draw_prob": prob_draw,
                "away_win_prob": prob_away_win,
                "confidence": float(confidence),
                "suggestion": suggestion,
                "success": True,
                "features_used": self._feature_columns,
                "model_version": self._model_metadata.get("model_version", "v1"),
            }

            logger.info(
                f"âœ… é¢„æµ‹å®Œæˆ: {result_names[prediction]} (ç½®ä¿¡åº¦: {confidence:.1%})"
            )
            return result

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹å¤±è´¥ (match_id={match_id}): {e}")
            return {
                "match_id": match_id,
                "error": f"é¢„æµ‹æœåŠ¡é”™è¯¯: {str(e)}",
                "success": False,
            }

    def predict_batch(self, match_ids: list[int]) -> list[dict]:
        """æ‰¹é‡é¢„æµ‹æ¯”èµ›ç»“æœ.

        Args:
            match_ids: æ¯”èµ›IDåˆ—è¡¨

        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        for match_id in match_ids:
            result = self.predict_match(match_id)
            results.append(result)
        return results

    def get_model_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯."""
        if not self._model_metadata:
            return {"error": "æ¨¡å‹æœªåŠ è½½"}

        return {
            "model_version": self._model_metadata.get("model_version"),
            "training_date": self._model_metadata.get("training_date"),
            "feature_count": len(self._feature_columns),
            "target_classes": self._model_metadata.get("target_classes"),
            "test_accuracy": self._model_metadata.get("test_accuracy"),
            "feature_names": self._feature_columns,
        }

    def health_check(self) -> dict:
        """å¥åº·æ£€æŸ¥."""
        try:
            if not HAVE_XGBOOST:
                return {
                    "status": "degraded",
                    "model_loaded": False,
                    "feature_data_loaded": not self._feature_data.empty,
                    "feature_count": len(self._feature_columns)
                    if self._feature_columns
                    else 0,
                    "initialized": self._initialized,
                    "note": "XGBoost not available - running in mock mode",
                    "xgboost_available": False,
                }

            model_loaded = self._model is not None
            feature_data_loaded = self._feature_data is not None
            feature_count = len(self._feature_columns) if self._feature_columns else 0

            return {
                "status": "healthy" if model_loaded else "unhealthy",
                "model_loaded": model_loaded,
                "feature_data_loaded": not self._feature_data.empty
                if feature_data_loaded
                else False,
                "feature_count": feature_count,
                "initialized": self._initialized,
                "xgboost_available": True,
            }
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}


# å…¨å±€æ¨ç†æœåŠ¡å®ä¾‹
inference_service = InferenceService()
