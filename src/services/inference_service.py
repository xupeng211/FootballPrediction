"""è¶³çƒé¢„æµ‹æ¨ç†æœåŠ¡
Football Prediction Inference Service.

æä¾›åŸºäºXGBoostæ¨¡å‹çš„å®æ—¶æ¨ç†æœåŠ¡ï¼ŒåŒ…æ‹¬ï¼š
- æ¨¡å‹åŠ è½½å’Œç®¡ç†
- ç‰¹å¾æå–å’Œé¢„å¤„ç†
- é¢„æµ‹ç»“æœç”Ÿæˆ
"""

import json
import logging
import os
import pandas as pd
from pathlib import Path
from typing import Optional

# å°è¯•å¯¼å…¥XGBoostï¼Œå¦‚æœå¤±è´¥åˆ™è¿è¡Œåœ¨Mockæ¨¡å¼
try:
    import xgboost as xgb

    HAVE_XGBOOST = True
except ImportError:
    HAVE_XGBOOST = False
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ XGBoost not found. Inference service running in MOCK mode.")

logger = logging.getLogger(__name__)


class InferenceService:
    """è¶³çƒé¢„æµ‹æ¨ç†æœåŠ¡å•ä¾‹ç±»."""

    _instance = None
    _model = None
    _model_metadata = None
    _feature_data = None
    _feature_columns = None

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼å®ç°."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–æ¨ç†æœåŠ¡."""
        if not hasattr(self, "_initialized"):
            self._initialized = False
            self._load_model()
            self._load_feature_data()
            self._initialized = True
            logger.info("âœ… æ¨ç†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„XGBoostæ¨¡å‹."""
        if not HAVE_XGBOOST:
            logger.warning("âš ï¸ XGBoostä¸å¯ç”¨ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½ï¼Œä½¿ç”¨Mockæ¨¡å¼")
            self._model = None
            self._model_metadata = {
                "model_version": "mock_v1",
                "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
            }
            self._feature_columns = [
                "home_team_id",
                "away_team_id",
                "home_last_5_points",
                "away_last_5_points",
                "home_last_5_avg_goals",
                "away_last_5_avg_goals",
                "h2h_last_3_home_wins",
                "home_last_5_goal_diff",
                "away_last_5_goal_diff",
                "home_win_streak",
                "away_win_streak",
                "home_last_5_win_rate",
                "away_last_5_win_rate",
                "home_rest_days",
                "away_rest_days",
            ]
            return

        try:
            # ä¼˜å…ˆåŠ è½½æœ€æ–°çš„V4 Optunaä¼˜åŒ–æ¨¡å‹
            v4_model_path = Path("models/football_prediction_v4_optuna.pkl")
            v4_results_path = Path("models/football_prediction_v4_optuna_results.json")

            # å¤‡ç”¨ï¼šv2æ¨¡å‹è·¯å¾„ (æ³¨æ„ï¼šå½“å‰å·²ç§»åŠ¨åˆ°scripts/temp/)
            # v2_model_path = Path("models/football_prediction_v2.pkl")
            # v2_metadata_path = Path("models/model_metadata.json")

            # å¤‡ç”¨ï¼šæ—§æ¨¡å‹è·¯å¾„
            pkl_model_path = Path("models/football_xgboost_v2_best.pkl")
            json_model_path = Path("models/football_model_v1.json")
            metadata_path = Path("models/football_model_v1_metadata.json")

            # ä¼˜å…ˆä½¿ç”¨æœ€æ–°çš„V4 Optunaä¼˜åŒ–æ¨¡å‹
            if v4_model_path.exists():
                logger.info(f"ğŸš€ åŠ è½½V4 Optunaä¼˜åŒ–æ¨¡å‹: {v4_model_path}")
                import pickle

                with open(v4_model_path, 'rb') as f:
                    self._model = pickle.load(f)

                # åŠ è½½V4æ¨¡å‹çš„ä¼˜åŒ–ç»“æœä½œä¸ºå…ƒæ•°æ®
                if v4_results_path.exists():
                    with open(v4_results_path) as f:
                        v4_results = json.load(f)

                    self._model_metadata = {
                        "model_version": "v4_optuna",
                        "model_type": "XGBClassifier",
                        "target_classes": ["å®¢é˜Ÿèƒœ", "å¹³å±€", "ä¸»é˜Ÿèƒœ"],  # away_win, draw, home_win
                        "best_score": v4_results.get("best_score"),
                        "n_trials": v4_results.get("n_trials"),
                        "optimization_time": v4_results.get("optimization_time"),
                        "test_accuracy": v4_results.get("best_score"),
                        "feature_count": len(v4_results.get("feature_names", [])),
                        "label_encoder_classes": v4_results.get("label_encoder_classes"),
                    }

                    self._feature_columns = v4_results.get("feature_names", [])
                    logger.info("âœ… V4æ¨¡å‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
                    logger.info(f"ğŸ“Š V4æ¨¡å‹å‡†ç¡®ç‡: {v4_results.get('best_score', 'N/A'):.4f}")
                    logger.info(f"ğŸ”§ V4æ¨¡å‹ç‰¹å¾æ•°é‡: {len(self._feature_columns)}")
                else:
                    logger.warning("âš ï¸ V4å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
                    self._model_metadata = {
                        "model_version": "v4_optuna",
                        "target_classes": ["å®¢é˜Ÿèƒœ", "å¹³å±€", "ä¸»é˜Ÿèƒœ"],
                        "model_type": "XGBClassifier",
                    }
                    # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œå°è¯•ä»æ¨¡å‹æ¨æ–­ç‰¹å¾
                    if hasattr(self._model, 'feature_names'):
                        self._feature_columns = list(self._model.feature_names)
                    else:
                        logger.warning("âš ï¸ æ— æ³•è·å–V4æ¨¡å‹ç‰¹å¾åç§°")
                        self._feature_columns = []

                logger.info("âœ… V4 Optunaä¼˜åŒ–æ¨¡å‹åŠ è½½æˆåŠŸ")

            # å¤‡ç”¨ï¼šä½¿ç”¨æ—§æ¨¡å‹
            elif pkl_model_path.exists():
                logger.info(f"ğŸ”„ åŠ è½½å¤‡ç”¨PKLæ¨¡å‹: {pkl_model_path}")
                import joblib

                self._model = joblib.load(pkl_model_path)
                logger.info("âœ… XGBoost PKLæ¨¡å‹åŠ è½½æˆåŠŸ")

                # å°è¯•åŠ è½½JSONæ ¼å¼çš„å…ƒæ•°æ®
                if metadata_path.exists():
                    with open(metadata_path, encoding="utf-8") as f:
                        self._model_metadata = json.load(f)
                    logger.info("âœ… æ¨¡å‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
                else:
                    # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
                    self._model_metadata = {
                        "model_version": "v2_best",
                        "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
                        "model_type": "xgboost_v2",
                    }
                    logger.warning("âš ï¸ ä½¿ç”¨é»˜è®¤æ¨¡å‹å…ƒæ•°æ®")

            elif json_model_path.exists():
                logger.info(f"ğŸ”„ åŠ è½½JSONæ ¼å¼æ¨¡å‹: {json_model_path}")
                self._model = xgb.XGBClassifier()
                self._model.load_model(str(json_model_path))
                logger.info("âœ… XGBoost JSONæ¨¡å‹åŠ è½½æˆåŠŸ")

                # åŠ è½½æ¨¡å‹å…ƒæ•°æ®
                if not metadata_path.exists():
                    raise FileNotFoundError(f"æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_path}")
                with open(metadata_path, encoding="utf-8") as f:
                    self._model_metadata = json.load(f)
                logger.info("âœ… æ¨¡å‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
            else:
                raise FileNotFoundError("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")

            # å¼ºåˆ¶ä½¿ç”¨æ­£ç¡®çš„ç‰¹å¾åç§°ï¼ˆåŸºäºå®é™…æ¨¡å‹çš„feature_namesï¼‰
            actual_feature_names = (
                self._model.get_booster().feature_names
                if hasattr(self._model.get_booster(), "feature_names")
                else None
            )
            if actual_feature_names:
                self._feature_columns = actual_feature_names
                logger.info(f"âœ… ä½¿ç”¨æ¨¡å‹å®é™…çš„ç‰¹å¾åç§°: {self._feature_columns}")
            else:
                self._feature_columns = [
                    "feature_0",
                    "feature_1",
                    "feature_2",
                    "feature_3",
                    "feature_4",
                ]
                logger.warning(
                    f"âš ï¸ æ— æ³•è·å–æ¨¡å‹ç‰¹å¾åç§°ï¼Œä½¿ç”¨é»˜è®¤å€¼: {self._feature_columns}"
                )

            logger.info(
                f"âœ… æ¨¡å‹è®¾ç½®å®Œæˆï¼Œç‰¹å¾åˆ—: {len(self._feature_columns)}, æ¨¡å‹ç‰ˆæœ¬: {self._model_metadata.get('model_version', 'unknown')}"
            )

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # é™çº§åˆ°Mockæ¨¡å¼
            logger.warning("ğŸ”„ é™çº§åˆ°Mockæ¨¡å¼")
            self._model = None
            self._model_metadata = {
                "model_version": "mock_v1",
                "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
            }
            self._feature_columns = [
                "home_team_id",
                "away_team_id",
                "home_last_5_points",
                "away_last_5_points",
                "home_last_5_avg_goals",
                "away_last_5_avg_goals",
                "h2h_last_3_home_wins",
                "home_last_5_goal_diff",
                "away_last_5_goal_diff",
                "home_win_streak",
                "away_win_streak",
                "home_last_5_win_rate",
                "away_last_5_win_rate",
                "home_rest_days",
                "away_rest_days",
            ]

    def _load_feature_data(self):
        """åŠ è½½ç‰¹å¾æ•°æ®ç”¨äºæ¨ç†."""
        try:
            dataset_path = Path("data/dataset_v1.csv")

            if not dataset_path.exists():
                logger.warning(f"âš ï¸ ç‰¹å¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
                self._feature_data = pd.DataFrame()
                return

            # åŠ è½½ç‰¹å¾æ•°æ®
            self._feature_data = pd.read_csv(dataset_path)

            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
            if "match_date" in self._feature_data.columns:
                self._feature_data["match_date"] = pd.to_datetime(
                    self._feature_data["match_date"]
                )

            logger.info(f"âœ… ç‰¹å¾æ•°æ®åŠ è½½æˆåŠŸ: {len(self._feature_data)} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾æ•°æ®åŠ è½½å¤±è´¥: {e}")
            self._feature_data = pd.DataFrame()

    async def _get_features_for_match(self, match_id: int) -> dict | None:
        """æ ¹æ®æ¯”èµ›IDä»æ•°æ®åº“è·å–ç‰¹å¾æ•°æ®.

        Args:
            match_id: æ¯”èµ›ID

        Returns:
            ç‰¹å¾æ•°æ®å­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        try:
            logger.info(f"ğŸ” Fetching features from DB for match {match_id}")

            # å¯¼å…¥æ•°æ®åº“è¿æ¥ç®¡ç†å™¨
            from src.database.connection import DatabaseManager

            # è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
            db_manager = DatabaseManager()

            # ç¡®ä¿æ•°æ®åº“ç®¡ç†å™¨å·²åˆå§‹åŒ–
            if not hasattr(db_manager, "_initialized") or not db_manager._initialized:
                from src.core.config import get_settings

                settings = get_settings()
                db_manager.initialize(database_url=settings.database_url)

            # ä½¿ç”¨å¼‚æ­¥ä¼šè¯æŸ¥è¯¢æ•°æ®åº“
            async with db_manager.get_async_session() as session:
                from sqlalchemy import text

                # æ‰§è¡ŒSQLæŸ¥è¯¢
                result = await session.execute(
                    text(
                        "SELECT feature_data FROM features WHERE match_id = :match_id"
                    ),
                    {"match_id": match_id},
                )
                row = result.first()

                if row and row[0]:  # feature_data å­˜åœ¨
                    # å¤„ç†JSONBå¯¹è±¡ï¼Œç¡®ä¿æ­£ç¡®è½¬æ¢ä¸ºPythonå­—å…¸
                    features_data = row[0]
                    if isinstance(features_data, str):
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æJSON
                        features_dict = json.loads(features_data)
                    elif hasattr(features_data, '__dict__'):
                        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•è½¬æ¢ä¸ºå­—å…¸
                        features_dict = dict(features_data)
                    else:
                        # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                        features_dict = features_data

                    logger.info(
                        f"âœ… Successfully fetched features for match {match_id}: {len(features_dict)} features"
                    )
                    return features_dict
                else:
                    logger.warning(f"âš ï¸ No features found for match {match_id}")
                    return None

        except Exception as e:
            logger.error(f"âŒ è·å–ç‰¹å¾å¤±è´¥ (match_id={match_id}): {e}")
            return self._get_default_features()

    def _get_default_features(self) -> dict:
        """è·å–é»˜è®¤ç‰¹å¾æ•°æ®."""
        return {
            "home_team_id": 1,
            "away_team_id": 2,
            "home_last_5_points": 6,
            "away_last_5_points": 7,
            "home_last_5_avg_goals": 1.4,
            "away_last_5_avg_goals": 1.5,
            "h2h_last_3_home_wins": 1,
            "home_last_5_goal_diff": 0,
            "away_last_5_goal_diff": 0,
            "home_win_streak": 0,
            "away_win_streak": 0,
            "home_last_5_win_rate": 0.37,
            "away_last_5_win_rate": 0.38,
            "home_rest_days": 7,
            "away_rest_days": 7,
        }

    async def predict_match(self, match_id: int) -> dict:
        """å¯¹æŒ‡å®šæ¯”èµ›è¿›è¡Œé¢„æµ‹.

        Args:
            match_id: æ¯”èµ›ID

        Returns:
            åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        # å¦‚æœXGBoostä¸å¯ç”¨ï¼Œè¿”å›Mockæ•°æ®
        if not HAVE_XGBOOST:
            logger.info(f"ğŸ”® Mockæ¨¡å¼é¢„æµ‹æ¯”èµ› {match_id}")
            return {
                "match_id": match_id,
                "prediction": "home_win",
                "confidence": 0.60,
                "home_win_prob": 0.6,
                "draw_prob": 0.2,
                "away_win_prob": 0.2,
                "status": "mock_data",
                "note": "XGBoost not installed (Docker lightweight mode)",
                "success": True,
                "model_version": "mock_v1",
                "suggestion": "Mockæ¨¡å¼é¢„æµ‹ï¼Œä¸»é˜Ÿèƒœï¼Œç½®ä¿¡åº¦ä¸­ç­‰(60%)",
            }

        try:
            logger.info(f"ğŸ”® å¼€å§‹é¢„æµ‹æ¯”èµ› {match_id}")

            # è·å–ç‰¹å¾æ•°æ®
            features = await self._get_features_for_match(match_id)
            if features is None:
                return {
                    "match_id": match_id,
                    "error": "æ— æ³•è·å–æ¯”èµ›ç‰¹å¾æ•°æ®",
                    "success": False,
                }

            # ä½¿ç”¨v2æ¨¡å‹çš„çœŸå®ç‰¹å¾åˆ—è¿›è¡Œé¢„æµ‹
            try:
                logger.info("ğŸ¯ ä½¿ç”¨v2æ¨¡å‹çš„13ä¸ªçœŸå®ç‰¹å¾è¿›è¡Œé¢„æµ‹")
                logger.info(f"ğŸ“‹ æ¨¡å‹ç‰¹å¾åˆ—: {self._feature_columns}")

                # ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„ç‰¹å¾åˆ—æ˜ å°„ï¼Œç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
                feature_vector = []
                for col in self._feature_columns:
                    if col in features:
                        feature_vector.append(features[col])
                    else:
                        logger.warning(f"âš ï¸ ç¼ºå¤±ç‰¹å¾åˆ—: {col}ï¼Œä½¿ç”¨é»˜è®¤å€¼0")
                        feature_vector.append(0)

                logger.info(f"âœ… æ„å»ºçš„ç‰¹å¾å‘é‡: {feature_vector}")

            except Exception as e:
                logger.error(f"âŒ ç‰¹å¾æ˜ å°„å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤ç‰¹å¾å‘é‡ï¼ˆåŸºäºæ–°ç‰¹å¾çš„é»˜è®¤å€¼ï¼‰
                feature_vector = [6, 7, 1.4, 1.5, 0, 0, 0, 0, 0.37, 0.38, 7, 7, 1]

            # è½¬æ¢ä¸ºDataFrame
            feature_df = pd.DataFrame([feature_vector], columns=self._feature_columns)

            # è¿›è¡Œé¢„æµ‹
            prediction = self._model.predict(feature_df)[0]
            probabilities = self._model.predict_proba(feature_df)[0]

            # æ ¹æ®æ¨¡å‹ç±»åˆ«æ•°é‡åŠ¨æ€æ˜ å°„ç»“æœ
            model_classes = self._model.classes_
            if len(model_classes) == 2:
                # äºŒåˆ†ç±»æ¨¡å‹ï¼š0=å¹³å±€/å®¢é˜Ÿèƒœ, 1=ä¸»é˜Ÿèƒœ
                result_names = {0: "away_or_draw", 1: "home_win"}
            else:
                # ä¸‰åˆ†ç±»æ¨¡å‹ - æ”¯æŒV4æ¨¡å‹çš„è‹±æ–‡æ ‡ç­¾å’Œæ—§æ¨¡å‹çš„ä¸­æ–‡æ ‡ç­¾
                if hasattr(self._model, 'classes_') and len(self._model.classes_) == 3:
                    # æ£€æŸ¥æ¨¡å‹æ ‡ç­¾ç±»å‹
                    class_list = list(self._model.classes_)
                    if 'away_win' in class_list and 'draw' in class_list and 'home_win' in class_list:
                        # V4æ¨¡å‹è‹±æ–‡æ ‡ç­¾æ˜ å°„ (away_win, draw, home_win)
                        away_idx = class_list.index('away_win')
                        draw_idx = class_list.index('draw')
                        home_idx = class_list.index('home_win')
                        result_names = {away_idx: "å®¢é˜Ÿèƒœ", draw_idx: "å¹³å±€", home_idx: "ä¸»é˜Ÿèƒœ"}
                        logger.info(f"ğŸ·ï¸ ä½¿ç”¨V4æ¨¡å‹è‹±æ–‡æ ‡ç­¾æ˜ å°„: {result_names}")
                    elif 'Away' in class_list and 'Draw' in class_list and 'Home' in class_list:
                        # æ–°æ¨¡å‹è‹±æ–‡æ ‡ç­¾æ˜ å°„
                        away_idx = class_list.index('Away')
                        draw_idx = class_list.index('Draw')
                        home_idx = class_list.index('Home')
                        result_names = {away_idx: "å®¢é˜Ÿèƒœ", draw_idx: "å¹³å±€", home_idx: "ä¸»é˜Ÿèƒœ"}
                        logger.info(f"ğŸ·ï¸ ä½¿ç”¨æ–°æ¨¡å‹è‹±æ–‡æ ‡ç­¾æ˜ å°„: {result_names}")
                    else:
                        # æ—§æ¨¡å‹ä¸­æ–‡æ ‡ç­¾æ˜ å°„
                        result_names = {0: "å¹³å±€", 1: "ä¸»é˜Ÿèƒœ", 2: "å®¢é˜Ÿèƒœ"}
                else:
                    # é»˜è®¤ä¸­æ–‡æ ‡ç­¾æ˜ å°„
                    result_names = {0: "å¹³å±€", 1: "ä¸»é˜Ÿèƒœ", 2: "å®¢é˜Ÿèƒœ"}

            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆæœ€é«˜æ¦‚ç‡ï¼‰
            confidence = max(probabilities)

            # ç”ŸæˆæŠ•æ³¨å»ºè®®
            if confidence > 0.6:
                suggestion = (
                    f"æ¨¡å‹é¢„æµ‹{result_names[prediction]}ï¼Œç½®ä¿¡åº¦è¾ƒé«˜({confidence:.1%})"
                )
            elif confidence > 0.4:
                suggestion = f"æ¨¡å‹å€¾å‘{result_names[prediction]}ï¼Œä½†ä¸ç¡®å®šæ€§è¾ƒå¤§({confidence:.1%})"
            else:
                suggestion = f"é¢„æµ‹ç»“æœä¸ç¡®å®šæ€§å¾ˆé«˜({confidence:.1%})ï¼Œå»ºè®®è°¨æ…å‚è€ƒ"

            # æ ¹æ®æ¨¡å‹ç±»å‹æ ¼å¼åŒ–æ¦‚ç‡è¾“å‡º
            if len(model_classes) == 2:
                # äºŒåˆ†ç±»æ¨¡å‹ï¼šprobabilities = [P(éä¸»é˜Ÿèƒœ), P(ä¸»é˜Ÿèƒœ)]
                prob_home_win = round(float(probabilities[1]), 3)
                prob_not_home_win = round(float(probabilities[0]), 3)

                # å°†éä¸»é˜Ÿèƒœæ¦‚ç‡åˆ†é…ç»™å¹³å±€å’Œå®¢é˜Ÿèƒœ
                prob_draw = round(prob_not_home_win * 0.3, 3)  # 30% åˆ†é…ç»™å¹³å±€
                prob_away_win = round(prob_not_home_win * 0.7, 3)  # 70% åˆ†é…ç»™å®¢é˜Ÿèƒœ

                predicted_outcome = "home" if prediction == 1 else "away_or_draw"
            else:
                # ä¸‰åˆ†ç±»æ¨¡å‹ - æ™ºèƒ½å¤„ç†V4æ¨¡å‹ã€æ–°æ¨¡å‹å’Œæ—§æ¨¡å‹çš„æ ‡ç­¾é¡ºåº
                class_list = list(model_classes)

                # æ£€æŸ¥æ˜¯å¦æ˜¯V4æ¨¡å‹çš„è‹±æ–‡æ ‡ç­¾ (away_win, draw, home_win)
                if 'away_win' in class_list and 'draw' in class_list and 'home_win' in class_list:
                    # V4æ¨¡å‹ï¼šæŒ‰å®é™…ç´¢å¼•è·å–æ¦‚ç‡
                    away_prob = float(probabilities[class_list.index('away_win')])
                    draw_prob = float(probabilities[class_list.index('draw')])
                    home_prob = float(probabilities[class_list.index('home_win')])

                    prob_home_win = round(home_prob, 3)
                    prob_draw = round(draw_prob, 3)
                    prob_away_win = round(away_prob, 3)

                    # æ ¹æ®é¢„æµ‹ç»“æœç¡®å®šoutcome
                    if prediction == class_list.index('home_win'):
                        predicted_outcome = "home"
                    elif prediction == class_list.index('draw'):
                        predicted_outcome = "draw"
                    else:
                        predicted_outcome = "away"

                    logger.info(f"ğŸ¯ V4æ¨¡å‹æ¦‚ç‡åˆ†å¸ƒ: Home={prob_home_win}, Draw={prob_draw}, Away={prob_away_win}")
                elif 'Away' in class_list and 'Draw' in class_list and 'Home' in class_list:
                    # æ–°æ¨¡å‹ï¼šæŒ‰å®é™…ç´¢å¼•è·å–æ¦‚ç‡
                    away_prob = float(probabilities[class_list.index('Away')])
                    draw_prob = float(probabilities[class_list.index('Draw')])
                    home_prob = float(probabilities[class_list.index('Home')])

                    prob_home_win = round(home_prob, 3)
                    prob_draw = round(draw_prob, 3)
                    prob_away_win = round(away_prob, 3)

                    # æ ¹æ®é¢„æµ‹ç»“æœç¡®å®šoutcome
                    if prediction == class_list.index('Home'):
                        predicted_outcome = "home"
                    elif prediction == class_list.index('Draw'):
                        predicted_outcome = "draw"
                    else:
                        predicted_outcome = "away"

                    logger.info(f"ğŸ¯ æ–°æ¨¡å‹æ¦‚ç‡åˆ†å¸ƒ: Home={prob_home_win}, Draw={prob_draw}, Away={prob_away_win}")
                else:
                    # æ—§æ¨¡å‹ï¼šå‡è®¾é¡ºåºæ˜¯ [å¹³å±€, ä¸»é˜Ÿèƒœ, å®¢é˜Ÿèƒœ]
                    prob_home_win = round(float(probabilities[1]), 3)
                    prob_draw = round(float(probabilities[0]), 3) if len(probabilities) > 2 else 0.0
                    prob_away_win = round(float(probabilities[2]), 3) if len(probabilities) > 2 else 0.0

                    predicted_outcome = (
                        "home"
                        if prediction == 1
                        else ("draw" if prediction == 0 else "away")
                    )

            result = {
                "match_id": match_id,
                "prediction": result_names[prediction],
                "predicted_outcome": predicted_outcome,
                "home_win_prob": prob_home_win,
                "draw_prob": prob_draw,
                "away_win_prob": prob_away_win,
                "confidence": float(confidence),
                "suggestion": suggestion,
                "success": True,
                "features_used": self._feature_columns,
                "model_version": self._model_metadata.get("model_version", "v1"),
            }

            logger.info(
                f"âœ… é¢„æµ‹å®Œæˆ: {result_names[prediction]} (ç½®ä¿¡åº¦: {confidence:.1%})"
            )
            return result

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹å¤±è´¥ (match_id={match_id}): {e}")
            return {
                "match_id": match_id,
                "error": f"é¢„æµ‹æœåŠ¡é”™è¯¯: {str(e)}",
                "success": False,
            }

    def predict_batch(self, match_ids: list[int]) -> list[dict]:
        """æ‰¹é‡é¢„æµ‹æ¯”èµ›ç»“æœ.

        Args:
            match_ids: æ¯”èµ›IDåˆ—è¡¨

        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        for match_id in match_ids:
            result = self.predict_match(match_id)
            results.append(result)
        return results

    def get_model_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯."""
        if not self._model_metadata:
            return {"error": "æ¨¡å‹æœªåŠ è½½"}

        return {
            "model_version": self._model_metadata.get("model_version"),
            "training_date": self._model_metadata.get("training_date"),
            "feature_count": len(self._feature_columns),
            "target_classes": self._model_metadata.get("target_classes"),
            "test_accuracy": self._model_metadata.get("test_accuracy"),
            "feature_names": self._feature_columns,
        }

    def health_check(self) -> dict:
        """å¥åº·æ£€æŸ¥."""
        try:
            if not HAVE_XGBOOST:
                return {
                    "status": "degraded",
                    "model_loaded": False,
                    "feature_data_loaded": not self._feature_data.empty,
                    "feature_count": len(self._feature_columns)
                    if self._feature_columns
                    else 0,
                    "initialized": self._initialized,
                    "note": "XGBoost not available - running in mock mode",
                    "xgboost_available": False,
                }

            model_loaded = self._model is not None
            feature_data_loaded = self._feature_data is not None
            feature_count = len(self._feature_columns) if self._feature_columns else 0

            return {
                "status": "healthy" if model_loaded else "unhealthy",
                "model_loaded": model_loaded,
                "feature_data_loaded": not self._feature_data.empty
                if feature_data_loaded
                else False,
                "feature_count": feature_count,
                "initialized": self._initialized,
                "xgboost_available": True,
            }
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}


# å…¨å±€æ¨ç†æœåŠ¡å®ä¾‹
inference_service = InferenceService()
