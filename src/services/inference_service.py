"""è¶³çƒé¢„æµ‹æ¨ç†æœåŠ¡ (å¢å¼ºç‰ˆ) v3.0
Football Prediction Inference Service (Enhanced) v3.0

P2-6ä»»åŠ¡æˆæœï¼šæ•´åˆçœŸå®æ¨¡å‹ä¸Mockæ¨¡å¼çš„ç»Ÿä¸€æ¨ç†æœåŠ¡ï¼Œå®ç°ï¼š
- çœŸå®XGBoostæ¨¡å‹ä¼˜å…ˆåŠ è½½
- ä¼˜é›…çš„è‡ªåŠ¨é™çº§æœºåˆ¶
- å®Œæ•´çš„API Schemaå…¼å®¹æ€§
- ç»Ÿä¸€çš„ç‰¹å¾æå–é€»è¾‘
- å¼‚æ­¥æ¨¡å‹ç®¡ç†å’Œç¼“å­˜

ä¸»è¦ç‰¹æ€§:
- è‡ªåŠ¨é™çº§ï¼šçœŸå®æ¨¡å‹ä¸å¯ç”¨æ—¶æ— ç¼åˆ‡æ¢åˆ°Mockæ¨¡å¼
- APIå…¼å®¹ï¼šå®Œå…¨å…¼å®¹PredictionResponse schema
- æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼šModelLoaderä¼˜å…ˆï¼Œæ–‡ä»¶ç³»ç»Ÿå¤‡ç”¨
- ç‰¹å¾ä¸€è‡´æ€§ï¼šè®­ç»ƒå’Œæ¨ç†ä½¿ç”¨ç›¸åŒçš„15ä¸ªç‰¹å¾
- ç›‘æ§å®Œå¤‡ï¼šæä¾›å¥åº·æ£€æŸ¥å’Œæ€§èƒ½æŒ‡æ ‡

ä½œè€…: Inference Engineer (P2-6)
åˆ›å»ºæ—¶é—´: 2025-12-07
ç‰ˆæœ¬: 3.0.0
"""

import logging
import os
import pandas as pd
from pathlib import Path
from typing import Optional, Any
import asyncio

# åˆå§‹åŒ–logger
logger = logging.getLogger(__name__)

# V6.0: ä¼˜å…ˆæ£€æŸ¥Mockç¯å¢ƒå˜é‡ï¼Œé˜²æ­¢èµ„æºè€—å°½
ML_MODE = os.getenv("FOOTBALL_PREDICTION_ML_MODE", "real").lower()
INFERENCE_SERVICE_MOCK = os.getenv("INFERENCE_SERVICE_MOCK", "false").lower() == "true"
SKIP_ML_MODEL_LOADING = os.getenv("SKIP_ML_MODEL_LOADING", "false").lower() == "true"

# å¦‚æœè®¾ç½®ä¸ºMockæ¨¡å¼ï¼Œå®Œå…¨è·³è¿‡MLç›¸å…³å¯¼å…¥å’ŒåŠ è½½
FORCE_MOCK_MODE = (
    ML_MODE == "mock"
    or INFERENCE_SERVICE_MOCK
    or SKIP_ML_MODEL_LOADING
    or os.getenv("XGBOOST_MOCK", "false").lower() == "true"
    or os.getenv("JOBLIB_MOCK", "false").lower() == "true"
)

if FORCE_MOCK_MODE:
    logger.info("ğŸ”§ V3.0: å¼ºåˆ¶Mockæ¨¡å¼å·²å¯ç”¨ - è·³è¿‡æ‰€æœ‰MLåº“å¯¼å…¥ä»¥èŠ‚çœèµ„æº")
    HAVE_JOBLIB = False
    HAVE_XGBOOST = False
else:
    # å°è¯•å¯¼å…¥å¿…è¦çš„åº“
    try:
        import joblib

        HAVE_JOBLIB = True
    except ImportError:
        HAVE_JOBLIB = False
        logger.warning("âš ï¸ joblib not found. Will attempt safe fallback methods.")

    try:
        import xgboost as xgb

        HAVE_XGBOOST = True
    except ImportError:
        HAVE_XGBOOST = False
        logger.warning("âš ï¸ XGBoost not found. Inference service running in MOCK mode.")


class InferenceService:
    """è¶³çƒé¢„æµ‹æ¨ç†æœåŠ¡ (å¢å¼ºç‰ˆ)"""

    _instance = None
    _model = None
    _model_metadata = None
    _model_loader = None
    _feature_columns = None
    _mode = "unknown"  # real/mock/degraded

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼å®ç°."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–æ¨ç†æœåŠ¡."""
        if not hasattr(self, "_initialized"):
            self._initialized = False
            # å°è¯•è·å–äº‹ä»¶å¾ªç¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°çš„
            try:
                asyncio.get_running_loop()
                # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œåˆ›å»ºä»»åŠ¡
                asyncio.create_task(self._initialize_async())
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                asyncio.run(self._initialize_async())
            self._initialized = True
            logger.info(f"âœ… æ¨ç†æœåŠ¡v3.0åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: {self._mode}")

    async def _initialize_async(self):
        """å¼‚æ­¥åˆå§‹åŒ–ç»„ä»¶"""
        await self._load_model_loader()
        await self._load_model_with_fallback()
        logger.info(f"âœ… æ¨ç†æœåŠ¡å¼‚æ­¥åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: {self._mode}")

    async def _load_model_loader(self):
        """åŠ è½½ModelLoader"""
        if FORCE_MOCK_MODE:
            self._model_loader = None
            logger.info("ğŸ”§ è·³è¿‡ModelLoaderåŠ è½½ - å¼ºåˆ¶Mockæ¨¡å¼")
            return

        try:
            from src.inference.loader import get_model_loader

            self._model_loader = await get_model_loader()
            logger.info("âœ… ModelLoaderåŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ ModelLoaderåŠ è½½å¤±è´¥: {e}")
            self._model_loader = None

    async def _load_model_with_fallback(self):
        """åŠ è½½æ¨¡å‹å¹¶å®ç°è‡ªåŠ¨é™çº§é€»è¾‘"""
        logger.info("ğŸ”„ å¼€å§‹æ¨¡å‹åŠ è½½æµç¨‹...")

        # 1. æ£€æŸ¥å¼ºåˆ¶Mockæ¨¡å¼
        if FORCE_MOCK_MODE:
            await self._switch_to_mock_mode("å¼ºåˆ¶Mockæ¨¡å¼ (ç¯å¢ƒå˜é‡)")
            return

        # 2. æ£€æŸ¥XGBoostå¯ç”¨æ€§
        if not HAVE_XGBOOST:
            await self._switch_to_mock_mode("XGBoostä¸å¯ç”¨")
            return

        # 3. å°è¯•åŠ è½½çœŸå®æ¨¡å‹
        model_loaded = False
        load_error = None

        try:
            # ç­–ç•¥1: ä½¿ç”¨ModelLoader
            if self._model_loader:
                try:
                    from src.inference.loader import ModelType

                    models = await self._model_loader.list_models(ModelType.XGBOOST)

                    if models:
                        latest_model = max(models, key=lambda x: x.created_at)
                        logger.info(
                            f"ğŸš€ ModelLoaderåŠ è½½æœ€æ–°æ¨¡å‹: {latest_model.model_name}"
                        )

                        loaded_model = await self._model_loader.load(
                            latest_model.model_name
                        )
                        self._model = loaded_model.access()

                        self._model_metadata = {
                            "model_version": latest_model.model_name,
                            "model_type": latest_model.model_type.value,
                            "target_classes": ["å®¢é˜Ÿèƒœ", "å¹³å±€", "ä¸»é˜Ÿèƒœ"],
                            "created_at": latest_model.created_at.isoformat(),
                            "file_size": latest_model.file_size,
                            "source": "ModelLoader",
                        }

                        self._feature_columns = self._extract_features_from_model()
                        model_loaded = True
                        logger.info("âœ… ModelLoaderæ¨¡å‹åŠ è½½æˆåŠŸ")

                except Exception as e:
                    load_error = f"ModelLoaderå¤±è´¥: {str(e)}"
                    logger.warning(f"âš ï¸ ModelLoaderåŠ è½½å¤±è´¥: {e}")

            # ç­–ç•¥2: æ–‡ä»¶ç³»ç»ŸåŠ è½½
            if not model_loaded:
                try:
                    model_paths = [
                        (
                            "artifacts/models/football_prediction_v1_xgboost_2023-2024_5000matches.pkl",
                            "p2_5_pipeline",
                        ),
                        ("models/football_prediction_v4_optuna.pkl", "v4_optuna"),
                        ("models/football_xgboost_v2_best.pkl", "v2_best"),
                    ]

                    for model_path, version_name in model_paths:
                        path_obj = Path(model_path)
                        if path_obj.exists():
                            logger.info(f"ğŸ”„ å°è¯•æ–‡ä»¶ç³»ç»ŸåŠ è½½: {model_path}")

                            if HAVE_JOBLIB:
                                self._model = joblib.load(path_obj)
                                logger.info("âœ… ä½¿ç”¨joblibåŠ è½½æ¨¡å‹æˆåŠŸ")

                                self._model_metadata = {
                                    "model_version": version_name,
                                    "model_type": "XGBClassifier",
                                    "target_classes": ["å®¢é˜Ÿèƒœ", "å¹³å±€", "ä¸»é˜Ÿèƒœ"],
                                    "source": "file_system",
                                }

                                self._feature_columns = (
                                    self._extract_features_from_model()
                                )
                                model_loaded = True
                                logger.info(f"âœ… æ–‡ä»¶ç³»ç»Ÿæ¨¡å‹åŠ è½½æˆåŠŸ: {version_name}")
                                break
                            else:
                                raise ImportError(
                                    "joblib not available for model loading"
                                )

                except Exception as e:
                    if not load_error:
                        load_error = f"æ–‡ä»¶ç³»ç»ŸåŠ è½½å¤±è´¥: {str(e)}"
                    logger.warning(f"âš ï¸ æ–‡ä»¶ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")

        except Exception as e:
            load_error = f"æ¨¡å‹åŠ è½½è¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ æ¨¡å‹åŠ è½½è¿‡ç¨‹å¼‚å¸¸: {e}")

        # 4. æ ¹æ®åŠ è½½ç»“æœè®¾ç½®æ¨¡å¼
        if model_loaded:
            self._mode = "real"
            logger.info(
                f"âœ… çœŸå®æ¨¡å‹åŠ è½½æˆåŠŸ - ç‰ˆæœ¬: {self._model_metadata.get('model_version')}"
            )
        else:
            await self._switch_to_mock_mode(load_error or "æ¨¡å‹åŠ è½½å¤±è´¥")

    async def _switch_to_mock_mode(self, reason: str):
        """åˆ‡æ¢åˆ°Mockæ¨¡å¼"""
        self._mode = "mock"
        self._model = None

        self._model_metadata = {
            "model_version": f"mock_v3_{reason}",
            "target_classes": ["å¹³å±€", "ä¸»é˜Ÿèƒœ", "å®¢é˜Ÿèƒœ"],
            "mock_mode": True,
            "reason": reason,
            "source": "fallback",
        }

        # ä½¿ç”¨ç»Ÿä¸€ç‰¹å¾æå–å™¨çš„ç‰¹å¾
        self._feature_columns = self._get_training_features()

        logger.warning(f"ğŸ”„ è‡ªåŠ¨é™çº§åˆ°Mockæ¨¡å¼ - åŸå› : {reason}")

    def _get_training_features(self) -> list[str]:
        """è·å–è®­ç»ƒæ—¶ä½¿ç”¨çš„ç‰¹å¾åˆ—ï¼ˆä¸feature_extractor.pyä¸€è‡´ï¼‰"""
        return [
            "home_xg",
            "away_xg",
            "home_possession",
            "away_possession",
            "home_shots",
            "away_shots",
            "home_shots_on_target",
            "away_shots_on_target",
            "xg_difference",
            "xg_ratio",
            "possession_difference",
            "shots_difference",
            "home_shot_efficiency",
            "away_shot_efficiency",
        ]

    def _extract_features_from_model(self) -> list[str]:
        """ä»æ¨¡å‹ä¸­æå–ç‰¹å¾åˆ—"""
        # å°è¯•ä»æ¨¡å‹è·å–ç‰¹å¾åˆ—
        if hasattr(self._model, "feature_names_in_"):
            return list(self._model.feature_names_in_)
        elif hasattr(self._model, "feature_names"):
            return list(self._model.feature_names)
        elif hasattr(self._model, "get_booster") and hasattr(
            self._model.get_booster(), "feature_names"
        ):
            return list(self._model.get_booster().feature_names)
        else:
            # ä½¿ç”¨è®­ç»ƒæ•°æ®å‡†å¤‡è„šæœ¬ä¸­çš„ç‰¹å¾
            logger.warning("âš ï¸ æ— æ³•ä»æ¨¡å‹è·å–ç‰¹å¾åˆ—ï¼Œä½¿ç”¨è®­ç»ƒè„šæœ¬ä¸­çš„ç‰¹å¾")
            return self._get_training_features()

    async def _get_features_for_match(self, match_id: int) -> Optional[dict[str, Any]]:
        """ä»æ•°æ®åº“è·å–æ¯”èµ›ç‰¹å¾æ•°æ®ï¼ˆä¸è®­ç»ƒæ•°æ®æ ¼å¼ä¸€è‡´ï¼‰"""
        try:
            logger.info(f"ğŸ” ä»æ•°æ®åº“è·å–æ¯”èµ› {match_id} çš„ç‰¹å¾æ•°æ®")

            # ä½¿ç”¨ç»Ÿä¸€çš„async_manager
            from src.database.async_manager import get_db_session
            from src.database.models import Match
            from sqlalchemy import select

            async with get_db_session() as session:
                # æŸ¥è¯¢æ¯”èµ›æ•°æ®
                result = await session.execute(
                    select(Match).where(Match.id == match_id)
                )
                match = result.scalar_one_or_none()

                if not match:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ¯”èµ› {match_id}")
                    return None

                # ä½¿ç”¨ç‰¹å¾æå–å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                try:
                    from src.features.feature_extractor import FeatureExtractor

                    match_data = {
                        "home_xg": getattr(match, "home_xg", None),
                        "away_xg": getattr(match, "away_xg", None),
                        "home_possession": getattr(match, "home_possession", None),
                        "away_possession": getattr(match, "away_possession", None),
                        "home_shots": getattr(match, "home_shots", None),
                        "away_shots": getattr(match, "away_shots", None),
                        "home_shots_on_target": getattr(
                            match, "home_shots_on_target", None
                        ),
                        "away_shots_on_target": getattr(
                            match, "away_shots_on_target", None
                        ),
                    }
                    features = FeatureExtractor.extract_features_from_match(match_data)
                    logger.info("âœ… ä½¿ç”¨FeatureExtractorè·å–ç‰¹å¾æˆåŠŸ")
                    return features
                except Exception as e:
                    logger.warning(f"âš ï¸ FeatureExtractorå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼: {e}")

                # ä¼ ç»Ÿæ–¹å¼ç‰¹å¾æå–
                features = {
                    # åŸºç¡€ç‰¹å¾
                    "home_xg": getattr(match, "home_xg", 1.5),
                    "away_xg": getattr(match, "away_xg", 1.2),
                    "home_possession": getattr(match, "home_possession", 50.0),
                    "away_possession": getattr(match, "away_possession", 50.0),
                    "home_shots": getattr(match, "home_shots", 12),
                    "away_shots": getattr(match, "away_shots", 10),
                    "home_shots_on_target": getattr(match, "home_shots_on_target", 4),
                    "away_shots_on_target": getattr(match, "away_shots_on_target", 3),
                }

                # ç‰¹å¾å·¥ç¨‹ï¼ˆä¸è®­ç»ƒæ•°æ®å‡†å¤‡è„šæœ¬ä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
                features["xg_difference"] = features["home_xg"] - features["away_xg"]
                features["xg_ratio"] = features["home_xg"] / (
                    features["away_xg"] + 0.001
                )
                features["possession_difference"] = (
                    features["home_possession"] - features["away_possession"]
                )
                features["shots_difference"] = (
                    features["home_shots"] - features["away_shots"]
                )
                features["home_shot_efficiency"] = features["home_shots_on_target"] / (
                    features["home_shots"] + 0.001
                )
                features["away_shot_efficiency"] = features["away_shots_on_target"] / (
                    features["away_shots"] + 0.001
                )

                logger.info(f"âœ… æˆåŠŸè·å–æ¯”èµ› {match_id} çš„ç‰¹å¾æ•°æ®")
                return features

        except Exception as e:
            logger.error(f"âŒ è·å–ç‰¹å¾å¤±è´¥ (match_id={match_id}): {e}")
            return self._get_default_features()

    def _get_default_features(self) -> dict[str, Any]:
        """è·å–é»˜è®¤ç‰¹å¾æ•°æ®ï¼ˆä¸è®­ç»ƒæ•°æ®æ ¼å¼ä¸€è‡´ï¼‰"""
        return {
            "home_xg": 1.5,
            "away_xg": 1.2,
            "home_possession": 50.0,
            "away_possession": 50.0,
            "home_shots": 12,
            "away_shots": 10,
            "home_shots_on_target": 4,
            "away_shots_on_target": 3,
            "xg_difference": 0.3,
            "xg_ratio": 1.25,
            "possession_difference": 0.0,
            "shots_difference": 2,
            "home_shot_efficiency": 0.33,
            "away_shot_efficiency": 0.30,
        }

    async def predict_match(self, match_id: int) -> dict[str, Any]:
        """å¯¹æŒ‡å®šæ¯”èµ›è¿›è¡Œé¢„æµ‹ - APIå…¼å®¹ç‰ˆæœ¬"""
        try:
            logger.info(f"ğŸ”® å¼€å§‹é¢„æµ‹æ¯”èµ› {match_id}")

            # è·å–ç‰¹å¾æ•°æ®
            features = await self._get_features_for_match(match_id)
            if features is None:
                return {
                    "match_id": match_id,
                    "error": "æ— æ³•è·å–æ¯”èµ›ç‰¹å¾æ•°æ®",
                    "success": False,
                }

            # æ ¹æ®æ¨¡å¼é€‰æ‹©é¢„æµ‹æ–¹æ³•
            if self._mode == "mock" or not HAVE_XGBOOST:
                return self._get_mock_prediction(match_id)

            # çœŸå®æ¨¡å‹é¢„æµ‹
            return await self._predict_with_real_model(match_id, features)

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹å¤±è´¥ (match_id={match_id}): {e}")
            return {
                "match_id": match_id,
                "error": f"é¢„æµ‹æœåŠ¡é”™è¯¯: {str(e)}",
                "success": False,
            }

    async def _predict_with_real_model(
        self, match_id: int, features: dict[str, Any]
    ) -> dict[str, Any]:
        """ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        try:
            # æ„å»ºç‰¹å¾å‘é‡ï¼ˆç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            feature_vector = []
            for col in self._feature_columns:
                if col in features:
                    feature_vector.append(features[col])
                else:
                    logger.warning(f"âš ï¸ ç¼ºå¤±ç‰¹å¾åˆ—: {col}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    # ä½¿ç”¨é»˜è®¤å€¼
                    if "efficiency" in col:
                        feature_vector.append(0.3)
                    elif "difference" in col or "ratio" in col:
                        feature_vector.append(0.0)
                    elif "possession" in col:
                        feature_vector.append(50.0)
                    elif "shots" in col:
                        feature_vector.append(10)
                    else:
                        feature_vector.append(1.0)

            logger.info(f"âœ… æ„å»ºçš„ç‰¹å¾å‘é‡é•¿åº¦: {len(feature_vector)}")

            # è½¬æ¢ä¸ºDataFrame
            feature_df = pd.DataFrame([feature_vector], columns=self._feature_columns)

            # è¿›è¡Œé¢„æµ‹
            prediction = self._model.predict(feature_df)[0]
            probabilities = self._model.predict_proba(feature_df)[0]

            # è§£æé¢„æµ‹ç»“æœ
            result = self._parse_prediction_result(prediction, probabilities, match_id)

            logger.info(
                f"âœ… é¢„æµ‹å®Œæˆ: {result['prediction']} (ç½®ä¿¡åº¦: {result['confidence']:.1%})"
            )
            return result

        except Exception as e:
            logger.error(f"âŒ çœŸå®æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            # é™çº§åˆ°Mocké¢„æµ‹
            return self._get_mock_prediction(match_id)

    def _parse_prediction_result(
        self, prediction: int, probabilities: list, match_id: int
    ) -> dict[str, Any]:
        """è§£æé¢„æµ‹ç»“æœ - ä¿æŒAPIå…¼å®¹æ€§"""
        # è·å–æ¨¡å‹ç±»åˆ«
        model_classes = self._model.classes_

        # æ ¹æ®æ¨¡å‹ç±»åˆ«æ•°é‡åŠ¨æ€æ˜ å°„ç»“æœ
        if len(model_classes) == 2:
            # äºŒåˆ†ç±»æ¨¡å‹ï¼š0=éä¸»é˜Ÿèƒœ, 1=ä¸»é˜Ÿèƒœ
            result_names = {0: "away_or_draw", 1: "home_win"}
        else:
            # ä¸‰åˆ†ç±»æ¨¡å‹
            class_list = list(model_classes)
            if (
                "away_win" in class_list
                and "draw" in class_list
                and "home_win" in class_list
            ):
                # V4/P2-5æ¨¡å‹è‹±æ–‡æ ‡ç­¾æ˜ å°„
                away_idx = class_list.index("away_win")
                draw_idx = class_list.index("draw")
                home_idx = class_list.index("home_win")
                result_names = {
                    away_idx: "å®¢é˜Ÿèƒœ",
                    draw_idx: "å¹³å±€",
                    home_idx: "ä¸»é˜Ÿèƒœ",
                }
            else:
                # é»˜è®¤ä¸­æ–‡æ ‡ç­¾æ˜ å°„
                result_names = {0: "å¹³å±€", 1: "ä¸»é˜Ÿèƒœ", 2: "å®¢é˜Ÿèƒœ"}

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = max(probabilities)

        # æ ¼å¼åŒ–æ¦‚ç‡è¾“å‡º
        if len(model_classes) == 2:
            # äºŒåˆ†ç±»å¤„ç†
            prob_home_win = round(float(probabilities[1]), 3)
            prob_not_home_win = round(float(probabilities[0]), 3)
            prob_draw = round(prob_not_home_win * 0.3, 3)
            prob_away_win = round(prob_not_home_win * 0.7, 3)
        else:
            # ä¸‰åˆ†ç±»å¤„ç†
            if "away_win" in class_list:
                float(probabilities[class_list.index("away_win")])
                float(probabilities[class_list.index("draw")])
                float(probabilities[class_list.index("home_win")])
            else:
                # é»˜è®¤é¡ºåºå¤„ç†
                if len(probabilities) == 3:
                    prob_away_win = round(float(probabilities[0]), 3)
                    prob_draw = round(float(probabilities[1]), 3)
                    prob_home_win = round(float(probabilities[2]), 3)
                else:
                    prob_home_win = round(float(probabilities[0]), 3)
                    prob_draw = round(float(probabilities[1]), 3)
                    prob_away_win = round(float(probabilities[2]), 3)

        # ç¡®å®šé¢„æµ‹çš„outcome
        if len(model_classes) == 2:
            predicted_outcome = "home" if prediction == 1 else "away_or_draw"
        else:
            if "away_win" in class_list:
                if prediction == class_list.index("home_win"):
                    predicted_outcome = "home"
                elif prediction == class_list.index("draw"):
                    predicted_outcome = "draw"
                else:
                    predicted_outcome = "away"
            else:
                predicted_outcome = (
                    "home"
                    if prediction == 1
                    else ("draw" if prediction == 0 else "away")
                )

        # APIå…¼å®¹çš„è¿”å›æ ¼å¼
        return {
            "match_id": match_id,
            "prediction": result_names[prediction],
            "predicted_outcome": predicted_outcome,
            "home_win_prob": prob_home_win,
            "draw_prob": prob_draw,
            "away_win_prob": prob_away_win,
            "confidence": float(confidence),
            "success": True,
            "features_used": self._feature_columns,
            "model_version": self._model_metadata.get("model_version", "v3.0"),
            "model_source": self._model_metadata.get("source", "unknown"),
            "mode": self._mode,  # æ–°å¢ï¼šæŒ‡ç¤ºå½“å‰æ¨¡å¼
            "mock_reason": (
                self._model_metadata.get("reason") if self._mode == "mock" else None
            ),  # æ–°å¢ï¼šMockåŸå› 
        }

    def _get_mock_prediction(self, match_id: int) -> dict[str, Any]:
        """è·å–Mocké¢„æµ‹ç»“æœ - APIå…¼å®¹ç‰ˆæœ¬"""
        return {
            "match_id": match_id,
            "prediction": "ä¸»é˜Ÿèƒœ",
            "confidence": 0.65,
            "home_win_prob": 0.65,
            "draw_prob": 0.20,
            "away_win_prob": 0.15,
            "success": True,
            "model_version": self._model_metadata.get("model_version", "mock_v3"),
            "mode": "mock",
            "mock_reason": self._model_metadata.get("reason", "default_mock"),
            "features_used": self._feature_columns,
            "model_source": self._model_metadata.get("source", "mock"),
        }

    async def predict_batch(self, match_ids: list[int]) -> list[dict[str, Any]]:
        """æ‰¹é‡é¢„æµ‹æ¯”èµ›ç»“æœ"""
        tasks = [self.predict_match(match_id) for match_id in match_ids]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(
                    {
                        "match_id": match_ids[i],
                        "error": f"é¢„æµ‹æœåŠ¡é”™è¯¯: {str(result)}",
                        "success": False,
                    }
                )
            else:
                processed_results.append(result)

        return processed_results

    def get_model_info(self) -> dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯ - APIå…¼å®¹ç‰ˆæœ¬"""
        if not self._model_metadata:
            return {"error": "æ¨¡å‹æœªåŠ è½½"}

        return {
            "model_version": self._model_metadata.get("model_version"),
            "model_source": self._model_metadata.get("source", "unknown"),
            "model_type": self._model_metadata.get("model_type", "unknown"),
            "target_classes": self._model_metadata.get("target_classes"),
            "feature_count": len(self._feature_columns) if self._feature_columns else 0,
            "feature_names": self._feature_columns,
            "xgboost_available": HAVE_XGBOOST,
            "mode": self._mode,
            "mock_reason": (
                self._model_metadata.get("reason") if self._mode == "mock" else None
            ),
        }

    def health_check(self) -> dict[str, Any]:
        """å¥åº·æ£€æŸ¥ - APIå…¼å®¹ç‰ˆæœ¬"""
        try:
            if not HAVE_XGBOOST:
                return {
                    "status": "degraded",
                    "model_loaded": False,
                    "feature_count": (
                        len(self._feature_columns) if self._feature_columns else 0
                    ),
                    "initialized": self._initialized,
                    "mode": self._mode,
                    "note": "XGBoost not available - running in mock mode",
                    "xgboost_available": False,
                    "version": "v3.0",
                }

            model_loaded = self._model is not None
            feature_count = len(self._feature_columns) if self._feature_columns else 0

            return {
                "status": (
                    "healthy" if self._mode == "real" and model_loaded else "degraded"
                ),
                "model_loaded": model_loaded,
                "feature_count": feature_count,
                "initialized": self._initialized,
                "mode": self._mode,
                "xgboost_available": True,
                "version": "v3.0",
                "model_source": (
                    self._model_metadata.get("source", "unknown")
                    if self._model_metadata
                    else "unknown"
                ),
            }
        except Exception as e:
            return {"status": "unhealthy", "error": str(e), "version": "v3.0"}


# å…¨å±€æ¨ç†æœåŠ¡å®ä¾‹ (ä¿æŒå‘åå…¼å®¹)
inference_service = InferenceService()


# æ–°å¢ï¼šè·å–æœåŠ¡å®ä¾‹çš„ä¾¿æ·æ–¹æ³•
async def get_inference_service() -> InferenceService:
    """è·å–æ¨ç†æœåŠ¡å®ä¾‹ (å¼‚æ­¥å‹å¥½ç‰ˆæœ¬)"""
    return inference_service
