#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆåŸºç¡€ä»“å‚¨
é›†æˆå¼‚æ­¥I/Oä¼˜åŒ–å’ŒæŸ¥è¯¢ä¼˜åŒ–åŠŸèƒ½
"""

from abc import ABC, abstractmethod
from collections.abc import Callable
from typing import Any, Generic, TypeVar

from sqlalchemy import delete
from sqlalchemy.ext.asyncio import AsyncSession

from src.database.connection import DatabaseManager
from src.database.repositories.base import BaseRepository
from src.performance.async_optimizer import get_batch_processor, get_connection_pool
from src.performance.db_query_optimizer import get_query_optimizer

T = TypeVar("T")


class OptimizedRepository(BaseRepository[T], ABC, Generic[T]):
    """
    ä¼˜åŒ–ç‰ˆåŸºç¡€ä»“å‚¨
    é›†æˆå¼‚æ­¥I/Oä¼˜åŒ–å’ŒæŸ¥è¯¢ä¼˜åŒ–åŠŸèƒ½ï¼Œæä¾›é«˜æ€§èƒ½çš„æ•°æ®è®¿é—®
    """

    def __init__(self, model_class: type[T], db_manager: DatabaseManager | None = None):
        super().__init__(model_class, db_manager)
        self.query_optimizer = get_query_optimizer()
        self.connection_pool = get_connection_pool()
        self.batch_processor = get_batch_processor()

    # ========================================
    # ä¼˜åŒ–çš„CRUDæ“ä½œ
    # ========================================

    async def create_optimized(
        self, obj_data: dict[str, Any], session: AsyncSession | None = None
    ) -> T:
        """
        ä¼˜åŒ–çš„åˆ›å»ºæ“ä½œ
        ä½¿ç”¨è¿æ¥æ± å’ŒæŸ¥è¯¢ä¼˜åŒ–
        """
        if session:
            # å¦‚æœæä¾›äº†ä¼šè¯ï¼Œç›´æ¥ä½¿ç”¨
            db_obj = self.model_class(**obj_data)
            session.add(db_obj)
            await session.commit()
            await session.refresh(db_obj)
            return db_obj
        else:
            # ä½¿ç”¨ä¼˜åŒ–çš„è¿æ¥æ± 
            async with self.connection_pool.get_connection() as sess:
                return await self._execute_create(sess, obj_data)

    async def _execute_create(
        self, session: AsyncSession, obj_data: dict[str, Any]
    ) -> T:
        """å†…éƒ¨åˆ›å»ºæ‰§è¡Œæ–¹æ³•"""
        db_obj = self.model_class(**obj_data)
        session.add(db_obj)
        await session.commit()
        await session.refresh(db_obj)
        return db_obj

    async def get_by_id_optimized(
        self, obj_id: int | str, session: AsyncSession | None = None
    ) -> T | None:
        """
        ä¼˜åŒ–çš„æ ¹æ®IDè·å–è®°å½•
        ä½¿ç”¨æŸ¥è¯¢ä¼˜åŒ–å’Œç¼“å­˜
        """
        query = f"SELECT * FROM {self._model_name.lower()} WHERE id = :id"
        params = {"id": obj_id}

        return await self.query_optimizer.execute_optimized_query(
            query, params, analyze=True, auto_explain=False
        )

    async def find_by_optimized(
        self,
        filters: dict[str, Any],
        limit: int | None = None,
        offset: int | None = None,
        order_by: str | None = None,
        session: AsyncSession | None = None,
    ) -> list[T]:
        """
        ä¼˜åŒ–çš„æ¡ä»¶æŸ¥è¯¢
        ä½¿ç”¨æŸ¥è¯¢åˆ†æå’Œæ‰§è¡Œè®¡åˆ’ä¼˜åŒ–
        """
        # æ„å»ºä¼˜åŒ–æŸ¥è¯¢
        query = f"SELECT * FROM {self._model_name.lower()} WHERE 1=1"
        params = {}

        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        for key, value in filters.items():
            if hasattr(self.model_class, key):
                query += f" AND {key} = :{key}"
                params[key] = value

        # æ·»åŠ æ’åº
        if order_by and hasattr(self.model_class, order_by):
            query += f" ORDER BY {order_by}"

        # æ·»åŠ åˆ†é¡µ
        if limit:
            query += f" LIMIT {limit}"
        if offset:
            query += f" OFFSET {offset}"

        return await self.query_optimizer.execute_optimized_query(query, params)

    async def find_by_with_index_hint(
        self,
        filters: dict[str, Any],
        index_hint: str | None = None,
        limit: int | None = None,
        offset: int | None = None,
    ) -> list[T]:
        """
        ä½¿ç”¨ç´¢å¼•æç¤ºçš„æŸ¥è¯¢
        """
        query = f"SELECT * FROM {self._model_name.lower()}"
        if index_hint:
            query += f" USE INDEX ({index_hint})"

        query += " WHERE 1=1"
        params = {}

        for key, value in filters.items():
            if hasattr(self.model_class, key):
                query += f" AND {key} = :{key}"
                params[key] = value

        if limit:
            query += f" LIMIT {limit}"
        if offset:
            query += f" OFFSET {offset}"

        return await self.query_optimizer.execute_optimized_query(query, params)

    # ========================================
    # æ‰¹é‡æ“ä½œä¼˜åŒ–
    # ========================================

    async def bulk_create_optimized(
        self, objects_data: list[dict[str, Any]]
    ) -> list[T]:
        """
        ä¼˜åŒ–çš„æ‰¹é‡åˆ›å»º
        ä½¿ç”¨å¼‚æ­¥æ‰¹é‡å¤„ç†å™¨
        """

        async def process_batch(batch_data: list[dict[str, Any]]) -> list[T]:
            async with self.connection_pool.get_connection() as session:
                db_objects = [self.model_class(**data) for data in batch_data]
                session.add_all(db_objects)
                await session.commit()

                # åˆ·æ–°å¯¹è±¡ä»¥è·å–ID
                for obj in db_objects:
                    await session.refresh(obj)

                return db_objects

        # ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨
        results = await self.batch_processor.process_batch(objects_data, process_batch)
        # æ‰å¹³åŒ–ç»“æœ
        return [item for sublist in results if sublist for item in sublist]

    async def bulk_update_optimized(self, updates: list[dict[str, Any]]) -> int:
        """
        ä¼˜åŒ–çš„æ‰¹é‡æ›´æ–°
        ä½¿ç”¨CASE WHENè¯­å¥ä¼˜åŒ–
        """
        if not updates:
            return 0

        # æ„å»ºæ‰¹é‡æ›´æ–°æŸ¥è¯¢
        ids = [update["id"] for update in updates if "id" in update]
        if not ids:
            return 0

        # è·å–ç¬¬ä¸€ä¸ªæ›´æ–°çš„å­—æ®µä½œä¸ºæ¨¡æ¿
        first_update = next(u for u in updates if "id" in u and len(u) > 1)
        update_fields = [k for k in first_update.keys() if k != "id"]

        if not update_fields:
            return 0

        # æ„å»ºCASE WHENè¯­å¥
        query = f"UPDATE {self._model_name.lower()} SET "
        params = {}

        for i, field in enumerate(update_fields):
            query += f"{field} = CASE id "
            for update in updates:
                if "id" in update and field in update:
                    query += (
                        f"WHEN :id_{i}_{update['id']} THEN :{field}_{i}_{update['id']} "
                    )
                    params[f"id_{i}_{update['id']}"] = update["id"]
                    params[f"{field}_{i}_{update['id']}"] = update[field]
            query += "END"
            if i < len(update_fields) - 1:
                query += ", "

        query += " WHERE id IN :ids"
        params["ids"] = ids

        async with self.connection_pool.get_connection() as session:
            stmt = update(self.model_class).where(self.model_class.id.in_(ids))

            # æ‰§è¡Œæ›´æ–°
            for update_data in updates:
                if "id" in update_data:
                    obj_id = update_data.pop("id")
                    stmt = stmt.where(self.model_class.id == obj_id).values(
                        **update_data
                    )

            result = await session.execute(stmt)
            await session.commit()
            return result.rowcount

    async def bulk_delete_optimized(self, ids: list[int | str]) -> int:
        """
        ä¼˜åŒ–çš„æ‰¹é‡åˆ é™¤
        """
        if not ids:
            return 0

        query = f"DELETE FROM {self._model_name.lower()} WHERE id = ANY(:ids)"
        params = {"ids": ids}

        async with self.connection_pool.get_connection() as session:
            stmt = delete(self.model_class).where(self.model_class.id.in_(ids))
            result = await session.execute(stmt)
            await session.commit()
            return result.rowcount

    # ========================================
    # é«˜çº§æŸ¥è¯¢åŠŸèƒ½
    # ========================================

    async def find_with_joins(
        self,
        filters: dict[str, Any] | None = None,
        joins: list[dict[str, Any]] | None = None,
        select_fields: list[str] | None = None,
        limit: int | None = None,
        offset: int | None = None,
    ) -> list[dict[str, Any]]:
        """
        å¸¦è¿æ¥çš„å¤æ‚æŸ¥è¯¢

        Args:
            filters: è¿‡æ»¤æ¡ä»¶
            joins: è¿æ¥é…ç½® [{"table": "related_table", "local_key": "id", "foreign_key": "related_id"}, ...]
            select_fields: é€‰æ‹©çš„å­—æ®µ
            limit: é™åˆ¶æ•°é‡
            offset: åç§»é‡

        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸åˆ—è¡¨
        """
        # æ„å»ºåŸºç¡€æŸ¥è¯¢
        query = "SELECT"
        params = {}

        # é€‰æ‹©å­—æ®µ
        if select_fields:
            query += ", ".join(select_fields)
        else:
            query += f"{self._model_name.lower()}.*"

        query += f" FROM {self._model_name.lower()}"

        # æ·»åŠ è¿æ¥
        if joins:
            for join_config in joins:
                join_table = join_config["table"]
                local_key = join_config["local_key"]
                foreign_key = join_config["foreign_key"]
                join_type = join_config.get("type", "INNER JOIN")

                query += f" {join_type} {join_table} ON {self._model_name.lower()}.{local_key} = {join_table}.{foreign_key}"

        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            query += " WHERE 1=1"
            for key, value in filters.items():
                query += f" AND {key} = :{key}"
                params[key] = value

        # æ·»åŠ åˆ†é¡µ
        if limit:
            query += f" LIMIT {limit}"
        if offset:
            query += f" OFFSET {offset}"

        return await self.query_optimizer.execute_optimized_query(query, params)

    async def find_aggregated(
        self,
        group_by: list[str],
        aggregates: dict[str, str],
        filters: dict[str, Any] | None = None,
        having: dict[str, Any] | None = None,
        order_by: str | None = None,
    ) -> list[dict[str, Any]]:
        """
        èšåˆæŸ¥è¯¢

        Args:
            group_by: åˆ†ç»„å­—æ®µ
            aggregates: èšåˆå‡½æ•° {"total": "SUM(amount)", "count": "COUNT(*)"}
            filters: è¿‡æ»¤æ¡ä»¶
            having: HAVINGæ¡ä»¶
            order_by: æ’åºå­—æ®µ

        Returns:
            èšåˆç»“æœåˆ—è¡¨
        """
        # æ„å»ºSELECTå­å¥
        select_fields = group_by.copy()
        for alias, func in aggregates.items():
            select_fields.append(f"{func} as {alias}")

        query = f"SELECT {', '.join(select_fields)} FROM {self._model_name.lower()}"
        params = {}

        # WHEREæ¡ä»¶
        if filters:
            query += " WHERE 1=1"
            for key, value in filters.items():
                query += f" AND {key} = :{key}"
                params[key] = value

        # GROUP BY
        query += f" GROUP BY {', '.join(group_by)}"

        # HAVINGæ¡ä»¶
        if having:
            query += " HAVING 1=1"
            for key, value in having.items():
                query += f" AND {key} = :having_{key}"
                params[f"having_{key}"] = value

        # ORDER BY
        if order_by:
            query += f" ORDER BY {order_by}"

        return await self.query_optimizer.execute_optimized_query(query, params)

    async def exists_with_cache(
        self, filters: dict[str, Any], cache_ttl: int = 300
    ) -> bool:
        """
        å¸¦ç¼“å­˜çš„å­˜åœ¨æ€§æ£€æŸ¥
        """
        cache_key = f"exists_{self._model_name}_{str(filters)}"

        # è¿™é‡Œå¯ä»¥é›†æˆRedisç¼“å­˜
        # æš‚æ—¶ç›´æ¥æŸ¥è¯¢æ•°æ®åº“
        query = f"SELECT EXISTS(SELECT 1 FROM {self._model_name.lower()} WHERE 1=1"
        params = {}

        for key, value in filters.items():
            if hasattr(self.model_class, key):
                query += f" AND {key} = :{key}"
                params[key] = value

        query += ")"

        result = await self.query_optimizer.execute_optimized_query(
            query, params, use_cache=True
        )
        return bool(result)

    # ========================================
    # æ€§èƒ½ç›‘æ§å’Œåˆ†æ
    # ========================================

    async def analyze_query_performance(
        self, filters: dict[str, Any] | None = None
    ) -> dict[str, Any]:
        """
        åˆ†ææŸ¥è¯¢æ€§èƒ½
        """
        # æ„å»ºæµ‹è¯•æŸ¥è¯¢
        query = f"SELECT * FROM {self._model_name.lower()}"
        params = {}

        if filters:
            query += " WHERE 1=1"
            for key, value in filters.items():
                query += f" AND {key} = :{key}"
                params[key] = value

        # è·å–æŸ¥è¯¢åˆ†æ
        analysis = self.query_optimizer.analyzer.analyze_query(query)

        # æ·»åŠ è¡¨ç‰¹å®šä¿¡æ¯
        analysis["table_name"] = self._model_name.lower()
        analysis["repository_type"] = "optimized"

        return analysis

    def get_performance_metrics(self) -> dict[str, Any]:
        """
        è·å–ä»“å‚¨æ€§èƒ½æŒ‡æ ‡
        """
        return {
            "query_optimizer_metrics": self.query_optimizer.get_performance_report(),
            "connection_pool_stats": self.connection_pool.get_pool_stats(),
            "batch_processor_metrics": self.batch_processor.metrics.__dict__,
        }

    # ========================================
    # äº‹åŠ¡ä¼˜åŒ–
    # ========================================

    async def execute_transaction_optimized(
        self, operations: list[Callable[[AsyncSession], Any]]
    ) -> list[Any]:
        """
        ä¼˜åŒ–çš„äº‹åŠ¡æ‰§è¡Œ
        ä½¿ç”¨è¿æ¥æ± å’Œé”™è¯¯å¤„ç†
        """
        async with self.connection_pool.get_connection() as session:
            try:
                results = []
                for operation in operations:
                    result = await operation(session)
                    results.append(result)

                await session.commit()
                return results

            except Exception as e:
                await session.rollback()
                logger.error(f"ä¼˜åŒ–äº‹åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                raise

    # ========================================
    # æŠ½è±¡æ–¹æ³•å®ç°
    # ========================================

    @abstractmethod
    async def get_related_data(
        self,
        obj_id: int | str,
        relation_name: str,
        session: AsyncSession | None = None,
    ) -> Any:
        """
        è·å–å…³è”æ•°æ®ï¼ˆå­ç±»éœ€è¦å®ç°ï¼‰
        """
        pass


# ä¾¿æ·å‡½æ•°
async def create_optimized_repository(
    model_class: type[T], db_manager: DatabaseManager | None = None
) -> OptimizedRepository[T]:
    """
    åˆ›å»ºä¼˜åŒ–ä»“å‚¨å®ä¾‹
    """
    # è¿™é‡Œéœ€è¦å…·ä½“çš„å­ç±»å®ç°
    # è¿”å›åŸºç±»å®ä¾‹ç”¨äºæ¼”ç¤º
    return OptimizedRepository(model_class, db_manager)


if __name__ == "__main__":

    async def demo_optimized_repository():
        """æ¼”ç¤ºä¼˜åŒ–ä»“å‚¨åŠŸèƒ½"""
        print("ğŸš€ æ¼”ç¤ºä¼˜åŒ–ä»“å‚¨åŠŸèƒ½")

        # è¿™é‡Œéœ€è¦å®é™…çš„æ¨¡å‹ç±»
        # from src.domain.entities import Match
        # repo = OptimizedRepository(Match)

        print("âœ… ä¼˜åŒ–ä»“å‚¨åŠŸèƒ½æ¼”ç¤ºå®Œæˆ")

    import asyncio

    asyncio.run(demo_optimized_repository())
