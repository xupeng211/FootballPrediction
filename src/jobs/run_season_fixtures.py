#!/usr/bin/env python3
"""
å…¨é‡L1é‡‡é›†è„šæœ¬ - 2023-24è‹±è¶…å®Œæ•´èµ›å­£ç‰ˆæœ¬ (æ ‡å‡†åŒ–å…¥å£)
Full Season L1 Collection Script - Complete 2023-24 Premier League Version (Standard Entry Point)
"""

import asyncio
import sys
import os
from datetime import datetime
import logging
from pathlib import Path

# å…³é”®ä¿®æ­£ï¼šæ·»åŠ é¡¹ç›®æ ¹è·¯å¾„åˆ°sys.pathï¼Œç¡®ä¿èƒ½æ­£ç¡®å¯¼å…¥srcæ¨¡å—
# å½“å‰æ–‡ä»¶ä½ç½®ï¼šsrc/jobs/run_season_fixtures.py
# é¡¹ç›®æ ¹ç›®å½•ï¼šsrc/jobs/çš„ä¸Šä¸€çº§
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.collectors.html_fotmob_collector import HTMLFotMobCollector
import psycopg2
import requests
import json
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
DATABASE_URL = "postgresql://postgres:postgres-dev-password@localhost:5432/football_prediction"


def save_teams_to_db(teams_data):
    """ç›´æ¥ä½¿ç”¨SQLä¿å­˜çƒé˜Ÿæ•°æ®"""
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()

        saved_count = 0
        for team in teams_data:
            try:
                team_id = team.get("id")
                team_name = team.get("name")
                if not team_name:
                    continue

                # ç®€å•æ’å…¥ï¼Œè·³è¿‡é‡å¤
                cur.execute("""
                    INSERT INTO teams (name, country, fotmob_external_id, created_at, updated_at)
                    VALUES (%s, %s, %s, NOW(), NOW())
                    ON CONFLICT (fotmob_external_id) DO NOTHING
                """, (team_name, "England", team_id))

                if cur.rowcount > 0:
                    saved_count += 1
                    logger.info(f"ğŸ’¾ æ–°å¢çƒé˜Ÿ: {team_name} (ID: {team_id})")

            except Exception as e:
                logger.warning(f"âš ï¸ ä¿å­˜çƒé˜Ÿå¤±è´¥: {team.get('id', 'unknown')} - {e}")

        conn.commit()
        conn.close()
        logger.info(f"âœ… æˆåŠŸä¿å­˜ {saved_count} æ”¯æ–°çƒé˜Ÿ")
        return saved_count

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜çƒé˜Ÿæ•°æ®å¤±è´¥: {e}")
        return 0


def save_matches_to_db(match_data):
    """ç›´æ¥ä½¿ç”¨SQLä¿å­˜æ¯”èµ›æ•°æ®"""
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()

        # è·å–çƒé˜Ÿæ˜ å°„
        cur.execute("SELECT fotmob_external_id, id FROM teams WHERE fotmob_external_id IS NOT NULL")
        team_mapping = {row[0]: row[1] for row in cur.fetchall()}

        saved_count = 0
        for match in match_data:
            try:
                fotmob_id = str(match.get("id", ""))
                home_team = match.get("home", {}).get("name", "")
                away_team = match.get("away", {}).get("name", "")

                # è·å–çƒé˜ŸID
                home_fotmob_id = match.get("home", {}).get("id")
                away_fotmob_id = match.get("away", {}).get("id")

                home_team_id = team_mapping.get(home_fotmob_id)
                away_team_id = team_mapping.get(away_fotmob_id)

                if not home_team_id or not away_team_id:
                    logger.warning(f"âš ï¸ è·³è¿‡æ¯”èµ›ï¼ˆæ‰¾ä¸åˆ°çƒé˜Ÿï¼‰: {fotmob_id} - {home_team} vs {away_team}")
                    continue

                # æ’å…¥æ¯”èµ›
                cur.execute("""
                    INSERT INTO matches (
                        home_team_id, away_team_id,
                        home_score, away_score, status, match_date,
                        fotmob_id, data_source, data_completeness, created_at, updated_at
                    ) VALUES (
                        %s, %s, 0, 0, 'pending', NOW(),
                        %s, 'fotmob_v2', 'partial', NOW(), NOW()
                    )
                    ON CONFLICT (fotmob_id) DO NOTHING
                """, (home_team_id, away_team_id, fotmob_id))

                if cur.rowcount > 0:
                    saved_count += 1
                    logger.info(f"ğŸ’¾ ä¿å­˜æ¯”èµ›: {fotmob_id} - {home_team} vs {away_team}")

            except Exception as e:
                logger.warning(f"âš ï¸ ä¿å­˜æ¯”èµ›å¤±è´¥: {match.get('id', 'unknown')} - {e}")

        conn.commit()
        conn.close()
        logger.info(f"âœ… æˆåŠŸä¿å­˜ {saved_count} åœºæ¯”èµ›")
        return saved_count

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ¯”èµ›æ•°æ®å¤±è´¥: {e}")
        return 0


def extract_nextjs_data(html):
    """ä»HTMLä¸­æå–Next.jsæ•°æ®"""
    patterns = [
        r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*type=["\']application/json["\'][^>]*>(.*?)</script>',
        r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*>(.*?)</script>',
        r'window\.__NEXT_DATA__\s*=\s*(\{.*?\});?\s*<\/script>'
    ]

    for pattern in patterns:
        matches = re.findall(pattern, html, re.DOTALL)
        if matches:
            nextjs_data_str = matches[0].strip()
            if nextjs_data_str.startswith('window.__NEXT_DATA__'):
                nextjs_data_str = nextjs_data_str.replace('window.__NEXT_DATA__', '').replace('=', '').strip()
                if nextjs_data_str.endswith(';'):
                    nextjs_data_str = nextjs_data_str[:-1]
            try:
                return json.loads(nextjs_data_str)
            except json.JSONDecodeError:
                continue
    return None


def extract_fixtures_data(nextjs_data):
    """ä»Next.jsæ•°æ®ä¸­æå–æ¯”èµ›æ•°æ®"""
    try:
        matches = []
        props = nextjs_data.get("props", {})
        page_props = props.get("pageProps", {})

        # è·¯å¾„1: fixtures
        fixtures = page_props.get("fixtures", {})
        if fixtures:
            extracted_matches = extract_matches_from_fixtures(fixtures)
            matches.extend(extracted_matches)
            if extracted_matches:
                logger.info(f"ğŸ“… ä»fixturesæå–åˆ° {len(extracted_matches)} åœºæ¯”èµ›")

        # è·¯å¾„2: overview.allMatches (ä¸»è¦æ•°æ®æº)
        if not matches:
            overview = page_props.get("overview", {})
            if overview:
                matches_data = overview.get("matches", {})
                if "allMatches" in matches_data:
                    all_matches = matches_data["allMatches"]
                    if isinstance(all_matches, list):
                        valid_matches = [m for m in all_matches if is_valid_match(m)]
                        matches.extend(valid_matches)
                        logger.info(f"ğŸ“… ä»overview.allMatchesæå–åˆ° {len(valid_matches)} åœºæ¯”èµ›")

        # è·¯å¾„3: é¡µé¢çº§æ·±åº¦æœç´¢
        if not matches:
            logger.info("ğŸ” åœ¨é¡µé¢æ•°æ®ä¸­æ·±åº¦æœç´¢æ¯”èµ›...")
            page_matches = recursive_search_matches(page_props, "pageProps")
            matches.extend(page_matches)
            if page_matches:
                logger.info(f"ğŸ“… æ·±åº¦æœç´¢æ‰¾åˆ° {len(page_matches)} åœºæ¯”èµ›")

        # è¿‡æ»¤æœ‰æ•ˆæ¯”èµ› - å…¨é‡å¤„ç†ï¼Œæ— åˆ‡ç‰‡é™åˆ¶
        valid_matches = []
        for match in matches:
            if isinstance(match, dict) and is_valid_match(match):
                # ç¡®ä¿æ¯”èµ›æœ‰è”èµ›ID
                if "leagueId" not in match:
                    match["leagueId"] = 47  # Premier League
                if "leagueName" not in match:
                    match["leagueName"] = "Premier League"
                valid_matches.append(match)

        return valid_matches

    except Exception as e:
        logger.error(f"âŒ fixturesæ•°æ®æå–å¼‚å¸¸: {e}")
        return []


def extract_matches_from_fixtures(fixtures_data):
    """ä»fixturesæ•°æ®ä¸­æå–æ¯”èµ›åˆ—è¡¨"""
    try:
        matches = []

        if isinstance(fixtures_data, dict):
            if "matches" in fixtures_data:
                direct_matches = fixtures_data["matches"]
                if isinstance(direct_matches, list):
                    matches.extend(direct_matches)

            # é€’å½’æœç´¢matches
            if not matches:
                matches.extend(recursive_search_matches(fixtures_data))

        return matches

    except Exception as e:
        logger.error(f"âŒ fixturesæ¯”èµ›æå–å¼‚å¸¸: {e}")
        return []


def recursive_search_matches(data, path="", depth=0, max_depth=6):
    """é€’å½’æœç´¢matchesæ•°æ®"""
    matches = []

    if depth > max_depth:
        return matches

    try:
        if isinstance(data, dict):
            for key, value in data.items():
                key_lower = str(key).lower()

                if key_lower == "matches" and isinstance(value, list):
                    logger.debug(f"ğŸ” åœ¨ {path}.{key} æ‰¾åˆ°matches: {len(value)} åœºæ¯”èµ›")
                    for match in value:
                        if isinstance(match, dict) and is_valid_match(match):
                            matches.append(match)

                elif isinstance(value, (dict, list)):
                    new_path = f"{path}.{key}" if path else key
                    matches.extend(recursive_search_matches(value, new_path, depth + 1, max_depth))

        elif isinstance(data, list) and len(data) > 0:
            for i, item in enumerate(data):
                if isinstance(item, (dict, list)):
                    new_path = f"{path}[{i}]" if path else f"[{i}]"
                    matches.extend(recursive_search_matches(item, new_path, depth + 1, max_depth))

    except Exception as e:
        logger.debug(f"é€’å½’æœç´¢å¼‚å¸¸ (è·¯å¾„: {path}): {e}")

    return matches


def is_valid_match(match):
    """éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ¯”èµ›æ•°æ®"""
    required_fields = ["home", "away"]
    has_home_away = any(field in match for field in required_fields)
    has_id = "id" in match
    return has_home_away or has_id


def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("""
ğŸ† è‹±è¶…èµ›å­£æ•°æ®é‡‡é›†å·¥å…·
==========================

ç”¨æ³•:
  python3 src/jobs/run_season_fixtures.py [é€‰é¡¹]

é€‰é¡¹:
  --help, -h    æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  --dry-run     ä»…æµ‹è¯•ç½‘ç»œè¿æ¥å’Œæ•°æ®æå–ï¼Œä¸å†™å…¥æ•°æ®åº“
  --league-id   æŒ‡å®šè”èµ›ID (é»˜è®¤: 47 = Premier League)
  --verbose     è¯¦ç»†æ—¥å¿—è¾“å‡º

ç¤ºä¾‹:
  python3 src/jobs/run_season_fixtures.py                    # æ ‡å‡†æ¨¡å¼
  python3 src/jobs/run_season_fixtures.py --dry-run         # æµ‹è¯•æ¨¡å¼
  python3 src/jobs/run_season_fixtures.py --verbose         # è¯¦ç»†æ¨¡å¼

æ³¨æ„:
  - æ­¤è„šæœ¬ä¼šé‡‡é›†å®Œæ•´çš„èµ›å­£æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
  - ç¡®ä¿æ•°æ®åº“æœåŠ¡æ­£åœ¨è¿è¡Œ
  - é¦–æ¬¡è¿è¡Œä¼šåˆ›å»ºçƒé˜Ÿå’Œæ¯”èµ›è®°å½•
    """)


async def main():
    """ä¸»å‡½æ•° - å…¨èµ›å­£é‡‡é›†"""
    import argparse

    parser = argparse.ArgumentParser(description='è‹±è¶…èµ›å­£æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--dry-run', action='store_true', help='ä»…æµ‹è¯•ï¼Œä¸å†™å…¥æ•°æ®åº“')
    parser.add_argument('--league-id', type=int, default=47, help='è”èµ›ID (é»˜è®¤: 47)')
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†æ—¥å¿—')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    logger.info("ğŸš€ å¯åŠ¨2023-24è‹±è¶…å…¨èµ›å­£L1æ•°æ®é‡‡é›†")
    logger.info("ğŸ¯ ç›®æ ‡ï¼šå®Œæ•´380åœºè‹±è¶…æ¯”èµ› + æ•°æ®åº“å­˜å‚¨")

    if args.dry_run:
        logger.info("ğŸ§ª è¿è¡Œåœ¨æµ‹è¯•æ¨¡å¼ - ä¸ä¼šå†™å…¥æ•°æ®åº“")

    # åˆå§‹åŒ–é‡‡é›†å™¨
    collector = HTMLFotMobCollector(
        max_retries=3,
        timeout=(10, 30),
        enable_stealth=True
    )
    await collector.initialize()

    try:
        # è”èµ›é¡µé¢URL
        test_url = f"https://www.fotmob.com/leagues/{args.league_id}/overview/premier-league"
        logger.info(f"ğŸ•·ï¸ è®¿é—®è‹±è¶…è”èµ›é¡µé¢: {test_url}")

        # å‘èµ·è¯·æ±‚
        response = requests.get(
            test_url,
            headers=collector._get_current_headers(),
            timeout=collector.timeout,
            allow_redirects=True,
            verify=False
        )

        logger.info(f"ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}, å¤§å°: {len(response.text):,} å­—ç¬¦")

        if response.status_code != 200:
            logger.error(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
            return 1

        # æå–Next.jsæ•°æ®
        if '__NEXT_DATA__' not in response.text:
            logger.error("âŒ é¡µé¢æ— Next.jsæ•°æ®")
            return 1

        nextjs_data = extract_nextjs_data(response.text)
        if not nextjs_data:
            logger.error("âŒ Next.jsæ•°æ®è§£æå¤±è´¥")
            return 1

        logger.info("âœ… Next.jsæ•°æ®è§£ææˆåŠŸ")

        # æå–æ¯”èµ›æ•°æ® - å…¨é‡æ— é™åˆ¶
        matches = extract_fixtures_data(nextjs_data)
        if matches:
            logger.info(f"ğŸ‰ æˆåŠŸæ‰¾åˆ° {len(matches)} åœºæ¯”èµ›æ•°æ®!")

            # æ˜¾ç¤ºå‰å‡ åœºæ¯”èµ›ä¿¡æ¯
            logger.info("âš½ æ¯”èµ›åˆ—è¡¨é¢„è§ˆ:")
            for j, match in enumerate(matches[:10], 1):
                home = match.get("home", {}).get("name", "Unknown")
                away = match.get("away", {}).get("name", "Unknown")
                match_id = match.get("id", "N/A")
                logger.info(f"   {j:2d}. {home:<25} vs {away:<25} (ID: {match_id})")

            if len(matches) > 10:
                logger.info(f"   ... è¿˜æœ‰ {len(matches) - 10} åœºæ¯”èµ›")

            if not args.dry_run:
                # æå–æ‰€æœ‰çƒé˜Ÿæ•°æ® - å…¨é‡å¤„ç†
                teams_data = [
                    {"id": team.get("id"), "name": team.get("name")}
                    for match in matches  # å…¨éƒ¨æ¯”èµ›ï¼Œæ— åˆ‡ç‰‡
                    for team in [match.get("home", {}), match.get("away", {})]
                ]
                unique_teams = {team["id"]: team for team in teams_data if team.get("id")}
                unique_team_list = list(unique_teams.values())

                logger.info(f"ğŸ† å‘ç° {len(unique_team_list)} æ”¯ç‹¬ç‰¹çƒé˜Ÿ")

                # ä¿å­˜çƒé˜Ÿæ•°æ®
                if unique_team_list:
                    logger.info("ğŸ’¾ å¼€å§‹ä¿å­˜çƒé˜Ÿæ•°æ®...")
                    teams_saved = save_teams_to_db(unique_team_list)
                    if teams_saved > 0:
                        logger.info(f"âœ… çƒé˜Ÿæ•°æ®ä¿å­˜æˆåŠŸ: {teams_saved} æ”¯æ–°çƒé˜Ÿ")

                # ä¿å­˜æ¯”èµ›æ•°æ® - å…¨é‡å¤„ç†
                logger.info("ğŸ’¾ å¼€å§‹ä¿å­˜æ¯”èµ›æ•°æ®åˆ°æ•°æ®åº“...")
                matches_saved = save_matches_to_db(matches)
                if matches_saved > 0:
                    logger.info(f"âœ… æ¯”èµ›æ•°æ®ä¿å­˜æˆåŠŸ: {matches_saved} åœºæ¯”èµ›")

                    # æœ€ç»ˆç»Ÿè®¡
                    logger.info("ğŸŠ **2023-24è‹±è¶…å…¨èµ›å­£L1é‡‡é›†å®Œæˆï¼**")
                    logger.info(f"   ğŸ“Š æ€»æ¯”èµ›æ•°: {len(matches)}")
                    logger.info(f"   ğŸ’¾ å…¥åº“æ¯”èµ›: {matches_saved}")
                    logger.info(f"   ğŸ† å‚èµ›çƒé˜Ÿ: {len(unique_team_list)}")

                    return 0
                else:
                    logger.warning("âš ï¸ æ¯”èµ›æ•°æ®ä¿å­˜å¤±è´¥")
                    return 1
            else:
                logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼å®Œæˆ - æœªå†™å…¥æ•°æ®åº“")
                return 0
        else:
            logger.error("âŒ æœªæ‰¾åˆ°æ¯”èµ›æ•°æ®")
            return 1

    except Exception as e:
        logger.error(f"âŒ å…¨èµ›å­£é‡‡é›†å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1

    finally:
        await collector.close()


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)
