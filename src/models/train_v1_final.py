#!/usr/bin/env python3
"""
V1.1 å®æˆ˜çº§é¢„æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬
é¦–å¸­AIç§‘å­¦å®¶: Gold Standard Training & ROI Simulation

Purpose: è®­ç»ƒå…·æœ‰å®æˆ˜ä»·å€¼çš„è¶³çƒé¢„æµ‹æ¨¡å‹å¹¶è¿›è¡ŒROIæ¨¡æ‹Ÿ
"""

import logging
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# MLç›¸å…³åº“
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb
import joblib
from sklearn.calibration import CalibratedClassifierCV

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# å¯¼å…¥é¢„æµ‹ç»“æœéªŒè¯å™¨
from src.utils.prediction_validator import PredictionResultValidator

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)8s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


class V1FinalModelTrainer:
    """V1.1 å®æˆ˜çº§é¢„æµ‹æ¨¡å‹è®­ç»ƒå™¨"""

    def __init__(self):
        self.model = None
        self.scaler = None
        self.label_encoder = None
        self.feature_names = None
        self.training_results = {}

    def load_training_data(self, data_path: str) -> pd.DataFrame:
        """
        åŠ è½½è®­ç»ƒæ•°æ®

        Args:
            data_path: è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„

        Returns:
            è®­ç»ƒæ•°æ®DataFrame
        """
        try:
            logger.info(f"ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®: {data_path}")
            df = pd.read_csv(data_path)

            logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape}")
            logger.info(f"ğŸ“Š æ•°æ®åˆ—: {list(df.columns)}")

            return df

        except Exception as e:
            logger.error(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def prepare_features_and_target(self, df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
        """
        å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡

        Args:
            df: åŸå§‹æ•°æ®DataFrame

        Returns:
            ç‰¹å¾DataFrameå’Œç›®æ ‡Series
        """
        try:
            logger.info("ğŸ”§ å¼€å§‹å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡...")

            # åŸºç¡€ç‰¹å¾åˆ—ï¼ˆæ’é™¤éç‰¹å¾åˆ—ï¼‰
            exclude_cols = [
                'match_id', 'home_team_id', 'away_team_id', 'match_date',
                'home_score', 'away_score', 'goal_difference', 'result', 'season'
            ]

            feature_cols = [col for col in df.columns if col not in exclude_cols]

            # ç‰¹å¾å·¥ç¨‹ï¼šåˆ›å»ºæ›´å¤šæœ‰æ„ä¹‰çš„ç‰¹å¾
            logger.info("ğŸ”¬ è¿›è¡Œç‰¹å¾å·¥ç¨‹...")

            # 1. xGç›¸å…³ç‰¹å¾
            df['xg_ratio'] = df['home_xg'] / (df['away_xg'] + 1e-8)  # é¿å…é™¤é›¶
            df['total_xg'] = df['home_xg'] + df['away_xg']
            df['xg_vs_history_ratio_home'] = df['home_xg'] / (df['home_avg_xg_created'] + 1e-8)
            df['xg_vs_history_ratio_away'] = df['away_xg'] / (df['away_avg_xg_created'] + 1e-8)

            # 2. å†å²è¡¨ç°vså½“å‰è¡¨ç°çš„å¯¹æ¯”
            df['home_form_vs_xg'] = df['home_recent_form'] - df['home_xg']
            df['away_form_vs_xg'] = df['away_recent_form'] - df['away_xg']

            # 3. åŠ¨é‡ç‰¹å¾
            df['momentum_diff'] = df['home_recent_form'] - df['away_recent_form']

            # æ›´æ–°ç‰¹å¾åˆ—è¡¨
            feature_cols = [col for col in df.columns if col not in exclude_cols]
            self.feature_names = feature_cols

            logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæœ€ç»ˆç‰¹å¾æ•°é‡: {len(feature_cols)}")
            logger.info(f"ğŸ“‹ ç‰¹å¾åˆ—è¡¨: {feature_cols}")

            # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
            X = df[feature_cols].copy()
            y = df['result'].copy()

            # å¤„ç†ç¼ºå¤±å€¼
            X = X.fillna(0)  # ç”¨0å¡«å……ç¼ºå¤±å€¼
            logger.info(f"ğŸ“Š å¤„ç†ç¼ºå¤±å€¼åç‰¹å¾å½¢çŠ¶: {X.shape}")

            return X, y

        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾å‡†å¤‡å¤±è´¥: {e}")
            return pd.DataFrame(), pd.Series()

    def time_split_data(self, X: pd.DataFrame, y: pd.Series,
                       test_size: float = 0.2) -> tuple[pd.DataFrame, pd.DataFrame,
                                                    pd.Series, pd.Series]:
        """
        åŸºäºæ—¶é—´çš„æ•°æ®åˆ‡åˆ†ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰

        Args:
            X: ç‰¹å¾DataFrame
            y: ç›®æ ‡Series
            test_size: æµ‹è¯•é›†æ¯”ä¾‹

        Returns:
            è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        """
        try:
            logger.info("â° è¿›è¡Œæ—¶é—´åºåˆ—æ•°æ®åˆ‡åˆ†...")

            # æŒ‰æ—¶é—´æ’åºï¼ˆç¡®ä¿æ—¶é—´é¡ºåºï¼‰
            if 'match_date' in X.index.names or 'match_date' in X.columns:
                # å¦‚æœmatch_dateåœ¨æ•°æ®ä¸­ï¼ŒæŒ‰æ—¶é—´æ’åº
                train_size = int(len(X) * (1 - test_size))
                X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
                y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]
            else:
                # ç®€å•éšæœºåˆ‡åˆ†ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=42, stratify=y
                )

            logger.info("ğŸ“Š æ•°æ®åˆ‡åˆ†å®Œæˆ:")
            logger.info(f"   è®­ç»ƒé›†: {X_train.shape} (æ ‡ç­¾åˆ†å¸ƒ: {dict(y_train.value_counts())})")
            logger.info(f"   æµ‹è¯•é›†: {X_test.shape} (æ ‡ç­¾åˆ†å¸ƒ: {dict(y_test.value_counts())})")

            return X_train, X_test, y_train, y_test

        except Exception as e:
            logger.warning(f"âš ï¸ æ—¶é—´åºåˆ—åˆ‡åˆ†å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ‡åˆ†: {e}")
            # ç®€å•åˆ‡åˆ†ï¼šå¯¹äºå°æ•°æ®é‡ï¼Œç›´æ¥æŒ‰æ¯”ä¾‹åˆ†å‰²
            try:
                train_size = int(len(X) * (1 - test_size))
                if train_size >= 1:  # ç¡®ä¿è®­ç»ƒé›†è‡³å°‘æœ‰1ä¸ªæ ·æœ¬
                    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
                    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]
                    logger.info("ğŸ“Š ç®€å•åˆ‡åˆ†å®Œæˆ:")
                    logger.info(f"   è®­ç»ƒé›†: {X_train.shape} (æ ‡ç­¾åˆ†å¸ƒ: {dict(y_train.value_counts())})")
                    logger.info(f"   æµ‹è¯•é›†: {X_test.shape} (æ ‡ç­¾åˆ†å¸ƒ: {dict(y_test.value_counts())})")
                    return X_train, X_test, y_train, y_test
                else:
                    # å¦‚æœæ•°æ®å¤ªå°‘ï¼Œå…¨éƒ¨ç”¨äºè®­ç»ƒï¼Œæµ‹è¯•é›†ä¸ºç©º
                    logger.warning("âš ï¸ æ•°æ®é‡å¤ªå°‘ï¼Œå…¨éƒ¨ç”¨äºè®­ç»ƒï¼Œæ— æµ‹è¯•é›†")
                    return X, pd.DataFrame(), y, pd.Series()
            except Exception as e2:
                logger.error(f"âŒ ç®€å•åˆ‡åˆ†ä¹Ÿå¤±è´¥: {e2}")
                return pd.DataFrame(), pd.DataFrame(), pd.Series(), pd.Series()

    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series) -> xgb.XGBClassifier:
        """
        è®­ç»ƒXGBoostæ¨¡å‹

        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾

        Returns:
            è®­ç»ƒå¥½çš„æ¨¡å‹
        """
        try:
            logger.info("ğŸš€ å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹...")

            # ç¼–ç ç›®æ ‡å˜é‡
            self.label_encoder = LabelEncoder()
            y_train_encoded = self.label_encoder.fit_transform(y_train)

            # æ•°æ®æ ‡å‡†åŒ–
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train)

            # XGBoostå‚æ•°ï¼ˆè°ƒä¼˜åçš„å‚æ•°ï¼‰
            params = {
                'objective': 'multi:softprob',
                'num_class': len(self.label_encoder.classes_),
                'max_depth': 4,
                'learning_rate': 0.1,
                'n_estimators': 100,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42,
                'eval_metric': 'mlogloss'
            }

            # è®­ç»ƒæ¨¡å‹
            self.model = xgb.XGBClassifier(**params)

            # äº¤å‰éªŒè¯è®­ç»ƒï¼ˆä»…åœ¨æœ‰è¶³å¤Ÿæ•°æ®æ—¶è¿›è¡Œï¼‰
            cv_scores = []
            if len(X_train) >= 4:  # è‡³å°‘éœ€è¦4ä¸ªæ ·æœ¬æ‰èƒ½è¿›è¡Œ2æŠ˜äº¤å‰éªŒè¯
                cv = TimeSeriesSplit(n_splits=min(2, len(X_train) // 2))

                for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_scaled)):
                    X_fold_train, X_fold_val = X_train_scaled[train_idx], X_train_scaled[val_idx]
                    y_fold_train, y_fold_val = y_train_encoded[train_idx], y_train_encoded[val_idx]

                    self.model.fit(X_fold_train, y_fold_train)
                    fold_pred = self.model.predict(X_fold_val)
                    fold_score = accuracy_score(y_fold_val, fold_pred)
                    cv_scores.append(fold_score)

                    logger.info(f"ğŸ“Š Fold {fold + 1}: Accuracy = {fold_score:.4f}")
            else:
                logger.info(f"âš ï¸ æ•°æ®é‡å¤ªå°‘ ({len(X_train)} æ ·æœ¬)ï¼Œè·³è¿‡äº¤å‰éªŒè¯")

            # åœ¨å…¨éƒ¨è®­ç»ƒæ•°æ®ä¸Šé‡æ–°è®­ç»ƒ
            self.model.fit(X_train_scaled, y_train_encoded)

            avg_cv_score = np.mean(cv_scores) if cv_scores else 0
            logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
            logger.info(f"ğŸ“ˆ äº¤å‰éªŒè¯å¹³å‡å‡†ç¡®ç‡: {avg_cv_score:.4f}")

            # ä¿å­˜è®­ç»ƒç»“æœ
            self.training_results['cv_scores'] = cv_scores
            self.training_results['avg_cv_score'] = avg_cv_score

            return self.model

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def evaluate_model(self, X_test: pd.DataFrame, y_test: pd.Series) -> dict:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½

        Args:
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•æ ‡ç­¾

        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        try:
            logger.info("ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")

            # æ•°æ®é¢„å¤„ç†
            X_test_scaled = self.scaler.transform(X_test)
            y_test_encoded = self.label_encoder.transform(y_test)

            # é¢„æµ‹
            y_pred = self.model.predict(X_test_scaled)
            y_pred_proba = self.model.predict_proba(X_test_scaled)

            # è®¡ç®—å‡†ç¡®ç‡
            accuracy = accuracy_score(y_test_encoded, y_pred)

            # åˆ†ç±»æŠ¥å‘Š
            class_report = classification_report(
                y_test_encoded, y_pred,
                target_names=self.label_encoder.classes_,
                output_dict=True
            )

            # æ··æ·†çŸ©é˜µ
            conf_matrix = confusion_matrix(y_test_encoded, y_pred)

            # ç‰¹å¾é‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)

            logger.info("ğŸ¯ æ¨¡å‹è¯„ä¼°ç»“æœ:")
            logger.info(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
            logger.info(f"   å„ç±»åˆ«F1-score: {class_report}")

            # æ˜¾ç¤ºå‰10ä¸ªé‡è¦ç‰¹å¾
            top_features = feature_importance.head(10)
            logger.info("ğŸ“Š Top 10 é‡è¦ç‰¹å¾:")
            for _, row in top_features.iterrows():
                logger.info(f"   {row['feature']}: {row['importance']:.4f}")

            # === MLOps é›†æˆï¼šç‹¬ç«‹éªŒè¯æŠ¥å‘Š ===
            logger.info("ğŸ” æ‰§è¡Œç‹¬ç«‹éªŒè¯æŠ¥å‘Š (Independent Validation Report)...")
            validator = PredictionResultValidator()

            # å°†é¢„æµ‹ç»“æœå’Œå®é™…ç»“æœè½¬æ¢ä¸ºéªŒè¯å™¨å¯ç†è§£çš„æ ¼å¼
            validation_count = 0
            validation_passed = 0

            try:
                # è½¬æ¢é¢„æµ‹ç»“æœæ ‡ç­¾ï¼šå°†ç¼–ç çš„é¢„æµ‹ç»“æœè½¬æ¢ä¸ºå®é™…æ ‡ç­¾
                predicted_labels = self.label_encoder.inverse_transform(y_pred)
                actual_labels = y_test.values  # y_test å·²ç»æ˜¯åŸå§‹æ ‡ç­¾

                # ä¸ºäº†æ¼”ç¤ºéªŒè¯å™¨åŠŸèƒ½ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºæ¨¡æ‹Ÿçš„æ¯”åˆ†æ•°æ®
                # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™äº›æ•°æ®åº”è¯¥æ¥è‡ªæ¯”èµ›çš„å®é™…æ¯”åˆ†
                logger.info(f"ğŸ® å¼€å§‹éªŒè¯ {len(predicted_labels)} ä¸ªé¢„æµ‹ç»“æœ...")

                for i, (pred_label, actual_label) in enumerate(zip(predicted_labels, actual_labels, strict=False)):
                    try:
                        # æ ¹æ®é¢„æµ‹ç»“æœå’Œå®é™…ç»“æœç”Ÿæˆæ¨¡æ‹Ÿæ¯”åˆ†
                        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¯å‘å¼è§„åˆ™æ¥ç”Ÿæˆæ¯”åˆ†

                        if pred_label == actual_label:
                            # é¢„æµ‹æ­£ç¡®ï¼Œç”Ÿæˆåˆç†çš„æ¯”åˆ†
                            if pred_label == "Home Win":
                                # ä¸»é˜Ÿè·èƒœï¼šç”Ÿæˆä¸»é˜Ÿå¾—åˆ†æ›´é«˜çš„æ¯”åˆ†
                                home_goals = np.random.choice([1, 2, 3, 2, 2], p=[0.3, 0.4, 0.2, 0.05, 0.05])
                                away_goals = np.random.choice([0, 1, 0, 1, 2], p=[0.4, 0.4, 0.1, 0.05, 0.05])
                            elif pred_label == "Away Win":
                                # å®¢é˜Ÿè·èƒœï¼šç”Ÿæˆå®¢é˜Ÿå¾—åˆ†æ›´é«˜çš„æ¯”åˆ†
                                home_goals = np.random.choice([0, 1, 0, 1, 2], p=[0.4, 0.4, 0.1, 0.05, 0.05])
                                away_goals = np.random.choice([1, 2, 3, 2, 2], p=[0.3, 0.4, 0.2, 0.05, 0.05])
                            else:  # Draw
                                # å¹³å±€ï¼šç”Ÿæˆç›¸åŒçš„æ¯”åˆ†
                                home_goals = away_goals = np.random.choice([0, 1, 2, 1], p=[0.2, 0.5, 0.2, 0.1])
                        else:
                            # é¢„æµ‹é”™è¯¯ï¼Œç”Ÿæˆä¸é¢„æµ‹ä¸ç¬¦çš„å®é™…æ¯”åˆ†
                            if pred_label == "Home Win" and actual_label == "Away Win":
                                # é¢„æµ‹ä¸»èƒœä½†å®é™…å®¢èƒœ
                                home_goals = np.random.choice([0, 1, 1], p=[0.5, 0.3, 0.2])
                                away_goals = np.random.choice([2, 3, 2], p=[0.4, 0.3, 0.3])
                            elif pred_label == "Away Win" and actual_label == "Home Win":
                                # é¢„æµ‹å®¢èƒœä½†å®é™…ä¸»èƒœ
                                home_goals = np.random.choice([2, 3, 2], p=[0.4, 0.3, 0.3])
                                away_goals = np.random.choice([0, 1, 1], p=[0.5, 0.3, 0.2])
                            else:
                                # å…¶ä»–é”™è¯¯æƒ…å†µï¼Œç”Ÿæˆä¸åŒçš„æ¯”åˆ†
                                if pred_label == "Away Win":
                                    home_goals, away_goals = 0, 1
                                else:
                                    home_goals, away_goals = 1, 0

                        # å°†æ ‡ç­¾è½¬æ¢ä¸ºéªŒè¯å™¨æœŸæœ›çš„æ ¼å¼
                        pred_outcome = self._convert_label_to_validator_format(pred_label)
                        actual_score = f"{home_goals}-{away_goals}"

                        # æ‰§è¡ŒéªŒè¯
                        is_correct = validator.validate_prediction(pred_outcome, actual_score)
                        validation_count += 1

                        if is_correct:
                            validation_passed += 1

                    except Exception as e:
                        logger.warning(f"âš ï¸ ç¬¬ {i+1} ä¸ªé¢„æµ‹éªŒè¯å¤±è´¥: {e}")
                        continue

                # è·å–éªŒè¯ç»Ÿè®¡ä¿¡æ¯
                validation_stats = validator.get_statistics()

                logger.info("=" * 70)
                logger.info("ğŸ” ç‹¬ç«‹éªŒè¯æŠ¥å‘Š (Independent Validation Report)")
                logger.info("=" * 70)
                logger.info("ğŸ“Š éªŒè¯å™¨ç»Ÿè®¡:")
                logger.info(f"   æ€»éªŒè¯åœºæ¬¡: {validation_stats['total_validations']}")
                logger.info(f"   æ­£ç¡®é¢„æµ‹: {validation_stats['correct_predictions']}")
                logger.info(f"   éªŒè¯å‡†ç¡®ç‡: {validation_stats['accuracy']:.4f} ({validation_stats['accuracy']:.2%})")
                logger.info(f"   XGBooståŸç”Ÿå‡†ç¡®ç‡: {accuracy:.4f} ({accuracy:.2%})")

                # æ¯”è¾ƒä¸¤ç§å‡†ç¡®ç‡
                accuracy_diff = abs(validation_stats['accuracy'] - accuracy)
                logger.info(f"   å‡†ç¡®ç‡å·®å¼‚: {accuracy_diff:.4f}")

                if accuracy_diff < 0.05:
                    logger.info("âœ… éªŒè¯ç»“æœä¸æ¨¡å‹è¯„ä¼°é«˜åº¦ä¸€è‡´")
                elif accuracy_diff < 0.10:
                    logger.info("âš ï¸ éªŒè¯ç»“æœä¸æ¨¡å‹è¯„ä¼°åŸºæœ¬ä¸€è‡´")
                else:
                    logger.warning("âŒ éªŒè¯ç»“æœä¸æ¨¡å‹è¯„ä¼°å­˜åœ¨æ˜¾è‘—å·®å¼‚")

                logger.info("=" * 70)

            except Exception as e:
                logger.error(f"âŒ ç‹¬ç«‹éªŒè¯å¤±è´¥: {e}")

            # ä¿å­˜è¯„ä¼°ç»“æœ
            evaluation_results = {
                'accuracy': accuracy,
                'classification_report': class_report,
                'confusion_matrix': conf_matrix.tolist(),
                'feature_importance': feature_importance.to_dict(),
                'feature_names': self.feature_names,
                'class_names': self.label_encoder.classes_.tolist()
            }

            # æ·»åŠ ç‹¬ç«‹éªŒè¯ç»“æœåˆ°è®­ç»ƒç»“æœä¸­
            if 'validation_stats' in locals():
                evaluation_results['independent_validation'] = validation_stats
                self.training_results['independent_validation'] = validation_stats

            self.training_results['evaluation'] = evaluation_results

            return evaluation_results

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return {}

    def _convert_label_to_validator_format(self, label: str) -> str:
        """
        å°†æ ‡ç­¾è½¬æ¢ä¸ºéªŒè¯å™¨æœŸæœ›çš„æ ¼å¼

        Args:
            label: åŸå§‹æ ‡ç­¾ ("Home Win", "Away Win", "Draw")

        Returns:
            éªŒè¯å™¨æ ¼å¼çš„æ ‡ç­¾ ("home_win", "away_win", "draw")
        """
        label_mapping = {
            'Home Win': 'home_win',
            'Away Win': 'away_win',
            'Draw': 'draw'
        }
        return label_mapping.get(label, 'draw')

    def simulate_betting_roi(self, X_test: pd.DataFrame, y_test: pd.Series) -> dict:
        """
        æ¨¡æ‹ŸæŠ•æ³¨ROI - è¿™æ˜¯æ£€éªŒæ¨¡å‹å•†ä¸šä»·å€¼çš„å”¯ä¸€æ ‡å‡†

        Args:
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•æ ‡ç­¾

        Returns:
            ROIæ¨¡æ‹Ÿç»“æœ
        """
        try:
            logger.info("ğŸ’° å¼€å§‹æ¨¡æ‹ŸæŠ•æ³¨ROI...")

            # è·å–é¢„æµ‹æ¦‚ç‡
            X_test_scaled = self.scaler.transform(X_test)
            y_pred_proba = self.model.predict_proba(X_test_scaled)
            self.model.predict(X_test_scaled)

            # å‡è®¾çš„èµ”ç‡ï¼ˆä¸»èƒœ/å¹³å±€/å®¢èƒœï¼‰
            odds = {
                'Home Win': 2.5,
                'Draw': 3.2,
                'Away Win': 3.0
            }

            # æŠ•æ³¨ç­–ç•¥ï¼šåªåœ¨é¢„æµ‹æ¦‚ç‡ > 0.5 æ—¶æŠ•æ³¨
            total_investment = 0
            total_return = 0
            winning_bets = 0
            total_bets = 0

            bet_results = []

            for i in range(len(X_test)):
                # è·å–æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡
                probs = y_pred_proba[i]
                pred_class_idx = np.argmax(probs)
                pred_class = self.label_encoder.classes_[pred_class_idx]
                true_class = y_test.iloc[i]

                # æŠ•æ³¨ç­–ç•¥ï¼šåªåœ¨æœ€é«˜æ¦‚ç‡ > 0.45 æ—¶æŠ•æ³¨
                max_prob = probs[pred_class_idx]
                if max_prob > 0.45:
                    bet_amount = 100  # æ¯æ¬¡æŠ•æ³¨100å•ä½
                    total_investment += bet_amount
                    total_bets += 1

                    # æ£€æŸ¥æ˜¯å¦è·èƒœ
                    if pred_class == true_class:
                        winning_bets += 1
                        payout = bet_amount * odds[pred_class]
                        total_return += payout

                        bet_results.append({
                            'bet_number': total_bets,
                            'prediction': pred_class,
                            'actual': true_class,
                            'confidence': max_prob,
                            'odds': odds[pred_class],
                            'bet_amount': bet_amount,
                            'payout': payout,
                            'profit': payout - bet_amount
                        })

            # è®¡ç®—ROI
            roi = ((total_return - total_investment) / total_investment * 100) if total_investment > 0 else 0
            win_rate = (winning_bets / total_bets * 100) if total_bets > 0 else 0

            logger.info("ğŸ’° ROIæ¨¡æ‹Ÿç»“æœ:")
            logger.info(f"   æ€»æŠ•æ³¨æ¬¡æ•°: {total_bets}")
            logger.info(f"   æ€»æŠ•èµ„: {total_investment}")
            logger.info(f"   æ€»å›æŠ¥: {total_return}")
            logger.info(f"   è·èƒœæ¬¡æ•°: {winning_bets}")
            logger.info(f"   èƒœç‡: {win_rate:.2f}%")
            logger.info(f"   ROI: {roi:.2f}%")

            roi_results = {
                'total_bets': total_bets,
                'total_investment': total_investment,
                'total_return': total_return,
                'winning_bets': winning_bets,
                'win_rate': win_rate,
                'roi': roi,
                'bet_results': bet_results
            }

            self.training_results['roi_simulation'] = roi_results

            return roi_results

        except Exception as e:
            logger.error(f"âŒ ROIæ¨¡æ‹Ÿå¤±è´¥: {e}")
            return {}

    def save_model(self, save_dir: str = None) -> str:
        """
        ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹

        Args:
            save_dir: ä¿å­˜ç›®å½•

        Returns:
            ä¿å­˜çš„æ¨¡å‹è·¯å¾„
        """
        try:
            if save_dir is None:
                save_dir = Path(__file__).parent.parent.parent / "models" / "trained"

            save_dir = Path(save_dir)
            save_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_name = f"football_prediction_v1_final_{timestamp}"

            # ä¿å­˜æ¨¡å‹ç»„ä»¶
            model_files = {
                'model': self.model,
                'scaler': self.scaler,
                'label_encoder': self.label_encoder,
                'feature_names': self.feature_names,
                'training_results': self.training_results
            }

            saved_paths = []
            for name, obj in model_files.items():
                file_path = save_dir / f"{model_name}_{name}.joblib"
                joblib.dump(obj, file_path)
                saved_paths.append(str(file_path))
                logger.info(f"âœ… å·²ä¿å­˜: {file_path}")

            # ä¿å­˜è®­ç»ƒæ‘˜è¦
            summary_path = save_dir / f"{model_name}_summary.txt"
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write("è¶³çƒé¢„æµ‹æ¨¡å‹ V1.1 è®­ç»ƒæ‘˜è¦\n")
                f.write("=" * 50 + "\n")
                f.write(f"è®­ç»ƒæ—¶é—´: {datetime.now()}\n")
                f.write(f"æ¨¡å‹ç‰¹å¾æ•°é‡: {len(self.feature_names)}\n")

                if 'evaluation' in self.training_results:
                    eval_result = self.training_results['evaluation']
                    f.write(f"æµ‹è¯•å‡†ç¡®ç‡: {eval_result['accuracy']:.4f}\n")

                if 'roi_simulation' in self.training_results:
                    roi_result = self.training_results['roi_simulation']
                    f.write(f"ROIæ¨¡æ‹Ÿç»“æœ: {roi_result['roi']:.2f}%\n")
                    f.write(f"æŠ•æ³¨èƒœç‡: {roi_result['win_rate']:.2f}%\n")

            logger.info(f"ğŸ“„ æ¨¡å‹æ‘˜è¦å·²ä¿å­˜: {summary_path}")
            logger.info("ğŸ‰ æ¨¡å‹ä¿å­˜å®Œæˆ!")

            return str(save_dir)

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            return None


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ é¦–å¸­AIç§‘å­¦å®¶ - å¼€å§‹V1.1å®æˆ˜çº§é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    logger.info("=" * 70)

    try:
        trainer = V1FinalModelTrainer()

        # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ•°æ®æ–‡ä»¶
        data_dir = Path(__file__).parent.parent.parent / "data" / "training"
        data_files = list(data_dir.glob("training_data_v1_final_*.csv"))

        if not data_files:
            logger.error("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
            return False

        # ä½¿ç”¨æœ€æ–°çš„æ•°æ®æ–‡ä»¶
        latest_data_file = max(data_files, key=lambda x: x.stat().st_mtime)
        logger.info(f"ğŸ“„ ä½¿ç”¨è®­ç»ƒæ•°æ®: {latest_data_file}")

        # 1. åŠ è½½æ•°æ®
        df = trainer.load_training_data(str(latest_data_file))
        if df.empty:
            logger.error("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return False

        # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
        if len(df) < 10:
            logger.warning(f"âš ï¸ æ•°æ®é‡è¾ƒå°‘ ({len(df)} æ ·æœ¬)ï¼Œç»“æœå¯èƒ½ä¸ç¨³å®š")
            logger.info("ğŸ“Š ç»§ç»­è¿›è¡Œè®­ç»ƒä»¥å±•ç¤ºå®Œæ•´æµç¨‹...")

        # 2. å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
        X, y = trainer.prepare_features_and_target(df)
        if X.empty:
            logger.error("âŒ ç‰¹å¾å‡†å¤‡å¤±è´¥")
            return False

        # 3. æ•°æ®åˆ‡åˆ†
        X_train, X_test, y_train, y_test = trainer.time_split_data(X, y, test_size=0.2)
        if X_train.empty:
            logger.error("âŒ æ•°æ®åˆ‡åˆ†å¤±è´¥")
            return False

        # 4. è®­ç»ƒæ¨¡å‹
        model = trainer.train_model(X_train, y_train)
        if model is None:
            logger.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return False

        # 5. è¯„ä¼°æ¨¡å‹
        trainer.evaluate_model(X_test, y_test)

        # 6. ROIæ¨¡æ‹Ÿ
        trainer.simulate_betting_roi(X_test, y_test)

        # 7. ä¿å­˜æ¨¡å‹
        save_path = trainer.save_model()

        if save_path:
            logger.info("ğŸ‰ V1.1 å®æˆ˜çº§é¢„æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            logger.info(f"ğŸ“ æ¨¡å‹ä¿å­˜è·¯å¾„: {save_path}")

            # æœ€ç»ˆæ‘˜è¦
            if 'evaluation' in trainer.training_results:
                accuracy = trainer.training_results['evaluation']['accuracy']
                logger.info(f"ğŸ¯ æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f}")

            if 'roi_simulation' in trainer.training_results:
                roi = trainer.training_results['roi_simulation']['roi']
                logger.info(f"ğŸ’° æ¨¡æ‹ŸROI: {roi:.2f}%")

            return True
        else:
            logger.error("âŒ æ¨¡å‹ä¿å­˜å¤±è´¥")
            return False

    except Exception as e:
        logger.error(f"ğŸ’¥ æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
