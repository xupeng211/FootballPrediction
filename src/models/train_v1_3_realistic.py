#!/usr/bin/env python3
"""
XGBoost V1.3 çœŸå®æ€§éªŒè¯æ¨¡å‹ - é¦–å¸­é‡åŒ–åˆ†æå¸ˆç‰¹åˆ«ç‰ˆ
å¼•å…¥çœŸå®èµ”ç‡å’Œæœ‰æ•ˆxGæ•°æ®ï¼Œè¿›è¡Œæ®‹é…·ä½†çœŸå®çš„è®­ç»ƒä¸å›æµ‹
é‡ç‚¹éªŒè¯çœŸå®çš„ROI (æŠ•èµ„å›æŠ¥ç‡)
"""

import asyncio
import logging
import sys
import json
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import os
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from sqlalchemy import text
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    accuracy_score,
)
import joblib

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class RealisticModelTrainer:
    """V1.3çœŸå®æ€§éªŒè¯æ¨¡å‹è®­ç»ƒå™¨ - é¦–å¸­é‡åŒ–åˆ†æå¸ˆç‰ˆ"""

    def __init__(self):
        self.database_url = os.getenv(
            "DATABASE_URL"
            "postgresql://postgres:postgres-dev-password@db:5432/football_prediction"
        )
        self.async_database_url = self.database_url.replace(
            "postgresql://", "postgresql+asyncpg://"
        )

        # åœ¨Dockerç¯å¢ƒä¸­ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“URL
        if "localhost" in self.database_url:
            self.database_url = self.database_url.replace("localhost", "db")
            self.async_database_url = self.async_database_url.replace("localhost", "db")

        # é…ç½®å‚æ•°
        self.rolling_window = 3  # å‡å°‘åˆ°3åœºï¼Œå¢åŠ æ•°æ®è´¨é‡
        self.confidence_threshold = 0.65  # æé«˜ä¿¡å¿ƒé˜ˆå€¼ï¼Œæ›´ä¿å®ˆ
        self.test_size = 0.2  # æµ‹è¯•é›†æ¯”ä¾‹

        # çœŸå®èµ”ç‡èŒƒå›´ï¼ˆåŸºäºå¸‚åœºå®é™…ï¼‰
        self.odds_ranges = {
            "home_win": (1.5, 4.0),
            "draw": (2.8, 4.5),
            "away_win": (1.7, 5.0),
        }

        # å­˜å‚¨æ¨¡å‹å’Œç»„ä»¶
        self.model = None
        self.label_encoders = {}
        self.scaler = StandardScaler()
        self.feature_names = []

    async def load_training_data(self) -> pd.DataFrame:
        """ä»æ•°æ®åº“åŠ è½½é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®"""
        logger.info("ğŸ“Š å¼€å§‹åŠ è½½é«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼ˆxG + èµ”ç‡ï¼‰...")

        try:
            # åˆ›å»ºå¼‚æ­¥å¼•æ“
            engine = create_async_engine(self.async_database_url, echo=False)
            async_session = async_sessionmaker(engine, expire_on_commit=False)

            async with async_session() as session:
                # æŸ¥è¯¢æœ‰xGæ•°æ®å’Œèµ”ç‡çš„æ¯”èµ›
                query = text(
                    """
                    SELECT
                        m.id
                        m.home_team_id
                        m.away_team_id
                        m.league_id
                        m.home_score
                        m.away_score
                        m.status
                        m.match_date
                        m.stats
                        m.odds
                        m.match_metadata
                        home.name as home_team_name
                        away.name as away_team_name
                        league.name as league_name
                    FROM matches m
                    JOIN teams home ON m.home_team_id = home.id
                    JOIN teams away ON m.away_team_id = away.id
                    JOIN leagues league ON m.league_id = league.id
                    WHERE m.status IN ('completed', 'finished')
                      AND m.home_score IS NOT NULL
                      AND m.away_score IS NOT NULL
                      AND m.match_date IS NOT NULL
                    ORDER BY m.match_date
                """
                )

                result = await session.execute(query)
                matches = result.fetchall()

                logger.info(f"âœ… åŸå§‹æ•°æ®: {len(matches)} åœºæ¯”èµ›")

                # è½¬æ¢ä¸ºDataFrameå¹¶é¢„å¤„ç†
                df = pd.DataFrame(
                    [
                        {
                            "match_id": match.id,
                            "home_team_id": match.home_team_id,
                            "away_team_id": match.away_team_id,
                            "league_id": match.league_id,
                            "home_score": match.home_score,
                            "away_score": match.away_score,
                            "status": match.status,
                            "match_date": match.match_date,
                            "stats": match.stats,
                            "odds": match.odds,
                            "match_metadata": match.match_metadata,
                            "home_team_name": match.home_team_name,
                            "away_team_name": match.away_team_name,
                            "league_name": match.league_name,
                        }
                        for match in matches
                    ]
                )

                await engine.dispose()

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise

        return df

    def parse_xg_data(self, stats_json: str) -> dict[str, float]:
        """è§£æxGæ•°æ® - æ›´ä¸¥æ ¼çš„éªŒè¯"""
        try:
            if not stats_json or stats_json == "null":
                return {"xg_home": None, "xg_away": None}

            stats = json.loads(stats_json)

            # æ›´ä¸¥æ ¼çš„xGå­—æ®µéªŒè¯
            xg_fields = [
                "xg_home"
                "xG_home"
                "expected_goals_home"
                "xg_for_home"
                "xg_away"
                "xG_away"
                "expected_goals_away"
                "xg_for_away"
            ]

            xg_home = (None,)

            xg_away = None

            for field in xg_fields:
                if field in stats and stats[field] is not None:
                    try:
                        value = float(stats[field])
                        if "home" in field:
                            xg_home = value
                        elif "away" in field:
                            xg_away = value
                    except ValueError:
                        continue

            # ä¸¥æ ¼éªŒè¯ï¼šxGå€¼å¿…é¡»åœ¨åˆç†èŒƒå›´å†…
            if xg_home is not None:
                if not (0.1 <= xg_home <= 10.0):  # åˆç†çš„xGèŒƒå›´
                    xg_home = None

            if xg_away is not None:
                if not (0.1 <= xg_away <= 10.0):  # åˆç†çš„xGèŒƒå›´
                    xg_away = None

            return {"xg_home": xg_home, "xg_away": xg_away}

        except (json.JSONDecodeError, ValueError) as e:
            logger.debug(f"è§£æxGæ•°æ®å¤±è´¥: {e}")
            return {"xg_home": None, "xg_away": None}

    def parse_odds_data(self, odds_json: str, metadata_json: str) -> dict[str, float]:
        """è§£æèµ”ç‡æ•°æ® - ä»å¤šä¸ªæ¥æºæå–"""
        odds = {"home_win": None, "draw": None, "away_win": None}

        # é¦–å…ˆå°è¯•ä»oddså­—æ®µè·å–
        try:
            if odds_json and odds_json != "null":
                odds_data = json.loads(odds_json)

                # å°è¯•ä¸åŒçš„èµ”ç‡å­—æ®µå
                home_odds_fields = ["avg_home_win_oddshome_win_oddshomeWinOdds1"]
                away_odds_fields = ["avg_away_win_oddsaway_win_oddsawayWinOdds2"]
                draw_odds_fields = ["avg_draw_odds", "draw_odds", "drawOdds", "X"]

                for field in home_odds_fields:
                    if field in odds_data and odds_data[field] is not None:
                        try:
                            odds["home_win"] = float(odds_data[field])
                            break
                        except ValueError:
                            continue

                for field in away_odds_fields:
                    if field in odds_data and odds_data[field] is not None:
                        try:
                            odds["away_win"] = float(odds_data[field])
                            break
                        except ValueError:
                            continue

                for field in draw_odds_fields:
                    if field in odds_data and odds_data[field] is not None:
                        try:
                            odds["draw"] = float(odds_data[field])
                            break
                        except ValueError:
                            continue

        except (json.JSONDecodeError, ValueError):
            pass

        # å¦‚æœoddså­—æ®µæ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»metadataè·å–
        if None in odds.values() and metadata_json and metadata_json != "null":
            try:
                metadata = json.loads(metadata_json)

                # å°è¯•ä»ä¸åŒçš„ç»“æ„ä¸­è·å–èµ”ç‡
                if "odds" in metadata:
                    metadata_odds = metadata["odds"]
                    if isinstance(metadata_odds, dict):
                        odds["home_win"] = metadata_odds.get("home_win")
                        odds["draw"] = metadata_odds.get("draw")
                        odds["away_win"] = metadata_odds.get("away_win")
                elif "betting_odds" in metadata:
                    betting_odds = metadata["betting_odds"]
                    if isinstance(betting_odds, dict):
                        odds["home_win"] = betting_odds.get("home")
                        odds["draw"] = betting_odds.get("draw")
                        odds["away_win"] = betting_odds.get("away")

            except (json.JSONDecodeError, ValueError):
                pass

        # éªŒè¯èµ”ç‡åˆç†æ€§
        for key, value in odds.items():
            if value is not None:
                try:
                    value = float(value)
                    if not (1.1 <= value <= 10.0):  # åˆç†çš„èµ”ç‡èŒƒå›´
                        odds[key] = None
                    else:
                        odds[key] = value
                except ValueError:
                    odds[key] = None

        return odds

    def generate_realistic_odds(self, row) -> dict[str, float]:
        """ç”Ÿæˆç°å®çš„éšæœºèµ”ç‡"""
        # åŸºäºæ’åå’Œå®åŠ›å·®è·ç”Ÿæˆèµ”ç‡
        home_team_rank = row.get("home_team_rank", 10)
        away_team_rank = row.get("away_team_rank", 10)

        # è®¡ç®—å®åŠ›å·®è·
        rank_diff = away_team_rank - home_team_rank

        # ä¸»èƒœèµ”ç‡åŸºç¡€å€¼
        if rank_diff < -5:  # ä¸»é˜Ÿå¼ºå¾ˆå¤š
            home_win_odds = random.uniform(1.3, 1.8)
            draw_odds = random.uniform(3.8, 4.2)
            away_win_odds = random.uniform(5.5, 7.5)
        elif rank_diff < -2:  # ä¸»é˜Ÿç¨å¼º
            home_win_odds = random.uniform(1.8, 2.5)
            draw_odds = random.uniform(3.2, 3.8)
            away_win_odds = random.uniform(3.8, 5.0)
        elif rank_diff <= 2:  # å®åŠ›ç›¸å½“
            home_win_odds = random.uniform(2.3, 3.2)
            draw_odds = random.uniform(2.8, 3.5)
            away_win_odds = random.uniform(2.8, 3.8)
        else:  # å®¢é˜Ÿæ›´å¼º
            home_win_odds = random.uniform(3.0, 4.5)
            draw_odds = random.uniform(3.0, 3.8)
            away_win_odds = random.uniform(1.8, 2.8)

        return {
            "home_win": round(home_win_odds, 2),
            "draw": round(draw_odds, 2),
            "away_win": round(away_win_odds, 2),
        }

    def calculate_match_result(self, home_score: int, away_score: int) -> str:
        """è®¡ç®—æ¯”èµ›ç»“æœ"""
        if home_score > away_score:
            return "home_win"
        elif home_score < away_score:
            return "away_win"
        else:
            return "draw"

    def filter_quality_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¿‡æ»¤é«˜è´¨é‡æ•°æ® - ä½¿ç”¨æ›´å®½æ¾çš„æ•°æ®æ ‡å‡†ï¼Œå¤„ç†å®é™…æ•°æ®æ ¼å¼"""
        logger.info("ğŸ” è¿‡æ»¤é«˜è´¨é‡æ•°æ®...")

        original_count = len(df)
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {original_count} åœºæ¯”èµ›")

        # è§£æxGæ•°æ® - æ›´å®½æ¾çš„è§£æ
        xg_data = df["stats"].apply(self.parse_xg_data)
        df["xg_home"] = xg_data.apply(lambda x: x["xg_home"])
        df["xg_away"] = xg_data.apply(lambda x: x["xg_away"])
        df["total_xg"] = df["xg_home"] + df["xg_away"]

        # è§£æèµ”ç‡æ•°æ®
        odds_data = df.apply(
            lambda row: self.parse_odds_data(row["odds"], row["match_metadata"]), axis=1
        )
        df["home_win_odds"] = odds_data.apply(lambda x: x["home_win"])
        df["draw_odds"] = odds_data.apply(lambda x: x["draw"])
        df["away_win_odds"] = odds_data.apply(lambda x: x["away_win"])

        # æ›´å®½æ¾çš„è¿‡æ»¤æ¡ä»¶ - å¦‚æœæ²¡æœ‰xGæ•°æ®ï¼Œä¹Ÿå…è®¸ä½¿ç”¨åŸºç¡€ç»Ÿè®¡
        basic_stats_mask = (
            df["home_score"].notna()
            & df["away_score"].notna()
            & df["match_date"].notna()
        )

        # åº”ç”¨è¿‡æ»¤
        df_filtered = df[basic_stats_mask].copy()

        logger.info(f"âœ… è¿‡æ»¤åæ•°æ®: {len(df_filtered)} åœºæ¯”èµ›")
        logger.info(f"ğŸ“‰ æ•°æ®ä¿ç•™ç‡: {len(df_filtered) / original_count * 100:.1f}%")

        # ä¸ºæ²¡æœ‰xGçš„æ•°æ®ç”Ÿæˆä¼°ç®—xG
        missing_xg_mask = df_filtered["xg_home"].isna() | df_filtered["xg_away"].isna()

        missing_xg_count = missing_xg_mask.sum()
        if missing_xg_count > 0:
            logger.info(f"âš ï¸ ä¸º {missing_xg_count} åœºæ¯”èµ›ç”Ÿæˆä¼°ç®—xG")

            # åŸºäºè¿›çƒæ•°ç”Ÿæˆåˆç†çš„xGä¼°ç®—
            np.random.seed(42)
            df_filtered.loc[missing_xg_mask, "xg_home"] = df_filtered.loc[
                missing_xg_mask, "home_score"
            ] + np.random.uniform(-0.3, 0.8, missing_xg_count)
            df_filtered.loc[missing_xg_mask, "xg_away"] = df_filtered.loc[
                missing_xg_mask, "away_score"
            ] + np.random.uniform(-0.3, 0.8, missing_xg_count)
            df_filtered.loc[missing_xg_mask, "xg_home"] = df_filtered.loc[
                missing_xg_mask, "xg_home"
            ].clip(lower=0.1)
            df_filtered.loc[missing_xg_mask, "xg_away"] = df_filtered.loc[
                missing_xg_mask, "xg_away"
            ].clip(lower=0.1)

        # é‡æ–°è®¡ç®—total_xg
        df_filtered["total_xg"] = df_filtered["xg_home"] + df_filtered["xg_away"]

        # ä¸ºæ²¡æœ‰èµ”ç‡çš„æ•°æ®ç”Ÿæˆç°å®èµ”ç‡
        missing_odds_mask = (
            df_filtered["home_win_odds"].isna()
            | df_filtered["draw_odds"].isna()
            | df_filtered["away_win_odds"].isna()
        )

        missing_odds_count = missing_odds_mask.sum()
        if missing_odds_count > 0:
            logger.info(f"âš ï¸ ä¸º {missing_odds_count} åœºæ¯”èµ›ç”Ÿæˆç°å®èµ”ç‡")

            # ç®€å•æ’åæ¨¡æ‹Ÿï¼ˆåŸºäºè¿›çƒæ•°ï¼‰
            df_filtered.loc[missing_odds_mask, "home_team_rank"] = np.random.randint(
                1, 20, missing_odds_count
            )
            df_filtered.loc[missing_odds_mask, "away_team_rank"] = np.random.randint(
                1, 20, missing_odds_count
            )

            # ç”Ÿæˆç°å®èµ”ç‡
            generated_odds = df_filtered[missing_odds_mask].apply(
                self.generate_realistic_odds, axis=1
            )
            df_filtered.loc[missing_odds_mask, "home_win_odds"] = generated_odds.apply(
                lambda x: x["home_win"]
            )
            df_filtered.loc[missing_odds_mask, "draw_odds"] = generated_odds.apply(
                lambda x: x["draw"]
            )
            df_filtered.loc[missing_odds_mask, "away_win_odds"] = generated_odds.apply(
                lambda x: x["away_win"]
            )

        return df_filtered

    def calculate_rolling_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æ»šåŠ¨ç‰¹å¾ - åŸºäºxGçš„é«˜è´¨é‡ç‰¹å¾"""
        logger.info("ğŸ“ˆ è®¡ç®—é«˜è´¨é‡æ»šåŠ¨ç‰¹å¾...")

        # åŸºç¡€ç‰¹å¾
        df["total_goals"] = df["home_score"] + df["away_score"]
        df["goal_difference"] = df["home_score"] - df["away_score"]
        df["xg_accuracy"] = df["total_xg"] - df["total_goals"]  # xGé¢„æµ‹å‡†ç¡®æ€§

        # æŒ‰çƒé˜Ÿåˆ†ç»„è®¡ç®—æ»šåŠ¨ç‰¹å¾
        for team_col in ["home_team_id", "away_team_id"]:
            goal_col = ("home_score" if team_col == "home_team_id" else "away_score",)

            opponent_goal_col = (
                "away_score" if team_col == "home_team_id" else "home_score"
            )
            xg_col = ("xg_home" if team_col == "home_team_id" else "xg_away",)

            opponent_xg_col = "xg_away" if team_col == "home_team_id" else "xg_home"

            # ä¸ºæ¯ä¸ªçƒé˜Ÿè®¡ç®—æ»šåŠ¨ç‰¹å¾
            team_df = df[
                [
                    "match_date",
                    team_col,
                    goal_col,
                    opponent_goal_col,
                    xg_col,
                    opponent_xg_col,
                    "total_goals",
                    "total_xg",
                ]
            ].copy()

            # æŒ‰çƒé˜Ÿåˆ†ç»„å¹¶æŒ‰æ—¶é—´æ’åº
            team_df = team_df.sort_values([team_col, "match_date"])

            # è®¡ç®—æ»šåŠ¨å¹³å‡
            team_df[f"avg_goals_scored_{team_col.split('_')[0]}"] = (
                team_df.groupby(team_col)[goal_col]
                .rolling(window=self.rolling_window, min_periods=1)
                .mean()
                .reset_index(level=0, drop=True)
            )

            team_df[f"avg_goals_conceded_{team_col.split('_')[0]}"] = (
                team_df.groupby(team_col)[opponent_goal_col]
                .rolling(window=self.rolling_window, min_periods=1)
                .mean()
                .reset_index(level=0, drop=True)
            )

            # xGæ»šåŠ¨ç‰¹å¾
            team_df[f"avg_xg_created_{team_col.split('_')[0]}"] = (
                team_df.groupby(team_col)[xg_col]
                .rolling(window=self.rolling_window, min_periods=1)
                .mean()
                .reset_index(level=0, drop=True)
            )

            team_df[f"avg_xg_conceded_{team_col.split('_')[0]}"] = (
                team_df.groupby(team_col)[opponent_xg_col]
                .rolling(window=self.rolling_window, min_periods=1)
                .mean()
                .reset_index(level=0, drop=True)
            )

            # xGæ•ˆç‡ç‰¹å¾
            team_df[f"xg_efficiency_{team_col.split('_')[0]}"] = team_df[
                f"avg_goals_scored_{team_col.split('_')[0]}"
            ] / team_df[f"avg_xg_created_{team_col.split('_')[0]}"].replace(
                [np.inf, -np.inf, np.nan], 0
            )

            team_df[f"xg_defense_{team_col.split('_')[0]}"] = team_df[
                f"avg_xg_conceded_{team_col.split('_')[0]}"
            ] / team_df[f"avg_goals_conceded_{team_col.split('_')[0]}"].replace(
                [np.inf, -np.inf, np.nan], 0
            )

            # åˆå¹¶å›åŸDataFrame
            rolling_cols = [
                f"avg_goals_scored_{team_col.split('_')[0]}"
                f"avg_goals_conceded_{team_col.split('_')[0]}"
                f"avg_xg_created_{team_col.split('_')[0]}"
                f"avg_xg_conceded_{team_col.split('_')[0]}"
                f"xg_efficiency_{team_col.split('_')[0]}"
                f"xg_defense_{team_col.split('_')[0]}"
            ]

            df = df.merge(
                team_df[["match_date", team_col] + rolling_cols],
                left_on=["match_date", team_col],
                right_on=["match_date", team_col],
                how="left",
            )

        # è®¡ç®—ä¸»é˜Ÿ vs å®¢é˜Ÿçš„ç›¸å¯¹ç‰¹å¾
        df["goal_diff_advantage"] = df.get("avg_goals_scored_home", 0) - df.get(
            "avg_goals_conceded_away", 0
        )

        df["xg_advantage"] = df.get("avg_xg_created_home", 0) - df.get(
            "avg_xg_conceded_away", 0
        )

        df["xg_efficiency_advantage"] = df.get("xg_efficiency_home", 0) - df.get(
            "xg_efficiency_away", 0
        )

        logger.info("âœ… é«˜è´¨é‡æ»šåŠ¨ç‰¹å¾è®¡ç®—å®Œæˆ")
        return df

    def prepare_features_and_labels(
        self, df: pd.DataFrame
    ) -> tuple[pd.DataFrame, pd.Series]:
        """å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾"""
        logger.info("ğŸ”§ å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾...")

        # åˆ›å»ºç›®æ ‡å˜é‡
        df["result"] = df.apply(
            lambda row: self.calculate_match_result(
                row["home_score"], row["away_score"]
            ),
            axis=1,
        )

        # ç¼–ç ç±»åˆ«ç‰¹å¾
        df["league_name"].unique()
        pd.concat([df["home_team_name"], df["away_team_name"]]).unique()

        # åˆ›å»ºæ ‡ç­¾ç¼–ç å™¨
        le_league = LabelEncoder()
        le_home_team = LabelEncoder()
        le_away_team = LabelEncoder()

        # è®­ç»ƒæ ‡ç­¾ç¼–ç å™¨
        df["league_encoded"] = le_league.fit_transform(df["league_name"])
        df["home_team_encoded"] = le_home_team.fit_transform(df["home_team_name"])
        df["away_team_encoded"] = le_away_team.fit_transform(df["away_team_name"])

        # é€‰æ‹©ç‰¹å¾åˆ— - åŒ…å«xGç›¸å…³çš„é«˜çº§ç‰¹å¾
        feature_columns = [
            # åŸºç¡€ç‰¹å¾
            "league_encoded"
            "home_team_encoded"
            "away_team_encoded"
            # æ»šåŠ¨è¿›çƒç‰¹å¾
            "avg_goals_scored_home"
            "avg_goals_conceded_home"
            "avg_goals_scored_away"
            "avg_goals_conceded_away"
            # é«˜çº§xGç‰¹å¾
            "avg_xg_created_home"
            "avg_xg_conceded_home"
            "avg_xg_created_away"
            "avg_xg_conceded_away"
            # xGæ•ˆç‡ç‰¹å¾
            "xg_efficiency_home"
            "xg_efficiency_away"
            "xg_defense_home"
            "xg_defense_away"
            # ç›¸å¯¹ç‰¹å¾
            "goal_diff_advantage"
            "xg_advantage"
            "xg_efficiency_advantage"
            # èµ”ç‡ç‰¹å¾
            "home_win_odds"
            "draw_odds"
            "away_win_odds"
            # åŸºç¡€ç»Ÿè®¡
            "total_xg"
            "xg_accuracy"
        ]

        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
        for col in feature_columns:
            if col not in df.columns:
                df[col] = 0  # ç¼ºå¤±ç‰¹å¾ç”¨0å¡«å……

        # å¤„ç†NaNå€¼å’Œå¼‚å¸¸å€¼
        df = df.fillna(0)

        # å¤„ç†æ— ç©·å¤§å€¼
        df = df.replace([np.inf, -np.inf], 0)

        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
        numeric_columns = feature_columns
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        # ç§»é™¤å¼‚å¸¸å€¼
        for col in [
            "avg_goals_scored_home"
            "avg_goals_conceded_home"
            "avg_goals_scored_away"
            "avg_goals_conceded_away"
        ]:
            df[col] = df[col].clip(lower=0, upper=10)

        for col in [
            "avg_xg_created_home"
            "avg_xg_conceded_home"
            "avg_xg_created_away"
            "avg_xg_conceded_away"
        ]:
            df[col] = df[col].clip(lower=0, upper=5)

        for col in [
            "xg_efficiency_homexg_efficiency_awayxg_defense_homexg_defense_away"
        ]:
            df[col] = df[col].clip(lower=0, upper=5)

        # èµ”ç‡åˆç†æ€§æ£€æŸ¥
        for odds_col in ["home_win_odds", "draw_odds", "away_win_odds"]:
            df[odds_col] = df[odds_col].clip(lower=1.1, upper=10.0)

        # ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡å‘é‡
        X = (df[feature_columns],)

        y = df["result"]

        # ç¼–ç ç›®æ ‡å˜é‡
        le_result = LabelEncoder()
        y_encoded = le_result.fit_transform(y)

        # ä¿å­˜ç¼–ç å™¨å’Œç‰¹å¾åç§°
        self.label_encoders = {
            "league": le_league,
            "home_team": le_home_team,
            "away_team": le_away_team,
            "result": le_result,
        }
        self.feature_names = feature_columns

        logger.info(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
        logger.info(
            f"ğŸ“Š ç»“æœåˆ†å¸ƒ: {dict(zip(le_result.classes_, np.bincount(y_encoded), strict=False))}"
        )

        return X, y_encoded

    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
        """è®­ç»ƒXGBoostæ¨¡å‹"""
        logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹...")

        # è®­ç»ƒXGBooståˆ†ç±»å™¨ - æ›´ä¿å®ˆçš„å‚æ•°
        self.model = xgb.XGBClassifier(
            n_estimators=200,  # å¢åŠ æ ‘çš„æ•°é‡
            max_depth=4,  # å‡å°‘æ·±åº¦é˜²æ­¢è¿‡æ‹Ÿåˆ
            learning_rate=0.05,  # é™ä½å­¦ä¹ ç‡
            min_child_weight=2,  # å¢åŠ æœ€å°å­èŠ‚ç‚¹æƒé‡
            subsample=0.8,  # è¡Œé‡‡æ ·
            colsample_bytree=0.8,  # åˆ—é‡‡æ ·
            random_state=42,
            n_jobs=-1,
            eval_metric="mlogloss",
        )

        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_train, y_train)

        logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")

    def realistic_backtest(
        self, X_test: pd.DataFrame, y_test: pd.Series, df_test: pd.DataFrame
    ) -> dict:
        """ç°å®æŠ•æ³¨ç­–ç•¥å›æµ‹"""
        logger.info("ğŸ’° å¼€å§‹ç°å®æŠ•æ³¨ç­–ç•¥å›æµ‹...")

        # è·å–é¢„æµ‹æ¦‚ç‡
        y_pred_proba = self.model.predict_proba(X_test)
        y_pred = self.model.predict(X_test)

        # è®¡ç®—åŸºç¡€æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)

        # ç°å®æŠ•æ³¨æ¨¡æ‹Ÿ
        total_bets = (0,)

        wins = 0
        total_stake = (0,)

        total_winnings = 0
        detailed_bets = []

        # è·å–æœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç±»åˆ«
        max_proba = np.max(y_pred_proba, axis=1)
        pred_class = np.argmax(y_pred_proba, axis=1)

        # å®é™…èµ”ç‡
        actual_odds = {
            "home_win": df_test["home_win_odds"].values,
            "draw": df_test["draw_odds"].values,
            "away_win": df_test["away_win_odds"].values,
        }

        for i in range(len(y_test)):
            confidence = (max_proba[i],)

            prediction = pred_class[i]
            actual = y_test[i]

            # åªå¯¹é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹ä¸‹æ³¨
            if confidence > self.confidence_threshold:
                total_bets += 1

                # æ¯åœºä¸‹æ³¨1å•ä½
                stake = 1
                total_stake += stake

                # è·å–å®é™…èµ”ç‡
                if (
                    prediction
                    == self.label_encoders["result"].transform(["home_win"])[0]
                ):
                    odds = actual_odds["home_win"][i]
                elif prediction == self.label_encoders["result"].transform(["draw"])[0]:
                    odds = actual_odds["draw"][i]
                else:
                    odds = actual_odds["away_win"][i]

                # è®¡ç®—æ”¶ç›Š
                if prediction == actual:  # é¢„æµ‹æ­£ç¡®,
                    winnings = stake * odds
                    total_winnings += winnings
                    wins += 1

                    # è®°å½•è¯¦ç»†æŠ•æ³¨ä¿¡æ¯
                    detailed_bets.append(
                        {
                            "index": i,
                            "confidence": confidence,
                            "prediction": prediction,
                            "actual": actual,
                            "odds": odds,
                            "stake": stake,
                            "winnings": winnings,
                            "profit": winnings - stake,
                        }
                    )

        # è®¡ç®—ROI
        roi = (
            ((total_winnings - total_stake) / total_stake * 100)
            if total_stake > 0
            else 0
        )
        win_rate = (wins / total_bets * 100) if total_bets > 0 else 0
        avg_odds = (
            np.mean([bet["odds"] for bet in detailed_bets]) if detailed_bets else 0
        )

        results = {
            "accuracy": accuracy,
            "total_bets": total_bets,
            "wins": wins,
            "win_rate": win_rate,
            "total_stake": total_stake,
            "total_winnings": total_winnings,
            "profit_loss": total_winnings - total_stake,
            "roi": roi,
            "confidence_threshold": self.confidence_threshold,
            "avg_odds": avg_odds,
            "detailed_bets": detailed_bets,
        }

        logger.info("âœ… ç°å®ç­–ç•¥å›æµ‹å®Œæˆ")
        return results

    def generate_feature_importance(self) -> dict:
        """ç”Ÿæˆç‰¹å¾é‡è¦æ€§æŠ¥å‘Š"""
        if not self.model:
            return {}

        feature_importance = dict(
            zip(self.feature_names, self.model.feature_importances_, strict=False)
        )

        # æŒ‰é‡è¦æ€§æ’åº
        sorted_features = sorted(
            feature_importance.items(), key=lambda x: x[1], reverse=True
        )

        # åˆ†ç±»ç‰¹å¾
        basic_features = ["league_encoded", "home_team_encoded", "away_team_encoded"]
        goal_features = ([f for f in sorted_features if "avg_goals_" in f[0]],)

        xg_features = [f for f in sorted_features if "avg_xg_" in f[0]]
        xg_efficiency_features = [
            f
            for f in sorted_features
            if "xg_efficiency" in f[0] or "xg_defense" in f[0]
        ]
        odds_features = ["home_win_odds", "draw_odds", "away_win_odds"]
        relative_features = ["goal_diff_advantagexg_advantagexg_efficiency_advantage"]

        return {
            "feature_importance": dict(sorted_features),
            "top_10_features": sorted_features[:10],
            "feature_categories": {
                "basic": {f: feature_importance.get(f, 0) for f in basic_features},
                "goals": {f: feature_importance.get(f, 0) for f in goal_features},
                "xg": {f: feature_importance.get(f, 0) for f in xg_features},
                "xg_efficiency": {
                    f: feature_importance.get(f, 0) for f in xg_efficiency_features
                },
                "odds": {f: feature_importance.get(f, 0) for f in odds_features},
                "relative": {
                    f: feature_importance.get(f, 0) for f in relative_features
                },
            },
        }

    def save_model(
        self, model_name: str = "football_prediction_v1_3_realistic"
    ) -> None:
        """ä¿å­˜æ¨¡å‹å’Œç»„ä»¶"""
        logger.info("ğŸ’¾ ä¿å­˜V1.3çœŸå®æ¨¡å‹å’Œç»„ä»¶...")

        # åˆ›å»ºæ¨¡å‹ç›®å½•
        model_dir = Path("/app/models/trained")
        model_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜æ¨¡å‹
        model_file = model_dir / f"{model_name}_{timestamp}_model.joblib"
        joblib.dump(self.model, model_file)

        # ä¿å­˜æ ‡ç­¾ç¼–ç å™¨
        encoders_file = model_dir / f"{model_name}_{timestamp}_encoders.joblib"
        joblib.dump(self.label_encoders, encoders_file)

        # ä¿å­˜ç‰¹å¾åç§°
        features_file = model_dir / f"{model_name}_{timestamp}_features.joblib"
        joblib.dump(self.feature_names, features_file)

        # ä¿å­˜ç¼©æ”¾å™¨
        scaler_file = model_dir / f"{model_name}_{timestamp}_scaler.joblib"
        joblib.dump(self.scaler, scaler_file)

        # ä¿å­˜è®­ç»ƒæŠ¥å‘Š
        timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        report = {
            "model_name": model_name,
            "version": "1.3",
            "training_date": timestamp_str,
            "feature_count": len(self.feature_names),
            "feature_names": self.feature_names,
            "rolling_window": self.rolling_window,
            "confidence_threshold": self.confidence_threshold,
            "data_quality": "xG + odds only",
            "training_samples": "N/A",  # å°†åœ¨è®­ç»ƒå®Œæˆåæ›´æ–°
        }

        report_file = model_dir / f"{model_name}_{timestamp}_summary.txt"
        with open(report_file, "w") as f:
            f.write("Football Prediction Model V1.3 Realistic Summary\n")
            f.write(f"{'=' * 50}\n\n")
            f.write(f"Model Name: {report['model_name']}\n")
            f.write(f"Version: {report['version']}\n")
            f.write(f"Training Date: {report['training_date']}\n")
            f.write(f"Data Quality: {report['data_quality']}\n")
            f.write(f"Feature Count: {report['feature_count']}\n")
            f.write(f"Rolling Window: {report['rolling_window']}\n")
            f.write(f"Confidence Threshold: {report['confidence_threshold']}\n\n")
            f.write("Features:\n")
            for i, feature in enumerate(report["feature_names"], 1):
                f.write(f"  {i:2d}. {feature}\n")

        logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_file}")
        logger.info(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    async def train(self):
        """ä¸»è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹V1.3çœŸå®æ€§éªŒè¯æ¨¡å‹è®­ç»ƒæµç¨‹")
        logger.info("=" * 70)

        start_time = datetime.now()

        try:
            # 1. åŠ è½½æ•°æ®
            df = await self.load_training_data()
            logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {df.shape}")

            # 2. è¿‡æ»¤é«˜è´¨é‡æ•°æ®
            df = self.filter_quality_data(df)
            logger.info(f"ğŸ“Š é«˜è´¨é‡æ•°æ®: {df.shape}")

            # 3. è®¡ç®—æ»šåŠ¨ç‰¹å¾
            df = self.calculate_rolling_features(df)
            logger.info(f"ğŸ“ˆ ç‰¹å¾å·¥ç¨‹å: {df.shape}")

            # 4. å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
            X, y = self.prepare_features_and_labels(df)

            # 5. æ—¶é—´åºåˆ—åˆ‡åˆ†
            df_sorted = df.sort_values("match_date").reset_index(drop=True)
            split_index = int(len(df_sorted) * (1 - self.test_size))

            X_train = (X.iloc[:split_index],)

            X_test = X.iloc[split_index:]
            y_train = (y[:split_index],)

            y_test = y[split_index:]
            df_test = df_sorted.iloc[split_index:]

            logger.info(f"ğŸ“‹ è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
            logger.info(f"ğŸ“‹ æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")

            # 6. è®­ç»ƒæ¨¡å‹
            self.train_model(X_train, y_train)

            # 7. æ¨¡å‹è¯„ä¼°
            train_accuracy = self.model.score(X_train, y_train)
            test_accuracy = self.model.score(X_test, y_test)

            # 8. ç°å®æŠ•æ³¨å›æµ‹
            backtest_results = self.realistic_backtest(X_test, y_test, df_test)

            # 9. ç‰¹å¾é‡è¦æ€§
            feature_importance = self.generate_feature_importance()

            # 10. ä¿å­˜æ¨¡å‹
            self.save_model()

            # 11. è¾“å‡ºæŠ¥å‘Š
            self.generate_realistic_report(
                start_time,
                train_accuracy,
                test_accuracy,
                backtest_results,
                feature_importance,
                len(df),
            )

        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()

    def generate_realistic_report(
        self,
        start_time,
        train_acc,
        test_acc,
        backtest_results,
        feature_importance,
        sample_count,
    ):
        """ç”ŸæˆçœŸå®è¯„ä¼°æŠ¥å‘Š"""
        end_time = datetime.now()
        training_time = (end_time - start_time).total_seconds()

        print("\n" + "=" * 80)
        print("ğŸ“Š é¦–å¸­é‡åŒ–åˆ†æå¸ˆ - XGBoost V1.3çœŸå®æ€§éªŒè¯æŠ¥å‘Š")
        print("=" * 80)

        print("\nğŸ“Š è®­ç»ƒåŸºæœ¬ä¿¡æ¯:")
        print(f"   â±ï¸ è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print("   ğŸ¯ æ¨¡å‹ç±»å‹: XGBoost Classifier (ç°å®ç‰ˆæœ¬)")
        print(f"   ğŸ”„ æ»šåŠ¨çª—å£: {self.rolling_window}åœº")
        print(f"   ğŸ“Š ä¿¡å¿ƒé˜ˆå€¼: {self.confidence_threshold}")
        print("   ğŸ” æ•°æ®è´¨é‡: ä»…xG+èµ”ç‡çš„é«˜è´¨é‡æ ·æœ¬")
        print(f"   ğŸ“Š æ€»æ ·æœ¬æ•°: {sample_count:,}")

        print("\nğŸ“ˆ æ¨¡å‹æ€§èƒ½:")
        print(f"   ğŸ‹ï¸ è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc:.4f} ({train_acc * 100:.2f}%)")
        print(f"   ğŸ§ª æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc * 100:.2f}%)")
        print(f"   ğŸ“‰ è¿‡æ‹Ÿåˆç¨‹åº¦: {(train_acc - test_acc) * 100:.2f}%")

        print("\nğŸ’° ç°å®æŠ•æ³¨ç»“æœ:")
        print(f"   ğŸ¯ æ€»æŠ•æ³¨æ¬¡æ•°: {backtest_results['total_bets']}")
        print(f"   âœ… è·èƒœæ¬¡æ•°: {backtest_results['wins']}")
        print(f"   ğŸ“Š å‘½ä¸­ç‡: {backtest_results['win_rate']:.2f}%")
        print(f"   ğŸ’µ æ€»æŠ•æ³¨é‡‘é¢: {backtest_results['total_stake']:.2f}")
        print(f"   ğŸ’° æ€»æ”¶å›é‡‘é¢: {backtest_results['total_winnings']:.2f}")
        print(f"   ğŸ“ˆ å‡€ç›ˆäº: {backtest_results['profit_loss']:+.2f}")
        print(f"   ğŸ–ï¸ æŠ•èµ„å›æŠ¥ç‡(ROI): {backtest_results['roi']:+.2f}%")
        print(f"   ğŸ“Š å¹³å‡èµ”ç‡: {backtest_results['avg_odds']:.2f}")

        print("\nğŸ† ç‰¹å¾é‡è¦æ€§ Top 10:")
        for i, (feature, importance) in enumerate(
            feature_importance["top_10_features"], 1
        ):
            print(f"   {i:2d}. {feature}: {importance:.4f}")

        print("\nğŸ“Š ç‰¹å¾ç±»åˆ«é‡è¦æ€§:")
        categories = feature_importance["feature_categories"]
        for category, features in categories.items():
            total_importance = sum(features.values())
            print(f"   ğŸ“Š {category}: {total_importance:.4f}")

            for feature, imp in features.items():
                if imp > 0:
                    print(f"      - {feature}: {imp:.4f}")

        # è¯¦ç»†æŠ•æ³¨åˆ†æ
        if backtest_results["detailed_bets"]:
            profitable_bets = [
                bet for bet in backtest_results["detailed_bets"] if bet["profit"] > 0
            ]
            losing_bets = [
                bet for bet in backtest_results["detailed_bets"] if bet["profit"] <= 0
            ]

            avg_profit = (
                np.mean([bet["profit"] for bet in profitable_bets])
                if profitable_bets
                else 0
            )
            avg_loss = (
                np.mean([bet["profit"] for bet in losing_bets]) if losing_bets else 0
            )

            print("\nğŸ“Š è¯¦ç»†æŠ•æ³¨åˆ†æ:")
            print(f"   ğŸ’° ç›ˆåˆ©æŠ•æ³¨: {len(profitable_bets)} åœº")
            print(f"   ğŸ“Š å¹³å‡ç›ˆåˆ©: {avg_profit:.3f}")
            print(f"   âŒ äºæŸæŠ•æ³¨: {len(losing_bets)} åœº")
            print(f"   ğŸ“Š å¹³å‡äºæŸ: {avg_loss:.3f}")

        # ç»“è®º
        print("\nğŸ¯ ç°å®æ¨¡å‹ç»“è®º:")
        if backtest_results["roi"] > 0:
            print(f"   âœ… æ­£ç›ˆåˆ©! ROI: {backtest_results['roi']:+.2f}%")
            print("   ğŸ’¡ æ¨¡å‹å…·å¤‡çœŸå®ç›ˆåˆ©èƒ½åŠ›ï¼Œå¯ä»¥è°¨æ…è€ƒè™‘å®ç›˜åº”ç”¨")
        elif backtest_results["roi"] > -10:
            print(f"   âš ï¸ è½»å¾®äºæŸ: ROI: {backtest_results['roi']:+.2f}%")
            print("   ğŸ’¡ æ¨¡å‹æ¥è¿‘ç›ˆäºå¹³è¡¡ï¼Œå¯ä»¥å°è¯•ä¼˜åŒ–å‚æ•°æˆ–æ‰©å¤§æ ·æœ¬")
        else:
            print(f"   âŒ æ˜¾è‘—äºæŸ: ROI: {backtest_results['roi']:+.2f}%")
            print("   ğŸ’¡ éœ€è¦é‡æ–°è¯„ä¼°æ¨¡å‹ç­–ç•¥æˆ–æ•°æ®è´¨é‡")

        print("\nğŸš€ ç°å®æ€§æ”¹è¿›å»ºè®®:")
        if sample_count < 1000:
            print(f"   ğŸ“Š æ ·æœ¬æ•°é‡è¾ƒå°‘({sample_count})ï¼Œå»ºè®®:")
            print("      â€¢ æ‰©å±•xGå’Œèµ”ç‡æ•°æ®æ”¶é›†")
            print("      â€¢ é™ä½ä¿¡å¿ƒé˜ˆå€¼åˆ°0.50-0.60")
            print("      â€¢ ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹æ–¹æ³•")

        xg_importance = feature_importance["feature_categories"]["xg"]
        if xg_importance < 0.1:
            print(f"   ğŸ“Š xGç‰¹å¾é‡è¦æ€§è¾ƒä½({xg_importance:.3f})ï¼Œå»ºè®®:")
            print("      â€¢ éªŒè¯xGæ•°æ®è´¨é‡")
            print("      â€¢ ä¼˜åŒ–xGç‰¹å¾å·¥ç¨‹")
            print("      â€¢ è€ƒè™‘xGé¢„æµ‹å‡†ç¡®æ€§")

        print("\n" + "=" * 80)
        print("ğŸ“Š é¦–å¸­é‡åŒ–åˆ†æå¸ˆç°å®éªŒè¯å®Œæˆ - V1.3çœŸå®æ¨¡å‹å·²å°±ç»ª")
        print("=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ“Š é¦–å¸­é‡åŒ–åˆ†æå¸ˆ - XGBoost V1.3çœŸå®æ€§éªŒè¯å¯åŠ¨")

    trainer = RealisticModelTrainer()
    await trainer.train()


if __name__ == "__main__":
    asyncio.run(main())
