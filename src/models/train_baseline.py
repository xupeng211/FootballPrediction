#!/usr/bin/env python3
"""
Phase 3 åŸºçº¿æ¨¡å‹è®­ç»ƒå™¨
é¦–å¸­ AI ç§‘å­¦å®¶: æœºå™¨å­¦ä¹ ä¸“å®¶

Purpose: è®­ç»ƒXGBooståŸºçº¿é¢„æµ‹æ¨¡å‹
ä½¿ç”¨ç‰¹å¾å·¥ç¨‹æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
"""

import logging
import sys
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Tuple, Any
from datetime import datetime

# æœºå™¨å­¦ä¹ åº“
import xgboost as xgb
from sklearn.metrics import (
    accuracy_score,
    log_loss,
    classification_report,
    confusion_matrix,
)
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.features.pipeline import FeaturePipeline

logger = logging.getLogger(__name__)


class BaselineTrainer:
    """
    XGBooståŸºçº¿æ¨¡å‹è®­ç»ƒå™¨

    åŠŸèƒ½ï¼š
    1. è°ƒç”¨ç‰¹å¾æµæ°´çº¿è·å–æ•°æ®
    2. æ—¶é—´åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    3. è®­ç»ƒXGBooståˆ†ç±»æ¨¡å‹
    4. è¯„ä¼°æ¨¡å‹æ€§èƒ½ (Accuracy, LogLoss)
    5. è¾“å‡ºè¯¦ç»†çš„è®­ç»ƒæŠ¥å‘Š
    """

    def __init__(self):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        self.feature_pipeline = FeaturePipeline()
        self.model = None
        self.label_encoder = LabelEncoder()

        logger.info("âœ… åŸºçº¿è®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸ")

    def prepare_data(
        self, train_end_date: str = "2024-05-01"
    ) -> tuple[pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray]:
        """
        å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®

        Args:
            train_end_date: è®­ç»ƒé›†ç»“æŸæ—¥æœŸ

        Returns:
            (X_train, X_test, y_train, y_test)
        """
        logger.info("ğŸ”„ å¼€å§‹å‡†å¤‡è®­ç»ƒæ•°æ®...")

        try:
            # æ„å»ºç‰¹å¾æ•°æ®é›†
            df, feature_cols = self.feature_pipeline.build_features(window=5)

            # æ—¶é—´åˆ‡åˆ†
            train_df, test_df = self.feature_pipeline.split_data(df, train_end_date)

            # é€‰æ‹©ç‰¹å¾åˆ—
            X_train = train_df[feature_cols].fillna(0)
            X_test = test_df[feature_cols].fillna(0)

            # å‡†å¤‡ç›®æ ‡å˜é‡
            y_train = train_df["result"].values
            y_test = test_df["result"].values

            # ç§»é™¤åŒ…å«NaNçš„æ ·æœ¬
            train_mask = ~(X_train.isna().any(axis=1) | pd.isna(y_train))
            test_mask = ~(X_test.isna().any(axis=1) | pd.isna(y_test))

            X_train = X_train[train_mask]
            y_train = y_train[train_mask]
            X_test = X_test[test_mask]
            y_test = y_test[test_mask]

            logger.info("âœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.info(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾")
            logger.info(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬, {X_test.shape[1]} ç‰¹å¾")
            logger.info(f"   ç‰¹å¾åˆ—: {len(feature_cols)} ä¸ª")

            # æ˜¾ç¤ºç›®æ ‡å˜é‡åˆ†å¸ƒ
            unique_train, counts_train = np.unique(y_train, return_counts=True)
            unique_test, counts_test = np.unique(y_test, return_counts=True)

            logger.info(f"   è®­ç»ƒé›†åˆ†å¸ƒ: {dict(zip(unique_train, counts_train, strict=False))}")
            logger.info(f"   æµ‹è¯•é›†åˆ†å¸ƒ: {dict(zip(unique_test, counts_test, strict=False))}")

            return X_train, X_test, y_train, y_test

        except Exception as e:
            logger.error(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            raise

    def train_model(
        self, X_train: pd.DataFrame, y_train: np.ndarray
    ) -> xgb.XGBClassifier:
        """
        è®­ç»ƒXGBoostæ¨¡å‹

        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾

        Returns:
            è®­ç»ƒå¥½çš„XGBoostæ¨¡å‹
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹...")

        # XGBoostå‚æ•°é…ç½®
        params = {
            "objective": "multi:softprob",  # å¤šåˆ†ç±»
            "num_class": 3,  # 3åˆ†ç±» (å®¢èƒœ/å¹³/ä¸»èƒœ)
            "eval_metric": "mlogloss",
            "max_depth": 6,
            "learning_rate": 0.1,
            "n_estimators": 100,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "random_state": 42,
            "n_jobs": -1,
        }

        # åˆ›å»ºæ¨¡å‹
        model = xgb.XGBClassifier(**params)

        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train, y_train, eval_set=[(X_train, y_train)], verbose=False)

        logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
        logger.info(f"   æ ‘çš„æ•°é‡: {model.n_estimators}")
        logger.info(f"   æœ€å¤§æ·±åº¦: {model.max_depth}")

        self.model = model
        return model

    def evaluate_model(
        self, model: xgb.XGBClassifier, X_test: pd.DataFrame, y_test: np.ndarray
    ) -> dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½

        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•æ ‡ç­¾

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        logger.info("ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")

        # é¢„æµ‹
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        logloss = log_loss(y_test, y_pred_proba)

        # è¯¦ç»†æŠ¥å‘Š
        class_names = ["å®¢èƒœ(0)", "å¹³å±€(1)", "ä¸»èƒœ(2)"]
        report = classification_report(
            y_test, y_pred, target_names=class_names, output_dict=True
        )

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, y_pred)

        logger.info("ğŸ“ˆ è¯„ä¼°ç»“æœ:")
        logger.info(f"   å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)")
        logger.info(f"   å¯¹æ•°æŸå¤± (LogLoss): {logloss:.4f}")

        # å„ç±»åˆ«å‡†ç¡®ç‡
        for i, class_name in enumerate(class_names):
            if str(i) in report:
                class_acc = report[str(i)]["precision"]
                logger.info(f"   {class_name} å‡†ç¡®ç‡: {class_acc:.4f}")

        # ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.DataFrame(
            {"feature": X_test.columns, "importance": model.feature_importances_}
        ).sort_values("importance", ascending=False)

        logger.info("\nğŸ” Top 10 é‡è¦ç‰¹å¾:")
        for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):
            logger.info(f"   {i+1:2d}. {row['feature']:30s}: {row['importance']:.4f}")

        # ä¿å­˜ç»“æœ
        results = {
            "accuracy": accuracy,
            "logloss": logloss,
            "classification_report": report,
            "confusion_matrix": cm,
            "feature_importance": feature_importance,
        }

        return results

    def save_results(
        self, results: dict[str, Any], model_name: str = "baseline_xgboost"
    ) -> None:
        """
        ä¿å­˜è®­ç»ƒç»“æœå’Œæ¨¡å‹

        Args:
            results: è¯„ä¼°ç»“æœ
            model_name: æ¨¡å‹åç§°
        """
        logger.info("ğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("results") / model_name
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜è¯„ä¼°æŠ¥å‘Š
        report_path = output_dir / f"report_{timestamp}.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("Phase 3 åŸºçº¿æ¨¡å‹è®­ç»ƒæŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n")
            f.write(f"æ¨¡å‹åç§°: {model_name}\n")
            f.write("=" * 50 + "\n\n")

            f.write(f"å‡†ç¡®ç‡: {results['accuracy']:.4f}\n")
            f.write(f"å¯¹æ•°æŸå¤±: {results['logloss']:.4f}\n\n")

            f.write("åˆ†ç±»æŠ¥å‘Š:\n")
            for class_name, metrics in results["classification_report"].items():
                if isinstance(metrics, dict):
                    f.write(f"  {class_name}:\n")
                    for metric, value in metrics.items():
                        f.write(f"    {metric}: {value:.4f}\n")

        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
        importance_path = output_dir / f"feature_importance_{timestamp}.csv"
        results["feature_importance"].to_csv(importance_path, index=False)

        # ä¿å­˜æ¨¡å‹
        if self.model:
            model_path = output_dir / f"model_{timestamp}.json"
            self.model.save_model(str(model_path))

        logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

    def run_training(
        self, train_end_date: str = "2024-05-01", save_results: bool = True
    ) -> dict[str, float]:
        """
        è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹

        Args:
            train_end_date: è®­ç»ƒé›†ç»“æŸæ—¥æœŸ
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ

        Returns:
            è¯„ä¼°æŒ‡æ ‡
        """
        logger.info("ğŸ¯ å¼€å§‹Phase 3åŸºçº¿æ¨¡å‹è®­ç»ƒæµç¨‹...")

        try:
            # 1. å‡†å¤‡æ•°æ®
            X_train, X_test, y_train, y_test = self.prepare_data(train_end_date)

            # 2. è®­ç»ƒæ¨¡å‹
            model = self.train_model(X_train, y_train)

            # 3. è¯„ä¼°æ¨¡å‹
            results = self.evaluate_model(model, X_test, y_test)

            # 4. ä¿å­˜ç»“æœ
            if save_results:
                self.save_results(results)

            # 5. è¾“å‡ºæ€»ç»“
            print("\n" + "=" * 80)
            print("ğŸ‰ Phase 3 åŸºçº¿æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print(
                f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)"
            )
            print(f"ğŸ“Š å¯¹æ•°æŸå¤±: {results['logloss']:.4f}")
            print("=" * 80)

            return {"accuracy": results["accuracy"], "logloss": results["logloss"]}

        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•° - è¿è¡ŒåŸºçº¿æ¨¡å‹è®­ç»ƒ"""
    logging.basicConfig(
        level=logging.INFO,
        format="ğŸ§  %(asctime)s [%(levelname)8s] %(name)s: %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )

    logger.info("ğŸš€ Phase 3 åŸºçº¿æ¨¡å‹è®­ç»ƒç³»ç»Ÿå¯åŠ¨")

    try:
        trainer = BaselineTrainer()
        metrics = trainer.run_training(
            train_end_date="2025-10-01", save_results=True  # è°ƒæ•´ä¸ºåˆé€‚çš„æ—¶é—´åˆ‡åˆ†
        )

        logger.info("ğŸ¯ è®­ç»ƒä»»åŠ¡æˆåŠŸå®Œæˆ!")
        return metrics

    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒä»»åŠ¡å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()
