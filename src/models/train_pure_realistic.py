#!/usr/bin/env python3
"""
æ•°æ®æ´ç™–å®¡è®¡å¸ˆ - çº¯çœŸå®æ•°æ®è®­ç»ƒ
ç»å¯¹çœŸå®ï¼Œé›¶å¡«å……ï¼Œé›¶æ¨¡æ‹Ÿ
åªä½¿ç”¨çœŸå®çš„xGæ•°æ®ï¼Œå“ªæ€•åªæœ‰23æ¡æ ·æœ¬
"""

import asyncio
import logging
import sys
import json
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple

import asyncpg
import os
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy import select, text
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import joblib

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class PureRealisticTrainer:
    """çº¯çœŸå®æ•°æ®è®­ç»ƒå™¨ - æ•°æ®æ´ç™–å®¡è®¡å¸ˆç‰ˆ"""

    def __init__(self):
        self.database_url = os.getenv("DATABASE_URL", "postgresql://postgres:postgres-dev-password@db:5432/football_prediction")
        self.async_database_url = self.database_url.replace("postgresql://", "postgresql+asyncpg://")

        if "localhost" in self.database_url:
            self.database_url = self.database_url.replace("localhost", "db")
            self.async_database_url = self.async_database_url.replace("localhost", "db")

        # é…ç½®å‚æ•° - ç»å¯¹çœŸå®
        self.confidence_threshold = 0.55  # é™ä½ä¿¡å¿ƒé˜ˆå€¼
        self.test_size = 0.3  # æµ‹è¯•é›†æ¯”ä¾‹

        # å­˜å‚¨æ¨¡å‹å’Œç»„ä»¶
        self.model = None
        self.label_encoders = {}
        self.feature_names = []

    async def load_pure_real_data(self) -> pd.DataFrame:
        """åŠ è½½çº¯çœŸå®æ•°æ® - ç»å¯¹ä¸å¡«å……ä»»ä½•æ•°æ®"""
        logger.info("ğŸ” å¼€å§‹åŠ è½½çº¯çœŸå®xGæ•°æ®...")

        try:
            engine = create_async_engine(self.async_database_url, echo=False)
            async_session = async_sessionmaker(engine, expire_on_commit=False)

            async with async_session() as session:
                # æŸ¥è¯¢åŒ…å«çœŸå®xGæ•°æ®çš„æ¯”èµ›
                query = text("""
                    SELECT
                        m.id,
                        m.home_team_id,
                        m.away_team_id,
                        m.league_id,
                        m.home_score,
                        m.away_score,
                        m.status,
                        m.match_date,
                        m.stats,
                        home.name as home_team_name,
                        away.name as away_team_name,
                        league.name as league_name
                    FROM matches m
                    JOIN teams home ON m.home_team_id = home.id
                    JOIN teams away ON m.away_team_id = away.id
                    JOIN leagues league ON m.league_id = league.id
                    WHERE m.status IN ('completed', 'finished')
                      AND m.home_score IS NOT NULL
                      AND m.away_score IS NOT NULL
                      AND m.match_date IS NOT NULL
                      AND m.stats IS NOT NULL
                      AND m.stats != 'null'
                      AND m.stats::text ILIKE '%xg%'
                    ORDER BY m.match_date
                """)

                result = await session.execute(query)
                matches = result.fetchall()

                logger.info(f"ğŸ“Š æ‰¾åˆ° {len(matches)} åœºå¯èƒ½åŒ…å«xGçš„æ¯”èµ›")

                await engine.dispose()

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise

        # è½¬æ¢ä¸ºDataFrameå¹¶ä¸¥æ ¼è¿‡æ»¤
        df = pd.DataFrame([
            {
                'match_id': match.id,
                'home_team_id': match.home_team_id,
                'away_team_id': match.away_team_id,
                'league_id': match.league_id,
                'home_score': match.home_score,
                'away_score': match.away_score,
                'status': match.status,
                'match_date': match.match_date,
                'stats': match.stats,
                'home_team_name': match.home_team_name,
                'away_team_name': match.away_team_name,
                'league_name': match.league_name
            }
            for match in matches
        ])

        return df

    def extract_real_xg(self, stats_json: str) -> dict[str, float]:
        """æå–çœŸå®çš„xGæ•°æ® - ä¸¥æ ¼éªŒè¯"""
        try:
            if not stats_json or stats_json == 'null':
                return {'xg_home': None, 'xg_away': None}

            stats = json.loads(stats_json)

            # é€’å½’æœç´¢çœŸå®çš„çƒé˜ŸxGæ•°æ®
            def find_team_xg(obj, path=""):
                xg_data = {'home': None, 'away': None}

                if isinstance(obj, dict):
                    for key, value in obj.items():
                        # ç›´æ¥åŒ¹é…xg_homeå’Œxg_awayå­—æ®µ
                        if key == 'xg_home' and isinstance(value, (int, float)):
                            xg_data['home'] = float(value)
                        elif key == 'xg_away' and isinstance(value, (int, float)):
                            xg_data['away'] = float(value)
                        elif isinstance(value, (dict, list)):
                            sub_xg = find_team_xg(value, f"{path}.{key}" if path else key)
                            if sub_xg['home'] is not None:
                                xg_data['home'] = sub_xg['home']
                            if sub_xg['away'] is not None:
                                xg_data['away'] = sub_xg['away']
                elif isinstance(obj, list):
                    for idx, item in enumerate(obj):
                        if isinstance(item, (dict, list)):
                            sub_xg = find_team_xg(item, f"{path}[{idx}]")
                            if sub_xg['home'] is not None:
                                xg_data['home'] = sub_xg['home']
                            if sub_xg['away'] is not None:
                                xg_data['away'] = sub_xg['away']

                return xg_data

            xg_result = find_team_xg(stats)

            # ä¸¥æ ¼éªŒè¯xGå€¼
            if xg_result['home'] is not None:
                if not (0.0 <= xg_result['home'] <= 10.0):
                    xg_result['home'] = None
            if xg_result['away'] is not None:
                if not (0.0 <= xg_result['away'] <= 10.0):
                    xg_result['away'] = None

            return {'xg_home': xg_result['home'], 'xg_away': xg_result['away']}

        except (json.JSONDecodeError, ValueError, TypeError):
            return {'xg_home': None, 'xg_away': None}

    def filter_pure_real_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¿‡æ»¤çº¯çœŸå®æ•°æ® - ç»å¯¹ä¸å…è®¸å¡«å……"""
        logger.info("ğŸ” ä¸¥æ ¼è¿‡æ»¤çº¯çœŸå®æ•°æ®...")

        original_count = len(df)
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {original_count} åœºæ¯”èµ›")

        # æå–çœŸå®xGæ•°æ®
        xg_data = df['stats'].apply(self.extract_real_xg)
        df['xg_home'] = xg_data.apply(lambda x: x['xg_home'])
        df['xg_away'] = xg_data.apply(lambda x: x['xg_away'])
        df['total_xg'] = df['xg_home'] + df['xg_away']

        # ä¸¥æ ¼è¿‡æ»¤æ¡ä»¶ - å¿…é¡»åŒæ—¶æœ‰ä¸»å®¢é˜ŸxG
        strict_mask = (
            df['xg_home'].notna() &
            df['xg_away'].notna() &
            (df['xg_home'] > 0) &
            (df['xg_away'] > 0) &
            (df['total_xg'] > 0.1) &
            df['match_date'].notna()
        )

        df_pure = df[strict_mask].copy()

        logger.info(f"âœ… çº¯çœŸå®æ•°æ®: {len(df_pure)} åœºæ¯”èµ›")
        logger.info(f"ğŸ“‰ çœŸå®æ•°æ®ä¿ç•™ç‡: {len(df_pure)/original_count*100:.1f}%")

        # ç»å¯¹ä¸å¡«å……ä»»ä½•æ•°æ®ï¼
        logger.info("ğŸš« æ•°æ®æ´ç™–å®¡è®¡å¸ˆå£°æ˜: ç»å¯¹æœªå¡«å……ä»»ä½•æ•°æ®ï¼")

        return df_pure

    def prepare_simple_features(self, df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
        """å‡†å¤‡ç®€å•ç‰¹å¾ - åŸºäºæœ‰é™çš„çœŸå®æ•°æ®"""
        logger.info("ğŸ”§ å‡†å¤‡ç®€å•ç‰¹å¾ï¼ˆåŸºäºæœ‰é™çœŸå®æ•°æ®ï¼‰...")

        # ç”±äºæ•°æ®é‡å¤ªå°‘ï¼Œåªèƒ½ä½¿ç”¨æœ€ç®€å•çš„ç‰¹å¾
        df['total_goals'] = df['home_score'] + df['away_score']
        df['goal_difference'] = df['home_score'] - df['away_score']
        df['xg_difference'] = df['xg_home'] - df['xg_away']
        df['xg_accuracy'] = df['total_xg'] - df['total_goals']  # xGé¢„æµ‹å‡†ç¡®æ€§

        # åˆ›å»ºç›®æ ‡å˜é‡
        df['result'] = df.apply(
            lambda row: 'home_win' if row['home_score'] > row['away_score']
                     else ('away_win' if row['home_score'] < row['away_score'] else 'draw'),
            axis=1
        )

        # ç®€å•ç‰¹å¾å·¥ç¨‹ - ç”±äºæ•°æ®å¤ªå°‘ï¼Œä¸èƒ½ä½¿ç”¨æ»šåŠ¨ç‰¹å¾
        feature_columns = [
            # åŸºç¡€ç‰¹å¾
            'home_score',
            'away_score',
            'total_goals',
            'goal_difference',

            # xGç‰¹å¾ï¼ˆæˆ‘ä»¬çš„æ ¸å¿ƒçœŸå®æ•°æ®ï¼‰
            'xg_home',
            'xg_away',
            'total_xg',
            'xg_difference',
            'xg_accuracy',
        ]

        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
        for col in feature_columns:
            if col not in df.columns:
                df[col] = 0

        # å¤„ç†NaNå€¼ï¼ˆåªå…è®¸ç”¨0å¡«å……ï¼Œå› ä¸ºçœŸå®æ•°æ®å·²ç»éªŒè¯è¿‡ï¼‰
        df = df.fillna(0)

        # ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡å‘é‡
        X = df[feature_columns]
        y = df['result']

        # ç¼–ç ç›®æ ‡å˜é‡
        le_result = LabelEncoder()
        y_encoded = le_result.fit_transform(y)

        # ä¿å­˜ç¼–ç å™¨å’Œç‰¹å¾åç§°
        self.label_encoders = {'result': le_result}
        self.feature_names = feature_columns

        logger.info(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
        logger.info(f"ğŸ“Š ç»“æœåˆ†å¸ƒ: {dict(zip(le_result.classes_, np.bincount(y_encoded), strict=False))}")

        return X, y_encoded

    def train_simple_model(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
        """è®­ç»ƒç®€å•æ¨¡å‹ - é€‚åˆå°æ•°æ®é‡"""
        logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒç®€å•æ¨¡å‹...")

        # ä½¿ç”¨é€‚åˆå°æ•°æ®é‡çš„å‚æ•°
        self.model = xgb.XGBClassifier(
            n_estimators=50,      # å‡å°‘æ ‘çš„æ•°é‡
            max_depth=3,          # å‡å°‘æ·±åº¦
            learning_rate=0.1,    # æé«˜å­¦ä¹ ç‡
            min_child_weight=1,   # å…è®¸æ›´å°çš„å­èŠ‚ç‚¹
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            n_jobs=-1,
            eval_metric='mlogloss'
        )

        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_train, y_train)

        logger.info("âœ… ç®€å•æ¨¡å‹è®­ç»ƒå®Œæˆ")

    def realistic_evaluation(self, X_test: pd.DataFrame, y_test: pd.Series) -> dict:
        """ç°å®è¯„ä¼° - ä¸ä½¿ç”¨èµ”ç‡ï¼ˆå› ä¸ºæ²¡æœ‰çœŸå®èµ”ç‡æ•°æ®ï¼‰"""
        logger.info("ğŸ“Š å¼€å§‹ç°å®è¯„ä¼°...")

        # åŸºç¡€é¢„æµ‹è¯„ä¼°
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)

        accuracy = accuracy_score(y_test, y_pred)

        # è®¡ç®—åŸºç¡€ç»Ÿè®¡ï¼ˆä¸æ¶‰åŠèµ”ç‡ï¼‰
        max_proba = np.max(y_pred_proba, axis=1)
        high_confidence_count = np.sum(max_proba > self.confidence_threshold)

        results = {
            'accuracy': accuracy,
            'test_samples': len(y_test),
            'high_confidence_predictions': high_confidence_count,
            'confidence_threshold': self.confidence_threshold,
            'avg_max_confidence': np.mean(max_proba),
            'feature_importance': dict(zip(self.feature_names, self.model.feature_importances_, strict=False))
        }

        logger.info("âœ… ç°å®è¯„ä¼°å®Œæˆ")
        return results

    def save_pure_model(self, model_name: str = "football_prediction_pure_real") -> None:
        """ä¿å­˜çº¯çœŸå®æ¨¡å‹"""
        logger.info("ğŸ’¾ ä¿å­˜çº¯çœŸå®æ¨¡å‹...")

        model_dir = Path("/app/models/trained")
        model_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜æ¨¡å‹
        model_file = model_dir / f"{model_name}_{timestamp}_model.joblib"
        joblib.dump(self.model, model_file)

        # ä¿å­˜ç»„ä»¶
        components_file = model_dir / f"{model_name}_{timestamp}_components.joblib"
        joblib.dump({
            'label_encoders': self.label_encoders,
            'feature_names': self.feature_names
        }, components_file)

        # ä¿å­˜æŠ¥å‘Š
        report_file = model_dir / f"{model_name}_{timestamp}_summary.txt"
        with open(report_file, 'w') as f:
            f.write("Pure Realistic Model Summary\n")
            f.write(f"{'='*50}\n\n")
            f.write(f"Model: {model_name}\n")
            f.write(f"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("Data Type: PURE REAL - No Imputation\n")
            f.write(f"Feature Count: {len(self.feature_names)}\n")
            f.write(f"Features: {', '.join(self.feature_names)}\n")
            f.write("\nDATA PURITY AUDITOR CERTIFIED: 100% REAL DATA\n")

        logger.info(f"âœ… çº¯çœŸå®æ¨¡å‹å·²ä¿å­˜: {model_file}")

    async def train(self):
        """ä¸»è®­ç»ƒæµç¨‹ - ç»å¯¹çœŸå®ç‰ˆ"""
        logger.info("ğŸš€ å¼€å§‹çº¯çœŸå®æ•°æ®è®­ç»ƒæµç¨‹")
        logger.info("="*80)
        logger.info("ğŸš« æ•°æ®æ´ç™–å®¡è®¡å¸ˆå£°æ˜: ç»å¯¹ä¸å¡«å……ä»»ä½•æ•°æ®ï¼")

        start_time = datetime.now()

        try:
            # 1. åŠ è½½æ•°æ®
            df = await self.load_pure_real_data()
            logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {df.shape}")

            # 2. ä¸¥æ ¼è¿‡æ»¤
            df_pure = self.filter_pure_real_data(df)
            logger.info(f"ğŸ“Š çº¯çœŸå®æ•°æ®: {df_pure.shape}")

            if len(df_pure) < 10:
                logger.error(f"âŒ çœŸå®æ•°æ®å¤ªå°‘({len(df_pure)}æ¡)ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
                return

            # 3. å‡†å¤‡ç‰¹å¾
            X, y = self.prepare_simple_features(df_pure)

            # 4. æ•°æ®åˆ‡åˆ†ï¼ˆç”±äºæ•°æ®å°‘ï¼Œä½¿ç”¨æ›´ä¿å®ˆçš„æµ‹è¯•é›†æ¯”ä¾‹ï¼‰
            if len(X) < 20:
                # æ•°æ®å¤ªå°‘ï¼Œç”¨ç®€å•åˆ‡åˆ†
                test_size = max(1, int(len(X) * 0.3))
                X_train = X.iloc[:-test_size]
                X_test = X.iloc[-test_size:]
                y_train = y[:-test_size]
                y_test = y[-test_size:]
            else:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=self.test_size, random_state=42, stratify=y
                )

            logger.info(f"ğŸ“‹ è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
            logger.info(f"ğŸ“‹ æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")

            # 5. è®­ç»ƒæ¨¡å‹
            self.train_simple_model(X_train, y_train)

            # 6. è¯„ä¼°
            train_accuracy = self.model.score(X_train, y_train)
            evaluation_results = self.realistic_evaluation(X_test, y_test)

            # 7. ä¿å­˜æ¨¡å‹
            self.save_pure_model()

            # 8. è¾“å‡ºæŠ¥å‘Š
            self.generate_pure_report(
                start_time, train_accuracy, evaluation_results, len(df_pure)
            )

        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def generate_pure_report(self, start_time, train_acc, eval_results, sample_count):
        """ç”Ÿæˆçº¯çœŸå®æŠ¥å‘Š"""
        end_time = datetime.now()
        training_time = (end_time - start_time).total_seconds()

        print("\n" + "="*80)
        print("ğŸ” æ•°æ®æ´ç™–å®¡è®¡å¸ˆ - çº¯çœŸå®æ•°æ®è®­ç»ƒæŠ¥å‘Š")
        print("="*80)

        print("\nğŸ“Š çº¯çœŸå®æ•°æ®ç»Ÿè®¡:")
        print(f"   ğŸ” çœŸå®æ ·æœ¬æ•°: {sample_count}")
        print(f"   â±ï¸ è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print("   ğŸ¯ æ¨¡å‹ç±»å‹: XGBoost Classifier (çº¯çœŸå®ç‰ˆ)")
        print("   ğŸš« æ•°æ®å¡«å……: ç»å¯¹ç¦æ­¢ï¼")
        print("   âœ… æ•°æ®çº¯åº¦: 100%çœŸå®")

        print("\nğŸ“ˆ æ¨¡å‹æ€§èƒ½:")
        print(f"   ğŸ‹ï¸ è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f} ({train_acc*100:.2f}%)")
        print(f"   ğŸ§ª æµ‹è¯•å‡†ç¡®ç‡: {eval_results['accuracy']:.4f} ({eval_results['accuracy']*100:.2f}%)")
        print(f"   ğŸ“Š æµ‹è¯•æ ·æœ¬: {eval_results['test_samples']}")
        print(f"   ğŸ¯ é«˜ä¿¡å¿ƒé¢„æµ‹: {eval_results['high_confidence_predictions']}")
        print(f"   ğŸ“Š å¹³å‡æœ€å¤§ç½®ä¿¡åº¦: {eval_results['avg_max_confidence']:.3f}")

        print("\nğŸ† ç‰¹å¾é‡è¦æ€§:")
        sorted_features = sorted(
            eval_results['feature_importance'].items(),
            key=lambda x: x[1],
            reverse=True
        )
        for i, (feature, importance) in enumerate(sorted_features, 1):
            print(f"   {i:2d}. {feature}: {importance:.4f}")

        print("\nğŸ¯ æ•°æ®æ´ç™–å®¡è®¡å¸ˆç»“è®º:")
        if sample_count >= 50:
            print(f"   âœ… æ•°æ®é‡å……è¶³({sample_count}æ¡)ï¼Œç»“æœå¯ä¿¡åº¦è¾ƒé«˜")
        elif sample_count >= 20:
            print(f"   âš ï¸  æ•°æ®é‡è¾ƒå°‘({sample_count}æ¡)ï¼Œç»“æœä»…ä¾›å‚è€ƒ")
        else:
            print(f"   âŒ æ•°æ®é‡æå°‘({sample_count}æ¡)ï¼Œç»Ÿè®¡æ„ä¹‰æœ‰é™")

        if eval_results['accuracy'] > 0.6:
            print("   âœ… æ¨¡å‹æ˜¾ç¤ºå‡ºä¸€å®šé¢„æµ‹èƒ½åŠ›")
        elif eval_results['accuracy'] > 0.4:
            print("   âš ï¸  æ¨¡å‹é¢„æµ‹èƒ½åŠ›æœ‰é™")
        else:
            print("   âŒ æ¨¡å‹é¢„æµ‹èƒ½åŠ›ä¸è¶³")

        print("\nğŸ’¡ å®¡è®¡å¸ˆå»ºè®®:")
        print("   1. ç»§ç»­æ”¶é›†æ›´å¤šçœŸå®xGæ•°æ®")
        print("   2. å½“å‰ç»“æœä»…ä½œä¸ºæŠ€æœ¯éªŒè¯")
        print("   3. å®é™…åº”ç”¨éœ€è¦æ›´å¤§çš„çœŸå®æ•°æ®é›†")

        print("\n" + "="*80)
        print("ğŸ” æ•°æ®æ´ç™–å®¡è®¡å¸ˆ - çº¯çœŸå®è®­ç»ƒå®Œæˆ")
        print("ğŸš« ç»å¯¹çœŸå®ï¼Œé›¶å¡«å……ï¼Œé›¶æ¨¡æ‹Ÿï¼")
        print("="*80)


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ” æ•°æ®æ´ç™–å®¡è®¡å¸ˆ - çº¯çœŸå®æ•°æ®è®­ç»ƒå¯åŠ¨")

    trainer = PureRealisticTrainer()
    await trainer.train()


if __name__ == "__main__":
    asyncio.run(main())
