"""
Football Prediction Evaluation Report Builder

è¶³çƒé¢„æµ‹è¯„ä¼°æŠ¥å‘Šæ„å»ºå™¨ï¼Œç”Ÿæˆè¯¦ç»†çš„HTMLå’ŒPDFè¯„ä¼°æŠ¥å‘Šã€‚
æ•´åˆæ‰€æœ‰è¯„ä¼°ç»“æœï¼Œæä¾›ä¸“ä¸šçº§çš„åˆ†ææŠ¥å‘Šã€‚

Author: Football Prediction Team
Version: 1.0.0
"""

import json
import os
import numpy as np
import pandas as pd
from typing import Optional, Union, Any
from pathlib import Path
from datetime import datetime
import logging
from dataclasses import asdict

try:
    from jinja2 import Environment, FileSystemLoader, Template

    HAS_JINJA2 = True
except ImportError:
    HAS_JINJA2 = False
    logging.warning("jinja2 not available - HTML reports will be disabled")

try:
    import weasyprint

    HAS_WEASYPRINT = True
except ImportError:
    HAS_WEASYPRINT = False
    logging.warning("weasyprint not available - PDF reports will be disabled")

logger = logging.getLogger(__name__)


class ReportBuilder:
    """è¯„ä¼°æŠ¥å‘Šæ„å»ºå™¨"""

    def __init__(self, output_dir: Union[str, Path] = None):
        """
        åˆå§‹åŒ–æŠ¥å‘Šæ„å»ºå™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.output_dir = Path(f"artifacts/eval/reports_{timestamp}")
        else:
            self.output_dir = Path(output_dir)

        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºæ¨¡æ¿
        self.template_env = self._create_template_environment()

    def _create_template_environment(self) -> Environment:
        """åˆ›å»ºJinja2æ¨¡æ¿ç¯å¢ƒ"""
        if not HAS_JINJA2:
            return None

        # ä½¿ç”¨å†…ç½®æ¨¡æ¿
        template_str = self._get_html_template()
        template = Template(template_str)

        # åˆ›å»ºå®‰å…¨çš„ç¯å¢ƒï¼ˆå¯ç”¨è‡ªåŠ¨è½¬ä¹‰ï¼‰
        env = Environment(autoescape=True)
        env.globals["template"] = template

        return env

    def _get_html_template(self) -> str:
        """è·å–HTMLæ¨¡æ¿å­—ç¬¦ä¸²"""
        return """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ title }}</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            text-align: center;
        }
        .header h1 {
            margin: 0;
            font-size: 2.5rem;
        }
        .header p {
            margin: 0.5rem 0 0 0;
            opacity: 0.9;
        }
        .section {
            background: white;
            margin-bottom: 2rem;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .section h2 {
            color: #667eea;
            border-bottom: 2px solid #667eea;
            padding-bottom: 0.5rem;
            margin-top: 0;
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1rem;
            margin-bottom: 2rem;
        }
        .metric-card {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        .metric-card h3 {
            margin: 0 0 0.5rem 0;
            color: #333;
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        .metric-value {
            font-size: 2rem;
            font-weight: bold;
            color: #667eea;
        }
        .metric-unit {
            font-size: 0.9rem;
            color: #666;
        }
        .good { color: #28a745; }
        .warning { color: #ffc107; }
        .danger { color: #dc3545; }
        .table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        .table th, .table td {
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid #dee2e6;
        }
        .table th {
            background-color: #f8f9fa;
            font-weight: 600;
        }
        .badge {
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 600;
        }
        .badge-success { background-color: #28a745; color: white; }
        .badge-warning { background-color: #ffc107; color: #212529; }
        .badge-danger { background-color: #dc3545; color: white; }
        .progress {
            width: 100%;
            height: 20px;
            background-color: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
        }
        .progress-bar {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        }
        .chart-placeholder {
            background: #f8f9fa;
            border: 2px dashed #dee2e6;
            border-radius: 8px;
            padding: 2rem;
            text-align: center;
            color: #6c757d;
            margin: 1rem 0;
        }
        .footer {
            text-align: center;
            padding: 2rem;
            color: #6c757d;
            border-top: 1px solid #dee2e6;
            margin-top: 3rem;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>âš½ {{ title }}</h1>
        <p>ç”Ÿæˆæ—¶é—´: {{ generation_time }} | æ¨¡å‹ç‰ˆæœ¬: {{ model_version }}</p>
    </div>

    {% if summary %}
    <div class="section">
        <h2>ğŸ“Š æ‰§è¡Œæ‘˜è¦</h2>
        <div class="metrics-grid">
            {% for metric in summary %}
            <div class="metric-card">
                <h3>{{ metric.name }}</h3>
                <div class="metric-value {{ metric.class }}">
                    {{ metric.value }}<span class="metric-unit">{{ metric.unit }}</span>
                </div>
                {% if metric.description %}
                <p><small>{{ metric.description }}</small></p>
                {% endif %}
            </div>
            {% endfor %}
        </div>
    </div>
    {% endif %}

    {% if metrics %}
    <div class="section">
        <h2>ğŸ¯ åˆ†ç±»æŒ‡æ ‡</h2>
        <table class="table">
            <thead>
                <tr>
                    <th>æŒ‡æ ‡</th>
                    <th>æ•°å€¼</th>
                    <th>çŠ¶æ€</th>
                </tr>
            </thead>
            <tbody>
                {% for key, value in metrics.items() %}
                <tr>
                    <td>{{ metric_names[key] or key }}</td>
                    <td>{{ "%.4f"|format(value) if value is number else value }}</td>
                    <td>
                        {% if key in ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted'] %}
                            {% if value >= 0.8 %}
                                <span class="badge badge-success">ä¼˜ç§€</span>
                            {% elif value >= 0.6 %}
                                <span class="badge badge-warning">è‰¯å¥½</span>
                            {% else %}
                                <span class="badge badge-danger">éœ€æ”¹è¿›</span>
                            {% endif %}
                        {% elif key in ['logloss', 'brier_score_avg'] %}
                            {% if value <= 0.3 %}
                                <span class="badge badge-success">ä¼˜ç§€</span>
                            {% elif value <= 0.5 %}
                                <span class="badge badge-warning">è‰¯å¥½</span>
                            {% else %}
                                <span class="badge badge-danger">éœ€æ”¹è¿›</span>
                            {% endif %}
                        {% else %}
                            <span class="badge badge-warning">æ ‡å‡†</span>
                        {% endif %}
                    </td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>
    {% endif %}

    {% if calibration_metrics %}
    <div class="section">
        <h2>ğŸ›ï¸ æ¦‚ç‡æ ¡å‡†æŒ‡æ ‡</h2>
        <table class="table">
            <thead>
                <tr>
                    <th>ç±»åˆ«</th>
                    <th>Brieråˆ†æ•°</th>
                    <th>ECE</th>
                    <th>MCE</th>
                    <th>çŠ¶æ€</th>
                </tr>
            </thead>
            <tbody>
                {% for class_name in ['H', 'D', 'A'] %}
                <tr>
                    <td>{{ class_names[class_name] }}</td>
                    <td>{{ "%.4f"|format(calibration_metrics['brier_score_' + class_name]) }}</td>
                    <td>{{ "%.4f"|format(calibration_metrics['ece_' + class_name]) }}</td>
                    <td>{{ "%.4f"|format(calibration_metrics['mce_' + class_name]) }}</td>
                    <td>
                        {% set brier = calibration_metrics['brier_score_' + class_name] %}
                        {% if brier <= 0.15 %}
                            <span class="badge badge-success">æ ¡å‡†è‰¯å¥½</span>
                        {% elif brier <= 0.25 %}
                            <span class="badge badge-warning">æ ¡å‡†ä¸€èˆ¬</span>
                        {% else %}
                            <span class="badge badge-danger">éœ€æ ¡å‡†</span>
                        {% endif %}
                    </td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>
    {% endif %}

    {% if backtest_result %}
    <div class="section">
        <h2>ğŸ’° å›æµ‹åˆ†æ</h2>
        <div class="metrics-grid">
            <div class="metric-card">
                <h3>æŠ•èµ„å›æŠ¥ç‡ (ROI)</h3>
                <div class="metric-value {{ 'good' if backtest_result.roi > 0 else 'danger' }}">
                    {{ "%.2f"|format(backtest_result.roi) }}<span class="metric-unit">%</span>
                </div>
            </div>
            <div class="metric-card">
                <h3>èƒœç‡</h3>
                <div class="metric-value">
                    {{ "%.2f"|format(backtest_result.win_rate) }}<span class="metric-unit">%</span>
                </div>
            </div>
            <div class="metric-card">
                <h3>æ€»æŠ•æ³¨æ¬¡æ•°</h3>
                <div class="metric-value">
                    {{ backtest_result.total_bets }}<span class="metric-unit">æ¬¡</span>
                </div>
            </div>
            <div class="metric-card">
                <h3>æœ€å¤§å›æ’¤</h3>
                <div class="metric-value {{ 'warning' if backtest_result.max_drawdown_percentage > 10 else 'good' }}">
                    {{ "%.2f"|format(backtest_result.max_drawdown_percentage) }}<span class="metric-unit">%</span>
                </div>
            </div>
        </div>

        <h3>å›æµ‹è¯¦æƒ…</h3>
        <table class="table">
            <thead>
                <tr>
                    <th>æŒ‡æ ‡</th>
                    <th>æ•°å€¼</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>åˆå§‹èµ„é‡‘</td><td>Â¥{{ "%.2f"|format(backtest_result.initial_bankroll) }}</td></tr>
                <tr><td>æœ€ç»ˆèµ„é‡‘</td><td>Â¥{{ "%.2f"|format(backtest_result.final_bankroll) }}</td></tr>
                <tr><td>å‡€æ”¶ç›Š</td><td>Â¥{{ "%.2f"|format(backtest_result.net_profit) }}</td></tr>
                <tr><td>æ€»æŠ•æ³¨é‡‘é¢</td><td>Â¥{{ "%.2f"|format(backtest_result.total_stake) }}</td></tr>
                <tr><td>è·èƒœæ¬¡æ•°</td><td>{{ backtest_result.winning_bets }}</td></tr>
                <tr><td>å¤±è´¥æ¬¡æ•°</td><td>{{ backtest_result.losing_bets }}</td></tr>
                <tr><td>å¹³å‡èµ”ç‡</td><td>{{ "%.2f"|format(backtest_result.avg_odds) }}</td></tr>
                <tr><td>å¤æ™®æ¯”ç‡</td><td>{{ "%.4f"|format(backtest_result.sharpe_ratio) }}</td></tr>
                <tr><td>ç›ˆåˆ©å› å­</td><td>{{ "%.4f"|format(backtest_result.profit_factor) }}</td></tr>
            </tbody>
        </table>
    </div>
    {% endif %}

    {% if charts %}
    <div class="section">
        <h2>ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨</h2>
        {% for chart_info in charts %}
        <div class="chart-placeholder">
            <h3>{{ chart_info.title }}</h3>
            <p>å›¾è¡¨æ–‡ä»¶: {{ chart_info.filename }}</p>
            <small>{{ chart_info.description }}</small>
        </div>
        {% endfor %}
    </div>
    {% endif %}

    {% if recommendations %}
    <div class="section">
        <h2>ğŸ’¡ æ”¹è¿›å»ºè®®</h2>
        {% for recommendation in recommendations %}
        <div class="metric-card">
            <h3>{{ recommendation.title }}</h3>
            <p>{{ recommendation.description }}</p>
            <strong>ä¼˜å…ˆçº§:</strong>
            <span class="badge badge-{{ recommendation.priority_class }}">
                {{ recommendation.priority }}
            </span>
        </div>
        {% endfor %}
    </div>
    {% endif %}

    <div class="footer">
        <p>æŠ¥å‘Šç”± Football Prediction Evaluation System è‡ªåŠ¨ç”Ÿæˆ</p>
        <p>ç”Ÿæˆæ—¶é—´: {{ generation_time }}</p>
    </div>
</body>
</html>
        """

    def _get_metric_status(self, metric_name: str, value: float) -> str:
        """è·å–æŒ‡æ ‡çŠ¶æ€"""
        if metric_name in [
            "accuracy",
            "f1_weighted",
            "precision_weighted",
            "recall_weighted",
        ]:
            if value >= 0.8:
                return "ä¼˜ç§€"
            elif value >= 0.6:
                return "è‰¯å¥½"
            else:
                return "éœ€æ”¹è¿›"
        elif metric_name in ["logloss", "brier_score_avg"]:
            if value <= 0.3:
                return "ä¼˜ç§€"
            elif value <= 0.5:
                return "è‰¯å¥½"
            else:
                return "éœ€æ”¹è¿›"
        else:
            return "æ ‡å‡†"

    def _get_metric_class(self, metric_name: str, value: float) -> str:
        """è·å–æŒ‡æ ‡CSSç±»"""
        if self._get_metric_status(metric_name, value) == "ä¼˜ç§€":
            return "good"
        elif self._get_metric_status(metric_name, value) == "éœ€æ”¹è¿›":
            return "danger"
        else:
            return "warning"

    def build_summary_metrics(
        self, metrics_result: dict, backtest_result=None
    ) -> list[dict]:
        """æ„å»ºæ‘˜è¦æŒ‡æ ‡"""
        summary = []

        # æ·»åŠ å…³é”®åˆ†ç±»æŒ‡æ ‡
        if "accuracy" in metrics_result:
            summary.append(
                {
                    "name": "å‡†ç¡®ç‡",
                    "value": f"{metrics_result['accuracy']:.4f}",
                    "unit": "",
                    "class": self._get_metric_class(
                        "accuracy", metrics_result["accuracy"]
                    ),
                    "description": "æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹",
                }
            )

        if "logloss" in metrics_result:
            summary.append(
                {
                    "name": "Log Loss",
                    "value": f"{metrics_result['logloss']:.4f}",
                    "unit": "",
                    "class": self._get_metric_class(
                        "logloss", metrics_result["logloss"]
                    ),
                    "description": "æ¦‚ç‡é¢„æµ‹è´¨é‡æŒ‡æ ‡ï¼Œè¶Šå°è¶Šå¥½",
                }
            )

        # æ·»åŠ æ ¡å‡†æŒ‡æ ‡
        if "brier_score_avg" in metrics_result:
            summary.append(
                {
                    "name": "å¹³å‡Brieråˆ†æ•°",
                    "value": f"{metrics_result['brier_score_avg']:.4f}",
                    "unit": "",
                    "class": self._get_metric_class(
                        "brier_score_avg", metrics_result["brier_score_avg"]
                    ),
                    "description": "æ¦‚ç‡æ ¡å‡†è´¨é‡ï¼Œè¶Šå°è¶Šå¥½",
                }
            )

        # æ·»åŠ å›æµ‹æŒ‡æ ‡
        if backtest_result:
            summary.append(
                {
                    "name": "ROI",
                    "value": f"{backtest_result.roi:.2f}",
                    "unit": "%",
                    "class": "good" if backtest_result.roi > 0 else "danger",
                    "description": "æŠ•èµ„å›æŠ¥ç‡",
                }
            )

            summary.append(
                {
                    "name": "èƒœç‡",
                    "value": f"{backtest_result.win_rate:.2f}",
                    "unit": "%",
                    "class": "good" if backtest_result.win_rate > 50 else "warning",
                    "description": "æŠ•æ³¨è·èƒœæ¯”ä¾‹",
                }
            )

        return summary

    def generate_recommendations(
        self, metrics_result: dict, backtest_result=None
    ) -> list[dict]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºåˆ†ç±»æŒ‡æ ‡çš„å»ºè®®
        accuracy = metrics_result.get("accuracy", 0)
        if accuracy < 0.6:
            recommendations.append(
                {
                    "title": "æé«˜æ¨¡å‹å‡†ç¡®ç‡",
                    "description": f"å½“å‰å‡†ç¡®ç‡{accuracy:.2%}è¾ƒä½ï¼Œå»ºè®®å¢åŠ ç‰¹å¾å·¥ç¨‹ã€è°ƒæ•´æ¨¡å‹å‚æ•°æˆ–å°è¯•å…¶ä»–ç®—æ³•ã€‚",
                    "priority": "é«˜",
                    "priority_class": "danger",
                }
            )

        # åŸºäºæ ¡å‡†æŒ‡æ ‡çš„å»ºè®®
        if "brier_score_avg" in metrics_result:
            brier_score = metrics_result["brier_score_avg"]
            if brier_score > 0.25:
                recommendations.append(
                    {
                        "title": "æ”¹è¿›æ¦‚ç‡æ ¡å‡†",
                        "description": f"å¹³å‡Brieråˆ†æ•°{brier_score:.4f}è¾ƒé«˜ï¼Œå»ºè®®åº”ç”¨æ¦‚ç‡æ ¡å‡†æ–¹æ³•å¦‚Isotonicå›å½’æˆ–Plattç¼©æ”¾ã€‚",
                        "priority": "ä¸­",
                        "priority_class": "warning",
                    }
                )

        # åŸºäºå›æµ‹æŒ‡æ ‡çš„å»ºè®®
        if backtest_result:
            if backtest_result.roi < 0:
                recommendations.append(
                    {
                        "title": "ä¼˜åŒ–æŠ•æ³¨ç­–ç•¥",
                        "description": f"å½“å‰ROIä¸º{backtest_result.roi:.2f}%ï¼Œå»ºè®®è°ƒæ•´æŠ•æ³¨é˜ˆå€¼ã€æ”¹è¿›ä»·å€¼è®¡ç®—æˆ–é‡‡ç”¨æ›´ä¿å®ˆçš„èµ„é‡‘ç®¡ç†ç­–ç•¥ã€‚",
                        "priority": "é«˜",
                        "priority_class": "danger",
                    }
                )

            if backtest_result.max_drawdown_percentage > 20:
                recommendations.append(
                    {
                        "title": "æ§åˆ¶é£é™©",
                        "description": f"æœ€å¤§å›æ’¤è¾¾åˆ°{backtest_result.max_drawdown_percentage:.2f}%ï¼Œå»ºè®®å®æ–½æ›´ä¸¥æ ¼çš„èµ„é‡‘ç®¡ç†ç­–ç•¥ã€‚",
                        "priority": "ä¸­",
                        "priority_class": "warning",
                    }
                )

        return recommendations

    def build_html_report(
        self,
        metrics_result: dict,
        calibration_result=None,
        backtest_result=None,
        charts: list[dict] = None,
        model_name: str = "Football Prediction Model",
        model_version: str = "1.0.0",
    ) -> str:
        """
        æ„å»ºHTMLè¯„ä¼°æŠ¥å‘Š

        Args:
            metrics_result: åˆ†ç±»æŒ‡æ ‡ç»“æœ
            calibration_result: æ ¡å‡†ç»“æœ
            backtest_result: å›æµ‹ç»“æœ
            charts: å›¾è¡¨ä¿¡æ¯åˆ—è¡¨
            model_name: æ¨¡å‹åç§°
            model_version: æ¨¡å‹ç‰ˆæœ¬

        Returns:
            HTMLæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if not HAS_JINJA2:
            logger.error("jinja2 not available - cannot build HTML report")
            return ""

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"evaluation_report_{timestamp}.html"

        # å‡†å¤‡æ¨¡æ¿æ•°æ®
        template_data = {
            "title": f"{model_name} - è¯„ä¼°æŠ¥å‘Š",
            "generation_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "model_version": model_version,
            "summary": self.build_summary_metrics(metrics_result, backtest_result),
            "metrics": metrics_result,
            "calibration_metrics": {
                k: v
                for k, v in metrics_result.items()
                if k.startswith("brier_score_")
                or k.startswith("ece_")
                or k.startswith("mce_")
            },
            "backtest_result": backtest_result,
            "charts": charts or [],
            "recommendations": self.generate_recommendations(
                metrics_result, backtest_result
            ),
            "metric_names": {
                "accuracy": "å‡†ç¡®ç‡",
                "precision_weighted": "åŠ æƒç²¾ç¡®ç‡",
                "recall_weighted": "åŠ æƒå¬å›ç‡",
                "f1_weighted": "åŠ æƒF1åˆ†æ•°",
                "precision_macro": "å®å¹³å‡ç²¾ç¡®ç‡",
                "recall_macro": "å®å¹³å‡å¬å›ç‡",
                "f1_macro": "å®å¹³å‡F1åˆ†æ•°",
                "logloss": "å¯¹æ•°æŸå¤±",
                "brier_score_avg": "å¹³å‡Brieråˆ†æ•°",
                "ece_avg": "å¹³å‡æœŸæœ›æ ¡å‡†è¯¯å·®",
                "mce_avg": "å¹³å‡æœ€å¤§æ ¡å‡†è¯¯å·®",
            },
            "class_names": {"H": "ä¸»èƒœ", "D": "å¹³å±€", "A": "å®¢èƒœ"},
        }

        # æ¸²æŸ“HTML
        template = self.template_env.globals["template"]
        html_content = template.render(**template_data)

        # ä¿å­˜HTMLæ–‡ä»¶
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(html_content)

        logger.info(f"HTML report generated: {output_file}")
        return str(output_file)

    def build_json_report(
        self,
        metrics_result: dict,
        calibration_result=None,
        backtest_result=None,
        charts: list[dict] = None,
        model_name: str = "Football Prediction Model",
        model_version: str = "1.0.0",
    ) -> str:
        """
        æ„å»ºJSONè¯„ä¼°æŠ¥å‘Š

        Args:
            metrics_result: åˆ†ç±»æŒ‡æ ‡ç»“æœ
            calibration_result: æ ¡å‡†ç»“æœ
            backtest_result: å›æµ‹ç»“æœ
            charts: å›¾è¡¨ä¿¡æ¯åˆ—è¡¨
            model_name: æ¨¡å‹åç§°
            model_version: æ¨¡å‹ç‰ˆæœ¬

        Returns:
            JSONæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"evaluation_report_{timestamp}.json"

        # å‡†å¤‡JSONæ•°æ®
        report_data = {
            "metadata": {
                "model_name": model_name,
                "model_version": model_version,
                "generation_time": datetime.now().isoformat(),
                "report_version": "1.0.0",
            },
            "summary": self.build_summary_metrics(metrics_result, backtest_result),
            "metrics": metrics_result,
            "recommendations": self.generate_recommendations(
                metrics_result, backtest_result
            ),
            "charts": charts or [],
        }

        # æ·»åŠ æ ¡å‡†ç»“æœ
        if calibration_result:
            report_data["calibration"] = (
                calibration_result.to_dict()
                if hasattr(calibration_result, "to_dict")
                else calibration_result
            )

        # æ·»åŠ å›æµ‹ç»“æœ
        if backtest_result:
            report_data["backtest"] = backtest_result.to_dict()

        # ä¿å­˜JSONæ–‡ä»¶
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"JSON report generated: {output_file}")
        return str(output_file)

    def build_pdf_report(self, html_file: str = None, **kwargs) -> str:
        """
        æ„å»ºPDFè¯„ä¼°æŠ¥å‘Š

        Args:
            html_file: HTMLæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œå…ˆç”ŸæˆHTMLï¼‰
            **kwargs: ä¼ é€’ç»™build_html_reportçš„å‚æ•°

        Returns:
            PDFæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if not HAS_WEASYPRINT:
            logger.error("weasyprint not available - cannot build PDF report")
            return ""

        if html_file is None:
            html_file = self.build_html_report(**kwargs)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_file = self.output_dir / f"evaluation_report_{timestamp}.pdf"

        try:
            # è½¬æ¢HTMLä¸ºPDF
            html_doc = weasyprint.HTML(filename=html_file)
            html_doc.write_pdf(pdf_file)

            logger.info(f"PDF report generated: {pdf_file}")
            return str(pdf_file)

        except Exception as e:
            logger.error(f"Error generating PDF report: {e}")
            return ""

    def build_comprehensive_report(
        self,
        metrics_result: dict,
        calibration_result=None,
        backtest_result=None,
        charts: list[dict] = None,
        model_name: str = "Football Prediction Model",
        model_version: str = "1.0.0",
        formats: list[str] = None,
    ) -> dict[str, str]:
        """
        æ„å»ºç»¼åˆè¯„ä¼°æŠ¥å‘Š

        Args:
            metrics_result: åˆ†ç±»æŒ‡æ ‡ç»“æœ
            calibration_result: æ ¡å‡†ç»“æœ
            backtest_result: å›æµ‹ç»“æœ
            charts: å›¾è¡¨ä¿¡æ¯åˆ—è¡¨
            model_name: æ¨¡å‹åç§°
            model_version: æ¨¡å‹ç‰ˆæœ¬
            formats: è¦ç”Ÿæˆçš„æŠ¥å‘Šæ ¼å¼åˆ—è¡¨

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„å­—å…¸
        """
        if formats is None:
            formats = ["html", "json"]
        report_files = {}

        # ç”ŸæˆHTMLæŠ¥å‘Š
        if "html" in formats:
            html_file = self.build_html_report(
                metrics_result=metrics_result,
                calibration_result=calibration_result,
                backtest_result=backtest_result,
                charts=charts,
                model_name=model_name,
                model_version=model_version,
            )
            if html_file:
                report_files["html"] = html_file

                # å¦‚æœéœ€è¦PDFä¸”HTMLå·²ç”Ÿæˆï¼Œå°è¯•è½¬æ¢
                if "pdf" in formats:
                    pdf_file = self.build_pdf_report(html_file=html_file)
                    if pdf_file:
                        report_files["pdf"] = pdf_file

        # ç”ŸæˆJSONæŠ¥å‘Š
        if "json" in formats:
            json_file = self.build_json_report(
                metrics_result=metrics_result,
                calibration_result=calibration_result,
                backtest_result=backtest_result,
                charts=charts,
                model_name=model_name,
                model_version=model_version,
            )
            if json_file:
                report_files["json"] = json_file

        logger.info(
            f"Comprehensive report generated with formats: {list(report_files.keys())}"
        )
        return report_files


# ä¾¿æ·å‡½æ•°
def generate_evaluation_report(
    metrics_result: dict,
    calibration_result=None,
    backtest_result=None,
    charts: list[dict] = None,
    output_dir: str = None,
    model_name: str = "Model",
    formats: list[str] = None,
) -> dict[str, str]:
    """
    ä¾¿æ·çš„è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå‡½æ•°

    Args:
        metrics_result: åˆ†ç±»æŒ‡æ ‡ç»“æœ
        calibration_result: æ ¡å‡†ç»“æœ
        backtest_result: å›æµ‹ç»“æœ
        charts: å›¾è¡¨ä¿¡æ¯åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        model_name: æ¨¡å‹åç§°
        formats: è¦ç”Ÿæˆçš„æŠ¥å‘Šæ ¼å¼åˆ—è¡¨

    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„å­—å…¸
    """
    if formats is None:
        formats = ["html", "json"]
    builder = ReportBuilder(output_dir=output_dir)
    return builder.build_comprehensive_report(
        metrics_result=metrics_result,
        calibration_result=calibration_result,
        backtest_result=backtest_result,
        charts=charts,
        model_name=model_name,
        formats=formats,
    )
