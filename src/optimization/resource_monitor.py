#!/usr/bin/env python3
"""
èµ„æºç›‘æ§å’Œä¼˜åŒ–ç³»ç»Ÿ
æä¾›å®æ—¶èµ„æºç›‘æ§ã€æ€§èƒ½åˆ†æã€è‡ªåŠ¨è°ƒä¼˜å’Œèµ„æºæ± ç®¡ç†åŠŸèƒ½
"""

import asyncio
import statistics
from collections import defaultdict, deque
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any

from src.core.logger import get_logger

logger = get_logger(__name__)


class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""

    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


class ResourceType(Enum):
    """èµ„æºç±»å‹"""

    CPU = "cpu"
    MEMORY = "memory"
    DISK_IO = "disk_io"
    NETWORK_IO = "network_io"
    DATABASE_CONNECTIONS = "database_connections"
    CACHE_USAGE = "cache_usage"
    API_REQUESTS = "api_requests"
    BACKGROUND_TASKS = "background_tasks"


@dataclass
class ResourceMetric:
    """èµ„æºæŒ‡æ ‡"""

    resource_type: ResourceType
    name: str
    current_value: float
    unit: str
    threshold_warning: float
    threshold_critical: float
    timestamp: datetime
    tags: dict[str, str] = None

    @property
    def is_warning(self) -> bool:
        """æ˜¯å¦è¾¾åˆ°è­¦å‘Šçº§åˆ«"""
        return self.current_value >= self.threshold_warning

    @property
    def is_critical(self) -> bool:
        """æ˜¯å¦è¾¾åˆ°ä¸¥é‡çº§åˆ«"""
        return self.current_value >= self.threshold_critical

    @property
    def alert_level(self) -> AlertLevel:
        """å‘Šè­¦çº§åˆ«"""
        if self.is_critical:
            return AlertLevel.CRITICAL
        elif self.is_warning:
            return AlertLevel.WARNING
        else:
            return AlertLevel.INFO


@dataclass
class ResourceAlert:
    """èµ„æºå‘Šè­¦"""

    resource_type: ResourceType
    metric_name: str
    alert_level: AlertLevel
    message: str
    current_value: float
    threshold: float
    timestamp: datetime
    resolved: bool = False
    resolved_at: datetime | None = None
    tags: dict[str, str] = None

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "resource_type": self.resource_type.value,
            "metric_name": self.metric_name,
            "alert_level": self.alert_level.value,
            "message": self.message,
            "current_value": self.current_value,
            "threshold": self.threshold,
            "timestamp": self.timestamp.isoformat(),
            "resolved": self.resolved,
            "resolved_at": self.resolved_at.isoformat() if self.resolved_at else None,
            "tags": self.tags or {},
        }


@dataclass
class OptimizationAction:
    """ä¼˜åŒ–åŠ¨ä½œ"""

    action_id: str
    resource_type: ResourceType
    action_type: str  # scale_up, scale_down, optimize_config, restart_service
    description: str
    parameters: dict[str, Any]
    expected_impact: str
    risk_level: str  # low, medium, high
    cooldown_period: int  # å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
    last_applied: datetime | None = None

    def can_apply(self) -> bool:
        """æ˜¯å¦å¯ä»¥åº”ç”¨æ­¤åŠ¨ä½œ"""
        if not self.last_applied:
            return True

        cooldown_elapsed = datetime.now() - self.last_applied
        return cooldown_elapsed.total_seconds() >= self.cooldown_period


class ResourceMonitor:
    """èµ„æºç›‘æ§å™¨"""

    def __init__(self, config: dict | None = None):
        self.config = config or self._get_default_config()
        self.metrics_history: dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.active_alerts: dict[str, ResourceAlert] = {}
        self.optimization_actions: dict[str, OptimizationAction] = {}
        self.monitoring_active = False
        self.auto_optimization_enabled = self.config.get("auto_optimization", False)

        # æ€§èƒ½åŸºçº¿
        self.performance_baseline = {}
        self.baseline_established = False

        # åˆå§‹åŒ–ä¼˜åŒ–åŠ¨ä½œ
        self._initialize_optimization_actions()

        logger.info("èµ„æºç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")

    def _get_default_config(self) -> dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "monitoring_interval": 60,  # ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
            "metrics_retention_hours": 24,  # æŒ‡æ ‡ä¿ç•™æ—¶é—´
            "alert_cooldown_minutes": 15,  # å‘Šè­¦å†·å´æ—¶é—´
            "auto_optimization": True,  # è‡ªåŠ¨ä¼˜åŒ–
            "optimization_threshold": 0.8,  # ä¼˜åŒ–é˜ˆå€¼
            "performance_window_minutes": 30,  # æ€§èƒ½è¯„ä¼°çª—å£
            "max_concurrent_optimizations": 3,  # æœ€å¤§å¹¶å‘ä¼˜åŒ–æ•°
            "risk_tolerance": "medium",  # é£é™©å®¹å¿åº¦
        }

    def _initialize_optimization_actions(self) -> None:
        """åˆå§‹åŒ–ä¼˜åŒ–åŠ¨ä½œ"""
        actions = [
            # CPUä¼˜åŒ–åŠ¨ä½œ
            OptimizationAction(
                action_id="cpu_scale_up",
                resource_type=ResourceType.CPU,
                action_type="scale_up",
                description="å¢åŠ CPUèµ„æº",
                parameters={"increment": 1, "max_vcpus": 16},
                expected_impact="CPUä½¿ç”¨ç‡ä¸‹é™15-25%",
                risk_level="low",
                cooldown_period=300,  # 5åˆ†é’Ÿ
            ),
            OptimizationAction(
                action_id="cpu_scale_down",
                resource_type=ResourceType.CPU,
                action_type="scale_down",
                description="å‡å°‘CPUèµ„æº",
                parameters={"decrement": 1, "min_vcpus": 2},
                expected_impact="èŠ‚çœæˆæœ¬10-20%",
                risk_level="medium",
                cooldown_period=600,  # 10åˆ†é’Ÿ
            ),
            # å†…å­˜ä¼˜åŒ–åŠ¨ä½œ
            OptimizationAction(
                action_id="memory_scale_up",
                resource_type=ResourceType.MEMORY,
                action_type="scale_up",
                description="å¢åŠ å†…å­˜èµ„æº",
                parameters={"increment_gb": 2, "max_memory_gb": 64},
                expected_impact="å†…å­˜å‹åŠ›ç¼“è§£ï¼Œæ€§èƒ½æå‡20-30%",
                risk_level="low",
                cooldown_period=300,
            ),
            OptimizationAction(
                action_id="memory_scale_down",
                resource_type=ResourceType.MEMORY,
                action_type="scale_down",
                description="å‡å°‘å†…å­˜èµ„æº",
                parameters={"decrement_gb": 2, "min_memory_gb": 4},
                expected_impact="èŠ‚çœæˆæœ¬15-25%",
                risk_level="medium",
                cooldown_period=600,
            ),
            # æ•°æ®åº“ä¼˜åŒ–åŠ¨ä½œ
            OptimizationAction(
                action_id="db_connections_optimize",
                resource_type=ResourceType.DATABASE_CONNECTIONS,
                action_type="optimize_config",
                description="ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± ",
                parameters={"max_connections": 100, "min_connections": 10},
                expected_impact="è¿æ¥æ•ˆç‡æå‡ï¼Œå“åº”æ—¶é—´å‡å°‘10-20%",
                risk_level="low",
                cooldown_period=180,
            ),
            # ç¼“å­˜ä¼˜åŒ–åŠ¨ä½œ
            OptimizationAction(
                action_id="cache_cleanup",
                resource_type=ResourceType.CACHE_USAGE,
                action_type="optimize_config",
                description="æ¸…ç†è¿‡æœŸç¼“å­˜æ•°æ®",
                parameters={"cleanup_expired": True, "compress_data": True},
                expected_impact="å†…å­˜ä½¿ç”¨å‡å°‘15-30%",
                risk_level="low",
                cooldown_period=900,  # 15åˆ†é’Ÿ
            ),
            OptimizationAction(
                action_id="cache_scale_up",
                resource_type=ResourceType.CACHE_USAGE,
                action_type="scale_up",
                description="æ‰©å±•ç¼“å­˜å®¹é‡",
                parameters={"increment_gb": 1, "max_memory_gb": 16},
                expected_impact="ç¼“å­˜å‘½ä¸­ç‡æå‡ï¼Œæ€§èƒ½æå‡10-20%",
                risk_level="medium",
                cooldown_period=600,
            ),
        ]

        for action in actions:
            self.optimization_actions[action.action_id] = action

    async def start_monitoring(self) -> None:
        """å¯åŠ¨ç›‘æ§"""
        if self.monitoring_active:
            logger.warning("èµ„æºç›‘æ§å·²åœ¨è¿è¡Œä¸­")
            return

        self.monitoring_active = True
        logger.info("å¯åŠ¨èµ„æºç›‘æ§...")

        monitoring_task = asyncio.create_task(self._monitoring_loop())

        try:
            await monitoring_task
        except asyncio.CancelledError:
            logger.info("èµ„æºç›‘æ§å·²åœæ­¢")
            self.monitoring_active = False
        except Exception as e:
            logger.error(f"èµ„æºç›‘æ§å¼‚å¸¸: {e}")
            self.monitoring_active = False
            raise

    async def stop_monitoring(self) -> None:
        """åœæ­¢ç›‘æ§"""
        self.monitoring_active = False
        logger.info("åœæ­¢èµ„æºç›‘æ§...")

    async def _monitoring_loop(self) -> None:
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring_active:
            try:
                # æ”¶é›†æ‰€æœ‰èµ„æºæŒ‡æ ‡
                metrics = await self._collect_all_metrics()

                # å¤„ç†æŒ‡æ ‡å¹¶æ£€æµ‹å‘Šè­¦
                await self._process_metrics(metrics)

                # æ‰§è¡Œè‡ªåŠ¨ä¼˜åŒ–
                if self.auto_optimization_enabled:
                    await self._auto_optimize()

                # æ¸…ç†è¿‡æœŸæ•°æ®
                await self._cleanup_expired_data()

                logger.debug("ç›‘æ§å‘¨æœŸå®Œæˆ")

            except Exception as e:
                logger.error(f"ç›‘æ§å‘¨æœŸå¼‚å¸¸: {e}")

            # ç­‰å¾…ä¸‹ä¸€ä¸ªç›‘æ§å‘¨æœŸ
            await asyncio.sleep(self.config["monitoring_interval"])

    async def _collect_all_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†æ‰€æœ‰èµ„æºæŒ‡æ ‡"""
        metrics = []

        # æ”¶é›†å„ç§èµ„æºæŒ‡æ ‡
        metric_collectors = [
            self._collect_cpu_metrics,
            self._collect_memory_metrics,
            self._collect_disk_io_metrics,
            self._collect_network_metrics,
            self._collect_database_metrics,
            self._collect_cache_metrics,
            self._collect_api_metrics,
            self._collect_background_task_metrics,
        ]

        for collector in metric_collectors:
            try:
                collector_metrics = await collector()
                metrics.extend(collector_metrics)
            except Exception as e:
                logger.warning(f"æŒ‡æ ‡æ”¶é›†å¤±è´¥ {collector.__name__}: {e}")

        return metrics

    async def _collect_cpu_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†CPUæŒ‡æ ‡"""
        try:
            import psutil

            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)

            # æ¯æ ¸å¿ƒCPUä½¿ç”¨ç‡
            cpu_per_core = psutil.cpu_percent(interval=1, percpu=True)

            # CPUè´Ÿè½½
            load_avg = psutil.getloadavg()

            metrics = [
                ResourceMetric(
                    resource_type=ResourceType.CPU,
                    name="cpu_usage_percent",
                    current_value=cpu_percent,
                    unit="percent",
                    threshold_warning=70.0,
                    threshold_critical=90.0,
                    timestamp=datetime.now(),
                    tags={"component": "system"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.CPU,
                    name="load_average_1m",
                    current_value=load_avg[0],
                    unit="count",
                    threshold_warning=psutil.cpu_count() * 0.7,
                    threshold_critical=psutil.cpu_count() * 0.9,
                    timestamp=datetime.now(),
                    tags={"component": "system"},
                ),
            ]

            # æ·»åŠ æ¯æ ¸å¿ƒCPUæŒ‡æ ‡
            for i, core_usage in enumerate(cpu_per_core):
                metrics.append(
                    ResourceMetric(
                        resource_type=ResourceType.CPU,
                        name=f"cpu_core_{i}_usage",
                        current_value=core_usage,
                        unit="percent",
                        threshold_warning=80.0,
                        threshold_critical=95.0,
                        timestamp=datetime.now(),
                        tags={"component": "system", "core": str(i)},
                    )
                )

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†CPUæŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_memory_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†å†…å­˜æŒ‡æ ‡"""
        try:
            import psutil

            virtual_memory = psutil.virtual_memory()
            swap_memory = psutil.swap_memory()

            metrics = [
                ResourceMetric(
                    resource_type=ResourceType.MEMORY,
                    name="memory_usage_percent",
                    current_value=virtual_memory.percent,
                    unit="percent",
                    threshold_warning=80.0,
                    threshold_critical=95.0,
                    timestamp=datetime.now(),
                    tags={"component": "system"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.MEMORY,
                    name="memory_available_gb",
                    current_value=virtual_memory.available / (1024**3),
                    unit="GB",
                    threshold_warning=2.0,
                    threshold_critical=1.0,
                    timestamp=datetime.now(),
                    tags={"component": "system"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.MEMORY,
                    name="swap_usage_percent",
                    current_value=swap_memory.percent,
                    unit="percent",
                    threshold_warning=50.0,
                    threshold_critical=80.0,
                    timestamp=datetime.now(),
                    tags={"component": "system"},
                ),
            ]

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†å†…å­˜æŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_disk_io_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†ç£ç›˜IOæŒ‡æ ‡"""
        try:
            import psutil

            disk_io = psutil.disk_io_counters()
            disk_usage = psutil.disk_usage("/")

            # è®¡ç®—IOé€Ÿç‡ï¼ˆéœ€è¦å†å²æ•°æ®ï¼‰
            metrics = []

            if disk_io:
                metrics.append(
                    ResourceMetric(
                        resource_type=ResourceType.DISK_IO,
                        name="disk_read_bytes_per_sec",
                        current_value=disk_io.read_bytes,  # å®é™…åº”è¯¥è®¡ç®—é€Ÿç‡
                        unit="bytes/sec",
                        threshold_warning=100 * 1024 * 1024,  # 100MB/s
                        threshold_critical=200 * 1024 * 1024,  # 200MB/s
                        timestamp=datetime.now(),
                        tags={"component": "storage"},
                    )
                )

                metrics.append(
                    ResourceMetric(
                        resource_type=ResourceType.DISK_IO,
                        name="disk_write_bytes_per_sec",
                        current_value=disk_io.write_bytes,  # å®é™…åº”è¯¥è®¡ç®—é€Ÿç‡
                        unit="bytes/sec",
                        threshold_warning=100 * 1024 * 1024,
                        threshold_critical=200 * 1024 * 1024,
                        timestamp=datetime.now(),
                        tags={"component": "storage"},
                    )
                )

            # ç£ç›˜ä½¿ç”¨ç‡
            usage_percent = (disk_usage.used / disk_usage.total) * 100
            metrics.append(
                ResourceMetric(
                    resource_type=ResourceType.DISK_IO,
                    name="disk_usage_percent",
                    current_value=usage_percent,
                    unit="percent",
                    threshold_warning=80.0,
                    threshold_critical=95.0,
                    timestamp=datetime.now(),
                    tags={"component": "storage"},
                )
            )

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†ç£ç›˜IOæŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_network_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†ç½‘ç»œæŒ‡æ ‡"""
        try:
            import psutil

            network_io = psutil.net_io_counters()

            metrics = []

            if network_io:
                # ç½‘ç»œIOé€Ÿç‡
                metrics.append(
                    ResourceMetric(
                        resource_type=ResourceType.NETWORK_IO,
                        name="network_bytes_sent_per_sec",
                        current_value=network_io.bytes_sent,  # å®é™…åº”è¯¥è®¡ç®—é€Ÿç‡
                        unit="bytes/sec",
                        threshold_warning=100 * 1024 * 1024,  # 100MB/s
                        threshold_critical=500 * 1024 * 1024,  # 500MB/s
                        timestamp=datetime.now(),
                        tags={"component": "network"},
                    )
                )

                metrics.append(
                    ResourceMetric(
                        resource_type=ResourceType.NETWORK_IO,
                        name="network_bytes_recv_per_sec",
                        current_value=network_io.bytes_recv,  # å®é™…åº”è¯¥è®¡ç®—é€Ÿç‡
                        unit="bytes/sec",
                        threshold_warning=100 * 1024 * 1024,
                        threshold_critical=500 * 1024 * 1024,
                        timestamp=datetime.now(),
                        tags={"component": "network"},
                    )
                )

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†ç½‘ç»œæŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_database_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†æ•°æ®åº“æŒ‡æ ‡"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æŒ‡æ ‡æ”¶é›†
        # å®é™…å®ç°éœ€è¦è¿æ¥åˆ°å…·ä½“æ•°æ®åº“

        try:
            # æ¨¡æ‹Ÿè¿æ¥æ•°
            active_connections = 25
            max_connections = 100

            # æ¨¡æ‹ŸæŸ¥è¯¢æ€§èƒ½
            avg_query_time = 85  # ms
            slow_queries = 5

            metrics = [
                ResourceMetric(
                    resource_type=ResourceType.DATABASE_CONNECTIONS,
                    name="active_connections",
                    current_value=active_connections,
                    unit="count",
                    threshold_warning=max_connections * 0.8,
                    threshold_critical=max_connections * 0.95,
                    timestamp=datetime.now(),
                    tags={"component": "database"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.DATABASE_CONNECTIONS,
                    name="connection_usage_percent",
                    current_value=(active_connections / max_connections) * 100,
                    unit="percent",
                    threshold_warning=80.0,
                    threshold_critical=95.0,
                    timestamp=datetime.now(),
                    tags={"component": "database"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.DATABASE_CONNECTIONS,
                    name="avg_query_time_ms",
                    current_value=avg_query_time,
                    unit="ms",
                    threshold_warning=200.0,
                    threshold_critical=1000.0,
                    timestamp=datetime.now(),
                    tags={"component": "database"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.DATABASE_CONNECTIONS,
                    name="slow_queries_count",
                    current_value=slow_queries,
                    unit="count",
                    threshold_warning=10.0,
                    threshold_critical=50.0,
                    timestamp=datetime.now(),
                    tags={"component": "database"},
                ),
            ]

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†æ•°æ®åº“æŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_cache_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†ç¼“å­˜æŒ‡æ ‡"""
        try:
            # æ¨¡æ‹ŸRedisæŒ‡æ ‡
            cache_memory = 1.5  # GB
            cache_memory_limit = 4.0  # GB
            hit_rate = 0.82  # 82%
            keys_count = 150000

            metrics = [
                ResourceMetric(
                    resource_type=ResourceType.CACHE_USAGE,
                    name="memory_usage_percent",
                    current_value=(cache_memory / cache_memory_limit) * 100,
                    unit="percent",
                    threshold_warning=80.0,
                    threshold_critical=95.0,
                    timestamp=datetime.now(),
                    tags={"component": "cache"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.CACHE_USAGE,
                    name="hit_rate_percent",
                    current_value=hit_rate * 100,
                    unit="percent",
                    threshold_warning=70.0,
                    threshold_critical=50.0,  # å‘½ä¸­ç‡ä½æ˜¯é—®é¢˜
                    timestamp=datetime.now(),
                    tags={"component": "cache"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.CACHE_USAGE,
                    name="keys_count",
                    current_value=keys_count,
                    unit="count",
                    threshold_warning=1000000,  # 100ä¸‡é”®
                    threshold_critical=2000000,  # 200ä¸‡é”®
                    timestamp=datetime.now(),
                    tags={"component": "cache"},
                ),
            ]

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†ç¼“å­˜æŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_api_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†APIæŒ‡æ ‡"""
        try:
            # æ¨¡æ‹ŸAPIæŒ‡æ ‡
            requests_per_minute = 850
            avg_response_time = 120  # ms
            error_rate = 0.02  # 2%

            metrics = [
                ResourceMetric(
                    resource_type=ResourceType.API_REQUESTS,
                    name="requests_per_minute",
                    current_value=requests_per_minute,
                    unit="req/min",
                    threshold_warning=1000.0,
                    threshold_critical=2000.0,
                    timestamp=datetime.now(),
                    tags={"component": "api"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.API_REQUESTS,
                    name="avg_response_time_ms",
                    current_value=avg_response_time,
                    unit="ms",
                    threshold_warning=500.0,
                    threshold_critical=2000.0,
                    timestamp=datetime.now(),
                    tags={"component": "api"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.API_REQUESTS,
                    name="error_rate_percent",
                    current_value=error_rate * 100,
                    unit="percent",
                    threshold_warning=5.0,
                    threshold_critical=15.0,
                    timestamp=datetime.now(),
                    tags={"component": "api"},
                ),
            ]

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†APIæŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _collect_background_task_metrics(self) -> list[ResourceMetric]:
        """æ”¶é›†åå°ä»»åŠ¡æŒ‡æ ‡"""
        try:
            # æ¨¡æ‹Ÿåå°ä»»åŠ¡æŒ‡æ ‡
            active_tasks = 15
            pending_tasks = 8
            failed_tasks_24h = 3

            metrics = [
                ResourceMetric(
                    resource_type=ResourceType.BACKGROUND_TASKS,
                    name="active_tasks_count",
                    current_value=active_tasks,
                    unit="count",
                    threshold_warning=50.0,
                    threshold_critical=100.0,
                    timestamp=datetime.now(),
                    tags={"component": "tasks"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.BACKGROUND_TASKS,
                    name="pending_tasks_count",
                    current_value=pending_tasks,
                    unit="count",
                    threshold_warning=20.0,
                    threshold_critical=50.0,
                    timestamp=datetime.now(),
                    tags={"component": "tasks"},
                ),
                ResourceMetric(
                    resource_type=ResourceType.BACKGROUND_TASKS,
                    name="failed_tasks_24h",
                    current_value=failed_tasks_24h,
                    unit="count",
                    threshold_warning=10.0,
                    threshold_critical=50.0,
                    timestamp=datetime.now(),
                    tags={"component": "tasks"},
                ),
            ]

            return metrics

        except Exception as e:
            logger.warning(f"æ”¶é›†åå°ä»»åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
            return []

    async def _process_metrics(self, metrics: list[ResourceMetric]) -> None:
        """å¤„ç†æŒ‡æ ‡"""
        current_time = datetime.now()

        for metric in metrics:
            # å­˜å‚¨æŒ‡æ ‡å†å²
            key = f"{metric.resource_type.value}_{metric.name}"
            self.metrics_history[key].append(metric)

            # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
            await self._check_alerts(metric)

        # æ›´æ–°æ€§èƒ½åŸºçº¿
        if not self.baseline_established:
            await self._establish_baseline()

    async def _check_alerts(self, metric: ResourceMetric) -> None:
        """æ£€æŸ¥å‘Šè­¦"""
        if not (metric.is_warning or metric.is_critical):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è§£å†³ç°æœ‰å‘Šè­¦
            await self._resolve_alerts_if_needed(metric)
            return

        # åˆ›å»ºå‘Šè­¦key
        alert_key = f"{metric.resource_type.value}_{metric.name}"

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ´»è·ƒå‘Šè­¦
        if alert_key in self.active_alerts:
            existing_alert = self.active_alerts[alert_key]

            # æ›´æ–°å‘Šè­¦çº§åˆ«ï¼ˆå¦‚æœå‡çº§ï¼‰
            if metric.alert_level.value > existing_alert.alert_level.value:
                existing_alert.alert_level = metric.alert_level
                existing_alert.current_value = metric.current_value
                existing_alert.timestamp = metric.timestamp
                logger.info(f"å‘Šè­¦å‡çº§: {alert_key} -> {metric.alert_level.value}")

        else:
            # åˆ›å»ºæ–°å‘Šè­¦
            alert = ResourceAlert(
                resource_type=metric.resource_type,
                metric_name=metric.name,
                alert_level=metric.alert_level,
                message=f"{metric.resource_type.value} {metric.name} è¾¾åˆ° {metric.alert_level.value} çº§åˆ«: {metric.current_value} {metric.unit}",
                current_value=metric.current_value,
                threshold=(
                    metric.threshold_critical
                    if metric.is_critical
                    else metric.threshold_warning
                ),
                timestamp=metric.timestamp,
                tags=metric.tags,
            )

            self.active_alerts[alert_key] = alert

            # å‘é€å‘Šè­¦é€šçŸ¥
            await self._send_alert(alert)

            logger.warning(f"æ–°å‘Šè­¦: {alert.message}")

    async def _resolve_alerts_if_needed(self, metric: ResourceMetric) -> None:
        """å¦‚æœæ¡ä»¶å…è®¸ï¼Œè§£å†³å‘Šè­¦"""
        alert_key = f"{metric.resource_type.value}_{metric.name}"

        if alert_key in self.active_alerts:
            # æ£€æŸ¥æ˜¯å¦å·²æ¢å¤åˆ°æ­£å¸¸æ°´å¹³
            if not metric.is_warning:
                alert = self.active_alerts[alert_key]
                alert.resolved = True
                alert.resolved_at = datetime.now()

                logger.info(f"å‘Šè­¦å·²è§£å†³: {alert.message}")

                # å‘é€è§£å†³é€šçŸ¥
                await self._send_alert_resolved(alert)

                # ä»æ´»è·ƒå‘Šè­¦ä¸­ç§»é™¤
                del self.active_alerts[alert_key]

    async def _send_alert(self, alert: ResourceAlert) -> None:
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„å‘Šè­¦ç³»ç»Ÿ
        # å¦‚é‚®ä»¶ã€Slackã€ä¼ä¸šå¾®ä¿¡ã€é’‰é’‰ç­‰

        message = f"ğŸš¨ [{alert.alert_level.value.upper()}] {alert.message}"
        message += f"\nå½“å‰å€¼: {alert.current_value}"
        message += f"\né˜ˆå€¼: {alert.threshold}"
        message += f"\næ—¶é—´: {alert.timestamp.strftime('%Y-%m-%d %H:%M:%S')}"

        if alert.tags:
            message += f"\næ ‡ç­¾: {', '.join(f'{k}={v}' for k, v in alert.tags.items())}"

        logger.warning(f"å‘Šè­¦é€šçŸ¥: {message}")

        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨é€šçŸ¥æœåŠ¡
        # await self.notification_service.send_alert(message, alert.alert_level)

    async def _send_alert_resolved(self, alert: ResourceAlert) -> None:
        """å‘é€å‘Šè­¦è§£å†³é€šçŸ¥"""
        message = f"âœ… å‘Šè­¦å·²è§£å†³: {alert.message}"
        message += f"\nè§£å†³æ—¶é—´: {alert.resolved_at.strftime('%Y-%m-%d %H:%M:%S')}"

        logger.info(f"å‘Šè­¦è§£å†³é€šçŸ¥: {message}")

        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨é€šçŸ¥æœåŠ¡
        # await self.notification_service.send_alert_resolved(message)

    async def _establish_baseline(self) -> None:
        """å»ºç«‹æ€§èƒ½åŸºçº¿"""
        if len(self.metrics_history) < 10:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®ç‚¹
            return

        try:
            baseline_data = {}

            for key, metrics in self.metrics_history.items():
                if len(metrics) >= 5:
                    values = [m.current_value for m in metrics]
                    baseline_data[key] = {
                        "mean": statistics.mean(values),
                        "median": statistics.median(values),
                        "stddev": statistics.stdev(values) if len(values) > 1 else 0,
                        "min": min(values),
                        "max": max(values),
                    }

            if baseline_data:
                self.performance_baseline = baseline_data
                self.baseline_established = True
                logger.info("æ€§èƒ½åŸºçº¿å»ºç«‹å®Œæˆ")

        except Exception as e:
            logger.warning(f"å»ºç«‹æ€§èƒ½åŸºçº¿å¤±è´¥: {e}")

    async def _auto_optimize(self) -> None:
        """è‡ªåŠ¨ä¼˜åŒ–"""
        if not self.active_alerts:
            return

        # æ”¶é›†éœ€è¦ä¼˜åŒ–çš„èµ„æºç±»å‹
        resource_types_with_alerts = set()
        for alert in self.active_alerts.values():
            if not alert.resolved and alert.alert_level in [
                AlertLevel.WARNING,
                AlertLevel.CRITICAL,
            ]:
                resource_types_with_alerts.add(alert.resource_type)

        # ä¸ºæ¯ç§èµ„æºç±»å‹å¯»æ‰¾ä¼˜åŒ–åŠ¨ä½œ
        optimization_candidates = []

        for resource_type in resource_types_with_alerts:
            candidates = await self._find_optimization_candidates(resource_type)
            optimization_candidates.extend(candidates)

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        optimization_candidates.sort(
            key=lambda x: self._get_optimization_priority(x), reverse=True
        )

        # æ‰§è¡Œä¼˜åŒ–ï¼ˆé™åˆ¶å¹¶å‘æ•°é‡ï¼‰
        max_concurrent = self.config["max_concurrent_optimizations"]
        executed_count = 0

        for action in optimization_candidates:
            if executed_count >= max_concurrent:
                break

            if action.can_apply():
                success = await self._execute_optimization_action(action)
                if success:
                    executed_count += 1
                    action.last_applied = datetime.now()

    async def _find_optimization_candidates(
        self, resource_type: ResourceType
    ) -> list[OptimizationAction]:
        """ä¸ºèµ„æºç±»å‹å¯»æ‰¾ä¼˜åŒ–å€™é€‰"""
        candidates = []

        # è·å–è¯¥èµ„æºç±»å‹çš„æ´»è·ƒå‘Šè­¦
        alerts = [
            alert
            for alert in self.active_alerts.values()
            if alert.resource_type == resource_type and not alert.resolved
        ]

        if not alerts:
            return candidates

        # æ ¹æ®å‘Šè­¦ç±»å‹å’Œä¸¥é‡ç¨‹åº¦é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–åŠ¨ä½œ
        for action in self.optimization_actions.values():
            if action.resource_type != resource_type:
                continue

            # æ ¹æ®å‘Šè­¦çº§åˆ«é€‰æ‹©åŠ¨ä½œ
            if any(alert.alert_level == AlertLevel.CRITICAL for alert in alerts):
                # ä¸¥é‡å‘Šè­¦ï¼Œé€‰æ‹©æ‰©å®¹åŠ¨ä½œ
                if (
                    "scale_up" in action.action_id
                    or "optimize_config" in action.action_id
                ):
                    candidates.append(action)
            elif any(alert.alert_level == AlertLevel.WARNING for alert in alerts):
                # è­¦å‘Šå‘Šè­¦ï¼Œå¯ä»¥é€‰æ‹©ç¼©å®¹æˆ–ä¼˜åŒ–é…ç½®
                if (
                    self.config["risk_tolerance"] == "aggressive"
                    and "scale_down" in action.action_id
                ):
                    candidates.append(action)
                elif "optimize_config" in action.action_id:
                    candidates.append(action)

        return candidates

    def _get_optimization_priority(self, action: OptimizationAction) -> float:
        """è·å–ä¼˜åŒ–ä¼˜å…ˆçº§åˆ†æ•°"""
        base_score = 0

        # æ ¹æ®é£é™©å®¹å¿åº¦è°ƒæ•´
        if self.config["risk_tolerance"] == "aggressive":
            if action.risk_level == "high":
                base_score += 3
            elif action.risk_level == "medium":
                base_score += 2
            else:
                base_score += 1
        elif self.config["risk_tolerance"] == "conservative":
            if action.risk_level == "low":
                base_score += 3
            elif action.risk_level == "medium":
                base_score += 1
        else:  # medium
            if action.risk_level == "medium":
                base_score += 3
            elif action.risk_level == "low":
                base_score += 2
            else:
                base_score += 1

        # æ ¹æ®åŠ¨ä½œç±»å‹è°ƒæ•´
        if "optimize_config" in action.action_type:
            base_score += 2  # é…ç½®ä¼˜åŒ–ä¼˜å…ˆçº§é«˜
        elif "scale_up" in action.action_type:
            base_score += 1  # æ‰©å®¹æ¬¡ä¹‹
        elif "scale_down" in action.action_type:
            base_score += 0  # ç¼©å®¹ä¼˜å…ˆçº§æœ€ä½

        return base_score

    async def _execute_optimization_action(self, action: OptimizationAction) -> bool:
        """æ‰§è¡Œä¼˜åŒ–åŠ¨ä½œ"""
        logger.info(f"æ‰§è¡Œä¼˜åŒ–åŠ¨ä½œ: {action.description}")

        try:
            if action.action_type == "scale_up":
                return await self._scale_up_resource(action)
            elif action.action_type == "scale_down":
                return await self._scale_down_resource(action)
            elif action.action_type == "optimize_config":
                return await self._optimize_resource_config(action)
            elif action.action_type == "restart_service":
                return await self._restart_service(action)
            else:
                logger.warning(f"ä¸æ”¯æŒçš„ä¼˜åŒ–åŠ¨ä½œç±»å‹: {action.action_type}")
                return False

        except Exception as e:
            logger.error(f"æ‰§è¡Œä¼˜åŒ–åŠ¨ä½œå¤±è´¥: {action.description}, é”™è¯¯: {e}")
            return False

    async def _scale_up_resource(self, action: OptimizationAction) -> bool:
        """æ‰©å®¹èµ„æº"""
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨äº‘æœåŠ¡APIè¿›è¡Œæ‰©å®¹
        logger.info(f"æ‰©å®¹èµ„æº: {action.resource_type.value}")
        await asyncio.sleep(1)  # æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
        return True

    async def _scale_down_resource(self, action: OptimizationAction) -> bool:
        """ç¼©å®¹èµ„æº"""
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨äº‘æœåŠ¡APIè¿›è¡Œç¼©å®¹
        logger.info(f"ç¼©å®¹èµ„æº: {action.resource_type.value}")
        await asyncio.sleep(1)  # æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
        return True

    async def _optimize_resource_config(self, action: OptimizationAction) -> bool:
        """ä¼˜åŒ–èµ„æºé…ç½®"""
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šä¿®æ”¹é…ç½®æ–‡ä»¶æˆ–è°ƒç”¨é…ç½®API
        logger.info(f"ä¼˜åŒ–èµ„æºé…ç½®: {action.resource_type.value}")
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿé…ç½®æ›´æ–°
        return True

    async def _restart_service(self, action: OptimizationAction) -> bool:
        """é‡å¯æœåŠ¡"""
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šé‡å¯ç›¸å…³æœåŠ¡
        logger.info(f"é‡å¯æœåŠ¡: {action.resource_type.value}")
        await asyncio.sleep(2)  # æ¨¡æ‹ŸæœåŠ¡é‡å¯æ—¶é—´
        return True

    async def _cleanup_expired_data(self) -> None:
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        cutoff_time = datetime.now() - timedelta(
            hours=self.config["metrics_retention_hours"]
        )

        # æ¸…ç†è¿‡æœŸæŒ‡æ ‡
        for key in list(self.metrics_history.keys()):
            metrics = self.metrics_history[key]
            while metrics and metrics[0].timestamp < cutoff_time:
                metrics.popleft()

        # æ¸…ç†å·²è§£å†³çš„å‘Šè­¦ï¼ˆä¿ç•™24å°æ—¶ï¼‰
        alert_cutoff = datetime.now() - timedelta(hours=24)
        resolved_alerts = [
            alert
            for alert in self.active_alerts.values()
            if alert.resolved and alert.resolved_at and alert.resolved_at < alert_cutoff
        ]

        for alert in resolved_alerts:
            alert_key = f"{alert.resource_type.value}_{alert.metric_name}"
            if (
                alert_key in self.active_alerts
                and self.active_alerts[alert_key].resolved
            ):
                del self.active_alerts[alert_key]

    def get_monitoring_status(self) -> dict:
        """è·å–ç›‘æ§çŠ¶æ€"""
        return {
            "monitoring_active": self.monitoring_active,
            "auto_optimization_enabled": self.auto_optimization_enabled,
            "total_metrics_collected": sum(
                len(metrics) for metrics in self.metrics_history.values()
            ),
            "active_alerts_count": len(self.active_alerts),
            "baseline_established": self.baseline_established,
            "optimization_actions_count": len(self.optimization_actions),
            "last_update": datetime.now().isoformat(),
        }

    def get_resource_summary(self) -> dict:
        """è·å–èµ„æºçŠ¶æ€æ‘˜è¦"""
        summary = {
            "resource_types": {},
            "active_alerts": [],
            "performance_baseline": self.baseline_established,
        }

        # æŒ‰èµ„æºç±»å‹æ±‡æ€»æŒ‡æ ‡
        for resource_type in ResourceType:
            type_metrics = []
            for key, metrics in self.metrics_history.items():
                if key.startswith(resource_type.value):
                    if metrics:  # å¦‚æœæœ‰æ•°æ®
                        latest_metric = metrics[-1]
                        type_metrics.append(latest_metric)

            if type_metrics:
                summary["resource_types"][resource_type.value] = {
                    "metrics_count": len(type_metrics),
                    "last_update": max(m.timestamp for m in type_metrics).isoformat(),
                    "warning_count": sum(1 for m in type_metrics if m.is_warning),
                    "critical_count": sum(1 for m in type_metrics if m.is_critical),
                    "metrics": [asdict(m) for m in type_metrics[-5:]],  # æœ€è¿‘5ä¸ªæŒ‡æ ‡
                }

        # æ´»è·ƒå‘Šè­¦
        summary["active_alerts"] = [
            alert.to_dict() for alert in self.active_alerts.values()
        ]

        return summary

    def get_optimization_recommendations(self) -> list[dict]:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        recommendations = []

        for alert in self.active_alerts.values():
            if alert.resolved:
                continue

            # æ ¹æ®å‘Šè­¦ç±»å‹ç”Ÿæˆå»ºè®®
            if alert.resource_type == ResourceType.CPU:
                if alert.alert_level == AlertLevel.CRITICAL:
                    recommendations.append(
                        {
                            "resource_type": alert.resource_type.value,
                            "priority": "high",
                            "action": "increase_cpu_resources",
                            "description": "CPUä½¿ç”¨ç‡ä¸¥é‡è¿‡é«˜ï¼Œå»ºè®®ç«‹å³å¢åŠ CPUèµ„æºæˆ–ä¼˜åŒ–ä»£ç æ€§èƒ½",
                            "estimated_impact": "æ€§èƒ½æå‡30-50%",
                        }
                    )
                elif alert.alert_level == AlertLevel.WARNING:
                    recommendations.append(
                        {
                            "resource_type": alert.resource_type.value,
                            "priority": "medium",
                            "action": "optimize_cpu_usage",
                            "description": "CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥CPUå¯†é›†å‹ä»»åŠ¡å¹¶è¿›è¡Œä¼˜åŒ–",
                            "estimated_impact": "æ€§èƒ½æå‡15-25%",
                        }
                    )

            elif alert.resource_type == ResourceType.MEMORY:
                if alert.alert_level == AlertLevel.CRITICAL:
                    recommendations.append(
                        {
                            "resource_type": alert.resource_type.value,
                            "priority": "high",
                            "action": "increase_memory",
                            "description": "å†…å­˜ä½¿ç”¨ç‡ä¸¥é‡è¿‡é«˜ï¼Œå»ºè®®å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨",
                            "estimated_impact": "ç¨³å®šæ€§æ˜¾è‘—æå‡",
                        }
                    )
                elif alert.alert_level == AlertLevel.WARNING:
                    recommendations.append(
                        {
                            "resource_type": alert.resource_type.value,
                            "priority": "medium",
                            "action": "optimize_memory_usage",
                            "description": "å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼å¹¶ä¼˜åŒ–æ•°æ®ç»“æ„",
                            "estimated_impact": "ç¨³å®šæ€§æå‡20-30%",
                        }
                    )

            elif alert.resource_type == ResourceType.DATABASE_CONNECTIONS:
                recommendations.append(
                    {
                        "resource_type": alert.resource_type.value,
                        "priority": "high",
                        "action": "optimize_database_connections",
                        "description": "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–è¿æ¥æ± é…ç½®æˆ–å¢åŠ æ•°æ®åº“å®ä¾‹",
                        "estimated_impact": "å“åº”æ—¶é—´å‡å°‘20-40%",
                    }
                )

            elif alert.resource_type == ResourceType.CACHE_USAGE:
                if "hit_rate" in alert.metric_name:
                    recommendations.append(
                        {
                            "resource_type": alert.resource_type.value,
                            "priority": "medium",
                            "action": "optimize_cache_strategy",
                            "description": "ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½ï¼Œå»ºè®®è°ƒæ•´ç¼“å­˜ç­–ç•¥æˆ–å¢åŠ ç¼“å­˜å®¹é‡",
                            "estimated_impact": "æ€§èƒ½æå‡15-30%",
                        }
                    )

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"high": 3, "medium": 2, "low": 1}
        recommendations.sort(
            key=lambda x: priority_order.get(x["priority"], 0), reverse=True
        )

        return recommendations


async def demo_resource_monitor():
    """æ¼”ç¤ºèµ„æºç›‘æ§åŠŸèƒ½"""
    print("ğŸ” æ¼”ç¤ºä¼ä¸šçº§èµ„æºç›‘æ§ç³»ç»Ÿ")
    print("=" * 50)

    # åˆå§‹åŒ–èµ„æºç›‘æ§å™¨
    monitor = ResourceMonitor()

    print("\nğŸ“Š æ”¶é›†èµ„æºæŒ‡æ ‡...")
    metrics = await monitor._collect_all_metrics()

    print(f"æ”¶é›†åˆ° {len(metrics)} ä¸ªæŒ‡æ ‡:")
    for metric in metrics[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
        status = "ğŸš¨" if metric.is_critical else "âš ï¸" if metric.is_warning else "âœ…"
        print(
            f"  {status} {metric.resource_type.value}.{metric.name}: "
            f"{metric.current_value:.2f} {metric.unit}"
        )

    print("\nğŸš¨ æ£€æŸ¥å‘Šè­¦...")
    for metric in metrics:
        await monitor._check_alerts(metric)

    active_alerts = len(monitor.active_alerts)
    print(f"å½“å‰æ´»è·ƒå‘Šè­¦: {active_alerts}")

    if monitor.active_alerts:
        print("\nå‘Šè­¦è¯¦æƒ…:")
        for alert_key, alert in monitor.active_alerts.items():
            print(f"  [{alert.alert_level.value.upper()}] {alert.message}")

    print("\nğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
    recommendations = monitor.get_optimization_recommendations()

    if recommendations:
        print(f"æ‰¾åˆ° {len(recommendations)} æ¡ä¼˜åŒ–å»ºè®®:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. [{rec['priority'].upper()}] {rec['description']}")
            print(f"     å»ºè®®: {rec['action']}")
            print(f"     é¢„æœŸå½±å“: {rec['estimated_impact']}")
    else:
        print("æš‚æ— ä¼˜åŒ–å»ºè®®")

    print("\nğŸ“ˆ ç›‘æ§çŠ¶æ€:")
    status = monitor.get_monitoring_status()
    print(f"  ç›‘æ§çŠ¶æ€: {'è¿è¡Œä¸­' if status['monitoring_active'] else 'å·²åœæ­¢'}")
    print(f"  è‡ªåŠ¨ä¼˜åŒ–: {'å¯ç”¨' if status['auto_optimization_enabled'] else 'ç¦ç”¨'}")
    print(f"  æ€»æŒ‡æ ‡æ•°: {status['total_metrics_collected']}")
    print(f"  æ´»è·ƒå‘Šè­¦: {status['active_alerts_count']}")
    print(f"  åŸºçº¿å»ºç«‹: {'æ˜¯' if status['baseline_established'] else 'å¦'}")

    print("\nğŸ”§ æ¼”ç¤ºè‡ªåŠ¨ä¼˜åŒ–...")
    if monitor.auto_optimization_enabled and monitor.active_alerts:
        await monitor._auto_optimize()
        print("è‡ªåŠ¨ä¼˜åŒ–å®Œæˆ")
    else:
        print("è·³è¿‡è‡ªåŠ¨ä¼˜åŒ–ï¼ˆæ— å‘Šè­¦æˆ–æœªå¯ç”¨ï¼‰")

    print("\nâœ… èµ„æºç›‘æ§æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    asyncio.run(demo_resource_monitor())
