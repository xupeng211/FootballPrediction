"""
ç”Ÿäº§æ¨¡å‹åŠ è½½å™¨
å•ä¾‹æ¨¡å¼åŠ è½½Phase 2è®­ç»ƒçš„XGBoostæ¨¡å‹å’Œç›¸å…³å·¥ä»¶

åŠŸèƒ½:
1. å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹å·¥ä»¶ (ä»…ä¸€æ¬¡)
2. æä¾›é¢„æµ‹æ¥å£
3. ç¡®ä¿çº¿ç¨‹å®‰å…¨å’Œå†…å­˜æ•ˆç‡

ä½œè€…: Backend Engineer
åˆ›å»ºæ—¶é—´: 2025-12-10
ç‰ˆæœ¬: 1.0.0 - Phase 3 Inference
"""

import json
import pickle
import logging
from pathlib import Path
from typing import Dict, Any
import numpy as np
import xgboost as xgb

from ..features.enhanced_feature_extractor import (
    EnhancedFeatureExtractor,
    FeatureConfig,
)

logger = logging.getLogger(__name__)


class ModelLoader:
    """å•ä¾‹æ¨¡å‹åŠ è½½å™¨"""

    _instance = None
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._initialized:
            self.model = None
            self.label_encoder = None
            self.feature_columns = None
            self.feature_extractor = None
            self.model_metadata = None
            self._initialized = True
            logger.info("ğŸ”§ ModelLoaderå®ä¾‹å·²åˆ›å»º")

    def load_model_artifacts(self) -> bool:
        """åŠ è½½æ¨¡å‹å·¥ä»¶"""
        try:
            logger.info("ğŸ“¦ å¼€å§‹åŠ è½½æ¨¡å‹å·¥ä»¶...")

            models_dir = Path("models")
            model_name = "football_xgboost_baseline"

            # 1. åŠ è½½XGBoostæ¨¡å‹ (JSONæ ¼å¼)
            model_json_path = models_dir / f"{model_name}.json"
            if not model_json_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_json_path}")

            self.model = xgb.XGBClassifier()
            self.model.load_model(str(model_json_path))
            logger.info(f"   âœ… XGBoostæ¨¡å‹å·²åŠ è½½: {model_json_path}")

            # 2. åŠ è½½LabelEncoder
            encoder_path = models_dir / f"{model_name}_label_encoder.pkl"
            if not encoder_path.exists():
                raise FileNotFoundError(f"ç¼–ç å™¨æ–‡ä»¶ä¸å­˜åœ¨: {encoder_path}")

            with open(encoder_path, "rb") as f:
                self.label_encoder = pickle.load(f)
            logger.info(f"   âœ… LabelEncoderå·²åŠ è½½: {encoder_path}")

            # 3. åŠ è½½ç‰¹å¾åˆ—è¡¨
            features_path = models_dir / f"{model_name}_features.json"
            if not features_path.exists():
                raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {features_path}")

            with open(features_path, "r") as f:
                features_data = json.load(f)
                self.feature_columns = features_data["feature_columns"]
            logger.info(f"   âœ… ç‰¹å¾åˆ—è¡¨å·²åŠ è½½: {len(self.feature_columns)}ä¸ªç‰¹å¾")

            # 4. åŠ è½½æ¨¡å‹å…ƒæ•°æ®
            metadata_path = models_dir / f"{model_name}_metadata.json"
            if metadata_path.exists():
                with open(metadata_path, "r") as f:
                    self.model_metadata = json.load(f)
                logger.info("   âœ… æ¨¡å‹å…ƒæ•°æ®å·²åŠ è½½")

            # 5. åˆå§‹åŒ–ç‰¹å¾æå–å™¨
            config = FeatureConfig(
                include_metadata=True,
                include_basic_stats=True,
                include_advanced_stats=True,
                include_context=True,
                include_derived_features=True,
            )
            self.feature_extractor = EnhancedFeatureExtractor(config)
            logger.info("   âœ… ç‰¹å¾æå–å™¨å·²åˆå§‹åŒ–")

            logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å‹å·¥ä»¶åŠ è½½å®Œæˆ!")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹å·¥ä»¶åŠ è½½å¤±è´¥: {e}")
            return False

    def is_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return (
            self.model is not None
            and self.label_encoder is not None
            and self.feature_columns is not None
            and self.feature_extractor is not None
        )

    def predict(self, match_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¯¹å•åœºæ¯”èµ›è¿›è¡Œé¢„æµ‹

        Args:
            match_data: æ¯”èµ›æ•°æ®å­—å…¸

        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        if not self.is_loaded():
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨load_model_artifacts()")

        try:
            # 1. ç‰¹å¾æå–
            features = self.feature_extractor.extract_features(match_data)

            # 2. ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®
            feature_vector = []
            missing_features = []

            for feature_name in self.feature_columns:
                if feature_name in features:
                    value = features[feature_name]
                    # å¤„ç†None/NaNå€¼
                    if value is None or (isinstance(value, float) and np.isnan(value)):
                        feature_vector.append(0.0)
                    else:
                        feature_vector.append(float(value))
                else:
                    feature_vector.append(0.0)  # é»˜è®¤å€¼
                    missing_features.append(feature_name)

            if missing_features:
                logger.warning(f"âš ï¸ ç¼ºå¤±ç‰¹å¾: {missing_features[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª

            # 3. è½¬æ¢ä¸ºnumpyæ•°ç»„
            X = np.array(feature_vector).reshape(1, -1)

            # 4. æ¨¡å‹é¢„æµ‹
            prediction_encoded = self.model.predict(X)[0]
            probabilities = self.model.predict_proba(X)[0]

            # 5. è§£ç é¢„æµ‹ç»“æœ
            prediction_label = self.label_encoder.inverse_transform(
                [prediction_encoded]
            )[0]

            # 6. æ„å»ºæ¦‚ç‡å­—å…¸
            class_names = self.label_encoder.classes_
            prob_dict = {}
            for i, class_name in enumerate(class_names):
                prob_dict[class_name] = float(probabilities[i])

            # 7. ç¡®ä¿æ¦‚ç‡å’Œä¸º1
            total_prob = sum(prob_dict.values())
            if total_prob > 0:
                prob_dict = {k: v / total_prob for k, v in prob_dict.items()}

            return {
                "prediction": prediction_label,
                "probabilities": prob_dict,
                "confidence": max(prob_dict.values()),
                "feature_count": len(self.feature_columns),
                "missing_features": len(missing_features),
            }

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            raise

    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if not self.is_loaded():
            return {"status": "not_loaded"}

        info = {
            "status": "loaded",
            "model_type": "XGBoost Classifier",
            "feature_count": len(self.feature_columns) if self.feature_columns else 0,
            "target_classes": list(self.label_encoder.classes_)
            if self.label_encoder
            else [],
            "model_metadata": self.model_metadata or {},
        }

        return info


# å…¨å±€æ¨¡å‹åŠ è½½å™¨å®ä¾‹
model_loader = ModelLoader()
