#!/usr/bin/env python3
"""
FotMob HTML æ•°æ®é‡‡é›†å™¨ - å¼‚æ­¥æ ‡å‡†åŒ–ç‰ˆæœ¬
FotMob HTML Data Collector - Async Standard Version

åŸºäºAsync Base Classçš„æ ‡å‡†åŒ–å¼‚æ­¥é‡‡é›†å™¨
"""

import asyncio
import json
import logging
import random
import re
from typing import Optional, , Any, 
from datetime import datetime

import httpx
from httpx import AsyncClient, Response

from src.core.async_base import AsyncBaseCollector, AsyncConfig
from .user_agent import UserAgentManager

logger = logging.getLogger(__name__)


class AsyncHTMLFotMobCollector(AsyncBaseCollector):
    """
    FotMob HTML å¼‚æ­¥æ•°æ®é‡‡é›†å™¨

    ç»§æ‰¿AsyncBaseCollectorï¼Œä½¿ç”¨æ ‡å‡†å¼‚æ­¥åŸºç¡€è®¾æ–½
    """

    def __init__(
        self,
        max_retries: int = 3,
        timeout: int = 30,
        enable_stealth: bool = True,
        enable_proxy: bool = False,
    ):
        # åˆ›å»ºå¼‚æ­¥é…ç½®
        config = AsyncConfig(
            http_timeout=timeout,
            max_retries=max_retries,
            retry_delay=1.0,
            rate_limit_delay=0.5,  # 500msé—´éš”é¿å…é¢‘ç‡é™åˆ¶
        )

        # åˆå§‹åŒ–å¼‚æ­¥åŸºç±»
        super().__init__(config=config, name="AsyncHTMLFotMobCollector")

        # FotMobç‰¹å®šé…ç½®
        self.max_retries = max_retries
        self.enable_stealth = enable_stealth
        self.enable_proxy = enable_proxy

        # ç»Ÿè®¡ä¿¡æ¯
        self.fotmob_stats = {
            "matches_collected": 0,
            "ua_switches": 0,
            "retry_count": 0,
        }

        # ç”¨æˆ·ä»£ç†ç®¡ç†å™¨
        self.user_manager = UserAgentManager()
        self.current_headers = None
        self.last_rotation = 0.0

        logger.info("ğŸ•·ï¸ FotMob HTMLå¼‚æ­¥é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")

    async def _get_headers(self) -> dict[str, str]:
        """è·å–å½“å‰è¯·æ±‚å¤´"""
        if self.enable_stealth:
            await self._refresh_disguise()

        # ä½¿ç”¨FotMobç‰¹å®šçš„è¯·æ±‚å¤´
        headers = await super()._get_headers()
        headers.update(
            {
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Language": "en-GB,en;q=0.9,en;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Cache-Control": "max-age=0",
            }
        )

        return headers

    async def _get_user_agent(self) -> str:
        """è·å–FotMobç‰¹å®šçš„User-Agent"""
        if self.enable_stealth and self.user_manager:
            headers = self.user_manager.get_realistic_headers()
            return headers.get("User-Agent", await super()._get_user_agent())

        return await super()._get_user_agent()

    async def _refresh_disguise(self):
        """åˆ·æ–°User-Agentä¼ªè£…"""
        if not self.enable_stealth:
            return

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½®æ¢
        now = asyncio.get_event_loop().time()
        rotation_interval = 300  # 5åˆ†é’Ÿ
        if now - self.last_rotation < rotation_interval:
            return

        if self.user_manager:
            self.current_headers = self.user_manager.get_realistic_headers()
            self.fotmob_stats["ua_switches"] += 1
            logger.info(f"ğŸ”„ User-Agentè½®æ¢ (#{self.fotmob_stats['ua_switches']})")

        self.last_rotation = now

    async def collect_match_data(self, match_id: str) -> Optional[dict[str, Any]]:
        """
        é‡‡é›†å•åœºæ¯”èµ›æ•°æ®

        Args:
            match_id (str): æ¯”èµ›ID

        Returns:
            Optional[dict[str, Any]]: æ¯”èµ›æ•°æ®
        """
        try:
            url = f"https://www.fotmob.com/match/{match_id}"
            logger.info(f"ğŸ•·ï¸ è¯·æ±‚æ¯”èµ›æ•°æ®: {url}")

            # 20%æ¦‚ç‡åˆ·æ–°ä¼ªè£…
            if random.random() < 0.2:
                await self._refresh_disguise()

            # å‘èµ·å¼‚æ­¥è¯·æ±‚
            response = await self.fetch_with_retry(url)

            logger.info(
                f"ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}, å¤§å°: {len(response.text):,} å­—ç¬¦"
            )

            # å¤„ç†ä¸åŒçš„å“åº”çŠ¶æ€
            if response.status_code in [200, 404]:
                self.fotmob_stats["matches_collected"] += 1

                # æ£€æŸ¥æ˜¯å¦åŒ…å«Next.jsæ•°æ®
                if "__NEXT_DATA__" in response.text:
                    logger.info("âœ… å‘ç°Next.js SSRæ•°æ®")

                    # æå–Next.jsæ•°æ®
                    nextjs_data = await self._extract_nextjs_data(
                        response.text, match_id
                    )

                    if nextjs_data:
                        # æå–contentæ•°æ®
                        content_data = await self._extract_content_data(
                            nextjs_data, match_id
                        )

                        if content_data:
                            logger.info(f"âœ… æ•°æ®æå–æˆåŠŸ: {match_id}")
                            return {"match": {"id": match_id}, "content": content_data}
                        else:
                            logger.warning(f"âš ï¸ contentæ•°æ®æå–å¤±è´¥: {match_id}")
                            return None
                    else:
                        logger.warning(f"âš ï¸ Next.jsæ•°æ®è§£æå¤±è´¥: {match_id}")
                        return None
                else:
                    if response.status_code == 404:
                        logger.info(f"â„¹ï¸ 404é¡µé¢æ— Next.jsæ•°æ®: {match_id}")
                    else:
                        logger.warning(f"âš ï¸ é¡µé¢æ— Next.jsæ•°æ®: {match_id}")
                    return None

            elif response.status_code == 429:
                logger.warning("âš ï¸ è§¦å‘é¢‘ç‡é™åˆ¶")
                self.fotmob_stats["retry_count"] += 1
                await asyncio.sleep(random.uniform(10, 20))
                return await self.collect_match_data(match_id)

            elif response.status_code == 403:
                logger.warning("âš ï¸ è§¦å‘åçˆ¬æ£€æµ‹")
                self.fotmob_stats["retry_count"] += 1
                await self._refresh_disguise()
                await asyncio.sleep(random.uniform(5, 10))
                return await self.collect_match_data(match_id)

            else:
                logger.error(f"âŒ æœªå¤„ç†çš„çŠ¶æ€ç : {response.status_code}")
                return None

        except Exception as e:
            logger.error(f"âŒ é‡‡é›†å¼‚å¸¸ {match_id}: {e}")
            return None

    async def _extract_nextjs_data(
        self, html: str, match_id: str
    ) -> Optional[dict[str, Any]]:
        """
        ä»HTMLä¸­æå–Next.jsæ•°æ®

        Args:
            html (str): HTMLå†…å®¹
            match_id (str): æ¯”èµ›ID

        Returns:
            Optional[dict[str, Any]]: Next.jsæ•°æ®
        """
        try:
            # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œç²¾ç¡®åŒ¹é…scriptæ ‡ç­¾
            patterns = [
                r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*typing.Type=["\']application/json["\'][^>]*>(.*?)</script>',
                r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*>(.*?)</script>',
                r"window\.__NEXT_DATA__\s*=\s*(\{.*?\});?\s*<\/script>",
            ]

            for pattern in patterns:
                matches = re.findall(pattern, html, re.DOTALL)
                if matches:
                    nextjs_data_str = matches[0].strip()

                    # æ¸…ç†å¯èƒ½çš„JavaScriptåŒ…è£…
                    if nextjs_data_str.startswith("window.__NEXT_DATA__"):
                        nextjs_data_str = (
                            nextjs_data_str.replace("window.__NEXT_DATA__", "")
                            .replace("=", "")
                            .strip()
                        )
                        if nextjs_data_str.endswith(";"):
                            nextjs_data_str = nextjs_data_str[:-1]

                    try:
                        nextjs_data = json.loads(nextjs_data_str)
                        logger.info(f"âœ… Next.js JSONè§£ææˆåŠŸ: {match_id}")
                        return nextjs_data
                    except json.JSONDecodeError as e:
                        logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥ {match_id}: {e}")
                        logger.debug(f"   æ•°æ®é¢„è§ˆ: {nextjs_data_str[:200]}...")
                        continue

            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°__NEXT_DATA__: {match_id}")
            return None

        except Exception as e:
            logger.error(f"âŒ Next.jsæå–å¼‚å¸¸ {match_id}: {e}")
            return None

    async def _extract_content_data(
        self, nextjs_data: dict[str, Any], match_id: str
    ) -> Optional[dict[str, Any]]:
        """
        ä»Next.jsæ•°æ®ä¸­æå–content

        Args:
            nextjs_data (dict[str, Any]): Next.jsæ•°æ®
            match_id (str): æ¯”èµ›ID

        Returns:
            Optional[dict[str, Any]]: contentæ•°æ®
        """
        try:
            props = nextjs_data.get("props", {})
            if not props:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°props: {match_id}")
                return None

            page_props = props.get("pageProps", {})
            if not page_props:
                # æ£€æŸ¥æ˜¯å¦æ˜¯404é¡µé¢
                url = props.get("url", "")
                if "/404" in url:
                    logger.info(f"â„¹ï¸ è·³è¿‡404é¡µé¢: {match_id}")
                return None

            content = page_props.get("content", {})
            if not content:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°content: {match_id}")
                return None

            logger.info(f"âœ… æˆåŠŸæå–content: {match_id}")
            logger.info(f"   Content Keys: {list(content.keys())}")

            # éªŒè¯MLç‰¹å¾å­—æ®µ
            required_features = [
                "matchFacts",
                "stats",
                "lineup",
                "shotmap",
                "playerStats",
            ]
            found_features = [
                feature for feature in required_features if feature in content
            ]

            logger.info(f"   æ‰¾åˆ°MLç‰¹å¾: {found_features}/{len(required_features)}")

            # æ£€æŸ¥xGæ•°æ®
            if "stats" in content:
                stats = content.get("stats", {})
                if isinstance(stats, dict):
                    periods = stats.get("Periods", {})
                    all_stats = periods.get("All", {})
                    stats_list = all_stats.get("stats", [])

                    xg_found = False
                    for stat_group in stats_list:
                        if isinstance(stat_group, dict) and "stats" in stat_group:
                            for stat in stat_group.get("stats", []):
                                if isinstance(stat, dict):
                                    title = stat.get("title", "").lower()
                                    if "expected goals" in title or "xg" in title:
                                        xg_values = stat.get("stats", [])
                                        if xg_values and len(xg_values) >= 2:
                                            logger.info(
                                                f"ğŸ¯ æ‰¾åˆ°xGæ•°æ®: ä¸»é˜Ÿ={xg_values[0]}, å®¢é˜Ÿ={xg_values[1]}"
                                            )
                                            xg_found = True
                                            break
                        if xg_found:
                            break

                    if not xg_found:
                        logger.info(f"â„¹ï¸ æœªæ‰¾åˆ°xGæ•°æ®: {match_id}")

            return content

        except Exception as e:
            logger.error(f"âŒ contentæå–å¼‚å¸¸ {match_id}: {e}")
            import traceback

            logger.debug(f"ğŸ” è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    async def get_stats(self) -> dict[str, Any]:
        """è·å–é‡‡é›†ç»Ÿè®¡ä¿¡æ¯"""
        # è·å–åŸºç±»ç»Ÿè®¡
        base_stats = super().get_stats()

        # æ·»åŠ FotMobç‰¹å®šç»Ÿè®¡
        fotmob_stats = self.fotmob_stats.copy()
        fotmob_stats.update(base_stats)

        fotmob_stats["stealth_mode"] = self.enable_stealth
        fotmob_stats["proxy_enabled"] = self.enable_proxy
        fotmob_stats["collection_rate"] = fotmob_stats["matches_collected"] / max(
            fotmob_stats["total_requests"], 1
        )

        return fotmob_stats


# å‘åå…¼å®¹çš„åˆ«å
HTMLFotMobCollector = AsyncHTMLFotMobCollector
