#!/usr/bin/env python3
"""
è®­ç»ƒæ•°æ®å‡†å¤‡è„šæœ¬ (Prepare Training Data)

ä»æ•°æ®åº“è¯»å–matchesè¡¨ï¼Œæ„å»ºç‰¹å¾é›†å’Œæ ‡ç­¾ï¼Œä¸ºæ¨¡å‹è®­ç»ƒåšå‡†å¤‡ã€‚

ç‰¹å¾ (X):
- home_xg, away_xg (æœŸæœ›è¿›çƒæ•°)
- home_possession, away_possession (æ§çƒç‡)
- home_shots, away_shots (å°„é—¨æ•°)
- home_shots_on_target, away_shots_on_target (å°„æ­£æ•°)

æ ‡ç­¾ (y):
- 0: Home Win, 1: Draw, 2: Away Win

ä½œè€…: ML Engineer (P2-5)
åˆ›å»ºæ—¶é—´: 2025-12-06
ç‰ˆæœ¬: 1.0.0
"""

import logging
import sys
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.database.async_manager import get_db_session
from src.database.models import Match
from sqlalchemy import select, and_, or_

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)8s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f"/tmp/prepare_training_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.log")
    ]
)
logger = logging.getLogger(__name__)


class TrainingDataPreparer:
    """è®­ç»ƒæ•°æ®å‡†å¤‡å™¨"""

    def __init__(self):
        self.required_features = [
            'home_xg', 'away_xg',
            'home_possession', 'away_possession',
            'home_shots', 'away_shots',
            'home_shots_on_target', 'away_shots_on_target'
        ]

    async def load_matches_from_database(self, limit: Optional[int] = None) -> pd.DataFrame:
        """
        ä»æ•°æ®åº“åŠ è½½æ¯”èµ›æ•°æ®

        Args:
            limit: é™åˆ¶åŠ è½½çš„è®°å½•æ•°ï¼ŒNoneè¡¨ç¤ºåŠ è½½æ‰€æœ‰

        Returns:
            åŒ…å«æ¯”èµ›æ•°æ®çš„DataFrame
        """
        logger.info("ğŸ“Š ä»æ•°æ®åº“åŠ è½½æ¯”èµ›æ•°æ®...")

        async with get_db_session() as session:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = [
                Match.status.in_(["finished", "completed"]),
                Match.home_score.isnot(None),
                Match.away_score.isnot(None)
            ]

            query = select(Match).where(and_(*conditions)).order_by(Match.match_date.desc())

            if limit:
                query = query.limit(limit)

            result = await session.execute(query)
            matches = result.scalars().all()

            logger.info(f"   åŠ è½½äº† {len(matches)} åœºæ¯”èµ›æ•°æ®")

            # è½¬æ¢ä¸ºDataFrame
            matches_data = []
            for match in matches:
                match_dict = {
                    'id': match.id,
                    'home_team_id': match.home_team_id,
                    'away_team_id': match.away_team_id,
                    'home_score': match.home_score,
                    'away_score': match.away_score,
                    'match_date': match.match_date,
                    'status': match.status,
                    'league_id': match.league_id,
                    'season': match.season,
                }

                # æ·»åŠ æ–°å¢çš„ç»Ÿè®¡å­—æ®µï¼ˆä½¿ç”¨getattrå¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„å­—æ®µï¼‰
                for feature in self.required_features:
                    value = getattr(match, feature, None)
                    match_dict[feature] = value

                matches_data.append(match_dict)

            df = pd.DataFrame(matches_data)
            logger.info(f"   DataFrameå½¢çŠ¶: {df.shape}")

            return df

    def prepare_features_and_labels(self, df: pd.DataFrame) -> tuple[pd.DataFrame, np.ndarray]:
        """
        å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾

        Args:
            df: åŸå§‹æ¯”èµ›æ•°æ®DataFrame

        Returns:
            (ç‰¹å¾DataFrame, æ ‡ç­¾æ•°ç»„)
        """
        logger.info("ğŸ”§ å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾...")

        # æ•°æ®è´¨é‡æ£€æŸ¥
        original_count = len(df)
        df = self._clean_data(df)
        logger.info(f"   æ•°æ®æ¸…æ´—å: {len(df)} æ¡è®°å½• (åŸå§‹: {original_count})")

        if len(df) == 0:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®")

        # æ„å»ºç‰¹å¾çŸ©é˜µ X
        X = df[self.required_features].copy()

        # ç‰¹å¾å·¥ç¨‹
        X = self._engineer_features(X)

        logger.info(f"   ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        logger.info(f"   ç‰¹å¾åˆ—: {list(X.columns)}")

        # æ„å»ºæ ‡ç­¾ y
        y = self._create_labels(df)

        logger.info(f"   æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y)} (Home:0, Draw:1, Away:2)")

        # ç‰¹å¾ç»Ÿè®¡
        self._log_feature_stats(X)

        return X, y

    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—"""
        logger.info("   å¼€å§‹æ•°æ®æ¸…æ´—...")

        original_count = len(df)

        # ç§»é™¤å…³é”®å­—æ®µä¸ºç©ºçš„è®°å½•
        required_fields = ['home_score', 'away_score'] + self.required_features
        for field in required_fields:
            if field in df.columns:
                null_count = df[field].isnull().sum()
                if null_count > 0:
                    logger.warning(f"   å­—æ®µ {field} æœ‰ {null_count} ä¸ªç©ºå€¼")

        # åˆ é™¤æ‰€æœ‰å…³é”®å­—æ®µéƒ½ä¸ºç©ºçš„è®°å½•
        df_cleaned = df.dropna(subset=required_fields, how='any')

        # åˆ é™¤é‡å¤è®°å½•
        df_cleaned = df_cleaned.drop_duplicates()

        logger.info("   æ•°æ®æ¸…æ´—å®Œæˆ:")
        logger.info(f"     åˆ é™¤ç©ºå€¼è®°å½•: {original_count - len(df_cleaned)} æ¡")
        logger.info(f"     åˆ é™¤é‡å¤è®°å½•: {len(df) - len(df_cleaned)} æ¡")
        logger.info(f"     æœ€ç»ˆè®°å½•æ•°: {len(df_cleaned)} æ¡")

        return df_cleaned

    def _engineer_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾å·¥ç¨‹"""
        logger.info("   æ‰§è¡Œç‰¹å¾å·¥ç¨‹...")

        X_engineered = X.copy()

        # 1. å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨ä¸­ä½æ•°ï¼‰
        for col in X_engineered.columns:
            if X_engineered[col].isnull().any():
                median_val = X_engineered[col].median()
                X_engineered[col] = X_engineered[col].fillna(median_val)
                logger.info(f"     å¡«å…… {col} ç¼ºå¤±å€¼: ä¸­ä½æ•°={median_val}")

        # 2. åˆ›å»ºè¡ç”Ÿç‰¹å¾
        if all(col in X_engineered.columns for col in ['home_xg', 'away_xg']):
            # xGå·®å€¼
            X_engineered['xg_difference'] = X_engineered['home_xg'] - X_engineered['away_xg']

            # xGæ¯”ç‡
            X_engineered['xg_ratio'] = X_engineered['home_xg'] / (X_engineered['away_xg'] + 0.001)  # é¿å…0é™¤

        if all(col in X_engineered.columns for col in ['home_possession', 'away_possession']):
            # æ§çƒç‡å·®å€¼
            X_engineered['possession_difference'] = X_engineered['home_possession'] - X_engineered['away_possession']

        if all(col in X_engineered.columns for col in ['home_shots', 'away_shots']):
            # å°„é—¨å·®å€¼
            X_engineered['shots_difference'] = X_engineered['home_shots'] - X_engineered['away_shots']

            # å°„é—¨æ•ˆç‡
            X_engineered['home_shot_efficiency'] = X_engineered['home_shots_on_target'] / (X_engineered['home_shots'] + 0.001)
            X_engineered['away_shot_efficiency'] = X_engineered['away_shots_on_target'] / (X_engineered['away_shots'] + 0.001)

        logger.info(f"     è¡ç”Ÿç‰¹å¾åçš„å½¢çŠ¶: {X_engineered.shape}")

        return X_engineered

    def _create_labels(self, df: pd.DataFrame) -> np.ndarray:
        """åˆ›å»ºæ ‡ç­¾"""
        def determine_result(row):
            home_score = row['home_score']
            away_score = row['away_score']

            if home_score > away_score:
                return 0  # Home Win
            elif away_score > home_score:
                return 2  # Away Win
            else:
                return 1  # Draw

        y = df.apply(determine_result, axis=1).values
        return y

    def _log_feature_stats(self, X: pd.DataFrame):
        """è®°å½•ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("   ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:")

        for col in X.columns:
            if X[col].dtype in ['float64', 'int64']:
                stats = {
                    'count': X[col].count(),
                    'mean': X[col].mean(),
                    'std': X[col].std(),
                    'min': X[col].min(),
                    'max': X[col].max(),
                    'null_count': X[col].isnull().sum()
                }

                logger.info(f"     {col:<25}: "
                           f"count={stats['count']:>5}, "
                           f"mean={stats['mean']:>7.3f}, "
                           f"std={stats['std']:>7.3f}, "
                           f"min={stats['min']:>7.3f}, "
                           f"max={stats['max']:>7.3f}")

    async def save_training_data(self, X: pd.DataFrame, y: np.ndarray,
                               output_path: str = "data/training_set_v1.parquet") -> None:
        """
        ä¿å­˜è®­ç»ƒæ•°æ®

        Args:
            X: ç‰¹å¾DataFrame
            y: æ ‡ç­¾æ•°ç»„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        logger.info(f"ğŸ’¾ ä¿å­˜è®­ç»ƒæ•°æ®åˆ°: {output_path}")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ç‰¹å¾å’Œæ ‡ç­¾
        X.to_parquet(output_path, index=False)

        # ä¿å­˜æ ‡ç­¾
        y_path = output_path.replace('.parquet', '_labels.npz')
        np.save(y_path, y)

        logger.info(f"   ç‰¹å¾æ•°æ®: {X.shape}, æ ‡ç­¾æ•°æ®: {y.shape}")
        logger.info(f"   ç‰¹å¾æ–‡ä»¶: {output_path}")
        logger.info(f"   æ ‡ç­¾æ–‡ä»¶: {y_path}")

    async def prepare_training_data(self, limit: Optional[int] = None,
                                   output_path: str = "data/training_set_v1.parquet") -> tuple[pd.DataFrame, np.ndarray]:
        """
        æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæ•°æ®å‡†å¤‡æµç¨‹

        Args:
            limit: é™åˆ¶è®°å½•æ•°
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            (ç‰¹å¾DataFrame, æ ‡ç­¾æ•°ç»„)
        """
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ•°æ®å‡†å¤‡æµç¨‹")

        # 1. ä»æ•°æ®åº“åŠ è½½æ•°æ®
        df = await self.load_matches_from_database(limit)

        # 2. å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
        X, y = self.prepare_features_and_labels(df)

        # 3. ä¿å­˜è®­ç»ƒæ•°æ®
        await self.save_training_data(X, y, output_path)

        logger.info("âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
        return X, y


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– è®­ç»ƒæ•°æ®å‡†å¤‡å¼€å§‹")
    print("=" * 50)

    preparer = TrainingDataPreparer()

    try:
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        # å¯ä»¥è®¾ç½®limitå‚æ•°æ¥é™åˆ¶æ•°æ®é‡ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•
        X, y = await preparer.prepare_training_data(
            limit=None,  # è®¾ç½®ä¸ºNoneä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®
            output_path="data/training_set_v1.parquet"
        )

        print("\nğŸ“Š æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   ç‰¹å¾çŸ©é˜µ: {X.shape}")
        print(f"   æ ‡ç­¾å‘é‡: {y.shape}")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: Home(0): {np.sum(y == 0)}, Draw(1): {np.sum(y == 1)}, Away(2): {np.sum(y == 2)}")

        print("\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: data/training_set_v1.parquet")
        print("âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ!")

        return 0

    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒæ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
