#!/usr/bin/env python3
"""
é¦–å¸­AIç§‘å­¦å®¶ä¸“ç”¨ - V1æ•°æ®é›†æ„å»ºå™¨
åŸºäºé«˜è´¨é‡æ•°æ®æ„å»ºMLè®­ç»ƒç‰¹å¾é›†
"""

import subprocess
import pandas as pd
import numpy as np
import logging
from datetime import datetime
from pathlib import Path

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class V1DatasetBuilder:
    """V1æ•°æ®é›†æ„å»ºå™¨"""

    def __init__(self):
        self.data = None
        self.features_df = None

    def load_match_data(self):
        """ä»Silver Layerè§†å›¾åŠ è½½æ¯”èµ›æ•°æ®"""
        try:
            logger.info("ğŸ“Š ä»view_match_featuresåŠ è½½æ¯”èµ›æ•°æ®...")

            # ä½¿ç”¨docker execæŸ¥è¯¢æ•°æ®
            cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-c",
                """
                SELECT
                    match_date,
                    home_team_name,
                    away_team_name,
                    home_score,
                    away_score,
                    home_xg,
                    away_xg,
                    venue,
                    referee
                FROM view_match_features
                WHERE home_score IS NOT NULL
                  AND away_score IS NOT NULL
                ORDER BY match_date, home_team_name, away_team_name;
                """,
            ]

            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {result.stderr}")
                return False

            # è§£æCSVè¾“å‡º
            lines = result.stdout.strip().split("\n")
            if len(lines) < 3:
                logger.error("âŒ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¡Œ")
                return False

            # è·³è¿‡è¡¨å¤´å’Œåˆ†éš”ç¬¦
            data_lines = [line for line in lines[2:] if line.strip()]

            # è§£ææ•°æ®
            data = []
            for line in data_lines:
                parts = [p.strip() for p in line.split("|")]
                if len(parts) >= 9:
                    try:
                        data.append(
                            {
                                "match_date": parts[0],
                                "home_team": parts[1],
                                "away_team": parts[2],
                                "home_score": int(parts[3]) if parts[3] else None,
                                "away_score": int(parts[4]) if parts[4] else None,
                                "home_xg": (
                                    float(parts[5])
                                    if parts[5] and parts[5] != ""
                                    else None
                                ),
                                "away_xg": (
                                    float(parts[6])
                                    if parts[6] and parts[6] != ""
                                    else None
                                ),
                                "venue": parts[7],
                                "referee": parts[8],
                            }
                        )
                    except (ValueError, IndexError) as e:
                        logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆè¡Œ: {line} - {e}")
                        continue

            self.data = pd.DataFrame(data)
            self.data["match_date"] = pd.to_datetime(self.data["match_date"])
            self.data = self.data.sort_values("match_date")

            logger.info(f"âœ… åŠ è½½äº† {len(self.data)} åœºæ¯”èµ›")
            logger.info(
                f"ğŸ“… æ—¶é—´èŒƒå›´: {self.data['match_date'].min()} åˆ° {self.data['match_date'].max()}"
            )
            logger.info(f"âš½ xGæ•°æ®è¦†ç›–: {self.data['home_xg'].notna().sum()} åœºæ¯”èµ›")

            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¼‚å¸¸: {e}")
            return False

    def build_rolling_features(self):
        """æ„å»ºæ»šåŠ¨ç‰¹å¾"""
        logger.info("ğŸ”§ æ„å»ºæ»šåŠ¨ç‰¹å¾...")

        # ä¸ºæ¯æ”¯çƒé˜Ÿæ„å»ºå†å²æ•°æ®
        teams = pd.concat([self.data["home_team"], self.data["away_team"]]).unique()

        all_team_stats = {}

        for team in teams:
            # è·å–è¯¥çƒé˜Ÿæ‰€æœ‰æ¯”èµ›ï¼ˆä¸»å®¢é˜Ÿéƒ½è¦è€ƒè™‘ï¼‰
            home_games = self.data[self.data["home_team"] == team].copy()
            away_games = self.data[self.data["away_team"] == team].copy()

            # ä¸»é˜Ÿæ•°æ®
            home_games["goals_scored"] = home_games["home_score"]
            home_games["goals_conceded"] = home_games["away_score"]
            home_games["xg_created"] = home_games["home_xg"]
            home_games["xg_conceded"] = home_games["away_xg"]

            # å®¢é˜Ÿæ•°æ®
            away_games["goals_scored"] = away_games["away_score"]
            away_games["goals_conceded"] = away_games["home_score"]
            away_games["xg_created"] = away_games["away_xg"]
            away_games["xg_conceded"] = away_games["home_xg"]

            # ç»Ÿä¸€æ ¼å¼
            team_games = pd.concat([home_games, away_games], ignore_index=True)
            team_games = team_games.sort_values("match_date")

            # è®¡ç®—æ»šåŠ¨ç»Ÿè®¡ï¼ˆè¿‡å»5åœºï¼‰
            windows = [5]
            for window in windows:
                team_games[f"avg_goals_scored_{window}"] = (
                    team_games["goals_scored"]
                    .rolling(window, min_periods=1)
                    .mean()
                    .shift(1)  # é˜²æ­¢æ•°æ®æ³„éœ²
                )

                team_games[f"avg_goals_conceded_{window}"] = (
                    team_games["goals_conceded"]
                    .rolling(window, min_periods=1)
                    .mean()
                    .shift(1)
                )

                team_games[f"avg_xg_created_{window}"] = (
                    team_games["xg_created"]
                    .rolling(window, min_periods=1)
                    .mean()
                    .shift(1)
                )

                team_games[f"avg_xg_conceded_{window}"] = (
                    team_games["xg_conceded"]
                    .rolling(window, min_periods=1)
                    .mean()
                    .shift(1)
                )

                team_games[f"games_played_{window}"] = (
                    team_games["goals_scored"]
                    .rolling(window, min_periods=1)
                    .count()
                    .shift(1)
                )

            all_team_stats[team] = team_games[
                ["match_date"]
                + [f"avg_goals_scored_{w}" for w in windows]
                + [f"avg_goals_conceded_{w}" for w in windows]
                + [f"avg_xg_created_{w}" for w in windows]
                + [f"avg_xg_conceded_{w}" for w in windows]
                + [f"games_played_{w}" for w in windows]
            ]

        # å°†ç»Ÿè®¡ä¿¡æ¯åˆå¹¶åˆ°åŸå§‹æ•°æ®
        logger.info("ğŸ”„ åˆå¹¶ç»Ÿè®¡ä¿¡æ¯åˆ°åŸå§‹æ•°æ®...")

        # æ·»åŠ ä¸»é˜Ÿç‰¹å¾
        home_features = []
        for _, row in self.data.iterrows():
            team_stats = all_team_stats[row["home_team"]]
            team_row = team_stats[team_stats["match_date"] <= row["match_date"]]

            if not team_row.empty:
                latest_stats = team_row.iloc[-1]
                feature_dict = {
                    "home_avg_goals_scored_5": latest_stats.get(
                        "avg_goals_scored_5", 0
                    ),
                    "home_avg_goals_conceded_5": latest_stats.get(
                        "avg_goals_conceded_5", 0
                    ),
                    "home_avg_xg_created_5": latest_stats.get("avg_xg_created_5", 0),
                    "home_avg_xg_conceded_5": latest_stats.get("avg_xg_conceded_5", 0),
                    "home_games_played_5": latest_stats.get("games_played_5", 0),
                }
            else:
                feature_dict = {
                    "home_avg_goals_scored_5": 0,
                    "home_avg_goals_conceded_5": 0,
                    "home_avg_xg_created_5": 0,
                    "home_avg_xg_conceded_5": 0,
                    "home_games_played_5": 0,
                }

            home_features.append(feature_dict)

        # æ·»åŠ å®¢é˜Ÿç‰¹å¾
        away_features = []
        for _, row in self.data.iterrows():
            team_stats = all_team_stats[row["away_team"]]
            team_row = team_stats[team_stats["match_date"] <= row["match_date"]]

            if not team_row.empty:
                latest_stats = team_row.iloc[-1]
                feature_dict = {
                    "away_avg_goals_scored_5": latest_stats.get(
                        "avg_goals_scored_5", 0
                    ),
                    "away_avg_goals_conceded_5": latest_stats.get(
                        "avg_goals_conceded_5", 0
                    ),
                    "away_avg_xg_created_5": latest_stats.get("avg_xg_created_5", 0),
                    "away_avg_xg_conceded_5": latest_stats.get("avg_xg_conceded_5", 0),
                    "away_games_played_5": latest_stats.get("games_played_5", 0),
                }
            else:
                feature_dict = {
                    "away_avg_goals_scored_5": 0,
                    "away_avg_goals_conceded_5": 0,
                    "away_avg_xg_created_5": 0,
                    "away_avg_xg_conceded_5": 0,
                    "away_games_played_5": 0,
                }

            away_features.append(feature_dict)

        # åˆå¹¶ç‰¹å¾
        self.features_df = self.data.copy()
        home_df = pd.DataFrame(home_features)
        away_df = pd.DataFrame(away_features)

        self.features_df = pd.concat(
            [
                self.features_df.reset_index(drop=True),
                home_df.reset_index(drop=True),
                away_df.reset_index(drop=True),
            ],
            axis=1,
        )

        logger.info(f"âœ… ç‰¹å¾æ„å»ºå®Œæˆï¼Œç»´åº¦: {self.features_df.shape}")

    def build_target(self):
        """æ„å»ºç›®æ ‡å˜é‡"""
        logger.info("ğŸ¯ æ„å»ºç›®æ ‡å˜é‡...")

        def determine_result(row):
            if pd.isna(row["home_score"]) or pd.isna(row["away_score"]):
                return None
            elif row["home_score"] > row["away_score"]:
                return 2  # ä¸»èƒœ
            elif row["home_score"] < row["away_score"]:
                return 0  # å®¢èƒœ
            else:
                return 1  # å¹³å±€

        self.features_df["result"] = self.features_df.apply(determine_result, axis=1)

        # ç§»é™¤æ²¡æœ‰ç»“æœçš„æ¯”èµ›
        self.features_df = self.features_df.dropna(subset=["result"])
        self.features_df["result"] = self.features_df["result"].astype(int)

        logger.info(f"âœ… ç›®æ ‡å˜é‡æ„å»ºå®Œæˆ: {len(self.features_df)} åœºæœ‰æ•ˆæ¯”èµ›")

    def save_dataset(self):
        """ä¿å­˜æ•°æ®é›†"""
        try:
            # åˆ›å»ºç›®å½•
            output_dir = Path("data/training_sets")
            output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜å®Œæ•´æ•°æ®é›†
            output_file = output_dir / "v1_dataset.csv"
            self.features_df.to_csv(output_file, index=False)

            logger.info(f"ğŸ’¾ æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}")
            logger.info(f"ğŸ“Š æ•°æ®é›†ç»´åº¦: {self.features_df.shape}")

            # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
            feature_cols = [
                col
                for col in self.features_df.columns
                if "avg_" in col or "games_" in col
            ]
            logger.info(f"ğŸ”§ ç‰¹å¾åˆ—æ•°: {len(feature_cols)}")
            logger.info(
                f"ğŸ¯ ç›®æ ‡åˆ†å¸ƒ: {self.features_df['result'].value_counts().to_dict()}"
            )

            # æ˜¾ç¤ºæ ·æœ¬
            logger.info("ğŸ“‹ æ•°æ®æ ·æœ¬:")
            sample_cols = [
                "match_date",
                "home_team",
                "away_team",
                "home_score",
                "away_score",
                "result",
            ] + feature_cols[:3]
            logger.info(self.features_df[sample_cols].head().to_string())

            return True

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ•°æ®é›†å¤±è´¥: {e}")
            return False

    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®é›†æ„å»ºæµç¨‹"""
        logger.info("ğŸš€ å¯åŠ¨é¦–å¸­AIç§‘å­¦å®¶ - V1æ•°æ®é›†æ„å»ºå™¨")
        start_time = datetime.now()

        # 1. åŠ è½½æ•°æ®
        if not self.load_match_data():
            return False

        # 2. æ„å»ºç‰¹å¾
        self.build_rolling_features()

        # 3. æ„å»ºç›®æ ‡
        self.build_target()

        # 4. ä¿å­˜æ•°æ®é›†
        success = self.save_dataset()

        # è®¡ç®—è€—æ—¶
        duration = (datetime.now() - start_time).total_seconds()
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’")

        if success:
            logger.info("ğŸ‰ V1æ•°æ®é›†æ„å»ºå®Œæˆï¼")
            logger.info("ğŸ“ˆ å‡†å¤‡è¿›è¡Œæ¨¡å‹è®­ç»ƒ...")
            logger.info("â­ï¸  ä¸‹ä¸€æ­¥: python src/models/train_v1_xgboost.py")

        return success


def main():
    """ä¸»å‡½æ•°"""
    try:
        builder = V1DatasetBuilder()
        success = builder.run()

        if success:
            logger.info("âœ… V1æ•°æ®é›†æ„å»ºæˆåŠŸ")
            return 0
        else:
            logger.error("âŒ V1æ•°æ®é›†æ„å»ºå¤±è´¥")
            return 1

    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
