#!/usr/bin/env python3
"""
Async Migration Tool - å¼‚æ­¥åŒ–è‡ªåŠ¨è¿ç§»å·¥å…·
è‡ªåŠ¨å°†åŒæ­¥ä»£ç è¿ç§»ä¸ºå¼‚æ­¥ä»£ç 

åŠŸèƒ½:
1. è‡ªåŠ¨æ£€æµ‹åŒæ­¥è°ƒç”¨æ¨¡å¼
2. ç”Ÿæˆå¼‚æ­¥åŒ–å»ºè®®å’Œè¡¥ä¸
3. å®‰å…¨æ¨¡å¼çš„ä»£ç è½¬æ¢
4. ç”Ÿæˆè¿ç§»æŠ¥å‘Š

ä½œè€…: Asyncæ¶æ„è´Ÿè´£äºº
åˆ›å»ºæ—¶é—´: 2025-12-06
"""

import ast
import asyncio
import os
import re
import sys
import time
from dataclasses import dataclass
from difflib import unified_diff
from pathlib import Path
import argparse
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class MigrationPattern:
    """è¿ç§»æ¨¡å¼å®šä¹‰"""

    name: str
    pattern: str
    replacement: str
    description: str
    priority: str  # "high", "medium", "low"
    requires_await: bool = True
    target_files: list[str] = None  # ç›®æ ‡æ–‡ä»¶æ¨¡å¼


@dataclass
class MigrationIssue:
    """è¿ç§»é—®é¢˜è®°å½•"""

    file_path: str
    line_number: int
    issue_type: str
    description: str
    suggested_fix: str
    priority: str


class AsyncMigrationAnalyzer:
    """å¼‚æ­¥åŒ–è¿ç§»åˆ†æå™¨"""

    def __init__(self, root_dir: str = "src"):
        self.root_dir = Path(root_dir)
        self.migration_patterns = self._define_migration_patterns()
        self.issues: list[MigrationIssue] = []

    def _define_migration_patterns(self) -> list[MigrationPattern]:
        """å®šä¹‰è¿ç§»æ¨¡å¼"""
        return [
            # HTTPå®¢æˆ·ç«¯è¿ç§»
            MigrationPattern(
                name="requests_import",
                pattern=r"import\s+requests",
                replacement="import httpx",
                description="å°†requestså¯¼å…¥æ›¿æ¢ä¸ºhttpx",
                priority="high",
                target_files=["src/collectors/*.py", "src/data/collectors/*.py"],
            ),
            MigrationPattern(
                name="requests_get",
                pattern=r"requests\.get\(",
                replacement="await httpx.AsyncClient().get(",
                description="å°†åŒæ­¥GETè¯·æ±‚æ›¿æ¢ä¸ºå¼‚æ­¥",
                priority="high",
                requires_await=True,
            ),
            MigrationPattern(
                name="requests_post",
                pattern=r"requests\.post\(",
                replacement="await httpx.AsyncClient().post(",
                description="å°†åŒæ­¥POSTè¯·æ±‚æ›¿æ¢ä¸ºå¼‚æ­¥",
                priority="high",
                requires_await=True,
            ),
            MigrationPattern(
                name="requests_session",
                pattern=r"requests\.Session\(",
                replacement="httpx.AsyncClient(",
                description="å°†åŒæ­¥Sessionæ›¿æ¢ä¸ºå¼‚æ­¥Client",
                priority="high",
            ),
            MigrationPattern(
                name="curl_cffi_import",
                pattern=r"from\s+curl_cffi\s+import\s+requests",
                replacement="import httpx",
                description="å°†curl_cffiå¯¼å…¥æ›¿æ¢ä¸ºhttpx",
                priority="high",
            ),
            # æ—¶é—´é˜»å¡è°ƒç”¨è¿ç§»
            MigrationPattern(
                name="time_sleep",
                pattern=r"time\.sleep\(",
                replacement="await asyncio.sleep(",
                description="å°†åŒæ­¥sleepæ›¿æ¢ä¸ºå¼‚æ­¥",
                priority="medium",
                requires_await=True,
            ),
            # å‡½æ•°å®šä¹‰è¿ç§»
            MigrationPattern(
                name="def_to_async",
                pattern=r"def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(",
                replacement="async def \\1(",
                description="å°†å‡½æ•°å®šä¹‰è½¬æ¢ä¸ºå¼‚æ­¥",
                priority="medium",
                requires_await=False,
            ),
            # æ•°æ®åº“æ“ä½œè¿ç§»
            MigrationPattern(
                name="session_execute",
                pattern=r"session\.execute\(",
                replacement="await session.execute(",
                description="æ•°æ®åº“æ“ä½œæ·»åŠ await",
                priority="medium",
                requires_await=True,
            ),
            MigrationPattern(
                name="session_commit",
                pattern=r"session\.commit\(",
                replacement="await session.commit(",
                description="æ•°æ®åº“æäº¤æ·»åŠ await",
                priority="medium",
                requires_await=True,
            ),
        ]

    def analyze_file(self, file_path: Path) -> list[MigrationIssue]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„è¿ç§»éœ€æ±‚"""
        issues = []

        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # åº”ç”¨è¿ç§»æ¨¡å¼æ£€æµ‹
            for pattern in self.migration_patterns:
                if pattern.target_files:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ¹é…ç›®æ ‡æ¨¡å¼
                    if not any(
                        file_path.match(target) for target in pattern.target_files
                    ):
                        continue

                for line_num, line in enumerate(lines, 1):
                    if re.search(pattern.pattern, line):
                        issue = MigrationIssue(
                            file_path=str(file_path),
                            line_number=line_num,
                            issue_type=pattern.name,
                            description=f"æ£€æµ‹åˆ°{pattern.description}",
                            suggested_fix=self._generate_fix_suggestion(line, pattern),
                            priority=pattern.priority,
                        )
                        issues.append(issue)

            # é¢å¤–æ£€æŸ¥: æ£€æµ‹éœ€è¦æ·»åŠ awaitçš„å‡½æ•°è°ƒç”¨
            issues.extend(self._detect_missing_awaits(file_path, content, lines))

        except Exception as e:
            logger.error(f"åˆ†ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        return issues

    def _detect_missing_awaits(
        self, file_path: Path, content: str, lines: list[str]
    ) -> list[MigrationIssue]:
        """æ£€æµ‹ç¼ºå¤±çš„awaitå…³é”®å­—"""
        issues = []

        # è§£æASTæ¥æ£€æµ‹å‡½æ•°è°ƒç”¨
        try:
            tree = ast.parse(content)

            # æŸ¥æ‰¾å¼‚æ­¥è°ƒç”¨ä½†ç¼ºå°‘awaitçš„æƒ…å†µ
            for node in ast.walk(tree):
                if isinstance(node, ast.Call):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„å¼‚æ­¥å‡½æ•°è°ƒç”¨
                    if self._is_async_function_call(node):
                        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘await
                        if not self._has_await_ancestor(node, tree):
                            line_num = node.lineno
                            issue = MigrationIssue(
                                file_path=str(file_path),
                                line_number=line_num,
                                issue_type="missing_await",
                                description="å¼‚æ­¥å‡½æ•°è°ƒç”¨ç¼ºå°‘awaitå…³é”®å­—",
                                suggested_fix="åœ¨å‡½æ•°è°ƒç”¨å‰æ·»åŠ 'await '",
                                priority="high",
                            )
                            issues.append(issue)

        except SyntaxError:
            # å¦‚æœASTè§£æå¤±è´¥ï¼Œè¿›è¡Œç®€å•çš„æ–‡æœ¬æ£€æµ‹
            pass

        return issues

    def _is_async_function_call(self, node: ast.Call) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å¼‚æ­¥å‡½æ•°è°ƒç”¨"""
        if isinstance(node.func, ast.Attribute):
            # æ£€æŸ¥æ–¹æ³•è°ƒç”¨
            async_methods = {
                "fetch",
                "fetch_json",
                "execute",
                "get",
                "post",
                "get_async_session",
            }
            return node.func.attr in async_methods
        elif isinstance(node.func, ast.Name):
            # æ£€æŸ¥å‡½æ•°è°ƒç”¨
            async_functions = {"get_db_session", "async_create_engine", "fetch_data"}
            return node.func.id in async_functions
        return False

    def _has_await_ancestor(self, node: ast.AST, tree: ast.AST) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦è¢«awaitåŒ…è£¹"""
        # ç®€åŒ–å®ç°ï¼šåœ¨å®é™…å·¥å…·ä¸­éœ€è¦æ›´å¤æ‚çš„ASTéå†
        return False

    def _generate_fix_suggestion(self, line: str, pattern: MigrationPattern) -> str:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        if pattern.name == "def_to_async":
            return "å°† 'def' æ”¹ä¸º 'async def'"
        elif pattern.requires_await:
            return f"æ›¿æ¢ä¸º '{pattern.replacement}' å¹¶ç¡®ä¿åœ¨å¼‚æ­¥å‡½æ•°ä¸­è°ƒç”¨"
        else:
            return f"æ›¿æ¢ä¸º '{pattern.replacement}'"

    def analyze_directory(self) -> list[MigrationIssue]:
        """åˆ†ææ•´ä¸ªç›®å½•"""
        all_issues = []

        # æŸ¥æ‰¾Pythonæ–‡ä»¶
        python_files = list(self.root_dir.rglob("*.py"))

        logger.info(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶å¾…åˆ†æ")

        for file_path in python_files:
            logger.info(f"åˆ†ææ–‡ä»¶: {file_path}")
            file_issues = self.analyze_file(file_path)
            all_issues.extend(file_issues)

        return all_issues

    def generate_migration_report(self, issues: list[MigrationIssue]) -> str:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        report = []
        report.append("# å¼‚æ­¥åŒ–è¿ç§»æŠ¥å‘Š\n")
        report.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")

        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        high_priority = [i for i in issues if i.priority == "high"]
        medium_priority = [i for i in issues if i.priority == "medium"]
        low_priority = [i for i in issues if i.priority == "low"]

        report.append("## ğŸ“Š è¿ç§»ç»Ÿè®¡\n")
        report.append(f"- ğŸ”´ é«˜ä¼˜å…ˆçº§é—®é¢˜: {len(high_priority)}")
        report.append(f"- ğŸŸ¡ ä¸­ç­‰ä¼˜å…ˆçº§é—®é¢˜: {len(medium_priority)}")
        report.append(f"- ğŸŸ¢ ä½ä¼˜å…ˆçº§é—®é¢˜: {len(low_priority)}")
        report.append(f"- ğŸ“‹ æ€»é—®é¢˜æ•°: {len(issues)}\n")

        # æŒ‰æ–‡ä»¶åˆ†ç»„
        file_issues = {}
        for issue in issues:
            file_path = issue.file_path
            if file_path not in file_issues:
                file_issues[file_path] = []
            file_issues[file_path].append(issue)

        report.append("## ğŸ“ æ–‡ä»¶è¯¦æƒ…\n")
        for file_path, file_issue_list in file_issues.items():
            report.append(f"### {file_path}")
            report.append(f"é—®é¢˜æ•°é‡: {len(file_issue_list)}\n")

            for issue in sorted(file_issue_list, key=lambda x: x.line_number):
                priority_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                    issue.priority, "âšª"
                )
                report.append(
                    f"{priority_icon} **ç¬¬{issue.line_number}è¡Œ** - {issue.issue_type}"
                )
                report.append(f"   - æè¿°: {issue.description}")
                report.append(f"   - å»ºè®®: {issue.suggested_fix}")
                report.append("")

        return "\n".join(report)


class AsyncMigrationGenerator:
    """å¼‚æ­¥åŒ–è¿ç§»ä»£ç ç”Ÿæˆå™¨"""

    def __init__(self, root_dir: str = "src"):
        self.root_dir = Path(root_dir)

    def generate_patch(self, file_path: Path, issues: list[MigrationIssue]) -> str:
        """ä¸ºå•ä¸ªæ–‡ä»¶ç”Ÿæˆè¡¥ä¸"""
        try:
            with open(file_path, encoding="utf-8") as f:
                original_content = f.read()

            modified_content = self._apply_modifications(original_content, issues)

            # ç”Ÿæˆunified diff
            original_lines = original_content.splitlines(keepends=True)
            modified_lines = modified_content.splitlines(keepends=True)

            diff = unified_diff(
                original_lines,
                modified_lines,
                fromfile=f"a/{file_path}",
                tofile=f"b/{file_path}",
                lineterm="",
            )

            return "".join(diff)

        except Exception as e:
            logger.error(f"ç”Ÿæˆè¡¥ä¸å¤±è´¥ {file_path}: {e}")
            return f"# Error generating patch for {file_path}: {str(e)}"

    def _apply_modifications(self, content: str, issues: list[MigrationIssue]) -> str:
        """åº”ç”¨ä»£ç ä¿®æ”¹"""
        lines = content.split("\n")

        # æŒ‰è¡Œå·æ’åºï¼Œä»åå¾€å‰åº”ç”¨ä¿®æ”¹ï¼Œé¿å…è¡Œå·åç§»
        sorted_issues = sorted(issues, key=lambda x: x.line_number, reverse=True)

        for issue in sorted_issues:
            line_idx = issue.line_number - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
            if 0 <= line_idx < len(lines):
                original_line = lines[line_idx]

                if issue.issue_type == "def_to_async":
                    # å°†defæ”¹ä¸ºasync def
                    lines[line_idx] = re.sub(r"^\s*def\s", "async def ", original_line)
                elif issue.issue_type == "requests_get":
                    # æ›¿æ¢requests.get
                    lines[line_idx] = re.sub(
                        r"requests\.get\(",
                        "await httpx.AsyncClient().get(",
                        original_line,
                    )
                elif issue.issue_type == "requests_post":
                    # æ›¿æ¢requests.post
                    lines[line_idx] = re.sub(
                        r"requests\.post\(",
                        "await httpx.AsyncClient().post(",
                        original_line,
                    )
                elif issue.issue_type == "time_sleep":
                    # æ›¿æ¢time.sleep
                    lines[line_idx] = re.sub(
                        r"time\.sleep\(", "await asyncio.sleep(", original_line
                    )
                elif issue.issue_type == "missing_await":
                    # åœ¨å‡½æ•°è°ƒç”¨å‰æ·»åŠ await
                    lines[line_idx] = re.sub(
                        r"(\s*)([a-zA-Z_][a-zA-Z0-9_]*\([^)]*\))",
                        r"\1await \2",
                        original_line,
                        count=1,
                    )

        return "\n".join(lines)

    def generate_all_patches(self, all_issues: list[MigrationIssue]) -> dict[str, str]:
        """ä¸ºæ‰€æœ‰æ–‡ä»¶ç”Ÿæˆè¡¥ä¸"""
        patches = {}

        # æŒ‰æ–‡ä»¶åˆ†ç»„
        file_issues = {}
        for issue in all_issues:
            file_path = issue.file_path
            if file_path not in file_issues:
                file_issues[file_path] = []
            file_issues[file_path].append(issue)

        # ä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆè¡¥ä¸
        for file_path, issues in file_issues.items():
            patch_path = Path(file_path)
            patches[str(patch_path)] = self.generate_patch(patch_path, issues)

        return patches

    def save_patches(
        self, patches: dict[str, str], output_dir: str = "patches/async_unification"
    ):
        """ä¿å­˜è¡¥ä¸æ–‡ä»¶"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        for file_path, patch_content in patches.items():
            # ç”Ÿæˆè¡¥ä¸æ–‡ä»¶å
            patch_filename = Path(file_path).name.replace(".py", ".patch")
            patch_file_path = output_path / patch_filename

            with open(patch_file_path, "w", encoding="utf-8") as f:
                f.write(patch_content)

            logger.info(f"è¡¥ä¸å·²ä¿å­˜: {patch_file_path}")


class AsyncMigrationTool:
    """å¼‚æ­¥åŒ–è¿ç§»å·¥å…·ä¸»ç±»"""

    def __init__(self, root_dir: str = "src", dry_run: bool = True):
        self.root_dir = root_dir
        self.dry_run = dry_run
        self.analyzer = AsyncMigrationAnalyzer(root_dir)
        self.generator = AsyncMigrationGenerator(root_dir)

    async def run_migration(self):
        """è¿è¡Œè¿ç§»æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å¼‚æ­¥åŒ–è¿ç§»åˆ†æ")
        logger.info(f"ğŸ“ ç›®æ ‡ç›®å½•: {self.root_dir}")
        logger.info(f"ğŸ”§ æ¨¡å¼: {'åˆ†ææ¨¡å¼' if self.dry_run else 'åº”ç”¨æ¨¡å¼'}")

        # æ­¥éª¤1: åˆ†æä»£ç 
        logger.info("ğŸ“Š æ­£åœ¨åˆ†æä»£ç ...")
        issues = self.analyzer.analyze_directory()

        if not issues:
            logger.info("âœ… æœªå‘ç°éœ€è¦è¿ç§»çš„ä»£ç ")
            return

        logger.info(f"ğŸ” å‘ç° {len(issues)} ä¸ªè¿ç§»é—®é¢˜")

        # æ­¥éª¤2: ç”ŸæˆæŠ¥å‘Š
        logger.info("ğŸ“‹ æ­£åœ¨ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")
        report = self.analyzer.generate_migration_report(issues)

        report_path = "reports/async_migration_report.md"
        Path(report_path).parent.mkdir(exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # æ­¥éª¤3: ç”Ÿæˆè¡¥ä¸ (ä»…åœ¨dry_runæ¨¡å¼ä¸‹)
        if self.dry_run:
            logger.info("ğŸ”§ æ­£åœ¨ç”Ÿæˆè¿ç§»è¡¥ä¸...")
            patches = self.generator.generate_all_patches(issues)
            self.generator.save_patches(patches)
            logger.info("âœ… è¡¥ä¸ç”Ÿæˆå®Œæˆ")
        else:
            logger.warning("âš ï¸  å®é™…åº”ç”¨æ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨ --dry-run æ¨¡å¼")

        # æ­¥éª¤4: ç”ŸæˆéªŒè¯è„šæœ¬
        await self._generate_validation_script(issues)

        logger.info("ğŸ‰ å¼‚æ­¥åŒ–è¿ç§»åˆ†æå®Œæˆ!")

    async def _generate_validation_script(self, issues: list[MigrationIssue]):
        """ç”ŸæˆéªŒè¯è„šæœ¬"""
        validation_script = """#!/usr/bin/env python3
\"\"\"
å¼‚æ­¥åŒ–è¿ç§»éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯è¿ç§»åçš„ä»£ç æ­£ç¡®æ€§

ç”Ÿæˆçš„éªŒè¯ä»»åŠ¡:
"""

        # æŒ‰æ–‡ä»¶åˆ†ç»„ç”ŸæˆéªŒè¯ä»»åŠ¡
        file_issues = {}
        for issue in issues:
            file_path = issue.file_path
            if file_path not in file_issues:
                file_issues[file_path] = []
            file_issues[file_path].append(issue)

        for file_path, _file_issue_list in file_issues.items():
            validation_script += f"""
# éªŒè¯ {file_path}
async def test_{Path(file_path).stem}():
    '''æµ‹è¯•{file_path}çš„å¼‚æ­¥åŒ–è¿ç§»ç»“æœ'''
    try:
        # å¯¼å…¥æ¨¡å—
        import sys
        sys.path.append('src')

        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“æ–‡ä»¶ç¼–å†™æµ‹è¯•
        # TODO: ä¸º {file_path} ç¼–å†™å…·ä½“çš„éªŒè¯æµ‹è¯•

        print("âœ… {file_path} éªŒè¯é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ {file_path} éªŒè¯å¤±è´¥: {{e}}")
        return False

"""

        validation_script += """
async def main():
    '''ä¸»éªŒè¯å‡½æ•°'''
    print("ğŸ” å¼€å§‹éªŒè¯å¼‚æ­¥åŒ–è¿ç§»ç»“æœ...")

    # TODO: å®ç°å…·ä½“çš„éªŒè¯é€»è¾‘
    print("âš ï¸  è¯·æ ¹æ®å…·ä½“è¿ç§»å†…å®¹å®ç°éªŒè¯é€»è¾‘")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
"""

        script_path = "scripts/validate_async_migration.py"
        with open(script_path, "w", encoding="utf-8") as f:
            f.write(validation_script)

        # ä½¿è„šæœ¬å¯æ‰§è¡Œ
        os.chmod(script_path, 0o755)
        logger.info(f"ğŸ§ª éªŒè¯è„šæœ¬å·²ç”Ÿæˆ: {script_path}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¼‚æ­¥åŒ–è¿ç§»å·¥å…·")
    parser.add_argument("--root-dir", default="src", help="æºä»£ç æ ¹ç›®å½• (é»˜è®¤: src)")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=True,
        help="åˆ†ææ¨¡å¼ï¼Œåªç”ŸæˆæŠ¥å‘Šå’Œè¡¥ä¸ (é»˜è®¤)",
    )
    parser.add_argument(
        "--apply", action="store_true", help="åº”ç”¨æ¨¡å¼ï¼Œç›´æ¥ä¿®æ”¹ä»£ç  (å®éªŒæ€§åŠŸèƒ½)"
    )

    args = parser.parse_args()

    if args.apply:
        args.dry_run = False

    # åˆ›å»ºè¿ç§»å·¥å…·å®ä¾‹
    migration_tool = AsyncMigrationTool(root_dir=args.root_dir, dry_run=args.dry_run)

    try:
        await migration_tool.run_migration()
    except KeyboardInterrupt:
        logger.info("â¹ï¸  ç”¨æˆ·ä¸­æ–­è¿ç§»")
    except Exception as e:
        logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
