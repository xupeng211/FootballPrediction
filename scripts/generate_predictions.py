#!/usr/bin/env python3
"""
æ‰¹é‡ç”Ÿæˆå†å²æ¯”èµ›é¢„æµ‹æ•°æ®
Batch Generate Historical Match Predictions

ç”¨äºå¡«è¡¥é¢„æµ‹æ•°æ®åº“çš„ç©ºç™½ï¼Œç”Ÿæˆå†å²æ¯”èµ›çš„é¢„æµ‹ç»“æœã€‚
"""

import asyncio
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

import logging
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy import text

# å¯¼å…¥æ¨ç†æœåŠ¡å’Œæ•°æ®åº“
from src.services.inference_service import InferenceService
from src.database.definitions import initialize_database
from src.config.config_manager import CONFIG_MANAGER

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
DATABASE_URL = (
    "postgresql+asyncpg://postgres:postgres-dev-password@db:5432/football_prediction"
)


class BatchPredictionGenerator:
    """æ‰¹é‡é¢„æµ‹ç”Ÿæˆå™¨"""

    def __init__(self):
        self.engine = create_async_engine(DATABASE_URL, echo=False)
        self.async_session = sessionmaker(
            self.engine, class_=AsyncSession, expire_on_commit=False
        )

    async def get_match_ids(
        self, limit: int = None, only_unpredicted: bool = True
    ) -> list[int]:
        """è·å–æ¯”èµ›IDåˆ—è¡¨

        Args:
            limit: é™åˆ¶æ•°é‡ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶
            only_unpredicted: æ˜¯å¦åªè·å–æœªé¢„æµ‹çš„æ¯”èµ›
        """
        async with self.async_session() as session:
            if only_unpredicted:
                query = text(
                    """
                    SELECT m.id FROM matches m
                    LEFT JOIN predictions p ON m.id = p.match_id
                    WHERE p.match_id IS NULL
                    ORDER BY m.match_date DESC
                    LIMIT :limit
                """
                )
            else:
                query = text(
                    "SELECT id FROM matches ORDER BY match_date DESC LIMIT :limit"
                )

            result = await session.execute(query, {"limit": limit if limit else 10000})
            return [row[0] for row in result.fetchall()]

    async def prediction_exists(self, match_id: int, user_id: int = 1) -> bool:
        """æ£€æŸ¥é¢„æµ‹æ˜¯å¦å·²å­˜åœ¨"""
        async with self.async_session() as session:
            result = await session.execute(
                text(
                    "SELECT COUNT(*) FROM predictions WHERE match_id = :match_id AND user_id = :user_id"
                ),
                {"match_id": match_id, "user_id": user_id},
            )
            count = result.scalar()
            return count > 0

    async def save_prediction(
        self,
        match_id: int,
        user_id: int = 1,
        home_win_prob: float = 0.33,
        draw_prob: float = 0.33,
        away_win_prob: float = 0.34,
        predicted_outcome: str = "home",
        confidence: float = 0.75,
    ):
        """ä¿å­˜é¢„æµ‹åˆ°æ•°æ®åº“"""
        async with self.async_session() as session:
            try:
                # æ„å»ºåˆ†æ•°å­—ç¬¦ä¸²ï¼ˆæ¨¡æ‹Ÿé¢„æµ‹åˆ†æ•°ï¼‰
                if predicted_outcome == "home":
                    score = "2-1"
                elif predicted_outcome == "away":
                    score = "1-2"
                else:
                    score = "1-1"

                await session.execute(
                    text(
                        """
                        INSERT INTO predictions
                        (user_id, match_id, score, confidence, status, created_at, updated_at)
                        VALUES
                        (:user_id, :match_id, :score, :confidence, 'COMPLETED', :created_at, :updated_at)
                    """
                    ),
                    {
                        "user_id": user_id,
                        "match_id": match_id,
                        "score": score,
                        "confidence": f"{confidence:.6f}",
                        "created_at": datetime.utcnow(),
                        "updated_at": datetime.utcnow(),
                    },
                )
                await session.commit()
                logger.info(f"âœ… å·²ä¿å­˜æ¯”èµ› {match_id} çš„é¢„æµ‹")
                return True
            except Exception:
                await session.rollback()
                logger.error(f"âŒ ä¿å­˜æ¯”èµ› {match_id} é¢„æµ‹å¤±è´¥: {e}")
                return False

    async def generate_real_prediction(self, match_id: int) -> dict[str, Any]:
        """ä¸ºæ¯”èµ›ç”ŸæˆçœŸå®çš„æ¨¡å‹é¢„æµ‹æ•°æ®"""
        try:
            # ç¡®ä¿æ•°æ®åº“å·²åˆå§‹åŒ–
            try:
                initialize_database(database_url=CONFIG_MANAGER.database_url)
            except Exception:
                logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æ¨ç†æœåŠ¡: {e}")

            # åˆå§‹åŒ–æ¨ç†æœåŠ¡
            inference_service = InferenceService()

            # è°ƒç”¨çœŸå®æ¨ç†æœåŠ¡
            logger.info(f"ğŸ§  ä½¿ç”¨AIæ¨¡å‹é¢„æµ‹æ¯”èµ› {match_id}")
            prediction_result = await inference_service.predict_match(match_id)

            if not prediction_result.get("success", False):
                logger.error(
                    f"âŒ æ¨ç†æœåŠ¡é¢„æµ‹å¤±è´¥: {prediction_result.get('error', 'Unknown error')}"
                )
                # å¦‚æœæ¨ç†å¤±è´¥ï¼Œè¿”å›åŸºç¡€é¢„æµ‹
                return {
                    "match_id": match_id,
                    "home_win_prob": 0.34,
                    "draw_prob": 0.33,
                    "away_win_prob": 0.33,
                    "predicted_outcome": "home",
                    "confidence": 0.5,
                    "status": "fallback",
                }

            # æå–æ¨ç†ç»“æœä¸­çš„å…³é”®ä¿¡æ¯
            predicted_outcome = prediction_result.get("predicted_outcome", "home")

            # ç¡®ä¿predicted_outcomeæ˜¯æœŸæœ›çš„æ ¼å¼
            if predicted_outcome == "home":
                predicted_outcome_clean = "home"
            elif predicted_outcome == "away":
                predicted_outcome_clean = "away"
            elif predicted_outcome == "draw":
                predicted_outcome_clean = "draw"
            elif predicted_outcome == "home_win":
                predicted_outcome_clean = "home"
            elif predicted_outcome == "away_win":
                predicted_outcome_clean = "away"
            elif predicted_outcome == "away_or_draw":
                # å¯¹äºaway_or_drawï¼Œé€‰æ‹©æ¦‚ç‡æ›´é«˜çš„
                if prediction_result.get("away_win_prob", 0) > prediction_result.get(
                    "draw_prob", 0
                ):
                    predicted_outcome_clean = "away"
                else:
                    predicted_outcome_clean = "draw"
            else:
                predicted_outcome_clean = "home"  # é»˜è®¤å€¼

            logger.info(
                f"âœ… AIæ¨¡å‹é¢„æµ‹æˆåŠŸ: {predicted_outcome_clean}, ç½®ä¿¡åº¦: {prediction_result.get('confidence', 0):.3f}"
            )

            return {
                "match_id": match_id,
                "home_win_prob": float(prediction_result.get("home_win_prob", 0.33)),
                "draw_prob": float(prediction_result.get("draw_prob", 0.33)),
                "away_win_prob": float(prediction_result.get("away_win_prob", 0.34)),
                "predicted_outcome": predicted_outcome_clean,
                "confidence": float(prediction_result.get("confidence", 0.5)),
                "status": "ai_generated",
            }

        except Exception:
            logger.error(f"âŒ ç”ŸæˆçœŸå®é¢„æµ‹å¤±è´¥: {e}")
            # è¿”å›åŸºç¡€é¢„æµ‹ä½œä¸ºåå¤‡
            return {
                "match_id": match_id,
                "home_win_prob": 0.34,
                "draw_prob": 0.33,
                "away_win_prob": 0.33,
                "predicted_outcome": "home",
                "confidence": 0.5,
                "status": "fallback_error",
            }

    async def batch_generate_predictions(self, batch_size: int = 50):
        """æ‰¹é‡ç”Ÿæˆé¢„æµ‹"""
        logger.info("ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆé¢„æµ‹æ•°æ®...")

        # è·å–æ¯”èµ›IDåˆ—è¡¨
        match_ids = await self.get_match_ids(batch_size)
        logger.info(f"ğŸ“‹ è·å–åˆ° {len(match_ids)} åœºæ¯”èµ›")

        success_count = 0
        failed_count = 0

        for match_id in match_ids:
            try:
                # æ£€æŸ¥é¢„æµ‹æ˜¯å¦å·²å­˜åœ¨
                if await self.prediction_exists(match_id):
                    logger.info(f"â­ï¸  æ¯”èµ› {match_id} é¢„æµ‹å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    continue

                # ç”ŸæˆçœŸå®é¢„æµ‹
                prediction = await self.generate_real_prediction(match_id)

                # ä¿å­˜åˆ°æ•°æ®åº“
                success = await self.save_prediction(
                    match_id=match_id,
                    home_win_prob=prediction["home_win_prob"],
                    draw_prob=prediction["draw_prob"],
                    away_win_prob=prediction["away_win_prob"],
                    predicted_outcome=prediction["predicted_outcome"],
                    confidence=prediction["confidence"],
                )

                if success:
                    success_count += 1
                else:
                    failed_count += 1

            except Exception:
                logger.error(f"âŒ å¤„ç†æ¯”èµ› {match_id} å¤±è´¥: {e}")
                failed_count += 1

        logger.info(f"ğŸ‰ æ‰¹é‡é¢„æµ‹ç”Ÿæˆå®Œæˆï¼æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")
        return {"success_count": success_count, "failed_count": failed_count}

    async def get_statistics(self):
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        async with self.async_session() as session:
            matches_result = await session.execute(text("SELECT COUNT(*) FROM matches"))
            predictions_result = await session.execute(
                text("SELECT COUNT(*) FROM predictions")
            )

            matches_count = matches_result.scalar()
            predictions_count = predictions_result.scalar()

            logger.info(
                f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡: æ¯”èµ› {matches_count} åœº, é¢„æµ‹ {predictions_count} æ¡"
            )

            return {
                "matches_count": matches_count,
                "predictions_count": predictions_count,
                "coverage_rate": (
                    predictions_count / matches_count if matches_count > 0 else 0
                ),
            }

    async def generate_all_predictions(self):
        """ä¸ºæ‰€æœ‰æœªé¢„æµ‹çš„æ¯”èµ›ç”Ÿæˆé¢„æµ‹"""
        logger.info("ğŸ¯ å¼€å§‹ä¸ºæ‰€æœ‰æœªé¢„æµ‹çš„æ¯”èµ›ç”Ÿæˆé¢„æµ‹...")

        # è·å–æ‰€æœ‰æœªé¢„æµ‹çš„æ¯”èµ›
        match_ids = await self.get_match_ids(limit=None, only_unpredicted=True)
        logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(match_ids)} åœºæœªé¢„æµ‹çš„æ¯”èµ›")

        success_count = 0
        failed_count = 0
        batch_size = 100

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(match_ids), batch_size):
            batch_match_ids = match_ids[i : i + batch_size]
            logger.info(
                f"æ­£åœ¨å¤„ç†ç¬¬ {i // batch_size + 1} æ‰¹ï¼Œå…± {len(batch_match_ids)} åœºæ¯”èµ›..."
            )

            for match_id in batch_match_ids:
                try:
                    # ç”ŸæˆçœŸå®é¢„æµ‹
                    prediction = await self.generate_real_prediction(match_id)

                    # ä¿å­˜åˆ°æ•°æ®åº“
                    success = await self.save_prediction(
                        match_id=match_id,
                        home_win_prob=prediction["home_win_prob"],
                        draw_prob=prediction["draw_prob"],
                        away_win_prob=prediction["away_win_prob"],
                        predicted_outcome=prediction["predicted_outcome"],
                        confidence=prediction["confidence"],
                    )

                    if success:
                        success_count += 1
                    else:
                        failed_count += 1

                except Exception:
                    logger.error(f"âŒ å¤„ç†æ¯”èµ› {match_id} å¤±è´¥: {e}")
                    failed_count += 1

            # æ¯æ‰¹å¤„ç†å®Œåæ˜¾ç¤ºè¿›åº¦
            progress = (i + len(batch_match_ids)) / len(match_ids) * 100
            logger.info(
                f"ğŸ“ˆ è¿›åº¦: {progress:.1f}% ({i + len(batch_match_ids)}/{len(match_ids)})"
            )

        logger.info(f"ğŸ‰ å…¨é‡é¢„æµ‹ç”Ÿæˆå®Œæˆï¼æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")
        return {"success_count": success_count, "failed_count": failed_count}

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        await self.engine.dispose()


async def main():
    """ä¸»å‡½æ•°"""
    import sys

    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    generate_all = "--all" in sys.argv or len(sys.argv) > 1 and sys.argv[1] == "all"

    logger.info("ğŸƒâ€â™‚ï¸ å¯åŠ¨æ‰¹é‡é¢„æµ‹ç”Ÿæˆå™¨")

    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        initialize_database(database_url=CONFIG_MANAGER.database_url)
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
    except Exception:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        raise

    generator = BatchPredictionGenerator()

    try:
        # è·å–åˆå§‹ç»Ÿè®¡
        await generator.get_statistics()

        if generate_all:
            # æ‰§è¡Œå…¨é‡é¢„æµ‹
            logger.info("ğŸ¯ å¼€å§‹å…¨é‡é¢„æµ‹ç”Ÿæˆæ¨¡å¼")
            await generator.generate_all_predictions()
        else:
            # å°æ‰¹é‡æµ‹è¯•
            logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ - ç”Ÿæˆå°‘é‡é¢„æµ‹")
            await generator.batch_generate_predictions(batch_size=20)

        # è·å–æœ€ç»ˆç»Ÿè®¡
        await generator.get_statistics()

        logger.info("âœ… é¢„æµ‹ç”Ÿæˆä»»åŠ¡å®Œæˆ")

    except Exception:
        logger.error(f"âŒ é¢„æµ‹ç”Ÿæˆå¤±è´¥: {e}")
        raise
    finally:
        await generator.close()


if __name__ == "__main__":
    asyncio.run(main())
