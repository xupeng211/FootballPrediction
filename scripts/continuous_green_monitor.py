#!/usr/bin/env python3
"""
æŒç»­ç»¿ç¯ç›‘æ§æœåŠ¡
ç¡®ä¿æ‰€æœ‰CI/CDå·¥ä½œæµæŒç»­ä¿æŒç»¿ç¯çŠ¶æ€
"""

import json
import logging
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from subprocess import PIPE, Popen, run
from typing import Dict, List, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("logs/green_monitor.log"), logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)


class WorkflowMonitor:
    """å·¥ä½œæµç›‘æ§å™¨"""

    def __init__(self, check_interval: int = 300):  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        self.check_interval = check_interval
        self.state_file = Path("logs/monitor_state.json")
        self.alert_threshold = 3  # è¿ç»­å¤±è´¥3æ¬¡è§¦å‘å‘Šè­¦
        self.ensure_log_directory()

    def ensure_log_directory(self):
        """ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨"""
        Path("logs").mkdir(exist_ok=True)

    def load_state(self) -> Dict:
        """åŠ è½½ç›‘æ§çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½çŠ¶æ€æ–‡ä»¶: {e}")

        return {"last_check": None, "workflow_status": {}, "failure_counts": {}, "alerts_sent": []}

    def save_state(self, state: Dict):
        """ä¿å­˜ç›‘æ§çŠ¶æ€"""
        try:
            with open(self.state_file, "w", encoding="utf-8") as f:
                json.dump(state, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"æ— æ³•ä¿å­˜çŠ¶æ€æ–‡ä»¶: {e}")

    def run_command(self, command: str, capture_output: bool = True) -> Dict:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            if capture_output:
                result = run(command, shell=True, capture_output=True, text=True, timeout=30)
                return {
                    "success": result.returncode == 0,
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                }
            else:
                process = Popen(command, shell=True, stdout=PIPE, stderr=PIPE, text=True)
                return {"success": True, "process": process}
        except Exception as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {command}, é”™è¯¯: {e}")
            return {"success": False, "error": str(e)}

    def check_workflow_status(self, workflow_name: str) -> Dict:
        """æ£€æŸ¥ç‰¹å®šå·¥ä½œæµçŠ¶æ€"""
        logger.info(f"æ£€æŸ¥å·¥ä½œæµ: {workflow_name}")

        # ä½¿ç”¨gh CLIè·å–å·¥ä½œæµçŠ¶æ€
        command = f'gh run list --workflow="{workflow_name}" --limit=3 --json status,conclusion,headBranch,createdAt'
        result = self.run_command(command)

        if not result["success"]:
            logger.error(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {workflow_name}")
            return {
                "workflow": workflow_name,
                "status": "error",
                "success": False,
                "error": result.get("error", "æœªçŸ¥é”™è¯¯"),
            }

        try:
            data = json.loads(result["stdout"])
            if not data:
                return {
                    "workflow": workflow_name,
                    "status": "no_runs",
                    "success": False,
                    "error": "æ²¡æœ‰æ‰¾åˆ°è¿è¡Œè®°å½•",
                }

            latest = data[0]
            status = latest.get("status", "unknown")
            conclusion = latest.get("conclusion", "unknown")
            branch = latest.get("headBranch", "unknown")
            created_at = latest.get("createdAt", "")

            # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
            is_success = status == "completed" and conclusion == "success"

            return {
                "workflow": workflow_name,
                "status": status,
                "conclusion": conclusion,
                "branch": branch,
                "created_at": created_at,
                "success": is_success,
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"è§£æå·¥ä½œæµçŠ¶æ€å¤±è´¥: {workflow_name}, é”™è¯¯: {e}")
            return {
                "workflow": workflow_name,
                "status": "parse_error",
                "success": False,
                "error": str(e),
            }

    def check_all_workflows(self) -> Dict:
        """æ£€æŸ¥æ‰€æœ‰å·¥ä½œæµçŠ¶æ€"""
        workflows = [
            "Main CI/CD Pipeline",
            "ğŸ¤– Automated Testing Pipeline (Simplified)",
            "æµ‹è¯•å·¥ä½œæµ",
            "è´¨é‡å®ˆæŠ¤ç³»ç»Ÿé›†æˆ",
            "é¡¹ç›®å¥åº·ç›‘æ§",
            "ğŸ§  æ™ºèƒ½è´¨é‡ç›‘æ§",
        ]

        results = {}
        for workflow in workflows:
            results[workflow] = self.check_workflow_status(workflow)
            time.sleep(1)  # é¿å…APIé™åˆ¶

        return results

    def analyze_results(self, results: Dict, state: Dict) -> List[Dict]:
        """åˆ†æç»“æœå¹¶ç”Ÿæˆå‘Šè­¦"""
        alerts = []
        workflow_status = state.get("workflow_status", {})
        failure_counts = state.get("failure_counts", {})

        for workflow, result in results.items():
            workflow_name = workflow
            is_success = result.get("success", False)

            # æ›´æ–°å¤±è´¥è®¡æ•°
            if not is_success:
                failure_counts[workflow_name] = failure_counts.get(workflow_name, 0) + 1
            else:
                failure_counts[workflow_name] = 0

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
            if failure_counts[workflow_name] >= self.alert_threshold:
                alert = {
                    "type": "workflow_failure",
                    "workflow": workflow_name,
                    "failure_count": failure_counts[workflow_name],
                    "latest_status": result.get("status", "unknown"),
                    "latest_conclusion": result.get("conclusion", "unknown"),
                    "message": f"å·¥ä½œæµ {workflow_name} è¿ç»­å¤±è´¥ {failure_counts[workflow_name]} æ¬¡",
                    "timestamp": datetime.now().isoformat(),
                }
                alerts.append(alert)

            # æ£€æŸ¥çŠ¶æ€å˜åŒ–
            previous_status = workflow_status.get(workflow_name, {})
            if previous_status.get("success") != is_success:
                change_alert = {
                    "type": "status_change",
                    "workflow": workflow_name,
                    "previous_success": previous_status.get("success"),
                    "current_success": is_success,
                    "message": f"å·¥ä½œæµ {workflow_name} çŠ¶æ€ä» {'æˆåŠŸ' if previous_status.get('success') else 'å¤±è´¥'} å˜ä¸º {'æˆåŠŸ' if is_success else 'å¤±è´¥'}",
                    "timestamp": datetime.now().isoformat(),
                }
                alerts.append(change_alert)

        # æ›´æ–°çŠ¶æ€
        state["workflow_status"] = results
        state["failure_counts"] = failure_counts

        return alerts

    def send_alert(self, alert: Dict):
        """å‘é€å‘Šè­¦"""
        logger.warning(f"ğŸš¨ å‘Šè­¦: {alert['message']}")

        # è¿™é‡Œå¯ä»¥æ‰©å±•å‘é€åˆ°å…¶ä»–æ¸ é“ï¼ˆé‚®ä»¶ã€Slackç­‰ï¼‰
        # ç›®å‰åªè®°å½•åˆ°æ—¥å¿—

    def generate_report(self, results: Dict) -> Dict:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        total_workflows = len(results)
        successful_workflows = sum(1 for r in results.values() if r.get("success", False))
        success_rate = (successful_workflows / total_workflows * 100) if total_workflows > 0 else 0

        report = {
            "timestamp": datetime.now().isoformat(),
            "total_workflows": total_workflows,
            "successful_workflows": successful_workflows,
            "failed_workflows": total_workflows - successful_workflows,
            "success_rate": round(success_rate, 2),
            "all_green": success_rate == 100,
            "workflows": results,
        }

        return report

    def save_report(self, report: Dict):
        """ä¿å­˜ç›‘æ§æŠ¥å‘Š"""
        report_file = Path("logs/latest_monitor_report.json")
        try:
            with open(report_file, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"æ— æ³•ä¿å­˜æŠ¥å‘Š: {e}")

    def run_once(self) -> bool:
        """è¿è¡Œä¸€æ¬¡æ£€æŸ¥"""
        logger.info("ğŸ” å¼€å§‹æ£€æŸ¥å·¥ä½œæµçŠ¶æ€...")

        # åŠ è½½çŠ¶æ€
        state = self.load_state()

        # æ£€æŸ¥æ‰€æœ‰å·¥ä½œæµ
        results = self.check_all_workflows()

        # åˆ†æç»“æœ
        alerts = self.analyze_results(results, state)

        # å‘é€å‘Šè­¦
        for alert in alerts:
            self.send_alert(alert)
            state["alerts_sent"].append(alert)

        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(results)

        # ä¿å­˜æŠ¥å‘Š
        self.save_report(report)

        # æ›´æ–°çŠ¶æ€
        state["last_check"] = datetime.now().isoformat()
        self.save_state(state)

        # è¾“å‡ºæ‘˜è¦
        if report["all_green"]:
            logger.info(f"ğŸ‰ æ‰€æœ‰å·¥ä½œæµéƒ½æ˜¯ç»¿ç¯ï¼æˆåŠŸç‡: {report['success_rate']}%")
        else:
            logger.warning(
                f"âš ï¸ å·¥ä½œæµçŠ¶æ€: {report['successful_workflows']}/{report['total_workflows']} æˆåŠŸ ({report['success_rate']}%)"
            )

        return report["all_green"]

    def run_continuous(self):
        """æŒç»­è¿è¡Œç›‘æ§"""
        logger.info(f"ğŸš¦ å¯åŠ¨æŒç»­ç»¿ç¯ç›‘æ§ï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}ç§’")

        while True:
            try:
                self.run_once()
                logger.info(f"â° ç­‰å¾… {self.check_interval} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥...")
                time.sleep(self.check_interval)

            except KeyboardInterrupt:
                logger.info("ğŸ‘‹ ç›‘æ§æœåŠ¡å·²åœæ­¢")
                break
            except Exception as e:
                logger.error(f"ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                logger.info("ç­‰å¾…30ç§’åé‡è¯•...")
                time.sleep(30)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æŒç»­ç»¿ç¯ç›‘æ§æœåŠ¡")
    parser.add_argument("--interval", type=int, default=300, help="æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--once", action="store_true", help="åªè¿è¡Œä¸€æ¬¡æ£€æŸ¥")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆå¹¶æ˜¾ç¤ºæœ€æ–°æŠ¥å‘Š")

    args = parser.parse_args()

    monitor = WorkflowMonitor(check_interval=args.interval)

    if args.report:
        # æ˜¾ç¤ºæœ€æ–°æŠ¥å‘Š
        report_file = Path("logs/latest_monitor_report.json")
        if report_file.exists():
            with open(report_file, "r", encoding="utf-8") as f:
                report = json.load(f)

            print("ğŸ“Š æœ€æ–°ç›‘æ§æŠ¥å‘Š:")
            print(f"æ—¶é—´: {report['timestamp']}")
            print(f"æ€»è®¡: {report['total_workflows']} ä¸ªå·¥ä½œæµ")
            print(f"æˆåŠŸ: {report['successful_workflows']} ä¸ª")
            print(f"å¤±è´¥: {report['failed_workflows']} ä¸ª")
            print(f"æˆåŠŸç‡: {report['success_rate']}%")
            print(f"å…¨éƒ¨ç»¿ç¯: {'æ˜¯' if report['all_green'] else 'å¦'}")

            if not report["all_green"]:
                print("\nâŒ å¤±è´¥çš„å·¥ä½œæµ:")
                for name, result in report["workflows"].items():
                    if not result.get("success", False):
                        print(
                            f"  - {name}: {result.get('status', 'unknown')}/{result.get('conclusion', 'unknown')}"
                        )
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›‘æ§æŠ¥å‘Š")

    elif args.once:
        # åªè¿è¡Œä¸€æ¬¡
        success = monitor.run_once()
        sys.exit(0 if success else 1)

    else:
        # æŒç»­è¿è¡Œ
        monitor.run_continuous()


if __name__ == "__main__":
    main()
