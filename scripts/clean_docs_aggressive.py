#!/usr/bin/env python3
"""
Docsç›®å½•æ·±åº¦æ¸…ç†è„šæœ¬
æ›´æ¿€è¿›åœ°æ¸…ç†ä¸å¿…è¦çš„æ–‡ä»¶
"""

import os
import shutil
from pathlib import Path
import tarfile


def clean_docs_aggressive():
    """æ¿€è¿›åœ°æ¸…ç†docsç›®å½•"""
    docs_path = Path("docs")

    print("ğŸ”¥ å¼€å§‹æ·±åº¦æ¸…ç†docsç›®å½•...")

    # 1. åˆ é™¤æ—§çš„å½’æ¡£æ–‡ä»¶
    print("\n1ï¸âƒ£ æ¸…ç†å½’æ¡£æ–‡ä»¶...")
    archive_files = [
        docs_path / "_reports/archive/legacy_archive_2025-10-04.tar.gz",
        docs_path / "_reports/archive/legacy_archive.tar.gz",
        docs_path / "_reports/archive/old_docs.tar.gz",
    ]

    removed_archives = 0
    for archive_file in archive_files:
        if archive_file.exists():
            size_mb = archive_file.stat().st_size / (1024 * 1024)
            print(f"   åˆ é™¤å½’æ¡£æ–‡ä»¶: {archive_file.name} ({size_mb:.1f}MB)")
            archive_file.unlink()
            removed_archives += 1

    print(f"   âœ… åˆ é™¤äº† {removed_archives} ä¸ªå½’æ¡£æ–‡ä»¶")

    # 2. åˆ é™¤ç¤ºä¾‹å’Œæµ‹è¯•æ–‡æ¡£
    print("\n2ï¸âƒ£ æ¸…ç†ç¤ºä¾‹å’Œæµ‹è¯•æ–‡æ¡£...")
    example_patterns = [
        "testing/examples.md",
        "testing/sample_*.md",
        "testing/test_*.md",
        "how-to/examples/",
        "samples/",
        "examples/",
        "demo/",
        "test_docs/",
    ]

    removed_examples = 0
    for pattern in example_patterns:
        for path in docs_path.glob(pattern):
            if path.is_file():
                print(f"   åˆ é™¤ç¤ºä¾‹æ–‡ä»¶: {path.relative_to(docs_path)}")
                path.unlink()
                removed_examples += 1
            elif path.is_dir():
                print(f"   åˆ é™¤ç¤ºä¾‹ç›®å½•: {path.relative_to(docs_path)}")
                shutil.rmtree(path)
                removed_examples += 1

    print(f"   âœ… åˆ é™¤äº† {removed_examples} ä¸ªç¤ºä¾‹æ–‡ä»¶/ç›®å½•")

    # 3. æ¸…ç†è¿‡æ—¶çš„æŠ¥å‘Š
    print("\n3ï¸âƒ£ æ¸…ç†è¿‡æ—¶çš„æŠ¥å‘Š...")
    report_dir = docs_path / "_reports/archive/2025-09"
    if report_dir.exists():
        old_reports = ["cleanup", "deployment", "migration", "performance"]

        removed_reports = 0
        for report_type in old_reports:
            report_path = report_dir / report_type
            if report_path.exists():
                print(f"   åˆ é™¤è¿‡æ—¶æŠ¥å‘Š: {report_path.relative_to(docs_path)}")
                shutil.rmtree(report_path)
                removed_reports += 1

        print(f"   âœ… åˆ é™¤äº† {removed_reports} ä¸ªè¿‡æ—¶æŠ¥å‘Šç›®å½•")

    # 4. åˆ é™¤å†—ä½™çš„å¤§å‹æ–‡æ¡£
    print("\n4ï¸âƒ£ æ£€æŸ¥å¤§å‹æ–‡æ¡£...")
    large_files_to_check = [
        ("architecture/DATA_DESIGN.md", "æ¶æ„è®¾è®¡æ–‡æ¡£"),
        ("how-to/PRODUCTION_DEPLOYMENT_GUIDE.md", "ç”Ÿäº§éƒ¨ç½²æŒ‡å—"),
        ("testing/ci_config.md", "CIé…ç½®æ–‡æ¡£"),
        ("testing/performance_tests.md", "æ€§èƒ½æµ‹è¯•æ–‡æ¡£"),
    ]

    for file_path, description in large_files_to_check:
        full_path = docs_path / file_path
        if full_path.exists():
            size_kb = full_path.stat().st_size / 1024
            print(f"   {description}: {file_path} ({size_kb:.1f}KB)")

    # 5. æ¸…ç†ç©ºçš„ç´¢å¼•æ–‡ä»¶
    print("\n5ï¸âƒ£ æ¸…ç†ç©ºæˆ–æ— ç”¨çš„ç´¢å¼•æ–‡ä»¶...")
    index_files = [
        docs_path / "_sidebar.md",
        docs_path / "_navbar.md",
        docs_path / "summary.md",
    ]

    removed_indices = 0
    for index_file in index_files:
        if index_file.exists():
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¾ˆå°æˆ–å†…å®¹å¾ˆå°‘
            if index_file.stat().st_size < 100:
                print(f"   åˆ é™¤å°å‹ç´¢å¼•æ–‡ä»¶: {index_file.name}")
                index_file.unlink()
                removed_indices += 1

    print(f"   âœ… åˆ é™¤äº† {removed_indices} ä¸ªå°å‹ç´¢å¼•æ–‡ä»¶")

    # 6. å‹ç¼©ç‰¹åˆ«å¤§çš„æ–‡ä»¶
    print("\n6ï¸âƒ£ å‹ç¼©å¤§æ–‡ä»¶...")
    very_large_files = [docs_path / "architecture/DATA_DESIGN.md"]

    compressed_files = 0
    for file_path in very_large_files:
        if file_path.exists() and file_path.stat().st_size > 150 * 1024:  # >150KB
            # åˆ›å»ºå‹ç¼©ç‰ˆæœ¬
            gz_path = file_path.with_suffix(file_path.suffix + ".gz")
            if not gz_path.exists():
                print(f"   å‹ç¼©å¤§æ–‡ä»¶: {file_path.name}")
                with open(file_path, "rb") as f_in:
                    with open(gz_path, "wb") as f_out:
                        shutil.copyfileobj(f_in, f_out)
                # åˆ é™¤åŸæ–‡ä»¶
                file_path.unlink()
                compressed_files += 1

    print(f"   âœ… å‹ç¼©äº† {compressed_files} ä¸ªå¤§æ–‡ä»¶")

    # 7. æœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡ï¼š")

    # è®¡ç®—æ¸…ç†åçš„æ–‡ä»¶æ•°å’Œå¤§å°
    total_files = len(list(docs_path.rglob("*.md")))
    total_size_mb = sum(
        f.stat().st_size for f in docs_path.rglob("*") if f.is_file()
    ) / (1024 * 1024)

    print(f"   - å‰©ä½™Markdownæ–‡ä»¶æ•°: {total_files}")
    print(f"   - å‰©ä½™ç›®å½•å¤§å°: {total_size_mb:.2f}MB")
    print(f"   - åˆ é™¤å½’æ¡£æ–‡ä»¶: {removed_archives}")
    print(f"   - åˆ é™¤ç¤ºä¾‹æ–‡ä»¶: {removed_examples}")
    print(
        f"   - åˆ é™¤è¿‡æ—¶æŠ¥å‘Š: {removed_reports if 'removed_reports' in locals() else 0}"
    )
    print(f"   - åˆ é™¤ç´¢å¼•æ–‡ä»¶: {removed_indices}")
    print(
        f"   - å‹ç¼©å¤§æ–‡ä»¶: {compressed_files if 'compressed_files' in locals() else 0}"
    )

    # 8. æä¾›è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®
    print("\nğŸ’¡ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®ï¼š")
    print("   1. è€ƒè™‘å°†å¤§å‹æ–‡æ¡£æ‹†åˆ†æˆå¤šä¸ªå°æ–‡æ¡£")
    print("   2. ä½¿ç”¨å›¾ç‰‡å‹ç¼©å·¥å…·ä¼˜åŒ–docsä¸­çš„å›¾ç‰‡")
    print("   3. è€ƒè™‘å°†ä¸å¸¸ç”¨çš„æ–‡æ¡£ç§»åŠ¨åˆ°wikiæˆ–å•ç‹¬çš„ä»“åº“")

    print("\nâœ… docsç›®å½•æ·±åº¦æ¸…ç†å®Œæˆï¼")


if __name__ == "__main__":
    clean_docs_aggressive()
