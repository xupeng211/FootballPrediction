#!/usr/bin/env python3
"""
ğŸ¤– AIç¼–ç¨‹å‹å¥½Issueåˆ†æå™¨
è‡ªåŠ¨åˆ†æGitHub Issueï¼Œä¸ºAIç¼–ç¨‹åŠ©æ‰‹æä¾›ä¿®å¤å»ºè®®

ç‰ˆæœ¬: v1.0 | åˆ›å»ºæ—¶é—´: 2025-10-26 | ä½œè€…: Claude AI Assistant
"""

import os
import sys
import json
import re
import argparse
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass

@dataclass
class IssueAnalysis:
    """Issueåˆ†æç»“æœ"""
    title: str
    body: str
    labels: List[str]
    priority: str
    issue_type: str
    suggested_commands: List[str]
    affected_files: List[str]
    related_workflows: List[str]
    estimated_effort: str
    auto_fixable: bool

class AIIssueAnalyzer:
    """AIç¼–ç¨‹å‹å¥½Issueåˆ†æå™¨"""

    def __init__(self):
        self.root_dir = Path(__file__).parent.parent
        self.issue_patterns = self._load_issue_patterns()
        self.fix_commands = self._load_fix_commands()
        self.workflow_mappings = self._load_workflow_mappings()

    def _load_issue_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½Issueè¯†åˆ«æ¨¡å¼"""
        return {
            "syntax_error": [
                r"SyntaxError",
                r"è¯­æ³•é”™è¯¯",
                r"invalid syntax",
                r"Unexpected EOF"
            ],
            "type_error": [
                r"MyPy.*error",
                r"type.*error",
                r"ç±»å‹é”™è¯¯",
                r"Argument.*not.*assignable"
            ],
            "import_error": [
                r"ModuleNotFoundError",
                r"ImportError",
                r"æ¨¡å—æœªæ‰¾åˆ°",
                r"cannot import"
            ],
            "test_failure": [
                r"test.*failed",
                r"pytest.*failed",
                r"æµ‹è¯•å¤±è´¥",
                r"assertion.*error"
            ],
            "coverage_issue": [
                r"coverage.*low",
                r"è¦†ç›–ç‡.*ä½",
                r"cov-fail-under",
                r"test coverage"
            ],
            "lint_error": [
                r"Ruff.*error",
                r"ä»£ç é£æ ¼.*é”™è¯¯",
                r"format.*error",
                r"lint.*failed"
            ],
            "security_issue": [
                r"Bandit.*error",
                r"å®‰å…¨.*é—®é¢˜",
                r"vulnerability",
                r"pip-audit"
            ],
            "dependency_issue": [
                r"ä¾èµ–.*é—®é¢˜",
                r"pip install.*failed",
                r"package.*not found",
                r"version.*conflict"
            ],
            "ci_failure": [
                r"CI.*failed",
                r"workflow.*failed",
                r"GitHub Actions.*failed",
                r"build.*failed"
            ]
        }

    def _load_fix_commands(self) -> Dict[str, List[str]]:
        """åŠ è½½ä¿®å¤å‘½ä»¤"""
        return {
            "syntax_error": [
                "python -m py_compile src/**/*.py",
                "python scripts/smart_quality_fixer.py --syntax-only",
                "find . -name '*.py' -exec python -m py_compile {} \\;"
            ],
            "type_error": [
                "python scripts/smart_mypy_fixer.py",
                "mypy src/ --config-file mypy_minimum.ini",
                "python scripts/quality_guardian.py --check-only --type-check"
            ],
            "import_error": [
                "make install",
                "python scripts/smart_quality_fixer.py --imports-only",
                "pip install -r requirements/requirements.lock"
            ],
            "test_failure": [
                "make test-quick",
                "pytest tests/unit/ -v --tb=short",
                "python scripts/smart_quality_fixer.py --test-fix"
            ],
            "coverage_issue": [
                "make coverage-targeted MODULE=<module>",
                "pytest tests/unit/ --cov=src/ --cov-report=term-missing",
                "python scripts/improvement_monitor.py"
            ],
            "lint_error": [
                "make fmt",
                "ruff format src/",
                "ruff check src/ --fix"
            ],
            "security_issue": [
                "make security-check",
                "bandit -r src/ -f json -o bandit-report.json",
                "pip-audit --format=json --output=audit-report.json"
            ],
            "dependency_issue": [
                "make install-locked",
                "pip install --upgrade pip",
                "pip install -r requirements/base.txt"
            ],
            "ci_failure": [
                "./ci-verify.sh",
                "make ci",
                "make prepush"
            ]
        }

    def _load_workflow_mappings(self) -> Dict[str, List[str]]:
        """åŠ è½½é—®é¢˜ç±»å‹åˆ°å·¥ä½œæµçš„æ˜ å°„"""
        return {
            "syntax_error": ["main-ci-optimized.yml"],
            "type_error": ["main-ci-optimized.yml", "project-health-monitor.yml"],
            "import_error": ["main-ci-optimized.yml", "automated-testing.yml"],
            "test_failure": ["main-ci-optimized.yml", "automated-testing.yml", "nightly-tests.yml"],
            "coverage_issue": ["test-guard.yml", "project-health-monitor.yml", "nightly-tests.yml"],
            "lint_error": ["main-ci-optimized.yml", "project-health-monitor.yml"],
            "security_issue": ["main-ci-optimized.yml", "automated-testing.yml"],
            "dependency_issue": ["main-ci-optimized.yml", "automated-testing.yml"],
            "ci_failure": ["main-ci-optimized.yml", "project-health-monitor.yml"]
        }

    def analyze_issue(self, title: str, body: str) -> IssueAnalysis:
        """åˆ†æGitHub Issue"""
        content = f"{title} {body}".lower()

        # è¯†åˆ«é—®é¢˜ç±»å‹
        issue_type = self._identify_issue_type(content)

        # ç¡®å®šä¼˜å…ˆçº§
        priority = self._determine_priority(title, body, issue_type)

        # æå–ç›¸å…³æ–‡ä»¶
        affected_files = self._extract_files(title, body)

        # è·å–å»ºè®®å‘½ä»¤
        suggested_commands = self.fix_commands.get(issue_type, [])

        # è·å–ç›¸å…³å·¥ä½œæµ
        related_workflows = self.workflow_mappings.get(issue_type, [])

        # ä¼°ç®—å·¥ä½œé‡
        estimated_effort = self._estimate_effort(issue_type, content)

        # åˆ¤æ–­æ˜¯å¦å¯è‡ªåŠ¨ä¿®å¤
        auto_fixable = self._is_auto_fixable(issue_type, content)

        # ç”Ÿæˆæ ‡ç­¾
        labels = self._generate_labels(issue_type, priority, auto_fixable)

        return IssueAnalysis(
            title=title,
            body=body,
            labels=labels,
            priority=priority,
            issue_type=issue_type,
            suggested_commands=suggested_commands,
            affected_files=affected_files,
            related_workflows=related_workflows,
            estimated_effort=estimated_effort,
            auto_fixable=auto_fixable
        )

    def _identify_issue_type(self, content: str) -> str:
        """è¯†åˆ«é—®é¢˜ç±»å‹"""
        for issue_type, patterns in self.issue_patterns.items():
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return issue_type
        return "general"

    def _determine_priority(self, title: str, body: str, issue_type: str) -> str:
        """ç¡®å®šä¼˜å…ˆçº§"""
        content = f"{title} {body}".lower()

        # ç´§æ€¥å…³é”®è¯
        urgent_keywords = ["urgent", "ç´§æ€¥", "critical", "ä¸¥é‡", "blocker", "é˜»å¡"]
        if any(keyword in content for keyword in urgent_keywords):
            return "high"

        # é«˜ä¼˜å…ˆçº§é—®é¢˜ç±»å‹
        high_priority_types = ["syntax_error", "security_issue", "ci_failure"]
        if issue_type in high_priority_types:
            return "high"

        # ä¸­ä¼˜å…ˆçº§é—®é¢˜ç±»å‹
        medium_priority_types = ["type_error", "test_failure", "import_error"]
        if issue_type in medium_priority_types:
            return "medium"

        return "low"

    def _extract_files(self, title: str, body: str) -> List[str]:
        """æå–ç›¸å…³æ–‡ä»¶è·¯å¾„"""
        content = f"{title} {body}"
        files = []

        # åŒ¹é…Pythonæ–‡ä»¶è·¯å¾„
        python_files = re.findall(r'\b([\w/]+\.py)\b', content)
        files.extend(python_files)

        # åŒ¹é…src/è·¯å¾„
        src_files = re.findall(r'\b(src/[\w/]+)\b', content)
        files.extend(src_files)

        # åŒ¹é…tests/è·¯å¾„
        test_files = re.findall(r'\b(tests/[\w/]+)\b', content)
        files.extend(test_files)

        return list(set(files))

    def _estimate_effort(self, issue_type: str, content: str) -> str:
        """ä¼°ç®—ä¿®å¤å·¥ä½œé‡"""
        effort_mapping = {
            "syntax_error": "5-15åˆ†é’Ÿ",
            "lint_error": "5-15åˆ†é’Ÿ",
            "import_error": "10-30åˆ†é’Ÿ",
            "type_error": "30-60åˆ†é’Ÿ",
            "test_failure": "30-120åˆ†é’Ÿ",
            "coverage_issue": "60-240åˆ†é’Ÿ",
            "security_issue": "120-480åˆ†é’Ÿ",
            "dependency_issue": "15-60åˆ†é’Ÿ",
            "ci_failure": "30-120åˆ†é’Ÿ",
            "general": "60-240åˆ†é’Ÿ"
        }
        return effort_mapping.get(issue_type, "60-240åˆ†é’Ÿ")

    def _is_auto_fixable(self, issue_type: str, content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯è‡ªåŠ¨ä¿®å¤"""
        auto_fixable_types = [
            "syntax_error", "lint_error", "import_error",
            "dependency_issue", "coverage_issue"
        ]

        if issue_type not in auto_fixable_types:
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰å¤æ‚å…³é”®è¯
        complex_keywords = ["complex", "å¤æ‚", "architecture", "æ¶æ„", "design", "è®¾è®¡"]
        if any(keyword in content for keyword in complex_keywords):
            return False

        return True

    def _generate_labels(self, issue_type: str, priority: str, auto_fixable: bool) -> List[str]:
        """ç”ŸæˆIssueæ ‡ç­¾"""
        labels = ["ai-programming"]

        # ä¼˜å…ˆçº§æ ‡ç­¾
        labels.append(f"priority/{priority}")

        # é—®é¢˜ç±»å‹æ ‡ç­¾
        if issue_type != "general":
            labels.append(issue_type)

        # è‡ªåŠ¨ä¿®å¤æ ‡ç­¾
        if auto_fixable:
            labels.append("auto-fixable")

        # AIç¼–ç¨‹ç›¸å…³æ ‡ç­¾
        if "test" in issue_type:
            labels.append("testing")
        if "ci" in issue_type or "coverage" in issue_type:
            labels.append("ci/cd")

        return labels

    def generate_ai_friendly_comment(self, analysis: IssueAnalysis) -> str:
        """ç”ŸæˆAIç¼–ç¨‹å‹å¥½çš„è¯„è®º"""
        comment = f"""## ğŸ¤– AIç¼–ç¨‹åŠ©æ‰‹åˆ†ææŠ¥å‘Š

### ğŸ“‹ é—®é¢˜åˆ†æ
- **é—®é¢˜ç±»å‹**: {analysis.issue_type}
- **ä¼˜å…ˆçº§**: {analysis.priority}
- **é¢„è®¡ä¿®å¤æ—¶é—´**: {analysis.estimated_effort}
- **å¯è‡ªåŠ¨ä¿®å¤**: {'æ˜¯' if analysis.auto_fixable else 'å¦'}

### ğŸ”§ AIç¼–ç¨‹åŠ©æ‰‹å»ºè®®

#### æ¨èä¿®å¤å‘½ä»¤:
```bash
# æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹å‘½ä»¤
{chr(10).join(f"# {cmd}" for cmd in analysis.suggested_commands)}
```

#### ç›¸å…³å·¥ä½œæµ:
{chr(10).join(f"- [{workflow}](.github/workflows/{workflow})" for workflow in analysis.related_workflows)}

#### AIç¼–ç¨‹å·¥å…·ä½¿ç”¨å»ºè®®:
"""

        if analysis.auto_fixable:
            comment += """
âœ¨ **è‡ªåŠ¨ä¿®å¤å»ºè®®**:
è¿™ä¸ªé—®é¢˜çœ‹èµ·æ¥å¯ä»¥è‡ªåŠ¨ä¿®å¤ï¼ä½ å¯ä»¥å°è¯•:

1. **ä½¿ç”¨è´¨é‡å®ˆæŠ¤ç³»ç»Ÿ**:
   ```bash
   python3 scripts/quality_guardian.py --check-only
   python3 scripts/smart_quality_fixer.py
   ```

2. **éªŒè¯ä¿®å¤æ•ˆæœ**:
   ```bash
   python3 scripts/improvement_monitor.py
   ```
"""

        if analysis.affected_files:
            comment += f"""
ğŸ“ **ç›¸å…³æ–‡ä»¶**:
{chr(10).join(f"- `{file}`" for file in analysis.affected_files)}
"""

        comment += f"""
### ğŸ¯ Claude Codeå·¥ä½œæµç¨‹

1. **ç¯å¢ƒæ£€æŸ¥**:
   ```bash
   make env-check
   ```

2. **å¿«é€Ÿè´¨é‡æ£€æŸ¥**:
   ```bash
   python3 scripts/quality_guardian.py --check-only
   ```

3. **æ™ºèƒ½ä¿®å¤**:
   ```bash
   python3 scripts/smart_quality_fixer.py
   ```

4. **éªŒè¯ä¿®å¤**:
   ```bash
   make test-quick
   ```

5. **å®Œæ•´éªŒè¯**:
   ```bash
   make prepush
   ```

### ğŸ“š å‚è€ƒèµ„æ–™
- [CLAUDE.md](CLAUDE.md) - AIç¼–ç¨‹åŠ©æ‰‹ä½¿ç”¨æŒ‡å—
- [è´¨é‡å®ˆæŠ¤ç³»ç»ŸæŒ‡å—](docs/QUALITY_GUARDIAN_SYSTEM_GUIDE.md)
- [æµ‹è¯•æ”¹è¿›æŒ‡å—](docs/testing/TEST_IMPROVEMENT_GUIDE.md)

---
*ğŸ¤– æ­¤åˆ†æç”±AIç¼–ç¨‹åŠ©æ‰‹åˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆ | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

        return comment

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AIç¼–ç¨‹å‹å¥½Issueåˆ†æå™¨")
    parser.add_argument("--title", required=True, help="Issueæ ‡é¢˜")
    parser.add_argument("--body", required=True, help="Issueå†…å®¹")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--comment", action="store_true", help="ç”ŸæˆAIå‹å¥½è¯„è®º")

    args = parser.parse_args()

    analyzer = AIIssueAnalyzer()
    analysis = analyzer.analyze_issue(args.title, args.body)

    if args.comment:
        output = analyzer.generate_ai_friendly_comment(analysis)
    else:
        output = json.dumps(analysis.__dict__, ensure_ascii=False, indent=2)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(output)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(output)

if __name__ == "__main__":
    from datetime import datetime
    main()