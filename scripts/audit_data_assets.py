#!/usr/bin/env python3
"""
æ•°æ®èµ„äº§ç›˜ç‚¹å®¡è®¡è„šæœ¬ - éå¹²æ‰°å¼åªè¯»æ£€æŸ¥
Non-Destructive Data Assets Audit Script

æ‰§è¡Œ4ä¸ªå…³é”®çš„åªè¯»æ£€æŸ¥ï¼ŒéªŒè¯æ•°æ®åº“ä¸­æ–°æ•°æ®å’Œæ¶æ„çš„å®Œæ•´æ€§
"""

import asyncio
import logging
import sys
import os
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("data_audit.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ.setdefault('DATABASE_URL', 'postgresql://postgres:postgres@db:5432/football_prediction')

@dataclass
class AuditResult:
    """å®¡è®¡ç»“æœæ•°æ®ç±»"""
    check_name: str
    status: str  # "PASS", "FAIL", "WARNING"
    details: Dict[str, Any]
    execution_time: float
    error_message: Optional[str] = None

class DataAssetAuditor:
    """æ•°æ®èµ„äº§å®¡è®¡å™¨ - ä¸“é—¨æ‰§è¡Œéå¹²æ‰°å¼åªè¯»æ£€æŸ¥"""

    def __init__(self):
        self.db_manager = None
        self.results: List[AuditResult] = []

    async def initialize(self):
        """åˆå§‹åŒ–å®¡è®¡å™¨"""
        try:
            from src.database.async_manager import initialize_database, get_db_session

            logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
            initialize_database()
            logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")

            # éªŒè¯è¿æ¥
            from sqlalchemy import text
            async with get_db_session() as session:
                result = await session.execute(text("SELECT 1 as test"))
                test_value = result.scalar()
                if test_value != 1:
                    raise RuntimeError("æ•°æ®åº“è¿æ¥éªŒè¯å¤±è´¥")
                logger.info("âœ… æ•°æ®åº“è¿æ¥éªŒè¯é€šè¿‡")

            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def _execute_query_with_timing(self, query: str, query_name: str) -> tuple:
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è®°å½•æ‰§è¡Œæ—¶é—´"""
        from src.database.async_manager import get_db_session
        from sqlalchemy import text
        import time

        start_time = time.time()

        try:
            async with get_db_session() as session:
                result = await session.execute(text(query))
                execution_time = time.time() - start_time

                logger.debug(f"ğŸ•’ æŸ¥è¯¢ '{query_name}' æ‰§è¡Œæ—¶é—´: {execution_time:.3f}s")
                return result, execution_time

        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ æŸ¥è¯¢ '{query_name}' æ‰§è¡Œå¤±è´¥: {e}")
            raise e

    async def check_schema_integrity(self) -> AuditResult:
        """æ£€æŸ¥1: Schemaå®Œæ•´æ€§æ£€æŸ¥ - éªŒè¯JSONå­—æ®µæ•°æ®ç±»å‹"""
        logger.info("ğŸ” æ‰§è¡ŒSchemaå®Œæ•´æ€§æ£€æŸ¥...")

        query = """
        SELECT
            column_name,
            data_type,
            udt_name
        FROM information_schema.columns
        WHERE table_name = 'matches'
            AND table_schema = 'public'
            AND (column_name LIKE '%json%' OR column_name LIKE '%stats%' OR column_name LIKE '%environment%')
        ORDER BY column_name;
        """

        try:
            result, execution_time = await self._execute_query_with_timing(query, "Schema Integrity")
            rows = result.fetchall()

            # éªŒè¯ç»“æœ
            expected_json_columns = [
                'stats_json', 'lineups_json', 'odds_snapshot_json',
                'match_info', 'environment_json', 'lineups',
                'stats', 'events', 'odds', 'match_metadata'
            ]

            found_columns = [row[0] for row in rows]
            json_columns = []
            jsonb_columns = []

            for row in rows:
                column_name, data_type, udt_name = row
                if 'json' in data_type.lower() or 'json' in udt_name.lower():
                    json_columns.append((column_name, data_type, udt_name))
                    if data_type.lower() == 'jsonb':
                        jsonb_columns.append(column_name)

            details = {
                "total_columns_found": len(rows),
                "expected_json_columns": len(expected_json_columns),
                "found_columns": found_columns,
                "json_columns": [(col, dtype) for col, dtype, udt in json_columns],
                "jsonb_columns": jsonb_columns,
                "query_result_count": len(rows)
            }

            # åˆ¤æ–­æ£€æŸ¥çŠ¶æ€
            status = "PASS"
            if len(json_columns) == 0:
                status = "FAIL"
            elif len(json_columns) < len(expected_json_columns) * 0.8:
                status = "WARNING"

            return AuditResult(
                check_name="Schema Integrity Check",
                status=status,
                details=details,
                execution_time=execution_time
            )

        except Exception as e:
            return AuditResult(
                check_name="Schema Integrity Check",
                status="FAIL",
                details={},
                execution_time=0,
                error_message=str(e)
            )

    async def check_data_volume(self) -> AuditResult:
        """æ£€æŸ¥2: æ•°æ®æ€»é‡æ£€æŸ¥ - ç»Ÿè®¡æ¯”èµ›æ€»æ•°"""
        logger.info("ğŸ” æ‰§è¡Œæ•°æ®æ€»é‡æ£€æŸ¥...")

        query = "SELECT COUNT(*) as total_matches FROM matches;"

        try:
            result, execution_time = await self._execute_query_with_timing(query, "Data Volume")
            total_matches = result.scalar()

            # è·å–æœ‰æ•°æ®çš„è®°å½•æ•°ç»Ÿè®¡
            detailed_stats_query = """
            SELECT
                COUNT(*) as total_matches,
                COUNT(CASE WHEN stats_json IS NOT NULL THEN 1 END) as matches_with_stats,
                COUNT(CASE WHEN environment_json IS NOT NULL THEN 1 END) as matches_with_environment,
                COUNT(CASE WHEN home_xg IS NOT NULL THEN 1 END) as matches_with_xg,
                MAX(created_at) as latest_record,
                MIN(created_at) as earliest_record
            FROM matches;
            """

            detailed_result, _ = await self._execute_query_with_timing(detailed_stats_query, "Detailed Volume Stats")
            detailed_row = detailed_result.first()

            details = {
                "total_matches": total_matches,
                "matches_with_stats": detailed_row.matches_with_stats,
                "matches_with_environment": detailed_row.matches_with_environment,
                "matches_with_xg": detailed_row.matches_with_xg,
                "data_completeness_pct": round((detailed_row.matches_with_stats / total_matches * 100) if total_matches > 0 else 0, 2),
                "environment_completeness_pct": round((detailed_row.matches_with_environment / total_matches * 100) if total_matches > 0 else 0, 2),
                "xg_completeness_pct": round((detailed_row.matches_with_xg / total_matches * 100) if total_matches > 0 else 0, 2),
                "latest_record": str(detailed_row.latest_record) if detailed_row.latest_record else None,
                "earliest_record": str(detailed_row.earliest_record) if detailed_row.earliest_record else None
            }

            # åˆ¤æ–­æ£€æŸ¥çŠ¶æ€
            status = "PASS"
            if total_matches == 0:
                status = "FAIL"
            elif total_matches < 100:
                status = "WARNING"

            return AuditResult(
                check_name="Data Volume Check",
                status=status,
                details=details,
                execution_time=execution_time
            )

        except Exception as e:
            return AuditResult(
                check_name="Data Volume Check",
                status="FAIL",
                details={},
                execution_time=0,
                error_message=str(e)
            )

    async def check_data_quality_xg(self) -> AuditResult:
        """æ£€æŸ¥3: æ•°æ®è´¨é‡æŠ½æ · - éªŒè¯xGæ•°æ®å®Œæ•´æ€§"""
        logger.info("ğŸ” æ‰§è¡Œæ•°æ®è´¨é‡æŠ½æ ·æ£€æŸ¥ (xGæ•°æ®)...")

        # éšæœºæŠ½å–ä¸€æ¡æœ‰stats_jsonçš„è®°å½•
        query = """
        SELECT
            id,
            fotmob_id,
            home_team_name,
            away_team_name,
            home_xg,
            away_xg,
            stats_json,
            collection_time
        FROM matches
        WHERE stats_json IS NOT NULL
        ORDER BY RANDOM()
        LIMIT 1;
        """

        try:
            result, execution_time = await self._execute_query_with_timing(query, "Data Quality xG")
            row = result.first()

            if not row:
                return AuditResult(
                    check_name="Data Quality Check (xG)",
                    status="WARNING",
                    details={"message": "No records with stats_json found"},
                    execution_time=execution_time
                )

            # è§£æå’ŒéªŒè¯JSONæ•°æ®
            stats_json = row.stats_json
            home_xg = row.home_xg
            away_xg = row.away_xg

            xg_validation = {
                "has_stats_json": stats_json is not None,
                "stats_json_type": type(stats_json).__name__,
                "home_xg_numeric": home_xg is not None,
                "away_xg_numeric": away_xg is not None,
                "home_xg_value": float(home_xg) if home_xg is not None else None,
                "away_xg_value": float(away_xg) if away_xg is not None else None,
            }

            # å¦‚æœstats_jsonæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
            if isinstance(stats_json, str):
                try:
                    parsed_stats = json.loads(stats_json)
                    xg_validation["stats_json_parsed"] = True
                    xg_validation["stats_json_keys"] = list(parsed_stats.keys()) if isinstance(parsed_stats, dict) else "Not a dict"
                except:
                    xg_validation["stats_json_parsed"] = False
            elif isinstance(stats_json, dict):
                xg_validation["stats_json_parsed"] = True
                xg_validation["stats_json_keys"] = list(stats_json.keys())
            else:
                xg_validation["stats_json_parsed"] = False

            details = {
                "sample_match_id": row.id,
                "sample_fotmob_id": row.fotmob_id,
                "sample_match": f"{row.home_team_name} vs {row.away_team_name}",
                "collection_time": str(row.collection_time) if row.collection_time else None,
                "xg_validation": xg_validation
            }

            # åˆ¤æ–­æ£€æŸ¥çŠ¶æ€
            status = "PASS"
            if not xg_validation["has_stats_json"]:
                status = "FAIL"
            elif not (xg_validation["home_xg_numeric"] or xg_validation["away_xg_numeric"]):
                status = "WARNING"

            return AuditResult(
                check_name="Data Quality Check (xG)",
                status=status,
                details=details,
                execution_time=execution_time
            )

        except Exception as e:
            return AuditResult(
                check_name="Data Quality Check (xG)",
                status="FAIL",
                details={},
                execution_time=0,
                error_message=str(e)
            )

    async def check_environment_context(self) -> AuditResult:
        """æ£€æŸ¥4: ç¯å¢ƒæš—ç‰©è´¨æŠ½æ · - éªŒè¯è£åˆ¤å’Œåœºåœ°æ•°æ®"""
        logger.info("ğŸ” æ‰§è¡Œç¯å¢ƒæš—ç‰©è´¨æŠ½æ ·æ£€æŸ¥ (è£åˆ¤å’Œåœºåœ°æ•°æ®)...")

        query = """
        SELECT
            id,
            fotmob_id,
            home_team_name,
            away_team_name,
            environment_json,
            venue,
            match_time
        FROM matches
        WHERE environment_json IS NOT NULL
        ORDER BY RANDOM()
        LIMIT 1;
        """

        try:
            result, execution_time = await self._execute_query_with_timing(query, "Environment Context")
            row = result.first()

            if not row:
                return AuditResult(
                    check_name="Environment Context Check",
                    status="WARNING",
                    details={"message": "No records with environment_json found"},
                    execution_time=execution_time
                )

            # è§£æå’ŒéªŒè¯ç¯å¢ƒæ•°æ®
            environment_json = row.environment_json
            venue = row.venue

            env_validation = {
                "has_environment_json": environment_json is not None,
                "environment_json_type": type(environment_json).__name__,
                "has_venue": venue is not None,
                "venue_value": venue
            }

            # è§£æenvironment_jsonå†…å®¹
            referee_info = {}
            venue_info = {}

            if isinstance(environment_json, str):
                try:
                    parsed_env = json.loads(environment_json)
                    env_validation["environment_json_parsed"] = True

                    # æ£€æŸ¥è£åˆ¤ä¿¡æ¯
                    if isinstance(parsed_env, dict) and "referee" in parsed_env:
                        referee_data = parsed_env["referee"]
                        if isinstance(referee_data, dict):
                            referee_info = {
                                "has_referee": True,
                                "has_id": "id" in referee_data,
                                "has_name": "name" in referee_data,
                                "referee_keys": list(referee_data.keys())
                            }
                        else:
                            referee_info = {"has_referee": False, "referee_type": type(referee_data).__name__}
                    else:
                        referee_info = {"has_referee": False}

                    # æ£€æŸ¥åœºåœ°ä¿¡æ¯
                    if isinstance(parsed_env, dict) and "venue" in parsed_env:
                        venue_data = parsed_env["venue"]
                        if isinstance(venue_data, dict):
                            venue_info = {
                                "has_venue_info": True,
                                "has_coordinates": "coordinates" in venue_data,
                                "has_name": "name" in venue_data,
                                "venue_keys": list(venue_data.keys())
                            }
                        else:
                            venue_info = {"has_venue_info": False, "venue_type": type(venue_data).__name__}
                    else:
                        venue_info = {"has_venue_info": False}

                except Exception as parse_error:
                    env_validation["environment_json_parsed"] = False
                    env_validation["parse_error"] = str(parse_error)
                    referee_info = {"has_referee": False, "error": "Parse failed"}
                    venue_info = {"has_venue_info": False, "error": "Parse failed"}

            elif isinstance(environment_json, dict):
                env_validation["environment_json_parsed"] = True
                # ç±»ä¼¼çš„å­—å…¸è§£æé€»è¾‘...
            else:
                env_validation["environment_json_parsed"] = False

            details = {
                "sample_match_id": row.id,
                "sample_fotmob_id": row.fotmob_id,
                "sample_match": f"{row.home_team_name} vs {row.away_team_name}",
                "match_time": str(row.match_time) if row.match_time else None,
                "env_validation": env_validation,
                "referee_info": referee_info,
                "venue_info": venue_info
            }

            # åˆ¤æ–­æ£€æŸ¥çŠ¶æ€
            status = "PASS"
            if not env_validation["has_environment_json"]:
                status = "FAIL"
            elif not referee_info.get("has_referee") and not venue_info.get("has_venue_info"):
                status = "WARNING"

            return AuditResult(
                check_name="Environment Context Check",
                status=status,
                details=details,
                execution_time=execution_time
            )

        except Exception as e:
            return AuditResult(
                check_name="Environment Context Check",
                status="FAIL",
                details={},
                execution_time=0,
                error_message=str(e)
            )

    async def run_full_audit(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®èµ„äº§å®¡è®¡"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå®Œæ•´çš„æ•°æ®èµ„äº§å®¡è®¡...")

        start_time = datetime.now()

        # æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥
        checks = [
            self.check_schema_integrity(),
            self.check_data_volume(),
            self.check_data_quality_xg(),
            self.check_environment_context()
        ]

        self.results = await asyncio.gather(*checks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for result in self.results:
            if isinstance(result, Exception):
                processed_results.append(AuditResult(
                    check_name="Unknown Check",
                    status="FAIL",
                    details={},
                    execution_time=0,
                    error_message=str(result)
                ))
            else:
                processed_results.append(result)

        self.results = processed_results

        end_time = datetime.now()
        total_time = (end_time - start_time).total_seconds()

        # æ±‡æ€»ç»“æœ
        summary = {
            "audit_timestamp": start_time.isoformat(),
            "total_execution_time": total_time,
            "total_checks": len(self.results),
            "passed_checks": len([r for r in self.results if r.status == "PASS"]),
            "failed_checks": len([r for r in self.results if r.status == "FAIL"]),
            "warning_checks": len([r for r in self.results if r.status == "WARNING"]),
            "overall_status": "PASS" if all(r.status in ["PASS", "WARNING"] for r in self.results) else "FAIL",
            "results": self.results
        }

        logger.info(f"âœ… å®¡è®¡å®Œæˆ - æ€»ç”¨æ—¶: {total_time:.2f}s")
        logger.info(f"ğŸ“Š ç»“æœ: é€šè¿‡ {summary['passed_checks']}, å¤±è´¥ {summary['failed_checks']}, è­¦å‘Š {summary['warning_checks']}")

        return summary

    def generate_markdown_report(self, audit_summary: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„å¯è§†åŒ–æŠ¥å‘Š"""
        report = []
        report.append("# ğŸ“Š æ•°æ®èµ„äº§ç›˜ç‚¹å®¡è®¡æŠ¥å‘Š")
        report.append("")
        report.append("## ğŸ“‹ å®¡è®¡æ¦‚è§ˆ")
        report.append("")
        report.append(f"- **å®¡è®¡æ—¶é—´**: {audit_summary['audit_timestamp']}")
        report.append(f"- **æ€»æ‰§è¡Œæ—¶é—´**: {audit_summary['total_execution_time']:.3f} ç§’")
        report.append(f"- **æ£€æŸ¥é¡¹ç›®**: {audit_summary['total_checks']} é¡¹")
        report.append(f"- **é€šè¿‡æ£€æŸ¥**: {audit_summary['passed_checks']} é¡¹")
        report.append(f"- **å¤±è´¥æ£€æŸ¥**: {audit_summary['failed_checks']} é¡¹")
        report.append(f"- **è­¦å‘Šæ£€æŸ¥**: {audit_summary['warning_checks']} é¡¹")
        report.append(f"- **æ•´ä½“çŠ¶æ€**: {self._get_status_emoji(audit_summary['overall_status'])} {audit_summary['overall_status']}")
        report.append("")

        # è¯¦ç»†æ£€æŸ¥ç»“æœè¡¨æ ¼
        report.append("## ğŸ” è¯¦ç»†æ£€æŸ¥ç»“æœ")
        report.append("")
        report.append("| æ£€æŸ¥é¡¹ç›® | çŠ¶æ€ | æ‰§è¡Œæ—¶é—´ | å…³é”®æŒ‡æ ‡ | å¤‡æ³¨ |")
        report.append("|---------|------|----------|----------|------|")

        for result in audit_summary["results"]:
            status_emoji = self._get_status_emoji(result.status)
            key_metrics = self._extract_key_metrics(result.check_name, result.details)
            notes = result.error_message or "æ­£å¸¸"

            report.append(f"| {result.check_name} | {status_emoji} {result.status} | {result.execution_time:.3f}s | {key_metrics} | {notes} |")

        report.append("")

        # è¯¦ç»†æ•°æ®è´¨é‡ä¿¡æ¯
        report.append("## ğŸ“ˆ æ•°æ®è´¨é‡è¯¦æƒ…")
        report.append("")

        for result in audit_summary["results"]:
            if result.status == "FAIL" or result.details:
                report.append(f"### {result.check_name}")
                report.append("")
                report.append(f"**çŠ¶æ€**: {self._get_status_emoji(result.status)} {result.status}")
                report.append(f"**æ‰§è¡Œæ—¶é—´**: {result.execution_time:.3f}s")
                report.append("")

                if "total_matches" in result.details:
                    report.append(f"- **æ¯”èµ›æ€»æ•°**: {result.details['total_matches']:,}")
                    report.append(f"- **æ•°æ®å®Œæ•´åº¦**: {result.details.get('data_completeness_pct', 0):.1f}%")
                    report.append(f"- **ç¯å¢ƒæ•°æ®å®Œæ•´åº¦**: {result.details.get('environment_completeness_pct', 0):.1f}%")
                    report.append(f"- **xGæ•°æ®å®Œæ•´åº¦**: {result.details.get('xg_completeness_pct', 0):.1f}%")

                if "sample_match" in result.details:
                    report.append(f"- **é‡‡æ ·æ¯”èµ›**: {result.details['sample_match']}")
                    report.append(f"- **æ¯”èµ›ID**: {result.details.get('sample_match_id')}")

                if "json_columns" in result.details:
                    report.append(f"- **JSONå­—æ®µæ•°**: {len(result.details['json_columns'])}")
                    report.append(f"- **JSONBå­—æ®µæ•°**: {len(result.details.get('jsonb_columns', []))}")

                report.append("")

        # å®¡è®¡ç»“è®º
        report.append("## ğŸ“ å®¡è®¡ç»“è®º")
        report.append("")

        if audit_summary['overall_status'] == 'PASS':
            report.append("âœ… **å®¡è®¡é€šè¿‡** - æ•°æ®èµ„äº§çŠ¶æ€è‰¯å¥½ï¼Œæ‰€æœ‰å…³é”®æ£€æŸ¥é¡¹ç›®å‡æ­£å¸¸")
        elif audit_summary['failed_checks'] == 0:
            report.append("âš ï¸ **å®¡è®¡é€šè¿‡ï¼ˆå«è­¦å‘Šï¼‰** - æ•°æ®èµ„äº§åŸºæœ¬æ­£å¸¸ï¼Œå­˜åœ¨éƒ¨åˆ†éœ€è¦å…³æ³¨çš„é¡¹")
        else:
            report.append("âŒ **å®¡è®¡å¤±è´¥** - å‘ç°å…³é”®é—®é¢˜ï¼Œéœ€è¦ç«‹å³å¤„ç†")

        report.append("")
        report.append("---")
        report.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}*")

        return "\n".join(report)

    def _get_status_emoji(self, status: str) -> str:
        """è·å–çŠ¶æ€emoji"""
        return {
            "PASS": "âœ…",
            "FAIL": "âŒ",
            "WARNING": "âš ï¸"
        }.get(status, "â“")

    def _extract_key_metrics(self, check_name: str, details: Dict[str, Any]) -> str:
        """æå–å…³é”®æŒ‡æ ‡ç”¨äºè¡¨æ ¼æ˜¾ç¤º"""
        if check_name == "Schema Integrity Check":
            json_cols = len(details.get("json_columns", []))
            return f"{json_cols} JSONå­—æ®µ"

        elif check_name == "Data Volume Check":
            total = details.get("total_matches", 0)
            completeness = details.get("data_completeness_pct", 0)
            return f"{total:,} åœºæ¯”èµ› ({completeness:.1f}%)"

        elif check_name == "Data Quality Check (xG)":
            has_stats = details.get("xg_validation", {}).get("has_stats_json", False)
            has_xg = details.get("xg_validation", {}).get("home_xg_numeric", False) or details.get("xg_validation", {}).get("away_xg_numeric", False)
            return f"Stats: {'âœ“' if has_stats else 'âœ—'}, xG: {'âœ“' if has_xg else 'âœ—'}"

        elif check_name == "Environment Context Check":
            has_env = details.get("env_validation", {}).get("has_environment_json", False)
            has_referee = details.get("referee_info", {}).get("has_referee", False)
            return f"Env: {'âœ“' if has_env else 'âœ—'}, Referee: {'âœ“' if has_referee else 'âœ—'}"

        return "æ— å…³é”®æŒ‡æ ‡"

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨æ•°æ®èµ„äº§ç›˜ç‚¹å®¡è®¡...")

    auditor = DataAssetAuditor()

    # åˆå§‹åŒ–
    if not await auditor.initialize():
        logger.error("âŒ å®¡è®¡å™¨åˆå§‹åŒ–å¤±è´¥")
        return False

    # æ‰§è¡Œå®¡è®¡
    try:
        audit_summary = await auditor.run_full_audit()

        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        markdown_report = auditor.generate_markdown_report(audit_summary)

        # ä¿å­˜åˆ°æ–‡ä»¶
        report_file = Path("data_audit_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)

        logger.info(f"ğŸ“„ å®¡è®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        # è¾“å‡ºæŠ¥å‘Šåˆ°æ§åˆ¶å°
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®èµ„äº§ç›˜ç‚¹å®¡è®¡æŠ¥å‘Š")
        print("="*60)
        print(markdown_report)

        return audit_summary['overall_status'] == 'PASS'

    except Exception as e:
        logger.error(f"âŒ å®¡è®¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)