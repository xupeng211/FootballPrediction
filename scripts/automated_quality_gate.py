#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦ç³»ç»Ÿ
åŸºäºIssue #98æ™ºèƒ½è´¨é‡ä¿®å¤æ–¹æ³•è®ºå’ŒIssue #94è¦†ç›–ç‡æå‡å®è·µ

é›†æˆIssue #98å»ºç«‹çš„æ™ºèƒ½ä¿®å¤å·¥å…·é“¾ï¼š
- æ™ºèƒ½è¯­æ³•ä¿®å¤
- è´¨é‡æ£€æŸ¥è‡ªåŠ¨åŒ–
- è¦†ç›–ç‡ç›‘æ§
- æŒç»­æ”¹è¿›å»ºè®®

ä¸ºIssue #89 CI/CDä¼˜åŒ–æä¾›æ ¸å¿ƒè‡ªåŠ¨åŒ–æ”¯æŒ
"""

import os
import sys
import json
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class AutomatedQualityGate:
    """è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦ç³»ç»Ÿ - åŸºäºIssue #98æ–¹æ³•è®º"""

    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(__file__).parent.parent
        self.reports_dir = self.project_root / "quality-reports"
        self.ci_reports_dir = self.project_root / "ci-reports"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.reports_dir.mkdir(exist_ok=True)
        self.ci_reports_dir.mkdir(exist_ok=True)

        # è´¨é‡æ ‡å‡† - åŸºäºIssue #98å®è·µ
        self.quality_standards = {
            "min_coverage": 10.0,  # å½“å‰åŸºçº¿ï¼Œé€æ­¥æå‡åˆ°80%
            "max_syntax_errors": 50,
            "max_import_errors": 100,
            "min_test_pass_rate": 85.0,
            "max_ruff_errors": 20,
            "max_mypy_errors": 15,
        }

        # æ£€æŸ¥ç»“æœ
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "checks_performed": [],
            "overall_status": "pending",
            "summary": {},
            "recommendations": [],
            "gate_status": "unknown",
        }

    def run_syntax_check(self) -> Dict[str, Any]:
        """è¿è¡Œè¯­æ³•æ£€æŸ¥ - åŸºäºIssue #98è¯­æ³•ä¿®å¤æ–¹æ³•è®º"""
        logger.info("ğŸ”§ æ‰§è¡Œè¯­æ³•æ£€æŸ¥...")

        # åŸºäºIssue #98çš„æ™ºèƒ½è¯­æ³•ä¿®å¤
        syntax_check_cmd = ["python3", "scripts/smart_quality_fixer.py", "--syntax-only"]

        try:
            result = subprocess.run(
                syntax_check_cmd, cwd=self.project_root, capture_output=True, text=True, timeout=300
            )

            syntax_result = {
                "check_name": "syntax_check",
                "status": "pass" if result.returncode == 0 else "fail",
                "errors_fixed": 0,  # ä»è¾“å‡ºä¸­è§£æ
                "details": result.stdout,
                "recommendations": [],
            }

            # è§£æä¿®å¤ç»“æœ
            if "ä¿®å¤è¯­æ³•é”™è¯¯:" in result.stdout:
                try:
                    fixed_count = int(
                        result.stdout.split("ä¿®å¤è¯­æ³•é”™è¯¯:")[1].split("ä¸ª")[0].strip()
                    )
                    syntax_result["errors_fixed"] = fixed_count
                except:
                    pass

            # ç”Ÿæˆå»ºè®®
            if syntax_result["status"] == "fail":
                syntax_result["recommendations"].append("è¿è¡Œè¯­æ³•ä¿®å¤å·¥å…·è§£å†³è¯­æ³•é—®é¢˜")
            elif syntax_result["errors_fixed"] > 0:
                syntax_result["recommendations"].append(
                    f"æˆåŠŸä¿®å¤{syntax_result['errors_fixed']}ä¸ªè¯­æ³•é”™è¯¯"
                )

            logger.info(f"âœ… è¯­æ³•æ£€æŸ¥å®Œæˆ: {syntax_result['status']}")
            return syntax_result

        except subprocess.TimeoutExpired:
            logger.error("âŒ è¯­æ³•æ£€æŸ¥è¶…æ—¶")
            return {
                "check_name": "syntax_check",
                "status": "timeout",
                "errors_fixed": 0,
                "details": "æ£€æŸ¥è¶…æ—¶",
                "recommendations": ["æ£€æŸ¥æ˜¯å¦æœ‰æ— é™å¾ªç¯æˆ–å¤æ‚è¯­æ³•é—®é¢˜"],
            }
        except Exception as e:
            logger.error(f"âŒ è¯­æ³•æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "check_name": "syntax_check",
                "status": "error",
                "errors_fixed": 0,
                "details": str(e),
                "recommendations": ["æ£€æŸ¥è¯­æ³•æ£€æŸ¥å·¥å…·æ˜¯å¦æ­£å¸¸å·¥ä½œ"],
            }

    def run_quality_check(self) -> Dict[str, Any]:
        """è¿è¡Œè´¨é‡æ£€æŸ¥ - åŸºäºIssue #98è´¨é‡å®ˆæŠ¤ç³»ç»Ÿ"""
        logger.info("ğŸ›¡ï¸ æ‰§è¡Œè´¨é‡æ£€æŸ¥...")

        # åŸºäºIssue #98çš„è´¨é‡å®ˆæŠ¤å·¥å…·
        quality_check_cmd = ["python3", "scripts/quality_guardian.py", "--check-only"]

        try:
            result = subprocess.run(
                quality_check_cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
            )

            quality_result = {
                "check_name": "quality_check",
                "status": "pass" if result.returncode == 0 else "fail",
                "details": result.stdout,
                "metrics": {},
                "recommendations": [],
            }

            # è§£æè´¨é‡æŒ‡æ ‡
            if "ç»¼åˆè´¨é‡åˆ†æ•°:" in result.stdout:
                try:
                    score_line = [
                        line for line in result.stdout.split("\n") if "ç»¼åˆè´¨é‡åˆ†æ•°:" in line
                    ][0]
                    score = float(score_line.split("ç»¼åˆè´¨é‡åˆ†æ•°:")[1].split("/")[0].strip())
                    quality_result["metrics"]["overall_score"] = score
                except:
                    pass

            if "æµ‹è¯•è¦†ç›–ç‡:" in result.stdout:
                try:
                    coverage_line = [
                        line for line in result.stdout.split("\n") if "æµ‹è¯•è¦†ç›–ç‡:" in line
                    ][0]
                    coverage = float(coverage_line.split("æµ‹è¯•è¦†ç›–ç‡:")[1].split("%")[0].strip())
                    quality_result["metrics"]["coverage"] = coverage
                except:
                    pass

            # ç”Ÿæˆå»ºè®®
            if (
                quality_result["metrics"].get("coverage", 0)
                < self.quality_standards["min_coverage"]
            ):
                quality_result["recommendations"].append(
                    f"è¦†ç›–ç‡{quality_result['metrics']['coverage']:.1f}%ä½äºæ ‡å‡†{self.quality_standards['min_coverage']}%"
                )

            if quality_result["metrics"].get("overall_score", 0) < 6.0:
                quality_result["recommendations"].append("æ•´ä½“è´¨é‡åˆ†æ•°åä½ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³å…³é”®é—®é¢˜")

            logger.info(f"âœ… è´¨é‡æ£€æŸ¥å®Œæˆ: {quality_result['status']}")
            return quality_result

        except subprocess.TimeoutExpired:
            logger.error("âŒ è´¨é‡æ£€æŸ¥è¶…æ—¶")
            return {
                "check_name": "quality_check",
                "status": "timeout",
                "details": "æ£€æŸ¥è¶…æ—¶",
                "metrics": {},
                "recommendations": ["æ£€æŸ¥é¡¹ç›®å¤æ‚åº¦æˆ–ä¼˜åŒ–æ£€æŸ¥é€»è¾‘"],
            }
        except Exception as e:
            logger.error(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "check_name": "quality_check",
                "status": "error",
                "details": str(e),
                "metrics": {},
                "recommendations": ["æ£€æŸ¥è´¨é‡å®ˆæŠ¤å·¥å…·æ˜¯å¦æ­£å¸¸å·¥ä½œ"],
            }

    def run_test_coverage_check(self) -> Dict[str, Any]:
        """è¿è¡Œæµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥ - æ”¯æŒIssue #94è¦†ç›–ç‡æå‡è®¡åˆ’"""
        logger.info("ğŸ“Š æ‰§è¡Œæµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥...")

        try:
            # è¿è¡Œå¿«é€Ÿæµ‹è¯•å’Œè¦†ç›–ç‡æ£€æŸ¥
            test_cmd = [
                "python",
                "-m",
                "pytest",
                "tests/unit/utils/",  # é‡ç‚¹æ£€æŸ¥utilsæ¨¡å—
                "--cov=src/utils",
                "--cov-report=term-missing",
                "--cov-report=json:htmlcov/coverage.json",
                "--tb=short",
                "-x",  # é‡åˆ°ç¬¬ä¸€ä¸ªå¤±è´¥å°±åœæ­¢
                "--maxfail=10",
            ]

            result = subprocess.run(
                test_cmd, cwd=self.project_root, capture_output=True, text=True, timeout=600
            )

            coverage_result = {
                "check_name": "test_coverage",
                "status": "pass" if result.returncode == 0 else "fail",
                "details": result.stdout,
                "metrics": {},
                "recommendations": [],
            }

            # å°è¯•è¯»å–è¦†ç›–ç‡æŠ¥å‘Š
            coverage_file = self.project_root / "htmlcov" / "coverage.json"
            if coverage_file.exists():
                try:
                    with open(coverage_file, "r") as f:
                        coverage_data = json.load(f)
                        coverage_result["metrics"]["coverage_percent"] = coverage_data.get(
                            "totals", {}
                        ).get("percent_covered", 0)
                        coverage_result["metrics"]["lines_covered"] = coverage_data.get(
                            "totals", {}
                        ).get("covered_lines", 0)
                        coverage_result["metrics"]["lines_missing"] = coverage_data.get(
                            "totals", {}
                        ).get("missing_lines", 0)
                except Exception as e:
                    logger.warning(f"æ— æ³•è§£æè¦†ç›–ç‡æŠ¥å‘Š: {e}")

            # ä»è¾“å‡ºä¸­è§£ææµ‹è¯•ç»“æœ
            if "passed" in result.stdout and "failed" in result.stdout:
                try:
                    summary_lines = [
                        line
                        for line in result.stdout.split("\n")
                        if "passed" in line and "failed" in line
                    ]
                    if summary_lines:
                        summary_line = summary_lines[0]
                        # è§£æç±»ä¼¼ "20 passed, 1 failed" çš„æ ¼å¼
                        if "passed" in summary_line:
                            passed = int(summary_line.split("passed")[0].strip().split()[-1])
                            coverage_result["metrics"]["tests_passed"] = passed
                        if "failed" in summary_line:
                            failed_part = summary_line.split("failed")[0].strip()
                            failed = int(failed_part.split()[-1])
                            coverage_result["metrics"]["tests_failed"] = failed
                except:
                    pass

            # ç”Ÿæˆå»ºè®®
            coverage_percent = coverage_result["metrics"].get("coverage_percent", 0)
            if coverage_percent < self.quality_standards["min_coverage"]:
                coverage_result["recommendations"].append(
                    f"è¦†ç›–ç‡{coverage_percent:.1f}%ä½äºç›®æ ‡{self.quality_standards['min_coverage']}%ï¼Œç»§ç»­æ‰§è¡ŒIssue #94è®¡åˆ’"
                )
            else:
                coverage_result["recommendations"].append(
                    f"è¦†ç›–ç‡{coverage_percent:.1f}%è¾¾åˆ°å½“å‰æ ‡å‡†ï¼Œç»§ç»­å‘80%ç›®æ ‡è¿ˆè¿›"
                )

            logger.info(f"âœ… è¦†ç›–ç‡æ£€æŸ¥å®Œæˆ: {coverage_percent:.1f}%")
            return coverage_result

        except subprocess.TimeoutExpired:
            logger.error("âŒ è¦†ç›–ç‡æ£€æŸ¥è¶…æ—¶")
            return {
                "check_name": "test_coverage",
                "status": "timeout",
                "details": "æ£€æŸ¥è¶…æ—¶",
                "metrics": {},
                "recommendations": ["ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œæ•ˆç‡æˆ–å¢åŠ è¶…æ—¶æ—¶é—´"],
            }
        except Exception as e:
            logger.error(f"âŒ è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "check_name": "test_coverage",
                "status": "error",
                "details": str(e),
                "metrics": {},
                "recommendations": ["æ£€æŸ¥æµ‹è¯•ç¯å¢ƒå’Œä¾èµ–"],
            }

    def evaluate_gate_status(self, results: List[Dict[str, Any]]) -> str:
        """è¯„ä¼°è´¨é‡é—¨ç¦çŠ¶æ€"""
        logger.info("ğŸ¯ è¯„ä¼°è´¨é‡é—¨ç¦çŠ¶æ€...")

        failed_checks = [r for r in results if r.get("status") == "fail"]
        error_checks = [r for r in results if r.get("status") == "error"]
        timeout_checks = [r for r in results if r.get("status") == "timeout"]

        if error_checks:
            return "error"
        elif timeout_checks:
            return "timeout"
        elif failed_checks:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯æ¥å—çš„å¤±è´¥
            critical_failures = [r for r in failed_checks if r["check_name"] in ["syntax_check"]]
            if critical_failures:
                return "fail"
            else:
                return "warning"
        else:
            return "pass"

    def generate_report(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")

        # ç»Ÿè®¡æ£€æŸ¥ç»“æœ
        passed_checks = len([r for r in results if r.get("status") == "pass"])
        failed_checks = len([r for r in results if r.get("status") == "fail"])
        error_checks = len([r for r in results if r.get("status") == "error"])
        timeout_checks = len([r for r in results if r.get("status") == "timeout"])

        # æ”¶é›†æ‰€æœ‰å»ºè®®
        all_recommendations = []
        for result in results:
            all_recommendations.extend(result.get("recommendations", []))

        # æ±‡æ€»å…³é”®æŒ‡æ ‡
        metrics = {}
        for result in results:
            if "metrics" in result:
                metrics.update(result["metrics"])

        report = {
            "timestamp": datetime.now().isoformat(),
            "gate_status": self.evaluate_gate_status(results),
            "summary": {
                "total_checks": len(results),
                "passed": passed_checks,
                "failed": failed_checks,
                "errors": error_checks,
                "timeouts": timeout_checks,
            },
            "metrics": metrics,
            "checks": results,
            "recommendations": list(set(all_recommendations)),  # å»é‡
            "next_steps": self._generate_next_steps(results),
            "integration_notes": {
                "issue_94_support": "æ”¯æŒIssue #94è¦†ç›–ç‡æå‡è®¡åˆ’",
                "issue_98_methodology": "åŸºäºIssue #98æ™ºèƒ½è´¨é‡ä¿®å¤æ–¹æ³•è®º",
                "issue_89_objective": "ä¸ºIssue #89 CI/CDä¼˜åŒ–æä¾›è‡ªåŠ¨åŒ–æ”¯æŒ",
            },
        }

        return report

    def _generate_next_steps(self, results: List[Dict[str, Any]]) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®"""
        next_steps = []

        # åŸºäºæ£€æŸ¥ç»“æœç”Ÿæˆå»ºè®®
        for result in results:
            if result.get("status") == "fail":
                if result["check_name"] == "syntax_check":
                    next_steps.append("è¿è¡Œå®Œæ•´è¯­æ³•ä¿®å¤: python3 scripts/smart_quality_fixer.py")
                elif result["check_name"] == "quality_check":
                    next_steps.append("æ‰§è¡Œæ·±åº¦è´¨é‡åˆ†æ: python3 scripts/quality_guardian.py")
                elif result["check_name"] == "test_coverage":
                    next_steps.append("ç»§ç»­Issue #94è¦†ç›–ç‡æå‡è®¡åˆ’ï¼Œé‡ç‚¹å…³æ³¨utilsæ¨¡å—")

        # åŸºäºæŒ‡æ ‡ç”Ÿæˆå»ºè®®
        coverage = self._get_metric(results, "coverage_percent")
        if coverage and coverage < 15:
            next_steps.append("ä¼˜å…ˆæå‡è¦†ç›–ç‡åˆ°15%+ï¼Œå·©å›ºIssue #94 Day 1æˆæœ")

        return next_steps

    def _get_metric(self, results: List[Dict[str, Any]], metric_name: str) -> Optional[float]:
        """ä»æ£€æŸ¥ç»“æœä¸­è·å–æŒ‡æ ‡"""
        for result in results:
            if metric_name in result.get("metrics", {}):
                return result["metrics"][metric_name]
        return None

    def run_all_checks(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰è´¨é‡æ£€æŸ¥"""
        logger.info("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦æ£€æŸ¥...")

        # æ‰§è¡Œå„é¡¹æ£€æŸ¥
        checks = []

        # 1. è¯­æ³•æ£€æŸ¥
        checks.append(self.run_syntax_check())

        # 2. è´¨é‡æ£€æŸ¥
        checks.append(self.run_quality_check())

        # 3. æµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥
        checks.append(self.run_test_coverage_check())

        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(checks)

        # ä¿å­˜æŠ¥å‘Š
        report_file = (
            self.ci_reports_dir
            / f"quality_gate_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ“‹ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        return report

    def print_summary(self, report: Dict[str, Any]):
        """æ‰“å°æ£€æŸ¥æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ¯ è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦æ£€æŸ¥æ‘˜è¦")
        print("=" * 60)

        # é—¨ç¦çŠ¶æ€
        status_emoji = {"pass": "âœ…", "warning": "âš ï¸", "fail": "âŒ", "error": "ğŸš¨", "timeout": "â°"}

        gate_status = report["gate_status"]
        print(f"é—¨ç¦çŠ¶æ€: {status_emoji.get(gate_status, 'â“')} {gate_status.upper()}")

        # æ£€æŸ¥æ‘˜è¦
        summary = report["summary"]
        print(f"æ£€æŸ¥æ€»æ•°: {summary['total_checks']}")
        print(f"é€šè¿‡: {summary['passed']} âœ…")
        print(f"å¤±è´¥: {summary['failed']} âŒ")
        print(f"é”™è¯¯: {summary['errors']} ğŸš¨")
        print(f"è¶…æ—¶: {summary['timeouts']} â°")

        # å…³é”®æŒ‡æ ‡
        if report["metrics"]:
            print("\nğŸ“Š å…³é”®æŒ‡æ ‡:")
            for metric, value in report["metrics"].items():
                if isinstance(value, float):
                    print(f"  {metric}: {value:.1f}")
                else:
                    print(f"  {metric}: {value}")

        # å»ºè®®
        if report["recommendations"]:
            print("\nğŸ’¡ ä¸»è¦å»ºè®®:")
            for rec in report["recommendations"][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  â€¢ {rec}")

        # ä¸‹ä¸€æ­¥
        if report["next_steps"]:
            print("\nğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
            for step in report["next_steps"]:
                print(f"  â€¢ {step}")

        print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦ç³»ç»Ÿ")
    parser.add_argument("--project-root", type=Path, help="é¡¹ç›®æ ¹ç›®å½•")
    parser.add_argument(
        "--output-format", choices=["json", "text"], default="text", help="è¾“å‡ºæ ¼å¼"
    )
    parser.add_argument("--save-report", action="store_true", help="ä¿å­˜è¯¦ç»†æŠ¥å‘Š")

    args = parser.parse_args()

    # åˆ›å»ºè´¨é‡é—¨ç¦å®ä¾‹
    gate = AutomatedQualityGate(args.project_root)

    try:
        # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
        report = gate.run_all_checks()

        # è¾“å‡ºç»“æœ
        if args.output_format == "json":
            print(json.dumps(report, indent=2, ensure_ascii=False))
        else:
            gate.print_summary(report)

        # è®¾ç½®é€€å‡ºç 
        exit_codes = {"pass": 0, "warning": 0, "fail": 1, "error": 2, "timeout": 3}

        sys.exit(exit_codes.get(report["gate_status"], 2))

    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ£€æŸ¥")
        sys.exit(130)
    except Exception as e:
        logger.error(f"è´¨é‡é—¨ç¦æ£€æŸ¥å¤±è´¥: {e}")
        sys.exit(2)


if __name__ == "__main__":
    main()
