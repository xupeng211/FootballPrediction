#!/usr/bin/env python3
"""
Data Forensics Expert - Real Data Depth Inspection
æ•°æ®å–è¯ä¸“å®¶ - V2é‡‡é›†å™¨æ•°æ®æ·±åº¦æ£€æŸ¥

Principal Data Forensics Expert: é¦–å¸­æ•°æ®å–è¯ä¸“å®¶
Purpose: éªŒè¯V2é‡‡é›†å™¨å®é™…æ•è·çš„å…³é”®æ•°æ®å­—æ®µ
Target: xG, èµ”ç‡, çƒå‘˜è¯„åˆ†, è·‘åŠ¨è·ç¦»ç­‰ç”¨æˆ·å…³æ³¨çš„æ ¸å¿ƒæ•°æ®
"""

import asyncio
import json
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)8s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


class DataForensicsExpert:
    """æ•°æ®å–è¯ä¸“å®¶"""

    def __init__(self):
        """åˆå§‹åŒ–å–è¯ä¸“å®¶"""
        self.captured_data = {}
        self.inspection_results = {}

    async def capture_target_match(self) -> Optional[str]:
        """
        å®šç‚¹ç‹™å‡»ï¼šæ•è·æ˜¨å¤©çš„äº”å¤§è”èµ›ç„¦ç‚¹æˆ˜

        Returns:
            æ¯”èµ›æ•°æ®JSONå­—ç¬¦ä¸²
        """
        logger.info("ğŸ¯ å¼€å§‹å®šç‚¹ç‹™å‡»ï¼šè·å–æ˜¨å¤©çš„äº”å¤§è”èµ›ç„¦ç‚¹æˆ˜")

        try:
            from src.data.collectors.fotmob_browser import FotmobBrowserScraper

            # è®¡ç®—æ˜¨å¤©çš„æ—¥æœŸ
            yesterday = datetime.now() - timedelta(days=1)
            date_str = yesterday.strftime("%Y-%m-%d")
            logger.info(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {date_str}")

            async with FotmobBrowserScraper() as scraper:
                # 1. è·å–æ˜¨å¤©çš„æ¯”èµ›åˆ—è¡¨
                logger.info("ğŸ“‹ è·å–æ¯”èµ›åˆ—è¡¨...")
                matches_data = await scraper.scrape_matches(date_str)

                if not matches_data or "matches" not in matches_data:
                    logger.error("âŒ æœªæ‰¾åˆ°æ¯”èµ›æ•°æ®")
                    return None

                matches = matches_data["matches"]
                logger.info(f"âœ… æ‰¾åˆ° {len(matches)} åœºæ¯”èµ›")

                # 2. å¯»æ‰¾äº”å¤§è”èµ›çš„ç„¦ç‚¹æˆ˜
                target_match = None
                premier_league_matches = []

                for match in matches:
                    # å¯»æ‰¾è‹±è¶…æ¯”èµ›
                    if match.get("league", {}).get("name") == "Premier League":
                        premier_league_matches.append(match)
                        logger.info(
                            f"ğŸ´ó§ó¢ó¥ó®ó§ó¿ æ‰¾åˆ°è‹±è¶…æ¯”èµ›: {match.get('home', {}).get('name')} vs {match.get('away', {}).get('name')}"
                        )

                    # å¯»æ‰¾å…¶ä»–äº”å¤§è”èµ›
                    if match.get("league", {}).get("name") in [
                        "Premier League",
                        "La Liga",
                        "Bundesliga",
                        "Serie A",
                        "Ligue 1",
                    ]:
                        # ä¼˜å…ˆé€‰æ‹©çŸ¥åçƒé˜Ÿçš„æ¯”èµ›
                        home_name = match.get("home", {}).get("name", "").lower()
                        away_name = match.get("away", {}).get("name", "").lower()

                        top_teams = [
                            "liverpool",
                            "manchester",
                            "chelsea",
                            "arsenal",
                            "real madrid",
                            "barcelona",
                            "bayern munich",
                            "juventus",
                            "psg",
                            "milan",
                            "inter",
                        ]

                        if any(
                            team in home_name or team in away_name for team in top_teams
                        ):
                            target_match = match
                            logger.info(f"ğŸ¯ å‘ç°ç„¦ç‚¹æˆ˜: {home_name} vs {away_name}")
                            break

                # å¦‚æœæ²¡æ‰¾åˆ°ç„¦ç‚¹æˆ˜ï¼Œé€‰æ‹©ç¬¬ä¸€åœºè‹±è¶…æ¯”èµ›
                if not target_match and premier_league_matches:
                    target_match = premier_league_matches[0]
                    logger.info("ğŸ¯ é€‰æ‹©é¦–åœºè‹±è¶…æ¯”èµ›")

                if not target_match:
                    logger.error("âŒ æœªæ‰¾åˆ°åˆé€‚çš„æ¯”èµ›")
                    return None

                # 3. è·å–æ¯”èµ›çš„è¯¦ç»†ä¿¡æ¯
                match_id = target_match.get("id")
                match_name = f"{target_match.get('home', {}).get('name')} vs {target_match.get('away', {}).get('name')}"

                logger.info(f"ğŸ¬ å¼€å§‹æ•è·æ¯”èµ›è¯¦æƒ…: {match_name} (ID: {match_id})")

                # è¿™é‡Œæˆ‘ä»¬éœ€è¦é‡æ–°åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„è¯¦æƒ…é¡µé‡‡é›†å™¨
                detailed_data = await self._capture_match_details(match_id, match_name)

                return detailed_data

        except Exception as e:
            logger.error(f"âŒ æ•è·æ¯”èµ›æ•°æ®å¤±è´¥: {e}")
            return None

    async def _capture_match_details(
        self, match_id: int, match_name: str
    ) -> Optional[str]:
        """æ•è·æ¯”èµ›è¯¦æƒ…æ•°æ®"""
        logger.info(f"ğŸ” æ·±åº¦å–è¯: {match_name}")

        try:
            from src.data.collectors.fotmob_browser_v2 import FotmobBrowserScraperV2

            async with FotmobBrowserScraperV2() as scraper:
                # æ•è·æ¯”èµ›è¯¦æƒ…é¡µçš„æ‰€æœ‰æ•°æ®
                logger.info("ğŸŒ å¯åŠ¨æµè§ˆå™¨ï¼Œæ‹¦æˆªAPIè°ƒç”¨...")

                # å¯¼èˆªåˆ°æ¯”èµ›è¯¦æƒ…é¡µ
                detail_url = f"https://www.fotmob.com/match/{match_id}"
                detailed_data = await scraper.scrape_match_details(match_id)

                if detailed_data:
                    logger.info(f"âœ… æˆåŠŸæ•è·æ¯”èµ›è¯¦æƒ…: {len(str(detailed_data))} å­—ç¬¦")
                    self.captured_data = detailed_data
                    return json.dumps(detailed_data, indent=2, ensure_ascii=False)
                else:
                    logger.error("âŒ æ•è·è¯¦æƒ…å¤±è´¥")
                    return None

        except ImportError:
            logger.warning("âš ï¸ FotmobBrowserScraperV2 ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨åŸºç¡€ç‰ˆæœ¬")
            return await self._fallback_capture(match_id, match_name)
        except Exception as e:
            logger.error(f"âŒ è¯¦æƒ…æ•è·å¼‚å¸¸: {e}")
            return None

    async def _fallback_capture(self, match_id: int, match_name: str) -> Optional[str]:
        """å¤‡ç”¨æ•è·æ–¹æ¡ˆ"""
        logger.info("ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ•è·æ–¹æ¡ˆ")

        try:
            from src.data.collectors.fotmob_browser import FotmobBrowserScraper

            async with FotmobBrowserScraper() as scraper:
                # å°è¯•ä»åŒ¹é…åˆ—è¡¨è·å–æ›´è¯¦ç»†ä¿¡æ¯
                yesterday = datetime.now() - timedelta(days=1)
                date_str = yesterday.strftime("%Y-%m-%d")

                matches_data = await scraper.scrape_matches(date_str)

                if matches_data and "matches" in matches_data:
                    for match in matches_data["matches"]:
                        if match.get("id") == match_id:
                            logger.info("âœ… ä»æ¯”èµ›åˆ—è¡¨æ‰¾åˆ°è¯¦ç»†ä¿¡æ¯")
                            return json.dumps(match, indent=2, ensure_ascii=False)

                return None

        except Exception as e:
            logger.error(f"âŒ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e}")
            return None

    def inspect_data_depth(self, data_str: str) -> dict[str, Any]:
        """
        æ·±åº¦æ£€æŸ¥æ•°æ®å­—æ®µ

        Args:
            data_str: JSONå­—ç¬¦ä¸²æ ¼å¼çš„æ¯”èµ›æ•°æ®

        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        if not data_str:
            return {"error": "æ²¡æœ‰æ•°æ®å¯æ£€æŸ¥"}

        logger.info("ğŸ” å¼€å§‹æ·±åº¦æ•°æ®å–è¯...")

        try:
            data = json.loads(data_str)
        except json.JSONDecodeError as e:
            return {"error": f"JSONè§£æå¤±è´¥: {e}"}

        results = {
            "data_size_bytes": len(data_str.encode("utf-8")),
            "has_xG": False,
            "has_lineups": False,
            "has_ratings": False,
            "has_odds": False,
            "has_running_distance": False,
            "has_momentum": False,
            "detailed_findings": {},
            "sample_structure": {},
        }

        # 1. æ£€æŸ¥xGæ•°æ®
        logger.info("ğŸ“Š æ£€æŸ¥xGæ•°æ®...")
        xg_results = self._check_xg_data(data)
        results.update(xg_results)

        # 2. æ£€æŸ¥é˜µå®¹æ•°æ®
        logger.info("ğŸ‘¥ æ£€æŸ¥é˜µå®¹æ•°æ®...")
        lineup_results = self._check_lineup_data(data)
        results.update(lineup_results)

        # 3. æ£€æŸ¥çƒå‘˜è¯„åˆ†
        logger.info("â­ æ£€æŸ¥çƒå‘˜è¯„åˆ†...")
        rating_results = self._check_rating_data(data)
        results.update(rating_results)

        # 4. æ£€æŸ¥èµ”ç‡æ•°æ®
        logger.info("ğŸ’° æ£€æŸ¥èµ”ç‡æ•°æ®...")
        odds_results = self._check_odds_data(data)
        results.update(odds_results)

        # 5. æ£€æŸ¥è·‘åŠ¨è·ç¦»
        logger.info("ğŸƒ æ£€æŸ¥è·‘åŠ¨è·ç¦»...")
        distance_results = self._check_running_distance(data)
        results.update(distance_results)

        # 6. æ£€æŸ¥åŠ¿å¤´å›¾
        logger.info("ğŸ“ˆ æ£€æŸ¥åŠ¿å¤´å›¾...")
        momentum_results = self._check_momentum_data(data)
        results.update(momentum_results)

        # 7. ç”Ÿæˆæ ·æœ¬ç»“æ„
        logger.info("ğŸ—ºï¸ ç”Ÿæˆæ•°æ®ç»“æ„æ ·æœ¬...")
        results["sample_structure"] = self._generate_structure_sample(data)

        return results

    def _check_xg_data(self, data: dict[str, Any]) -> dict[str, Any]:
        """æ£€æŸ¥xGæ•°æ®"""
        results = {"has_xG": False, "xg_details": {}}

        xg_keywords = ["xg", "expected goals", "xg", "expectedgoals"]
        xg_found = self._deep_search(data, xg_keywords)

        if xg_found:
            results["has_xG"] = True
            results["xg_details"] = {
                "locations": xg_found,
                "sample_values": self._extract_sample_values(data, xg_found[:2]),
            }
            logger.info("âœ… å‘ç°xGæ•°æ®")
        else:
            logger.info("âŒ æœªå‘ç°xGæ•°æ®")

        return results

    def _check_lineup_data(self, data: dict[str, Any]) -> dict[str, Any]:
        """æ£€æŸ¥é˜µå®¹æ•°æ®"""
        results = {"has_lineups": False, "lineup_details": {}}

        lineup_keywords = ["lineup", "lineups", "starting xi", "players", "team"]
        lineup_found = self._deep_search(data, lineup_keywords)

        if lineup_found:
            results["has_lineups"] = True
            results["lineup_details"] = {
                "locations": lineup_found,
                "forward_names": self._extract_forward_names(data),
            }
            logger.info("âœ… å‘ç°é˜µå®¹æ•°æ®")
        else:
            logger.info("âŒ æœªå‘ç°é˜µå®¹æ•°æ®")

        return results

    def _check_rating_data(self, data: dict[str, Any]) -> dict[str, Any]:
        """æ£€æŸ¥çƒå‘˜è¯„åˆ†"""
        results = {"has_ratings": False, "rating_details": {}}

        rating_keywords = ["rating", "fotmob rating", "player rating", "score"]
        rating_found = self._deep_search(data, rating_keywords)

        if rating_found:
            results["has_ratings"] = True
            results["rating_details"] = {
                "locations": rating_found,
                "sample_ratings": self._extract_sample_values(data, rating_found[:3]),
            }
            logger.info("âœ… å‘ç°çƒå‘˜è¯„åˆ†æ•°æ®")
        else:
            logger.info("âŒ æœªå‘ç°çƒå‘˜è¯„åˆ†æ•°æ®")

        return results

    def _check_odds_data(self, data: dict[str, Any]) -> dict[str, Any]:
        """æ£€æŸ¥èµ”ç‡æ•°æ®"""
        results = {"has_odds": False, "odds_details": {}}

        odds_keywords = ["odds", "betting", "bookmaker", "price", "win", "draw"]
        odds_found = self._deep_search(data, odds_keywords)

        if odds_found:
            results["has_odds"] = True
            results["odds_details"] = {
                "locations": odds_found,
                "bookmakers": self._extract_bookmakers(data),
                "odds_type": self._determine_odds_type(data),
            }
            logger.info("âœ… å‘ç°èµ”ç‡æ•°æ®")
        else:
            logger.info("âŒ æœªå‘ç°èµ”ç‡æ•°æ®")

        return results

    def _check_running_distance(self, data: dict[str, Any]) -> dict[str, Any]:
        """æ£€æŸ¥è·‘åŠ¨è·ç¦»"""
        results = {"has_running_distance": False, "distance_details": {}}

        distance_keywords = ["distance", "km", "running", "cover", "meter", "miles"]
        distance_found = self._deep_search(data, distance_keywords)

        if distance_found:
            results["has_running_distance"] = True
            results["distance_details"] = {
                "locations": distance_found,
                "sample_distances": self._extract_sample_values(
                    data, distance_found[:3]
                ),
            }
            logger.info("âœ… å‘ç°è·‘åŠ¨è·ç¦»æ•°æ®")
        else:
            logger.info("âŒ æœªå‘ç°è·‘åŠ¨è·ç¦»æ•°æ®")

        return results

    def _check_momentum_data(self, data: dict[str, Any]) -> dict[str, Any]:
        """æ£€æŸ¥åŠ¿å¤´å›¾æ•°æ®"""
        results = {"has_momentum": False, "momentum_details": {}}

        momentum_keywords = ["momentum", "graph", "timeline", "pressure", "attack"]
        momentum_found = self._deep_search(data, momentum_keywords)

        if momentum_found:
            results["has_momentum"] = True
            results["momentum_details"] = {
                "locations": momentum_found,
                "sample_data": self._extract_sample_values(data, momentum_found[:2]),
            }
            logger.info("âœ… å‘ç°åŠ¿å¤´å›¾æ•°æ®")
        else:
            logger.info("âŒ æœªå‘ç°åŠ¿å¤´å›¾æ•°æ®")

        return results

    def _deep_search(self, data: Any, keywords: list[str], path: str = "") -> list[str]:
        """æ·±åº¦æœç´¢å…³é”®è¯"""
        found_paths = []

        if isinstance(data, dict):
            for key, value in data.items():
                current_path = f"{path}.{key}" if path else key

                # æ£€æŸ¥keyæ˜¯å¦åŒ¹é…å…³é”®è¯
                if any(keyword in key.lower() for keyword in keywords):
                    found_paths.append(current_path)

                # é€’å½’æœç´¢å€¼
                found_paths.extend(self._deep_search(value, keywords, current_path))

        elif isinstance(data, list):
            for i, item in enumerate(data):
                current_path = f"{path}[{i}]" if path else f"[{i}]"
                found_paths.extend(self._deep_search(item, keywords, current_path))

        return found_paths

    def _extract_forward_names(self, data: dict[str, Any]) -> list[str]:
        """æå–å‰é”‹åå­—"""
        forwards = []

        def extract_names_recursive(d, depth=0):
            if depth > 10:  # é˜²æ­¢æ— é™é€’å½’
                return

            if isinstance(d, dict):
                # æŸ¥æ‰¾å‰é”‹ç›¸å…³ä¿¡æ¯
                for key, value in d.items():
                    if any(
                        word in key.lower()
                        for word in ["forward", "striker", "attacker"]
                    ):
                        if isinstance(value, str):
                            forwards.append(value)
                        elif isinstance(value, dict) and "name" in value:
                            forwards.append(value["name"])

                    extract_names_recursive(value, depth + 1)

            elif isinstance(d, list):
                for item in d:
                    extract_names_recursive(item, depth + 1)

        extract_names_recursive(data)
        return forwards[:5]  # è¿”å›å‰5ä¸ªå‰é”‹åå­—

    def _extract_bookmakers(self, data: dict[str, Any]) -> list[str]:
        """æå–åšå½©å…¬å¸åç§°"""
        bookmakers = set()

        common_bookmakers = [
            "bet365",
            "william hill",
            "pinnacle",
            "betfair",
            "ladbrokes",
            "coral",
            "sky bet",
            "betway",
            "10bet",
            "marathonbet",
        ]

        def find_bookmakers_recursive(d, depth=0):
            if depth > 10:
                return

            if isinstance(d, str):
                lower_str = d.lower()
                for bookmaker in common_bookmakers:
                    if bookmaker in lower_str:
                        bookmakers.add(bookmaker)

            elif isinstance(d, dict):
                for key, value in d.items():
                    find_bookmakers_recursive(key, depth + 1)
                    find_bookmakers_recursive(value, depth + 1)

            elif isinstance(d, list):
                for item in d:
                    find_bookmakers_recursive(item, depth + 1)

        find_bookmakers_recursive(data)
        return list(bookmakers)

    def _determine_odds_type(self, data: dict[str, Any]) -> str:
        """åˆ¤æ–­èµ”ç‡ç±»å‹"""
        # ç®€å•åˆ¤æ–­ï¼šå¦‚æœæœ‰openingæˆ–initialå…³é”®å­—ï¼Œå¯èƒ½æ˜¯åˆç›˜
        if self._deep_search(data, ["opening", "initial", "first"]):
            return "å¯èƒ½åŒ…å«åˆç›˜"
        # å¦‚æœæœ‰closingæˆ–finalå…³é”®å­—ï¼Œå¯èƒ½æ˜¯ç»ˆç›˜
        elif self._deep_search(data, ["closing", "final", "last"]):
            return "å¯èƒ½åŒ…å«ç»ˆç›˜"
        else:
            return "æ— æ³•ç¡®å®šç±»å‹"

    def _extract_sample_values(
        self, data: dict[str, Any], paths: list[str]
    ) -> dict[str, Any]:
        """æå–æŒ‡å®šè·¯å¾„çš„æ ·æœ¬å€¼"""
        samples = {}

        for path in paths:
            try:
                value = self._get_value_by_path(data, path)
                if value is not None:
                    samples[path] = value
            except Exception:
                continue

        return samples

    def _get_value_by_path(self, data: dict[str, Any], path: str) -> Any:
        """æ ¹æ®è·¯å¾„è·å–å€¼"""
        current = data
        parts = path.split(".")

        for part in parts:
            if "[" in part and "]" in part:
                # å¤„ç†æ•°ç»„ç´¢å¼•
                key, index_str = part.split("[")
                index = int(index_str.rstrip("]"))
                current = current[key][index]
            else:
                current = current[part]

        return current

    def _generate_structure_sample(
        self, data: dict[str, Any], max_depth: int = 2
    ) -> dict[str, Any]:
        """ç”Ÿæˆæ•°æ®ç»“æ„æ ·æœ¬"""

        def get_structure(d, depth=0):
            if depth >= max_depth:
                return str(type(d).__name__)

            if isinstance(d, dict):
                return {k: get_structure(v, depth + 1) for k, v in list(d.items())[:5]}
            elif isinstance(d, list):
                return [get_structure(d[0], depth + 1)] if d else []
            else:
                return str(type(d).__name__)

        return get_structure(data)

    def generate_forensics_report(self, results: dict[str, Any]) -> str:
        """ç”Ÿæˆå–è¯æŠ¥å‘Š"""
        report = f"""
# ğŸ” æ•°æ®å–è¯ä¸“å®¶æŠ¥å‘Š

## ğŸ“Š åŸºç¡€ä¿¡æ¯
- **æ•°æ®å¤§å°**: {results.get('data_size_bytes', 0):,} å­—èŠ‚
- **æ£€æŸ¥æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ å…³é”®æ•°æ®æ£€æŸ¥ç»“æœ

### 1. xG (é¢„æœŸè¿›çƒ) æ•°æ®
- **çŠ¶æ€**: {'âœ… å­˜åœ¨' if results.get('has_xG') else 'âŒ ç¼ºå¤±'}
{self._format_details(results.get('xg_details', {}), 'xG')}

### 2. é˜µå®¹æ•°æ®
- **çŠ¶æ€**: {'âœ… å­˜åœ¨' if results.get('has_lineups') else 'âŒ ç¼ºå¤±'}
{self._format_details(results.get('lineup_details', {}), 'é˜µå®¹')}

### 3. çƒå‘˜è¯„åˆ†
- **çŠ¶æ€**: {'âœ… å­˜åœ¨' if results.get('has_ratings') else 'âŒ ç¼ºå¤±'}
{self._format_details(results.get('rating_details', {}), 'è¯„åˆ†')}

### 4. èµ”ç‡æ•°æ®
- **çŠ¶æ€**: {'âœ… å­˜åœ¨' if results.get('has_odds') else 'âŒ ç¼ºå¤±'}
{self._format_details(results.get('odds_details', {}), 'èµ”ç‡')}

### 5. è·‘åŠ¨è·ç¦»
- **çŠ¶æ€**: {'âœ… å­˜åœ¨' if results.get('has_running_distance') else 'âŒ ç¼ºå¤±'}
{self._format_details(results.get('distance_details', {}), 'è·‘åŠ¨è·ç¦»')}

### 6. åŠ¿å¤´å›¾
- **çŠ¶æ€**: {'âœ… å­˜åœ¨' if results.get('has_momentum') else 'âŒ ç¼ºå¤±'}
{self._format_details(results.get('momentum_details', {}), 'åŠ¿å¤´å›¾')}

## ğŸ—ºï¸ æ•°æ®ç»“æ„æ ·æœ¬
```json
{json.dumps(results.get('sample_structure', {}), indent=2, ensure_ascii=False)}
```

## ğŸ¯ å–è¯ç»“è®º
{self._generate_conclusion(results)}
"""
        return report

    def _format_details(self, details: dict[str, Any], category: str) -> str:
        """æ ¼å¼åŒ–è¯¦æƒ…ä¿¡æ¯"""
        if not details:
            return "   - æ— è¯¦ç»†ä¿¡æ¯"

        formatted = []

        if "locations" in details:
            formatted.append(f"   - ä½ç½®: {', '.join(details['locations'][:3])}")

        if "sample_values" in details:
            formatted.append(f"   - æ ·æœ¬å€¼: {details['sample_values']}")

        if "forward_names" in details and details["forward_names"]:
            formatted.append(
                f"   - å‰é”‹åå­—: {', '.join(details['forward_names'][:3])}"
            )

        if "bookmakers" in details and details["bookmakers"]:
            formatted.append(f"   - åšå½©å…¬å¸: {', '.join(details['bookmakers'])}")

        if "odds_type" in details:
            formatted.append(f"   - èµ”ç‡ç±»å‹: {details['odds_type']}")

        return "\n".join(formatted)

    def _generate_conclusion(self, results: dict[str, Any]) -> str:
        """ç”Ÿæˆç»“è®º"""
        positive_count = sum(
            [
                results.get("has_xG", False),
                results.get("has_lineups", False),
                results.get("has_ratings", False),
                results.get("has_odds", False),
                results.get("has_running_distance", False),
                results.get("has_momentum", False),
            ]
        )

        total_count = 6
        percentage = (positive_count / total_count) * 100

        if percentage >= 80:
            return f"ğŸ‰ **ä¼˜ç§€**: {positive_count}/{total_count} é¡¹æ ¸å¿ƒæ•°æ®å­˜åœ¨ ({percentage:.0f}%)ï¼ŒV2é‡‡é›†å™¨è¡¨ç°ä¼˜å¼‚ï¼"
        elif percentage >= 60:
            return f"âœ… **è‰¯å¥½**: {positive_count}/{total_count} é¡¹æ ¸å¿ƒæ•°æ®å­˜åœ¨ ({percentage:.0f}%)ï¼ŒV2é‡‡é›†å™¨åŸºæœ¬æ»¡è¶³éœ€æ±‚ã€‚"
        elif percentage >= 40:
            return f"âš ï¸ **ä¸€èˆ¬**: {positive_count}/{total_count} é¡¹æ ¸å¿ƒæ•°æ®å­˜åœ¨ ({percentage:.0f}%)ï¼ŒV2é‡‡é›†å™¨éœ€è¦æ”¹è¿›ã€‚"
        else:
            return f"âŒ **ä¸è¶³**: {positive_count}/{total_count} é¡¹æ ¸å¿ƒæ•°æ®å­˜åœ¨ ({percentage:.0f}%)ï¼ŒV2é‡‡é›†å™¨å­˜åœ¨ä¸¥é‡ç¼ºé™·ã€‚"


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ•µï¸ æ•°æ®å–è¯ä¸“å®¶å¼€å§‹å·¥ä½œ...")

    expert = DataForensicsExpert()

    try:
        # Step 1: å®šç‚¹ç‹™å‡» - æ•è·ç›®æ ‡æ¯”èµ›æ•°æ®
        logger.info("=" * 60)
        logger.info("Step 1: å®šç‚¹ç‹™å‡» - æ•è·ç›®æ ‡æ¯”èµ›æ•°æ®")
        logger.info("=" * 60)

        captured_data = await expert.capture_target_match()

        if not captured_data:
            logger.error("âŒ æ•°æ®æ•è·å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå–è¯åˆ†æ")
            sys.exit(1)

        # Step 2: æ·±åº¦å–è¯ - åˆ†ææ•°æ®å†…å®¹
        logger.info("\n" + "=" * 60)
        logger.info("Step 2: æ·±åº¦å–è¯ - åˆ†ææ•°æ®å†…å®¹")
        logger.info("=" * 60)

        results = expert.inspect_data_depth(captured_data)

        # Step 3: ç”ŸæˆæŠ¥å‘Š
        logger.info("\n" + "=" * 60)
        logger.info("Step 3: ç”Ÿæˆå–è¯æŠ¥å‘Š")
        logger.info("=" * 60)

        report = expert.generate_forensics_report(results)

        # æ‰“å°æŠ¥å‘Š
        print(report)

        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_path = "data_forensics_report.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        logger.info(f"ğŸ“„ è¯¦ç»†å–è¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

        # ä¿å­˜åŸå§‹æ•°æ®
        raw_data_path = "captured_match_data.json"
        with open(raw_data_path, "w", encoding="utf-8") as f:
            f.write(captured_data)

        logger.info(f"ğŸ“„ åŸå§‹æ•è·æ•°æ®å·²ä¿å­˜åˆ°: {raw_data_path}")

        # è¿”å›é€‚å½“çš„é€€å‡ºç 
        if results.get("has_lineups") and results.get("has_ratings"):
            logger.info("ğŸ‰ å–è¯æˆåŠŸï¼šå‘ç°å…³é”®æ•°æ®å­—æ®µ")
            sys.exit(0)
        else:
            logger.warning("âš ï¸ å–è¯å®Œæˆï¼šä½†ç¼ºå°‘å…³é”®æ•°æ®å­—æ®µ")
            sys.exit(1)

    except Exception as e:
        logger.error(f"âŒ å–è¯è¿‡ç¨‹å¤±è´¥: {e}")
        sys.exit(2)


if __name__ == "__main__":
    asyncio.run(main())
