#!/usr/bin/env python3
"""
Playwright L2 æ·±åº¦è¡¥å…¨è„šæœ¬

ä½¿ç”¨Playwrightæµè§ˆå™¨è‡ªåŠ¨åŒ–æ¥ç»•è¿‡åçˆ¬è™«æœºåˆ¶ï¼Œè·å–Lineups/Statsæ•°æ®
ç›®æ ‡ï¼šå¤„ç†26,000+æ¡è®°å½•ï¼Œç‰¹åˆ«æ˜¯data_completeness = 'partial'çš„è®°å½•
"""

import asyncio
import json
import logging
import sys
import os
import time
import psycopg2
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

try:
    from playwright.async_api import async_playwright, Page, Browser, BrowserContext
except ImportError as e:
    print("âŒ éœ€è¦å®‰è£…playwright: pip install playwright")
    print("ç„¶åè¿è¡Œ: playwright install chromium")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('playwright_l2_backfill.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class L2MatchResult:
    """L2å¤„ç†ç»“æœæ•°æ®ç»“æ„"""
    match_id: int
    success: bool
    lineups_count: int
    stats_count: int
    events_count: int
    processing_time: float
    error_message: Optional[str] = None


class PlaywrightL2Processor:
    """Playwright L2æ·±åº¦å¤„ç†å™¨"""

    def __init__(self):
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.processed_count = 0
        self.success_count = 0
        self.total_time = 0

    async def initialize(self):
        """åˆå§‹åŒ–Playwrightæµè§ˆå™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ–Playwrightæµè§ˆå™¨...")

        try:
            playwright = await async_playwright().start()

            # å¯åŠ¨æµè§ˆå™¨ï¼ˆä½¿ç”¨æ— å¤´æ¨¡å¼ï¼‰
            self.browser = await playwright.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-accelerated-2d-canvas',
                    '--disable-gpu',
                    '--window-size=1920,1080'
                ]
            )

            # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            )

            # åˆ›å»ºé¡µé¢
            self.page = await self.context.new_page()

            # è®¾ç½®ç½‘ç»œæ‹¦æˆª
            await self.page.route('**/*', self._handle_request)

            logger.info("âœ… Playwrightæµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.error(f"âŒ Playwrightåˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def _handle_request(self, route):
        """å¤„ç†ç½‘ç»œè¯·æ±‚"""
        await route.continue_()

    async def get_partial_matches(self, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–éœ€è¦å¤„ç†çš„partialè®°å½•"""
        try:
            conn = psycopg2.connect(
                host='db',
                database='football_prediction',
                user='postgres',
                password='postgres-dev-password',
                port='5432'
            )
            cursor = conn.cursor()

            query = """
            SELECT id, home_team_id, away_team_id, match_date, home_score, away_score,
                   stats, lineups, events, original_url, data_completeness
            FROM matches
            WHERE data_completeness = 'partial'
                AND home_score IS NOT NULL
                AND away_score IS NOT NULL
            LIMIT %s
            """

            cursor.execute(query, (limit,))
            columns = [desc[0] for desc in cursor.description]
            matches = [dict(zip(columns, row)) for row in cursor.fetchall()]

            cursor.close()
            conn.close()

            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(matches)} æ¡éœ€è¦å¤„ç†çš„è®°å½•")
            return matches

        except Exception as e:
            logger.error(f"âŒ è·å–è®°å½•å¤±è´¥: {e}")
            return []

    async def construct_match_url(self, match_data: Dict[str, Any]) -> Optional[str]:
        """æ„é€ æ¯”èµ›è¯¦æƒ…é¡µé¢URL"""
        match_id = match_data['id']

        # å°è¯•å¤šç§URLæ„é€ æ–¹å¼
        urls_to_try = [
            f"https://fbref.com/en/matches/{match_id}",
            f"https://www.fbref.com/en/matches/{match_id}",
            f"https://fbref.com/match/{match_id}",
        ]

        return urls_to_try[0]  # è¿”å›ç¬¬ä¸€ä¸ªå°è¯•çš„URL

    async def extract_match_details(self, url: str) -> Optional[Dict[str, Any]]:
        """ä»æ¯”èµ›é¡µé¢æå–è¯¦ç»†ä¿¡æ¯"""
        if not self.page:
            return None

        try:
            logger.info(f"ğŸŒ è®¿é—®é¡µé¢: {url}")
            start_time = time.time()

            # è®¿é—®é¡µé¢
            response = await self.page.goto(url, timeout=30000)

            if response.status != 200:
                logger.warning(f"âš ï¸ é¡µé¢çŠ¶æ€ç : {response.status}")
                return None

            # ç­‰å¾…é¡µé¢åŠ è½½
            await self.page.wait_for_load_state('networkidle', timeout=10000)

            # å°è¯•ç­‰å¾…å…³é”®å…ƒç´ 
            try:
                await self.page.wait_for_selector('table', timeout=5000)
            except:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°tableï¼Œå¯èƒ½éœ€è¦ä¸åŒçš„é€‰æ‹©å™¨
                pass

            # æå–é¡µé¢å†…å®¹
            page_content = await self.page.content()

            # åŸºç¡€HTMLè§£æ
            details = {
                'url': url,
                'page_title': await self.page.title(),
                'content_length': len(page_content),
                'lineups': await self._extract_lineups(),
                'stats': await self._extract_stats(),
                'events': await self._extract_events(),
                'access_time': time.time() - start_time
            }

            logger.info(f"âœ… é¡µé¢è®¿é—®æˆåŠŸï¼Œè€—æ—¶: {details['access_time']:.2f}s")
            return details

        except Exception as e:
            logger.error(f"âŒ é¡µé¢æå–å¤±è´¥: {e}")
            return None

    async def _extract_lineups(self) -> Optional[Dict[str, Any]]:
        """æå–é˜µå®¹æ•°æ®"""
        try:
            # å°è¯•æŸ¥æ‰¾é˜µå®¹ç›¸å…³å…ƒç´ 
            lineups_selectors = [
                'table.lineups',
                '[id*="lineup"]',
                '.lineup',
                'table:has(th:contains("Player"))'
            ]

            for selector in lineups_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        text = await element.text_content()
                        if text and len(text.strip()) > 50:  # æœ‰æ„ä¹‰çš„é˜µå®¹æ•°æ®
                            return {
                                'extracted': True,
                                'selector': selector,
                                'text_length': len(text),
                                'sample': text[:200] + '...' if len(text) > 200 else text
                            }
                except:
                    continue

            return {'extracted': False, 'message': 'No lineup data found'}

        except Exception as e:
            logger.warning(f"âš ï¸ é˜µå®¹æå–è­¦å‘Š: {e}")
            return {'extracted': False, 'error': str(e)}

    async def _extract_stats(self) -> Optional[Dict[str, Any]]:
        """æå–ç»Ÿè®¡æ•°æ®"""
        try:
            # å°è¯•æŸ¥æ‰¾ç»Ÿè®¡ç›¸å…³å…ƒç´ 
            stats_selectors = [
                'table.stats',
                '[id*="stats"]',
                '.stats',
                'table:has(th:contains("Stat"))',
                'div.stats'
            ]

            for selector in stats_selectors:
                try:
                    elements = await self.page.query_selector_all(selector)
                    if elements:
                        stats_data = []
                        for element in elements[:3]:  # åªå–å‰3ä¸ªé¿å…è¿‡å¤š
                            text = await element.text_content()
                            if text and len(text.strip()) > 20:
                                stats_data.append({
                                    'selector': selector,
                                    'text_length': len(text),
                                    'sample': text[:100] + '...' if len(text) > 100 else text
                                })

                        if stats_data:
                            return {
                                'extracted': True,
                                'data_count': len(stats_data),
                                'data': stats_data
                            }
                except:
                    continue

            return {'extracted': False, 'message': 'No stats data found'}

        except Exception as e:
            logger.warning(f"âš ï¸ ç»Ÿè®¡æå–è­¦å‘Š: {e}")
            return {'extracted': False, 'error': str(e)}

    async def _extract_events(self) -> Optional[Dict[str, Any]]:
        """æå–äº‹ä»¶æ•°æ®"""
        try:
            # å°è¯•æŸ¥æ‰¾äº‹ä»¶ç›¸å…³å…ƒç´ 
            events_selectors = [
                'table.events',
                '[id*="event"]',
                '.events',
                'table:has(th:contains("Minute"))'
            ]

            for selector in events_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        text = await element.text_content()
                        if text and len(text.strip()) > 30:  # æœ‰æ„ä¹‰çš„äº‹ä»¶æ•°æ®
                            return {
                                'extracted': True,
                                'selector': selector,
                                'text_length': len(text),
                                'sample': text[:200] + '...' if len(text) > 200 else text
                            }
                except:
                    continue

            return {'extracted': False, 'message': 'No events data found'}

        except Exception as e:
            logger.warning(f"âš ï¸ äº‹ä»¶æå–è­¦å‘Š: {e}")
            return {'extracted': False, 'error': str(e)}

    async def update_match_with_details(self, match_id: int, details: Dict[str, Any]) -> bool:
        """æ›´æ–°æ¯”èµ›è®°å½•çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            conn = psycopg2.connect(
                host='db',
                database='football_prediction',
                user='postgres',
                password='postgres-dev-password',
                port='5432'
            )
            cursor = conn.cursor()

            # è·å–ç°æœ‰æ•°æ®
            cursor.execute("SELECT stats, lineups, events FROM matches WHERE id = %s", (match_id,))
            result = cursor.fetchone()

            if result:
                existing_stats, existing_lineups, existing_events = result

                # æ›´æ–°æ•°æ®ï¼ˆå¦‚æœæå–åˆ°äº†æ–°æ•°æ®ï¼‰
                new_stats = existing_stats or {}
                new_lineups = existing_lineups or {}
                new_events = existing_events or {}

                # æ›´æ–°å­—æ®µ
                if details.get('lineups', {}).get('extracted'):
                    new_lineups.update({
                        'playwright_extracted': True,
                        'extraction_time': datetime.now().isoformat(),
                        'extraction_details': details['lineups']
                    })

                if details.get('stats', {}).get('extracted'):
                    new_stats.update({
                        'playwright_extracted': True,
                        'extraction_time': datetime.now().isoformat(),
                        'extraction_details': details['stats']
                    })

                if details.get('events', {}).get('extracted'):
                    new_events.update({
                        'playwright_extracted': True,
                        'extraction_time': datetime.now().isoformat(),
                        'extraction_details': details['events']
                    })

                # åˆ¤æ–­æ˜¯å¦åº”è¯¥æ ‡è®°ä¸ºcomplete
                has_new_data = any([
                    details.get('lineups', {}).get('extracted'),
                    details.get('stats', {}).get('extracted'),
                    details.get('events', {}).get('extracted')
                ])

                new_completeness = 'complete' if has_new_data else 'partial'

                # æ›´æ–°æ•°æ®åº“
                from psycopg2.extras import Json
                update_query = """
                UPDATE matches
                SET stats = %s, lineups = %s, events = %s,
                    data_completeness = %s, updated_at = NOW()
                WHERE id = %s
                """

                cursor.execute(update_query, (
                    Json(new_stats),
                    Json(new_lineups),
                    Json(new_events),
                    new_completeness,
                    match_id
                ))
                conn.commit()

                logger.info(f"âœ… æˆåŠŸæ›´æ–°æ¯”èµ› {match_id}ï¼Œå®Œæ•´åº¦: {new_completeness}")
                return True

            else:
                logger.error(f"âŒ æ‰¾ä¸åˆ°æ¯”èµ›è®°å½• {match_id}")
                return False

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ•°æ®åº“å¤±è´¥: {e}")
            return False
        finally:
            if 'conn' in locals():
                conn.close()

    async def process_single_match(self, match_data: Dict[str, Any]) -> L2MatchResult:
        """å¤„ç†å•æ¡æ¯”èµ›è®°å½•"""
        match_id = match_data['id']
        start_time = time.time()

        logger.info(f"ğŸ¯ å¼€å§‹å¤„ç†æ¯”èµ› {match_id}")

        try:
            # æ„é€ URL
            url = await self.construct_match_url(match_data)
            if not url:
                return L2MatchResult(
                    match_id=match_id,
                    success=False,
                    lineups_count=0,
                    stats_count=0,
                    events_count=0,
                    processing_time=0,
                    error_message="æ— æ³•æ„é€ URL"
                )

            # æå–è¯¦æƒ…
            details = await self.extract_match_details(url)
            if not details:
                return L2MatchResult(
                    match_id=match_id,
                    success=False,
                    lineups_count=0,
                    stats_count=0,
                    events_count=0,
                    processing_time=time.time() - start_time,
                    error_message="é¡µé¢è®¿é—®å¤±è´¥"
                )

            # æ›´æ–°æ•°æ®åº“
            update_success = await self.update_match_with_details(match_id, details)

            # ç»Ÿè®¡æå–çš„æ•°æ®é‡
            lineups_count = 1 if details.get('lineups', {}).get('extracted') else 0
            stats_count = len(details.get('stats', {}).get('data', [])) if details.get('stats', {}).get('extracted') else 0
            events_count = 1 if details.get('events', {}).get('extracted') else 0

            processing_time = time.time() - start_time

            return L2MatchResult(
                match_id=match_id,
                success=update_success,
                lineups_count=lineups_count,
                stats_count=stats_count,
                events_count=events_count,
                processing_time=processing_time
            )

        except Exception as e:
            logger.error(f"ğŸ’¥ å¤„ç†æ¯”èµ› {match_id} å¼‚å¸¸: {e}")
            return L2MatchResult(
                match_id=match_id,
                success=False,
                lineups_count=0,
                stats_count=0,
                events_count=0,
                processing_time=time.time() - start_time,
                error_message=str(e)
            )

    async def process_matches_batch(self, batch_size: int = 50):
        """æ‰¹é‡å¤„ç†æ¯”èµ›è®°å½•"""
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")

        await self.initialize()

        try:
            while True:
                # è·å–å¾…å¤„ç†è®°å½•
                matches = await self.get_partial_matches(batch_size)

                if not matches:
                    logger.info("âœ… æ²¡æœ‰æ›´å¤šå¾…å¤„ç†è®°å½•")
                    break

                logger.info(f"ğŸ“‹ å¤„ç†æ‰¹æ¬¡: {len(matches)} æ¡è®°å½•")

                # å¤„ç†æ¯æ¡è®°å½•
                batch_results = []
                for i, match in enumerate(matches, 1):
                    logger.info(f"ğŸ“ å¤„ç†è¿›åº¦: {i}/{len(matches)}")

                    result = await self.process_single_match(match)
                    batch_results.append(result)

                    # æ›´æ–°ç»Ÿè®¡
                    self.processed_count += 1
                    if result.success:
                        self.success_count += 1
                    self.total_time += result.processing_time

                    # çŸ­æš‚ä¼‘æ¯
                    await asyncio.sleep(2)

                # è¾“å‡ºæ‰¹æ¬¡ç»“æœ
                self._print_batch_summary(batch_results)

                # å¦‚æœæˆåŠŸå¤„ç†äº†ä¸€äº›è®°å½•ï¼Œç»§ç»­ä¸‹ä¸€æ‰¹
                if self.success_count > 0:
                    logger.info("ğŸ¯ æœ¬æ‰¹æ¬¡æœ‰æˆåŠŸè®°å½•ï¼Œç»§ç»­ä¸‹ä¸€æ‰¹...")
                else:
                    logger.warning("âš ï¸ æœ¬æ‰¹æ¬¡æ²¡æœ‰æˆåŠŸè®°å½•ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç­–ç•¥")
                    break

        except KeyboardInterrupt:
            logger.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        except Exception as e:
            logger.error(f"ğŸ’¥ æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
        finally:
            await self.cleanup()

    def _print_batch_summary(self, results: List[L2MatchResult]):
        """è¾“å‡ºæ‰¹æ¬¡å¤„ç†æ€»ç»“"""
        successful = sum(1 for r in results if r.success)
        total_lineups = sum(r.lineups_count for r in results)
        total_stats = sum(r.stats_count for r in results)
        total_events = sum(r.events_count for r in results)
        avg_time = sum(r.processing_time for r in results) / len(results) if results else 0

        print("\n" + "="*60)
        print("ğŸ† æ‰¹æ¬¡å¤„ç†æ€»ç»“")
        print("="*60)
        print(f"ğŸ“Š æœ¬æ‰¹æ¬¡è®°å½•æ•°: {len(results)}")
        print(f"âœ… æˆåŠŸå¤„ç†: {successful}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {successful/len(results)*100:.1f}%")
        print(f"ğŸ‘¥ é˜µå®¹æ•°æ®: {total_lineups} æ¡")
        print(f"ğŸ“Š ç»Ÿè®¡æ•°æ®: {total_stats} æ¡")
        print(f"âš¡ äº‹ä»¶æ•°æ®: {total_events} æ¡")
        print(f"â±ï¸  å¹³å‡è€—æ—¶: {avg_time:.2f}s/è®°å½•")
        print("="*60)

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.page:
            await self.page.close()
        if self.context:
            await self.context.close()
        if self.browser:
            await self.browser.close()
        logger.info("ğŸ§¹ æµè§ˆå™¨èµ„æºå·²æ¸…ç†")

    async def print_final_summary(self):
        """è¾“å‡ºæœ€ç»ˆæ€»ç»“"""
        print("\n" + "="*80)
        print("ğŸ† Playwright L2 å¤„ç†æœ€ç»ˆæ€»ç»“")
        print("="*80)
        print(f"ğŸ“Š æ€»å¤„ç†è®°å½•æ•°: {self.processed_count}")
        print(f"âœ… æˆåŠŸå¤„ç†è®°å½•æ•°: {self.success_count}")
        print(f"ğŸ“ˆ æ€»ä½“æˆåŠŸç‡: {self.success_count/max(1, self.processed_count)*100:.1f}%")
        print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {self.total_time:.2f}s")
        if self.processed_count > 0:
            print(f"ğŸ“Š å¹³å‡å¤„ç†æ—¶é—´: {self.total_time/self.processed_count:.2f}s/è®°å½•")
        print("="*80)


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Playwright L2 æ·±åº¦è¡¥å…¨å¼•æ“å¯åŠ¨")
    print("è¿™æ˜¯è·å–Lineups/Statsçš„æœ€åä¸€çº¿å¸Œæœ›ï¼")
    print("="*60)

    processor = PlaywrightL2Processor()

    try:
        # å¤„ç†å‰å‡ æ¡è®°å½•ä½œä¸ºéªŒè¯
        await processor.process_matches_batch(batch_size=10)

        # è¾“å‡ºæœ€ç»ˆæ€»ç»“
        await processor.print_final_summary()

    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸»ç¨‹åºå¼‚å¸¸: {e}")
    finally:
        await processor.cleanup()


if __name__ == "__main__":
    asyncio.run(main())