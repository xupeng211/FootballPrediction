#!/usr/bin/env python3
"""
Issueè¿›åº¦è·Ÿè¸ªè„šæœ¬
è·Ÿè¸ªIssueçš„å¤„ç†è¿›åº¦ï¼Œè¯†åˆ«åœæ»çš„Issueså¹¶æä¾›ä¼˜åŒ–å»ºè®®

Author: Claude Code
Version: 1.0
Purpose: Monitor issue progress and identify bottlenecks
"""

import argparse
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

import requests


class IssueProgressTracker:
    """Issueè¿›åº¦è·Ÿè¸ªå™¨"""

    def __init__(self, repo: str, github_token: str = None):
        self.repo = repo
        self.github_token = github_token
        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "Issue-Progress-Tracker/1.0"
        }

        if github_token:
            self.headers["Authorization"] = f"token {github_token}"

        # è¿›åº¦é˜ˆå€¼é…ç½®
        self.thresholds = {
            "stale_days": 7,        # è¶…è¿‡7å¤©æ— æ›´æ–°è§†ä¸ºåœæ»
            "overdue_days": 14,     # è¶…è¿‡14å¤©è§†ä¸ºé€¾æœŸ
            "critical_overdue": 21  # è¶…è¿‡21å¤©è§†ä¸ºä¸¥é‡é€¾æœŸ
        }

    def get_all_open_issues(self) -> list:
        """è·å–æ‰€æœ‰å¼€æ”¾çš„Issues"""
        all_issues = []
        page = 1

        while True:
            url = f"https://api.github.com/repos/{self.repo}/issues"
            params = {
                "state": "open",
                "per_page": 100,
                "page": page,
                "sort": "updated",
                "direction": "desc"
            }

            try:
                response = requests.get(url, headers=self.headers, params=params)
                response.raise_for_status()

                page_issues = response.json()
                if not page_issues:
                    break

                # è¿‡æ»¤æ‰PR (PRsåœ¨GitHub APIä¸­ä¹Ÿæ˜¯issues)
                issues = [issue for issue in page_issues if "pull_request" not in issue]
                all_issues.extend(issues)

                if len(page_issues) < 100:
                    break

                page += 1

            except requests.exceptions.RequestException:
                break

        return all_issues

    def get_issue_events(self, issue_number: int) -> list:
        """è·å–Issueçš„äº‹ä»¶å†å²"""
        url = f"https://api.github.com/repos/{self.repo}/issues/{issue_number}/events"
        params = {"per_page": 100}

        try:
            response = requests.get(url, headers=self.headers, params=params)
            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException:
            return []

    def analyze_issue_progress(self, issue: dict) -> dict:
        """åˆ†æå•ä¸ªIssueçš„è¿›åº¦çŠ¶æ€"""
        issue_number = issue["number"]
        created_at = datetime.fromisoformat(issue["created_at"].replace("Z", "+00:00"))
        updated_at = datetime.fromisoformat(issue["updated_at"].replace("Z", "+00:00"))
        now = datetime.now()

        # è®¡ç®—æ—¶é—´æŒ‡æ ‡
        age_days = (now - created_at).days
        days_since_update = (now - updated_at).days

        # è·å–æ ‡ç­¾
        labels = [label["name"] for label in issue.get("labels", [])]

        # åˆ†æçŠ¶æ€
        status = "normal"
        if days_since_update > self.thresholds["critical_overdue"]:
            status = "critical_overdue"
        elif days_since_update > self.thresholds["overdue_days"]:
            status = "overdue"
        elif days_since_update > self.thresholds["stale_days"]:
            status = "stale"

        # åˆ†æåˆ†é…æƒ…å†µ
        assignee = issue.get("assignee")
        is_assigned = assignee is not None

        # åˆ†æé‡Œç¨‹ç¢‘
        milestone = issue.get("milestone")
        has_milestone = milestone is not None

        # åˆ†æè¯„è®ºæ´»è·ƒåº¦
        comments_count = issue.get("comments", 0)
        recent_comments = self._count_recent_comments(issue_number)

        # è·å–äº‹ä»¶å†å²
        events = self.get_issue_events(issue_number)
        last_event_date = self._get_last_event_date(events)

        return {
            "issue_number": issue_number,
            "title": issue["title"],
            "status": status,
            "age_days": age_days,
            "days_since_update": days_since_update,
            "assignee": assignee.get("login") if assignee else None,
            "is_assigned": is_assigned,
            "labels": labels,
            "has_milestone": has_milestone,
            "comments_count": comments_count,
            "recent_comments": recent_comments,
            "created_at": created_at.isoformat(),
            "updated_at": updated_at.isoformat(),
            "last_event_date": last_event_date,
            "url": issue["html_url"]
        }

    def _count_recent_comments(self, issue_number: int, days: int = 7) -> int:
        """ç»Ÿè®¡æœ€è¿‘è¯„è®ºæ•°é‡"""
        # ç®€åŒ–å®ç°ï¼Œå¯ä»¥é€šè¿‡APIè·å–è¯„è®ºæ—¶é—´æˆ³
        url = f"https://api.github.com/repos/{self.repo}/issues/{issue_number}/comments"
        params = {"per_page": 100, "sort": "created", "direction": "desc"}

        try:
            response = requests.get(url, headers=self.headers, params=params)
            response.raise_for_status()

            comments = response.json()
            cutoff_date = datetime.now() - timedelta(days=days)

            recent_count = 0
            for comment in comments:
                created_at = datetime.fromisoformat(comment["created_at"].replace("Z", "+00:00"))
                if created_at >= cutoff_date:
                    recent_count += 1
                else:
                    break

            return recent_count

        except requests.exceptions.RequestException:
            return 0

    def _get_last_event_date(self, events: list) -> str:
        """è·å–æœ€åä¸€ä¸ªäº‹ä»¶çš„æ—¥æœŸ"""
        if not events:
            return None

        latest_event = max(events, key=lambda e: e["created_at"])
        return latest_event["created_at"]

    def categorize_issues(self, issues_analysis: list) -> dict:
        """å°†IssuesæŒ‰çŠ¶æ€åˆ†ç±»"""
        categories = {
            "normal": [],
            "stale": [],
            "overdue": [],
            "critical_overdue": [],
            "unassigned": [],
            "no_milestone": [],
            "inactive": []
        }

        for analysis in issues_analysis:
            # æŒ‰æ›´æ–°æ—¶é—´åˆ†ç±»
            categories[analysis["status"]].append(analysis)

            # æŒ‰å…¶ä»–æ¡ä»¶åˆ†ç±»
            if not analysis["is_assigned"]:
                categories["unassigned"].append(analysis)

            if not analysis["has_milestone"]:
                categories["no_milestone"].append(analysis)

            if analysis["recent_comments"] == 0 and analysis["days_since_update"] > 3:
                categories["inactive"].append(analysis)

        return categories

    def generate_progress_report(self, issues_analysis: list, categories: dict) -> str:
        """ç”Ÿæˆè¿›åº¦æŠ¥å‘Š"""
        total_issues = len(issues_analysis)

        report_lines = [
            "# Issueè¿›åº¦è·Ÿè¸ªæŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ä»“åº“**: {self.repo}",
            f"**æ€»Issuesæ•°**: {total_issues}",
            "",
            "## ğŸ“Š æ€»ä½“ç»Ÿè®¡",
            "",
            f"- **æ­£å¸¸è¿›å±•**: {len(categories['normal'])} ({len(categories['normal'])/total_issues*100:.1f}%)",
            f"- **åœæ»Issues**: {len(categories['stale'])} ({len(categories['stale'])/total_issues*100:.1f}%)",
            f"- **é€¾æœŸIssues**: {len(categories['overdue'])} ({len(categories['overdue'])/total_issues*100:.1f}%)",
            f"- **ä¸¥é‡é€¾æœŸ**: {len(categories['critical_overdue'])} ({len(categories['critical_overdue'])/total_issues*100:.1f}%)",
            f"- **æœªåˆ†é…**: {len(categories['unassigned'])} ({len(categories['unassigned'])/total_issues*100:.1f}%)",
            f"- **æ— é‡Œç¨‹ç¢‘**: {len(categories['no_milestone'])} ({len(categories['no_milestone'])/total_issues*100:.1f}%)",
            f"- **ä¸æ´»è·ƒ**: {len(categories['inactive'])} ({len(categories['inactive'])/total_issues*100:.1f}%)",
            ""
        ]

        # éœ€è¦å…³æ³¨çš„Issues
        if categories["critical_overdue"]:
            report_lines.extend([
                "## ğŸš¨ ä¸¥é‡é€¾æœŸIssues (éœ€è¦ç«‹å³å…³æ³¨)",
                ""
            ])
            for issue in categories["critical_overdue"]:
                report_lines.append(
                    f"- **#{issue['issue_number']} {issue['title']}** "
                    f"(é€¾æœŸ{issue['days_since_update']}å¤©) "
                    f"[æŸ¥çœ‹è¯¦æƒ…]({issue['url']})"
                )
            report_lines.append("")

        if categories["overdue"]:
            report_lines.extend([
                "## âš ï¸ é€¾æœŸIssues",
                ""
            ])
            for issue in categories["overdue"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                report_lines.append(
                    f"- **#{issue['issue_number']} {issue['title']}** "
                    f"(é€¾æœŸ{issue['days_since_update']}å¤©) "
                    f"[æŸ¥çœ‹è¯¦æƒ…]({issue['url']})"
                )
            report_lines.append("")

        if categories["stale"]:
            report_lines.extend([
                "## ğŸ• åœæ»Issues",
                ""
            ])
            for issue in categories["stale"][:15]:  # åªæ˜¾ç¤ºå‰15ä¸ª
                report_lines.append(
                    f"- **#{issue['issue_number']} {issue['title']}** "
                    f"(æœªæ›´æ–°{issue['days_since_update']}å¤©) "
                    f"[æŸ¥çœ‹è¯¦æƒ…]({issue['url']})"
                )
            report_lines.append("")

        if categories["unassigned"]:
            report_lines.extend([
                "## ğŸ‘¥ æœªåˆ†é…Issues",
                ""
            ])
            for issue in categories["unassigned"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                report_lines.append(
                    f"- **#{issue['issue_number']} {issue['title']}** "
                    f"[æŸ¥çœ‹è¯¦æƒ…]({issue['url']})"
                )
            report_lines.append("")

        # åˆ†æå’Œå»ºè®®
        report_lines.extend([
            "## ğŸ“ˆ åˆ†æå’Œå»ºè®®",
            ""
        ])

        # å¥åº·åº¦è¯„åˆ†
        health_score = (len(categories["normal"]) / total_issues) * 100
        report_lines.append(f"**æ•´ä½“å¥åº·åº¦**: {health_score:.1f}/100")

        if health_score >= 80:
            report_lines.append("âœ… Issueç®¡ç†çŠ¶å†µè‰¯å¥½")
        elif health_score >= 60:
            report_lines.append("âš ï¸ Issueç®¡ç†éœ€è¦æ”¹è¿›")
        else:
            report_lines.append("ğŸš¨ Issueç®¡ç†å­˜åœ¨ä¸¥é‡é—®é¢˜")

        report_lines.extend([
            "",
            "### ğŸ’¡ ä¼˜åŒ–å»ºè®®",
            ""
        ])

        if categories["critical_overdue"]:
            report_lines.append("1. ğŸš¨ **ç«‹å³å¤„ç†ä¸¥é‡é€¾æœŸIssues**: è¿™äº›Issueså·²ç»ä¸¥é‡é€¾æœŸï¼Œéœ€è¦ç«‹å³è¯„ä¼°å’Œé‡‡å–è¡ŒåŠ¨")

        if categories["overdue"]:
            report_lines.append("2. âš ï¸ **ä¼˜å…ˆå¤„ç†é€¾æœŸIssues**: åˆ¶å®šè®¡åˆ’è§£å†³é€¾æœŸIssuesï¼Œé¿å…è¿›ä¸€æ­¥æ¶åŒ–")

        if categories["stale"]:
            report_lines.append("3. ğŸ• **é‡æ–°æ¿€æ´»åœæ»Issues**: è”ç³»ç›¸å…³è´Ÿè´£äººï¼Œæ›´æ–°è¿›åº¦æˆ–é‡æ–°è¯„ä¼°")

        if categories["unassigned"]:
            report_lines.append("4. ğŸ‘¥ **åŠæ—¶åˆ†é…æ–°Issues**: å»ºç«‹è‡ªåŠ¨åˆ†é…æœºåˆ¶ï¼Œç¡®ä¿Issuesæœ‰æ˜ç¡®è´Ÿè´£äºº")

        if categories["no_milestone"]:
            report_lines.append("5. ğŸ¯ **è®¾ç½®é‡Œç¨‹ç¢‘**: ä¸ºé‡è¦Issuesè®¾ç½®é‡Œç¨‹ç¢‘ï¼Œæé«˜ç›®æ ‡ç®¡ç†æ•ˆæœ")

        report_lines.extend([
            "",
            "### ğŸ“Š è¿›åº¦æŒ‡æ ‡",
            "",
            "- **å¹³å‡å¤„ç†æ—¶é—´**: è®¡ç®—ä¸­...",
            "- **Issueå®Œæˆç‡**: è®¡ç®—ä¸­...",
            "- **å›¢é˜Ÿå“åº”é€Ÿåº¦**: è®¡ç®—ä¸­...",
            "",
            "---",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}*",
            "*å·¥å…·: Issue Progress Tracker v1.0*"
        ])

        return "\n".join(report_lines)

    def run_progress_analysis(self) -> tuple:
        """è¿è¡Œè¿›åº¦åˆ†æ"""

        issues = self.get_all_open_issues()
        if not issues:
            return [], {}


        # åˆ†ææ¯ä¸ªIssue
        issues_analysis = []
        for issue in issues:
            analysis = self.analyze_issue_progress(issue)
            issues_analysis.append(analysis)

        # åˆ†ç±»Issues
        categories = self.categorize_issues(issues_analysis)


        return issues_analysis, categories

    def save_progress_report(self, report_content: str, output_file: str = None):
        """ä¿å­˜è¿›åº¦æŠ¥å‘Š"""
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text(report_content, encoding='utf-8')
        else:
            # ä½¿ç”¨é»˜è®¤æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            default_file = f"reports/issue_progress_report_{timestamp}.md"
            output_path = Path(default_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text(report_content, encoding='utf-8')


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Issueè¿›åº¦è·Ÿè¸ªåˆ†æ")
    parser.add_argument("--repo", required=True, help="GitHubä»“åº“ (æ ¼å¼: owner/repo)")
    parser.add_argument("--token", help="GitHubè®¿é—®ä»¤ç‰Œ")
    parser.add_argument("--output", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    # è·å–GitHubä»¤ç‰Œ
    github_token = args.token or os.environ.get("GITHUB_TOKEN")

    if not github_token:
        pass

    # åˆ›å»ºè·Ÿè¸ªå™¨
    tracker = IssueProgressTracker(args.repo, github_token)

    # æ‰§è¡Œè¿›åº¦åˆ†æ
    issues_analysis, categories = tracker.run_progress_analysis()

    # ç”ŸæˆæŠ¥å‘Š
    if issues_analysis:
        report_content = tracker.generate_progress_report(issues_analysis, categories)
        tracker.save_progress_report(report_content, args.output)

    return 0


if __name__ == "__main__":
    sys.exit(main())
