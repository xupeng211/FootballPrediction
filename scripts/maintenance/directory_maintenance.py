#!/usr/bin/env python3
"""
ç›®å½•ç»´æŠ¤è‡ªåŠ¨åŒ–è„šæœ¬
Directory Maintenance Automation Script

ç”¨äºè‡ªåŠ¨åŒ–ç»´æŠ¤FootballPredictioné¡¹ç›®çš„ç›®å½•ç»“æ„
åŒ…å«æ¸…ç†ã€æ£€æŸ¥ã€å½’æ¡£ã€ç›‘æ§ç­‰åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
    python3 scripts/maintenance/directory_maintenance.py [é€‰é¡¹]

ä½œè€…: Claude AI Assistant
ç‰ˆæœ¬: v1.0
åˆ›å»ºæ—¶é—´: 2025-11-03
"""

import os
import sys
import json
import shutil
import argparse
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple

class DirectoryMaintenance:
    """ç›®å½•ç»´æŠ¤ä¸»ç±»"""

    def __init__(self, project_root: Optional[Path] = None):
        """åˆå§‹åŒ–ç»´æŠ¤å·¥å…·"""
        self.project_root = project_root or Path(__file__).parent.parent.parent
        self.docs_dir = self.project_root / "docs"
        self.scripts_dir = self.project_root / "scripts"
        self.config_dir = self.project_root / "config"

        # ç»´æŠ¤é…ç½®
        self.temp_extensions = ['.tmp', '.bak', '.log', '.swp', '.swo']
        self.cache_dirs = ['__pycache__', '.pytest_cache', '.ruff_cache', '.mypy_cache']
        self.legacy_patterns = [
            'quality_report_*.json',
            'coverage_*.json',
            'improvement-report-*.md',
            'ci_coverage_report_*.json'
        ]

        # å¥åº·æŒ‡æ ‡é˜ˆå€¼
        self.max_root_files = 400
        self.max_empty_dirs = 5
        self.archive_days = 30

    def clean_temp_files(self) -> int:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        cleaned_count = 0
        total_size_freed = 0

        print("ğŸ§¹ å¼€å§‹æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")

        for ext in self.temp_extensions:
            for file_path in self.project_root.rglob(f"*{ext}"):
                if file_path.is_file():
                    file_size = file_path.stat().st_size
                    file_path.unlink()
                    cleaned_count += 1
                    total_size_freed += file_size

        # æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶
        cache_files = list(self.project_root.rglob("*.pyc")) + \
                     list(self.project_root.rglob("*.pyo")) + \
                     list(self.project_root.rglob("*.pyd"))

        for file_path in cache_files:
            if file_path.is_file():
                file_size = file_path.stat().st_size
                file_path.unlink()
                cleaned_count += 1
                total_size_freed += file_size

        size_mb = round(total_size_freed / (1024 * 1024), 2)
        print(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªä¸´æ—¶æ–‡ä»¶ï¼Œé‡Šæ”¾ {size_mb} MB ç©ºé—´")
        return cleaned_count

    def clean_cache_dirs(self) -> int:
        """æ¸…ç†ç¼“å­˜ç›®å½•"""
        cleaned_count = 0

        print("ğŸ—‚ï¸  å¼€å§‹æ¸…ç†ç¼“å­˜ç›®å½•...")

        for cache_dir in self.cache_dirs:
            for dir_path in self.project_root.rglob(cache_dir):
                if dir_path.is_dir():
                    try:
                        shutil.rmtree(dir_path)
                        cleaned_count += 1
                    except OSError as e:
                        print(f"âš ï¸  æ— æ³•åˆ é™¤ç›®å½• {dir_path}: {e}")

        print(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªç¼“å­˜ç›®å½•")
        return cleaned_count

    def check_misplaced_files(self) -> List[Path]:
        """æ£€æŸ¥é”™è¯¯æ”¾ç½®çš„æ–‡ä»¶"""
        misplaced_files = []

        print("ğŸ” å¼€å§‹æ£€æŸ¥é”™è¯¯æ”¾ç½®çš„æ–‡ä»¶...")

        # æ£€æŸ¥æ ¹ç›®å½•ä¸‹çš„Pythonæ–‡ä»¶
        for file_path in self.project_root.glob("*.py"):
            if file_path.name != "manage.py":  # æ’é™¤ç®¡ç†è„šæœ¬
                misplaced_files.append(file_path)

        # æ£€æŸ¥æ ¹ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶
        config_patterns = ["*.ini", "*.toml", "*.yml", "*.yaml"]
        for pattern in config_patterns:
            for file_path in self.project_root.glob(pattern):
                # ä¿ç•™ä¸€äº›ç‰¹æ®Šæ–‡ä»¶
                if file_path.name not in ["alembic.ini"]:  # ä¿ç•™ç¬¦å·é“¾æ¥
                    misplaced_files.append(file_path)

        # æ£€æŸ¥æ ¹ç›®å½•ä¸‹çš„å¤§é‡JSONæŠ¥å‘Šæ–‡ä»¶
        json_reports = list(self.project_root.glob("quality_report_*.json")) + \
                      list(self.project_root.glob("coverage_*.json"))
        misplaced_files.extend(json_reports)

        # æ£€æŸ¥æ ¹ç›®å½•ä¸‹çš„ä¸´æ—¶ç›®å½•
        temp_dirs = [".pytest_cache", "__pycache__", ".ruff_cache", ".mypy_cache"]
        for temp_dir in temp_dirs:
            dir_path = self.project_root / temp_dir
            if dir_path.exists():
                misplaced_files.append(dir_path)

        if misplaced_files:
            print(f"âš ï¸  å‘ç° {len(misplaced_files)} ä¸ªå¯èƒ½é”™è¯¯æ”¾ç½®çš„æ–‡ä»¶/ç›®å½•:")
            for item in misplaced_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                item_type = "ç›®å½•" if item.is_dir() else "æ–‡ä»¶"
                print(f"   - {item_type}: {item}")
            if len(misplaced_files) > 10:
                print(f"   - ... è¿˜æœ‰ {len(misplaced_files) - 10} ä¸ª")
        else:
            print("âœ… æœªå‘ç°æ˜æ˜¾é”™è¯¯æ”¾ç½®çš„æ–‡ä»¶")

        return misplaced_files

    def find_empty_dirs(self) -> List[Path]:
        """æŸ¥æ‰¾ç©ºç›®å½•"""
        empty_dirs = []

        print("ğŸ“ å¼€å§‹æŸ¥æ‰¾ç©ºç›®å½•...")

        for dir_path in self.project_root.rglob("*"):
            if dir_path.is_dir() and not any(dir_path.iterdir()):
                # æ’é™¤ä¸€äº›ç‰¹æ®Šç›®å½•
                if not any(parent.name in ['.git', '.venv', 'node_modules'] for parent in dir_path.parents):
                    empty_dirs.append(dir_path)

        if empty_dirs:
            print(f"âš ï¸  å‘ç° {len(empty_dirs)} ä¸ªç©ºç›®å½•:")
            for dir_path in empty_dirs[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"   - {dir_path}")
            if len(empty_dirs) > 10:
                print(f"   - ... è¿˜æœ‰ {len(empty_dirs) - 10} ä¸ª")
        else:
            print("âœ… æœªå‘ç°ç©ºç›®å½•")

        return empty_dirs

    def check_naming_conventions(self) -> Dict[str, List[str]]:
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        violations = {
            "snake_case_files": [],
            "kebab_case_dirs": [],
            "other_issues": []
        }

        print("ğŸ“ å¼€å§‹æ£€æŸ¥å‘½åè§„èŒƒ...")

        # æ£€æŸ¥ç›®å½•å‘½å (åº”è¯¥æ˜¯kebab-case)
        for dir_path in self.project_root.rglob("*"):
            if dir_path.is_dir() and dir_path.parent == self.project_root:
                dir_name = dir_path.name
                if '_' in dir_name and not dir_name.startswith('.'):
                    violations["kebab_case_dirs"].append(dir_name)

        # æ£€æŸ¥Pythonæ–‡ä»¶å‘½å (åº”è¯¥æ˜¯snake_case)
        for file_path in self.project_root.rglob("*.py"):
            file_name = file_path.stem
            if '-' in file_name or ' ' in file_name:
                violations["snake_case_files"].append(str(file_path))

        # ç»Ÿè®¡è¿è§„æ•°é‡
        total_violations = sum(len(items) for items in violations.values())
        if total_violations > 0:
            print(f"âš ï¸  å‘ç° {total_violations} ä¸ªå‘½åè§„èŒƒé—®é¢˜:")
            for violation_type, items in violations.items():
                if items:
                    print(f"   - {violation_type}: {len(items)} ä¸ª")
                    for item in items[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"     * {item}")
                    if len(items) > 3:
                        print(f"     * ... è¿˜æœ‰ {len(items) - 3} ä¸ª")
        else:
            print("âœ… å‘½åè§„èŒƒæ£€æŸ¥é€šè¿‡")

        return violations

    def archive_old_reports(self, days_old: int = None) -> int:
        """å½’æ¡£æ—§æŠ¥å‘Š"""
        days_old = days_old or self.archive_days
        cutoff_date = datetime.now() - timedelta(days=days_old)
        archived_count = 0

        print(f"ğŸ“¦ å¼€å§‹å½’æ¡£ {days_old} å¤©å‰çš„æŠ¥å‘Š...")

        # ç¡®ä¿å½’æ¡£ç›®å½•å­˜åœ¨
        archive_dir = self.docs_dir / "reports" / "legacy"
        archive_dir.mkdir(parents=True, exist_ok=True)

        # å½’æ¡£æ—§çš„JSONæŠ¥å‘Š
        for pattern in self.legacy_patterns:
            for report_path in self.project_root.glob(pattern):
                if report_path.is_file():
                    try:
                        # ä»æ–‡ä»¶åè§£ææ—¥æœŸ
                        file_date_str = self._extract_date_from_filename(report_path.name)
                        if file_date_str:
                            file_date = datetime.strptime(file_date_str, "%Y%m%d_%H%M%S")
                            if file_date < cutoff_date:
                                archive_path = archive_dir / report_path.name
                                if not archive_path.exists():
                                    shutil.move(str(report_path), str(archive_path))
                                    archived_count += 1
                    except (ValueError, IndexError):
                        # å¦‚æœæ— æ³•è§£ææ—¥æœŸï¼Œä¹Ÿå½’æ¡£
                        if report_path.stat().st_mtime < cutoff_date.timestamp():
                            archive_path = archive_dir / report_path.name
                            if not archive_path.exists():
                                shutil.move(str(report_path), str(archive_path))
                                archived_count += 1

        print(f"âœ… å½’æ¡£äº† {archived_count} ä¸ªæ—§æŠ¥å‘Š")
        return archived_count

    def _extract_date_from_filename(self, filename: str) -> Optional[str]:
        """ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
        # å°è¯•åŒ¹é…ä¸åŒçš„æ—¥æœŸæ ¼å¼
        import re

        # æ ¼å¼1: quality_report_20251103_094000.json
        match = re.search(r'(\d{8}_\d{6})', filename)
        if match:
            return match.group(1)

        # æ ¼å¼2: improvement-report-20251029-132325.md
        match = re.search(r'(\d{8}-\d{6})', filename)
        if match:
            return match.group(1).replace('-', '_')

        return None

    def generate_health_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç›®å½•å¥åº·æŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆç›®å½•å¥åº·æŠ¥å‘Š...")

        # åŸºæœ¬ç»Ÿè®¡
        root_files = list(self.project_root.iterdir())
        root_file_count = len(root_files)

        # è®¡ç®—å„ç±»æ–‡ä»¶æ•°é‡
        python_files = list(self.project_root.rglob("*.py"))
        markdown_files = list(self.project_root.rglob("*.md"))
        json_files = list(self.project_root.rglob("*.json"))

        # è®¡ç®—ç›®å½•æ•°é‡
        all_dirs = [d for d in self.project_root.rglob("*") if d.is_dir()]

        # è®¡ç®—é¡¹ç›®å¤§å°
        total_size = 0
        for file_path in self.project_root.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size

        # æ£€æŸ¥å¥åº·æŒ‡æ ‡
        health_score = 100
        issues = []

        if root_file_count > self.max_root_files:
            health_score -= 20
            issues.append(f"æ ¹ç›®å½•æ–‡ä»¶è¿‡å¤š ({root_file_count} > {self.max_root_files})")

        empty_dirs = self.find_empty_dirs()
        if len(empty_dirs) > self.max_empty_dirs:
            health_score -= 10
            issues.append(f"ç©ºç›®å½•è¿‡å¤š ({len(empty_dirs)} > {self.max_empty_dirs})")

        naming_violations = self.check_naming_conventions()
        total_violations = sum(len(items) for items in naming_violations.values())
        if total_violations > 10:
            health_score -= 15
            issues.append(f"å‘½åè§„èŒƒé—®é¢˜è¿‡å¤š ({total_violations} ä¸ª)")

        report = {
            "timestamp": datetime.now().isoformat(),
            "health_score": max(0, health_score),
            "statistics": {
                "root_files": root_file_count,
                "python_files": len(python_files),
                "markdown_files": len(markdown_files),
                "json_files": len(json_files),
                "total_dirs": len(all_dirs),
                "total_size_mb": round(total_size / (1024 * 1024), 2)
            },
            "issues": issues,
            "misplaced_files": len(self.check_misplaced_files()),
            "empty_dirs": len(empty_dirs),
            "naming_violations": total_violations
        }

        return report

    def save_health_report(self, report: Dict[str, Any]) -> Path:
        """ä¿å­˜å¥åº·æŠ¥å‘Š"""
        reports_dir = self.docs_dir / "reports" / "health"
        reports_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = reports_dir / f"health_report_{timestamp}.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ å¥åº·æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return report_file

    def auto_fix_issues(self, dry_run: bool = True) -> Dict[str, int]:
        """è‡ªåŠ¨ä¿®å¤å¸¸è§é—®é¢˜"""
        fixes = {
            "removed_empty_dirs": 0,
            "moved_misplaced_files": 0,
            "archived_old_reports": 0,
            "cleaned_temp_files": 0,
            "cleaned_cache_dirs": 0
        }

        print(f"ğŸ”§ å¼€å§‹{'æ¨¡æ‹Ÿ' if dry_run else 'å®é™…'}ä¿®å¤...")

        # 1. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if not dry_run:
            fixes["cleaned_temp_files"] = self.clean_temp_files()
            fixes["cleaned_cache_dirs"] = self.clean_cache_dirs()

        # 2. å½’æ¡£æ—§æŠ¥å‘Š
        if not dry_run:
            fixes["archived_old_reports"] = self.archive_old_reports()

        # 3. åˆ é™¤ç©ºç›®å½•
        empty_dirs = self.find_empty_dirs()
        if not dry_run:
            for dir_path in empty_dirs:
                try:
                    dir_path.rmdir()
                    fixes["removed_empty_dirs"] += 1
                except OSError:
                    pass
        else:
            fixes["removed_empty_dirs"] = len(empty_dirs)

        # 4. ç§»åŠ¨é”™è¯¯æ”¾ç½®çš„æ–‡ä»¶
        misplaced_files = self.check_misplaced_files()
        if not dry_run:
            # åˆ›å»ºåˆé€‚çš„ç›®å½•
            (self.scripts_dir / "temp").mkdir(exist_ok=True)
            (self.docs_dir / "reports" / "temp").mkdir(exist_ok=True)

            for file_path in misplaced_files:
                if file_path.is_file():
                    if file_path.suffix == '.py':
                        dest = self.scripts_dir / "temp" / file_path.name
                    elif file_path.suffix in ['.json', '.md']:
                        dest = self.docs_dir / "reports" / "temp" / file_path.name
                    else:
                        continue

                    if not dest.exists():
                        shutil.move(str(file_path), str(dest))
                        fixes["moved_misplaced_files"] += 1
        else:
            fixes["moved_misplaced_files"] = len(misplaced_files)

        print(f"âœ… {'æ¨¡æ‹Ÿ' if dry_run else 'å®é™…'}ä¿®å¤å®Œæˆ:")
        for fix_type, count in fixes.items():
            if count > 0:
                print(f"   - {fix_type}: {count}")

        return fixes

    def run_maintenance(self,
                       clean_temp: bool = True,
                       clean_cache: bool = True,
                       archive_reports: bool = True,
                       generate_report: bool = True,
                       auto_fix: bool = False,
                       dry_run: bool = False) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„ç»´æŠ¤æµç¨‹"""
        print("ğŸš€ å¼€å§‹ç›®å½•ç»´æŠ¤æµç¨‹...")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"ğŸ¯ æ¨¡å¼: {'æ¨¡æ‹Ÿè¿è¡Œ' if dry_run else 'å®é™…æ‰§è¡Œ'}")
        print("-" * 50)

        results = {
            "start_time": datetime.now().isoformat(),
            "actions": [],
            "issues_found": {},
            "fixes_applied": {},
            "health_report": None
        }

        try:
            # 1. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if clean_temp:
                if dry_run:
                    print("ğŸ§¹ [æ¨¡æ‹Ÿ] æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                    results["actions"].append("temp_files_cleaned_simulated")
                else:
                    temp_count = self.clean_temp_files()
                    results["fixes_applied"]["temp_files_cleaned"] = temp_count
                    results["actions"].append("temp_files_cleaned")

            # 2. æ¸…ç†ç¼“å­˜ç›®å½•
            if clean_cache:
                if dry_run:
                    print("ğŸ—‚ï¸  [æ¨¡æ‹Ÿ] æ¸…ç†ç¼“å­˜ç›®å½•...")
                    results["actions"].append("cache_dirs_cleaned_simulated")
                else:
                    cache_count = self.clean_cache_dirs()
                    results["fixes_applied"]["cache_dirs_cleaned"] = cache_count
                    results["actions"].append("cache_dirs_cleaned")

            # 3. æ£€æŸ¥é—®é¢˜
            misplaced_files = self.check_misplaced_files()
            empty_dirs = self.find_empty_dirs()
            naming_violations = self.check_naming_conventions()

            results["issues_found"] = {
                "misplaced_files": len(misplaced_files),
                "empty_dirs": len(empty_dirs),
                "naming_violations": sum(len(items) for items in naming_violations.values())
            }

            # 4. å½’æ¡£æ—§æŠ¥å‘Š
            if archive_reports:
                if dry_run:
                    print("ğŸ“¦ [æ¨¡æ‹Ÿ] å½’æ¡£æ—§æŠ¥å‘Š...")
                    results["actions"].append("reports_archived_simulated")
                else:
                    archive_count = self.archive_old_reports()
                    results["fixes_applied"]["reports_archived"] = archive_count
                    results["actions"].append("reports_archived")

            # 5. è‡ªåŠ¨ä¿®å¤
            if auto_fix:
                fixes = self.auto_fix_issues(dry_run=dry_run)
                if dry_run:
                    results["issues_found"]["potential_fixes"] = fixes
                else:
                    results["fixes_applied"].update(fixes)
                results["actions"].append("auto_fix_applied")

            # 6. ç”Ÿæˆå¥åº·æŠ¥å‘Š
            if generate_report:
                health_report = self.generate_health_report()
                results["health_report"] = health_report

                if not dry_run:
                    report_file = self.save_health_report(health_report)
                    results["health_report_file"] = str(report_file)
                else:
                    results["actions"].append("health_report_generated_simulated")

            results["end_time"] = datetime.now().isoformat()
            results["success"] = True

        except Exception as e:
            results["success"] = False
            results["error"] = str(e)
            print(f"âŒ ç»´æŠ¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

        # æ‰“å°æ€»ç»“
        print("-" * 50)
        if results["success"]:
            print("âœ… ç›®å½•ç»´æŠ¤æµç¨‹å®Œæˆ!")
            print(f"ğŸ“Š å¥åº·è¯„åˆ†: {results['health_report']['health_score'] if results.get('health_report') else 'N/A'}")
            print(f"ğŸ“ æ ¹ç›®å½•æ–‡ä»¶æ•°: {results['health_report']['statistics']['root_files'] if results.get('health_report') else 'N/A'}")
        else:
            print("âŒ ç›®å½•ç»´æŠ¤æµç¨‹å¤±è´¥!")

        return results

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="FootballPrediction é¡¹ç›®ç›®å½•ç»´æŠ¤å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python3 scripts/maintenance/directory_maintenance.py                    # å®Œæ•´ç»´æŠ¤
  python3 scripts/maintenance/directory_maintenance.py --check-only        # ä»…æ£€æŸ¥
  python3 scripts/maintenance/directory_maintenance.py --dry-run          # æ¨¡æ‹Ÿè¿è¡Œ
  python3 scripts/maintenance/directory_maintenance.py --auto-fix         # è‡ªåŠ¨ä¿®å¤
  python3 scripts/maintenance/directory_maintenance.py --clean-only       # ä»…æ¸…ç†
        """
    )

    parser.add_argument(
        "--project-root",
        type=Path,
        help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹)"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶"
    )

    parser.add_argument(
        "--check-only",
        action="store_true",
        help="ä»…æ£€æŸ¥é—®é¢˜ï¼Œä¸æ‰§è¡Œä¿®å¤"
    )

    parser.add_argument(
        "--clean-only",
        action="store_true",
        help="ä»…æ‰§è¡Œæ¸…ç†æ“ä½œ"
    )

    parser.add_argument(
        "--auto-fix",
        action="store_true",
        help="è‡ªåŠ¨ä¿®å¤å‘ç°çš„é—®é¢˜"
    )

    parser.add_argument(
        "--no-temp",
        action="store_true",
        help="ä¸æ¸…ç†ä¸´æ—¶æ–‡ä»¶"
    )

    parser.add_argument(
        "--no-cache",
        action="store_true",
        help="ä¸æ¸…ç†ç¼“å­˜ç›®å½•"
    )

    parser.add_argument(
        "--no-archive",
        action="store_true",
        help="ä¸å½’æ¡£æ—§æŠ¥å‘Š"
    )

    parser.add_argument(
        "--no-report",
        action="store_true",
        help="ä¸ç”Ÿæˆå¥åº·æŠ¥å‘Š"
    )

    parser.add_argument(
        "--archive-days",
        type=int,
        default=30,
        help="å½’æ¡£å¤šå°‘å¤©å‰çš„æŠ¥å‘Š (é»˜è®¤: 30)"
    )

    args = parser.parse_args()

    # åˆ›å»ºç»´æŠ¤å·¥å…·å®ä¾‹
    maintenance = DirectoryMaintenance(args.project_root)

    # è®¾ç½®å½’æ¡£å¤©æ•°
    if args.archive_days:
        maintenance.archive_days = args.archive_days

    # ç¡®å®šè¿è¡Œæ¨¡å¼
    if args.check_only:
        print("ğŸ” ä»…æ£€æŸ¥æ¨¡å¼...")
        # åªæ‰§è¡Œæ£€æŸ¥ï¼Œä¸æ‰§è¡Œä»»ä½•ä¿®æ”¹æ“ä½œ
        misplaced_files = maintenance.check_misplaced_files()
        empty_dirs = maintenance.find_empty_dirs()
        naming_violations = maintenance.check_naming_conventions()
        health_report = maintenance.generate_health_report()

        print(f"\nğŸ“Š æ£€æŸ¥å®Œæˆï¼Œå¥åº·è¯„åˆ†: {health_report['health_score']}")
        if health_report['issues']:
            print("âš ï¸  å‘ç°çš„é—®é¢˜:")
            for issue in health_report['issues']:
                print(f"   - {issue}")

    elif args.clean_only:
        print("ğŸ§¹ ä»…æ¸…ç†æ¨¡å¼...")
        results = maintenance.run_maintenance(
            clean_temp=not args.no_temp,
            clean_cache=not args.no_cache,
            archive_reports=not args.no_archive,
            generate_report=not args.no_report,
            auto_fix=False,
            dry_run=args.dry_run
        )

    else:
        # å®Œæ•´ç»´æŠ¤æµç¨‹
        results = maintenance.run_maintenance(
            clean_temp=not args.no_temp,
            clean_cache=not args.no_cache,
            archive_reports=not args.no_archive,
            generate_report=not args.no_report,
            auto_fix=args.auto_fix,
            dry_run=args.dry_run
        )

        # ä¿å­˜ç»´æŠ¤ç»“æœ
        if not args.dry_run and results.get("success"):
            maintenance_log_dir = maintenance.project_root / "logs" / "maintenance"
            maintenance_log_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_file = maintenance_log_dir / f"maintenance_log_{timestamp}.json"

            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)

            print(f"ğŸ“ ç»´æŠ¤æ—¥å¿—å·²ä¿å­˜: {log_file}")

if __name__ == "__main__":
    main()