#!/usr/bin/env python3
"""
FotMobæ™ºèƒ½å›å¡«å¼•æ“ - ç”Ÿäº§çº§æ•°æ®æ”¶å‰²æœº
Chief Architect: å·¥ä¸šçº§å†å²æ•°æ®å›å¡«ç³»ç»Ÿ
Purpose: é«˜å¹¶å‘ã€æ™ºèƒ½åŒ–çš„å†å²æ•°æ®å›å¡«ï¼Œæ”¯æŒå¤šä¸ªèµ›å­£æ‰¹é‡å¤„ç†
"""

import asyncio
import logging
import sys
import time
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, insert
from sqlalchemy.dialects.postgresql import insert as pg_insert

from src.data.collectors.fotmob_universal_collector import FotMobUniversalCollector
from src.database.definitions import get_async_session
from src.database.models.league import League
from src.database.models.match import Match

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class BackfillConfig:
    """å›å¡«é…ç½®"""
    seasons: List[str]
    max_concurrent_leagues: int = 10
    max_concurrent_requests: int = 20
    batch_size: int = 100
    rate_limit_delay: float = 0.2
    retry_attempts: int = 3
    dry_run: bool = False
    skip_existing: bool = True


@dataclass
class BackfillStats:
    """å›å¡«ç»Ÿè®¡"""
    start_time: float
    leagues_processed: int = 0
    seasons_processed: int = 0
    matches_found: int = 0
    matches_inserted: int = 0
    matches_updated: int = 0
    duplicates_skipped: int = 0
    errors: List[str] = None

    def __post_init__(self):
        if self.errors is None:
            self.errors = []

    @property
    def elapsed_time(self) -> float:
        return time.time() - self.start_time

    @property
    def processing_rate(self) -> float:
        return self.matches_found / max(self.elapsed_time, 1)

    def to_dict(self) -> Dict:
        return {
            'elapsed_time': f"{self.elapsed_time:.2f}s",
            'leagues_processed': self.leagues_processed,
            'seasons_processed': self.seasons_processed,
            'matches_found': self.matches_found,
            'matches_inserted': self.matches_inserted,
            'matches_updated': self.matches_updated,
            'duplicates_skipped': self.duplicates_skipped,
            'processing_rate': f"{self.processing_rate:.1f} matches/sec",
            'error_count': len(self.errors)
        }


class FotMobSmartBackfill:
    """FotMobæ™ºèƒ½å›å¡«å¼•æ“"""

    def __init__(self, config: BackfillConfig):
        self.config = config
        self.stats = BackfillStats(start_time=time.time())
        self.collector = None

    async def __aenter__(self):
        self.collector = FotMobUniversalCollector(
            max_concurrent=self.config.max_concurrent_requests,
            rate_limit_delay=self.config.rate_limit_delay,
            retry_attempts=self.config.retry_attempts
        )
        await self.collector.__aenter__()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.collector:
            await self.collector.__aexit__(exc_type, exc_val, exc_tb)

    async def run_backfill(self) -> Dict[str, any]:
        """æ‰§è¡Œå®Œæ•´çš„å†å²æ•°æ®å›å¡«"""
        logger.info("ğŸš€ FotMobæ™ºèƒ½å›å¡«å¼•æ“å¯åŠ¨")
        logger.info("=" * 80)
        logger.info(f"ğŸ“‹ é…ç½®å‚æ•°:")
        logger.info(f"   èµ›å­£: {self.config.seasons}")
        logger.info(f"   æœ€å¤§å¹¶å‘è”èµ›: {self.config.max_concurrent_leagues}")
        logger.info(f"   æ‰¹å¤„ç†å¤§å°: {self.config.batch_size}")
        logger.info(f"   è·³è¿‡å·²å­˜åœ¨: {self.config.skip_existing}")
        logger.info(f"   æ¨¡æ‹Ÿè¿è¡Œ: {self.config.dry_run}")

        try:
            # 1. è·å–æœ‰FotMob IDçš„è”èµ›
            leagues = await self._get_active_leagues()
            if not leagues:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰FotMob IDçš„æ´»è·ƒè”èµ›")

            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(leagues)} ä¸ªæ´»è·ƒè”èµ›")

            # 2. å¹¶å‘å¤„ç†è”èµ›å’Œèµ›å­£
            await self._process_leagues_seasons(leagues)

            # 3. ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report()

            logger.info("=" * 80)
            logger.info("ğŸ‰ å›å¡«ä»»åŠ¡å®Œæˆ!")
            logger.info(f"ğŸ“ˆ æ€»å¤„ç†æ•ˆç‡: {self.stats.processing_rate:.1f} æ¯”èµ›/ç§’")

            return report

        except Exception as e:
            error_msg = f"å›å¡«æµç¨‹å¤±è´¥: {e}"
            logger.error(f"ğŸ’¥ {error_msg}")
            self.stats.errors.append(error_msg)
            return {'error': error_msg, 'stats': self.stats.to_dict()}

    async def _get_active_leagues(self) -> List[Dict[str, str]]:
        """è·å–æœ‰FotMob IDçš„æ´»è·ƒè”èµ›"""
        try:
            async with get_async_session() as session:
                result = await session.execute(
                    select(League.id, League.name, League.fotmob_id)
                    .where(League.fotmob_id.isnot(None))
                    .where(League.is_active == True)
                    .order_by(League.name)
                )

                leagues = []
                for row in result:
                    leagues.append({
                        'id': row.id,
                        'name': row.name,
                        'fotmob_id': row.fotmob_id
                    })

                return leagues

        except Exception as e:
            logger.error(f"âŒ è·å–è”èµ›å¤±è´¥: {e}")
            return []

    async def _process_leagues_seasons(self, leagues: List[Dict[str, str]]):
        """å¹¶å‘å¤„ç†è”èµ›å’Œèµ›å­£"""
        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç† {len(leagues)} ä¸ªè”èµ› x {len(self.config.seasons)} ä¸ªèµ›å­£")

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        semaphore = asyncio.Semaphore(self.config.max_concurrent_leagues)

        async def process_league_season(league: Dict[str, str], season: str):
            async with semaphore:
                return await self._process_single_league_season(league, season)

        # ç”Ÿæˆæ‰€æœ‰ä»»åŠ¡
        tasks = []
        for league in leagues:
            for season in self.config.seasons:
                task = process_league_season(league, season)
                tasks.append((league['name'], season, task))

        # æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        results = []
        for i, (league_name, season, task) in enumerate(tasks):
            try:
                result = await task
                results.append((league_name, season, result))
                self.stats.seasons_processed += 1

                # è¿›åº¦æŠ¥å‘Š
                if (i + 1) % 10 == 0:
                    progress = (i + 1) / len(tasks) * 100
                    logger.info(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({i + 1}/{len(tasks)})")

            except Exception as e:
                error_msg = f"å¤„ç† {league_name} {season} å¤±è´¥: {e}"
                logger.error(f"âŒ {error_msg}")
                self.stats.errors.append(error_msg)
                results.append((league_name, season, {'error': str(e)}))

        # ç»Ÿè®¡æˆåŠŸå¤„ç†çš„è”èµ›
        successful_leagues = set()
        for league_name, season, result in results:
            if not result.get('error'):
                successful_leagues.add(league_name)

        self.stats.leagues_processed = len(successful_leagues)

    async def _process_single_league_season(
        self,
        league: Dict[str, str],
        season: str
    ) -> Dict[str, any]:
        """å¤„ç†å•ä¸ªè”èµ›çš„å•ä¸ªèµ›å­£"""
        league_name = league['name']
        fotmob_id = league['fotmob_id']

        try:
            logger.debug(f"ğŸ† å¤„ç† {league_name} {season}")

            # ä½¿ç”¨é‡‡é›†å™¨è·å–æ¯”èµ›æ•°æ®
            matches = await self.collector.fetch_matches_by_league(fotmob_id, season)

            if not matches:
                logger.debug(f"âš ï¸ {league_name} {season} æ²¡æœ‰æ¯”èµ›æ•°æ®")
                return {'matches_found': 0, 'matches_processed': 0}

            self.stats.matches_found += len(matches)

            # å¦‚æœæ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œåªè¿”å›ç»Ÿè®¡
            if self.config.dry_run:
                return {
                    'matches_found': len(matches),
                    'matches_processed': 0,
                    'status': 'dry_run'
                }

            # æ‰¹é‡å¤„ç†æ¯”èµ›æ•°æ®
            processed = await self._batch_upsert_matches(matches, league)

            return processed

        except Exception as e:
            error_msg = f"å¤„ç† {league_name} {season} å¤±è´¥: {e}"
            logger.error(f"âŒ {error_msg}")
            return {'error': error_msg}

    async def _batch_upsert_matches(
        self,
        matches: List[Dict],
        league: Dict[str, str]
    ) -> Dict[str, int]:
        """æ‰¹é‡æ’å…¥/æ›´æ–°æ¯”èµ›æ•°æ®"""
        if not matches:
            return {'inserted': 0, 'updated': 0, 'skipped': 0}

        try:
            # åˆ†æ‰¹å¤„ç†
            total_inserted = 0
            total_updated = 0
            total_skipped = 0

            for i in range(0, len(matches), self.config.batch_size):
                batch = matches[i:i + self.config.batch_size]
                result = await self._process_match_batch(batch, league)

                total_inserted += result['inserted']
                total_updated += result['updated']
                total_skipped += result['skipped']

                # æäº¤æ‰¹æ¬¡
                if not self.config.dry_run:
                    async with get_async_session() as session:
                        await session.commit()

                # çŸ­æš‚å»¶è¿Ÿé¿å…æ•°æ®åº“è¿‡è½½
                await asyncio.sleep(0.01)

            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            self.stats.matches_inserted += total_inserted
            self.stats.matches_updated += total_updated
            self.stats.duplicates_skipped += total_skipped

            return {
                'inserted': total_inserted,
                'updated': total_updated,
                'skipped': total_skipped,
                'total': len(matches)
            }

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return {'error': str(e), 'inserted': 0, 'updated': 0, 'skipped': 0}

    async def _process_match_batch(
        self,
        batch: List[Dict],
        league: Dict[str, str]
    ) -> Dict[str, int]:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡çš„æ¯”èµ›"""
        if self.config.dry_run:
            return {'inserted': 0, 'updated': 0, 'skipped': len(batch)}

        try:
            async with get_async_session() as session:
                inserted = 0
                updated = 0
                skipped = 0

                for match_data in batch:
                    try:
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        if self.config.skip_existing:
                            existing = await session.execute(
                                select(Match).where(
                                    Match.fotmob_id == match_data['fotmob_id']
                                )
                            )
                            if existing.scalar_one_or_none():
                                skipped += 1
                                continue

                        # å‡†å¤‡æ¯”èµ›è®°å½•
                        match_record = await self._prepare_match_record(match_data, league)

                        # ä½¿ç”¨UPSERT
                        stmt = pg_insert(Match).values(**match_record)
                        stmt = stmt.on_conflict('fotmob_id').do_update(
                            set_=match_record
                        )

                        await session.execute(stmt)

                        # ç»Ÿè®¡æ“ä½œç±»å‹
                        result = await session.execute(
                            select(Match).where(
                                Match.fotmob_id == match_data['fotmob_id']
                            )
                        )
                        if result.scalar_one_or_none():
                            if skipped == 0:  # å¦‚æœä¸æ˜¯è·³è¿‡çš„ï¼Œè¯´æ˜æ˜¯æ–°æ’å…¥
                                inserted += 1
                            else:
                                updated += 1

                    except Exception as e:
                        logger.warning(f"âš ï¸ å¤„ç†æ¯”èµ›å¤±è´¥ {match_data.get('fotmob_id')}: {e}")
                        skipped += 1

                return {
                    'inserted': inserted,
                    'updated': updated,
                    'skipped': skipped
                }

        except Exception as e:
            logger.error(f"âŒ æ‰¹æ¬¡å¤„ç†å¼‚å¸¸: {e}")
            return {'error': str(e), 'inserted': 0, 'updated': 0, 'skipped': 0}

    async def _prepare_match_record(
        self,
        match_data: Dict,
        league: Dict[str, str]
    ) -> Dict:
        """å‡†å¤‡æ¯”èµ›è®°å½•"""
        return {
            'fotmob_id': match_data['fotmob_id'],
            'league_id': league['id'],
            'home_team_name': match_data['home_team_name'],
            'away_team_name': match_data['away_team_name'],
            'match_date': datetime.strptime(
                match_data['match_date'], '%Y-%m-%d'
            ).date(),
            'home_score': match_data.get('home_score'),
            'away_score': match_data.get('away_score'),
            'status': match_data['status'],
            'venue': match_data.get('venue', ''),
            'season': match_data['season'],
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }

    def _generate_report(self) -> Dict[str, any]:
        """ç”Ÿæˆå›å¡«æŠ¥å‘Š"""
        return {
            'summary': self.stats.to_dict(),
            'config': {
                'seasons': self.config.seasons,
                'max_concurrent_leagues': self.config.max_concurrent_leagues,
                'batch_size': self.config.batch_size,
                'dry_run': self.config.dry_run
            },
            'performance': {
                'total_time': f"{self.stats.elapsed_time:.2f}s",
                'avg_processing_rate': f"{self.stats.processing_rate:.1f} matches/sec",
                'leagues_per_season': self.stats.leagues_processed / max(len(self.config.seasons), 1)
            },
            'data_quality': {
                'total_matches_found': self.stats.matches_found,
                'successfully_processed': self.stats.matches_inserted + self.stats.matches_updated,
                'processing_success_rate': f"{(self.stats.matches_inserted + self.stats.matches_updated) / max(self.stats.matches_found, 1) * 100:.1f}%"
            }
        }


# ä¾¿æ·å‡½æ•°
async def run_backfill(
    seasons: Optional[List[str]] = None,
    max_concurrent: int = 10,
    dry_run: bool = False
) -> Dict[str, any]:
    """
    è¿è¡ŒFotMobå†å²æ•°æ®å›å¡«

    Args:
        seasons: è¦å›å¡«çš„èµ›å­£åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºæœ€è¿‘5ä¸ªèµ›å­£
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œ

    Returns:
        å›å¡«æŠ¥å‘Š
    """
    # é»˜è®¤é…ç½®ï¼šæœ€è¿‘5ä¸ªèµ›å­£
    if not seasons:
        current_year = datetime.now().year
        seasons = [f"{year}/{year+1}" for year in range(current_year - 5, current_year)]

    config = BackfillConfig(
        seasons=seasons,
        max_concurrent_leagues=max_concurrent,
        dry_run=dry_run,
        skip_existing=True,
        batch_size=50
    )

    async with FotMobSmartBackfill(config) as backfill:
        return await backfill.run_backfill()


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='FotMobæ™ºèƒ½å›å¡«å¼•æ“')
    parser.add_argument('--seasons', nargs='+', help='è¦å›å¡«çš„èµ›å­£ (å¦‚: 2023/2024 2022/2023)')
    parser.add_argument('--max-concurrent', type=int, default=10, help='æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('--dry-run', action='store_true', help='æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…å†™å…¥æ•°æ®')
    parser.add_argument('--recent-years', type=int, default=5, help='å›å¡«æœ€è¿‘Nå¹´çš„æ•°æ®')

    args = parser.parse_args()

    # ç¡®å®šèµ›å­£
    if args.seasons:
        seasons = args.seasons
    else:
        current_year = datetime.now().year
        seasons = [f"{year}/{year+1}" for year in range(current_year - args.recent_years, current_year)]

    logger.info("ğŸŒŸ FotMobæ™ºèƒ½å›å¡«å¼•æ“")
    logger.info(f"ğŸ“… å›å¡«èµ›å­£: {seasons}")
    logger.info(f"ğŸ”§ å¹¶å‘æ•°: {args.max_concurrent}")
    logger.info(f"ğŸ§ª æ¨¡æ‹Ÿè¿è¡Œ: {args.dry_run}")
    logger.info("=" * 80)

    try:
        # è¿è¡Œå›å¡«
        report = await run_backfill(
            seasons=seasons,
            max_concurrent=args.max_concurrent,
            dry_run=args.dry_run
        )

        if 'error' in report:
            logger.error(f"âŒ å›å¡«å¤±è´¥: {report['error']}")
            sys.exit(1)
        else:
            logger.info("âœ… å›å¡«æˆåŠŸå®Œæˆ!")

            # æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
            summary = report['summary']
            performance = report['performance']
            data_quality = report['data_quality']

            print("\nğŸ“Š å›å¡«æŠ¥å‘Š:")
            print(f"   æ‰§è¡Œæ—¶é—´: {summary['elapsed_time']}")
            print(f"   å¤„ç†è”èµ›: {summary['leagues_processed']}")
            print(f"   å¤„ç†èµ›å­£: {summary['seasons_processed']}")
            print(f"   å‘ç°æ¯”èµ›: {summary['matches_found']}")
            print(f"   æ’å…¥æ¯”èµ›: {summary['matches_inserted']}")
            print(f"   æ›´æ–°æ¯”èµ›: {summary['matches_updated']}")
            print(f"   è·³è¿‡é‡å¤: {summary['duplicates_skipped']}")
            print(f"   å¤„ç†æ•ˆç‡: {summary['processing_rate']}")
            print(f"   æ•°æ®è´¨é‡: {data_quality['processing_success_rate']}")

    except KeyboardInterrupt:
        logger.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())