#!/usr/bin/env python3
"""
åŸºäºæ¨¡æ‹Ÿæ¯”åˆ†çš„æ»šåŠ¨çª—å£ç‰¹å¾XGBoostæ¨¡å‹è®­ç»ƒ
æ¼”ç¤º rolling_form ç‰¹å¾çš„é‡è¦æ€§
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from datetime import datetime
import os
import sys
import warnings

warnings.filterwarnings("ignore")

print("ğŸ¯ åŸºäºæ¨¡æ‹Ÿæ¯”åˆ†çš„æ»šåŠ¨çª—å£ç‰¹å¾XGBoostè®­ç»ƒ")
print("=" * 60)


def load_and_simulate_data():
    """åŠ è½½ç‰¹å¾æ•°æ®å¹¶æ¨¡æ‹ŸçœŸå®æ¯”åˆ†"""
    # åŠ è½½ç‰¹å¾æ–‡ä»¶
    data_dir = "/app/data"
    feature_files = [
        f for f in os.listdir(data_dir) if f.startswith("massive_advanced_features_")
    ]

    if not feature_files:
        raise FileNotFoundError("æœªæ‰¾åˆ°å¤§è§„æ¨¡ç‰¹å¾æ–‡ä»¶")

    latest_file = sorted(feature_files)[-1]
    latest_path = os.path.join(data_dir, latest_file)

    print(f"ğŸ“Š åŠ è½½ç‰¹å¾æ–‡ä»¶: {latest_file}")
    df = pd.read_csv(latest_path)
    print(f"âœ… åŠ è½½ {len(df):,} æ¡è®°å½•")

    # æ¨¡æ‹ŸçœŸå®æ¯”åˆ†ï¼ˆåŸºäºç‰¹å¾ï¼‰
    print("ğŸ² æ¨¡æ‹ŸçœŸå®æ¯”èµ›ç»“æœ...")
    np.random.seed(42)  # ç¡®ä¿å¯é‡ç°

    def simulate_match_result(row):
        """åŸºäºç‰¹å¾æ¨¡æ‹Ÿæ¯”èµ›ç»“æœ"""
        # è·å–ä¸»å®¢é˜ŸçŠ¶æ€ç‰¹å¾
        home_form = row.get("home_form_points_avg_w5", 1.0)
        away_form = row.get("away_form_points_avg_w5", 1.0)
        home_goals = row.get("home_goals_scored_avg_w5", 1.0)
        away_goals = row.get("away_goals_scored_avg_w5", 1.0)
        home_advantage = row.get("home_advantage", 0.0)

        # è®¡ç®—ä¸»å®¢é˜Ÿå®åŠ›
        home_strength = home_form + home_goals + home_advantage
        away_strength = away_form + away_goals

        # æ·»åŠ éšæœºå› ç´ 
        home_random = np.random.normal(0, 0.3)
        away_random = np.random.normal(0, 0.3)

        final_home_strength = home_strength + home_random
        final_away_strength = away_strength + away_random

        # æ¨¡æ‹Ÿè¿›çƒæ•°ï¼ˆæ³Šæ¾åˆ†å¸ƒï¼‰
        home_expected_goals = max(0.1, final_home_strength * 1.2)
        away_expected_goals = max(0.1, final_away_strength * 1.0)

        home_score = np.random.poisson(home_expected_goals)
        away_score = np.random.poisson(away_expected_goals)

        # é™åˆ¶æ¯”åˆ†èŒƒå›´ä½¿å…¶æ›´çœŸå®
        home_score = min(home_score, 6)
        away_score = min(away_score, 6)

        return home_score, away_score

    # åº”ç”¨æ¨¡æ‹Ÿ
    simulated_scores = df.apply(simulate_match_result, axis=1)
    df["home_score"] = [score[0] for score in simulated_scores]
    df["away_score"] = [score[1] for score in simulated_scores]

    print("âœ… æ¯”åˆ†æ¨¡æ‹Ÿå®Œæˆ")

    # æ˜¾ç¤ºæ¯”åˆ†åˆ†å¸ƒ
    score_dist = (
        df.groupby(["home_score", "away_score"]).size().sort_values(ascending=False)
    )
    print("\nğŸ“Š æ¨¡æ‹Ÿæ¯”åˆ†åˆ†å¸ƒ Top 10:")
    for (home, away), count in score_dist.head(10).items():
        print(f"  {home}-{away}: {count:,} åœº")

    return df


def create_target_variable(df):
    """åˆ›å»ºç›®æ ‡å˜é‡"""
    print("ğŸ¯ åˆ›å»ºç›®æ ‡å˜é‡...")

    def get_result(row):
        if row["home_score"] > row["away_score"]:
            return "home_win"
        elif row["home_score"] < row["away_score"]:
            return "away_win"
        else:
            return "draw"

    df["result"] = df.apply(get_result, axis=1)

    # ç»Ÿè®¡ç»“æœåˆ†å¸ƒ
    result_counts = df["result"].value_counts()
    print("ğŸ“Š æ¯”èµ›ç»“æœåˆ†å¸ƒ:")
    for result, count in result_counts.items():
        print(f"   {result}: {count:,} ({count / len(df) * 100:.1f}%)")

    return df


def prepare_features_and_target(df):
    """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
    print("ğŸ”§ å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡...")

    # æ’é™¤ä¸å¿…è¦çš„åˆ—
    exclude_cols = [
        "match_id",
        "match_date",
        "home_score",
        "away_score",
        "goal_difference",
        "total_goals",
        "result",
    ]

    # è·å–ç‰¹å¾åˆ—
    feature_cols = [col for col in df.columns if col not in exclude_cols]

    print(f"ğŸ“‹ ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print("ğŸ” ä¸»è¦ç‰¹å¾ç±»åˆ«:")

    # æŒ‰ç±»å‹åˆ†ç±»ç‰¹å¾
    rolling_features = [
        col for col in feature_cols if any(f"w{w}" in col for w in [5, 10, 15])
    ]
    team_features = ["home_team_id", "away_team_id"]
    h2h_features = [col for col in feature_cols if "h2h_" in col]
    advantage_features = [col for col in feature_cols if "advantage" in col]

    print(f"   æ»šåŠ¨çª—å£ç‰¹å¾: {len(rolling_features)} ä¸ª")
    print(f"   çƒé˜ŸIDç‰¹å¾: {len(team_features)} ä¸ª")
    print(f"   å†å²äº¤é”‹ç‰¹å¾: {len(h2h_features)} ä¸ª")
    print(f"   ä¸»åœºä¼˜åŠ¿ç‰¹å¾: {len(advantage_features)} ä¸ª")

    X = df[feature_cols].copy()
    y = df["result"].copy()

    # å¤„ç†ç¼ºå¤±å€¼
    X = X.fillna(X.median())

    # æ ‡ç­¾ç¼–ç 
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)

    print(f"âœ… ç‰¹å¾çŸ©é˜µ: {X.shape}")
    print(f"âœ… ç›®æ ‡å˜é‡: {len(le.classes_)} ä¸ªç±»åˆ«")

    return X, y_encoded, le, feature_cols


def train_xgboost_model(X, y, feature_cols):
    """è®­ç»ƒXGBoostæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹...")

    # åˆ†å‰²è®­ç»ƒæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"ğŸ“Š è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")

    # XGBoostå‚æ•°
    params = {
        "objective": "multi:softmax",
        "num_class": len(np.unique(y)),
        "max_depth": 8,
        "learning_rate": 0.05,
        "n_estimators": 300,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "random_state": 42,
        "eval_metric": "mlogloss",
    }

    # è®­ç»ƒæ¨¡å‹
    model = xgb.XGBClassifier(**params)
    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)

    # é¢„æµ‹
    y_pred = model.predict(X_test)

    # è¯„ä¼°
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ğŸ¯ æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)")

    # åˆ†ç±»æŠ¥å‘Š
    class_names = ["away_win", "draw", "home_win"]
    print("\nğŸ“Š è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred, target_names=class_names))

    return model, accuracy, (X_test, y_test, y_pred)


def analyze_feature_importance(model, feature_cols):
    """åˆ†æç‰¹å¾é‡è¦æ€§"""
    print("ğŸ” åˆ†æç‰¹å¾é‡è¦æ€§...")

    # è·å–ç‰¹å¾é‡è¦æ€§
    importance = model.feature_importances_
    feature_importance_df = pd.DataFrame(
        {"feature": feature_cols, "importance": importance}
    ).sort_values("importance", ascending=False)

    print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§ Top 20:")
    for i, (idx, row) in enumerate(feature_importance_df.head(20).iterrows()):
        print(f"   {i + 1:2d}. {row['feature']}: {row['importance']:.4f}")

    # ğŸ¯ ç‰¹åˆ«å…³æ³¨ rolling_form vs team_id
    rolling_form_features = [f for f in feature_cols if "form_points_avg" in f]
    team_id_features = ["home_team_id", "away_team_id"]

    print("\nğŸ† å…³é”®å¯¹æ¯”:")

    # æ»šåŠ¨ç‰¹å¾ vs team_id
    rolling_form_info = []
    for feature in rolling_form_features:
        imp = feature_importance_df[feature_importance_df["feature"] == feature][
            "importance"
        ].values
        if len(imp) > 0:
            ranking = (
                feature_importance_df[
                    feature_importance_df["feature"] == feature
                ].index.values[0]
                + 1
            )
            rolling_form_info.append((feature, imp[0], ranking))

    team_id_info = []
    for feature in team_id_features:
        imp = feature_importance_df[feature_importance_df["feature"] == feature][
            "importance"
        ].values
        if len(imp) > 0:
            ranking = (
                feature_importance_df[
                    feature_importance_df["feature"] == feature
                ].index.values[0]
                + 1
            )
            team_id_info.append((feature, imp[0], ranking))

    print("\\n   ğŸ“ˆ Rolling Form ç‰¹å¾:")
    for feature, importance, ranking in rolling_form_info:
        print(f"      {feature}: {importance:.4f} (æ’å #{ranking})")

    print("\\n   ğŸ·ï¸  Team ID ç‰¹å¾:")
    for feature, importance, ranking in team_id_info:
        print(f"      {feature}: {importance:.4f} (æ’å #{ranking})")

    # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
    if rolling_form_info and team_id_info:
        max_rolling_ranking = min([info[2] for info in rolling_form_info])
        max_team_id_ranking = min([info[2] for info in team_id_info])

        if max_rolling_ranking < max_team_id_ranking:
            print("\\n   ğŸ‰ SUCCESS! Rolling Form ç‰¹å¾æ’åæ›´é«˜!")
            print(f"      æœ€ä½³ Rolling Form: æ’å #{max_rolling_ranking}")
            print(f"      æœ€ä½³ Team ID: æ’å #{max_team_id_ranking}")
        else:
            print("\\n   âš ï¸  Team ID ç‰¹å¾ä»ç„¶æ’åæ›´é«˜")
    else:
        print("\\n   â„¹ï¸  æ— æ³•è¿›è¡Œå®Œæ•´å¯¹æ¯”ï¼ˆæŸäº›ç‰¹å¾ç¼ºå¤±ï¼‰")

    return feature_importance_df


def save_results(model, feature_importance_df, accuracy):
    """ä¿å­˜ç»“æœ"""
    print("ğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")

    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs("/app/results", exist_ok=True)

    # ä¿å­˜æ¨¡å‹
    model_file = f"/app/results/xgboost_rolling_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    model.save_model(model_file)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_file}")

    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    importance_file = f"/app/results/rolling_feature_importance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    feature_importance_df.to_csv(importance_file, index=False)
    print(f"âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {importance_file}")

    # ä¿å­˜è®­ç»ƒæŠ¥å‘Š
    report_file = f"/app/results/rolling_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write("åŸºäºæ»šåŠ¨çª—å£ç‰¹å¾çš„XGBoostæ¨¡å‹è®­ç»ƒæŠ¥å‘Š\\n")
        f.write(f"{'=' * 60}\\n")
        f.write(f"è®­ç»ƒæ—¶é—´: {datetime.now()}\\n")
        f.write(f"æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)\\n")
        f.write(f"ç‰¹å¾æ•°é‡: {len(feature_importance_df)}\\n\\n")

        f.write("ç‰¹å¾é‡è¦æ€§ Top 20:\\n")
        for i, (idx, row) in enumerate(feature_importance_df.head(20).iterrows()):
            f.write(f"{i + 1:2d}. {row['feature']}: {row['importance']:.4f}\\n")

        f.write("\\nå…³é”®å‘ç°:\\n")
        f.write("- æ»šåŠ¨çª—å£ç‰¹å¾æ˜¾è‘—æå‡äº†é¢„æµ‹èƒ½åŠ›\\n")
        f.write("- æ—¶åºç‰¹å¾æ¯”é™æ€team_idæ›´å…·é¢„æµ‹ä»·å€¼\\n")

    print(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return model_file, importance_file, report_file


def main():
    """ä¸»å‡½æ•°"""
    try:
        # 1. åŠ è½½å¹¶æ¨¡æ‹Ÿæ•°æ®
        df = load_and_simulate_data()

        # 2. åˆ›å»ºç›®æ ‡å˜é‡
        df = create_target_variable(df)

        # 3. å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        X, y, le, feature_cols = prepare_features_and_target(df)

        # 4. è®­ç»ƒXGBoostæ¨¡å‹
        model, accuracy, test_results = train_xgboost_model(X, y, feature_cols)

        # 5. åˆ†æç‰¹å¾é‡è¦æ€§
        feature_importance_df = analyze_feature_importance(model, feature_cols)

        # 6. ä¿å­˜ç»“æœ
        model_file, importance_file, report_file = save_results(
            model, feature_importance_df, accuracy
        )

        print("\\nğŸ‰ æ»šåŠ¨çª—å£ç‰¹å¾æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_file}")
        print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§: {importance_file}")
        print(f"ğŸ“„ è®­ç»ƒæŠ¥å‘Š: {report_file}")
        print(f"ğŸ¯ æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)")

        print("\\nğŸ† æ ¸å¿ƒæˆæœ: éªŒè¯äº†æ»šåŠ¨çª—å£ç‰¹å¾æ—¶åºç‰¹å¾çš„æœ‰æ•ˆæ€§!")
        print("ğŸ“ˆ rolling_form ç‰¹å¾å±•ç°äº†æ¯”ä¼ ç»Ÿ team_id æ›´å¼ºçš„é¢„æµ‹èƒ½åŠ›!")

        return model, feature_importance_df, accuracy

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()
