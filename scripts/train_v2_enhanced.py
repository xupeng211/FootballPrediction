#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆåŸºçº¿æ¨¡å‹è®­ç»ƒè„šæœ¬ - V2å¢å¼ºç‰¹å¾å®éªŒ
ä¸“æ³¨äºä¼˜åŒ–æ»šåŠ¨ç‰¹å¾å’Œæ—¶åºç‰¹å¾å·¥ç¨‹

æ ¸å¿ƒåŠŸèƒ½:
1. åœ¨è¯šå®åŸºçº¿åŸºç¡€ä¸Šæ·»åŠ å¢å¼ºç‰¹å¾
2. æ·»åŠ æ»šåŠ¨çš„èƒœç‡/çŠ¶æ€ç‰¹å¾
3. æ·»åŠ èµ›å­£å†…è¡¨ç°è¶‹åŠ¿ç‰¹å¾
4. å¯¹æ¯”V1åŸºçº¿æ€§èƒ½

ä½œè€…: Lead Algorithm Engineer
åˆ›å»ºæ—¶é—´: 2025-12-10
ç‰ˆæœ¬: 2.0.0 - Enhanced Features
"""

import pandas as pd
import numpy as np
from datetime import datetime
import logging
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, log_loss, classification_report
from xgboost import XGBClassifier

# å¯¼å…¥åŸºçº¿è®­ç»ƒå™¨
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))
from train_baseline import BaselineTrainer

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnhancedFeaturesTrainer(BaselineTrainer):
    """å¢å¼ºç‰¹å¾è®­ç»ƒå™¨"""

    def __init__(self):
        super().__init__()
        self.enhanced_features_cache = {}

    def calculate_enhanced_rolling_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—å¢å¼ºçš„æ»šåŠ¨ç‰¹å¾"""
        logger.info("ğŸš€ è®¡ç®—å¢å¼ºæ»šåŠ¨ç‰¹å¾")

        # åŸºç¡€æ»šåŠ¨ç‰¹å¾å·²å­˜åœ¨ï¼Œæˆ‘ä»¬æ·»åŠ æ›´å¤šé«˜çº§ç‰¹å¾

        enhanced_df = df.copy()

        # 1. ä¸»å®¢åœºè¡¨ç°å·®å¼‚ç‰¹å¾
        for window in [3, 5, 10]:
            # ä¸»å®¢åœºxGå·®å¼‚
            enhanced_df[f'h2h_xg_diff_{window}'] = (
                enhanced_df[f'home_last_{window}_avg_xg'] -
                enhanced_df[f'away_last_{window}_avg_xg']
            )

            # ä¸»å®¢åœºè¿›çƒå·®å¼‚
            enhanced_df[f'h2h_goals_diff_{window}'] = (
                enhanced_df[f'home_last_{window}_avg_goals_scored'] -
                enhanced_df[f'away_last_{window}_avg_goals_scored']
            )

            # ä¸»å®¢åœºèƒœç‡å·®å¼‚
            enhanced_df[f'h2h_win_rate_diff_{window}'] = (
                enhanced_df[f'home_last_{window}_win_rate'] -
                enhanced_df[f'away_last_{window}_win_rate']
            )

        # 2. è¿‘æœŸè¶‹åŠ¿ç‰¹å¾
        # 3åœºvs5åœºè¡¨ç°å¯¹æ¯”
        if 'home_last_3_avg_xg' in enhanced_df.columns and 'home_last_5_avg_xg' in enhanced_df.columns:
            enhanced_df['form_trend_xg_3_vs_5'] = (
                enhanced_df['home_last_3_avg_xg'] - enhanced_df['home_last_5_avg_xg']
            )

        # 5åœºvs10åœºè¡¨ç°å¯¹æ¯”
        if 'home_last_5_avg_xg' in enhanced_df.columns and 'home_last_10_avg_xg' in enhanced_df.columns:
            enhanced_df['form_trend_xg_5_vs_10'] = (
                enhanced_df['home_last_5_avg_xg'] - enhanced_df['home_last_10_avg_xg']
            )

        # 3åœºvs5åœºè¿›çƒå¯¹æ¯”
        if 'home_last_3_avg_goals_scored' in enhanced_df.columns and 'home_last_5_avg_goals_scored' in enhanced_df.columns:
            enhanced_df['form_trend_goals_3_vs_5'] = (
                enhanced_df['home_last_3_avg_goals_scored'] - enhanced_df['home_last_5_avg_goals_scored']
            )

        # 3. æ”»é˜²å¹³è¡¡ç‰¹å¾
        for window in [3, 5, 10]:
            # æ”»é˜²å¹³è¡¡æŒ‡æ•° = è¿›çƒèƒ½åŠ› - å¤±çƒé˜²å®ˆèƒ½åŠ›
            enhanced_df[f'attack_defense_balance_home_{window}'] = (
                enhanced_df[f'home_last_{window}_avg_goals_scored'] -
                enhanced_df[f'home_last_{window}_avg_goals_conceded']
            )

            enhanced_df[f'attack_defense_balance_away_{window}'] = (
                enhanced_df[f'away_last_{window}_avg_goals_scored'] -
                enhanced_df[f'away_last_{window}_avg_goals_conceded']
            )

            # æ€»ä½“æˆ˜æ–—æŒ‡æ•°
            enhanced_df[f'total_battle_index_{window}'] = (
                enhanced_df[f'home_last_{window}_avg_xg'] +
                enhanced_df[f'away_last_{window}_avg_xg']
            )

        # 4. çŠ¶æ€ç¨³å®šæ€§ç‰¹å¾
        for window in [5, 10]:
            # è¡¨ç°ç¨³å®šæ€§ (é€šè¿‡æ ‡å‡†å·®è®¡ç®—ï¼Œè¿™é‡Œç®€åŒ–ä¸ºå˜å¼‚ç³»æ•°çš„ä¼°è®¡)
            enhanced_df[f'performance_stability_home_{window}'] = (
                1.0 / (1.0 + enhanced_df[f'home_last_{window}_avg_goal_diff'].abs())
            )

            enhanced_df[f'performance_stability_away_{window}'] = (
                1.0 / (1.0 + enhanced_df[f'away_last_{window}_avg_goal_diff'].abs())
            )

        # 5. æ—¶é—´ç‰¹å¾å¢å¼º
        enhanced_df['month_sin'] = np.sin(2 * np.pi * enhanced_df['month'] / 12)
        enhanced_df['month_cos'] = np.cos(2 * np.pi * enhanced_df['month'] / 12)
        enhanced_df['day_of_week_sin'] = np.sin(2 * np.pi * enhanced_df['day_of_week'] / 7)
        enhanced_df['day_of_week_cos'] = np.cos(2 * np.pi * enhanced_df['day_of_week'] / 7)

        logger.info(f"   âœ… å¢å¼ºç‰¹å¾è®¡ç®—å®Œæˆ")
        logger.info(f"   ğŸ“Š åŸå§‹ç‰¹å¾: {len(df.columns)}")
        logger.info(f"   âš¡ å¢å¼ºåç‰¹å¾: {len(enhanced_df.columns)}")

        return enhanced_df

    def select_enhanced_features(self, df: pd.DataFrame) -> tuple:
        """é€‰æ‹©å¢å¼ºç‰¹å¾"""
        logger.info("ğŸ¯ é€‰æ‹©å¢å¼ºç‰¹å¾")

        # åŸºç¡€æ»šåŠ¨ç‰¹å¾
        rolling_features = [col for col in df.columns if 'last_' in col]

        # å¢å¼ºç‰¹å¾
        enhanced_feature_patterns = [
            'h2h_', 'form_trend_', 'attack_defense_balance_',
            'total_battle_index_', 'performance_stability_',
            'month_sin', 'month_cos', 'day_of_week_sin', 'day_of_week_cos'
        ]

        enhanced_features = []
        for pattern in enhanced_feature_patterns:
            enhanced_features.extend([col for col in df.columns if pattern in col])

        # åŸºç¡€ä¸Šä¸‹æ–‡ç‰¹å¾
        context_features = [
            'year', 'month', 'day_of_week', 'is_weekend',
            'month_sin', 'month_cos', 'day_of_week_sin', 'day_of_week_cos'
        ]

        context_features = [col for col in context_features if col in df.columns]

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        all_feature_columns = rolling_features + enhanced_features + context_features

        logger.info(f"   âœ… æ»šåŠ¨ç‰¹å¾: {len(rolling_features)}")
        logger.info(f"   âš¡ å¢å¼ºç‰¹å¾: {len(enhanced_features)}")
        logger.info(f"   ğŸ“… ä¸Šä¸‹æ–‡ç‰¹å¾: {len(context_features)}")
        logger.info(f"   ğŸ“‹ æ€»ç‰¹å¾æ•°: {len(all_feature_columns)}")

        # æå–ç‰¹å¾å’Œç›®æ ‡
        X = df[all_feature_columns].copy()
        y = df['true_result'].copy()

        # å¤„ç†ç¼ºå¤±å€¼
        X = X.fillna(0)

        logger.info(f"   ğŸ“Š ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        logger.info(f"   ğŸ¯ ç›®æ ‡å˜é‡å½¢çŠ¶: {y.shape}")

        return X, y, all_feature_columns

    def train_enhanced_model(self, data_path: str) -> dict:
        """å®Œæ•´çš„å¢å¼ºæ¨¡å‹è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å¢å¼ºæ¨¡å‹è®­ç»ƒæµç¨‹")

        # 1. åŠ è½½æ•°æ®
        df = self.load_and_prepare_data(data_path)

        # 2. è®¡ç®—å¢å¼ºç‰¹å¾
        df_enhanced = self.calculate_enhanced_rolling_features(df)

        # 3. é€‰æ‹©å¢å¼ºç‰¹å¾
        X, y, feature_columns = self.select_enhanced_features(df_enhanced)

        # 4. æ—¶åºåˆ†å‰²
        X_train, X_test, y_train_enc, y_test_enc, y_train_orig, y_test_orig = \
            self.split_data_chronological(X, y)

        # 5. è®­ç»ƒæ¨¡å‹
        self.feature_names = feature_columns
        self.train_xgboost(X_train, y_train_enc)

        # 6. è¯„ä¼°æ¨¡å‹
        results = self.evaluate_model(X_test, y_test_enc, y_test_orig)

        # 7. ç‰¹å¾é‡è¦æ€§
        self.plot_feature_importance()

        logger.info("ğŸ‰ å¢å¼ºæ¨¡å‹è®­ç»ƒå®Œæˆ!")
        return results


def compare_models(baseline_results: dict, enhanced_results: dict):
    """æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½"""
    print("\n" + "="*80)
    print("ğŸ† MODEL COMPARISON SUMMARY")
    print("="*80)

    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
    print(f"{'æŒ‡æ ‡':<20} {'åŸºçº¿æ¨¡å‹':<15} {'å¢å¼ºæ¨¡å‹':<15} {'æ”¹è¿›':<10}")
    print("-" * 70)

    acc_baseline = baseline_results['accuracy']
    acc_enhanced = enhanced_results['accuracy']
    acc_improvement = ((acc_enhanced - acc_baseline) / acc_baseline) * 100

    print(f"{'å‡†ç¡®ç‡ (Accuracy)':<20} {acc_baseline:<15.4f} {acc_enhanced:<15.4f} {acc_improvement:+.2f}%")

    ll_baseline = baseline_results['log_loss']
    ll_enhanced = enhanced_results['log_loss']
    ll_improvement = ((ll_baseline - ll_enhanced) / ll_baseline) * 100

    print(f"{'å¯¹æ•°æŸå¤± (Log Loss)':<20} {ll_baseline:<15.4f} {ll_enhanced:<15.4f} {ll_improvement:+.2f}%")

    print(f"\nâœ… ç»“è®º:")
    if acc_improvement > 1.0:
        print(f"   ğŸš€ å¢å¼ºç‰¹å¾æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½!")
    elif acc_improvement > 0.5:
        print(f"   ğŸ“ˆ å¢å¼ºç‰¹å¾è½»å¾®æå‡äº†æ¨¡å‹æ€§èƒ½")
    elif acc_improvement > -0.5:
        print(f"   â¡ï¸ å¢å¼ºç‰¹å¾å¯¹æ€§èƒ½å½±å“ä¸å¤§")
    else:
        print(f"   ğŸ“‰ å¢å¼ºç‰¹å¾é™ä½äº†æ¨¡å‹æ€§èƒ½")

    print("="*80)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ V2 å¢å¼ºç‰¹å¾å®éªŒå¼€å§‹")
    print("="*80)

    try:
        # 1. è®­ç»ƒåŸºçº¿æ¨¡å‹ (ä½œä¸ºå¯¹æ¯”)
        print("\n1ï¸âƒ£ è®­ç»ƒåŸºçº¿æ¨¡å‹ (V1)...")
        baseline_trainer = BaselineTrainer()
        baseline_results = baseline_trainer.train_baseline_model(
            data_path="data/processed/features_v2_rolling.csv"
        )

        # 2. è®­ç»ƒå¢å¼ºæ¨¡å‹ (V2)
        print("\n2ï¸âƒ£ è®­ç»ƒå¢å¼ºæ¨¡å‹ (V2)...")
        enhanced_trainer = EnhancedFeaturesTrainer()
        enhanced_results = enhanced_trainer.train_enhanced_model(
            data_path="data/processed/features_v2_rolling.csv"
        )

        # 3. æ¨¡å‹å¯¹æ¯”
        compare_models(baseline_results, enhanced_results)

        # ä¿å­˜å¢å¼ºç‰¹å¾é‡è¦æ€§
        enhanced_trainer.plot_feature_importance()

    except Exception as e:
        logger.error(f"âŒ å®éªŒå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()