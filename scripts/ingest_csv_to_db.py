#!/usr/bin/env python3
"""
CSVæ‰¹é‡å…¥åº“å™¨ - æ•°æ®æ²»ç†å·¥ç¨‹å¸ˆä¸“ç”¨
å°†FBrefé‡‡é›†çš„CSVæ•°æ®æ‰¹é‡å¯¼å…¥PostgreSQLæ•°æ®åº“
"""

import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import pandas as pd
import json
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.database.async_manager import get_async_db_session
from src.database.models.match import Match
from src.database.models.team import Team
from src.database.models.league import League
from sqlalchemy import select, insert, update, and_, or_
from sqlalchemy.ext.asyncio import AsyncSession

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("logs/csv_ingestion.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class CSVDataIngester:
    """CSVæ•°æ®æ‰¹é‡å…¥åº“å™¨"""

    def __init__(self):
        self.csv_dir = Path("data/fbref")
        self.ingestion_stats = {
            "total_files": 0,
            "total_matches": 0,
            "successful_matches": 0,
            "failed_matches": 0,
            "xg_coverage": {},
            "leagues_processed": [],
        }

        # åˆ›å»ºæ—¥å¿—ç›®å½•
        Path("logs").mkdir(exist_ok=True)

    async def run(self):
        """æ‰§è¡Œæ‰¹é‡å…¥åº“"""
        logger.info("ğŸš€ å¼€å§‹CSVæ‰¹é‡å…¥åº“...")
        start_time = datetime.now()

        # æ‰«ææ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(self.csv_dir.glob("*.csv"))
        self.ingestion_stats["total_files"] = len(csv_files)

        logger.info(f"ğŸ“ å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")

        # è·å–å¼‚æ­¥ä¼šè¯
        async with get_async_db_session() as session:
            for csv_file in csv_files:
                await self._process_csv_file(csv_file, session)
                await session.commit()  # æ¯ä¸ªæ–‡ä»¶æäº¤ä¸€æ¬¡

        # ç”ŸæˆxGè¦†ç›–ç‡æŠ¥å‘Š
        self._generate_xg_coverage_report()

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        logger.info("ğŸ‰ CSVæ‰¹é‡å…¥åº“å®Œæˆ!")
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’")
        logger.info(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {self.ingestion_stats}")

        return self.ingestion_stats

    async def _process_csv_file(self, csv_file: Path, session: AsyncSession):
        """å¤„ç†å•ä¸ªCSVæ–‡ä»¶"""
        league_id = csv_file.stem.replace("_all_seasons_matches", "")
        logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {csv_file.name} (è”èµ›ID: {league_id})")

        try:
            # è¯»å–CSVæ•°æ®
            df = pd.read_csv(csv_file)
            if df.empty:
                logger.warning(f"âš ï¸  æ–‡ä»¶ä¸ºç©º: {csv_file.name}")
                return

            # æ•°æ®æ¸…æ´—å’Œè½¬æ¢
            df_cleaned = self._clean_and_transform_data(df, league_id)
            if df_cleaned.empty:
                logger.warning(f"âš ï¸  æ¸…æ´—åæ— æœ‰æ•ˆæ•°æ®: {csv_file.name}")
                return

            # xGè¦†ç›–ç‡åˆ†æ
            xg_stats = self._analyze_xg_coverage(df_cleaned, league_id)

            # æ‰¹é‡å…¥åº“
            success_count = await self._batch_insert_matches(
                df_cleaned, session, league_id
            )

            # æ›´æ–°ç»Ÿè®¡
            self.ingestion_stats["total_matches"] += len(df_cleaned)
            self.ingestion_stats["successful_matches"] += success_count
            self.ingestion_stats["leagues_processed"].append(league_id)

            logger.info(
                f"âœ… {csv_file.name}: {success_count}/{len(df_cleaned)} åœºæ¯”èµ›å…¥åº“æˆåŠŸ"
            )
            logger.info(f"ğŸ“Š xGè¦†ç›–ç‡: {xg_stats}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {csv_file.name}: {e}")
            self.ingestion_stats["failed_matches"] += len(df) if "df" in locals() else 0

    def _clean_and_transform_data(
        self, df: pd.DataFrame, league_id: str
    ) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—å’Œè½¬æ¢"""
        logger.info(f"ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—: {len(df)} è¡ŒåŸå§‹æ•°æ®")

        # åˆ›å»ºæ–°DataFrame
        cleaned_data = []

        for idx, row in df.iterrows():
            try:
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                if pd.isna(row.get("Home")) or pd.isna(row.get("Away")):
                    continue

                # è§£ææ¯”åˆ†
                home_score = None
                away_score = None

                score = str(row.get("Score", "")).strip()
                if score and "â€“" in score:
                    # ä½¿ç”¨en dash (U+2013) åˆ†å‰²æ¯”åˆ†
                    parts = score.split("â€“")
                    if len(parts) == 2:
                        try:
                            home_score = int(parts[0].strip())
                            away_score = int(parts[1].strip())
                        except ValueError:
                            # å¦‚æœä¸èƒ½è½¬ä¸ºæ•´æ•°ï¼Œä¿æŒNone
                            pass

                # è§£ææ—¥æœŸ
                match_date = None
                date_str = str(row.get("Date", "")).strip()
                if date_str and date_str != "nan":
                    try:
                        # å¤„ç†å¯èƒ½çš„å¤šç§æ—¥æœŸæ ¼å¼
                        match_date = pd.to_datetime(date_str).to_pydatetime()
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­
                        pass

                # è§£æxGæ•°æ®
                home_xg = None
                away_xg = None

                if not pd.isna(row.get("xG")):
                    try:
                        home_xg = float(row.get("xG"))
                        if home_xg < 0 or home_xg > 10:  # åˆç†æ€§æ£€æŸ¥
                            home_xg = None
                    except (ValueError, TypeError):
                        pass

                if not pd.isna(row.get("xG.1")):
                    try:
                        away_xg = float(row.get("xG.1"))
                        if away_xg < 0 or away_xg > 10:  # åˆç†æ€§æ£€æŸ¥
                            away_xg = None
                    except (ValueError, TypeError):
                        pass

                # æ„å»ºåŒ¹é…é”® (ç”¨äºå»é‡)
                match_key = self._generate_match_key(
                    row.get("Home"), row.get("Away"), match_date
                )

                cleaned_record = {
                    "match_key": match_key,
                    "home_team_name": str(row.get("Home")).strip(),
                    "away_team_name": str(row.get("Away")).strip(),
                    "home_score": home_score,
                    "away_score": away_score,
                    "match_date": match_date,
                    "venue": (
                        str(row.get("Venue", "")).strip()
                        if not pd.isna(row.get("Venue"))
                        else None
                    ),
                    "attendance": None,
                    "league_id": league_id,
                    "season": "2024-2025",  # åŸºäºæ•°æ®æ¨æµ‹
                    "home_xg": home_xg,
                    "away_xg": away_xg,
                    "data_source": "fbref",
                    "raw_data": row.to_dict(),  # ä¿å­˜åŸå§‹æ•°æ®
                }

                # è§£æè§‚ä¼—äººæ•°
                attendance = row.get("Attendance")
                if attendance and not pd.isna(attendance):
                    try:
                        cleaned_record["attendance"] = int(
                            str(attendance).replace(",", "")
                        )
                    except ValueError:
                        pass

                cleaned_data.append(cleaned_record)

            except Exception as e:
                logger.warning(f"âš ï¸ è¡Œ {idx} æ•°æ®æ¸…æ´—å¤±è´¥: {e}")
                continue

        result_df = pd.DataFrame(cleaned_data)
        logger.info(f"âœ… æ¸…æ´—å®Œæˆ: {len(result_df)} è¡Œæœ‰æ•ˆæ•°æ®")

        return result_df

    def _generate_match_key(
        self, home_team: str, away_team: str, match_date: datetime
    ) -> str:
        """ç”Ÿæˆæ¯”èµ›å”¯ä¸€é”®"""
        if match_date:
            date_str = match_date.strftime("%Y-%m-%d")
        else:
            date_str = "unknown"

        # æ ‡å‡†åŒ–é˜Ÿå
        home_clean = re.sub(r"[^a-zA-Z0-9]", "", str(home_team).lower())
        away_clean = re.sub(r"[^a-zA-Z0-9]", "", str(away_team).lower())

        return f"{home_clean}_{away_clean}_{date_str}"

    def _analyze_xg_coverage(self, df: pd.DataFrame, league_id: str) -> Dict:
        """åˆ†æxGè¦†ç›–ç‡"""
        total_matches = len(df)
        matches_with_xg = df[(df["home_xg"].notna()) & (df["away_xg"].notna())].shape[0]

        xg_coverage = {
            "total_matches": total_matches,
            "matches_with_xg": matches_with_xg,
            "coverage_rate": (
                (matches_with_xg / total_matches * 100) if total_matches > 0 else 0
            ),
            "home_xg_mean": df["home_xg"].mean() if matches_with_xg > 0 else None,
            "away_xg_mean": df["away_xg"].mean() if matches_with_xg > 0 else None,
        }

        self.ingestion_stats["xg_coverage"][league_id] = xg_coverage

        return xg_coverage

    async def _batch_insert_matches(
        self, df: pd.DataFrame, session: AsyncSession, league_id: str
    ) -> int:
        """æ‰¹é‡æ’å…¥æ¯”èµ›æ•°æ®"""
        logger.info(f"ğŸ’¾ å¼€å§‹æ‰¹é‡æ’å…¥: {len(df)} åœºæ¯”èµ›")

        success_count = 0

        for idx, row in df.iterrows():
            try:
                # æŸ¥æ‰¾æˆ–åˆ›å»ºä¸»é˜Ÿ
                home_team_id = await self._get_or_create_team(
                    session, row["home_team_name"]
                )

                # æŸ¥æ‰¾æˆ–åˆ›å»ºå®¢é˜Ÿ
                away_team_id = await self._get_or_create_team(
                    session, row["away_team_name"]
                )

                # æŸ¥æ‰¾è”èµ›
                league_obj = await self._get_league_by_id(session, league_id)
                league_db_id = league_obj.id if league_obj else None

                # æ£€æŸ¥æ¯”èµ›æ˜¯å¦å·²å­˜åœ¨
                existing_match = await self._find_existing_match(
                    session, home_team_id, away_team_id, row["match_date"]
                )

                if existing_match:
                    # æ›´æ–°ç°æœ‰æ¯”èµ›
                    await self._update_match(
                        session, existing_match.id, row, league_db_id
                    )
                    success_count += 1
                else:
                    # æ’å…¥æ–°æ¯”èµ›
                    await self._insert_new_match(
                        session, row, home_team_id, away_team_id, league_db_id
                    )
                    success_count += 1

                if success_count % 100 == 0:
                    await session.commit()  # æ¯100æ¡æäº¤ä¸€æ¬¡

            except Exception as e:
                logger.warning(f"âš ï¸ è¡Œ {idx} å…¥åº“å¤±è´¥: {e}")
                continue

        await session.commit()  # æœ€ç»ˆæäº¤
        logger.info(f"âœ… æ‰¹é‡æ’å…¥å®Œæˆ: {success_count} åœºæ¯”èµ›æˆåŠŸ")

        return success_count

    async def _get_or_create_team(self, session: AsyncSession, team_name: str) -> int:
        """è·å–æˆ–åˆ›å»ºé˜Ÿä¼"""
        # æŸ¥æ‰¾ç°æœ‰é˜Ÿä¼
        result = await session.execute(select(Team).where(Team.name == team_name))
        team = result.scalar_one_or_none()

        if team:
            return team.id

        # åˆ›å»ºæ–°é˜Ÿä¼
        new_team = Team(name=team_name)
        session.add(new_team)
        await session.flush()  # è·å–ID

        logger.info(f"ğŸƒ åˆ›å»ºæ–°é˜Ÿä¼: {team_name} (ID: {new_team.id})")
        return new_team.id

    async def _get_league_by_id(
        self, session: AsyncSession, league_id: str
    ) -> Optional[League]:
        """æ ¹æ®IDè·å–è”èµ›"""
        # å°è¯•å¤šç§åŒ¹é…æ–¹å¼
        result = await session.execute(
            select(League).where(
                or_(
                    League.league_id == league_id,
                    League.name == league_id,
                    League.short_name == league_id,
                )
            )
        )
        return result.scalar_one_or_none()

    async def _find_existing_match(
        self,
        session: AsyncSession,
        home_team_id: int,
        away_team_id: int,
        match_date: datetime,
    ) -> Optional[Match]:
        """æŸ¥æ‰¾ç°æœ‰æ¯”èµ›"""
        if not match_date:
            return None

        result = await session.execute(
            select(Match).where(
                and_(
                    Match.home_team_id == home_team_id,
                    Match.away_team_id == away_team_id,
                    Match.match_date == match_date,
                )
            )
        )
        return result.scalar_one_or_none()

    async def _update_match(
        self,
        session: AsyncSession,
        match_id: int,
        row: pd.Series,
        league_id: Optional[int],
    ):
        """æ›´æ–°ç°æœ‰æ¯”èµ›"""
        update_data = {
            "home_score": row["home_score"],
            "away_score": row["away_score"],
            "venue": row["venue"],
            "attendance": row["attendance"],
            "league_id": league_id,
            "season": row["season"],
            "updated_at": datetime.now(),
            "data_source": row["data_source"],
            "data_completeness": (
                "complete" if row["home_xg"] and row["away_xg"] else "partial"
            ),
        }

        # æ›´æ–°JSONå­—æ®µ
        stats_data = {"home_xg": row["home_xg"], "away_xg": row["away_xg"]}
        update_data["stats"] = stats_data

        # ä¿å­˜åŸå§‹æ•°æ®
        update_data["match_metadata"] = {
            "raw_csv_data": row["raw_data"],
            "ingestion_timestamp": datetime.now().isoformat(),
        }

        await session.execute(
            update(Match).where(Match.id == match_id).values(**update_data)
        )

    async def _insert_new_match(
        self,
        session: AsyncSession,
        row: pd.Series,
        home_team_id: int,
        away_team_id: int,
        league_id: Optional[int],
    ):
        """æ’å…¥æ–°æ¯”èµ›"""
        new_match = Match(
            home_team_id=home_team_id,
            away_team_id=away_team_id,
            home_score=row["home_score"],
            away_score=row["away_score"],
            status="completed",
            match_date=row["match_date"] or datetime.now(),
            venue=row["venue"],
            attendance=row["attendance"],
            league_id=league_id,
            season=row["season"],
            created_at=datetime.now(),
            updated_at=datetime.now(),
            data_source=row["data_source"],
            data_completeness=(
                "complete" if row["home_xg"] and row["away_xg"] else "partial"
            ),
        )

        # è®¾ç½®JSONå­—æ®µ
        stats_data = {"home_xg": row["home_xg"], "away_xg": row["away_xg"]}
        new_match.stats = stats_data

        # ä¿å­˜åŸå§‹æ•°æ®
        new_match.match_metadata = {
            "raw_csv_data": row["raw_data"],
            "ingestion_timestamp": datetime.now().isoformat(),
        }

        session.add(new_match)

    def _generate_xg_coverage_report(self):
        """ç”ŸæˆxGè¦†ç›–ç‡æŠ¥å‘Š"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š xGè¦†ç›–ç‡åˆ†ææŠ¥å‘Š")
        logger.info("=" * 60)

        total_matches = sum(
            stats["total_matches"]
            for stats in self.ingestion_stats["xg_coverage"].values()
        )
        total_with_xg = sum(
            stats["matches_with_xg"]
            for stats in self.ingestion_stats["xg_coverage"].values()
        )
        overall_coverage = (
            (total_with_xg / total_matches * 100) if total_matches > 0 else 0
        )

        logger.info(
            f"ğŸŒ æ€»ä½“è¦†ç›–ç‡: {overall_coverage:.1f}% ({total_with_xg:,}/{total_matches:,} åœºæ¯”èµ›)"
        )
        logger.info("")

        # æŒ‰è¦†ç›–ç‡åˆ†ç»„æ˜¾ç¤º
        high_coverage = []
        medium_coverage = []
        low_coverage = []

        for league_id, stats in self.ingestion_stats["xg_coverage"].items():
            if stats["coverage_rate"] >= 80:
                high_coverage.append((league_id, stats))
            elif stats["coverage_rate"] >= 20:
                medium_coverage.append((league_id, stats))
            else:
                low_coverage.append((league_id, stats))

        logger.info("ğŸŸ¢ é«˜xGè¦†ç›–ç‡è”èµ› (â‰¥80%):")
        for league_id, stats in sorted(
            high_coverage, key=lambda x: x[1]["coverage_rate"], reverse=True
        ):
            logger.info(
                f"  {league_id:25s}: {stats['coverage_rate']:5.1f}% ({stats['matches_with_xg']:4d}/{stats['total_matches']:4d}) "
                f"[ä¸»é˜ŸxGå‡:{stats['home_xg_mean']:.2f}, å®¢é˜ŸxGå‡:{stats['away_xg_mean']:.2f}]"
            )

        if medium_coverage:
            logger.info("\nğŸŸ¡ ä¸­ç­‰xGè¦†ç›–ç‡è”èµ› (20-79%):")
            for league_id, stats in sorted(
                medium_coverage, key=lambda x: x[1]["coverage_rate"], reverse=True
            ):
                logger.info(
                    f"  {league_id:25s}: {stats['coverage_rate']:5.1f}% ({stats['matches_with_xg']:4d}/{stats['total_matches']:4d})"
                )

        if low_coverage:
            logger.info("\nğŸ”´ ä½xGè¦†ç›–ç‡è”èµ› (<20%):")
            for league_id, stats in sorted(
                low_coverage, key=lambda x: x[1]["coverage_rate"], reverse=True
            ):
                logger.info(
                    f"  {league_id:25s}: {stats['coverage_rate']:5.1f}% ({stats['matches_with_xg']:4d}/{stats['total_matches']:4d}) [ä»…æ¯”åˆ†æ•°æ®]"
                )


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ”§ å¯åŠ¨CSVæ‰¹é‡å…¥åº“å™¨")

    ingester = CSVDataIngester()
    stats = await ingester.run()

    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ å…¥åº“ç»Ÿè®¡æ‘˜è¦")
    logger.info("=" * 60)
    logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {stats['total_files']}")
    logger.info(f"âš½ æ€»æ¯”èµ›æ•°: {stats['total_matches']:,}")
    logger.info(f"âœ… æˆåŠŸå…¥åº“: {stats['successful_matches']:,}")
    logger.info(f"âŒ å¤±è´¥æ•°é‡: {stats['failed_matches']:,}")
    logger.info(
        f"ğŸ“Š æˆåŠŸç‡: {stats['successful_matches']/stats['total_matches']*100:.1f}%"
    )

    return 0 if stats["successful_matches"] > 0 else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
