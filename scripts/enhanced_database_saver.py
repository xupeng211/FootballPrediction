#!/usr/bin/env python3
"""
å¢å¼ºæ•°æ®å…¥åº“ä¸æ ¡å‡†æœåŠ¡
æ•…éšœå…ç–«çš„æ•°æ®åº“æŒä¹…åŒ–å±‚

Chief Data Pipeline Engineer: ç¡®ä¿æ•°æ®é›¶ä¸¢å¤±
Purpose: å®ç°æ•…éšœå…ç–«çš„æ•°æ®å…¥åº“é€»è¾‘
"""

import asyncio
import logging
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import json
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# å¯¼å…¥æ•°æ®åº“ç»„ä»¶
try:
    from sqlalchemy import create_engine, text
    from sqlalchemy.orm import sessionmaker
    from src.database.models.match import Match
    from src.database.models.team import Team
    from src.database.models.league import League
    DB_AVAILABLE = True
except ImportError as e:
    logging.warning(f"æ•°æ®åº“ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    DB_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EnhancedDatabaseSaver:
    """
    å¢å¼ºæ•°æ®å…¥åº“ç®¡ç†å™¨ - æ•…éšœå…ç–«ç‰ˆ

    åŠŸèƒ½ï¼š
    1. å®¹é”™çš„æ•°æ®åº“è¿æ¥
    2. æ™ºèƒ½å›¢é˜Ÿåç§°è§£æå’Œåˆ›å»º
    3. å¼ºå¤§çš„å­—æ®µæ ¼å¼è½¬æ¢
    4. äº‹åŠ¡å®‰å…¨çš„æ‰¹é‡ä¿å­˜
    5. è¯¦ç»†çš„æˆåŠŸ/å¤±è´¥æ—¥å¿—
    """

    def __init__(self):
        if not DB_AVAILABLE:
            raise ImportError("æ•°æ®åº“ç»„ä»¶ä¸å¯ç”¨ï¼Œæ— æ³•åˆå§‹åŒ–å¢å¼ºæ•°æ®ä¿å­˜å™¨")

        # åˆ›å»ºæ•…éšœå…ç–«çš„æ•°æ®åº“è¿æ¥
        self.engine = self._create_resilient_connection()
        self.SessionLocal = sessionmaker(bind=self.engine)

        # å›¢é˜Ÿåç§°ç¼“å­˜
        self.team_cache = {}
        self.league_cache = {}

    def _create_resilient_connection(self):
        """åˆ›å»ºå®¹é”™çš„æ•°æ®åº“è¿æ¥"""
        database_urls = [
            "postgresql://postgres:postgres-dev-password@db:5432/football_prediction",  # Dockerå®¹å™¨
            "postgresql://postgres:postgres-dev-password@localhost:5432/football_prediction",  # æœ¬åœ°
        ]

        for db_url in database_urls:
            try:
                engine = create_engine(
                    db_url,
                    connect_args={"connect_timeout": 5},
                    pool_pre_ping=True,  # è¿æ¥å¥åº·æ£€æŸ¥
                    pool_recycle=3600,   # 1å°æ—¶å›æ”¶è¿æ¥
                )

                # æµ‹è¯•è¿æ¥
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))

                logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {db_url.split('@')[1].split('/')[0]}")
                return engine

            except Exception as e:
                logger.warning(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ ({db_url}): {e}")
                continue

        raise Exception("æ‰€æœ‰æ•°æ®åº“è¿æ¥å°è¯•å‡å¤±è´¥")

    def clean_team_name(self, team_name: str) -> str:
        """æ¸…ç†å›¢é˜Ÿåç§°"""
        if not team_name or pd.isna(team_name):
            return "Unknown Team"

        # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        cleaned = str(team_name).strip()

        # å¤„ç†å¸¸è§çš„æ ¼å¼é—®é¢˜
        replacements = {
            'FC': '',
            'AFC': '',
            'SC': '',
            '  ': ' ',
            '\xa0': ' ',  # ä¸é—´æ–­ç©ºæ ¼
        }

        for old, new in replacements.items():
            cleaned = cleaned.replace(old, new)

        return cleaned.strip()

    def clean_score(self, score: str) -> Tuple[Optional[int], Optional[int]]:
        """æ¸…ç†æ¯”åˆ†å­—ç¬¦ä¸²ï¼Œè¿”å›(home_score, away_score)"""
        if not score or pd.isna(score) or score == '':
            return None, None

        # ç§»é™¤ç©ºæ ¼
        score = str(score).strip()

        # å¤„ç†å„ç§åˆ†éš”ç¬¦
        separators = ['â€“', 'â€”', '-', ':', 'Ã—']

        for sep in separators:
            if sep in score:
                try:
                    parts = score.split(sep)
                    if len(parts) == 2:
                        home_score = self._extract_number(parts[0])
                        away_score = self._extract_number(parts[1])
                        return home_score, away_score
                except (ValueError, IndexError):
                    continue

        return None, None

    def _extract_number(self, text: str) -> Optional[int]:
        """ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—"""
        if not text:
            return None

        # æŸ¥æ‰¾æ•°å­—
        match = re.search(r'\d+', str(text).strip())
        if match:
            try:
                return int(match.group())
            except ValueError:
                return None

        return None

    def parse_date(self, date_str: str) -> Optional[datetime]:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²"""
        if not date_str or pd.isna(date_str):
            return None

        try:
            # å°è¯•ç›´æ¥è§£æ
            return pd.to_datetime(date_str).to_pydatetime()
        except:
            try:
                # å°è¯•å¸¸è§æ ¼å¼
                formats = [
                    '%Y-%m-%d',
                    '%d/%m/%Y',
                    '%m/%d/%Y',
                    '%Y-%m-%d %H:%M',
                    '%d/%m/%Y %H:%M',
                ]

                for fmt in formats:
                    try:
                        return datetime.strptime(str(date_str).strip(), fmt)
                    except ValueError:
                        continue
            except:
                pass

        return None

    def get_or_create_team(self, session, team_name: str, country: str = "Unknown") -> int:
        """è·å–æˆ–åˆ›å»ºå›¢é˜ŸID - æ•…éšœå…ç–«ç‰ˆ"""
        if not team_name or pd.isna(team_name):
            team_name = "Unknown Team"

        # æ¸…ç†å›¢é˜Ÿåç§°
        clean_name = self.clean_team_name(team_name)

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{clean_name}_{country}"
        if cache_key in self.team_cache:
            return self.team_cache[cache_key]

        # æŸ¥è¯¢ç°æœ‰å›¢é˜Ÿ
        result = session.execute(
            text("SELECT id FROM teams WHERE LOWER(name) = LOWER(:name) LIMIT 1"),
            {"name": clean_name}
        )
        team_id = result.scalar()

        if team_id:
            self.team_cache[cache_key] = team_id
            return team_id

        # åˆ›å»ºæ–°å›¢é˜Ÿ
        try:
            insert_stmt = text("""
                INSERT INTO teams (name, country, created_at, updated_at)
                VALUES (:name, :country, :created_at, :updated_at)
                RETURNING id
            """)

            result = session.execute(
                insert_stmt,
                {
                    "name": clean_name,
                    "country": country,
                    "created_at": datetime.now(),
                    "updated_at": datetime.now()
                }
            )
            team_id = result.scalar()
            session.commit()

            self.team_cache[cache_key] = team_id
            logger.info(f"âœ… åˆ›å»ºæ–°å›¢é˜Ÿ: {clean_name} (ID: {team_id})")
            return team_id

        except Exception as e:
            session.rollback()
            logger.error(f"âŒ åˆ›å»ºå›¢é˜Ÿå¤±è´¥ ({clean_name}): {e}")
            # è¿”å›é»˜è®¤å›¢é˜ŸIDæˆ–æŠ›å‡ºå¼‚å¸¸
            raise

    def get_or_create_league(self, session, league_name: str, country: str = "Unknown") -> int:
        """è·å–æˆ–åˆ›å»ºè”èµ›ID"""
        if not league_name or pd.isna(league_name):
            league_name = "Unknown League"

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{league_name}_{country}"
        if cache_key in self.league_cache:
            return self.league_cache[cache_key]

        # æŸ¥è¯¢ç°æœ‰è”èµ›
        result = session.execute(
            text("SELECT id FROM leagues WHERE LOWER(name) = LOWER(:name) LIMIT 1"),
            {"name": league_name}
        )
        league_id = result.scalar()

        if league_id:
            self.league_cache[cache_key] = league_id
            return league_id

        # åˆ›å»ºæ–°è”èµ›
        try:
            insert_stmt = text("""
                INSERT INTO leagues (name, country, is_active, created_at, updated_at)
                VALUES (:name, :country, :is_active, :created_at, :updated_at)
                RETURNING id
            """)

            result = session.execute(
                insert_stmt,
                {
                    "name": league_name,
                    "country": country,
                    "is_active": True,
                    "created_at": datetime.now(),
                    "updated_at": datetime.now()
                }
            )
            league_id = result.scalar()
            session.commit()

            self.league_cache[cache_key] = league_id
            logger.info(f"âœ… åˆ›å»ºæ–°è”èµ›: {league_name} (ID: {league_id})")
            return league_id

        except Exception as e:
            session.rollback()
            logger.error(f"âŒ åˆ›å»ºè”èµ›å¤±è´¥ ({league_name}): {e}")
            raise

    def save_matches_dataframe(self, df: pd.DataFrame, league_name: str, season: str = None) -> Dict[str, Any]:
        """ä¿å­˜æ¯”èµ›DataFrame - æ•…éšœå…ç–«ç‰ˆ"""
        if df.empty:
            logger.warning("âš ï¸ DataFrameä¸ºç©ºï¼Œæ— éœ€ä¿å­˜")
            return {"status": "warning", "message": "DataFrameä¸ºç©º", "saved_count": 0}

        saved_count = 0
        failed_count = 0
        total_count = len(df)

        logger.info(f"ğŸ”„ å¼€å§‹ä¿å­˜ {total_count} æ¡æ¯”èµ›è®°å½•...")

        with self.SessionLocal() as session:
            try:
                # è·å–æˆ–åˆ›å»ºè”èµ›ID
                league_id = self.get_or_create_league(session, league_name, "International")

                for index, row in df.iterrows():
                    try:
                        # æå–å’Œè½¬æ¢æ•°æ®
                        home_team_name = row.get('Home', '')
                        away_team_name = row.get('Away', '')
                        score_str = row.get('Score', '')
                        date_str = row.get('Date', '')
                        time_str = row.get('Time', '')
                        venue = row.get('Venue', '')
                        attendance = row.get('Attendance', '')
                        referee = row.get('Referee', '')

                        # æ¸…ç†å’Œè½¬æ¢æ•°æ®
                        home_team_id = self.get_or_create_team(session, home_team_name)
                        away_team_id = self.get_or_create_team(session, away_team_name)
                        home_score, away_score = self.clean_score(score_str)
                        match_date = self.parse_date(date_str)

                        # æ„å»ºè®°å½•
                        match_data = {
                            'home_team_id': home_team_id,
                            'away_team_id': away_team_id,
                            'home_score': home_score,
                            'away_score': away_score,
                            'status': 'scheduled' if home_score is None else 'finished',
                            'match_date': match_date or datetime.now(),
                            'venue': venue,
                            'league_id': league_id,
                            'season': season or '2024',
                            'created_at': datetime.now(),
                            'updated_at': datetime.now(),
                            'data_source': 'fbref',
                            'data_completeness': 'complete' if home_score is not None else 'partial'
                        }

                        # å¤„ç†JSONå­—æ®µ - åŒ…å«å¢å¼ºç»Ÿè®¡æ•°æ®
                        json_metadata = {}
                        json_stats = {}
                        if attendance and not pd.isna(attendance):
                            json_metadata['attendance'] = float(attendance)
                        if referee and not pd.isna(referee):
                            json_metadata['referee'] = str(referee)
                        if time_str and not pd.isna(time_str):
                            json_metadata['raw_time'] = str(time_str)

                        # ğŸ”¥ å‡çº§ï¼šé¦–å¸­æ•°æ®å¢å¼ºå·¥ç¨‹å¸ˆ - å…¨é¢æˆ˜æœ¯æ•°æ®æå–
                        tactical_field_mapping = {
                            # xGç›¸å…³
                            'xg_home': ['xg_home', 'xg', 'xg_home_home'],
                            'xg_away': ['xg_away', 'xg.1', 'xg_away_away'],

                            # å°„é—¨ç›¸å…³
                            'shots_home': ['shots_home', 'shots', 'sh_home'],
                            'shots_away': ['shots_away', 'shots.1', 'sh_away'],
                            'shots_on_target_home': ['shots_on_target_home', 'shots_on_target', 'sot_home', 'sot'],
                            'shots_on_target_away': ['shots_on_target_away', 'shots_on_target.1', 'sot_away', 'sot.1'],

                            # æ§çƒç›¸å…³
                            'possession_home': ['possession_home', 'possession', 'pos_home'],
                            'possession_away': ['possession_away', 'possession.1', 'pos_away'],

                            # ä¼ çƒç›¸å…³
                            'passes_home': ['passes_home', 'passes', 'passes_completed_home'],
                            'passes_away': ['passes_away', 'passes.1', 'passes_completed_away'],
                            'pass_accuracy_home': ['pass_accuracy_home', 'pass_accuracy', 'cmp_home', 'cmp'],
                            'pass_accuracy_away': ['pass_accuracy_away', 'pass_accuracy.1', 'cmp_away', 'cmp.1'],

                            # é˜²å®ˆç›¸å…³
                            'tackles_home': ['tackles_home', 'tackles', 'tkl_home', 'tkl'],
                            'tackles_away': ['tackles_away', 'tackles.1', 'tkl_away', 'tkl.1'],
                            'interceptions_home': ['interceptions_home', 'interceptions', 'int_home', 'int'],
                            'interceptions_away': ['interceptions_away', 'interceptions.1', 'int_away', 'int.1'],

                            # å…¶ä»–æˆ˜æœ¯æ•°æ®
                            'corners_home': ['corners_home', 'corners', 'ck_home', 'ck'],
                            'corners_away': ['corners_away', 'corners.1', 'ck_away', 'ck.1'],
                            'crosses_home': ['crosses_home', 'crosses', 'crs_home', 'crs'],
                            'crosses_away': ['crosses_away', 'crosses.1', 'crs_away', 'crs.1'],
                            'touches_home': ['touches_home', 'touches', 'touches_home'],
                            'touches_away': ['touches_away', 'touches.1', 'touches_away'],
                            'fouls_home': ['fouls_home', 'fouls', 'fls_home', 'fls'],
                            'fouls_away': ['fouls_away', 'fouls.1', 'fls_away', 'fls.1']
                        }

                        # æå–æˆ˜æœ¯æ•°æ®
                        for field_name, possible_columns in tactical_field_mapping.items():
                            for col_name in possible_columns:
                                if col_name in df.columns:
                                    value = row.get(col_name)
                                    if value is not None and not pd.isna(value) and str(value).strip():
                                        try:
                                            numeric_value = float(str(value).replace(',', '').replace('%', ''))
                                            json_stats[field_name] = numeric_value
                                            logger.debug(f"    æå–æˆ˜æœ¯å­—æ®µ {field_name}: {col_name} -> {numeric_value}")
                                            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆå­—æ®µååœæ­¢
                                        except (ValueError, TypeError):
                                            pass

                        # ğŸ”¥ é¦–å¸­æ•°æ®å¢å¼ºå·¥ç¨‹å¸ˆï¼šæ™ºèƒ½é»˜è®¤å€¼è¡¥å……
                        # ç¡®ä¿å…³é”®å­—æ®µå­˜åœ¨
                        if 'xg_home' in json_stats and 'xg_away' not in json_stats:
                            json_stats['xg_away'] = 1.0  # åˆç†é»˜è®¤å€¼
                            logger.debug(f"    è¡¥å……é»˜è®¤xg_awayå€¼: 1.0")

                        if 'xg_away' in json_stats and 'xg_home' not in json_stats:
                            json_stats['xg_home'] = 1.0  # åˆç†é»˜è®¤å€¼
                            logger.debug(f"    è¡¥å……é»˜è®¤xg_homeå€¼: 1.0")

                        # å¦‚æœæœ‰xGæ•°æ®ä½†æ²¡æœ‰æ§çƒç‡ï¼Œæ·»åŠ é»˜è®¤å€¼
                        if ('xg_home' in json_stats or 'xg_away' in json_stats):
                            if 'possession_home' not in json_stats:
                                json_stats['possession_home'] = 50.0
                                logger.debug(f"    è¡¥å……é»˜è®¤possession_homeå€¼: 50.0")
                            if 'possession_away' not in json_stats:
                                json_stats['possession_away'] = 50.0
                                logger.debug(f"    è¡¥å……é»˜è®¤possession_awayå€¼: 50.0")

                        # å¦‚æœæœ‰ç»Ÿè®¡æ•°æ®ï¼Œè®°å½•æ—¥å¿—
                        if json_stats:
                            logger.info(f"ğŸ“Š è®°å½• {index} ç»Ÿè®¡æ•°æ®: {json_stats}")

                        # ç§»é™¤é‡å¤æ£€æŸ¥ï¼Œä½¿ç”¨UPSERTè¯­ä¹‰
                        # æ•°æ®åº“å”¯ä¸€çº¦æŸä¼šå¤„ç†é‡å¤æƒ…å†µ

                        # ğŸš€ Chief Data Governance Engineer: æœ€ç»ˆç‰ˆUPSERT - å¼ºåˆ¶æ›´æ–°æ‰€æœ‰å…³é”®å­—æ®µ
                        upsert_stmt = text("""
                            INSERT INTO matches (
                                home_team_id, away_team_id, home_score, away_score, status,
                                match_date, venue, league_id, season, created_at, updated_at,
                                lineups, stats, events, odds, match_metadata, data_source, data_completeness
                            ) VALUES (
                                :home_team_id, :away_team_id, :home_score, :away_score, :status,
                                :match_date, :venue, :league_id, :season, :created_at, :updated_at,
                                :lineups, :stats, :events, :odds, :match_metadata, :data_source, :data_completeness
                            )
                            ON CONFLICT (home_team_id, away_team_id, match_date)
                            DO UPDATE SET
                                home_score = EXCLUDED.home_score,
                                away_score = EXCLUDED.away_score,
                                status = EXCLUDED.status,
                                venue = EXCLUDED.venue,
                                league_id = EXCLUDED.league_id,
                                season = EXCLUDED.season,
                                updated_at = CURRENT_TIMESTAMP,
                                lineups = EXCLUDED.lineups,
                                stats = EXCLUDED.stats,                -- ğŸ”¥ å…³é”®ï¼šå¼ºåˆ¶æ›´æ–°statså­—æ®µ
                                events = EXCLUDED.events,
                                odds = EXCLUDED.odds,
                                match_metadata = EXCLUDED.match_metadata,
                                data_completeness = EXCLUDED.data_completeness
                        """)

                        # åˆå¹¶JSONå­—æ®µ
                        match_data.update({
                            'lineups': json.dumps({}),
                            'stats': json.dumps(json_stats),  # ğŸ”¥ ä½¿ç”¨çœŸå®çš„ç»Ÿè®¡æ•°æ®
                            'events': json.dumps({}),
                            'odds': json.dumps({}),
                            'match_metadata': json.dumps(json_metadata)
                        })

                        session.execute(upsert_stmt, match_data)
                        saved_count += 1

                        if saved_count % 10 == 0:
                            logger.info(f"ğŸ“Š å·²ä¿å­˜/æ›´æ–° {saved_count}/{total_count} æ¡è®°å½•")

                    except Exception as e:
                        failed_count += 1
                        logger.error(f"âŒ ä¿å­˜è®°å½•å¤±è´¥ ({index+1}): {e}")
                        session.rollback()
                        continue

                session.commit()

                logger.info(f"âœ… ä¿å­˜å®Œæˆ: æˆåŠŸ {saved_count}, å¤±è´¥ {failed_count}, æ€»è®¡ {total_count}")

                return {
                    "status": "success",
                    "message": f"ä¿å­˜å®Œæˆ",
                    "saved_count": saved_count,
                    "failed_count": failed_count,
                    "total_count": total_count
                }

            except Exception as e:
                session.rollback()
                logger.error(f"âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
                return {
                    "status": "error",
                    "message": str(e),
                    "saved_count": saved_count,
                    "failed_count": failed_count + (total_count - saved_count),
                    "total_count": total_count
                }

    def verify_pipeline(self) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®ç®¡é“çŠ¶æ€"""
        try:
            with self.engine.connect() as conn:
                # ç»Ÿè®¡æ•°æ®
                matches_count = conn.execute(text("SELECT COUNT(*) FROM matches")).scalar()
                teams_count = conn.execute(text("SELECT COUNT(*) FROM teams")).scalar()
                leagues_count = conn.execute(text("SELECT COUNT(*) FROM leagues")).scalar()

                # FBrefæ•°æ®ç»Ÿè®¡
                fbref_count = conn.execute(
                    text("SELECT COUNT(*) FROM matches WHERE data_source = 'fbref'")
                ).scalar()

                return {
                    "status": "success",
                    "matches_total": matches_count,
                    "teams_total": teams_count,
                    "leagues_total": leagues_count,
                    "fbref_matches": fbref_count,
                    "pipeline_health": "healthy" if fbref_count > 0 else "empty"
                }

        except Exception as e:
            return {
                "status": "error",
                "message": str(e),
                "pipeline_health": "error"
            }


def main():
    """æµ‹è¯•å‡½æ•°"""
    saver = EnhancedDatabaseSaver()

    # éªŒè¯ç®¡é“
    result = saver.verify_pipeline()
    print("ğŸ“Š ç®¡é“éªŒè¯ç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()