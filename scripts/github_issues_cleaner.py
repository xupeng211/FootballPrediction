#!/usr/bin/env python3
"""GitHub Issueså®šæœŸæ¸…ç†å·¥å…·"""

import json
import subprocess
from datetime import datetime, timedelta


class GitHubIssuesCleaner:
    def __init__(self, repo_path=None):
        self.repo_path = repo_path or "xupeng211/FootballPrediction"
        self.cleanup_actions = []

    def get_open_issues(self) -> list[dict]:
        """è·å–æ‰€æœ‰å¼€æ”¾Issues"""
        try:
            result = subprocess.run(
                ['gh', 'issue', 'list', '--repo', self.repo_path,
                 '--state', 'open', '--limit', '100', '--json', 'number,title,labels,createdAt,state,author'],
                capture_output=True, text=True
            )

            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                return []
        except Exception:
            return []

    def detect_duplicate_issues(self, issues: list[dict]) -> list[tuple[dict, dict]]:
        """æ£€æµ‹é‡å¤Issues"""
        duplicates = []

        for i, issue1 in enumerate(issues):
            for issue2 in issues[i+1:]:
                # ç®€å•çš„é‡å¤æ£€æµ‹é€»è¾‘
                similarity = self.calculate_similarity(issue1['title'], issue2['title'])
                if similarity > 0.8:  # 80%ç›¸ä¼¼åº¦é˜ˆå€¼
                    duplicates.append((issue1, issue2))

        return duplicates

    def calculate_similarity(self, str1: str, str2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦"""
        # ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
        words1 = set(str1.lower().split())
        words2 = set(str2.lower().split())

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union) if union else 0

    def detect_stale_issues(self, issues: list[dict], days_threshold=30) -> list[dict]:
        """æ£€æµ‹è¿‡æœŸIssues"""
        stale_issues = []
        cutoff_date = datetime.now() - timedelta(days=days_threshold)

        for issue in issues:
            created_at = datetime.fromisoformat(issue['createdAt'].replace('Z', '+00:00')).replace(tzinfo=None)
            if created_at < cutoff_date:
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ€è¿‘çš„æ´»åŠ¨
                if not self.has_recent_activity(issue['number']):
                    stale_issues.append(issue)

        return stale_issues

    def has_recent_activity(self, issue_number: int, days_threshold=7) -> bool:
        """æ£€æŸ¥Issueæ˜¯å¦æœ‰æœ€è¿‘æ´»åŠ¨"""
        try:
            result = subprocess.run(
                ['gh', 'issue', 'view', str(issue_number), '--repo', self.repo_path,
                 '--json', 'comments', '--jq', '.comments | map(select(.createdAt > now - 30d)) | length'],
                capture_output=True, text=True
            )

            if result.returncode == 0:
                recent_comments = int(result.stdout.strip())
                return recent_comments > 0
        except Exception:
            pass

        return False

    def detect_completed_issues(self, issues: list[dict]) -> list[dict]:
        """æ£€æµ‹å·²å®Œæˆä½†æœªå…³é—­çš„Issues"""
        completed_keywords = [
            'å®Œæˆ', 'finished', 'completed', 'done', 'âœ…',
            'è§£å†³', 'resolved', 'fixed', 'ä¿®å¤', 'æˆåŠŸ'
        ]

        completed_issues = []

        for issue in issues:
            # æ£€æŸ¥æ ‡é¢˜ä¸­æ˜¯å¦åŒ…å«å®Œæˆå…³é”®è¯
            title_lower = issue['title'].lower()
            if any(keyword in title_lower for keyword in completed_keywords):
                # è¿›ä¸€æ­¥éªŒè¯æ˜¯å¦çœŸçš„å®Œæˆ
                if self.verify_issue_completion(issue):
                    completed_issues.append(issue)

        return completed_issues

    def verify_issue_completion(self, issue: dict) -> bool:
        """éªŒè¯Issueæ˜¯å¦çœŸçš„å®Œæˆ"""
        # æ£€æŸ¥æ ‡ç­¾
        labels = [label['name'] for label in issue['labels']]
        if 'status/completed' in labels:
            return True

        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆç›¸å…³çš„è¯„è®º
        try:
            result = subprocess.run(
                ['gh', 'issue', 'view', str(issue['number']), '--repo', self.repo_path,
                 '--json', 'comments', '--jq', '.comments[-1].body'],
                capture_output=True, text=True
            )

            if result.returncode == 0:
                last_comment = result.stdout.strip().lower()
                completion_indicators = ['å®Œæˆ', 'finished', 'completed', 'done', 'âœ…']
                return any(indicator in last_comment for indicator in completion_indicators)
        except Exception:
            pass

        return False

    def generate_cleanup_plan(self, issues: list[dict]) -> dict:
        """ç”Ÿæˆæ¸…ç†è®¡åˆ’"""
        duplicates = self.detect_duplicate_issues(issues)
        stale_issues = self.detect_stale_issues(issues)
        completed_issues = self.detect_completed_issues(issues)

        plan = {
            'duplicates': duplicates,
            'stale_issues': stale_issues,
            'completed_issues': completed_issues,
            'total_actions': len(duplicates) + len(stale_issues) + len(completed_issues)
        }

        return plan

    def execute_cleanup_action(self, action_type: str, issue: dict, reason: str = "") -> bool:
        """æ‰§è¡Œæ¸…ç†æ“ä½œ"""
        try:
            if action_type == 'close_completed':
                comment = f"ğŸ¤– è‡ªåŠ¨å…³é—­: æ­¤Issueå·²å®Œæˆä½†æœªå…³é—­ã€‚\n{reason}"
                subprocess.run([
                    'gh', 'issue', 'close', str(issue['number']),
                    '--repo', self.repo_path, '--comment', comment
                ], check=True)

            elif action_type == 'mark_stale':
                subprocess.run([
                    'gh', 'issue', 'edit', str(issue['number']),
                    '--repo', self.repo_path, '--add-label', 'stale'
                ], check=True)

            elif action_type == 'request_merge_duplicate':
                # å¯¹äºé‡å¤Issuesï¼Œæ·»åŠ è¯„è®ºè¯·æ±‚åˆå¹¶
                comment = f"ğŸ¤– æ£€æµ‹åˆ°å¯èƒ½é‡å¤çš„Issueï¼Œè¯·è€ƒè™‘æ˜¯å¦éœ€è¦åˆå¹¶æˆ–å…³é—­å…¶ä¸­ä¸€ä¸ªã€‚\n{reason}"
                subprocess.run([
                    'gh', 'issue', 'comment', str(issue['number']),
                    '--repo', self.repo_path, '--body', comment
                ], check=True)

            return True
        except subprocess.CalledProcessError:
            return False

    def run_cleanup(self, dry_run=True) -> dict:
        """æ‰§è¡Œæ¸…ç†æµç¨‹"""
        issues = self.get_open_issues()


        plan = self.generate_cleanup_plan(issues)


        if dry_run:
            return plan

        # æ‰§è¡Œæ¸…ç†æ“ä½œ
        executed = 0
        failed = 0

        # å…³é—­å·²å®Œæˆçš„Issues
        for issue in plan['completed_issues']:
            if self.execute_cleanup_action('close_completed', issue):
                executed += 1
            else:
                failed += 1

        # æ ‡è®°è¿‡æœŸIssues
        for issue in plan['stale_issues']:
            if self.execute_cleanup_action('mark_stale', issue):
                executed += 1
            else:
                failed += 1

        # å¤„ç†é‡å¤Issues
        for issue1, issue2 in plan['duplicates']:
            reason = f"å¯èƒ½ä¸Issue #{issue2['number']}é‡å¤: {issue2['title']}"
            if self.execute_cleanup_action('request_merge_duplicate', issue1, reason):
                executed += 1
            else:
                failed += 1

        result = {
            'plan': plan,
            'executed': executed,
            'failed': failed,
            'total_issues': len(issues)
        }


        return result

if __name__ == '__main__':
    import sys

    dry_run = '--dry-run' in sys.argv
    cleaner = GitHubIssuesCleaner()
    result = cleaner.run_cleanup(dry_run=dry_run)

    # ä¿å­˜æŠ¥å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'dry_run': dry_run,
        'result': result
    }

    with open('github_issues_cleanup_report.json', 'w') as f:
        json.dump(report, f, indent=2)


    if not dry_run:
        pass
