#!/usr/bin/env python3
"""
åŸºäº Optuna çš„ XGBoost è¶…å‚æ•°ä¼˜åŒ–è„šæœ¬
XGBoost Hyperparameter Tuning with Optuna

è¯¥è„šæœ¬ä½¿ç”¨ Optuna æ¡†æ¶è‡ªåŠ¨å¯»æ‰¾ XGBoost çš„æœ€ä½³å‚æ•°ç»„åˆï¼Œä»¥æå‡é¢„æµ‹å‡†ç¡®ç‡ã€‚
è„šæœ¬ä¼šåŠ è½½ç°æœ‰æ•°æ®ï¼Œè¿›è¡Œç‰¹å¾å·¥ç¨‹ï¼Œç„¶åæ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–ã€‚

ä½¿ç”¨æ–¹æ³• / Usage:
    python scripts/tune_model_optuna.py

è¾“å‡º / Output:
    - Optuna ä¼˜åŒ–è¿‡ç¨‹æ—¥å¿—
    - æœ€ä½³å‚æ•°ç»„åˆ
    - æå‡åçš„å‡†ç¡®ç‡
    - ä¼˜åŒ–åçš„æ¨¡å‹æ–‡ä»¶
"""

import os
import sys
import logging
import json
import pickle
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ ¸å¿ƒä¾èµ–
try:
    import pandas as pd
    import numpy as np
    import optuna
    from optuna.samplers import TPESampler
    from optuna.visualization import plot_optimization_history, plot_parallel_coordinate
    import xgboost as xgb
    from sklearn.model_selection import train_test_split, StratifiedKFold
    from sklearn.metrics import accuracy_score, f1_score, classification_report
    from sklearn.preprocessing import LabelEncoder, StandardScaler

    HAS_DEPENDENCIES = True
except ImportError as e:
    HAS_DEPENDENCIES = False
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    print("è¯·å®‰è£…: pip install optuna xgboost scikit-learn pandas numpy")
    sys.exit(1)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from src.ml.xgboost_hyperparameter_optimization import (
        XGBoostHyperparameterOptimizer,
    )
    from src.ml.enhanced_feature_engineering import EnhancedFeatureEngineering

    HAS_PROJECT_MODULES = True
except ImportError:
    HAS_PROJECT_MODULES = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class OptunaHyperparameterTuner:
    """åŸºäº Optuna çš„ XGBoost è¶…å‚æ•°ä¼˜åŒ–å™¨."""

    def __init__(
        self,
        n_trials: int = 50,
        cv_folds: int = 5,
        random_state: int = 42,
        model_save_path: str = "models/football_prediction_v4_optuna.pkl",
    ):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨.

        Args:
            n_trials: è¯•éªŒæ¬¡æ•°
            cv_folds: äº¤å‰éªŒè¯æŠ˜æ•°
            random_state: éšæœºç§å­
            model_save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
        """
        self.n_trials = n_trials
        self.cv_folds = cv_folds
        self.random_state = random_state
        self.model_save_path = model_save_path

        # åˆå§‹åŒ–å˜é‡
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.study = None
        self.best_model = None
        self.best_params = None
        self.best_score = None
        self.feature_names = None
        self.label_encoder = None

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path("logs").mkdir(exist_ok=True, parents=True)
        Path("models").mkdir(exist_ok=True, parents=True)

        logger.info("ğŸš€ åˆå§‹åŒ– Optuna è¶…å‚æ•°ä¼˜åŒ–å™¨")
        logger.info(f"ğŸ“Š è¯•éªŒæ¬¡æ•°: {n_trials}, äº¤å‰éªŒè¯: {cv_folds}æŠ˜")

    def load_and_prepare_data(
        self, data_path: str = "data/advanced_features.csv"
    ) -> bool:
        """åŠ è½½å¹¶å‡†å¤‡è®­ç»ƒæ•°æ®.

        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„

        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸ“ åŠ è½½æ•°æ®é›†: {data_path}")

            # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(data_path):
                logger.error(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
                # å°è¯•å…¶ä»–å¯èƒ½çš„æ•°æ®æ–‡ä»¶
                alternative_paths = [
                    "data/processed_dataset.csv",
                    "data/football_matches.csv",
                    "data/matches_features.csv",
                ]
                for alt_path in alternative_paths:
                    if os.path.exists(alt_path):
                        data_path = alt_path
                        logger.info(f"ğŸ”„ ä½¿ç”¨æ›¿ä»£æ•°æ®æ–‡ä»¶: {data_path}")
                        break
                else:
                    logger.error("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ•°æ®æ–‡ä»¶")
                    return False

            # åŠ è½½æ•°æ®
            data = pd.read_csv(data_path)
            logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {data.shape}")

            # æ•°æ®é¢„å¤„ç†
            logger.info("ğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")

            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_columns = ["result"]  # ç›®æ ‡å˜é‡
            missing_columns = [
                col for col in required_columns if col not in data.columns
            ]
            if missing_columns:
                logger.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                logger.info(f"ğŸ“‹ å¯ç”¨åˆ—: {list(data.columns)}")
                return False

            # ç§»é™¤ä¸å¿…è¦çš„åˆ—
            columns_to_drop = [
                "match_id",
                "match_date",
                "home_team_id",
                "away_team_id",
                "league_id",
                "season",
                "home_score",
                "away_score",
                "goal_difference",
                "total_goals",
                "over_2_5_goals",
                "both_teams_score",
            ]
            columns_to_drop = [col for col in columns_to_drop if col in data.columns]
            data = data.drop(columns=columns_to_drop)

            # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
            X = data.drop("result", axis=1)
            y = data["result"]

            # å¤„ç†ç¼ºå¤±å€¼
            X = X.fillna(X.median())

            # ç¼–ç ç›®æ ‡å˜é‡
            if y.dtype == "object":
                self.label_encoder = LabelEncoder()
                y_encoded = self.label_encoder.fit_transform(y)
                logger.info(f"ğŸ·ï¸ ç›®æ ‡å˜é‡ç¼–ç : {self.label_encoder.classes_}")
            else:
                y_encoded = y
                self.label_encoder = None

            # ç‰¹å¾é€‰æ‹©ï¼šç§»é™¤å¸¸æ•°ç‰¹å¾
            constant_features = X.columns[X.nunique() <= 1].tolist()
            if constant_features:
                logger.info(f"ğŸ—‘ï¸ ç§»é™¤å¸¸æ•°ç‰¹å¾: {constant_features}")
                X = X.drop(columns=constant_features)

            # ç‰¹å¾ç¼©æ”¾
            scaler = StandardScaler()
            X_scaled = pd.DataFrame(
                scaler.fit_transform(X), columns=X.columns, index=X.index
            )

            # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X_scaled,
                y_encoded,
                test_size=0.2,
                random_state=self.random_state,
                stratify=y_encoded,
            )

            self.feature_names = list(X_scaled.columns)

            logger.info("ğŸ“Š æœ€ç»ˆæ•°æ®å½¢çŠ¶:")
            logger.info(f"   è®­ç»ƒé›†: {self.X_train.shape}")
            logger.info(f"   æµ‹è¯•é›†: {self.X_test.shape}")
            logger.info(f"   ç‰¹å¾æ•°é‡: {len(self.feature_names)}")

            # ç›®æ ‡å˜é‡åˆ†å¸ƒ
            unique, counts = np.unique(self.y_train, return_counts=True)
            logger.info("ğŸ¯ è®­ç»ƒé›†ç›®æ ‡å˜é‡åˆ†å¸ƒ:")
            for cls, count in zip(unique, counts, strict=False):
                percentage = count / len(self.y_train) * 100
                if self.label_encoder:
                    cls_name = self.label_encoder.inverse_transform([cls])[0]
                    logger.info(f"   {cls_name}: {count} ({percentage:.1f}%)")
                else:
                    logger.info(f"   ç±»åˆ« {cls}: {count} ({percentage:.1f}%)")

            return True

        except Exception:
            logger.error(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return False

    def objective(self, trial: optuna.Trial) -> float:
        """Optuna ç›®æ ‡å‡½æ•°.

        Args:
            trial: Optuna è¯•éªŒå¯¹è±¡

        Returns:
            float: éªŒè¯é›†å‡†ç¡®ç‡
        """
        # å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´
        param = {
            "objective": (
                "binary:logistic"
                if len(np.unique(self.y_train)) == 2
                else "multi:softprob"
            ),
            "eval_metric": "mlogloss",
            "random_state": self.random_state,
            "use_label_encoder": False,
            # ä¸»è¦è¶…å‚æ•°
            "max_depth": trial.suggest_int("max_depth", 3, 10),
            "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
            "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
            "subsample": trial.suggest_float("subsample", 0.6, 1.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
            # æ­£åˆ™åŒ–å‚æ•°
            "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 1.0),
            "reg_lambda": trial.suggest_float("reg_lambda", 0.0, 2.0),
            "min_child_weight": trial.suggest_float("min_child_weight", 1, 10),
            # å…¶ä»–å‚æ•°
            "gamma": trial.suggest_float("gamma", 0.0, 1.0),
            "max_leaves": trial.suggest_int("max_leaves", 0, 100),
        }

        # è®¾ç½®å¤šåˆ†ç±»å‚æ•°
        if len(np.unique(self.y_train)) > 2:
            param["num_class"] = len(np.unique(self.y_train))

        # äº¤å‰éªŒè¯
        cv = StratifiedKFold(
            n_splits=self.cv_folds, shuffle=True, random_state=self.random_state
        )
        cv_scores = []

        for train_idx, val_idx in cv.split(self.X_train, self.y_train):
            X_tr, X_val = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]
            y_tr, y_val = self.y_train[train_idx], self.y_train[val_idx]

            # è®­ç»ƒæ¨¡å‹
            model = xgb.XGBClassifier(**param)

            # æ—©åœ
            eval_set = [(X_val, y_val)]
            model.fit(
                X_tr, y_tr, eval_set=eval_set, early_stopping_rounds=50, verbose=False
            )

            # é¢„æµ‹å’Œè¯„ä¼°
            y_pred = model.predict(X_val)
            accuracy = accuracy_score(y_val, y_pred)
            cv_scores.append(accuracy)

        # è¿”å›å¹³å‡å‡†ç¡®ç‡
        mean_accuracy = np.mean(cv_scores)

        # è®°å½•ä¸­é—´ç»“æœ
        trial.report(mean_accuracy, step=0)

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä¸­æ–­ï¼ˆå‰ªæï¼‰
        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()

        return mean_accuracy

    def optimize(self) -> dict[str, Any]:
        """æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–.

        Returns:
            Dict: ä¼˜åŒ–ç»“æœ
        """
        if self.X_train is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ load_and_prepare_data() å‡†å¤‡æ•°æ®")

        logger.info("ğŸ¯ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")

        # åˆ›å»ºç ”ç©¶
        self.study = optuna.create_study(
            direction="maximize",
            sampler=TPESampler(seed=self.random_state),
            pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3),
        )

        # å®šä¹‰å›è°ƒå‡½æ•°
        def callback(study: optuna.Study, trial: optuna.Trial) -> None:
            if trial.number % 10 == 0 or trial.number == self.n_trials - 1:
                logger.info(
                    f"ğŸ“Š Trial {trial.number + 1}/{self.n_trials} - "
                    f"Best Score: {study.best_value:.4f} - "
                    f"Current Score: {trial.value if trial.value else 'N/A':.4f}"
                )

        # æ‰§è¡Œä¼˜åŒ–
        self.study.optimize(
            self.objective, n_trials=self.n_trials, callbacks=[callback]
        )

        # è·å–æœ€ä½³ç»“æœ
        self.best_params = self.study.best_params
        self.best_score = self.study.best_value

        logger.info("ğŸ‰ ä¼˜åŒ–å®Œæˆ!")
        logger.info(f"ğŸ† æœ€ä½³å‡†ç¡®ç‡: {self.best_score:.4f}")
        logger.info(f"âš™ï¸ æœ€ä½³å‚æ•°: {json.dumps(self.best_params, indent=2)}")

        # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        logger.info("ğŸ”§ ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
        best_params_full = self.best_params.copy()
        best_params_full.update(
            {
                "objective": (
                    "binary:logistic"
                    if len(np.unique(self.y_train)) == 2
                    else "multi:softprob"
                ),
                "eval_metric": "mlogloss",
                "random_state": self.random_state,
                "use_label_encoder": False,
            }
        )

        if len(np.unique(self.y_train)) > 2:
            best_params_full["num_class"] = len(np.unique(self.y_train))

        self.best_model = xgb.XGBClassifier(**best_params_full)

        # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        eval_set = [(self.X_test, self.y_test)]
        self.best_model.fit(
            self.X_train,
            self.y_train,
            eval_set=eval_set,
            early_stopping_rounds=100,
            verbose=False,
        )

        # è¯„ä¼°æ¨¡å‹
        train_score = accuracy_score(
            self.y_train, self.best_model.predict(self.X_train)
        )
        test_score = accuracy_score(self.y_test, self.best_model.predict(self.X_test))

        logger.info("ğŸ“Š æœ€ç»ˆæ¨¡å‹æ€§èƒ½:")
        logger.info(f"   è®­ç»ƒé›†å‡†ç¡®ç‡: {train_score:.4f}")
        logger.info(f"   æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.4f}")

        # ä¿å­˜ç»“æœ
        self.save_results()

        return {
            "best_params": self.best_params,
            "best_score": self.best_score,
            "train_accuracy": train_score,
            "test_accuracy": test_score,
            "n_trials": len(self.study.trials),
            "study_name": self.study.study_name,
        }

    def save_results(self) -> None:
        """ä¿å­˜ä¼˜åŒ–ç»“æœå’Œæ¨¡å‹."""
        try:
            # ä¿å­˜æ¨¡å‹
            with open(self.model_save_path, "wb") as f:
                pickle.dump(self.best_model, f)
            logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {self.model_save_path}")

            # ä¿å­˜ä¼˜åŒ–ç»“æœ
            results = {
                "best_params": self.best_params,
                "best_score": float(self.best_score),
                "n_trials": len(self.study.trials),
                "study_name": self.study.study_name,
                "feature_names": self.feature_names,
                "optimization_time": datetime.now().isoformat(),
                "label_encoder_classes": (
                    self.label_encoder.classes_.tolist() if self.label_encoder else None
                ),
            }

            results_path = self.model_save_path.replace(".pkl", "_results.json")
            with open(results_path, "w") as f:
                json.dump(results, f, indent=2)
            logger.info(f"ğŸ“„ ä¼˜åŒ–ç»“æœå·²ä¿å­˜: {results_path}")

            # ä¿å­˜ç ”ç©¶
            study_path = self.model_save_path.replace(".pkl", "_study.pkl")
            with open(study_path, "wb") as f:
                pickle.dump(self.study, f)
            logger.info(f"ğŸ”¬ Optuna ç ”ç©¶å·²ä¿å­˜: {study_path}")

        except Exception:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def generate_report(self) -> None:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š."""
        if not self.study:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç ”ç©¶æ¥ç”ŸæˆæŠ¥å‘Š")
            return

        try:
            logger.info("ğŸ“Š ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")

            # åŸºç¡€ç»Ÿè®¡
            logger.info("ğŸ“ˆ ä¼˜åŒ–ç»Ÿè®¡:")
            logger.info(f"   æ€»è¯•éªŒæ¬¡æ•°: {len(self.study.trials)}")
            logger.info(f"   æœ€ä½³å‡†ç¡®ç‡: {self.study.best_value:.4f}")
            completed_trials = len(
                [
                    t
                    for t in self.study.trials
                    if t.state == optuna.trial.TrialState.COMPLETE
                ]
            )
            logger.info(f"   æ”¹è¿›æ¬¡æ•°: {completed_trials}")

            # å‚æ•°é‡è¦æ€§
            try:
                importance = optuna.importance.get_param_importances(self.study)
                logger.info("ğŸ” å‚æ•°é‡è¦æ€§:")
                for param, imp in sorted(
                    importance.items(), key=lambda x: x[1], reverse=True
                ):
                    logger.info(f"   {param}: {imp:.4f}")
            except Exception:
                logger.warning(f"âš ï¸ æ— æ³•è®¡ç®—å‚æ•°é‡è¦æ€§: {e}")

            # æœ€ä½³è¯•éªŒè¯¦æƒ…
            best_trial = self.study.best_trial
            logger.info(f"ğŸ† æœ€ä½³è¯•éªŒ (Trial {best_trial.number}):")
            for param, value in best_trial.params.items():
                logger.info(f"   {param}: {value}")

            logger.info("ğŸ“‹ ä¼˜åŒ–è¿‡ç¨‹:")
            for _i, trial in enumerate(self.study.trials[:10]):  # æ˜¾ç¤ºå‰10ä¸ªè¯•éªŒ
                if trial.state == optuna.trial.TrialState.COMPLETE:
                    logger.info(f"   Trial {trial.number}: {trial.value:.4f}")
                elif trial.state == optuna.trial.TrialState.PRUNED:
                    logger.info(f"   Trial {trial.number}: Pruned")

            if len(self.study.trials) > 10:
                logger.info(f"   ... è¿˜æœ‰ {len(self.study.trials) - 10} ä¸ªè¯•éªŒ")

        except Exception:
            logger.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°."""
    logger.info("ğŸš€ å¼€å§‹ Optuna XGBoost è¶…å‚æ•°ä¼˜åŒ–")

    # æ£€æŸ¥ä¾èµ–
    if not HAS_DEPENDENCIES:
        logger.error(
            "âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œè¯·å®‰è£…: pip install optuna xgboost scikit-learn pandas numpy"
        )
        return

    # åˆ›å»ºä¼˜åŒ–å™¨
    tuner = OptunaHyperparameterTuner(
        n_trials=30,  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
        cv_folds=5,
        random_state=42,
    )

    # åŠ è½½æ•°æ®
    logger.info("ğŸ“ ç¬¬ä¸€æ­¥: åŠ è½½å’Œå‡†å¤‡æ•°æ®")
    if not tuner.load_and_prepare_data():
        logger.error("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        return

    # æ‰§è¡Œä¼˜åŒ–
    logger.info("ğŸ¯ ç¬¬äºŒæ­¥: æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–")
    try:
        results = tuner.optimize()

        # ç”ŸæˆæŠ¥å‘Š
        logger.info("ğŸ“Š ç¬¬ä¸‰æ­¥: ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š")
        tuner.generate_report()

        logger.info("ğŸ‰ Optuna è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
        logger.info(f"ğŸ“ˆ æœ€ä½³å‡†ç¡®ç‡: {results['best_score']:.4f}")
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {tuner.model_save_path}")

        # ä¸åŸºå‡†æ¨¡å‹æ¯”è¾ƒ
        baseline_accuracy = 0.5255  # åŸºå‡†å‡†ç¡®ç‡ 52.55%
        improvement = (results["best_score"] - baseline_accuracy) * 100
        logger.info(
            f"ğŸš€ å‡†ç¡®ç‡æå‡: {improvement:+.2f}% (ä» {baseline_accuracy:.2%} åˆ° {results['best_score']:.2%})"
        )

    except Exception:
        logger.error(f"âŒ ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
