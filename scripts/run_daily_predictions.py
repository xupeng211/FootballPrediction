#!/usr/bin/env python3
"""
æ¯æ—¥é¢„æµ‹è¿è¡Œè„šæœ¬
è‡ªåŠ¨ä¸ºå³å°†è¿›è¡Œçš„æ¯”èµ›ç”Ÿæˆé¢„æµ‹ç»“æœ

åŠŸèƒ½:
1. è·å–æœªæ¥3å¤©å†…çš„é¢„å®šæ¯”èµ›
2. åŠ¨æ€è®¡ç®—æ»šåŠ¨ç‰¹å¾
3. è°ƒç”¨æ¨ç†APIè¿›è¡Œé¢„æµ‹
4. ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“
5. ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š

ä½œè€…: Full Stack Automation Engineer
åˆ›å»ºæ—¶é—´: 2025-01-10
ç‰ˆæœ¬: 1.0.0 - Phase 4 Daily Automation
"""

import asyncio
import sys
import json
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import requests
from sqlalchemy import text

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.database.async_manager import get_db_session, initialize_database
from src.features.dynamic_rolling import get_features_for_upcoming_match
from src.inference.schemas import PredictionRequest
from src.core.config import get_settings

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DailyPredictionRunner:
    """æ¯æ—¥é¢„æµ‹è¿è¡Œå™¨"""

    def __init__(self, inference_api_url: str = "http://app:8000"):
        self.inference_api_url = inference_api_url.rstrip('/')
        self.settings = get_settings()
        self.session = requests.Session()
        self.session.headers.update({
            "Content-Type": "application/json",
            "Accept": "application/json"
        })

        # é¢„æµ‹ç»Ÿè®¡
        self.stats = {
            'total_matches': 0,
            'successful_predictions': 0,
            'failed_predictions': 0,
            'skipped_matches': 0,
            'prediction_distribution': {"Home": 0, "Draw": 0, "Away": 0}
        }

    async def run_daily_predictions(self, days_ahead: int = 3) -> Dict[str, Any]:
        """
        è¿è¡Œæ¯æ—¥é¢„æµ‹æµç¨‹

        Args:
            days_ahead: é¢„æµ‹æœªæ¥å‡ å¤©çš„æ¯”èµ›

        Returns:
            é¢„æµ‹ç»“æœç»Ÿè®¡
        """
        logger.info(f"ğŸš€ å¼€å§‹è¿è¡Œæ¯æ—¥é¢„æµ‹ (æœªæ¥ {days_ahead} å¤©)")

        try:
            # 1. è·å–å³å°†è¿›è¡Œçš„æ¯”èµ›
            upcoming_matches = await self._get_upcoming_matches(days_ahead)
            self.stats['total_matches'] = len(upcoming_matches)

            logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(upcoming_matches)} åœºå³å°†è¿›è¡Œçš„æ¯”èµ›")

            if not upcoming_matches:
                logger.info("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å³å°†è¿›è¡Œçš„æ¯”èµ›")
                return self._generate_report()

            # 2. ä¸ºæ¯åœºæ¯”èµ›ç”Ÿæˆé¢„æµ‹
            await self._process_matches_batch(upcoming_matches)

            # 3. ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report()

            logger.info("ğŸ‰ æ¯æ—¥é¢„æµ‹æµç¨‹å®Œæˆ!")
            return report

        except Exception as e:
            logger.error(f"âŒ æ¯æ—¥é¢„æµ‹æµç¨‹å¤±è´¥: {e}")
            self.stats['failed_predictions'] = self.stats['total_matches']
            return self._generate_report()

    async def _get_upcoming_matches(self, days_ahead: int) -> List[Dict[str, Any]]:
        """è·å–å³å°†è¿›è¡Œçš„æ¯”èµ›"""
        start_date = datetime.now()
        end_date = start_date + timedelta(days=days_ahead)

        sql = """
        SELECT
            m.id,
            m.home_team_id,
            m.away_team_id,
            m.home_team_name,
            m.away_team_name,
            m.match_date,
            m.league_id,
            m.status,
            -- æ£€æŸ¥æ˜¯å¦å·²æœ‰é¢„æµ‹
            CASE WHEN p.id IS NOT NULL THEN true ELSE false END as has_prediction
        FROM matches m
        LEFT JOIN match_predictions p ON m.id = p.match_id
            AND p.model_version = :model_version
            AND p.created_at >= CURRENT_DATE
        WHERE m.match_date BETWEEN :start_date AND :end_date
            AND m.status = 'scheduled'
        ORDER BY m.match_date ASC;
        """

        async with get_db_session() as session:
            result = await session.execute(text(sql), {
                "start_date": start_date,
                "end_date": end_date,
                "model_version": "v1.0.0"
            })

            matches = []
            for row in result.fetchall():
                matches.append({
                    'match_id': row.id,
                    'home_team_id': row.home_team_id,
                    'away_team_id': row.away_team_id,
                    'home_team_name': row.home_team_name,
                    'away_team_name': row.away_team_name,
                    'match_date': row.match_date,
                    'league_id': row.league_id,
                    'league_name': None,  # æ•°æ®åº“ä¸­æ²¡æœ‰è¿™ä¸ªå­—æ®µ
                    'status': row.status,
                    'has_prediction': row.has_prediction
                })

            return matches

    async def _process_matches_batch(self, matches: List[Dict[str, Any]]):
        """æ‰¹é‡å¤„ç†æ¯”èµ›é¢„æµ‹"""
        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç† {len(matches)} åœºæ¯”èµ›")

        async with get_db_session() as session:
            for i, match in enumerate(matches, 1):
                try:
                    logger.info(f"ğŸ“Š å¤„ç†ç¬¬ {i}/{len(matches)} åœºæ¯”èµ›: "
                               f"{match['home_team_name']} vs {match['away_team_name']}")

                    # è·³è¿‡å·²æœ‰é¢„æµ‹çš„æ¯”èµ›
                    if match.get('has_prediction'):
                        logger.info(f"   â­ï¸ è·³è¿‡ (å·²æœ‰ä»Šæ—¥é¢„æµ‹)")
                        self.stats['skipped_matches'] += 1
                        continue

                    # 1. è®¡ç®—åŠ¨æ€ç‰¹å¾
                    features = await get_features_for_upcoming_match(match['match_id'])
                    if not features.get('match_date'):
                        logger.warning(f"   âš ï¸ ç‰¹å¾è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¯”èµ›")
                        self.stats['failed_predictions'] += 1
                        continue

                    # 2. è°ƒç”¨æ¨ç†API
                    prediction_result = await self._call_inference_api(match, features)
                    if not prediction_result:
                        self.stats['failed_predictions'] += 1
                        continue

                    # 3. ä¿å­˜é¢„æµ‹ç»“æœ
                    await self._save_prediction(session, match, prediction_result)
                    self.stats['successful_predictions'] += 1

                    # æ›´æ–°ç»Ÿè®¡
                    prediction = prediction_result['prediction']
                    self.stats['prediction_distribution'][prediction] += 1

                    logger.info(f"   âœ… é¢„æµ‹æˆåŠŸ: {prediction} "
                               f"(ç½®ä¿¡åº¦: {prediction_result['confidence']:.3f})")

                except Exception as e:
                    logger.error(f"   âŒ å¤„ç†æ¯”èµ›å¤±è´¥: {e}")
                    self.stats['failed_predictions'] += 1

            # æäº¤æ‰€æœ‰é¢„æµ‹
            await session.commit()

    async def _call_inference_api(
        self,
        match: Dict[str, Any],
        features: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨æ¨ç†APIè¿›è¡Œé¢„æµ‹"""
        try:
            # æ„å»ºé¢„æµ‹è¯·æ±‚
            prediction_request = {
                "match_id": int(match['match_id']) if isinstance(match['match_id'], (int, str)) else 12345,  # ç¡®ä¿æ˜¯æ•°å­—ID
                "home_team_name": match['home_team_name'],
                "away_team_name": match['away_team_name'],
                "match_date": features['match_date'],
                "home_score": 0,  # å³å°†è¿›è¡Œçš„æ¯”èµ›ï¼Œæ¯”åˆ†ä¸º0
                "away_score": 0,
                "home_xg": features.get('home_last_5_avg_xg_for', 0),
                "away_xg": features.get('away_last_5_avg_xg_for', 0),
                "home_total_shots": int(features.get('home_last_5_avg_goals_scored', 0) * 10),
                "away_total_shots": int(features.get('away_last_5_avg_goals_scored', 0) * 10),
                "home_shots_on_target": int(features.get('home_last_5_avg_goals_scored', 0) * 4),
                "away_shots_on_target": int(features.get('away_last_5_avg_goals_scored', 0) * 4),
                "league_id": match['league_id'],
                "league_name": match['league_name'],
                "stats_json": {
                    "feature_source": features['feature_source'],
                    "home_matches_used": features['home_team_matches_used'],
                    "away_matches_used": features['away_team_matches_used']
                }
            }

            # è°ƒç”¨API
            response = self.session.post(
                f"{self.inference_api_url}/api/v1/inference/predict",
                json=prediction_request,
                timeout=30
            )

            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"   âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.error(f"   âŒ è°ƒç”¨æ¨ç†APIå¤±è´¥: {e}")
            return None

    async def _save_prediction(
        self,
        session,
        match: Dict[str, Any],
        prediction_result: Dict[str, Any]
    ):
        """ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“"""
        sql = """
        INSERT INTO match_predictions (
            match_id, prediction, confidence, probabilities,
            model_version, feature_count, missing_features,
            processing_time_ms, prediction_source
        ) VALUES (
            :match_id, :prediction, :confidence, :probabilities,
            :model_version, :feature_count, :missing_features,
            :processing_time_ms, :prediction_source
        );
        """

        params = {
            "match_id": match['match_id'],
            "prediction": prediction_result['prediction'],
            "confidence": prediction_result['confidence'],
            "probabilities": json.dumps(prediction_result['probabilities']),
            "model_version": prediction_result.get('model_version', 'v1.0.0'),
            "feature_count": prediction_result.get('feature_count', 0),
            "missing_features": prediction_result.get('missing_features', 0),
            "processing_time_ms": prediction_result.get('processing_time_ms'),
            "prediction_source": "daily_automation"
        }

        await session.execute(text(sql), params)

    def _generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
        total_processed = self.stats['successful_predictions'] + self.stats['failed_predictions']
        success_rate = (self.stats['successful_predictions'] / total_processed * 100) if total_processed > 0 else 0

        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_matches_found": self.stats['total_matches'],
                "matches_processed": total_processed,
                "successful_predictions": self.stats['successful_predictions'],
                "failed_predictions": self.stats['failed_predictions'],
                "skipped_matches": self.stats['skipped_matches'],
                "success_rate": round(success_rate, 2)
            },
            "prediction_distribution": self.stats['prediction_distribution'],
            "model_version": "v1.0.0",
            "automation_source": "daily_runner"
        }

        return report

    def print_report(self, report: Dict[str, Any]):
        """æ‰“å°é¢„æµ‹æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ¯æ—¥é¢„æµ‹æŠ¥å‘Š")
        print("=" * 60)

        summary = report['summary']
        print(f"\nğŸ“ˆ é¢„æµ‹ç»Ÿè®¡:")
        print(f"   å‘ç°æ¯”èµ›æ€»æ•°: {summary['total_matches_found']}")
        print(f"   å¤„ç†æ¯”èµ›æ•°: {summary['matches_processed']}")
        print(f"   âœ… æˆåŠŸé¢„æµ‹: {summary['successful_predictions']}")
        print(f"   âŒ å¤±è´¥é¢„æµ‹: {summary['failed_predictions']}")
        print(f"   â­ï¸ è·³è¿‡æ¯”èµ›: {summary['skipped_matches']}")
        print(f"   ğŸ“Š æˆåŠŸç‡: {summary['success_rate']}%")

        dist = report['prediction_distribution']
        if sum(dist.values()) > 0:
            print(f"\nğŸ¯ é¢„æµ‹åˆ†å¸ƒ:")
            print(f"   ä¸»èƒœ (Home): {dist['Home']}")
            print(f"   å¹³å±€ (Draw): {dist['Draw']}")
            print(f"   å®¢èƒœ (Away): {dist['Away']}")

        print(f"\nğŸ¤– æ¨¡å‹ä¿¡æ¯:")
        print(f"   ç‰ˆæœ¬: {report['model_version']}")
        print(f"   è‡ªåŠ¨åŒ–æ¥æº: {report['automation_source']}")
        print(f"   æŠ¥å‘Šæ—¶é—´: {report['timestamp']}")

        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸŒ… å¯åŠ¨æ¯æ—¥é¢„æµ‹è‡ªåŠ¨åŒ–ç³»ç»Ÿ")

    try:
        # 0. åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨...")
        initialize_database()

        # 1. æ£€æŸ¥æ¨ç†æœåŠ¡çŠ¶æ€
        runner = DailyPredictionRunner()

        # ç®€å•çš„å¥åº·æ£€æŸ¥
        try:
            response = requests.get(f"{runner.inference_api_url}/health", timeout=5)
            if response.status_code != 200:
                logger.error(f"âŒ æ¨ç†æœåŠ¡ä¸å¯ç”¨: {runner.inference_api_url}")
                return False
        except Exception as e:
            logger.error(f"âŒ æ— æ³•è¿æ¥åˆ°æ¨ç†æœåŠ¡: {e}")
            return False

        logger.info("âœ… æ¨ç†æœåŠ¡çŠ¶æ€æ­£å¸¸")

        # è¿è¡Œé¢„æµ‹æµç¨‹
        report = await runner.run_daily_predictions(days_ahead=3)

        # æ‰“å°æŠ¥å‘Š
        runner.print_report(report)

        # è¿”å›æˆåŠŸçŠ¶æ€
        success = report['summary']['success_rate'] >= 80  # 80%ä»¥ä¸ŠæˆåŠŸç‡ç®—æˆåŠŸ
        return success

    except KeyboardInterrupt:
        logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return False
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)