#!/usr/bin/env python3
"""
FBrefæ•°æ®è´¨æ£€è„šæœ¬
Data QA Specialist: æ•°æ®æ·±åº¦éªŒè¯ä¸“å®¶

Purpose: æ£€æŸ¥FBrefæ•°æ®é‡‡é›†æ·±åº¦ï¼Œç¡®ä¿Match Reporté“¾æ¥å®Œæ•´æ€§
"""

import asyncio
import sys
import json
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format="ğŸ” %(asctime)s [%(levelname)8s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


class FBrefDataQA:
    """FBrefæ•°æ®è´¨æ£€å‘˜"""

    def __init__(self):
        self.database_url = "postgresql://postgres:postgres-dev-password@localhost:5432/football_prediction"
        self.engine = None
        self.conn = None

    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            from sqlalchemy import create_engine, text

            self.engine = create_engine(self.database_url)
            self.conn = self.engine.connect()
            self.text = text  # ä¿å­˜textå‡½æ•°
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False

    def get_latest_fbref_match(self) -> Optional[dict[str, Any]]:
        """è·å–æœ€æ–°å…¥åº“çš„FBrefæ¯”èµ›æ•°æ®"""
        try:
            query = self.text(
                """
                SELECT m.id, m.match_date, m.home_score, m.away_score,
                       m.stats, m.match_metadata, m.data_source, m.season,
                       m.created_at,
                       ht.name as home_team, at.name as away_team
                FROM matches m
                LEFT JOIN teams ht ON m.home_team_id = ht.id
                LEFT JOIN teams at ON m.away_team_id = at.id
                WHERE m.data_source = 'fbref'
                ORDER BY m.created_at DESC
                LIMIT 1
            """
            )

            result = self.conn.execute(query)
            row = result.fetchone()

            if row:
                return {
                    "id": row[0],
                    "match_date": row[1],
                    "home_score": row[2],
                    "away_score": row[3],
                    "stats": row[4],
                    "match_metadata": row[5],
                    "data_source": row[6],
                    "season": row[7],
                    "created_at": row[8],
                    "home_team": row[9],
                    "away_team": row[10],
                }
            return None

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æœ€æ–°æ¯”èµ›å¤±è´¥: {e}")
            return None

    def analyze_xg_data(self, stats_data: dict) -> dict[str, Any]:
        """åˆ†æxGæ•°æ®è´¨é‡"""
        if not stats_data:
            return {"status": "missing", "details": "statså­—æ®µä¸ºç©º"}

        xg_analysis = {
            "status": "available",
            "has_xg_field": "xg" in stats_data,
            "xg_keys": [],
            "xg_content": {},
        }

        # æ£€æŸ¥xgå­—æ®µ
        if "xg" in stats_data:
            xg_data = stats_data["xg"]
            xg_analysis["xg_content"] = xg_data
            xg_analysis["xg_keys"] = (
                list(xg_data.keys()) if isinstance(xg_data, dict) else []
            )

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»å®¢é˜ŸxG
            has_home_xg = any(
                "home_xg" in str(key).lower() for key in xg_analysis["xg_keys"]
            )
            has_away_xg = any(
                "away_xg" in str(key).lower() for key in xg_analysis["xg_keys"]
            )
            xg_analysis["has_home_away_xg"] = has_home_xg and has_away_xg

            # éªŒè¯xGæ•°æ®ç±»å‹
            xg_analysis["xg_types"] = {}
            for key, value in xg_data.items():
                xg_analysis["xg_types"][key] = type(value).__name__

        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–xGç›¸å…³å­—æ®µ
        other_xg_keys = [key for key in stats_data.keys() if "xg" in key.lower()]
        xg_analysis["all_xg_keys"] = other_xg_keys

        return xg_analysis

    def analyze_raw_data_depth(self, raw_data: dict) -> dict[str, Any]:
        """åˆ†æåŸå§‹æ•°æ®æ·±åº¦ï¼Œç‰¹åˆ«å…³æ³¨Match Reporté“¾æ¥"""
        if not raw_data:
            return {"status": "missing", "details": "raw_dataå­—æ®µä¸ºç©º"}

        depth_analysis = {
            "status": "available",
            "total_fields": len(raw_data),
            "field_names": list(raw_data.keys()),
            "has_url_fields": [],
            "url_content": {},
            "potential_match_report_urls": [],
        }

        # æ£€æŸ¥URLç›¸å…³å­—æ®µ
        url_keywords = ["url", "link", "report", "match", "detail", "stats"]
        for field_name, field_value in raw_data.items():
            if any(keyword in field_name.lower() for keyword in url_keywords):
                depth_analysis["has_url_fields"].append(field_name)
                depth_analysis["url_content"][field_name] = str(field_value)

                # ç‰¹åˆ«æ£€æŸ¥æ˜¯å¦æ˜¯Match Reporté“¾æ¥
                if "match" in field_name.lower() or "report" in field_name.lower():
                    depth_analysis["potential_match_report_urls"].append(
                        {
                            "field": field_name,
                            "value": str(field_value),
                            "contains_fbref": "fbref" in str(field_value).lower(),
                        }
                    )

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ—ååŒ…å«ç›¸å…³é“¾æ¥ä¿¡æ¯
        link_column_names = [
            col
            for col in depth_analysis["field_names"]
            if any(
                keyword in col.lower() for keyword in url_keywords + ["href", "link"]
            )
        ]
        depth_analysis["link_column_names"] = link_column_names

        return depth_analysis

    def analyze_metadata_depth(self, metadata: dict) -> dict[str, Any]:
        """åˆ†æmetadataæ·±åº¦"""
        if not metadata:
            return {"status": "missing", "details": "metadataå­—æ®µä¸ºç©º"}

        meta_analysis = {
            "status": "available",
            "total_fields": len(metadata),
            "field_names": list(metadata.keys()),
            "has_urls": False,
            "url_fields": {},
            "potential_match_report_urls": [],
        }

        # æ£€æŸ¥metadataä¸­çš„URL
        for field_name, field_value in metadata.items():
            if isinstance(field_value, str) and (
                "http" in field_value or "fbref" in field_value
            ):
                meta_analysis["has_urls"] = True
                meta_analysis["url_fields"][field_name] = field_value

                if "match" in field_name.lower() or "report" in field_name.lower():
                    meta_analysis["potential_match_report_urls"].append(
                        {"field": field_name, "value": field_value}
                    )

        return meta_analysis

    def generate_qa_report(self, match_data: dict) -> str:
        """ç”Ÿæˆæ•°æ®è´¨æ£€æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       FBrefæ•°æ®è´¨é‡è´¨æ£€æŠ¥å‘Š                              â•‘
â•‘                     Data QA Specialist: æ•°æ®æ·±åº¦éªŒè¯                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ• è´¨æ£€æ—¶é—´: {timestamp}
ğŸ¯ æ£€æŸ¥å¯¹è±¡: æœ€æ–°å…¥åº“çš„FBrefæ¯”èµ›æ•°æ®

â”Œâ”€ ğŸ“Š åŸºç¡€æ¯”èµ›ä¿¡æ¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        # åŸºç¡€ä¿¡æ¯å±•ç¤º
        report += f"""
â”‚ æ¯”èµ›ID: {match_data['id']}
â”‚ ä¸»é˜Ÿ: {match_data['home_team']}
â”‚ å®¢é˜Ÿ: {match_data['away_team']}"""

        if (
            match_data["home_score"] is not None
            and match_data["away_score"] is not None
        ):
            report += f"""
â”‚ æ¯”åˆ†: {match_data['home_score']}-{match_data['away_score']}"""
        else:
            report += """
â”‚ æ¯”åˆ†: æœªå¼€å§‹"""

        report += f"""
â”‚ æ¯”èµ›æ—¥æœŸ: {match_data['match_date']}
â”‚ èµ›å­£: {match_data['season']}
â”‚ æ•°æ®æ¥æº: {match_data['data_source']}
â”‚ å…¥åº“æ—¶é—´: {match_data['created_at']}"""

        # xGæ•°æ®åˆ†æ
        xg_analysis = self.analyze_xg_data(match_data["stats"])
        report += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ“ˆ xGæ•°æ®æ·±åº¦åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if xg_analysis["status"] == "available":
            report += f"""
â”‚ xGæ•°æ®çŠ¶æ€: âœ… å­˜åœ¨
â”‚ xGä¸»å­—æ®µ: {'å­˜åœ¨' if xg_analysis['has_xg_field'] else 'ç¼ºå¤±'}
â”‚ xGå®Œæ•´åº¦: {'å®Œæ•´' if xg_analysis.get('has_home_away_xg') else 'éƒ¨åˆ†'}"""

            if xg_analysis["xg_keys"]:
                report += f"""
â”‚ xGæ•°æ®å­—æ®µ: {', '.join(xg_analysis['xg_keys'][:5])}"""

                # æ˜¾ç¤ºxGæ•°æ®ç±»å‹
                for key, value in xg_analysis["xg_types"].items():
                    report += f"""
â”‚   {key}: {value}"""

            if "all_xg_keys" in xg_analysis and xg_analysis["all_xg_keys"]:
                report += f"""
â”‚ æ‰€æœ‰xGç›¸å…³å­—æ®µ: {', '.join(xg_analysis['all_xg_keys'])}"""

        else:
            report += f"""
â”‚ xGæ•°æ®çŠ¶æ€: âŒ ç¼ºå¤±
â”‚ è¯¦æƒ…: {xg_analysis.get('details', 'æœªçŸ¥é”™è¯¯')}"""

        # åŸå§‹æ•°æ®æ·±åº¦åˆ†æ
        stats_data = match_data.get("stats", {})
        raw_data = (
            stats_data.get("raw_data", {}) if isinstance(stats_data, dict) else {}
        )
        metadata = match_data.get("match_metadata", {})

        raw_analysis = self.analyze_raw_data_depth(raw_data)
        report += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ”— é“¾æ¥æ·±åº¦åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if raw_analysis["status"] == "available":
            report += f"""
â”‚ åŸå§‹æ•°æ®å­—æ®µæ•°: {raw_analysis['total_fields']}
â”‚ URLç›¸å…³å­—æ®µæ•°: {len(raw_analysis['has_url_fields'])}"""

            if raw_analysis["has_url_fields"]:
                report += f"""
â”‚ URLå­—æ®µåˆ—è¡¨: {', '.join(raw_analysis['has_url_fields'])}"""

                for field, value in raw_analysis["url_content"].items():
                    preview = value[:100] + "..." if len(value) > 100 else value
                    report += f"""
â”‚   {field}: {preview}"""

            if raw_analysis["potential_match_report_urls"]:
                report += f"""
â”‚ âš ï¸  å‘ç°å¯èƒ½çš„Match Report URL: {len(raw_analysis['potential_match_report_urls'])} ä¸ª"""

                for url_info in raw_analysis["potential_match_report_urls"][:3]:
                    fbref_marker = "âœ…" if url_info["contains_fbref"] else "âŒ"
                    report += f"""
â”‚   {fbref_marker} {url_info['field']}: {url_info['value'][:80]}..."""

            if raw_analysis["link_column_names"]:
                report += f"""
â”‚ å¯èƒ½çš„é“¾æ¥åˆ—å: {', '.join(raw_analysis['link_column_names'])}"""

            if (
                not raw_analysis["has_url_fields"]
                and not raw_analysis["link_column_names"]
            ):
                report += """
â”‚ ğŸ” å»ºè®®æ£€æŸ¥å­—æ®µ: date, score, home, away ä¹‹å¤–çš„å…¶ä»–åˆ—"""
        else:
            report += f"""
â”‚ åŸå§‹æ•°æ®çŠ¶æ€: âŒ ç¼ºå¤±
â”‚ è¯¦æƒ…: {raw_analysis.get('details', 'æœªçŸ¥é”™è¯¯')}"""

        # metadataæ·±åº¦åˆ†æ
        meta_analysis = self.analyze_metadata_depth(metadata)
        report += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ“‹ Metadataæ·±åº¦åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if meta_analysis["status"] == "available":
            report += f"""
â”‚ Metadataå­—æ®µæ•°: {meta_analysis['total_fields']}
â”‚ åŒ…å«URL: {'æ˜¯' if meta_analysis['has_urls'] else 'å¦'}"""

            if meta_analysis["has_urls"]:
                report += f"""
â”‚ URLå­—æ®µæ•°: {len(meta_analysis['url_fields'])}"""

                for field, value in meta_analysis["url_fields"].items():
                    preview = value[:80] + "..." if len(value) > 80 else value
                    report += f"""
â”‚   {field}: {preview}"""

            if meta_analysis["potential_match_report_urls"]:
                report += f"""
â”‚ âš ï¸  å‘ç°å¯èƒ½çš„Match Report URL: {len(meta_analysis['potential_match_report_urls'])} ä¸ª"""

        else:
            report += f"""
â”‚ MetadataçŠ¶æ€: âŒ ç¼ºå¤±
â”‚ è¯¦æƒ…: {meta_analysis.get('details', 'æœªçŸ¥é”™è¯¯')}"""

        # ç”Ÿæˆå»ºè®®
        report += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ¯ è´¨æ£€ç»“è®ºä¸å»ºè®® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        conclusions = []
        recommendations = []

        # xGæ•°æ®è¯„ä¼°
        if xg_analysis["status"] == "available":
            if xg_analysis.get("has_home_away_xg"):
                conclusions.append("âœ… xGæ•°æ®å®Œæ•´æ€§é«˜")
            else:
                conclusions.append("âš ï¸ xGæ•°æ®éƒ¨åˆ†å®Œæ•´")
                recommendations.append("ğŸ”§ å»ºè®®è¡¥å……xGæ•°æ®æå–é€»è¾‘")
        else:
            conclusions.append("âŒ xGæ•°æ®ç¼ºå¤±")
            recommendations.append("ğŸš¨ ç«‹å³ä¿®å¤xGæ•°æ®é‡‡é›†")

        # æ·±åº¦é“¾æ¥è¯„ä¼°
        has_match_report_urls = (
            len(raw_analysis.get("potential_match_report_urls", [])) > 0
            or len(meta_analysis.get("potential_match_report_urls", [])) > 0
        )

        if has_match_report_urls:
            conclusions.append("âœ… å‘ç°Match Reporté“¾æ¥")
            recommendations.append("ğŸ‰ å¯åŸºäºè¿™äº›é“¾æ¥è¿›è¡Œæ·±åº¦é‡‡é›†")
        else:
            conclusions.append("âŒ æœªå‘ç°Match Reporté“¾æ¥")
            recommendations.append("âš ï¸ **é‡å¤§é£é™©**: éœ€è¦ç«‹å³ä¿®å¤é‡‡é›†å™¨")
            recommendations.append("ğŸ”§ å»ºè®®æ·»åŠ Match Reportå­—æ®µæå–å’Œå­˜å‚¨")
            recommendations.append("ğŸ”— çƒ­ä¿®å¤æ–¹æ¡ˆ: ä¿®æ”¹_clean_schedule_dataæ–¹æ³•")

        # æ•°æ®å®Œæ•´æ€§è¯„ä¼°
        if raw_analysis["total_fields"] >= 10:
            conclusions.append("âœ… åŸå§‹æ•°æ®ç»´åº¦ä¸°å¯Œ")
        else:
            conclusions.append("âš ï¸ åŸå§‹æ•°æ®ç»´åº¦æœ‰é™")
            recommendations.append("ğŸ“Š å»ºè®®å¢åŠ æ›´å¤šå­—æ®µé‡‡é›†")

        report += f"â”‚ è´¨æ£€ç»“è®º: {'; '.join(conclusions)}\nâ”‚"

        for rec in recommendations:
            report += f"â”‚ {rec}\n"

        report += f"""â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Šè´¨æ£€å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ”„å»ºè®®ä¸‹æ¬¡è´¨æ£€: {(datetime.now() + timedelta(hours=6)).strftime('%Y-%m-%d %H:%M:%S')}
"""

        return report

    def run_quality_check(self) -> bool:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®è´¨æ£€"""
        logger.info("ğŸ” å¼€å§‹FBrefæ•°æ®è´¨é‡è´¨æ£€")

        if not self.connect_database():
            logger.error("ğŸ’¥ æ— æ³•è¿æ¥æ•°æ®åº“ï¼Œè´¨æ£€å¤±è´¥")
            return False

        # è·å–æœ€æ–°FBrefæ¯”èµ›æ•°æ®
        match_data = self.get_latest_fbref_match()

        if not match_data:
            logger.error("ğŸ’¥ æ•°æ®åº“ä¸­æ— FBrefæ¯”èµ›æ•°æ®")
            return False

        logger.info(
            f"ğŸ“Š æ£€æŸ¥æ¯”èµ›: {match_data['home_team']} vs {match_data['away_team']}"
        )

        # ç”Ÿæˆè´¨æ£€æŠ¥å‘Š
        report = self.generate_qa_report(match_data)
        print(report)

        # ä¿å­˜æŠ¥å‘Š
        report_file = (
            Path(__file__).parent
            / "logs"
            / f'fbref_qa_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
        )
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)

        logger.info(f"ğŸ“‹ è´¨æ£€æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        # ç®€å•çš„å¥åº·è¯„åˆ†
        stats_data = match_data.get("stats", {})
        raw_data = (
            stats_data.get("raw_data", {}) if isinstance(stats_data, dict) else {}
        )

        has_xg = "xg" in stats_data
        has_urls = any(
            "url" in str(key).lower() or "link" in str(key).lower()
            for key in raw_data.keys()
        )

        if has_xg and has_urls:
            logger.info("ğŸ‰ æ•°æ®è´¨é‡è¯„ä¼°: ä¼˜ç§€ (A+)")
            return True
        elif has_xg or has_urls:
            logger.info("ğŸ“ˆ æ•°æ®è´¨é‡è¯„ä¼°: è‰¯å¥½ (B)")
            return True
        else:
            logger.warning("âš ï¸ æ•°æ®è´¨é‡è¯„ä¼°: éœ€è¦æ”¹è¿› (C)")
            return False

    def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
        if self.engine:
            self.engine.dispose()
            logger.info("âœ… æ•°æ®åº“å¼•æ“å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    qa = FBrefDataQA()

    try:
        success = qa.run_quality_check()

        logger.info(f"ğŸ¯ è´¨æ£€å®Œæˆ: {'æˆåŠŸ' if success else 'éœ€è¦æ”¹è¿›'}")
        return 0 if success else 1

    except Exception as e:
        logger.error(f"ğŸ’¥ è´¨æ£€è¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        return 1
    finally:
        qa.close_connection()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
