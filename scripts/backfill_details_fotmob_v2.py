#!/usr/bin/env python3
"""
FotMob L2 æ·±åº¦æ•°æ®é‡‡é›†è„šæœ¬ V2.0

ç³»ç»Ÿé›†æˆæ¶æ„:
- The Bridge (FotmobMatchMatcher) + The Harvest (FotmobDetailsCollector)
- æ›¿æ¢æ—§çš„ Playwright æ–¹æ¡ˆï¼Œä½¿ç”¨é«˜æ•ˆçš„ Web API

ä½œè€…: ç³»ç»Ÿé›†æˆæ¶æ„å¸ˆ
ç‰ˆæœ¬: 2.0.0
æ—¥æœŸ: 2024-12-04
"""

import asyncio
import logging
import sys
import os
import random
import time
from datetime import datetime, timedelta
import json
from typing import Optional, Dict, Any, List
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/fotmob_l2_v2.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from utils.fotmob_match_matcher import FotmobMatchMatcher
# ğŸŒ é™ç»´æ‰“å‡»ï¼šä½¿ç”¨ Playwright æµè§ˆå™¨é‡‡é›†å™¨
from data.collectors.fotmob_browser import FotmobBrowserScraper
from database.async_manager import get_db_session, initialize_database
from sqlalchemy import text


# ==================== çˆ¬è™«ä¼˜åŒ–å·¥å…·å‡½æ•° ====================

def wait_random(min_sec: float = 15.0, max_sec: float = 35.0) -> None:
    """
    éšæœºç­‰å¾…æ—¶é—´ï¼Œæ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º

    Args:
        min_sec: æœ€å°ç­‰å¾…ç§’æ•°
        max_sec: æœ€å¤§ç­‰å¾…ç§’æ•°
    """
    wait_time = random.uniform(min_sec, max_sec)
    logger.info(f"â±ï¸  éšèº«ç­‰å¾…: {wait_time:.2f} ç§’ (æ¨¡æ‹Ÿäººç±»è¡Œä¸º)")
    time.sleep(wait_time)


async def exponential_backoff_request(
    request_func,
    max_retries: int = 3,
    base_delay: float = 60.0,
    max_delay: float = 300.0,
    *args, **kwargs
) -> Any:
    """
    æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶ï¼Œå¤„ç† 429/403 é”™è¯¯

    Args:
        request_func: è¦é‡è¯•çš„è¯·æ±‚å‡½æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        max_delay: æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        *args, **kwargs: ä¼ é€’ç»™è¯·æ±‚å‡½æ•°çš„å‚æ•°

    Returns:
        è¯·æ±‚ç»“æœæˆ– Noneï¼ˆæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼‰
    """
    for attempt in range(max_retries + 1):
        try:
            result = await request_func(*args, **kwargs)
            if attempt > 0:
                logger.info(f"ğŸ”„ é‡è¯•æˆåŠŸ (ç¬¬ {attempt} æ¬¡é‡è¯•)")
            return result

        except Exception as e:
            error_msg = str(e).lower()

            # æ£€æŸ¥æ˜¯å¦æ˜¯é™æµæˆ–ç¦æ­¢è®¿é—®é”™è¯¯
            if any(code in error_msg for code in ['429', 'too many requests', '403', 'forbidden']):
                if attempt < max_retries:
                    # æŒ‡æ•°é€€é¿è®¡ç®—å»¶è¿Ÿ
                    delay = min(base_delay * (2 ** attempt), max_delay)
                    jitter = random.uniform(0.8, 1.2)  # æ·»åŠ  20% çš„éšæœºæŠ–åŠ¨
                    final_delay = delay * jitter

                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ°é™æµ/ç¦æ­¢è®¿é—®ï¼Œ{final_delay:.1f}ç§’åé‡è¯• (ç¬¬ {attempt + 1}/{max_retries + 1} æ¬¡)")
                    await asyncio.sleep(final_delay)
                    continue
                else:
                    logger.error(f"ğŸš« è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries + 1})ï¼Œæ”¾å¼ƒè¯·æ±‚")
                    return None
            else:
                # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡ºï¼Œä¸è¿›è¡Œé‡è¯•
                raise e

    return None


class FotMobL2CollectorV2:
    """
    FotMob L2 æ·±åº¦æ•°æ®é‡‡é›†å™¨ V2.0

    æ¶æ„æ¨¡å¼: Bridge (åŒ¹é…å™¨) + Harvest (é‡‡é›†å™¨) + Save (å­˜å‚¨å™¨)
    """

    def __init__(self, similarity_threshold: float = 70.0):
        """
        åˆå§‹åŒ– L2 é‡‡é›†å™¨

        Args:
            similarity_threshold: åŒ¹é…ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.logger.info("ğŸš€ åˆå§‹åŒ– L2 é‡‡é›†å™¨ç»„ä»¶...")
        self.logger.info("ğŸŒ é™ç»´æ‰“å‡»ï¼šä½¿ç”¨ Playwright æµè§ˆå™¨é‡‡é›†å™¨")
        self.matcher = FotmobMatchMatcher(similarity_threshold=similarity_threshold)
        # âœ… æµè§ˆå™¨é‡‡é›†å™¨å°†åœ¨è¿è¡Œæ—¶åŠ¨æ€åˆ›å»ºï¼Œé¿å…èµ„æºæµªè´¹

        # åˆå§‹åŒ–æ•°æ®åº“
        self.logger.info("ğŸ“¡ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        initialize_database()
        self.logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å®Œæˆ")

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "processed": 0,
            "matched": 0,
            "collected": 0,
            "saved": 0,
            "failed_match": 0,
            "failed_collection": 0,
            "failed_save": 0,
            "start_time": datetime.now()
        }

        self.logger.info("âœ… L2 é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")

    async def run_backfill_pipeline(self, limit: Optional[int] = None) -> dict[str, Any]:
        """
        è¿è¡Œ L2 æ•°æ®å›å¡«ç®¡é“

        Args:
            limit: å¤„ç†è®°å½•æ•°é‡é™åˆ¶ï¼ˆç”¨äºæµ‹è¯•ï¼‰

        Returns:
            å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        self.logger.info("ğŸ¯ å¯åŠ¨ L2 æ·±åº¦æ•°æ®å›å¡«ç®¡é“...")

        try:
            # Step 1: ä»æ•°æ®åº“è¯»å–å¾…å¤„ç†è®°å½•
            partial_records = await self._get_partial_records(limit)

            if not partial_records:
                self.logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ°å¾…å¤„ç†çš„è®°å½•")
                return self._generate_final_stats()

            self.logger.info(f"ğŸ“Š æ‰¾åˆ° {len(partial_records)} æ¡å¾…å¤„ç†è®°å½•")

            # Step 2: å¾ªç¯å¤„ç†æ¯æ¡è®°å½•
            for i, record in enumerate(partial_records, 1):
                try:
                    await self._process_single_record(record, i, len(partial_records))

                    # é£æ§ï¼šæ¯å¤„ç†ä¸€æ¡è®°å½•ï¼Œä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´ï¼ˆæµè§ˆå™¨æ“ä½œè¾ƒæ…¢ï¼‰
                    wait_seconds = random.uniform(8.0, 15.0)  # ğŸŒ é™ç»´æ‰“å‡»ï¼šæ›´é•¿çš„æµè§ˆå™¨ç­‰å¾…æ—¶é—´
                    logger.info(f"â±ï¸  æµè§ˆå™¨ç­‰å¾…: {wait_seconds:.2f} ç§’ (é™ç»´æ‰“å‡»æ¨¡å¼)")
                    await asyncio.sleep(wait_seconds)

                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†è®°å½• {record.get('id', 'unknown')} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    self.stats["failed_save"] += 1
                    continue

            # Step 3: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            final_stats = self._generate_final_stats()
            self.logger.info("ğŸ‰ L2 æ·±åº¦æ•°æ®å›å¡«å®Œæˆ!")
            self._log_final_stats(final_stats)

            return final_stats

        except Exception as e:
            self.logger.error(f"ğŸš¨ L2 ç®¡é“è¿è¡Œå¤±è´¥: {str(e)}")
            raise

    async def _get_partial_records(self, limit: Optional[int] = None) -> list[dict[str, Any]]:
        """
        ä»æ•°æ®åº“è·å– data_completeness='partial' çš„è®°å½•

        Args:
            limit: é™åˆ¶è¿”å›è®°å½•æ•°é‡

        Returns:
            å¾…å¤„ç†è®°å½•åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢ - ç»ˆæè°ƒåº¦ç­–ç•¥ï¼šåªå¤„ç†ç»å¯¹å®‰å…¨çš„å†å²æ•°æ®ï¼Œå½»åº•é¿å…æœªæ¥æ•°æ®å¹²æ‰°
            query = """
                SELECT m.id, ht.name as home_team, at.name as away_team, m.match_date, l.name as competition, m.season, m.data_completeness
                FROM matches m
                JOIN teams ht ON m.home_team_id = ht.id
                JOIN teams at ON m.away_team_id = at.id
                LEFT JOIN leagues l ON m.league_id = l.id
                WHERE m.data_completeness = 'partial'
                  AND m.match_date < CURRENT_DATE - INTERVAL '7 days'  -- ã€ç»ˆæå®‰å…¨ã€‘åªå¤„ç†è‡³å°‘7å¤©å‰çš„æ•°æ®ï¼Œ100%é¿å…æœªæ¥æ•°æ®
                  AND m.match_date >= CURRENT_DATE - INTERVAL '2 years'  -- æ—¶é—´çª—å£ï¼šæœ€è¿‘2å¹´ï¼ˆä¼˜åŒ–ç®—åŠ›åˆ†é…ï¼‰
                ORDER BY m.match_date DESC  -- å€’åºï¼šä»æœ€æ–°å‘è¿‡å»å›æº¯ï¼Œä¼˜å…ˆå¤„ç†åˆšç»“æŸçš„æ¯”èµ›
            """

            if limit:
                query += f" LIMIT {limit}"

            self.logger.debug(f"æ‰§è¡ŒæŸ¥è¯¢: {query}")

            # æ‰§è¡ŒæŸ¥è¯¢
            async with get_db_session() as session:
                result = await session.execute(text(query))
                rows = result.fetchall()
                records = []
                for row in rows:
                    records.append({
                        'id': row[0],
                        'home_team': row[1],
                        'away_team': row[2],
                        'match_date': row[3],
                        'competition': row[4],
                        'season': row[5],
                        'data_completeness': row[6]
                    })

            self.logger.info(f"ğŸ“‹ ä»æ•°æ®åº“è·å–åˆ° {len(records)} æ¡ partial è®°å½•")
            return records

        except Exception as e:
            self.logger.error(f"âŒ è·å– partial è®°å½•å¤±è´¥: {str(e)}")
            raise

    async def _process_single_record(self, record: dict[str, Any], current: int, total: int):
        """
        å¤„ç†å•æ¡è®°å½•çš„å®Œæ•´æµç¨‹ï¼šBridge -> Harvest -> Save

        Args:
            record: å¾…å¤„ç†è®°å½•
            current: å½“å‰å¤„ç†åºå·
            total: æ€»è®°å½•æ•°
        """
        record_id = record.get('id')
        home_team = record.get('home_team')
        away_team = record.get('away_team')
        match_date = record.get('match_date')

        self.logger.info(f"ğŸ”„ [{current}/{total}] å¤„ç†è®°å½•: {home_team} vs {away_team} ({match_date})")
        self.stats["processed"] += 1

        # Step A: The Bridge - åŒ¹é… FotMob ID
        fotmob_match = await self._bridge_fbref_to_fotmob(record)

        if not fotmob_match:
            self.logger.warning(f"âš ï¸  è·³è¿‡è®°å½• {record_id}: åŒ¹é…å¤±è´¥")
            self.stats["failed_match"] += 1
            await self._mark_record_as_failed(record_id, "match_failed")
            return

        fotmob_id = fotmob_match["matchId"]
        self.logger.info(f"âœ… æˆåŠŸåŒ¹é…: {home_team} -> {fotmob_id} (ç›¸ä¼¼åº¦: {fotmob_match['similarity_score']:.1f}%)")
        self.stats["matched"] += 1

        # Step B: The Harvest - é‡‡é›†è¯¦æƒ…æ•°æ®
        details_data = await self._harvest_match_details(fotmob_id)

        if not details_data:
            self.logger.warning(f"âš ï¸  è·³è¿‡è®°å½• {record_id}: é‡‡é›†å¤±è´¥")
            self.stats["failed_collection"] += 1
            await self._mark_record_as_failed(record_id, "collection_failed")
            return

        self.logger.info(f"âœ… æˆåŠŸé‡‡é›†è¯¦æƒ…: {fotmob_id}")
        self.stats["collected"] += 1

        # Step C: The Save - å­˜å‚¨æ•°æ®
        success = await self._save_match_details(record_id, details_data)

        if success:
            self.logger.info(f"âœ… è®°å½•å·²æ›´æ–°: {record_id} -> complete")
            self.stats["saved"] += 1
        else:
            self.logger.error(f"âŒ ä¿å­˜è®°å½• {record_id} å¤±è´¥")
            self.stats["failed_save"] += 1

    async def _bridge_fbref_to_fotmob(self, fbref_record: dict[str, Any]) -> Optional[dict[str, Any]]:
        """
        The Bridge: å°† FBref è®°å½•åŒ¹é…åˆ° FotMob ID

        Args:
            fbref_record: FBref æ•°æ®åº“è®°å½•

        Returns:
            åŒ¹é…ç»“æœæˆ– None
        """
        try:
            # å‡†å¤‡åŒ¹é…æ•°æ®
            match_data = {
                "home": fbref_record.get('home_team', ''),
                "away": fbref_record.get('away_team', ''),
                "date": fbref_record.get('match_date', '')
            }

            # æ‰§è¡Œæ¨¡ç³ŠåŒ¹é…ï¼Œåº”ç”¨æŒ‡æ•°é€€é¿
            async def match_request():
                return await self.matcher.find_match_by_fuzzy_match(match_data)

            result = await exponential_backoff_request(
                match_request,
                max_retries=3,
                base_delay=30.0,
                max_delay=180.0
            )

            return result

        except Exception as e:
            self.logger.error(f"âŒ Bridge åŒ¹é…å¤±è´¥: {str(e)}")
            return None

    async def _harvest_match_details(self, fotmob_id: str) -> Optional[dict[str, Any]]:
        """
        The Harvest: é‡‡é›†æ¯”èµ›è¯¦æƒ…æ•°æ®
        ğŸŒ é™ç»´æ‰“å‡»ï¼šä½¿ç”¨ Playwright æµè§ˆå™¨é‡‡é›†å™¨

        Args:
            fotmob_id: FotMob æ¯”èµ› ID

        Returns:
            è¯¦æƒ…æ•°æ®æˆ– None
        """
        try:
            self.logger.info(f"ğŸŒ å¯åŠ¨ Playwright æµè§ˆå™¨é‡‡é›†: {fotmob_id}")

            # åˆ›å»ºæµè§ˆå™¨é‡‡é›†å™¨å®ä¾‹ - åŠ¨æ€åˆ›å»ºé¿å…èµ„æºæµªè´¹
            async def details_request():
                async with FotmobBrowserScraper() as browser_scraper:
                    result = await browser_scraper.scrape_match_details(fotmob_id)

                    # è½¬æ¢ä¸ºç°æœ‰æ ¼å¼
                    if result:
                        return {
                            "matchId": result.match_id,
                            "match_info": {
                                "home_team": result.home_team,
                                "away_team": result.away_team,
                                "home_score": result.home_score,
                                "away_score": result.away_score,
                                "status": result.status,
                                "start_time": result.start_time
                            },
                            "lineup": result.lineups,
                            "shots": result.shots,
                            "stats": result.stats,
                            "fetched_at": datetime.utcnow().isoformat()
                        }
                    return None

            # æ‰§è¡Œæµè§ˆå™¨é‡‡é›† (æµè§ˆå™¨æ“ä½œéœ€è¦æ›´é•¿æ—¶é—´)
            details = await exponential_backoff_request(
                details_request,
                max_retries=2,  # å‡å°‘é‡è¯•æ¬¡æ•°
                base_delay=15.0,  # å¢åŠ å»¶è¿Ÿé€‚åº”æµè§ˆå™¨æ“ä½œ
                max_delay=45.0
            )

            return details

        except Exception as e:
            self.logger.error(f"âŒ Playwright æµè§ˆå™¨é‡‡é›†å¤±è´¥: {str(e)}")
            return None

    async def _save_match_details(self, record_id: int, details_data: dict[str, Any]) -> bool:
        """
        The Save: ä¿å­˜æ¯”èµ›è¯¦æƒ…åˆ°æ•°æ®åº“

        Args:
            record_id: æ•°æ®åº“è®°å½• ID
            details_data: é‡‡é›†çš„è¯¦æƒ…æ•°æ®

        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            async with get_db_session() as session:
                # Step 1: ä¿å­˜å°„é—¨æ•°æ®åˆ° events è¡¨
                await self._save_shotmap_data(session, record_id, details_data.get('shots', []))

                # Step 2: ä¿å­˜é˜µå®¹æ•°æ®åˆ° lineups è¡¨
                await self._save_lineup_data(session, record_id, details_data.get('lineup', {}))

                # Step 3: æ›´æ–°ä¸»è¡¨çŠ¶æ€ä¸º complete
                await self._mark_record_as_complete(session, record_id)

                # æäº¤äº‹åŠ¡
                await session.commit()

            return True

        except Exception as e:
            self.logger.error(f"âŒ Save ä¿å­˜å¤±è´¥: {str(e)}")
            return False

    async def _save_shotmap_data(self, session, record_id: int, shots: list[dict[str, Any]]):
        """ä¿å­˜å°„é—¨æ•°æ®åˆ° events è¡¨"""
        if not shots:
            return

        try:
            for shot in shots:
                shot_data = {
                    'match_id': record_id,
                    'event_type': 'shot',
                    'minute': shot.get('minute'),
                    'team': shot.get('team'),
                    'player_name': shot.get('player', {}).get('name', ''),
                    'player_id': shot.get('player', {}).get('id'),
                    'xg': shot.get('xg', 0.0),
                    'is_goal': shot.get('isGoal', False),
                    'shot_type': shot.get('shotType'),
                    'body_part': shot.get('bodyPart'),
                    'situation': shot.get('situation'),
                    'raw_data': json.dumps(shot)
                }

                # æ’å…¥å°„é—¨æ•°æ®
                columns = ', '.join(shot_data.keys())
                placeholders = ', '.join([f':{key}' for key in shot_data.keys()])
                query = f"INSERT INTO events ({columns}) VALUES ({placeholders})"

                await session.execute(text(query), shot_data)

            self.logger.debug(f"ğŸ’¾ ä¿å­˜äº† {len(shots)} æ¡å°„é—¨æ•°æ®")

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å°„é—¨æ•°æ®å¤±è´¥: {str(e)}")
            raise

    async def _save_lineup_data(self, session, record_id: int, lineup: dict[str, Any]):
        """ä¿å­˜é˜µå®¹æ•°æ®åˆ° lineups è¡¨"""
        if not lineup or not lineup.get('home') or not lineup.get('away'):
            return

        try:
            # ä¿å­˜ä¸»é˜Ÿé˜µå®¹
            await self._save_team_lineup(session, record_id, 'home', lineup['home'])

            # ä¿å­˜å®¢é˜Ÿé˜µå®¹
            await self._save_team_lineup(session, record_id, 'away', lineup['away'])

            self.logger.debug("ğŸ’¾ ä¿å­˜äº†é˜µå®¹æ•°æ®")

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜é˜µå®¹æ•°æ®å¤±è´¥: {str(e)}")
            raise

    async def _save_team_lineup(self, session, record_id: int, team_side: str, team_lineup: dict[str, Any]):
        """ä¿å­˜å•æ”¯çƒé˜Ÿé˜µå®¹"""
        starters = team_lineup.get('starters', [])
        substitutes = team_lineup.get('substitutes', [])

        # ä¿å­˜é¦–å‘é˜µå®¹
        for i, player in enumerate(starters):
            player_data = {
                'match_id': record_id,
                'team_side': team_side,
                'player_name': player.get('name', ''),
                'player_id': player.get('id'),
                'position': player.get('position', ''),
                'shirt_number': player.get('shirtNumber'),
                'is_starter': True,
                'is_captain': player.get('captain', False),
                'formation_order': i + 1,
                'raw_data': json.dumps(player)
            }

            await self._insert_lineup_record(session, player_data)

        # ä¿å­˜æ›¿è¡¥é˜µå®¹
        for i, player in enumerate(substitutes):
            player_data = {
                'match_id': record_id,
                'team_side': team_side,
                'player_name': player.get('name', ''),
                'player_id': player.get('id'),
                'position': player.get('position', ''),
                'shirt_number': player.get('shirtNumber'),
                'is_starter': False,
                'is_captain': player.get('captain', False),
                'formation_order': None,
                'raw_data': json.dumps(player)
            }

            await self._insert_lineup_record(session, player_data)

    async def _insert_lineup_record(self, session, player_data: dict[str, Any]):
        """æ’å…¥é˜µå®¹è®°å½•"""
        columns = ', '.join(player_data.keys())
        placeholders = ', '.join([f':{key}' for key in player_data.keys()])
        query = f"INSERT INTO lineups ({columns}) VALUES ({placeholders})"
        await session.execute(text(query), player_data)

    async def _mark_record_as_complete(self, session, record_id: int):
        """æ ‡è®°è®°å½•ä¸º complete"""
        query = """
            UPDATE matches
            SET data_completeness = 'complete',
                updated_at = NOW()
            WHERE id = :record_id
        """
        await session.execute(text(query), {"record_id": record_id})

    async def _mark_record_as_failed(self, record_id: int, failure_type: str):
        """æ ‡è®°è®°å½•ä¸ºå¤±è´¥çŠ¶æ€"""
        try:
            async with get_db_session() as session:
                query = """
                    UPDATE matches
                    SET data_completeness = 'failed',
                        updated_at = NOW()
                    WHERE id = :record_id
                """
                await session.execute(text(query), {
                    "record_id": record_id
                })
                await session.commit()

        except Exception as e:
            self.logger.error(f"âŒ æ ‡è®°è®°å½•å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")

    def _generate_final_stats(self) -> dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        end_time = datetime.now()
        duration = end_time - self.stats["start_time"]

        final_stats = {
            **self.stats,
            "end_time": end_time,
            "duration_seconds": duration.total_seconds(),
            "success_rate": (self.stats["saved"] / max(self.stats["processed"], 1)) * 100,
            "match_success_rate": (self.stats["matched"] / max(self.stats["processed"], 1)) * 100,
            "collection_success_rate": (self.stats["collected"] / max(self.stats["matched"], 1)) * 100,
        }

        return final_stats

    def _log_final_stats(self, stats: dict[str, Any]):
        """è®°å½•æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“Š L2 æ·±åº¦æ•°æ®å›å¡«ç»Ÿè®¡æŠ¥å‘Š")
        self.logger.info("=" * 80)
        self.logger.info(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {stats['duration_seconds']:.2f} ç§’")
        self.logger.info(f"ğŸ“‹ å¤„ç†è®°å½•: {stats['processed']}")
        self.logger.info(f"ğŸ¯ æˆåŠŸåŒ¹é…: {stats['matched']} ({stats['match_success_rate']:.1f}%)")
        self.logger.info(f"ğŸ“¡ æˆåŠŸé‡‡é›†: {stats['collected']} ({stats['collection_success_rate']:.1f}%)")
        self.logger.info(f"ğŸ’¾ æˆåŠŸä¿å­˜: {stats['saved']} ({stats['success_rate']:.1f}%)")
        self.logger.info(f"âŒ åŒ¹é…å¤±è´¥: {stats['failed_match']}")
        self.logger.info(f"âŒ é‡‡é›†å¤±è´¥: {stats['failed_collection']}")
        self.logger.info(f"âŒ ä¿å­˜å¤±è´¥: {stats['failed_save']}")
        self.logger.info("=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs("logs", exist_ok=True)

    logger.info("ğŸš€ å¯åŠ¨ FotMob L2 æ·±åº¦æ•°æ®é‡‡é›†å™¨ V2.0")

    # åˆ›å»ºé‡‡é›†å™¨å®ä¾‹
    collector = FotMobL2CollectorV2(similarity_threshold=70.0)

    try:
        # è¿è¡Œå›å¡«ç®¡é“
        stats = await collector.run_backfill_pipeline(limit=None)  # ğŸš€ å…¨é€Ÿè¿è¡Œï¼šå¤„ç†æ‰€æœ‰ 24,000+ æ¡è®°å½•

        # è¾“å‡ºæœ€ç»ˆçŠ¶æ€
        if stats["success_rate"] > 80:
            logger.info("ğŸ‰ L2 æ•°æ®é‡‡é›†ä»»åŠ¡åœ†æ»¡å®Œæˆ!")
            return 0
        else:
            logger.warning("âš ï¸  L2 æ•°æ®é‡‡é›†ä»»åŠ¡å®Œæˆï¼Œä½†æˆåŠŸç‡åä½")
            return 1

    except KeyboardInterrupt:
        logger.info("â¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢é‡‡é›†")
        return 130
    except Exception as e:
        logger.error(f"ğŸš¨ L2 é‡‡é›†å™¨è¿è¡Œå¤±è´¥: {str(e)}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
