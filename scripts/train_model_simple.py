#!/usr/bin/env python3
"""
ç®€å•ç›´æ¥çš„è¶³çƒé¢„æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬
Simple Football Prediction Model Training Script
"""

import json
import logging
import pickle
from datetime import datetime
from pathlib import Path

import pandas as pd
import xgboost as xgb
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def load_data_via_pandas():
    """ä½¿ç”¨pandasç›´æ¥ä»æ•°æ®åº“åŠ è½½æ•°æ®"""
    logger.info("ğŸ” ä½¿ç”¨pandasä»æ•°æ®åº“åŠ è½½è®­ç»ƒæ•°æ®...")

    try:
        from sqlalchemy import create_engine

        # åˆ›å»ºæ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
        import os

        db_url = os.getenv(
            "DATABASE_URL",
            "postgresql://postgres:postgres-dev-password@db:5432/football_prediction",
        )
        engine = create_engine(db_url)

        # æŸ¥è¯¢æ•°æ®
        query = """
        SELECT
            f.feature_data,
            m.home_score,
            m.away_score,
            CASE
                WHEN m.home_score > m.away_score THEN 'Home'
                WHEN m.home_score = m.away_score THEN 'Draw'
                WHEN m.home_score < m.away_score THEN 'Away'
            END as result_label,
            m.match_date
        FROM features f
        JOIN matches m ON f.match_id = m.id
        WHERE m.home_score IS NOT NULL
          AND m.away_score IS NOT NULL
          AND f.feature_data IS NOT NULL
        ORDER BY m.match_date
        """

        df = pd.read_sql(query, engine)
        logger.info(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(df)} æ¡è®­ç»ƒæ ·æœ¬")

        if len(df) == 0:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")

        # è§£æJSONç‰¹å¾æ•°æ®
        features_list = []
        for feature_json in df["feature_data"]:
            if isinstance(feature_json, str):
                features = json.loads(feature_json)
            else:
                features = feature_json
            features_list.append(features)

        # åˆ›å»ºç‰¹å¾DataFrame
        features_df = pd.DataFrame(features_list)
        features_df["result_label"] = df["result_label"].values
        features_df["match_date"] = pd.to_datetime(df["match_date"].values)

        logger.info(f"ğŸ¯ åŸå§‹ç‰¹å¾ç»´åº¦: {features_df.shape[1]} (åŒ…å«æ ‡ç­¾)")
        logger.info(
            f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {features_df['match_date'].min()} åˆ° {features_df['match_date'].max()}"
        )

        # æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
        logger.info("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒ:")
        label_dist = features_df["result_label"].value_counts()
        for label, count in label_dist.items():
            percentage = count / len(features_df) * 100
            logger.info(f"   {label}: {count} ({percentage:.1f}%)")

        return features_df

    except Exception:
        logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        raise


def preprocess_features(df):
    """é¢„å¤„ç†ç‰¹å¾æ•°æ®ï¼Œé¿å…æ•°æ®æ³„éœ²"""
    logger.info("ğŸ§¹ å¼€å§‹æ•°æ®é¢„å¤„ç†...")

    # ç§»é™¤æ˜ç¡®çš„éé¢„æµ‹æ€§ç‰¹å¾å’Œæ ‡è¯†ç¬¦
    exclude_cols = [
        "home_team_id",  # çƒé˜ŸIDï¼Œä¸åŒ…å«é¢„æµ‹ä¿¡æ¯
        "away_team_id",  # çƒé˜ŸIDï¼Œä¸åŒ…å«é¢„æµ‹ä¿¡æ¯
        "match_date",  # æ¯”èµ›æ—¥æœŸï¼Œä¸åº”è¯¥ç”¨äºé¢„æµ‹
        "match_result",  # æ¯”èµ›ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œä¼šæ³„éœ²ç­”æ¡ˆ
        "result_label",  # æ ‡ç­¾åˆ—
    ]

    # åªä¿ç•™çœŸæ­£çš„ç‰¹å¾åˆ—
    feature_cols = [col for col in df.columns if col not in exclude_cols]

    # è¿›ä¸€æ­¥è¿‡æ»¤ï¼šåªä¿ç•™æ•°å€¼å‹ç‰¹å¾
    numeric_features = []
    for col in feature_cols:
        if df[col].dtype in ["int64", "float64", "int32", "float32"]:
            numeric_features.append(col)
        else:
            logger.warning(f"âš ï¸ è·³è¿‡éæ•°å€¼ç‰¹å¾: {col} (ç±»å‹: {df[col].dtype})")

    logger.info(f"ğŸ“‹ é€‰æ‹©çš„æ•°å€¼ç‰¹å¾åˆ—: {numeric_features}")

    # æå–ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾
    X = df[numeric_features].copy()
    y = df["result_label"].copy()

    # æ£€æŸ¥æ•°æ®è´¨é‡
    logger.info("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
    logger.info(f"   ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    logger.info(f"   æ ‡ç­¾å‘é‡å½¢çŠ¶: {y.shape}")

    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_values = X.isnull().sum()
    if missing_values.sum() > 0:
        missing_cols = missing_values[missing_values > 0]
        logger.warning("âš ï¸ å‘ç°ç¼ºå¤±å€¼:")
        for col, count in missing_cols.items():
            percentage = count / len(X) * 100
            logger.warning(f"   {col}: {count} ({percentage:.1f}%)")

        # ä½¿ç”¨0å¡«å……ç¼ºå¤±å€¼
        X = X.fillna(0)
        logger.info("âœ… å·²ç”¨0å¡«å……ç¼ºå¤±å€¼")
    else:
        logger.info("âœ… æ— ç¼ºå¤±å€¼")

    # æ£€æŸ¥å¸¸æ•°ç‰¹å¾ï¼ˆæ–¹å·®ä¸º0ï¼‰
    constant_features = []
    for col in X.columns:
        if X[col].var() == 0:
            constant_features.append(col)

    if constant_features:
        logger.warning(f"âš ï¸ å‘ç°å¸¸æ•°ç‰¹å¾ï¼ˆæ–¹å·®ä¸º0ï¼‰: {constant_features}")
        X = X.drop(columns=constant_features)
        logger.info(f"âœ… å·²ç§»é™¤ {len(constant_features)} ä¸ªå¸¸æ•°ç‰¹å¾")

    logger.info(f"âœ… é¢„å¤„ç†å®Œæˆ: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")

    # ä¿å­˜ç‰¹å¾åˆ—åä¾›åç»­æ¨ç†ä½¿ç”¨
    feature_metadata = {
        "feature_columns": list(X.columns),
        "n_features": len(X.columns),
        "training_date": datetime.now().isoformat(),
        "training_samples": len(X),
        "excluded_columns": exclude_cols,
        "non_numeric_features": [
            col for col in feature_cols if col not in numeric_features
        ],
    }

    return X, y, feature_metadata


def train_model(X, y):
    """è®­ç»ƒXGBoostæ¨¡å‹"""
    logger.info("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

    # ç¼–ç æ ‡ç­¾
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)

    # æ—¶é—´åºåˆ—æ‹†åˆ†ï¼šä½¿ç”¨å‰80%çš„æ•°æ®è®­ç»ƒï¼Œå20%æµ‹è¯•
    split_index = int(len(X) * 0.8)

    X_train = X.iloc[:split_index]
    X_test = X.iloc[split_index:]
    y_train = y_encoded[:split_index]
    y_test = y_encoded[split_index:]

    logger.info("ğŸ“Š æ—¶é—´åºåˆ—æ‹†åˆ†:")
    logger.info(
        f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬ ({len(X_train) / len(X) * 100:.1f}%)"
    )
    logger.info(
        f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬ ({len(X_test) / len(X) * 100:.1f}%)"
    )

    # æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ‡ç­¾åˆ†å¸ƒ
    train_dist = pd.Series(y_train).value_counts().sort_index()
    test_dist = pd.Series(y_test).value_counts().sort_index()

    class_names = label_encoder.classes_
    logger.info(
        f"   è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(class_names, train_dist.values, strict=False))}"
    )
    logger.info(
        f"   æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(class_names, test_dist.values, strict=False))}"
    )

    # åˆ›å»ºXGBooståˆ†ç±»å™¨ - ä½¿ç”¨åˆç†çš„å‚æ•°é¿å…è¿‡æ‹Ÿåˆ
    model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=4,  # é™ä½æ·±åº¦é¿å…è¿‡æ‹Ÿåˆ
        learning_rate=0.1,
        random_state=42,
        objective="multi:softmax",
        num_class=3,
        eval_metric="mlogloss",
        subsample=0.8,  # éšæœºé‡‡æ ·
        colsample_bytree=0.8,  # ç‰¹å¾é‡‡æ ·
        reg_alpha=0.1,  # L1æ­£åˆ™åŒ–
        reg_lambda=1.0,  # L2æ­£åˆ™åŒ–
    )

    # è®­ç»ƒæ¨¡å‹
    logger.info("ğŸ¯ æ­£åœ¨è®­ç»ƒXGBoostæ¨¡å‹...")
    model.fit(X_train, y_train)

    # é¢„æµ‹
    y_pred = model.predict(X_test)
    model.predict_proba(X_test)

    # è¯„ä¼°
    accuracy = accuracy_score(y_test, y_pred)
    logger.info(f"ğŸ“ˆ æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.1f}%)")

    # æ£€æŸ¥å‡†ç¡®ç‡æ˜¯å¦åˆç†ï¼ˆè¶³çƒé¢„æµ‹ä¸‰åˆ†ç±»ï¼‰
    if accuracy > 0.65:
        logger.warning("âš ï¸ å‡†ç¡®ç‡è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨ç‰¹å¾æ³„éœ²ï¼")
    elif accuracy < 0.35:
        logger.warning("âš ï¸ å‡†ç¡®ç‡è¿‡ä½ï¼Œæ¨¡å‹å¯èƒ½æ¬ æ‹Ÿåˆ")
    else:
        logger.info("âœ… å‡†ç¡®ç‡åœ¨åˆç†èŒƒå›´å†… (35%-65%)")

    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    logger.info("ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    report = classification_report(
        y_test, y_pred, target_names=class_names, output_dict=True
    )

    for class_name in class_names:
        metrics = report[class_name]
        logger.info(f"   {class_name}:")
        logger.info(f"     ç²¾ç¡®ç‡: {metrics['precision']:.3f}")
        logger.info(f"     å¬å›ç‡: {metrics['recall']:.3f}")
        logger.info(f"     F1åˆ†æ•°: {metrics['f1-score']:.3f}")

    # æ··æ·†çŸ©é˜µ
    logger.info("ğŸ”¢ æ··æ·†çŸ©é˜µ:")
    cm = confusion_matrix(y_test, y_pred)
    logger.info("   å®é™…\\é¢„æµ‹  Home  Draw  Away")
    class_names = ["Home", "Draw", "Away"]
    for i, actual_class in enumerate(class_names):
        row_str = f"   {actual_class:6s}"
        for j in range(3):
            row_str += f"  {cm[i][j]:4d}"
        logger.info(row_str)

    # ç‰¹å¾é‡è¦æ€§
    logger.info("ğŸ† ç‰¹å¾é‡è¦æ€§æ’å (Top 10):")
    feature_importance = (
        pd.DataFrame({"feature": X.columns, "importance": model.feature_importances_})
        .sort_values("importance", ascending=False)
        .head(10)
    )

    for idx, row in feature_importance.iterrows():
        logger.info(f"   {idx + 1:2d}. {row['feature']}: {row['importance']:.4f}")

    return model, label_encoder, accuracy, feature_importance


def save_model_and_metadata(
    model, label_encoder, feature_metadata, feature_importance, accuracy
):
    """ä¿å­˜æ¨¡å‹å’Œç›¸å…³å…ƒæ•°æ®"""
    logger.info("ğŸ’¾ å¼€å§‹ä¿å­˜æ¨¡å‹...")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)

    # ä¿å­˜æ¨¡å‹
    model_path = models_dir / "football_prediction_v2.pkl"

    model_data = {
        "model": model,
        "label_encoder": label_encoder,
        "feature_metadata": feature_metadata,
    }

    with open(model_path, "wb") as f:
        pickle.dump(model_data, f)

    logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")

    # ä¿å­˜å…ƒæ•°æ®
    metadata_path = models_dir / "model_metadata.json"
    metadata = {
        "model_version": "v2",
        "model_path": str(model_path),
        "feature_metadata": feature_metadata,
        "feature_importance": feature_importance.to_dict("records"),
        "label_encoder_classes": label_encoder.classes_.tolist(),
        "training_accuracy": accuracy,
        "created_at": datetime.now().isoformat(),
        "model_type": "XGBClassifier",
        "target_classes": ["Home", "Draw", "Away"],
    }

    with open(metadata_path, "w") as f:
        json.dump(metadata, f, indent=2)

    logger.info(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")

    return model_path, metadata_path


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ¯ è¶³çƒé¢„æµ‹æ¨¡å‹è®­ç»ƒå¼€å§‹ (ç®€åŒ–ç‰ˆæœ¬)")
    logger.info("=" * 60)

    try:
        # 1. ä»æ•°æ®åº“åŠ è½½æ•°æ®
        df = load_data_via_pandas()

        # 2. é¢„å¤„ç†
        X, y, feature_metadata = preprocess_features(df)

        # 3. è®­ç»ƒæ¨¡å‹
        model, label_encoder, accuracy, feature_importance = train_model(X, y)

        # æ›´æ–°å…ƒæ•°æ®
        feature_metadata["accuracy"] = accuracy

        # 4. ä¿å­˜æ¨¡å‹
        model_path, metadata_path = save_model_and_metadata(
            model, label_encoder, feature_metadata, feature_importance, accuracy
        )

        logger.info("=" * 60)
        logger.info("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        logger.info(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_path}")
        logger.info(f"ğŸ“„ å…ƒæ•°æ®æ–‡ä»¶: {metadata_path}")
        logger.info(f"ğŸ¯ æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.1f}%)")
        logger.info(f"ğŸ”¢ ç‰¹å¾æ•°é‡: {len(feature_metadata['feature_columns'])}")
        logger.info("=" * 60)

        # ç”Ÿæˆæ¨¡å‹è´¨é‡æŠ¥å‘Š
        if 0.35 <= accuracy <= 0.65:
            logger.info("âœ… æ¨¡å‹è´¨é‡è¯„ä¼°: GOOD - å‡†ç¡®ç‡åœ¨åˆç†èŒƒå›´å†…")
        elif accuracy > 0.65:
            logger.warning("âš ï¸ æ¨¡å‹è´¨é‡è¯„ä¼°: WARNING - å‡†ç¡®ç‡å¯èƒ½è¿‡é«˜ï¼Œæ£€æŸ¥ç‰¹å¾æ³„éœ²")
        else:
            logger.warning(
                "âš ï¸ æ¨¡å‹è´¨é‡è¯„ä¼°: WARNING - å‡†ç¡®ç‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç‰¹å¾æˆ–è°ƒå‚"
            )

        return model_path, metadata_path

    except Exception:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback

        logger.error(f"ğŸ” è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise


if __name__ == "__main__":
    main()
