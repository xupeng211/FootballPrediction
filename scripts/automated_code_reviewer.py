#!/usr/bin/env python3
"""
AIé©±åŠ¨çš„è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ç³»ç»Ÿ
Automated Code Review System

åŸºäºIssue #98æ–¹æ³•è®ºï¼Œæä¾›æ™ºèƒ½ä»£ç å®¡æŸ¥å’Œæ”¹è¿›å»ºè®®
"""

import os
import sys
import json
import subprocess
import re
import ast
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from collections import defaultdict
import logging
from src.core.config import 
from src.core.config import 

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜æ•°æ®ç±»"""

    file_path: str
    line_number: int
    issue_type: str
    severity: str  # critical, high, medium, low
    message: str
    suggestion: str
    rule_id: str


@dataclass
class CodeMetrics:
    """ä»£ç æŒ‡æ ‡æ•°æ®ç±»"""

    file_path: str
    lines_of_code: int
    cyclomatic_complexity: int
    maintainability_index: float
    duplicate_lines: int
    test_coverage: float


class AutomatedCodeReviewer:
    """è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ç³»ç»Ÿ - åŸºäºIssue #98æ–¹æ³•è®º"""

    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(__file__).parent.parent
        self.src_dir = self.project_root / "src"
        self.test_dir = self.project_root / "tests"

        # å®¡æŸ¥ç»“æœ
        self.review_results = {
            "timestamp": datetime.now().isoformat(),
            "issues_found": [],
            "metrics": {},
            "summary": {},
            "recommendations": [],
            "quality_score": 0.0,
            "issue_98_methodology_applied": True,
        }

        # å®¡æŸ¥è§„åˆ™é…ç½®
        self.review_rules = self._load_review_rules()

    def _load_review_rules(self) -> Dict[str, Any]:
        """åŠ è½½å®¡æŸ¥è§„åˆ™"""
        return {
            "complexity_threshold": 10,
            "function_length_limit": 50,
            "class_length_limit": 200,
            "max_parameters": 7,
            "max_nesting_depth": 4,
            "min_test_coverage": 15.0,
            "duplicate_line_threshold": 5,
            "magic_number_threshold": 10,
        }

    def run_comprehensive_review(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢ä»£ç å®¡æŸ¥"""
        logger.info("ğŸ” å¼€å§‹è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥...")

        print("ğŸ” AIé©±åŠ¨è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ç³»ç»Ÿ")
        print("åŸºäºIssue #98æ–¹æ³•è®º")
        print("=" * 60)

        # 1. æ‰«æä»£ç é—®é¢˜
        print("\n1ï¸âƒ£ æ‰«æä»£ç è´¨é‡é—®é¢˜...")
        issues = self.scan_code_issues()

        # 2. è®¡ç®—ä»£ç æŒ‡æ ‡
        print("\n2ï¸âƒ£ è®¡ç®—ä»£ç è´¨é‡æŒ‡æ ‡...")
        metrics = self.calculate_code_metrics()

        # 3. åˆ†ææµ‹è¯•è¦†ç›–ç‡
        print("\n3ï¸âƒ£ åˆ†ææµ‹è¯•è¦†ç›–ç‡...")
        coverage_analysis = self.analyze_test_coverage()

        # 4. æ£€æµ‹ä»£ç é‡å¤
        print("\n4ï¸âƒ£ æ£€æµ‹ä»£ç é‡å¤...")
        duplication_analysis = self.detect_code_duplication()

        # 5. å®‰å…¨æ€§æ£€æŸ¥
        print("\n5ï¸âƒ£ æ‰§è¡Œå®‰å…¨æ€§æ£€æŸ¥...")
        security_issues = self.perform_security_analysis()

        # 6. æ€§èƒ½åˆ†æ
        print("\n6ï¸âƒ£ æ‰§è¡Œæ€§èƒ½åˆ†æ...")
        performance_issues = self.perform_performance_analysis()

        # 7. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("\n7ï¸âƒ£ ç”Ÿæˆç»¼åˆå®¡æŸ¥æŠ¥å‘Š...")
        self.generate_comprehensive_report(
            issues,
            metrics,
            coverage_analysis,
            duplication_analysis,
            security_issues,
            performance_issues,
        )

        print("\nâœ… ä»£ç å®¡æŸ¥å®Œæˆï¼")
        print(f"ğŸ“Š å‘ç°é—®é¢˜: {len(self.review_results['issues_found'])} ä¸ª")
        print(f"ğŸ“ˆ è´¨é‡è¯„åˆ†: {self.review_results['quality_score']:.1f}/10")

        return self.review_results

    def scan_code_issues(self) -> List[CodeIssue]:
        """æ‰«æä»£ç è´¨é‡é—®é¢˜"""
        issues = []

        # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(self.src_dir.rglob("*.py"))

        for py_file in python_files:
            try:
                file_issues = self._analyze_file_issues(py_file)
                issues.extend(file_issues)
            except Exception as e:
                logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {py_file}: {e}")

        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        issues.sort(key=lambda x: self._severity_priority(x.severity), reverse=True)

        self.review_results["issues_found"] = [
            {
                "file_path": issue.file_path,
                "line_number": issue.line_number,
                "issue_type": issue.issue_type,
                "severity": issue.severity,
                "message": issue.message,
                "suggestion": issue.suggestion,
                "rule_id": issue.rule_id,
            }
            for issue in issues
        ]

        print(f"  âœ… å‘ç°è´¨é‡é—®é¢˜: {len(issues)} ä¸ª")
        return issues

    def _analyze_file_issues(self, file_path: Path) -> List[CodeIssue]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„é—®é¢˜"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # è§£æAST
            try:
                tree = ast.parse(content)
            except SyntaxError:
                return [
                    CodeIssue(
                        file_path=str(file_path),
                        line_number=1,
                        issue_type="syntax_error",
                        severity="critical",
                        message="æ–‡ä»¶å­˜åœ¨è¯­æ³•é”™è¯¯",
                        suggestion="ä¿®å¤è¯­æ³•é”™è¯¯åé‡æ–°å®¡æŸ¥",
                        rule_id="SYNTAX001",
                    )
                ]

            # åˆ†æASTèŠ‚ç‚¹
            for node in ast.walk(tree):
                node_issues = self._analyze_ast_node(node, file_path, lines)
                issues.extend(node_issues)

            # é€è¡Œåˆ†æ
            for i, line in enumerate(lines, 1):
                line_issues = self._analyze_line(line, i, file_path)
                issues.extend(line_issues)

        except Exception as e:
            logger.error(f"æ–‡ä»¶åˆ†æå¤±è´¥ {file_path}: {e}")

        return issues

    def _analyze_ast_node(
        self, node: ast.AST, file_path: Path, lines: List[str]
    ) -> List[CodeIssue]:
        """åˆ†æASTèŠ‚ç‚¹é—®é¢˜"""
        issues = []

        # å‡½æ•°å¤æ‚åº¦æ£€æŸ¥
        if isinstance(node, ast.FunctionDef):
            complexity = self._calculate_cyclomatic_complexity(node)
            if complexity > self.review_rules["complexity_threshold"]:
                issues.append(
                    CodeIssue(
                        file_path=str(file_path),
                        line_number=node.lineno,
                        issue_type="high_complexity",
                        severity="high",
                        message=f"å‡½æ•° '{node.name}' çš„åœˆå¤æ‚åº¦è¿‡é«˜: {complexity}",
                        suggestion=f"å»ºè®®å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°ï¼Œç›®æ ‡å¤æ‚åº¦ < {self.review_rules['complexity_threshold']}",
                        rule_id="COMPLEX001",
                    )
                )

            # å‡½æ•°é•¿åº¦æ£€æŸ¥
            if hasattr(node, "end_lineno") and node.end_lineno:
                function_length = node.end_lineno - node.lineno + 1
                if function_length > self.review_rules["function_length_limit"]:
                    issues.append(
                        CodeIssue(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            issue_type="long_function",
                            severity="medium",
                            message=f"å‡½æ•° '{node.name}' è¿‡é•¿: {function_length} è¡Œ",
                            suggestion=f"å»ºè®®å°†å‡½æ•°æ‹†åˆ†ï¼Œç›®æ ‡é•¿åº¦ < {self.review_rules['function_length_limit']} è¡Œ",
                            rule_id="LENGTH001",
                        )
                    )

            # å‚æ•°æ•°é‡æ£€æŸ¥
            if len(node.args.args) > self.review_rules["max_parameters"]:
                issues.append(
                    CodeIssue(
                        file_path=str(file_path),
                        line_number=node.lineno,
                        issue_type="too_many_parameters",
                        severity="medium",
                        message=f"å‡½æ•° '{node.name}' å‚æ•°è¿‡å¤š: {len(node.args.args)} ä¸ª",
                        suggestion="è€ƒè™‘ä½¿ç”¨å‚æ•°å¯¹è±¡æˆ–é…ç½®å­—å…¸æ¥å‡å°‘å‚æ•°æ•°é‡",
                        rule_id="PARAM001",
                    )
                )

        # ç±»é•¿åº¦æ£€æŸ¥
        elif isinstance(node, ast.ClassDef):
            if hasattr(node, "end_lineno") and node.end_lineno:
                class_length = node.end_lineno - node.lineno + 1
                if class_length > self.review_rules["class_length_limit"]:
                    issues.append(
                        CodeIssue(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            issue_type="large_class",
                            severity="medium",
                            message=f"ç±» '{node.name}' è¿‡å¤§: {class_length} è¡Œ",
                            suggestion="å»ºè®®å°†ç±»æ‹†åˆ†ä¸ºå¤šä¸ªèŒè´£å•ä¸€çš„ç±»",
                            rule_id="CLASS001",
                        )
                    )

        return issues

    def _analyze_line(self, line: str, line_num: int, file_path: Path) -> List[CodeIssue]:
        """åˆ†æå•è¡Œä»£ç é—®é¢˜"""
        issues = []

        # é­”æ³•æ•°å­—æ£€æŸ¥
        magic_numbers = re.findall(r"\b\d{2,}\b", line)
        for num in magic_numbers:
            if int(num) > self.review_rules["magic_number_threshold"] and "TODO" not in line:
                issues.append(
                    CodeIssue(
                        file_path=str(file_path),
                        line_number=line_num,
                        issue_type="magic_number",
                        severity="low",
                        message=f"å‘ç°é­”æ³•æ•°å­—: {num}",
                        suggestion="å»ºè®®å°†é­”æ³•æ•°å­—æå–ä¸ºå‘½åå¸¸é‡",
                        rule_id="MAGIC001",
                    )
                )

        # é•¿è¡Œæ£€æŸ¥
        if len(line) > 120:
            issues.append(
                CodeIssue(
                    file_path=str(file_path),
                    line_number=line_num,
                    issue_type="long_line",
                    severity="low",
                    message=f"ä»£ç è¡Œè¿‡é•¿: {len(line)} å­—ç¬¦",
                    suggestion="å»ºè®®å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œï¼Œæé«˜å¯è¯»æ€§",
                    rule_id="FORMAT001",
                )
            )

        # TODO/FIXMEæ£€æŸ¥
        if "TODO" in line or "FIXME" in line:
            issues.append(
                CodeIssue(
                    file_path=str(file_path),
                    line_number=line_num,
                    issue_type="todo_comment",
                    severity="low",
                    message="å­˜åœ¨å¾…åŠäº‹é¡¹æ³¨é‡Š",
                    suggestion="åŠæ—¶å¤„ç†TODO/FIXMEé¡¹ç›®",
                    rule_id="TODO001",
                )
            )

        return issues

    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.With, ast.AsyncWith):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1

        return complexity

    def calculate_code_metrics(self) -> Dict[str, Any]:
        """è®¡ç®—ä»£ç è´¨é‡æŒ‡æ ‡"""
        metrics = {
            "total_files": 0,
            "total_lines": 0,
            "total_functions": 0,
            "total_classes": 0,
            "average_complexity": 0.0,
            "max_complexity": 0,
            "average_function_length": 0.0,
            "test_coverage": 0.0,
        }

        python_files = list(self.src_dir.rglob("*.py"))
        metrics["total_files"] = len(python_files)

        total_complexity = 0
        total_function_length = 0
        function_count = 0

        for py_file in python_files:
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    lines = content.split("\n")

                metrics["total_lines"] += len(lines)

                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        metrics["total_functions"] += 1
                        function_count += 1

                        complexity = self._calculate_cyclomatic_complexity(node)
                        total_complexity += complexity
                        metrics["max_complexity"] = max(metrics["max_complexity"], complexity)

                        if hasattr(node, "end_lineno") and node.end_lineno:
                            function_length = node.end_lineno - node.lineno + 1
                            total_function_length += function_length

                    elif isinstance(node, ast.ClassDef):
                        metrics["total_classes"] += 1

            except Exception as e:
                logger.error(f"è®¡ç®—æŒ‡æ ‡å¤±è´¥ {py_file}: {e}")

        # è®¡ç®—å¹³å‡å€¼
        if function_count > 0:
            metrics["average_complexity"] = total_complexity / function_count
            metrics["average_function_length"] = total_function_length / function_count

        self.review_results["metrics"] = metrics

        print(f"  âœ… å¤„ç†æ–‡ä»¶: {metrics['total_files']} ä¸ª")
        print(f"  âœ… æ€»ä»£ç è¡Œæ•°: {metrics['total_lines']} è¡Œ")
        print(f"  âœ… å¹³å‡å¤æ‚åº¦: {metrics['average_complexity']:.1f}")

        return metrics

    def analyze_test_coverage(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•è¦†ç›–ç‡"""
        coverage_info = {
            "overall_coverage": 0.0,
            "covered_files": 0,
            "uncovered_files": 0,
            "recommendations": [],
        }

        try:
            # å°è¯•è¯»å–è¦†ç›–ç‡æŠ¥å‘Š
            coverage_file = self.project_root / "htmlcov" / "index.html"
            if coverage_file.exists():
                with open(coverage_file, "r", encoding="utf-8") as f:
                    content = f.read()

                # è§£æè¦†ç›–ç‡ç™¾åˆ†æ¯”
                match = re.search(r"([0-9]*\.[0-9]%)", content)
                if match:
                    coverage_info["overall_coverage"] = float(match.group(1).rstrip("%"))

            # åˆ†ææµ‹è¯•æ–‡ä»¶ä¸æºæ–‡ä»¶çš„æ¯”ä¾‹
            test_files = list(self.test_dir.rglob("test_*.py"))
            src_files = list(self.src_dir.rglob("*.py"))

            coverage_info["test_files_count"] = len(test_files)
            coverage_info["source_files_count"] = len(src_files)
            coverage_info["test_to_source_ratio"] = len(test_files) / max(len(src_files), 1)

            # ç”Ÿæˆè¦†ç›–ç‡å»ºè®®
            if coverage_info["overall_coverage"] < self.review_rules["min_test_coverage"]:
                coverage_info["recommendations"].append(
                    f"æµ‹è¯•è¦†ç›–ç‡({coverage_info['overall_coverage']:.1f}%)ä½äºç›®æ ‡({self.review_rules['min_test_coverage']}%)"
                )

            if coverage_info["test_to_source_ratio"] < 0.8:
                coverage_info["recommendations"].append("å»ºè®®ä¸ºæ¯ä¸ªä¸»è¦æºæ–‡ä»¶ç¼–å†™å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶")

        except Exception as e:
            logger.error(f"è¦†ç›–ç‡åˆ†æå¤±è´¥: {e}")

        print(f"  âœ… æµ‹è¯•è¦†ç›–ç‡: {coverage_info['overall_coverage']:.1f}%")
        return coverage_info

    def detect_code_duplication(self) -> Dict[str, Any]:
        """æ£€æµ‹ä»£ç é‡å¤"""
        duplication_info = {
            "duplicated_blocks": 0,
            "duplicated_lines": 0,
            "duplication_percentage": 0.0,
            "similar_functions": [],
        }

        # ç®€åŒ–çš„é‡å¤æ£€æµ‹ï¼šæ£€æŸ¥ç›¸ä¼¼çš„å‡½æ•°ç»“æ„
        function_signatures = defaultdict(list)

        python_files = list(self.src_dir.rglob("*.py"))
        for py_file in python_files:
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()

                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # ç”Ÿæˆå‡½æ•°ç­¾åï¼ˆç®€åŒ–ç‰ˆï¼‰
                        signature = self._generate_function_signature(node)
                        function_signatures[signature].append(
                            {"file": str(py_file), "line": node.lineno, "name": node.name}
                        )

            except Exception as e:
                logger.error(f"é‡å¤æ£€æµ‹å¤±è´¥ {py_file}: {e}")

        # æ‰¾å‡ºé‡å¤çš„å‡½æ•°
        for signature, functions in function_signatures.items():
            if len(functions) > 1:
                duplication_info["duplicated_blocks"] += len(functions) - 1
                duplication_info["similar_functions"].append(
                    {"signature": signature, "occurrences": functions}
                )

        print(f"  âœ… å‘ç°é‡å¤å—: {duplication_info['duplicated_blocks']} ä¸ª")
        return duplication_info

    def _generate_function_signature(self, node: ast.FunctionDef) -> str:
        """ç”Ÿæˆå‡½æ•°ç­¾å"""
        args = [arg.arg for arg in node.args.args]
        return f"{node.name}({', '.join(args)})"

    def perform_security_analysis(self) -> List[Dict[str, Any]]:
        """æ‰§è¡Œå®‰å…¨æ€§åˆ†æ"""
        security_issues = []

        python_files = list(self.src_dir.rglob("*.py"))

        for py_file in python_files:
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    lines = content.split("\n")

                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥å®‰å…¨é—®é¢˜
                    if "eval(" in line or "exec(" in line:
                        security_issues.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "severity": "high",
                                "issue": "ä½¿ç”¨å±é™©çš„eval/execå‡½æ•°",
                                "recommendation": "é¿å…ä½¿ç”¨eval/execï¼Œè€ƒè™‘æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
                            }
                        )

                    if "password" in line.lower() and "=" in line and '"' in line:
                        security_issues.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "severity": "critical",
                                "issue": "å¯èƒ½ç¡¬ç¼–ç å¯†ç ",
                                "recommendation": "ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶å­˜å‚¨æ•æ„Ÿä¿¡æ¯",
                            }
                        )

                    if "sql" in line.lower() and "%" in line and "format" in line:
                        security_issues.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "severity": "high",
                                "issue": "å¯èƒ½çš„SQLæ³¨å…¥é£é™©",
                                "recommendation": "ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æ›¿ä»£å­—ç¬¦ä¸²æ ¼å¼åŒ–",
                            }
                        )

            except Exception as e:
                logger.error(f"å®‰å…¨åˆ†æå¤±è´¥ {py_file}: {e}")

        print(f"  âœ… å‘ç°å®‰å…¨é—®é¢˜: {len(security_issues)} ä¸ª")
        return security_issues

    def perform_performance_analysis(self) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ€§èƒ½åˆ†æ"""
        performance_issues = []

        python_files = list(self.src_dir.rglob("*.py"))

        for py_file in python_files:
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    lines = content.split("\n")

                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥æ€§èƒ½é—®é¢˜
                    if "while True:" in line and "sleep" not in line:
                        performance_issues.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "severity": "medium",
                                "issue": "å¯èƒ½çš„æ— é™å¾ªç¯",
                                "recommendation": "ç¡®ä¿å¾ªç¯æœ‰æ˜ç¡®çš„é€€å‡ºæ¡ä»¶",
                            }
                        )

                    if line.count("[") > 3 and "for" in line:
                        performance_issues.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "severity": "low",
                                "issue": "åµŒå¥—å¾ªç¯å¯èƒ½å½±å“æ€§èƒ½",
                                "recommendation": "è€ƒè™‘ä¼˜åŒ–ç®—æ³•æˆ–ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„",
                            }
                        )

                    if "+=" in line and "str" in line:
                        performance_issues.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "severity": "low",
                                "issue": "å­—ç¬¦ä¸²æ‹¼æ¥å¯èƒ½å½±å“æ€§èƒ½",
                                "recommendation": "è€ƒè™‘ä½¿ç”¨join()æˆ–f-stringæ›¿ä»£å­—ç¬¦ä¸²æ‹¼æ¥",
                            }
                        )

            except Exception as e:
                logger.error(f"æ€§èƒ½åˆ†æå¤±è´¥ {py_file}: {e}")

        print(f"  âœ… å‘ç°æ€§èƒ½é—®é¢˜: {len(performance_issues)} ä¸ª")
        return performance_issues

    def generate_comprehensive_report(
        self, issues, metrics, coverage, duplication, security, performance
    ):
        """ç”Ÿæˆç»¼åˆå®¡æŸ¥æŠ¥å‘Š"""
        # è®¡ç®—è´¨é‡è¯„åˆ†
        quality_score = self._calculate_overall_quality_score(issues, metrics, coverage, security)
        self.review_results["quality_score"] = quality_score

        # ç”Ÿæˆé—®é¢˜æ‘˜è¦
        issue_summary = self._generate_issue_summary(issues, security, performance)
        self.review_results["summary"] = issue_summary

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        recommendations = self._generate_comprehensive_recommendations(
            issues, metrics, coverage, security, performance
        )
        self.review_results["recommendations"] = recommendations

        # ä¿å­˜æŠ¥å‘Š
        self._save_review_report()

    def _calculate_overall_quality_score(self, issues, metrics, coverage, security_issues):
        """è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†"""
        base_score = 10.0

        # æ ¹æ®é—®é¢˜æ•°é‡æ‰£åˆ†
        critical_issues = len([i for i in issues if i.severity == "critical"])
        high_issues = len([i for i in issues if i.severity == "high"])
        medium_issues = len([i for i in issues if i.severity == "medium"])

        base_score -= critical_issues * 2.0
        base_score -= high_issues * 1.0
        base_score -= medium_issues * 0.5

        # æ ¹æ®å®‰å…¨æ€§é—®é¢˜æ‰£åˆ†
        critical_security = len([s for s in security_issues if s["severity"] == "critical"])
        high_security = len([s for s in security_issues if s["severity"] == "high"])

        base_score -= critical_security * 3.0
        base_score -= high_security * 1.5

        # æ ¹æ®è¦†ç›–ç‡è°ƒæ•´
        if coverage["overall_coverage"] < self.review_rules["min_test_coverage"]:
            base_score -= 1.0

        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´
        if metrics["average_complexity"] > self.review_rules["complexity_threshold"]:
            base_score -= 1.0

        return max(0.0, min(10.0, base_score))

    def _generate_issue_summary(self, issues, security_issues, performance_issues):
        """ç”Ÿæˆé—®é¢˜æ‘˜è¦"""
        return {
            "total_issues": len(issues) + len(security_issues) + len(performance_issues),
            "by_severity": {
                "critical": len([i for i in issues if i.severity == "critical"])
                + len([s for s in security_issues if s["severity"] == "critical"]),
                "high": len([i for i in issues if i.severity == "high"])
                + len([s for s in security_issues if s["severity"] == "high"])
                + len([p for p in performance_issues if p["severity"] == "high"]),
                "medium": len([i for i in issues if i.severity == "medium"])
                + len([p for p in performance_issues if p["severity"] == "medium"]),
                "low": len([i for i in issues if i.severity == "low"])
                + len([p for p in performance_issues if p["severity"] == "low"]),
            },
            "by_type": {
                "complexity": len([i for i in issues if i.issue_type == "high_complexity"]),
                "security": len(security_issues),
                "performance": len(performance_issues),
                "style": len([i for i in issues if i.issue_type in ["long_line", "magic_number"]]),
            },
        }

    def _generate_comprehensive_recommendations(
        self, issues, metrics, coverage, duplication, security, performance
    ):
        """ç”Ÿæˆç»¼åˆæ”¹è¿›å»ºè®®"""
        recommendations = [
            "ğŸ¤– åŸºäºIssue #98æ–¹æ³•è®ºï¼šå»ºè®®å®šæœŸè¿è¡Œä»£ç å®¡æŸ¥ä¿æŒä»£ç è´¨é‡",
            "ğŸ“Š è´¨é‡é—¨ç¦ï¼šå°†ä»£ç å®¡æŸ¥é›†æˆåˆ°CI/CDæµæ°´çº¿ä¸­",
            "ğŸ”§ å·¥å…·é›†æˆï¼šä¸pre-commité’©å­ç»“åˆå®ç°è‡ªåŠ¨åŒ–æ£€æŸ¥",
        ]

        # åŸºäºå…·ä½“é—®é¢˜ç”Ÿæˆå»ºè®®
        if coverage["overall_coverage"] < 15:
            recommendations.append("ğŸ§ª æµ‹è¯•ä¼˜å…ˆï¼šä¼˜å…ˆæå‡æµ‹è¯•è¦†ç›–ç‡åˆ°15%ä»¥ä¸Š")

        if metrics["average_complexity"] > 8:
            recommendations.append("ğŸ”„ é‡æ„å»ºè®®ï¼šé‡ç‚¹å…³æ³¨é«˜å¤æ‚åº¦å‡½æ•°çš„é‡æ„")

        if security_issues:
            recommendations.append("ğŸ”’ å®‰å…¨ä¼˜å…ˆï¼šç«‹å³ä¿®å¤æ‰€æœ‰å…³é”®å’Œé«˜ä¼˜å…ˆçº§å®‰å…¨é—®é¢˜")

        if performance_issues:
            recommendations.append("âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šä¼˜åŒ–è¯†åˆ«å‡ºçš„æ€§èƒ½ç“¶é¢ˆç‚¹")

        return recommendations

    def _save_review_report(self):
        """ä¿å­˜å®¡æŸ¥æŠ¥å‘Š"""
        report_file = self.project_root / "automated_code_review_report.json"

        try:
            with open(report_file, "w", encoding="utf-8") as f:
                json.dump(self.review_results, f, indent=2, ensure_ascii=False)

            logger.info(f"ä»£ç å®¡æŸ¥æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜å®¡æŸ¥æŠ¥å‘Šå¤±è´¥: {e}")

    def _severity_priority(self, severity: str) -> int:
        """è·å–ä¸¥é‡ç¨‹åº¦ä¼˜å…ˆçº§"""
        priority_map = {"critical": 4, "high": 3, "medium": 2, "low": 1}
        return priority_map.get(severity, 0)

    def print_review_summary(self):
        """æ‰“å°å®¡æŸ¥æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥æ‘˜è¦")
        print("=" * 60)

        # è´¨é‡è¯„åˆ†
        score = self.review_results["quality_score"]
        score_emoji = "ğŸŸ¢" if score >= 8 else "ğŸŸ¡" if score >= 6 else "ğŸ”´"
        print(f"è´¨é‡è¯„åˆ†: {score_emoji} {score:.1f}/10")

        # é—®é¢˜ç»Ÿè®¡
        summary = self.review_results["summary"]
        print("\nğŸ“‹ é—®é¢˜ç»Ÿè®¡:")
        print(f"  æ€»é—®é¢˜æ•°: {summary['total_issues']}")
        for severity, count in summary["by_severity"].items():
            if count > 0:
                emoji = {"critical": "ğŸš¨", "high": "âš ï¸", "medium": "â­", "low": "ğŸ’¡"}[severity]
                print(f"  {severity.upper()}: {emoji} {count}")

        # æŒ‡æ ‡ä¿¡æ¯
        metrics = self.review_results["metrics"]
        print("\nğŸ“ˆ ä»£ç æŒ‡æ ‡:")
        print(f"  æ–‡ä»¶æ€»æ•°: {metrics['total_files']}")
        print(f"  ä»£ç è¡Œæ•°: {metrics['total_lines']}")
        print(f"  å‡½æ•°æ•°é‡: {metrics['total_functions']}")
        print(f"  å¹³å‡å¤æ‚åº¦: {metrics['average_complexity']:.1f}")

        # å…³é”®å»ºè®®
        if self.review_results["recommendations"]:
            print("\nğŸ’¡ å…³é”®å»ºè®®:")
            for rec in self.review_results["recommendations"][:5]:
                print(f"  {rec}")

        print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="AIé©±åŠ¨è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ç³»ç»Ÿ")
    parser.add_argument("--project-root", type=Path, help="é¡¹ç›®æ ¹ç›®å½•")
    parser.add_argument(
        "--output-format", choices=["text", "json"], default="text", help="è¾“å‡ºæ ¼å¼"
    )
    parser.add_argument("--severity-filter", help="è¿‡æ»¤é—®é¢˜ä¸¥é‡ç¨‹åº¦ (critical,high,medium,low)")

    args = parser.parse_args()

    reviewer = AutomatedCodeReviewer(args.project_root)

    # è¿è¡Œå®¡æŸ¥
    results = reviewer.run_comprehensive_review()

    # è¾“å‡ºç»“æœ
    if args.output_format == "json":
        print(json.dumps(results, indent=2, ensure_ascii=False))
    else:
        reviewer.print_review_summary()

    # è®¾ç½®é€€å‡ºç 
    if results["quality_score"] < 6.0:
        sys.exit(1)
    elif results["summary"]["by_severity"]["critical"] > 0:
        sys.exit(2)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
