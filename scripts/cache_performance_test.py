#!/usr/bin/env python3
"""
Redisç¼“å­˜æ€§èƒ½æµ‹è¯•å·¥å…·
Redis Cache Performance Test Tool

æµ‹è¯•ç¼“å­˜ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬å‘½ä¸­ç‡ã€å“åº”æ—¶é—´ç­‰ã€‚
"""

import asyncio
import json
import logging
import random
import time
from dataclasses import dataclass
from typing import Any

import aiohttp
import numpy as np

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®"""

    api_base_url: str = "http://localhost:8000"
    concurrent_requests: int = 50
    total_requests: int = 1000
    test_duration: int = 60  # ç§’
    endpoints: list[str] = None
    payload_variants: dict[str, list[dict]] = None

    def __post_init__(self):
        if self.endpoints is None:
            self.endpoints = [
                "/predictions-srs/predict",
                "/predictions-srs/predict/batch",
                "/predictions-srs/metrics",
                "/betting/recommendations/12345",
                "/health"
            ]

        if self.payload_variants is None:
            self.payload_variants = {
                "/predictions-srs/predict": [
                    {
                        "match_info": {
                            "match_id": random.randint(1000, 9999),
                            "home_team": f"Team_{random.randint(1, 20)}",
                            "away_team": f"Team_{random.randint(21, 40)}",
                            "league": "Premier League",
                            "match_date": "2025-11-05T20:00:00Z"
                        },
                        "include_confidence": True,
                        "include_features": False
                    }
                    for _ in range(10)
                ],
                "/predictions-srs/predict/batch": [
                    {
                        "matches": [
                            {
                                "match_id": random.randint(1000, 9999),
                                "home_team": f"Team_{random.randint(1, 20)}",
                                "away_team": f"Team_{random.randint(21, 40)}",
                                "league": "Premier League",
                                "match_date": "2025-11-05T20:00:00Z"
                            }
                            for _ in range(random.randint(1, 5))
                        ],
                        "include_confidence": True,
                        "max_concurrent": 10
                    }
                    for _ in range(5)
                ]
            }


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœ"""

    total_requests: int
    successful_requests: int
    failed_requests: int
    cache_hits: int
    cache_misses: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float
    cache_hit_rate: float
    error_rate: float


class CachePerformanceTester:
    """ç¼“å­˜æ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(self, config: TestConfig):
        self.config = config
        self.session = None
        self.results = []

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        # åˆ›å»ºHTTPä¼šè¯
        connector = aiohttp.TCPConnector(
            limit=self.config.concurrent_requests,
            limit_per_host=self.config.concurrent_requests,
            ttl_dns_cache=300,
            use_dns_cache=True,
        )

        timeout = aiohttp.ClientTimeout(
            total=30,
            connect=10,
            sock_read=10
        )

        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }
        )

        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()

    async def run_single_request(self, endpoint: str) -> dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªè¯·æ±‚"""
        start_time = time.time()

        try:
            # é€‰æ‹©è¯·æ±‚æ–¹æ³•å’Œæ•°æ®
            if endpoint.startswith("/predictions-srs/predict"):
                if "/batch" in endpoint:
                    payload = random.choice(self.config.payload_variants.get(endpoint, [{}]))
                    async with self.session.post(
                        f"{self.config.api_base_url}{endpoint}",
                        json=payload
                    ) as response:
                        content = await response.text()
                        response_time = time.time() - start_time

                        return {
                            "status_code": response.status,
                            "response_time": response_time,
                            "success": response.status == 200,
                            "cache_hit": response.headers.get("X-Cache") == "HIT",
                            "content_length": len(content),
                            "error": None
                        }
                else:
                    payload = random.choice(self.config.payload_variants.get(endpoint, [{}]))
                    async with self.session.post(
                        f"{self.config.api_base_url}{endpoint}",
                        json=payload
                    ) as response:
                        content = await response.text()
                        response_time = time.time() - start_time

                        return {
                            "status_code": response.status,
                            "response_time": response_time,
                            "success": response.status == 200,
                            "cache_hit": response.headers.get("X-Cache") == "HIT",
                            "content_length": len(content),
                            "error": None
                        }
            else:
                async with self.session.get(f"{self.config.api_base_url}{endpoint}") as response:
                    content = await response.text()
                    response_time = time.time() - start_time

                    return {
                        "status_code": response.status,
                        "response_time": response_time,
                        "success": response.status == 200,
                        "cache_hit": response.headers.get("X-Cache") == "HIT",
                        "content_length": len(content),
                        "error": None
                    }

        except Exception as e:
            response_time = time.time() - start_time
            return {
                "status_code": 0,
                "response_time": response_time,
                "success": False,
                "cache_hit": False,
                "content_length": 0,
                "error": str(e)
            }

    async def run_concurrent_requests(self, num_requests: int) -> list[dict[str, Any]]:
        """æ‰§è¡Œå¹¶å‘è¯·æ±‚"""
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = []
        for _ in range(num_requests):
            endpoint = random.choice(self.config.endpoints)
            task = self.run_single_request(endpoint)
            tasks.append(task)

        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # è¿‡æ»¤å¼‚å¸¸ç»“æœ
        valid_results = []
        for result in results:
            if isinstance(result, dict):
                valid_results.append(result)
            else:
                # å¤„ç†å¼‚å¸¸
                valid_results.append({
                    "status_code": 0,
                    "response_time": 0,
                    "success": False,
                    "cache_hit": False,
                    "content_length": 0,
                    "error": str(result)
                })

        return valid_results

    def calculate_metrics(self, results: list[dict[str, Any]]) -> TestResult:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        if not results:
            raise ValueError("æ²¡æœ‰æµ‹è¯•ç»“æœ")

        # åŸºç¡€ç»Ÿè®¡
        total_requests = len(results)
        successful_requests = sum(1 for r in results if r["success"])
        failed_requests = total_requests - successful_requests

        # ç¼“å­˜ç»Ÿè®¡
        cache_hits = sum(1 for r in results if r["cache_hit"])
        cache_misses = total_requests - cache_hits

        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [r["response_time"] for r in results]
        avg_response_time = np.mean(response_times)
        min_response_time = np.min(response_times)
        max_response_time = np.max(response_times)
        p95_response_time = np.percentile(response_times, 95)
        p99_response_time = np.percentile(response_times, 99)

        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        cache_hit_rate = cache_hits / total_requests if total_requests > 0 else 0
        error_rate = failed_requests / total_requests if total_requests > 0 else 0

        return TestResult(
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            cache_hits=cache_hits,
            cache_misses=cache_misses,
            avg_response_time=avg_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=successful_requests / sum(response_times) if sum(response_times) > 0 else 0,
            cache_hit_rate=cache_hit_rate,
            error_rate=error_rate
        )

    async def run_performance_test(self) -> TestResult:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        logger.info("å¼€å§‹ç¼“å­˜æ€§èƒ½æµ‹è¯•...")
        logger.info(f"é…ç½®: {self.config.concurrent_requests}å¹¶å‘, {self.config.total_requests}æ€»è¯·æ±‚")

        all_results = []
        start_time = time.time()

        # åˆ†æ‰¹æ‰§è¡Œè¯·æ±‚
        batch_size = self.config.concurrent_requests
        remaining_requests = self.config.total_requests

        while remaining_requests > 0:
            current_batch_size = min(batch_size, remaining_requests)
            logger.info(f"æ‰§è¡Œæ‰¹æ¬¡: {current_batch_size} è¯·æ±‚")

            # æ‰§è¡Œå½“å‰æ‰¹æ¬¡
            batch_results = await self.run_concurrent_requests(current_batch_size)
            all_results.extend(batch_results)

            remaining_requests -= current_batch_size

            # æ˜¾ç¤ºè¿›åº¦
            completed = self.config.total_requests - remaining_requests
            progress = (completed / self.config.total_requests) * 100
            logger.info(f"è¿›åº¦: {progress:.1f}% ({completed}/{self.config.total_requests})")

            # çŸ­æš‚ä¼‘æ¯é¿å…è¿‡è½½
            await asyncio.sleep(0.1)

        total_time = time.time() - start_time
        logger.info(f"æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")

        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        final_result = self.calculate_metrics(all_results)
        final_result.requests_per_second = final_result.total_requests / total_time

        return final_result

    def print_results(self, result: TestResult):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š Redisç¼“å­˜æ€§èƒ½æµ‹è¯•ç»“æœ")
        print("="*60)

        print("ğŸ“ˆ è¯·æ±‚ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ•°: {result.total_requests}")
        print(f"  æˆåŠŸè¯·æ±‚: {result.successful_requests}")
        print(f"  å¤±è´¥è¯·æ±‚: {result.failed_requests}")
        print(f"  æˆåŠŸç‡: {(1 - result.error_rate) * 100:.2f}%")

        print("\nğŸ¯ ç¼“å­˜æ€§èƒ½:")
        print(f"  ç¼“å­˜å‘½ä¸­: {result.cache_hits}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­: {result.cache_misses}")
        print(f"  å‘½ä¸­ç‡: {result.cache_hit_rate * 100:.2f}%")

        print("\nâš¡ å“åº”æ—¶é—´:")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {result.avg_response_time * 1000:.2f}ms")
        print(f"  æœ€å°å“åº”æ—¶é—´: {result.min_response_time * 1000:.2f}ms")
        print(f"  æœ€å¤§å“åº”æ—¶é—´: {result.max_response_time * 1000:.2f}ms")
        print(f"  P95å“åº”æ—¶é—´: {result.p95_response_time * 1000:.2f}ms")
        print(f"  P99å“åº”æ—¶é—´: {result.p99_response_time * 1000:.2f}ms")

        print("\nğŸš€ ååé‡:")
        print(f"  æ¯ç§’è¯·æ±‚æ•°: {result.requests_per_second:.2f} RPS")

        # æ€§èƒ½è¯„çº§
        if result.cache_hit_rate >= 0.8:
            cache_grade = "ğŸŸ¢ ä¼˜ç§€"
        elif result.cache_hit_rate >= 0.6:
            cache_grade = "ğŸŸ¡ è‰¯å¥½"
        else:
            cache_grade = "ğŸ”´ éœ€è¦æ”¹è¿›"

        if result.avg_response_time <= 0.1:
            speed_grade = "ğŸŸ¢ ä¼˜ç§€"
        elif result.avg_response_time <= 0.5:
            speed_grade = "ğŸŸ¡ è‰¯å¥½"
        else:
            speed_grade = "ğŸ”´ éœ€è¦æ”¹è¿›"

        print("\nğŸ† æ€§èƒ½è¯„çº§:")
        print(f"  ç¼“å­˜æ•ˆæœ: {cache_grade}")
        print(f"  å“åº”é€Ÿåº¦: {speed_grade}")

        print("="*60)

    async def run_warmup_test(self, warmup_requests: int = 100):
        """è¿è¡Œé¢„çƒ­æµ‹è¯•"""
        logger.info(f"å¼€å§‹é¢„çƒ­æµ‹è¯• ({warmup_requests} è¯·æ±‚)...")

        warmup_results = await self.run_concurrent_requests(warmup_requests)
        warmup_success = sum(1 for r in warmup_results if r["success"])

        logger.info(f"é¢„çƒ­å®Œæˆ: {warmup_success}/{warmup_requests} æˆåŠŸ")

    async def save_results(self, result: TestResult, filename: str = "cache_performance_test.json"):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        results_data = {
            "timestamp": time.time(),
            "config": {
                "api_base_url": self.config.api_base_url,
                "concurrent_requests": self.config.concurrent_requests,
                "total_requests": self.config.total_requests,
                "endpoints": self.config.endpoints
            },
            "results": {
                "total_requests": result.total_requests,
                "successful_requests": result.successful_requests,
                "failed_requests": result.failed_requests,
                "cache_hits": result.cache_hits,
                "cache_misses": result.cache_misses,
                "avg_response_time": result.avg_response_time,
                "min_response_time": result.min_response_time,
                "max_response_time": result.max_response_time,
                "p95_response_time": result.p95_response_time,
                "p99_response_time": result.p99_response_time,
                "requests_per_second": result.requests_per_second,
                "cache_hit_rate": result.cache_hit_rate,
                "error_rate": result.error_rate
            }
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)

        logger.info(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")


async def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TestConfig(
        api_base_url="http://localhost:8000",
        concurrent_requests=20,
        total_requests=500
    )

    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    async with CachePerformanceTester(config) as tester:
        # é¢„çƒ­
        await tester.run_warmup_test()

        # æ­£å¼æµ‹è¯•
        result = await tester.run_performance_test()

        # æ˜¾ç¤ºç»“æœ
        tester.print_results(result)

        # ä¿å­˜ç»“æœ
        await tester.save_results(result)

        # éªŒè¯ç¼“å­˜æ€§èƒ½
        if result.cache_hit_rate < 0.6:
            logger.warning("ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜é…ç½®")
        elif result.cache_hit_rate > 0.9:
            logger.info("ç¼“å­˜æ€§èƒ½ä¼˜ç§€ï¼")

        if result.avg_response_time > 0.5:
            logger.warning("å¹³å‡å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–æ€§èƒ½")
        else:
            logger.info("å“åº”é€Ÿåº¦è‰¯å¥½ï¼")


if __name__ == "__main__":
    asyncio.run(main())
