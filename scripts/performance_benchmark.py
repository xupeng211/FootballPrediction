#!/usr/bin/env python3
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
Performance Benchmark Script

ç”¨äºæµ‹è¯•ç³»ç»Ÿæ€§èƒ½ï¼ŒåŒ…æ‹¬APIå“åº”æ—¶é—´ã€å¹¶å‘å¤„ç†èƒ½åŠ›å’Œèµ„æºä½¿ç”¨æƒ…å†µã€‚
"""

import asyncio
import json
import logging
import statistics
import time
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import httpx
import psutil
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

console = Console()


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""

    name: str
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float
    error_rate: float
    cpu_usage: float
    memory_usage: float
    duration: float


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=30.0)
        self.console = Console()

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()

    def get_system_metrics(self) -> Dict[str, float]:
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()

        return {
            "cpu_usage": cpu_percent,
            "memory_usage": memory.percent,
            "memory_used_gb": memory.used / (1024**3),
            "memory_total_gb": memory.total / (1024**3),
        }

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            # å°è¯•å¤šä¸ªå¥åº·æ£€æŸ¥ç«¯ç‚¹
            endpoints = ["/health", "/api/health", "/"]
            for endpoint in endpoints:
                try:
                    response = await self.client.get(f"{self.base_url}{endpoint}")
                    if response.status_code == 200:
                        logger.info(f"Health check successful via {endpoint}")
                        return True
            except Exception:
                    continue
            return False
        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return False

    async def single_request(self, endpoint: str, method: str = "GET", **kwargs) -> Dict[str, Any]:
        """å•ä¸ªè¯·æ±‚æµ‹è¯•"""
        start_time = time.time()
        success = False
        error_message = None
        status_code = None

        try:
            if method.upper() == "GET":
                response = await self.client.get(f"{self.base_url}{endpoint}", **kwargs)
            elif method.upper() == "POST":
                response = await self.client.post(f"{self.base_url}{endpoint}", **kwargs)
            else:
                raise ValueError(f"Unsupported method: {method}")

            end_time = time.time()
            response_time = end_time - start_time
            success = 200 <= response.status_code < 400
            status_code = response.status_code

            if not success:
                error_message = f"HTTP {status_code}"

        except Exception as e:
            end_time = time.time()
            response_time = end_time - start_time
            error_message = str(e)
            status_code = None

        return {
            "success": success,
            "response_time": response_time,
            "status_code": status_code,
            "error_message": error_message,
        }

    async def load_test(
        self,
        endpoint: str,
        concurrent_users: int = 10,
        requests_per_user: int = 20,
        method: str = "GET",
        **kwargs,
    ) -> BenchmarkResult:
        """è´Ÿè½½æµ‹è¯•"""
        console.print(f"ğŸš€ å¼€å§‹è´Ÿè½½æµ‹è¯•: {method} {endpoint}")
        console.print(f"ğŸ‘¥ å¹¶å‘ç”¨æˆ·æ•°: {concurrent_users}")
        console.print(f"ğŸ“Š æ¯ç”¨æˆ·è¯·æ±‚æ•°: {requests_per_user}")

        start_time = time.time()
        self.get_system_metrics()

        # æ”¶é›†æ‰€æœ‰è¯·æ±‚ç»“æœ
        all_response_times = []
        successful_requests = 0
        failed_requests = 0

        async def user_session():
            """å•ä¸ªç”¨æˆ·ä¼šè¯"""
            nonlocal successful_requests, failed_requests

            user_response_times = []

            for _ in range(requests_per_user):
                result = await self.single_request(endpoint, method, **kwargs)

                user_response_times.append(result["response_time"])

                if result["success"]:
                    successful_requests += 1
                else:
                    failed_requests += 1

                # çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                await asyncio.sleep(0.1)

            return user_response_times

        # æ‰§è¡Œå¹¶å‘ç”¨æˆ·ä¼šè¯
        tasks = [user_session() for _ in range(concurrent_users)]

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console,
        ) as progress:
            task = progress.add_task("æ‰§è¡Œè´Ÿè½½æµ‹è¯•...", total=None)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)

            progress.update(task, description="è´Ÿè½½æµ‹è¯•å®Œæˆ!")

        # æ”¶é›†æ‰€æœ‰å“åº”æ—¶é—´
        for user_times in results:
            if isinstance(user_times, list):
                all_response_times.extend(user_times)

        end_time = time.time()
        final_system_metrics = self.get_system_metrics()
        total_duration = end_time - start_time

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if all_response_times:
            avg_response_time = statistics.mean(all_response_times)
            min_response_time = min(all_response_times)
            max_response_time = max(all_response_times)

            # è®¡ç®—ç™¾åˆ†ä½æ•°
            sorted_times = sorted(all_response_times)
            p95_index = int(len(sorted_times) * 0.95)
            p99_index = int(len(sorted_times) * 0.99)
            p95_response_time = sorted_times[min(p95_index, len(sorted_times) - 1)]
            p99_response_time = sorted_times[min(p99_index, len(sorted_times) - 1)]
        else:
            avg_response_time = min_response_time = max_response_time = 0
            p95_response_time = p99_response_time = 0

        total_requests = concurrent_users * requests_per_user
        requests_per_second = total_requests / total_duration if total_duration > 0 else 0
        error_rate = (failed_requests / total_requests * 100) if total_requests > 0 else 0

        return BenchmarkResult(
            name=f"{method} {endpoint}",
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            avg_response_time=avg_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=requests_per_second,
            error_rate=error_rate,
            cpu_usage=final_system_metrics["cpu_usage"],
            memory_usage=final_system_metrics["memory_usage"],
            duration=total_duration,
        )

    def display_result(self, result: BenchmarkResult):
        """æ˜¾ç¤ºæµ‹è¯•ç»“æœ"""
        # åˆ›å»ºç»“æœè¡¨æ ¼
        table = Table(title=f"ğŸ æ€§èƒ½æµ‹è¯•ç»“æœ: {result.name}")

        table.add_column("æŒ‡æ ‡", style="cyan", no_wrap=True)
        table.add_column("æ•°å€¼", style="green")
        table.add_column("å•ä½", style="yellow")

        table.add_row("æ€»è¯·æ±‚æ•°", f"{result.total_requests:,}", "ä¸ª")
        table.add_row("æˆåŠŸè¯·æ±‚", f"{result.successful_requests:,}", "ä¸ª")
        table.add_row("å¤±è´¥è¯·æ±‚", f"{result.failed_requests:,}", "ä¸ª")
        table.add_row("æˆåŠŸç‡", f"{100 - result.error_rate:.2f}", "%")
        table.add_row("é”™è¯¯ç‡", f"{result.error_rate:.2f}", "%")
        table.add_row("", "", "")
        table.add_row("å¹³å‡å“åº”æ—¶é—´", f"{result.avg_response_time:.3f}", "ç§’")
        table.add_row("æœ€å°å“åº”æ—¶é—´", f"{result.min_response_time:.3f}", "ç§’")
        table.add_row("æœ€å¤§å“åº”æ—¶é—´", f"{result.max_response_time:.3f}", "ç§’")
        table.add_row("95%å“åº”æ—¶é—´", f"{result.p95_response_time:.3f}", "ç§’")
        table.add_row("99%å“åº”æ—¶é—´", f"{result.p99_response_time:.3f}", "ç§’")
        table.add_row("", "", "")
        table.add_row("è¯·æ±‚é€Ÿç‡", f"{result.requests_per_second:.2f}", "è¯·æ±‚/ç§’")
        table.add_row("æµ‹è¯•æ—¶é•¿", f"{result.duration:.2f}", "ç§’")
        table.add_row("", "", "")
        table.add_row("CPUä½¿ç”¨ç‡", f"{result.cpu_usage:.1f}", "%")
        table.add_row("å†…å­˜ä½¿ç”¨ç‡", f"{result.memory_usage:.1f}", "%")

        self.console.print(table)

        # æ˜¾ç¤ºæ€§èƒ½è¯„ä¼°
        self.evaluate_performance(result)

    def evaluate_performance(self, result: BenchmarkResult):
        """è¯„ä¼°æ€§èƒ½è¡¨ç°"""
        console.print("\nğŸ“Š æ€§èƒ½è¯„ä¼°:", style="bold blue")

        # å“åº”æ—¶é—´è¯„ä¼°
        if result.avg_response_time < 0.1:
            console.print("âœ… å“åº”æ—¶é—´: ä¼˜ç§€ (< 100ms)", style="green")
        elif result.avg_response_time < 0.5:
            console.print("âš ï¸  å“åº”æ—¶é—´: è‰¯å¥½ (100-500ms)", style="yellow")
        else:
            console.print("âŒ å“åº”æ—¶é—´: éœ€è¦ä¼˜åŒ– (> 500ms)", style="red")

        # é”™è¯¯ç‡è¯„ä¼°
        if result.error_rate == 0:
            console.print("âœ… é”™è¯¯ç‡: å®Œç¾ (0%)", style="green")
        elif result.error_rate < 1:
            console.print("âœ… é”™è¯¯ç‡: ä¼˜ç§€ (< 1%)", style="green")
        elif result.error_rate < 5:
            console.print("âš ï¸  é”™è¯¯ç‡: å¯æ¥å— (1-5%)", style="yellow")
        else:
            console.print("âŒ é”™è¯¯ç‡: éœ€è¦ä¼˜åŒ– (> 5%)", style="red")

        # ååé‡è¯„ä¼°
        if result.requests_per_second > 1000:
            console.print("âœ… ååé‡: ä¼˜ç§€ (> 1000 RPS)", style="green")
        elif result.requests_per_second > 500:
            console.print("âœ… ååé‡: è‰¯å¥½ (500-1000 RPS)", style="green")
        elif result.requests_per_second > 100:
            console.print("âš ï¸  ååé‡: å¯æ¥å— (100-500 RPS)", style="yellow")
        else:
            console.print("âŒ ååé‡: éœ€è¦ä¼˜åŒ– (< 100 RPS)", style="red")

        # ç³»ç»Ÿèµ„æºè¯„ä¼°
        if result.cpu_usage < 50:
            console.print("âœ… CPUä½¿ç”¨: æ­£å¸¸ (< 50%)", style="green")
        elif result.cpu_usage < 80:
            console.print("âš ï¸  CPUä½¿ç”¨: è¾ƒé«˜ (50-80%)", style="yellow")
        else:
            console.print("âŒ CPUä½¿ç”¨: è¿‡é«˜ (> 80%)", style="red")

        if result.memory_usage < 70:
            console.print("âœ… å†…å­˜ä½¿ç”¨: æ­£å¸¸ (< 70%)", style="green")
        elif result.memory_usage < 85:
            console.print("âš ï¸  å†…å­˜ä½¿ç”¨: è¾ƒé«˜ (70-85%)", style="yellow")
        else:
            console.print("âŒ å†…å­˜ä½¿ç”¨: è¿‡é«˜ (> 85%)", style="red")

    async def run_comprehensive_benchmark(self):
        """è¿è¡Œç»¼åˆåŸºå‡†æµ‹è¯•"""
        console.print("ğŸš€ å¼€å§‹ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•", style="bold blue")

        # é¦–å…ˆè¿›è¡Œå¥åº·æ£€æŸ¥
        if not await self.health_check():
            console.print("âŒ åº”ç”¨å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œè¯·ç¡®ä¿åº”ç”¨æ­£åœ¨è¿è¡Œ", style="red")
            return

        console.print("âœ… åº”ç”¨å¥åº·æ£€æŸ¥é€šè¿‡", style="green")

        # æµ‹è¯•åœºæ™¯åˆ—è¡¨
        test_scenarios = [
            {"name": "å¥åº·æ£€æŸ¥", "endpoint": "/api/health", "users": 20, "requests": 10},
            {"name": "æ ¹ç«¯ç‚¹", "endpoint": "/", "users": 10, "requests": 20},
            {"name": "è½»è´Ÿè½½", "endpoint": "/api/health", "users": 50, "requests": 20},
            {"name": "é‡è´Ÿè½½", "endpoint": "/", "users": 100, "requests": 10},
        ]

        results = []

        for scenario in test_scenarios:
            console.print(f"\n{'='*60}")
            console.print(f"æµ‹è¯•åœºæ™¯: {scenario['name']}", style="bold")
            console.print(f"{'='*60}")

            try:
                result = await self.load_test(
                    endpoint=scenario["endpoint"],
                    concurrent_users=scenario["users"],
                    requests_per_user=scenario["requests"],
                )

                results.append(result)
                self.display_result(result)

            except Exception as e:
                console.print(f"âŒ æµ‹è¯•å¤±è´¥: {e}", style="red")
                logger.error(f"Benchmark failed for {scenario['name']}: {e}")

        # æ˜¾ç¤ºæ€»ç»“
        if results:
            self.display_summary(results)

    def display_summary(self, results: List[BenchmarkResult]):
        """æ˜¾ç¤ºæµ‹è¯•æ€»ç»“"""
        console.print(f"\n{'='*60}")
        console.print("ğŸ“Š ç»¼åˆæ€§èƒ½æµ‹è¯•æ€»ç»“", style="bold blue")
        console.print(f"{'='*60}")

        # åˆ›å»ºæ€»ç»“è¡¨æ ¼
        summary_table = Table(title="æ€§èƒ½å¯¹æ¯”")
        summary_table.add_column("æµ‹è¯•åœºæ™¯", style="cyan")
        summary_table.add_column("å¹³å‡å“åº”æ—¶é—´", style="green")
        summary_table.add_column("è¯·æ±‚/ç§’", style="yellow")
        summary_table.add_column("é”™è¯¯ç‡", style="red")
        summary_table.add_column("CPU%", style="blue")
        summary_table.add_column("å†…å­˜%", style="magenta")

        for result in results:
            summary_table.add_row(
                result.name,
                f"{result.avg_response_time:.3f}s",
                f"{result.requests_per_second:.1f}",
                f"{result.error_rate:.2f}%",
                f"{result.cpu_usage:.1f}%",
                f"{result.memory_usage:.1f}%",
            )

        console.print(summary_table)

        # æ€»ä½“è¯„ä¼°
        avg_error_rate = statistics.mean([r.error_rate for r in results])
        avg_response_time = statistics.mean([r.avg_response_time for r in results])
        total_rps = sum([r.requests_per_second for r in results])

        console.print("\nğŸ“ˆ æ€»ä½“æŒ‡æ ‡:")
        console.print(f"  å¹³å‡é”™è¯¯ç‡: {avg_error_rate:.2f}%")
        console.print(f"  å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        console.print(f"  æ€»ååé‡: {total_rps:.1f} RPS")

        # å»ºè®®
        console.print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if avg_error_rate > 1:
            console.print("  - è€ƒè™‘å¢åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
        if avg_response_time > 0.5:
            console.print("  - è€ƒè™‘ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç¼“å­˜ç­–ç•¥")
        if any(r.cpu_usage > 80 for r in results):
            console.print("  - è€ƒè™‘æ°´å¹³æ‰©å±•æˆ–ä»£ç ä¼˜åŒ–")
        if any(r.memory_usage > 85 for r in results):
            console.print("  - æ£€æŸ¥å†…å­˜æ³„æ¼æˆ–å¢åŠ å†…å­˜")


async def main():
    """ä¸»å‡½æ•°"""
    console.print("ğŸƒâ€â™‚ï¸ è¶³çƒé¢„æµ‹ç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•", style="bold blue")
    console.print("=" * 60)

    # ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–åŸºç¡€URL
    import os

    base_url = os.getenv("BASE_URL", "http://localhost:8000")

    async with PerformanceBenchmark(base_url) as benchmark:
        await benchmark.run_comprehensive_benchmark()


if __name__ == "__main__":
    asyncio.run(main())
