#!/usr/bin/env python3
"""
Coverage Gap Analyzer - è¦†ç›–ç‡å·®è·åˆ†æå™¨
åˆ†ææœªè¦†ç›–çš„ä»£ç è¡Œæ•°æœ€å¤šçš„æ–‡ä»¶ï¼Œæ‰¾å‡ºé«˜å›æŠ¥æµ‹è¯•ç›®æ ‡
"""

import os
import ast
import json
from pathlib import Path
from typing import List, Dict, Tuple


def count_lines_in_file(file_path: Path) -> tuple[int, int]:
    """ç»Ÿè®¡æ–‡ä»¶ä¸­çš„ä»£ç è¡Œæ•°å’Œé€»è¾‘è¡Œæ•°"""
    if not file_path.exists():
        return 0, 0

    try:
        with open(file_path, encoding="utf-8") as f:
            content = f.read()

        # ç»Ÿè®¡éç©ºã€éæ³¨é‡Šçš„ä»£ç è¡Œæ•°
        lines = content.split("\n")
        code_lines = 0

        for line in lines:
            stripped = line.strip()
            if (
                stripped
                and not stripped.startswith("#")
                and not stripped.startswith('"""')
                and not stripped.startswith("'''")
            ):
                code_lines += 1

        total_lines = len(lines)
        return total_lines, code_lines

    except Exception:
        print(f"Error reading {file_path}: {e}")
        return 0, 0


def find_python_files(src_dir: Path) -> list[Path]:
    """æ‰¾åˆ°æ‰€æœ‰Pythonæ–‡ä»¶"""
    python_files = []
    for root, dirs, files in os.walk(src_dir):
        # è·³è¿‡__pycache__ç›®å½•
        dirs[:] = [d for d in dirs if not d.startswith("__pycache__")]

        for file in files:
            if file.endswith(".py"):
                python_files.append(Path(root) / file)

    return python_files


def load_existing_coverage() -> dict[str, float]:
    """åŠ è½½ç°æœ‰çš„è¦†ç›–ç‡æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
    coverage_file = Path("coverage_final_gap.json")
    if coverage_file.exists():
        try:
            with open(coverage_file) as f:
                data = json.load(f)
                return {
                    k: v.get("summary", {}).get("percent_covered", 0)
                    for k, v in data.get("files", {}).items()
                }
        except Exception:
            print(f"Error loading coverage data: {e}")

    return {}


def analyze_high_value_targets():
    """åˆ†æé«˜ä»·å€¼æµ‹è¯•ç›®æ ‡"""
    src_dir = Path("src")
    if not src_dir.exists():
        print("srcç›®å½•ä¸å­˜åœ¨")
        return

    # å·²å¤„ç†çš„æ–‡ä»¶ï¼ˆä»Šå¤©æµ‹è¯•è¿‡çš„ï¼‰
    processed_files = {
        "src/events/bus.py",
        "src/services/inference_service.py",
        "src/cache/intelligent_cache_warmup.py",
        "src/utils/string_utils.py",
    }

    # ç°æœ‰è¦†ç›–ç‡æ•°æ®
    existing_coverage = load_existing_coverage()

    print("ğŸ” æ‰«æPythonæ–‡ä»¶...")
    python_files = find_python_files(src_dir)

    candidates = []

    for file_path in python_files:
        rel_path = str(file_path)

        # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
        if rel_path in processed_files:
            continue

        # è·³è¿‡æµ‹è¯•æ–‡ä»¶å’Œç‰¹æ®Šæ–‡ä»¶
        if "test" in str(file_path) or "__init__.py" in str(file_path):
            continue

        # è·³è¿‡å¤ªå°çš„æ–‡ä»¶
        total_lines, code_lines = count_lines_in_file(file_path)
        if code_lines < 20:
            continue

        # ä¼°ç®—æœªè¦†ç›–ç‡ï¼ˆå¦‚æœç°æœ‰æ•°æ®å¯ç”¨ï¼‰
        coverage = existing_coverage.get(rel_path, 0)
        missing_lines = int(code_lines * (1 - coverage / 100))

        # ç¡®å®šæ¨¡å—ç±»å‹
        if "api" in str(file_path):
            module_type = "API"
        elif "services" in str(file_path):
            module_type = "Service"
        elif "cache" in str(file_path):
            module_type = "Cache"
        elif "ml" in str(file_path):
            module_type = "ML"
        elif "collectors" in str(file_path):
            module_type = "Collector"
        elif "database" in str(file_path):
            module_type = "Database"
        else:
            module_type = "Core"

        candidates.append(
            {
                "file": rel_path,
                "total_lines": total_lines,
                "code_lines": code_lines,
                "coverage": coverage,
                "missing_lines": missing_lines,
                "module_type": module_type,
            }
        )

    # æŒ‰æœªè¦†ç›–è¡Œæ•°æ’åº
    candidates.sort(key=lambda x: x["missing_lines"], reverse=True)

    return candidates


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š Coverage Gap Analysis Report")
    print("=" * 50)

    candidates = analyze_high_value_targets()

    if not candidates:
        print("æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å€™é€‰æ–‡ä»¶")
        return

    # æ˜¾ç¤ºTop 10
    print("ğŸ¯ Top 10 High-Value Coverage Targets:")
    print(f"{'File':<40} {'Type':<10} {'Lines':<8} {'Coverage':<10} {'Missing':<8}")
    print("-" * 80)

    for i, candidate in enumerate(candidates[:10], 1):
        file_name = candidate["file"].split("/")[-1]  # åªæ˜¾ç¤ºæ–‡ä»¶å
        print(
            f"{file_name:<40} {candidate['module_type']:<10} "
            f"{candidate['code_lines']:<8} {candidate['coverage']:.1f}%{' ':<5} "
            f"{candidate['missing_lines']:<8}"
        )

    print("\nğŸ“ˆ åˆ†æå®Œæˆ:")
    print(f"   æ€»å€™é€‰æ–‡ä»¶æ•°: {len(candidates)}")
    print(
        f"   Top 5 æ½œåœ¨è¦†ç›–æå‡: {sum(c['missing_lines'] for c in candidates[:5]):.0f} è¡Œä»£ç "
    )


if __name__ == "__main__":
    main()
