#!/usr/bin/env python3
"""
ğŸ•µï¸â€â™‚ï¸ æ‡‚çƒå¸ Web ç«¯ API é€†å‘å·¥ç¨‹æ¢æµ‹è„šæœ¬

ç›®æ ‡ï¼šæ¢æµ‹æ‡‚çƒå¸ Web ç«¯æ¥å£ï¼ŒéªŒè¯æ˜¯å¦åŒ…å« xG (æœŸæœ›è¿›çƒ) å’Œé˜µå®¹æ•°æ®
é¿å¼€ App å¼ºæ ¡éªŒï¼Œä¼˜å…ˆæ¢æµ‹ Web/H5 ç«¯æ¥å£

ä½œè€…ï¼šé€†å‘å·¥ç¨‹ä¸“å®¶ (é’ˆå¯¹ä¸­å›½ä½“è‚²åª’ä½“)
"""

import asyncio
import json
import logging
import re
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta

import httpx
from curl_cffi import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DongqiudiWebProbe:
    """æ‡‚çƒå¸ Web ç«¯ API æ¢æµ‹å™¨"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh-Hans;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://m.dongqiudi.com/'
        })

        # æ‡‚çƒå¸å¯èƒ½çš„ API ç«¯ç‚¹
        self.base_urls = [
            'https://m.dongqiudi.com/api',
            'https://dongqiudi.com/api',
            'https://www.dongqiudi.com/api',
            'https://api.dongqiudi.com'
        ]

        # å¯èƒ½çš„æ¯”èµ›åˆ—è¡¨ç«¯ç‚¹
        self.match_list_endpoints = [
            '/match/list',
            '/match/today',
            '/match/fixed',
            '/v1/match/list',
            '/v2/match/list',
            '/v3/match/list',
            '/mobile/match/list',
            '/h5/match/list'
        ]

        # å¯èƒ½çš„æ¯”èµ›è¯¦æƒ…ç«¯ç‚¹
        self.match_detail_endpoints = [
            '/match/detail',
            '/match/info',
            '/match/data',
            '/v1/match/detail',
            '/v2/match/detail',
            '/mobile/match/detail',
            '/h5/match/detail'
        ]

    async def probe_match_list(self) -> list[dict] | None:
        """æ­¥éª¤ A: è·å–æ¯”èµ›åˆ—è¡¨ï¼Œå¯»æ‰¾äº”å¤§è”èµ›å·²å®Œåœºæ¯”èµ›"""
        logger.info("ğŸ” æ­¥éª¤ A: æ¢æµ‹æ¯”èµ›åˆ—è¡¨æ¥å£...")

        for base_url in self.base_urls:
            for endpoint in self.match_list_endpoints:
                url = f"{base_url}{endpoint}"

                try:
                    logger.info(f"å°è¯•: {url}")
                    response = self.session.get(url, timeout=10)

                    if response.status_code == 200:
                        try:
                            data = response.json()
                            logger.info(f"âœ… æˆåŠŸè·å–æ•°æ®: {url}")

                            # è§£ææ¯”èµ›æ•°æ®
                            matches = self._parse_match_list(data)
                            if matches:
                                logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(matches)} åœºæ¯”èµ›")
                                return matches

                        except json.JSONDecodeError:
                            logger.warning(f"é JSON å“åº”: {url}")
                            continue

                    elif response.status_code in [301, 302, 307, 308]:
                        # å¤„ç†é‡å®šå‘
                        redirect_url = response.headers.get('Location')
                        if redirect_url:
                            logger.info(f"é‡å®šå‘åˆ°: {redirect_url}")

                    else:
                        logger.warning(f"çŠ¶æ€ç  {response.status_code}: {url}")

                except Exception as e:
                    logger.error(f"è¯·æ±‚å¤±è´¥ {url}: {e}")
                    continue

        # å¦‚æœ API æ¢æµ‹å¤±è´¥ï¼Œå°è¯•ä»ç½‘é¡µæŠ“å–
        logger.info("ğŸ”„ API æ¢æµ‹å¤±è´¥ï¼Œå°è¯•ä»ç½‘é¡µæŠ“å–...")
        return await self._scrape_match_list_from_web()

    def _parse_match_list(self, data: Any) -> list[dict]:
        """è§£ææ¯”èµ›åˆ—è¡¨æ•°æ®"""
        matches = []

        # å°è¯•ä¸åŒçš„æ•°æ®ç»“æ„
        if isinstance(data, dict):
            # æƒ…å†µ1: data.data æˆ– data.result
            for key in ['data', 'result', 'list', 'matches']:
                if key in data and isinstance(data[key], list):
                    matches.extend(data[key])

            # æƒ…å†µ2: åˆ†é¡µæ•°æ®
            if 'data' in data and isinstance(data['data'], dict):
                for sub_key in ['list', 'matches', 'items']:
                    if sub_key in data['data'] and isinstance(data['data'][sub_key], list):
                        matches.extend(data['data'][sub_key])

        elif isinstance(data, list):
            matches = data

        # è¿‡æ»¤äº”å¤§è”èµ›å·²å®Œåœºæ¯”èµ›
        filtered_matches = []
        for match in matches:
            if self._is_major_league_finished(match):
                filtered_matches.append(match)

        return filtered_matches

    def _is_major_league_finished(self, match: dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºäº”å¤§è”èµ›å·²å®Œåœºæ¯”èµ›"""
        try:
            # äº”å¤§è”èµ›æ ‡è¯†
            major_leagues = [
                'è‹±è¶…', 'è¥¿ç”²', 'å¾·ç”²', 'æ„ç”²', 'æ³•ç”²',
                'Premier League', 'La Liga', 'Bundesliga', 'Serie A', 'Ligue 1',
                'England', 'Spain', 'Germany', 'Italy', 'France'
            ]

            # æ£€æŸ¥è”èµ›åç§°
            league_name = ''
            for key in ['league', 'league_name', 'competition', 'comp']:
                if key in match and match[key]:
                    league_name = str(match[key]).lower()
                    break

            is_major = any(league.lower() in league_name for league in major_leagues)

            # æ£€æŸ¥æ¯”èµ›çŠ¶æ€
            status = ''
            for key in ['status', 'match_status', 'state', 'finished']:
                if key in match:
                    status = str(match[key]).lower()
                    break

            is_finished = any(word in status for word in ['finished', 'ended', 'å®Œåœº', 'å·²ç»“æŸ'])

            return is_major and is_finished

        except Exception as e:
            logger.debug(f"è§£ææ¯”èµ›çŠ¶æ€å¤±è´¥: {e}")
            return False

    async def _scrape_match_list_from_web(self) -> list[dict] | None:
        """ä»ç½‘é¡µæŠ“å–æ¯”èµ›åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä½¿ç”¨BeautifulSoupï¼‰"""
        urls_to_try = [
            'https://m.dongqiudi.com/',
            'https://dongqiudi.com/',
            'https://www.dongqiudi.com/'
        ]

        for url in urls_to_try:
            try:
                logger.info(f"æŠ“å–ç½‘é¡µ: {url}")
                response = self.session.get(url, timeout=10)

                if response.status_code == 200:
                    # å°è¯•ä» HTML ä¸­æå–æ¯”èµ›æ•°æ®ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
                    html_content = response.text

                    # æŸ¥æ‰¾åŒ…å«æ¯”èµ›æ•°æ®çš„ script æ ‡ç­¾
                    script_pattern = r'<script[^>]*>(.*?)</script>'
                    scripts = re.findall(script_pattern, html_content, re.DOTALL)

                    for script in scripts:
                        if 'match' in script.lower() or 'æ¯”èµ›' in script:
                            # å°è¯•æå– JSON æ•°æ®
                            try:
                                # æŸ¥æ‰¾ JSON å¯¹è±¡æ¨¡å¼
                                json_pattern = r'window\.__INITIAL_STATE__\s*=\s*({.*?});'
                                matches = re.findall(json_pattern, script, re.DOTALL)

                                for match_json in matches:
                                    try:
                                        data = json.loads(match_json)
                                        logger.info("âœ… ä»ç½‘é¡µæå–åˆ°åˆå§‹çŠ¶æ€æ•°æ®")
                                        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„è§£ææ¯”èµ›ä¿¡æ¯
                                        return []
                                    except json.JSONDecodeError:
                                        continue

                            except Exception as e:
                                logger.debug(f"è§£æ script å¤±è´¥: {e}")
                                continue

            except Exception as e:
                logger.error(f"æŠ“å–ç½‘é¡µå¤±è´¥ {url}: {e}")
                continue

        return None

    async def probe_match_detail(self, match_id: str) -> dict | None:
        """æ­¥éª¤ B: æ¢æµ‹æ¯”èµ›è¯¦æƒ…æ¥å£"""
        logger.info(f"ğŸ”¬ æ­¥éª¤ B: æ¢æµ‹æ¯”èµ›è¯¦æƒ…æ¥å£ (ID: {match_id})")

        for base_url in self.base_urls:
            for endpoint in self.match_detail_endpoints:
                # å°è¯•ä¸åŒçš„å‚æ•°æ ¼å¼
                param_formats = [
                    f"?id={match_id}",
                    f"?match_id={match_id}",
                    f"?matchId={match_id}",
                    f"/{match_id}",
                    f"/{match_id}.json"
                ]

                for param in param_formats:
                    url = f"{base_url}{endpoint}{param}"

                    try:
                        logger.info(f"å°è¯•: {url}")
                        response = self.session.get(url, timeout=10)

                        if response.status_code == 200:
                            try:
                                data = response.json()
                                logger.info(f"âœ… æˆåŠŸè·å–æ¯”èµ›è¯¦æƒ…: {url}")

                                # éªŒè¯æ•°æ®è´¨é‡
                                validation_result = self._validate_match_detail(data)
                                if validation_result['has_data']:
                                    return {
                                        'url': url,
                                        'data': data,
                                        'validation': validation_result
                                    }

                            except json.JSONDecodeError:
                                logger.warning(f"é JSON å“åº”: {url}")
                                continue

                        elif response.status_code == 404:
                            continue
                        else:
                            logger.debug(f"çŠ¶æ€ç  {response.status_code}: {url}")

                    except Exception as e:
                        logger.debug(f"è¯·æ±‚å¤±è´¥ {url}: {e}")
                        continue

        return None

    def _validate_match_detail(self, data: dict) -> dict:
        """éªŒè¯æ¯”èµ›è¯¦æƒ…æ•°æ®è´¨é‡"""
        validation = {
            'has_data': False,
            'has_xg': False,
            'has_lineup': False,
            'has_stats': False,
            'key_fields': []
        }

        try:
            # æ£€æŸ¥åŸºæœ¬æ•°æ®ç»“æ„
            if isinstance(data, dict) and data:
                validation['has_data'] = True

                # é€’å½’æŸ¥æ‰¾ xG ç›¸å…³å­—æ®µ
                xg_keywords = ['xg', 'expected_goals', 'xg_total', 'xg_home', 'xg_away', 'expected_goals']
                if self._find_keywords_in_data(data, xg_keywords):
                    validation['has_xg'] = True
                    validation['key_fields'].append('xGæ•°æ®')

                # é€’å½’æŸ¥æ‰¾é˜µå®¹ç›¸å…³å­—æ®µ
                lineup_keywords = ['lineup', 'lineups', 'formation', 'starting_lineup', 'players', 'squad']
                if self._find_keywords_in_data(data, lineup_keywords):
                    validation['has_lineup'] = True
                    validation['key_fields'].append('é˜µå®¹æ•°æ®')

                # é€’å½’æŸ¥æ‰¾æŠ€æœ¯ç»Ÿè®¡ç›¸å…³å­—æ®µ
                stats_keywords = ['statistics', 'stats', 'technical', 'possession', 'shots', 'passes']
                if self._find_keywords_in_data(data, stats_keywords):
                    validation['has_stats'] = True
                    validation['key_fields'].append('æŠ€æœ¯ç»Ÿè®¡')

        except Exception as e:
            logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")

        return validation

    def _find_keywords_in_data(self, data: Any, keywords: list[str]) -> bool:
        """é€’å½’æŸ¥æ‰¾å…³é”®è¯"""
        if isinstance(data, dict):
            for key, value in data.items():
                # æ£€æŸ¥é”®å
                if any(keyword in str(key).lower() for keyword in keywords):
                    return True

                # é€’å½’æ£€æŸ¥å€¼
                if self._find_keywords_in_data(value, keywords):
                    return True

        elif isinstance(data, list):
            for item in data:
                if self._find_keywords_in_data(item, keywords):
                    return True

        elif isinstance(data, str):
            # æ£€æŸ¥å­—ç¬¦ä¸²å†…å®¹
            return any(keyword in data.lower() for keyword in keywords)

        return False

    async def run_probe(self):
        """è¿è¡Œå®Œæ•´çš„æ¢æµ‹æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹æ‡‚çƒå¸ Web ç«¯ API æ¢æµ‹")

        # æ­¥éª¤ 1: è·å–æ¯”èµ›åˆ—è¡¨
        matches = await self.probe_match_list()

        if not matches:
            logger.error("âŒ æ— æ³•è·å–æ¯”èµ›åˆ—è¡¨")
            return

        # é€‰æ‹©ä¸€åœºæ¯”èµ›è¿›è¡Œè¯¦æƒ…æ¢æµ‹
        target_match = matches[0] if matches else None
        match_id = self._extract_match_id(target_match)

        if not match_id:
            logger.error("âŒ æ— æ³•æå–æ¯”èµ› ID")
            return

        logger.info(f"ğŸ“‹ ç›®æ ‡æ¯”èµ›: {target_match}")
        logger.info(f"ğŸ†” æ¯”èµ› ID: {match_id}")

        # æ­¥éª¤ 2: æ¢æµ‹æ¯”èµ›è¯¦æƒ…
        detail_result = await self.probe_match_detail(match_id)

        if detail_result:
            logger.info("âœ… æ¢æµ‹æˆåŠŸ!")
            logger.info(f"ğŸ“¡ æˆåŠŸæ¥å£: {detail_result['url']}")

            validation = detail_result['validation']
            logger.info("ğŸ“Š æ•°æ®éªŒè¯ç»“æœ:")
            logger.info(f"  - xG æ•°æ®: {'âœ… æœ‰' if validation['has_xg'] else 'âŒ æ— '}")
            logger.info(f"  - é˜µå®¹æ•°æ®: {'âœ… æœ‰' if validation['has_lineup'] else 'âŒ æ— '}")
            logger.info(f"  - æŠ€æœ¯ç»Ÿè®¡: {'âœ… æœ‰' if validation['has_stats'] else 'âŒ æ— '}")

            if validation['key_fields']:
                logger.info(f"ğŸ¯ å‘ç°å…³é”®å­—æ®µ: {', '.join(validation['key_fields'])}")

            # æ‰“å°éƒ¨åˆ†æ•°æ®ç»“æ„
            self._print_data_structure(detail_result['data'])

        else:
            logger.error("âŒ æ— æ³•è·å–æ¯”èµ›è¯¦æƒ…")

    def _extract_match_id(self, match: dict) -> str | None:
        """æå–æ¯”èµ› ID"""
        if not match:
            return None

        # å¸¸è§çš„ ID å­—æ®µå
        id_fields = ['id', 'match_id', 'matchId', 'game_id', 'gameId', 'pk']

        for field in id_fields:
            if field in match:
                return str(match[field])

        return None

    def _print_data_structure(self, data: Any, depth: int = 0, max_depth: int = 3):
        """æ‰“å°æ•°æ®ç»“æ„ï¼ˆé™åˆ¶æ·±åº¦ï¼‰"""
        if depth > max_depth:
            return

        indent = "  " * depth

        if isinstance(data, dict):
            for key, value in data.items():
                if isinstance(value, (dict, list)):
                    logger.info(f"{indent}{key}:")
                    self._print_data_structure(value, depth + 1, max_depth)
                else:
                    # æˆªæ–­é•¿å­—ç¬¦ä¸²
                    if isinstance(value, str) and len(value) > 50:
                        value = value[:50] + "..."
                    logger.info(f"{indent}{key}: {value}")

        elif isinstance(data, list):
            if data:
                logger.info(f"{indent}List (é•¿åº¦: {len(data)}):")
                # åªæ˜¾ç¤ºå‰å‡ ä¸ªå…ƒç´ 
                for i, item in enumerate(data[:3]):
                    logger.info(f"{indent}[{i}]:")
                    self._print_data_structure(item, depth + 1, max_depth)
                if len(data) > 3:
                    logger.info(f"{indent}... (è¿˜æœ‰ {len(data) - 3} ä¸ªå…ƒç´ )")
            else:
                logger.info(f"{indent}ç©ºåˆ—è¡¨")
        else:
            logger.info(f"{indent}{data}")


async def main():
    """ä¸»å‡½æ•°"""
    probe = DongqiudiWebProbe()
    await probe.run_probe()


if __name__ == "__main__":
    asyncio.run(main())
