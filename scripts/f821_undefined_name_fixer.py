#!/usr/bin/env python3
"""
F821æœªå®šä¹‰åç§°æ‰¹é‡ä¿®å¤å·¥å…·
F821 Undefined Name Batch Fixer

ä¸“é—¨ç”¨äºæ‰¹é‡ä¿®å¤F821æœªå®šä¹‰åç§°é”™è¯¯ï¼Œé‡‡ç”¨æ™ºèƒ½åˆ†æ+æ‰¹é‡å¤„ç†ç­–ç•¥ï¼š
1. ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åç§°åˆ†æ
2. æ™ºèƒ½å¯¼å…¥å»ºè®®å’Œä¿®å¤
3. æ‰¹é‡å¤„ç†æ ¸å¿ƒæ¨¡å—
4. å®‰å…¨éªŒè¯æœºåˆ¶

ç›®æ ‡: è§£å†³~6,619ä¸ªF821é”™è¯¯ï¼Œæ¢å¤æ ¸å¿ƒåŠŸèƒ½
"""

import ast
import json
import logging
import re
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class F821NameFixer:
    """F821æœªå®šä¹‰åç§°ä¿®å¤å™¨"""

    def __init__(self):
        self.fixes_applied = 0
        self.files_processed = 0
        self.files_fixed = 0
        self.import_mappings = {}  # å­˜å‚¨å‘ç°çš„å¯¼å…¥æ˜ å°„

        # å¸¸è§çš„æœªå®šä¹‰åç§°å’Œå¯èƒ½çš„ä¿®å¤æ–¹æ¡ˆ
        self.common_fixes = {
            'APIRouter': {'module': 'fastapi', 'import_type': 'from'},
            'HTTPException': {'module': 'fastapi', 'import_type': 'from'},
            'Query': {'module': 'fastapi', 'import_type': 'from'},
            'logger': {'module': 'logging', 'import_type': 'from', 'name': 'get_logger'},
            'datetime': {'module': 'datetime', 'import_type': 'from'},
            'Dict': {'module': 'typing', 'import_type': 'from'},
            'List': {'module': 'typing', 'import_type': 'from'},
            'Optional': {'module': 'typing', 'import_type': 'from'},
            'BaseModel': {'module': 'pydantic', 'import_type': 'from'},
            'Field': {'module': 'pydantic', 'import_type': 'from'},
            'Depends': {'module': 'fastapi', 'import_type': 'from'},
            'BackgroundTasks': {'module': 'fastapi', 'import_type': 'from'},
        }

    def get_f821_errors(self, limit: Optional[int] = None) -> List[Dict]:
        """è·å–F821æœªå®šä¹‰åç§°é”™è¯¯"""
        logger.info("ğŸ¯ æ­£åœ¨è·å–F821æœªå®šä¹‰åç§°é”™è¯¯åˆ—è¡¨...")
        errors = []

        try:
            result = subprocess.run(
                ['ruff', 'check', '--select=F821', '--format=json'],
                capture_output=True,
                text=True,
                timeout=120
            )

            if result.stdout.strip():
                try:
                    error_data = json.loads(result.stdout)
                    for error in error_data:
                        if error.get('code') == 'F821':
                            errors.append({
                                'file': error['filename'],
                                'line': error['location']['row'],
                                'column': error['location']['column'],
                                'message': error['message'],
                                'code': 'F821',
                                'undefined_name': self.extract_undefined_name(error['message'])
                            })

                            if limit and len(errors) >= limit:
                                break

                except json.JSONDecodeError:
                    logger.warning("æ— æ³•è§£æRuff JSONè¾“å‡ºï¼Œä½¿ç”¨æ–‡æœ¬è§£æ")
                    # å¤‡ç”¨æ–‡æœ¬è§£ææ–¹æ³•
                    lines = result.stdout.split('\n')
                    for line in lines:
                        if 'F821' in line and 'undefined name' in line:
                            parts = line.split(':')
                            if len(parts) >= 4:
                                message = ':'.join(parts[3:]).strip()
                                errors.append({
                                    'file': parts[0],
                                    'line': int(parts[1]),
                                    'column': int(parts[2]),
                                    'message': message,
                                    'code': 'F821',
                                    'undefined_name': self.extract_undefined_name(message)
                                })

                                if limit and len(errors) >= limit:
                                    break

        except Exception as e:
            logger.error(f"è·å–F821é”™è¯¯å¤±è´¥: {e}")

        logger.info(f"ğŸ¯ å‘ç° {len(errors)} ä¸ªF821æœªå®šä¹‰åç§°é”™è¯¯")
        return errors

    def extract_undefined_name(self, message: str) -> str:
        """ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–æœªå®šä¹‰çš„åç§°"""
        # æ¶ˆæ¯æ ¼å¼é€šå¸¸æ˜¯: "undefined name 'NAME'"
        match = re.search(r"undefined name '([^']+)'", message)
        if match:
            return match.group(1)
        return ""

    def analyze_undefined_name(self, file_path: str, undefined_name: str, line_num: int) -> Dict:
        """åˆ†ææœªå®šä¹‰åç§°å¹¶ç”Ÿæˆä¿®å¤å»ºè®®"""
        analysis = {
            'name': undefined_name,
            'strategy': 'unknown',
            'suggested_import': None,
            'confidence': 0.0,
            'context': {}
        }

        # æ£€æŸ¥å¸¸è§ä¿®å¤æ˜ å°„
        if undefined_name in self.common_fixes:
            fix_info = self.common_fixes[undefined_name]
            analysis.update({
                'strategy': 'add_common_import',
                'suggested_import': fix_info,
                'confidence': 0.8,
                'context': {'source': 'common_fixes_mapping'}
            })
            return analysis

        # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®ä¸­å®šä¹‰çš„ç±»/å‡½æ•°
        project_fix = self.find_project_definition(undefined_name, file_path)
        if project_fix:
            analysis.update({
                'strategy': 'add_project_import',
                'suggested_import': project_fix,
                'confidence': 0.9,
                'context': {'source': 'project_search'}
            })
            return analysis

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹¼å†™é”™è¯¯
        similar_names = self.find_similar_names(undefined_name, file_path)
        if similar_names:
            analysis.update({
                'strategy': 'typo_correction',
                'suggested_fix': similar_names[0],
                'confidence': 0.6,
                'context': {'similar_names': similar_names}
            })
            return analysis

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ˜¯å±€éƒ¨å˜é‡
        if self.is_likely_local_variable(undefined_name, file_path, line_num):
            analysis.update({
                'strategy': 'local_variable',
                'confidence': 0.4,
                'context': {'suggestion': 'check_variable_scope'}
            })
            return analysis

        return analysis

    def find_project_definition(self, name: str, current_file: str) -> Optional[Dict]:
        """åœ¨é¡¹ç›®ä¸­æŸ¥æ‰¾å®šä¹‰"""
        project_root = Path(__file__).parent.parent
        src_dir = project_root / 'src'

        # å¸¸è§çš„é¡¹ç›®æ¨¡å—è·¯å¾„
        search_paths = [
            src_dir / 'core',
            src_dir / 'utils',
            src_dir / 'models',
            src_dir / 'database',
            src_dir / 'services',
            src_dir / 'api',
        ]

        for search_path in search_paths:
            if not search_path.exists():
                continue

            # æœç´¢Pythonæ–‡ä»¶ä¸­çš„å®šä¹‰
            for py_file in search_path.rglob('*.py'):
                if py_file == Path(current_file):
                    continue

                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # ç®€å•æœç´¢å®šä¹‰
                    patterns = [
                        rf'class\s+{name}\s*\(',
                        rf'def\s+{name}\s*\(',
                        rf'{name}\s*=',
                        rf'{name}\s*:'
                    ]

                    for pattern in patterns:
                        if re.search(pattern, content):
                            # è®¡ç®—ç›¸å¯¹å¯¼å…¥è·¯å¾„
                            relative_path = py_file.relative_to(src_dir)
                            module_path = str(relative_path.with_suffix('')).replace('/', '.')

                            return {
                                'module': f'src.{module_path}',
                                'import_type': 'from',
                                'name': name,
                                'file_path': str(py_file)
                            }

                except Exception as e:
                    logger.debug(f"æœç´¢æ–‡ä»¶ {py_file} å¤±è´¥: {e}")
                    continue

        return None

    def find_similar_names(self, name: str, file_path: str) -> List[str]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„åç§°ï¼ˆå¯èƒ½çš„æ‹¼å†™é”™è¯¯ï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–æ‰€æœ‰æ ‡è¯†ç¬¦
            tree = ast.parse(content)
            names = set()

            for node in ast.walk(tree):
                if isinstance(node, ast.Name):
                    names.add(node.id)
                elif isinstance(node, ast.FunctionDef):
                    names.add(node.name)
                elif isinstance(node, ast.ClassDef):
                    names.add(node.name)

            # æŸ¥æ‰¾ç›¸ä¼¼åç§°
            similar = []
            for existing_name in names:
                if existing_name != name and self.string_similarity(name, existing_name) > 0.7:
                    similar.append(existing_name)

            return sorted(similar, key=lambda x: self.string_similarity(name, x), reverse=True)

        except Exception as e:
            logger.debug(f"æŸ¥æ‰¾ç›¸ä¼¼åç§°å¤±è´¥: {e}")
            return []

    def string_similarity(self, s1: str, s2: str) -> float:
        """ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—"""
        if not s1 or not s2:
            return 0.0

        # ç¼–è¾‘è·ç¦»ç®—æ³•
        m, n = len(s1), len(s2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]

        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j

        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if s1[i-1] == s2[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1

        max_len = max(m, n)
        return 1 - dp[m][n] / max_len

    def is_likely_local_variable(self, name: str, file_path: str, line_num: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å±€éƒ¨å˜é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            # æ£€æŸ¥å‰é¢å‡ è¡Œæ˜¯å¦æœ‰å®šä¹‰
            for i in range(max(0, line_num - 10), line_num - 1):
                line = lines[i].strip()
                if f'{name} =' in line or f'for {name}' in line or f'def {name}' in line:
                    return True

            return False

        except Exception:
            return False

    def apply_fix(self, file_path: str, line_num: int, analysis: Dict) -> bool:
        """åº”ç”¨ä¿®å¤æ–¹æ¡ˆ"""
        strategy = analysis['strategy']

        if strategy == 'add_common_import' or strategy == 'add_project_import':
            return self.add_import_fix(file_path, analysis['suggested_import'])
        elif strategy == 'typo_correction':
            return self.fix_typo(file_path, line_num, analysis['suggested_fix'])
        else:
            logger.warning(f"æœªå®ç°çš„ä¿®å¤ç­–ç•¥: {strategy}")
            return False

    def add_import_fix(self, file_path: str, import_info: Dict) -> bool:
        """æ·»åŠ å¯¼å…¥ä¿®å¤"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.split('\n')

            # æ‰¾åˆ°å¯¼å…¥åŒºåŸŸ
            import_end = 0
            for i, line in enumerate(lines):
                if line.strip().startswith(('import ', 'from ')):
                    import_end = i + 1
                elif line.strip() and not line.startswith('#') and import_end > 0:
                    break

            # æ„å»ºå¯¼å…¥è¯­å¥
            module = import_info['module']
            name = import_info.get('name', import_info.get('suggested_name', module.split('.')[-1]))

            import_statement = f"from {module} import {name}"

            # æ·»åŠ å¯¼å…¥
            lines.insert(import_end, import_statement)

            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(lines))

            logger.info(f"âœ… æ·»åŠ å¯¼å…¥: {file_path} - {import_statement}")
            return True

        except Exception as e:
            logger.error(f"æ·»åŠ å¯¼å…¥å¤±è´¥ {file_path}: {e}")
            return False

    def fix_typo(self, file_path: str, line_num: int, correct_name: str) -> bool:
        """ä¿®å¤æ‹¼å†™é”™è¯¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            if line_num <= len(lines):
                original_line = lines[line_num - 1]
                # è¿™é‡Œéœ€è¦æ›´æ™ºèƒ½çš„æ›¿æ¢é€»è¾‘
                # æš‚æ—¶è·³è¿‡æ‹¼å†™é”™è¯¯ä¿®å¤
                logger.info(f"âš ï¸ è·³è¿‡æ‹¼å†™é”™è¯¯ä¿®å¤: {file_path}:{line_num} - {original_line.strip()}")
                return False

        except Exception as e:
            logger.error(f"ä¿®å¤æ‹¼å†™é”™è¯¯å¤±è´¥ {file_path}:{line_num}: {e}")
            return False

    def run_batch_f821_fix(self, batch_size: int = 50) -> Dict:
        """è¿è¡Œæ‰¹é‡F821ä¿®å¤"""
        logger.info("ğŸ¯ å¼€å§‹F821æœªå®šä¹‰åç§°æ‰¹é‡ä¿®å¤...")

        # åˆ†æ‰¹å¤„ç†é”™è¯¯
        all_errors = self.get_f821_errors()
        total_errors = len(all_errors)

        if not all_errors:
            logger.info("âœ… æ²¡æœ‰å‘ç°F821é”™è¯¯")
            return {
                'success': True,
                'errors_fixed': 0,
                'files_processed': 0,
                'files_fixed': 0,
                'message': 'æ²¡æœ‰F821é”™è¯¯éœ€è¦ä¿®å¤'
            }

        # æŒ‰æ ¸å¿ƒæ¨¡å—ä¼˜å…ˆçº§æ’åº
        core_modules = ['src/api/', 'src/core/', 'src/utils/']
        prioritized_errors = []

        for module in core_modules:
            module_errors = [e for e in all_errors if module in e['file']]
            prioritized_errors.extend(module_errors)

        # æ·»åŠ å…¶ä»–é”™è¯¯
        other_errors = [e for e in all_errors if not any(module in e['file'] for module in core_modules)]
        prioritized_errors.extend(other_errors)

        # å¤„ç†æŒ‡å®šæ‰¹æ¬¡çš„é”™è¯¯
        errors_to_process = prioritized_errors[:batch_size]

        # æŒ‰æ–‡ä»¶åˆ†ç»„
        errors_by_file = {}
        for error in errors_to_process:
            file_path = error['file']
            if file_path not in errors_by_file:
                errors_by_file[file_path] = []
            errors_by_file[file_path].append(error)

        # ä¿®å¤æ¯ä¸ªæ–‡ä»¶
        files_fixed = 0
        total_errors_fixed = 0

        for file_path, file_errors in errors_by_file.items():
            logger.info(f"ğŸ”§ æ­£åœ¨ä¿®å¤æ–‡ä»¶: {file_path} ({len(file_errors)}ä¸ªé”™è¯¯)")

            file_fixed = False
            for error in file_errors:
                undefined_name = error['undefined_name']
                line_num = error['line']

                # åˆ†æé”™è¯¯
                analysis = self.analyze_undefined_name(file_path, undefined_name, line_num)
                logger.info(f"ğŸ“‹ é”™è¯¯åˆ†æ: {undefined_name} -> {analysis['strategy']} (confidence: {analysis['confidence']})")

                # åº”ç”¨ä¿®å¤
                if analysis['confidence'] > 0.6:  # åªåº”ç”¨é«˜ç½®ä¿¡åº¦çš„ä¿®å¤
                    if self.apply_fix(file_path, line_num, analysis):
                        total_errors_fixed += 1
                        file_fixed = True
                        self.fixes_applied += 1

            if file_fixed:
                files_fixed += 1

            self.files_processed += 1

        result = {
            'success': total_errors_fixed > 0,
            'total_errors': total_errors,
            'processed_errors': len(errors_to_process),
            'errors_fixed': total_errors_fixed,
            'files_processed': self.files_processed,
            'files_fixed': files_fixed,
            'remaining_errors': total_errors - total_errors_fixed,
            'fix_rate': f"{(total_errors_fixed / max(len(errors_to_process), 1)) * 100:.1f}%",
            'message': f'å¤„ç†äº† {len(errors_to_process)} ä¸ªé”™è¯¯ï¼Œä¿®å¤äº† {total_errors_fixed} ä¸ªï¼Œ{total_errors - total_errors_fixed} ä¸ªå‰©ä½™'
        }

        logger.info(f"ğŸ¯ F821æ‰¹é‡ä¿®å¤å®Œæˆ: {result}")
        return result

    def generate_progress_report(self) -> Dict:
        """ç”Ÿæˆè¿›åº¦æŠ¥å‘Š"""
        return {
            'fixer_name': 'F821 Undefined Name Batch Fixer',
            'timestamp': '2025-10-30T02:30:00.000000',
            'target_errors': '~6,619',
            'fixes_applied': self.fixes_applied,
            'files_processed': self.files_processed,
            'files_fixed': self.files_fixed,
            'success_rate': f"{(self.files_fixed / max(self.files_processed, 1)) * 100:.1f}%",
            'next_steps': 'ç»§ç»­æ‰¹é‡å¤„ç†å‰©ä½™çš„F821é”™è¯¯ï¼Œç„¶åè½¬å‘å…¶ä»–é”™è¯¯ç±»å‹'
        }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ F821 æœªå®šä¹‰åç§°æ‰¹é‡ä¿®å¤å·¥å…·")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡: ~6,619ä¸ªF821é”™è¯¯ | æ ¸å¿ƒæ¨¡å—ä¼˜å…ˆ")
    print("=" * 60)

    fixer = F821NameFixer()

    # è¿è¡Œæ‰¹é‡ä¿®å¤ï¼ˆå…ˆå¤„ç†50ä¸ªæµ‹è¯•ï¼‰
    result = fixer.run_batch_f821_fix(batch_size=50)

    # ç”ŸæˆæŠ¥å‘Š
    report = fixer.generate_progress_report()

    print("\nğŸ“Š æ‰¹é‡ä¿®å¤æ‘˜è¦:")
    print(f"   æ€»é”™è¯¯æ•°: {result['total_errors']}")
    print(f"   å¤„ç†é”™è¯¯æ•°: {result['processed_errors']}")
    print(f"   ä¿®å¤é”™è¯¯æ•°: {result['errors_fixed']}")
    print(f"   å‰©ä½™é”™è¯¯æ•°: {result['remaining_errors']}")
    print(f"   å¤„ç†æ–‡ä»¶æ•°: {result['files_processed']}")
    print(f"   ä¿®å¤æ–‡ä»¶æ•°: {result['files_fixed']}")
    print(f"   ä¿®å¤ç‡: {result['fix_rate']}")
    print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if result['success'] else 'âš ï¸ éœ€è¦æ›´å¤šå¤„ç†'}")

    # ä¿å­˜è¿›åº¦æŠ¥å‘Š
    report_file = Path('f821_batch_fix_progress.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            'result': result,
            'report': report
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ è¿›åº¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    if result['remaining_errors'] > 0:
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: ç»§ç»­å¤„ç†å‰©ä½™ {result['remaining_errors']} ä¸ªF821é”™è¯¯")
        print("ğŸ’¡ å»ºè®®: è¿è¡Œ 'python3 scripts/f821_undefined_name_fixer.py' ç»§ç»­æ‰¹é‡ä¿®å¤")

    return result


if __name__ == '__main__':
    main()