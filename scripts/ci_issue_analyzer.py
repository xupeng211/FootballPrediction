#!/usr/bin/env python3
"""
CIé—®é¢˜æ™ºèƒ½åˆ†æå™¨ - æ·±åº¦åˆ†æCIå¤±è´¥åŸå› å¹¶æä¾›ç²¾ç¡®è§£å†³æ–¹æ¡ˆ

è¿™ä¸ªæ¨¡å—ä¸“é—¨è´Ÿè´£ï¼š
1. æ·±åº¦è§£æå„ç§CIå·¥å…·çš„è¾“å‡ºæ ¼å¼
2. æ™ºèƒ½åˆ†ç±»CIé—®é¢˜å¹¶è¯„ä¼°å½±å“ç¨‹åº¦
3. æä¾›é’ˆå¯¹æ€§çš„è§£å†³æ–¹æ¡ˆå»ºè®®
4. ç”Ÿæˆé—®é¢˜è¶‹åŠ¿åˆ†ææŠ¥å‘Š

ä½œè€…ï¼šAI CI Guardian System
ç‰ˆæœ¬ï¼šv1.0.0
"""

import json
import re
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import click


class CIToolOutput:
    """CIå·¥å…·è¾“å‡ºè§£æå™¨åŸºç±»"""

    def parse(self, output: str) -> List[Dict]:
        """è§£æå·¥å…·è¾“å‡ºå¹¶è¿”å›æ ‡å‡†åŒ–çš„é—®é¢˜åˆ—è¡¨"""
        raise NotImplementedError


class RuffOutputParser(CIToolOutput):
    """Ruffä»£ç æ£€æŸ¥è¾“å‡ºè§£æå™¨"""

    def parse(self, output: str) -> List[Dict]:
        """è§£æRuffè¾“å‡º"""
        issues = []

        # Ruffè¾“å‡ºæ ¼å¼: path/to/file.py:line:col: CODE message
        pattern = r"([^:]+):(\d+):(\d+): (\w+) (.+)"

        for line in output.split("\n"):
            match = re.match(pattern, line.strip())
            if match:
                file_path, line_num, col_num, code, message = match.groups()

                issues.append(
                    {
                        "tool": "ruff",
                        "file_path": file_path,
                        "line_number": int(line_num),
                        "column": int(col_num),
                        "rule_code": code,
                        "message": message,
                        "severity": self._get_ruff_severity(code),
                        "category": self._get_ruff_category(code),
                    }
                )

        return issues

    def _get_ruff_severity(self, code: str) -> str:
        """æ ¹æ®Ruffè§„åˆ™ä»£ç ç¡®å®šä¸¥é‡ç¨‹åº¦"""
        if code.startswith(("E9", "F")):  # è¯­æ³•é”™è¯¯ã€æœªå®šä¹‰åç§°
            return "high"
        elif code.startswith(("E", "W")):  # ä¸€èˆ¬é”™è¯¯å’Œè­¦å‘Š
            return "medium"
        else:
            return "low"

    def _get_ruff_category(self, code: str) -> str:
        """æ ¹æ®Ruffè§„åˆ™ä»£ç ç¡®å®šé—®é¢˜åˆ†ç±»"""
        if code.startswith("F"):
            return "logic_error"
        elif code.startswith("E"):
            return "style_error"
        elif code.startswith("W"):
            return "style_warning"
        elif code.startswith("I"):
            return "import_issue"
        else:
            return "other"


class MyPyOutputParser(CIToolOutput):
    """MyPyç±»å‹æ£€æŸ¥è¾“å‡ºè§£æå™¨"""

    def parse(self, output: str) -> List[Dict]:
        """è§£æMyPyè¾“å‡º"""
        issues = []

        # MyPyè¾“å‡ºæ ¼å¼: path/to/file.py:line: error: message
        pattern = r"([^:]+):(\d+): (\w+): (.+)"

        for line in output.split("\n"):
            match = re.match(pattern, line.strip())
            if match:
                file_path, line_num, level, message = match.groups()

                issues.append(
                    {
                        "tool": "mypy",
                        "file_path": file_path,
                        "line_number": int(line_num),
                        "level": level,
                        "message": message,
                        "severity": "high" if level == "error" else "medium",
                        "category": self._get_mypy_category(message),
                    }
                )

        return issues

    def _get_mypy_category(self, message: str) -> str:
        """æ ¹æ®MyPyé”™è¯¯ä¿¡æ¯ç¡®å®šé—®é¢˜åˆ†ç±»"""
        if "incompatible types" in message.lower():
            return "type_mismatch"
        elif "missing type annotation" in message.lower():
            return "missing_annotation"
        elif "has no attribute" in message.lower():
            return "attribute_error"
        elif "cannot determine type" in message.lower():
            return "type_inference_failed"
        else:
            return "type_error"


class PytestOutputParser(CIToolOutput):
    """Pytestæµ‹è¯•è¾“å‡ºè§£æå™¨"""

    def parse(self, output: str) -> List[Dict]:
        """è§£æPytestè¾“å‡º"""
        issues = []

        # è§£æå¤±è´¥çš„æµ‹è¯•
        in_failure_section = False
        current_test = None
        failure_lines = []

        for line in output.split("\n"):
            # æ£€æµ‹å¤±è´¥æµ‹è¯•å¼€å§‹
            if "= FAILURES =" in line:
                in_failure_section = True
                continue

            # æ£€æµ‹å¤±è´¥æµ‹è¯•ç»“æŸ
            if line.startswith("=") and "short test summary" in line:
                in_failure_section = False
                if current_test and failure_lines:
                    issues.append(self._parse_test_failure(current_test, failure_lines))
                break

            if in_failure_section:
                # è§£ææµ‹è¯•åç§°
                if line.startswith("_" * 20):
                    if current_test and failure_lines:
                        issues.append(
                            self._parse_test_failure(current_test, failure_lines)
                        )

                    # æå–æ–°çš„æµ‹è¯•åç§°
                    test_match = re.search(r"([^:]+)::\w+::(test_\w+)", line)
                    if test_match:
                        current_test = {
                            "file_path": test_match.group(1),
                            "test_name": test_match.group(2),
                        }
                        failure_lines = []
                elif current_test:
                    failure_lines.append(line)

        # å¤„ç†æœ€åä¸€ä¸ªå¤±è´¥æµ‹è¯•
        if current_test and failure_lines:
            issues.append(self._parse_test_failure(current_test, failure_lines))

        return issues

    def _parse_test_failure(self, test_info: Dict, failure_lines: List[str]) -> Dict:
        """è§£æå•ä¸ªæµ‹è¯•å¤±è´¥ä¿¡æ¯"""
        failure_text = "\n".join(failure_lines)

        # æ£€æµ‹æ–­è¨€é”™è¯¯
        assert_match = re.search(r"assert (.+)", failure_text)
        assertion = assert_match.group(1) if assert_match else ""

        # æ£€æµ‹å¼‚å¸¸ç±»å‹
        exception_match = re.search(r"(\w+Error): (.+)", failure_text)
        exception_type = (
            exception_match.group(1) if exception_match else "AssertionError"
        )
        exception_message = exception_match.group(2) if exception_match else ""

        return {
            "tool": "pytest",
            "file_path": test_info["file_path"],
            "test_name": test_info["test_name"],
            "assertion": assertion,
            "exception_type": exception_type,
            "exception_message": exception_message,
            "failure_text": failure_text,
            "severity": "high",
            "category": self._get_test_failure_category(exception_type, failure_text),
        }

    def _get_test_failure_category(self, exception_type: str, failure_text: str) -> str:
        """æ ¹æ®æµ‹è¯•å¤±è´¥ä¿¡æ¯ç¡®å®šé—®é¢˜åˆ†ç±»"""
        if "ImportError" in exception_type or "ModuleNotFoundError" in exception_type:
            return "import_error"
        elif "AssertionError" in exception_type:
            return "assertion_failure"
        elif "AttributeError" in exception_type:
            return "attribute_error"
        elif "TypeError" in exception_type:
            return "type_error"
        else:
            return "test_failure"


class BanditOutputParser(CIToolOutput):
    """Banditå®‰å…¨æ£€æŸ¥è¾“å‡ºè§£æå™¨"""

    def parse(self, output: str) -> List[Dict]:
        """è§£æBanditè¾“å‡º"""
        issues = []

        # Bandité€šå¸¸è¾“å‡ºJSONæ ¼å¼ï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯æ–‡æœ¬æ ¼å¼
        try:
            # å°è¯•è§£æJSONæ ¼å¼
            data = json.loads(output)
            if "results" in data:
                for result in data["results"]:
                    issues.append(
                        {
                            "tool": "bandit",
                            "file_path": result.get("filename", ""),
                            "line_number": result.get("line_number", 0),
                            "test_id": result.get("test_id", ""),
                            "test_name": result.get("test_name", ""),
                            "issue_text": result.get("issue_text", ""),
                            "issue_severity": result.get("issue_severity", "MEDIUM"),
                            "issue_confidence": result.get(
                                "issue_confidence", "MEDIUM"
                            ),
                            "severity": self._get_bandit_severity(
                                result.get("issue_severity", "MEDIUM")
                            ),
                            "category": "security_issue",
                        }
                    )
        except json.JSONDecodeError:
            # è§£ææ–‡æœ¬æ ¼å¼
            pattern = r">> Issue: \[([^\]]+)\] (.+)"
            for line in output.split("\n"):
                match = re.search(pattern, line)
                if match:
                    test_id, description = match.groups()
                    issues.append(
                        {
                            "tool": "bandit",
                            "test_id": test_id,
                            "description": description,
                            "severity": "medium",
                            "category": "security_issue",
                        }
                    )

        return issues

    def _get_bandit_severity(self, bandit_severity: str) -> str:
        """è½¬æ¢Banditä¸¥é‡ç¨‹åº¦åˆ°æ ‡å‡†æ ¼å¼"""
        severity_map = {"HIGH": "high", "MEDIUM": "medium", "LOW": "low"}
        return severity_map.get(bandit_severity.upper(), "medium")


class CoverageOutputParser(CIToolOutput):
    """Coverageè¦†ç›–ç‡è¾“å‡ºè§£æå™¨"""

    def parse(self, output: str) -> List[Dict]:
        """è§£æCoverageè¾“å‡º"""
        issues = []

        # è§£æè¦†ç›–ç‡æ‘˜è¦
        pattern = r"TOTAL\s+\d+\s+\d+\s+(\d+)%"
        match = re.search(pattern, output)
        if match:
            total_coverage = int(match.group(1))

            if total_coverage < 80:  # å‡è®¾80%æ˜¯æœ€ä½è¦æ±‚
                issues.append(
                    {
                        "tool": "coverage",
                        "message": f"æ€»è¦†ç›–ç‡ {total_coverage}% ä½äºè¦æ±‚çš„80%",
                        "total_coverage": total_coverage,
                        "severity": "high" if total_coverage < 60 else "medium",
                        "category": "coverage_low",
                    }
                )

        # è§£æå…·ä½“æ–‡ä»¶çš„è¦†ç›–ç‡
        file_pattern = r"([^\s]+\.py)\s+\d+\s+\d+\s+(\d+)%"
        for line in output.split("\n"):
            match = re.search(file_pattern, line)
            if match:
                file_path, coverage = match.groups()
                coverage_pct = int(coverage)

                if coverage_pct < 80:
                    issues.append(
                        {
                            "tool": "coverage",
                            "file_path": file_path,
                            "coverage_percentage": coverage_pct,
                            "message": f"{file_path} è¦†ç›–ç‡ {coverage_pct}% è¿‡ä½",
                            "severity": "medium",
                            "category": "file_coverage_low",
                        }
                    )

        return issues


class CIAnalyzer:
    """CIé—®é¢˜æ™ºèƒ½åˆ†æå™¨ä¸»æ§åˆ¶å™¨"""

    def __init__(self, project_root: Path = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.parsers = {
            "ruff": RuffOutputParser(),
            "mypy": MyPyOutputParser(),
            "pytest": PytestOutputParser(),
            "bandit": BanditOutputParser(),
            "coverage": CoverageOutputParser(),
        }

    def analyze_tool_output(self, tool_name: str, output: str) -> List[Dict]:
        """åˆ†æç‰¹å®šå·¥å…·çš„è¾“å‡º"""
        parser = self.parsers.get(tool_name.lower())
        if not parser:
            click.echo(f"âš ï¸ ä¸æ”¯æŒçš„å·¥å…·: {tool_name}")
            return []

        return parser.parse(output)

    def analyze_quality_check_log(self, log_file: Path = None) -> Dict[str, List[Dict]]:
        """åˆ†æè´¨é‡æ£€æŸ¥æ—¥å¿—æ–‡ä»¶"""
        if not log_file:
            log_file = self.project_root / "logs" / "quality_check.json"

        if not log_file.exists():
            click.echo(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            return {}

        try:
            with open(log_file, "r", encoding="utf-8") as f:
                log_data = json.load(f)
        except Exception as e:
            click.echo(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
            return {}

        all_issues = {}

        if "checks" in log_data:
            for check_name, check_data in log_data["checks"].items():
                if not check_data.get("success", True):
                    output = check_data.get("output", "")
                    issues = self.analyze_tool_output(check_name, output)
                    if issues:
                        all_issues[check_name] = issues

        return all_issues

    def generate_problem_analysis_report(
        self, issues_by_tool: Dict[str, List[Dict]]
    ) -> Dict:
        """ç”Ÿæˆé—®é¢˜åˆ†ææŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_issues": 0,
                "by_severity": defaultdict(int),
                "by_category": defaultdict(int),
                "by_tool": defaultdict(int),
            },
            "detailed_analysis": {},
            "recommendations": [],
        }

        all_issues = []
        for tool, issues in issues_by_tool.items():
            all_issues.extend(issues)
            report["summary"]["by_tool"][tool] = len(issues)

        report["summary"]["total_issues"] = len(all_issues)

        # ç»Ÿè®¡åˆ†æ
        for issue in all_issues:
            severity = issue.get("severity", "medium")
            category = issue.get("category", "other")

            report["summary"]["by_severity"][severity] += 1
            report["summary"]["by_category"][category] += 1

        # è¯¦ç»†åˆ†æ
        report["detailed_analysis"] = self._generate_detailed_analysis(issues_by_tool)

        # ç”Ÿæˆå»ºè®®
        report["recommendations"] = self._generate_recommendations(issues_by_tool)

        return report

    def _generate_detailed_analysis(
        self, issues_by_tool: Dict[str, List[Dict]]
    ) -> Dict:
        """ç”Ÿæˆè¯¦ç»†åˆ†æ"""
        analysis = {}

        for tool, issues in issues_by_tool.items():
            tool_analysis = {
                "issue_count": len(issues),
                "severity_distribution": defaultdict(int),
                "common_problems": defaultdict(int),
                "affected_files": set(),
            }

            for issue in issues:
                severity = issue.get("severity", "medium")
                category = issue.get("category", "other")
                file_path = issue.get("file_path", "")

                tool_analysis["severity_distribution"][severity] += 1
                tool_analysis["common_problems"][category] += 1

                if file_path:
                    tool_analysis["affected_files"].add(file_path)

            # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
            tool_analysis["affected_files"] = list(tool_analysis["affected_files"])

            analysis[tool] = tool_analysis

        return analysis

    def _generate_recommendations(
        self, issues_by_tool: Dict[str, List[Dict]]
    ) -> List[Dict]:
        """ç”Ÿæˆè§£å†³å»ºè®®"""
        recommendations = []

        for tool, issues in issues_by_tool.items():
            if tool == "ruff":
                recommendations.extend(self._generate_ruff_recommendations(issues))
            elif tool == "mypy":
                recommendations.extend(self._generate_mypy_recommendations(issues))
            elif tool == "pytest":
                recommendations.extend(self._generate_pytest_recommendations(issues))
            elif tool == "bandit":
                recommendations.extend(self._generate_bandit_recommendations(issues))
            elif tool == "coverage":
                recommendations.extend(self._generate_coverage_recommendations(issues))

        return recommendations

    def _generate_ruff_recommendations(self, issues: List[Dict]) -> List[Dict]:
        """ç”ŸæˆRuffé—®é¢˜çš„è§£å†³å»ºè®®"""
        recommendations = []

        # æŒ‰é—®é¢˜ç±»å‹åˆ†ç»„
        by_category = defaultdict(list)
        for issue in issues:
            by_category[issue.get("category", "other")].append(issue)

        if "style_error" in by_category:
            recommendations.append(
                {
                    "tool": "ruff",
                    "category": "style_error",
                    "priority": "high",
                    "action": "auto_fix",
                    "description": "è¿è¡Œ ruff --fix è‡ªåŠ¨ä¿®å¤ä»£ç é£æ ¼é—®é¢˜",
                    "command": "ruff check --fix src/ tests/",
                    "affected_count": len(by_category["style_error"]),
                }
            )

        if "import_issue" in by_category:
            recommendations.append(
                {
                    "tool": "ruff",
                    "category": "import_issue",
                    "priority": "medium",
                    "action": "reorganize_imports",
                    "description": "é‡æ–°æ•´ç†importè¯­å¥çš„é¡ºåºå’Œåˆ†ç»„",
                    "command": "ruff check --select I --fix src/ tests/",
                    "affected_count": len(by_category["import_issue"]),
                }
            )

        return recommendations

    def _generate_mypy_recommendations(self, issues: List[Dict]) -> List[Dict]:
        """ç”ŸæˆMyPyé—®é¢˜çš„è§£å†³å»ºè®®"""
        recommendations = []

        by_category = defaultdict(list)
        for issue in issues:
            by_category[issue.get("category", "other")].append(issue)

        if "missing_annotation" in by_category:
            recommendations.append(
                {
                    "tool": "mypy",
                    "category": "missing_annotation",
                    "priority": "medium",
                    "action": "add_type_annotations",
                    "description": "ä¸ºç¼ºå°‘ç±»å‹æ³¨è§£çš„å‡½æ•°å’Œå˜é‡æ·»åŠ ç±»å‹æ³¨è§£",
                    "affected_count": len(by_category["missing_annotation"]),
                    "suggestion": "ä½¿ç”¨ typing æ¨¡å—ä¸­çš„ç±»å‹ï¼Œå¦‚ Dict, List, Optional ç­‰",
                }
            )

        if "type_mismatch" in by_category:
            recommendations.append(
                {
                    "tool": "mypy",
                    "category": "type_mismatch",
                    "priority": "high",
                    "action": "fix_type_errors",
                    "description": "ä¿®å¤ç±»å‹ä¸åŒ¹é…é”™è¯¯ï¼Œç¡®ä¿å˜é‡ç±»å‹ä¸€è‡´",
                    "affected_count": len(by_category["type_mismatch"]),
                }
            )

        return recommendations

    def _generate_pytest_recommendations(self, issues: List[Dict]) -> List[Dict]:
        """ç”ŸæˆPytesté—®é¢˜çš„è§£å†³å»ºè®®"""
        recommendations = []

        by_category = defaultdict(list)
        for issue in issues:
            by_category[issue.get("category", "other")].append(issue)

        if "assertion_failure" in by_category:
            recommendations.append(
                {
                    "tool": "pytest",
                    "category": "assertion_failure",
                    "priority": "high",
                    "action": "fix_test_logic",
                    "description": "æ£€æŸ¥æµ‹è¯•é€»è¾‘ï¼Œç¡®ä¿æ–­è¨€æ¡ä»¶æ­£ç¡®",
                    "affected_count": len(by_category["assertion_failure"]),
                }
            )

        if "import_error" in by_category:
            recommendations.append(
                {
                    "tool": "pytest",
                    "category": "import_error",
                    "priority": "high",
                    "action": "fix_imports",
                    "description": "ä¿®å¤æµ‹è¯•æ–‡ä»¶ä¸­çš„å¯¼å…¥é”™è¯¯ï¼Œæ£€æŸ¥æ¨¡å—è·¯å¾„",
                    "affected_count": len(by_category["import_error"]),
                }
            )

        return recommendations

    def _generate_bandit_recommendations(self, issues: List[Dict]) -> List[Dict]:
        """ç”ŸæˆBandité—®é¢˜çš„è§£å†³å»ºè®®"""
        recommendations = []

        if issues:
            recommendations.append(
                {
                    "tool": "bandit",
                    "category": "security_issue",
                    "priority": "high",
                    "action": "fix_security_issues",
                    "description": "ä¿®å¤å®‰å…¨æ¼æ´ï¼Œé¿å…ä½¿ç”¨ä¸å®‰å…¨çš„å‡½æ•°å’Œæ¨¡å¼",
                    "affected_count": len(issues),
                    "suggestion": "æ£€æŸ¥ç¡¬ç¼–ç å¯†ç ã€ä¸å®‰å…¨çš„éšæœºæ•°ç”Ÿæˆã€SQLæ³¨å…¥é£é™©ç­‰",
                }
            )

        return recommendations

    def _generate_coverage_recommendations(self, issues: List[Dict]) -> List[Dict]:
        """ç”ŸæˆCoverageé—®é¢˜çš„è§£å†³å»ºè®®"""
        recommendations = []

        low_coverage_files = [
            issue for issue in issues if issue.get("category") == "file_coverage_low"
        ]

        if low_coverage_files:
            recommendations.append(
                {
                    "tool": "coverage",
                    "category": "coverage_low",
                    "priority": "medium",
                    "action": "increase_test_coverage",
                    "description": "ä¸ºè¦†ç›–ç‡ä½çš„æ–‡ä»¶æ·»åŠ æ›´å¤šæµ‹è¯•ç”¨ä¾‹",
                    "affected_count": len(low_coverage_files),
                    "affected_files": [
                        issue.get("file_path") for issue in low_coverage_files
                    ],
                }
            )

        return recommendations


@click.command()
@click.option("--tool", "-t", help="åˆ†æç‰¹å®šå·¥å…·çš„è¾“å‡º (ruff, mypy, pytest, bandit, coverage)")
@click.option("--input-file", "-i", help="è¾“å…¥æ–‡ä»¶è·¯å¾„ (å·¥å…·è¾“å‡ºæˆ–æ—¥å¿—æ–‡ä»¶)")
@click.option("--output", "-o", help="è¾“å‡ºåˆ†ææŠ¥å‘Šçš„æ–‡ä»¶è·¯å¾„")
@click.option("--log-file", "-l", help="è´¨é‡æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·¯å¾„")
@click.option("--summary", "-s", is_flag=True, help="æ˜¾ç¤ºåˆ†ææ‘˜è¦")
@click.option("--recommendations", "-r", is_flag=True, help="æ˜¾ç¤ºè§£å†³å»ºè®®")
@click.option("--project-root", "-p", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
def main(tool, input_file, output, log_file, summary, recommendations, project_root):
    """
    ğŸ” CIé—®é¢˜æ™ºèƒ½åˆ†æå™¨

    æ·±åº¦åˆ†æCIå·¥å…·è¾“å‡ºï¼Œæä¾›ç²¾ç¡®çš„é—®é¢˜åˆ†ç±»å’Œè§£å†³æ–¹æ¡ˆå»ºè®®ã€‚

    Examples:
        ci_issue_analyzer.py -l logs/quality_check.json -s
        ci_issue_analyzer.py -t ruff -i ruff_output.txt -r
        ci_issue_analyzer.py -s -r -o analysis_report.json
    """

    project_path = Path(project_root) if project_root else Path.cwd()
    analyzer = CIAnalyzer(project_path)

    click.echo("ğŸ” CIé—®é¢˜æ™ºèƒ½åˆ†æå™¨å¯åŠ¨")

    if tool and input_file:
        # åˆ†æç‰¹å®šå·¥å…·çš„è¾“å‡ºæ–‡ä»¶
        input_path = Path(input_file)
        if not input_path.exists():
            click.echo(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return

        with open(input_path, "r", encoding="utf-8") as f:
            content = f.read()

        issues = analyzer.analyze_tool_output(tool, content)
        click.echo(f"ğŸ“Š ä» {tool} è¾“å‡ºä¸­æ£€æµ‹åˆ° {len(issues)} ä¸ªé—®é¢˜")

        if summary:
            for issue in issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                click.echo(
                    f"  - {issue.get('severity', 'unknown').upper()}: {issue.get('message', '')}"
                )

        issues_by_tool = {tool: issues}

    elif log_file or Path(project_path / "logs" / "quality_check.json").exists():
        # åˆ†æè´¨é‡æ£€æŸ¥æ—¥å¿—
        log_path = (
            Path(log_file) if log_file else project_path / "logs" / "quality_check.json"
        )
        issues_by_tool = analyzer.analyze_quality_check_log(log_path)

        total_issues = sum(len(issues) for issues in issues_by_tool.values())
        click.echo(f"ğŸ“Š ä»æ—¥å¿—ä¸­æ£€æµ‹åˆ° {total_issues} ä¸ªé—®é¢˜ï¼Œæ¶‰åŠ {len(issues_by_tool)} ä¸ªå·¥å…·")

    else:
        click.echo("âŒ è¯·æŒ‡å®šè¾“å…¥æ–‡ä»¶ (-i) æˆ–æ—¥å¿—æ–‡ä»¶ (-l)")
        return

    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    if issues_by_tool:
        report = analyzer.generate_problem_analysis_report(issues_by_tool)

        if summary:
            click.echo("\nğŸ“‹ é—®é¢˜æ‘˜è¦:")
            click.echo(f"  æ€»é—®é¢˜æ•°: {report['summary']['total_issues']}")
            click.echo("  ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:")
            for severity, count in report["summary"]["by_severity"].items():
                click.echo(f"    {severity}: {count}")
            click.echo("  å·¥å…·åˆ†å¸ƒ:")
            for tool, count in report["summary"]["by_tool"].items():
                click.echo(f"    {tool}: {count}")

        if recommendations:
            click.echo("\nğŸ’¡ è§£å†³å»ºè®®:")
            for rec in report["recommendations"]:
                priority = rec.get("priority", "medium")
                description = rec.get("description", "")
                click.echo(f"  [{priority.upper()}] {description}")
                if "command" in rec:
                    click.echo(f"    å‘½ä»¤: {rec['command']}")
                if "affected_count" in rec:
                    click.echo(f"    å½±å“: {rec['affected_count']} ä¸ªé—®é¢˜")

        # ä¿å­˜æŠ¥å‘Š
        if output:
            output_path = Path(output)
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            click.echo(f"ğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")

    else:
        click.echo("â„¹ï¸ æ²¡æœ‰æ£€æµ‹åˆ°CIé—®é¢˜")


if __name__ == "__main__":
    main()
