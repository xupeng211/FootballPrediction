#!/usr/bin/env python3
"""
XGBoosté«˜çº§æ¨¡å‹è®­ç»ƒè„šæœ¬ - V3ç‰ˆæœ¬
Chief Data Scientist: åŸºäºEWMAç‰¹å¾è®­ç»ƒé«˜æ€§èƒ½é¢„æµ‹æ¨¡å‹

æ ¸å¿ƒåŠŸèƒ½:
- åŠ è½½é«˜çº§ç‰¹å¾æ•°æ®é›†
- è®­ç»ƒå¤šç›®æ ‡XGBoostæ¨¡å‹
- ç‰¹å¾é‡è¦æ€§åˆ†æ
- æ¨¡å‹æ€§èƒ½è¯„ä¼°
"""

import os
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

try:
    import matplotlib.pyplot as plt

    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    logger.warning("âš ï¸ matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å¯è§†åŒ–ç”Ÿæˆ")

try:
    import seaborn as sns

    SEABORN_AVAILABLE = True
except ImportError:
    SEABORN_AVAILABLE = False
from datetime import datetime
import json
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)


class AdvancedXGBoostTrainer:
    """é«˜çº§XGBoostæ¨¡å‹è®­ç»ƒå™¨"""

    def __init__(self):
        self.models = {}
        self.feature_importance = {}
        self.label_encoders = {}
        self.evaluation_results = {}

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("/app/models", exist_ok=True)
        os.makedirs("/app/results", exist_ok=True)

        logger.info("ğŸ§  é«˜çº§XGBoostè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")

    def load_features_data(
        self, file_path: str = "/app/data/advanced_features.csv"
    ) -> pd.DataFrame:
        """åŠ è½½ç‰¹å¾æ•°æ®"""
        logger.info(f"ğŸ“Š åŠ è½½ç‰¹å¾æ•°æ®: {file_path}")

        df = pd.read_csv(file_path)
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
        logger.info(f"   ç‰¹å¾åˆ—: {list(df.columns)}")

        return df

    def prepare_features_and_targets(
        self, df: pd.DataFrame
    ) -> tuple[pd.DataFrame, dict[str, pd.Series]]:
        """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
        logger.info("âš™ï¸ å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡...")

        # è¯†åˆ«ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—
        exclude_cols = [
            "match_id",
            "match_date",
            "result",
            "home_score",
            "away_score",
            "goal_difference",
            "total_goals",
            "over_2_5_goals",
            "both_teams_score",
        ]

        feature_cols = [col for col in df.columns if col not in exclude_cols]

        # å¤„ç†ç¼ºå¤±å€¼ - å¡«å……seasonåˆ—
        df_clean = df.copy()
        if "season" in df_clean.columns:
            df_clean["season"] = df_clean["season"].fillna("2024")

        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½æ˜¯æ•°å€¼å‹
        X = df_clean[feature_cols].select_dtypes(include=[np.number])

        # å®šä¹‰ç›®æ ‡å˜é‡
        targets = {
            "match_result": df_clean["result"],  # æ¯”èµ›ç»“æœåˆ†ç±»
            "home_score": df_clean["home_score"],  # ä¸»é˜Ÿè¿›çƒæ•°
            "away_score": df_clean["away_score"],  # å®¢é˜Ÿè¿›çƒæ•°
            "goal_difference": df_clean["goal_difference"],  # è¿›çƒå·®
            "total_goals": df_clean["total_goals"],  # æ€»è¿›çƒæ•°
            "over_2_5_goals": df_clean["over_2_5_goals"],  # å¤§å°çƒ
            "both_teams_score": df_clean["both_teams_score"],  # åŒæ–¹è¿›çƒ
        }

        logger.info(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ: {X.shape}")
        logger.info(f"   ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        logger.info(f"   ç›®æ ‡å˜é‡: {list(targets.keys())}")

        return X, targets

    def train_classification_model(
        self, X: pd.DataFrame, y: pd.Series, target_name: str
    ) -> xgb.XGBClassifier:
        """è®­ç»ƒåˆ†ç±»æ¨¡å‹"""
        logger.info(f"ğŸ¯ è®­ç»ƒåˆ†ç±»æ¨¡å‹: {target_name}")

        # ç¼–ç ç›®æ ‡å˜é‡
        if y.dtype == "object":
            le = LabelEncoder()
            y_encoded = le.fit_transform(y)
            self.label_encoders[target_name] = le
        else:
            y_encoded = y

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )

        # XGBoostå‚æ•°
        params = {
            "objective": (
                "multi:softprob" if len(np.unique(y_encoded)) > 2 else "binary:logistic"
            ),
            "num_class": (
                len(np.unique(y_encoded)) if len(np.unique(y_encoded)) > 2 else None
            ),
            "max_depth": 6,
            "learning_rate": 0.1,
            "n_estimators": 100,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "random_state": 42,
            "eval_metric": "mlogloss" if len(np.unique(y_encoded)) > 2 else "logloss",
        }

        # è®­ç»ƒæ¨¡å‹
        model = xgb.XGBClassifier(**params)
        model.fit(X_train, y_train)

        # è¯„ä¼°æ¨¡å‹
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(model, X, y_encoded, cv=5, scoring="accuracy")

        logger.info(f"   æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
        logger.info(
            f"   äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}"
        )

        # ä¿å­˜è¯„ä¼°ç»“æœ
        self.evaluation_results[target_name] = {
            "test_accuracy": float(accuracy),
            "cv_mean": float(cv_scores.mean()),
            "cv_std": float(cv_scores.std()),
            "model_type": "classification",
            "feature_names": list(X.columns),
        }

        return model

    def train_regression_model(
        self, X: pd.DataFrame, y: pd.Series, target_name: str
    ) -> xgb.XGBRegressor:
        """è®­ç»ƒå›å½’æ¨¡å‹"""
        logger.info(f"ğŸ¯ è®­ç»ƒå›å½’æ¨¡å‹: {target_name}")

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # XGBoostå‚æ•°
        params = {
            "objective": "reg:squarederror",
            "max_depth": 6,
            "learning_rate": 0.1,
            "n_estimators": 100,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "random_state": 42,
        }

        # è®­ç»ƒæ¨¡å‹
        model = xgb.XGBRegressor(**params)
        model.fit(X_train, y_train)

        # è¯„ä¼°æ¨¡å‹
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(model, X, y, cv=5, scoring="r2")

        logger.info(f"   MSE: {mse:.4f}")
        logger.info(f"   MAE: {mae:.4f}")
        logger.info(f"   RÂ²: {r2:.4f}")
        logger.info(f"   äº¤å‰éªŒè¯RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

        # ä¿å­˜è¯„ä¼°ç»“æœ
        self.evaluation_results[target_name] = {
            "mse": float(mse),
            "mae": float(mae),
            "r2": float(r2),
            "cv_mean": float(cv_scores.mean()),
            "cv_std": float(cv_scores.std()),
            "model_type": "regression",
            "feature_names": list(X.columns),
        }

        return model

    def extract_feature_importance(
        self, model, target_name: str, feature_names: list[str]
    ):
        """æå–ç‰¹å¾é‡è¦æ€§"""
        if hasattr(model, "feature_importances_"):
            importance = model.feature_importances_
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            feature_importance = {
                feature: float(score)
                for feature, score in zip(feature_names, importance, strict=False)
            }

            # æŒ‰é‡è¦æ€§æ’åº
            sorted_importance = sorted(
                feature_importance.items(), key=lambda x: x[1], reverse=True
            )
            self.feature_importance[target_name] = sorted_importance

            logger.info(f"ğŸ“Š {target_name} Top 10 é‡è¦ç‰¹å¾:")
            for i, (feature, score) in enumerate(sorted_importance[:10]):
                logger.info(f"   {i + 1:2d}. {feature:30s}: {score:.4f}")

    def save_models(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info("ğŸ’¾ ä¿å­˜è®­ç»ƒæ¨¡å‹...")

        import joblib

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for target_name, model in self.models.items():
            model_path = f"/app/models/xgboost_{target_name}_{timestamp}.pkl"
            joblib.dump(model, model_path)
            logger.info(f"   æ¨¡å‹å·²ä¿å­˜: {model_path}")

        # ä¿å­˜æ ‡ç­¾ç¼–ç å™¨
        if self.label_encoders:
            encoder_path = f"/app/models/label_encoders_{timestamp}.pkl"
            joblib.dump(self.label_encoders, encoder_path)
            logger.info(f"   æ ‡ç­¾ç¼–ç å™¨å·²ä¿å­˜: {encoder_path}")

    def save_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        logger.info("ğŸ“‹ ä¿å­˜åˆ†æç»“æœ...")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜è¯„ä¼°ç»“æœ
        results_path = f"/app/results/model_evaluation_{timestamp}.json"
        with open(results_path, "w", encoding="utf-8") as f:
            json.dump(self.evaluation_results, f, indent=2, ensure_ascii=False)
        logger.info(f"   è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}")

        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
        importance_path = f"/app/results/feature_importance_{timestamp}.json"
        with open(importance_path, "w", encoding="utf-8") as f:
            json.dump(self.feature_importance, f, indent=2, ensure_ascii=False)
        logger.info(f"   ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {importance_path}")

    def generate_feature_importance_visualization(self):
        """ç”Ÿæˆç‰¹å¾é‡è¦æ€§å¯è§†åŒ–"""
        if not MATPLOTLIB_AVAILABLE:
            logger.warning("âš ï¸ matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å¯è§†åŒ–ç”Ÿæˆ")
            return

        logger.info("ğŸ“ˆ ç”Ÿæˆç‰¹å¾é‡è¦æ€§å¯è§†åŒ–...")

        try:
            # ä¸ºä¸»è¦ç›®æ ‡å˜é‡ç”Ÿæˆå›¾è¡¨
            main_targets = ["match_result", "total_goals", "over_2_5_goals"]

            for target_name in main_targets:
                if target_name in self.feature_importance:
                    importance_data = self.feature_importance[target_name]

                    # å–å‰20ä¸ªé‡è¦ç‰¹å¾
                    top_features = importance_data[:20]
                    features, scores = zip(*top_features, strict=False)

                    # åˆ›å»ºå›¾è¡¨
                    plt.figure(figsize=(12, 8))
                    plt.barh(range(len(features)), scores)
                    plt.yticks(range(len(features)), features)
                    plt.xlabel("ç‰¹å¾é‡è¦æ€§")
                    plt.title(f"{target_name} - Top 20 ç‰¹å¾é‡è¦æ€§")
                    plt.gca().invert_yaxis()

                    # ä¿å­˜å›¾è¡¨
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    chart_path = (
                        f"/app/results/feature_importance_{target_name}_{timestamp}.png"
                    )
                    plt.tight_layout()
                    plt.savefig(chart_path, dpi=300, bbox_inches="tight")
                    plt.close()

                    logger.info(f"   {target_name} ç‰¹å¾é‡è¦æ€§å›¾è¡¨å·²ä¿å­˜: {chart_path}")

        except Exception:
            logger.warning(f"âš ï¸ ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾è¡¨æ—¶å‡ºé”™: {e}")

    def print_summary_report(self):
        """æ‰“å°æ¨¡å‹è®­ç»ƒæ€»ç»“æŠ¥å‘Š"""
        print(f"\n{'=' * 80}")
        print("ğŸ¯ XGBoostæ¨¡å‹è®­ç»ƒæ€»ç»“æŠ¥å‘Š")
        print(f"{'=' * 80}")

        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ€»è§ˆ:")
        for target_name, results in self.evaluation_results.items():
            print(f"\n   ğŸ”¸ {target_name}:")
            if results["model_type"] == "classification":
                print(f"      æµ‹è¯•é›†å‡†ç¡®ç‡: {results['test_accuracy']:.4f}")
                print(
                    f"      äº¤å‰éªŒè¯å‡†ç¡®ç‡: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}"
                )
            else:
                print(f"      RÂ²: {results['r2']:.4f}")
                print(f"      MSE: {results['mse']:.4f}")
                print(f"      MAE: {results['mae']:.4f}")
                print(
                    f"      äº¤å‰éªŒè¯RÂ²: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}"
                )

        # EWMAç‰¹å¾é‡è¦æ€§åˆ†æ
        print("\nğŸ§  EWMAç‰¹å¾é‡è¦æ€§åˆ†æ:")
        ewma_features = [
            f
            for f in self.feature_importance.get("match_result", [])
            if "ewma" in f[0] or "rating" in f[0]
        ]

        if ewma_features:
            print("   Top EWMAç‰¹å¾ (match_result):")
            for i, (feature, score) in enumerate(ewma_features[:10]):
                print(f"      {i + 1:2d}. {feature:30s}: {score:.4f}")
        else:
            print("   æœªæ‰¾åˆ°EWMAç‰¹å¾åœ¨Topç‰¹å¾ä¸­")

        # åŸºç¡€ç‰¹å¾å¯¹æ¯”
        print("\nğŸ“ˆ åŸºç¡€ç‰¹å¾vsé«˜çº§ç‰¹å¾å¯¹æ¯”:")
        basic_features = [
            f
            for f in self.feature_importance.get("match_result", [])
            if f[0] in ["home_team_id", "away_team_id", "league_id"]
        ]

        if basic_features:
            print("   åŸºç¡€ç‰¹å¾æ’å:")
            for feature, score in basic_features:
                rank = next(
                    i
                    for i, (f, s) in enumerate(
                        self.feature_importance["match_result"], 1
                    )
                    if f == feature
                )
                print(f"      {feature:15s}: æ’åç¬¬{rank}ä½ (é‡è¦æ€§: {score:.4f})")
        else:
            print("   åŸºç¡€ç‰¹å¾æœªè¿›å…¥Topé‡è¦ç‰¹å¾")

        print("\nğŸ† æ¨¡å‹ä¿å­˜ä½ç½®:")
        print("   æ¨¡å‹æ–‡ä»¶: /app/models/xgboost_*.pkl")
        print("   è¯„ä¼°ç»“æœ: /app/results/model_evaluation_*.json")
        print("   ç‰¹å¾é‡è¦æ€§: /app/results/feature_importance_*.json")

        print(f"\n{'=' * 80}")

    def execute_training_pipeline(self):
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¯åŠ¨é«˜çº§XGBoostè®­ç»ƒæµç¨‹...")

        try:
            # 1. åŠ è½½æ•°æ®
            df = self.load_features_data()

            if len(df) == 0:
                logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®")
                return False

            # 2. å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
            X, targets = self.prepare_features_and_targets(df)

            # 3. è®­ç»ƒå„ä¸ªæ¨¡å‹
            target_configs = {
                "match_result": "classification",
                "total_goals": "regression",
                "over_2_5_goals": "classification",
                "both_teams_score": "classification",
                "home_score": "regression",
                "away_score": "regression",
            }

            for target_name, model_type in target_configs.items():
                if target_name in targets:
                    logger.info(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ {target_name} ({model_type})")

                    y = targets[target_name]

                    if model_type == "classification":
                        model = self.train_classification_model(X, y, target_name)
                    else:
                        model = self.train_regression_model(X, y, target_name)

                    self.models[target_name] = model

                    # æå–ç‰¹å¾é‡è¦æ€§
                    self.extract_feature_importance(model, target_name, list(X.columns))

            # 4. ä¿å­˜æ¨¡å‹å’Œç»“æœ
            self.save_models()
            self.save_results()
            self.generate_feature_importance_visualization()

            # 5. æ‰“å°æ€»ç»“æŠ¥å‘Š
            self.print_summary_report()

            return True

        except Exception:
            logger.error(f"ğŸ’¥ è®­ç»ƒæµç¨‹å¼‚å¸¸: {e}")
            import traceback

            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ XGBoosté«˜çº§æ¨¡å‹è®­ç»ƒå™¨ - V3ç‰ˆæœ¬")
    print("ğŸ¯ ç›®æ ‡: åŸºäºEWMAç‰¹å¾è®­ç»ƒé«˜æ€§èƒ½é¢„æµ‹æ¨¡å‹")
    print("ğŸ§  æ¶æ„: å¤šç›®æ ‡é¢„æµ‹ + ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print("=" * 80)

    trainer = AdvancedXGBoostTrainer()

    try:
        success = trainer.execute_training_pipeline()

        if success:
            print("\nğŸ‰ XGBoostæ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆ!")
            print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
            print("   /app/models/ - è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
            print("   /app/results/ - è¯„ä¼°ç»“æœå’Œç‰¹å¾é‡è¦æ€§åˆ†æ")
            print("ğŸ”¥ å…³é”®éªŒè¯ç‚¹: EWMAç‰¹å¾åº”æ’åé«˜äºåŸºç¡€ç‰¹å¾")
        else:
            print("\nâŒ XGBoostæ¨¡å‹è®­ç»ƒå¤±è´¥")

    except Exception:
        logger.error(f"ğŸ’¥ ç³»ç»Ÿå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
