#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
Performance Test Script

æµ‹è¯•ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–æ•ˆæœï¼š
- APIå“åº”æ—¶é—´æµ‹è¯•
- å¹¶å‘è¯·æ±‚æµ‹è¯•
- ç¼“å­˜æ•ˆæœæµ‹è¯•
- å†…å­˜ä½¿ç”¨ç›‘æ§

Author: Claude AI Assistant
Date: 2025-11-03
Version: 1.0.0
"""

import asyncio
import aiohttp
import time
import statistics
import json
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor
import requests
import psutil
import os

class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results: Dict[str, Any] = {}

    async def test_api_response_time(self, num_requests: int = 100) -> Dict[str, float]:
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        print(f"ğŸš€ æµ‹è¯•APIå“åº”æ—¶é—´ ({num_requests}ä¸ªè¯·æ±‚)...")

        times = []
        errors = 0

        async with aiohttp.ClientSession() as session:
            for i in range(num_requests):
                try:
                    start_time = time.time()
                    async with session.get(f"{self.base_url}/health") as response:
                        if response.status == 200:
                            end_time = time.time()
                            response_time = (end_time - start_time) * 1000  # ms
                            times.append(response_time)
                        else:
                            errors += 1
                except Exception as e:
                    errors += 1
                    print(f"è¯·æ±‚é”™è¯¯: {e}")

        if times:
            return {
                "average": statistics.mean(times),
                "median": statistics.median(times),
                "min": min(times),
                "max": max(times),
                "p95": self._percentile(times, 95),
                "p99": self._percentile(times, 99),
                "success_rate": (len(times) / num_requests) * 100,
                "error_count": errors
            }
        else:
            return {"error": "æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†"}

    async def test_concurrent_requests(self,
    concurrent_users: int = 50,
    requests_per_user: int = 10) -> Dict[str,
    Any]:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ›"""
        print(f"ğŸ”¥ æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç† ({concurrent_users}ä¸ªå¹¶å‘ç”¨æˆ·, æ¯ç”¨æˆ·{requests_per_user}ä¸ªè¯·æ±‚)...")

        async def user_session(user_id: int) -> List[float]:
            """å•ä¸ªç”¨æˆ·çš„ä¼šè¯"""
            times = []
            async with aiohttp.ClientSession() as session:
                for req_id in range(requests_per_user):
                    try:
                        start_time = time.time()
                        async with session.get(f"{self.base_url}/health") as response:
                            if response.status == 200:
                                end_time = time.time()
                                response_time = (end_time - start_time) * 1000
                                times.append(response_time)
                    except Exception:
                        pass
            return times

        # å¹¶å‘æ‰§è¡Œç”¨æˆ·ä¼šè¯
        start_time = time.time()
        tasks = [user_session(i) for i in range(concurrent_users)]
        user_results = await asyncio.gather(*tasks)
        end_time = time.time()

        # ç»Ÿè®¡ç»“æœ
        all_times = []
        total_requests = 0
        for times in user_results:
            all_times.extend(times)
            total_requests += len(times)

        total_time = end_time - start_time
        throughput = total_requests / total_time if total_time > 0 else 0

        if all_times:
            return {
                "concurrent_users": concurrent_users,
                "total_requests": total_requests,
                "total_time": total_time,
                "throughput": throughput,  # requests per second
                "average_response_time": statistics.mean(all_times),
                "p95_response_time": self._percentile(all_times, 95),
                "p99_response_time": self._percentile(all_times, 99),
                "success_rate": (len(all_times) / (concurrent_users * requests_per_user)) * 100
            }
        else:
            return {"error": "å¹¶å‘æµ‹è¯•å¤±è´¥"}

    def _percentile(self, data: List[float], percentile: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]

    def monitor_system_resources(self, duration: int = 30) -> Dict[str, Any]:
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨"""
        print(f"ğŸ“Š ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨ ({duration}ç§’)...")

        process = psutil.Process()
        cpu_usage = []
        memory_usage = []

        start_time = time.time()
        while time.time() - start_time < duration:
            cpu_usage.append(process.cpu_percent())
            memory_info = process.memory_info()
            memory_usage.append(memory_info.rss / 1024 / 1024)  # MB
            time.sleep(1)

        return {
            "duration": duration,
            "cpu": {
                "average": statistics.mean(cpu_usage) if cpu_usage else 0,
                "max": max(cpu_usage) if cpu_usage else 0,
                "min": min(cpu_usage) if cpu_usage else 0
            },
            "memory": {
                "average": statistics.mean(memory_usage) if memory_usage else 0,
                "max": max(memory_usage) if memory_usage else 0,
                "min": min(memory_usage) if memory_usage else 0
            }
        }

    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        print("ğŸ¯ å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•...")
        print("=" * 60)

        results = {
            "test_timestamp": time.time(),
            "test_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "system_info": self._get_system_info()
        }

        try:
            # 1. APIå“åº”æ—¶é—´æµ‹è¯•
            print("\n1ï¸âƒ£ APIå“åº”æ—¶é—´æµ‹è¯•")
            response_time_results = await self.test_api_response_time(50)
            results["response_time_test"] = response_time_results
            print(f"   å¹³å‡å“åº”æ—¶é—´: {response_time_results.get('average', 0):.2f}ms")
            print(f"   P95å“åº”æ—¶é—´: {response_time_results.get('p95', 0):.2f}ms")
            print(f"   æˆåŠŸç‡: {response_time_results.get('success_rate', 0):.2f}%")

            # 2. å¹¶å‘è¯·æ±‚æµ‹è¯•
            print("\n2ï¸âƒ£ å¹¶å‘è¯·æ±‚æµ‹è¯•")
            concurrent_results = await self.test_concurrent_requests(20, 5)
            results["concurrent_test"] = concurrent_results
            if "error" not in concurrent_results:
                print(f"   ååé‡: {concurrent_results.get('throughput', 0):.2f} req/s")
                print(f"   å¹³å‡å“åº”æ—¶é—´: {concurrent_results.get('average_response_time',
    0):.2f}ms")
                print(f"   æˆåŠŸç‡: {concurrent_results.get('success_rate', 0):.2f}%")

            # 3. ç³»ç»Ÿèµ„æºç›‘æ§
            print("\n3ï¸âƒ£ ç³»ç»Ÿèµ„æºç›‘æ§")
            resource_results = self.monitor_system_resources(10)
            results["resource_monitoring"] = resource_results
            cpu_avg = resource_results["cpu"]["average"]
            mem_avg = resource_results["memory"]["average"]
            print(f"   å¹³å‡CPUä½¿ç”¨ç‡: {cpu_avg:.2f}%")
            print(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {mem_avg:.2f}MB")

            # 4. è®¡ç®—æ€§èƒ½è¯„åˆ†
            print("\n4ï¸âƒ£ æ€§èƒ½è¯„åˆ†")
            performance_score = self._calculate_performance_score(results)
            results["performance_score"] = performance_score
            print(f"   æ€»ä½“æ€§èƒ½è¯„åˆ†: {performance_score['overall']:.2f}/100")
            print(f"   å“åº”æ—¶é—´è¯„åˆ†: {performance_score['response_time']:.2f}/100")
            print(f"   å¹¶å‘å¤„ç†è¯„åˆ†: {performance_score['concurrency']:.2f}/100")
            print(f"   èµ„æºä½¿ç”¨è¯„åˆ†: {performance_score['resource_usage']:.2f}/100")

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            results["error"] = str(e)

        print("\n" + "=" * 60)
        print("âœ… ç»¼åˆæ€§èƒ½æµ‹è¯•å®Œæˆ!")

        return results

    def _get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            "cpu_count": psutil.cpu_count(),
            "memory_total": psutil.virtual_memory().total / 1024 / 1024 / 1024,  # GB
            "python_version": f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}",
            "platform": os.name
        }

    def _calculate_performance_score(self, results: Dict[str, Any]) -> Dict[str, float]:
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        scores = {
            "response_time": 0,
            "concurrency": 0,
            "resource_usage": 0
        }

        # å“åº”æ—¶é—´è¯„åˆ† (ç›®æ ‡: <200ms)
        response_test = results.get("response_time_test", {})
        if "average" in response_test:
            avg_time = response_test["average"]
            if avg_time <= 200:
                scores["response_time"] = 100
            elif avg_time <= 500:
                scores["response_time"] = 80 - (avg_time - 200) * 0.1
            else:
                scores["response_time"] = max(0, 50 - (avg_time - 500) * 0.05)

        # å¹¶å‘å¤„ç†è¯„åˆ† (ç›®æ ‡: >50 req/s)
        concurrent_test = results.get("concurrent_test", {})
        if "throughput" in concurrent_test:
            throughput = concurrent_test["throughput"]
            if throughput >= 50:
                scores["concurrency"] = 100
            else:
                scores["concurrency"] = throughput * 2

        # èµ„æºä½¿ç”¨è¯„åˆ† (ç›®æ ‡: CPU<80%, å†…å­˜<1GB)
        resource_test = results.get("resource_monitoring", {})
        cpu_avg = resource_test.get("cpu", {}).get("average", 0)
        mem_avg = resource_test.get("memory", {}).get("average", 0)

        cpu_score = max(0, 100 - cpu_avg * 1.25) if cpu_avg < 80 else 0
        mem_score = max(0, 100 - mem_avg * 0.1) if mem_avg < 1000 else 0
        scores["resource_usage"] = (cpu_score + mem_score) / 2

        # æ€»ä½“è¯„åˆ†
        scores["overall"] = sum(scores.values()) / len(scores)

        return scores

    def save_results(self, results: Dict[str, Any], filename: str = None) -> str:
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"performance_test_results_{timestamp}.json"

        # ç¡®ä¿reportsç›®å½•å­˜åœ¨
        os.makedirs("reports/performance", exist_ok=True)
        filepath = f"reports/performance/{filename}"

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
        return filepath

    def print_summary(self, results: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ€§èƒ½æµ‹è¯•æ‘˜è¦æŠ¥å‘Š")
        print("=" * 60)

        # åŸºæœ¬ä¿¡æ¯
        print(f"æµ‹è¯•æ—¶é—´: {results.get('test_date', 'Unknown')}")
        print(f"ç³»ç»Ÿä¿¡æ¯: CPUæ ¸å¿ƒæ•° {results.get('system_info',
    {}).get('cpu_count',
    'Unknown')},
    "
              f"æ€»å†…å­˜ {results.get('system_info',
    {}).get('memory_total',
    'Unknown'):.1f}GB")

        # å“åº”æ—¶é—´
        response_test = results.get("response_time_test", {})
        if "average" in response_test:
            print(f"\nğŸ¯ å“åº”æ—¶é—´æ€§èƒ½:")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {response_test['average']:.2f}ms")
            print(f"   P95å“åº”æ—¶é—´: {response_test.get('p95', 0):.2f}ms")
            print(f"   æœ€å¤§å“åº”æ—¶é—´: {response_test.get('max', 0):.2f}ms")
            print(f"   æˆåŠŸç‡: {response_test.get('success_rate', 0):.2f}%")

        # å¹¶å‘æ€§èƒ½
        concurrent_test = results.get("concurrent_test", {})
        if "throughput" in concurrent_test:
            print(f"\nğŸ”¥ å¹¶å‘å¤„ç†æ€§èƒ½:")
            print(f"   ååé‡: {concurrent_test['throughput']:.2f} req/s")
            print(f"   å¹¶å‘ç”¨æˆ·æ•°: {concurrent_test.get('concurrent_users', 0)}")
            print(f"   æ€»è¯·æ±‚æ•°: {concurrent_test.get('total_requests', 0)}")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {concurrent_test.get('average_response_time', 0):.2f}ms")

        # èµ„æºä½¿ç”¨
        resource_test = results.get("resource_monitoring", {})
        if "cpu" in resource_test:
            print(f"\nğŸ’» ç³»ç»Ÿèµ„æºä½¿ç”¨:")
            print(f"   å¹³å‡CPUä½¿ç”¨ç‡: {resource_test['cpu']['average']:.2f}%")
            print(f"   æœ€å¤§CPUä½¿ç”¨ç‡: {resource_test['cpu']['max']:.2f}%")
            print(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {resource_test['memory']['average']:.2f}MB")
            print(f"   æœ€å¤§å†…å­˜ä½¿ç”¨: {resource_test['memory']['max']:.2f}MB")

        # æ€§èƒ½è¯„åˆ†
        score = results.get("performance_score", {})
        if "overall" in score:
            print(f"\nğŸ† æ€§èƒ½è¯„åˆ†:")
            print(f"   æ€»ä½“è¯„åˆ†: {score['overall']:.2f}/100")
            print(f"   å“åº”æ—¶é—´: {score.get('response_time', 0):.2f}/100")
            print(f"   å¹¶å‘å¤„ç†: {score.get('concurrency', 0):.2f}/100")
            print(f"   èµ„æºä½¿ç”¨: {score.get('resource_usage', 0):.2f}/100")

        print("\n" + "=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è¶³çƒé¢„æµ‹ç³»ç»Ÿæ€§èƒ½æµ‹è¯•å·¥å…·")
    print("=" * 50)

    tester = PerformanceTester()

    try:
        # è¿è¡Œç»¼åˆæµ‹è¯•
        results = await tester.run_comprehensive_test()

        # ä¿å­˜ç»“æœ
        filepath = tester.save_results(results)

        # æ‰“å°æ‘˜è¦
        tester.print_summary(results)

    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())
