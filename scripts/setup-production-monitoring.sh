#!/bin/bash

# ç”Ÿäº§ç¯å¢ƒç›‘æ§é…ç½®è„šæœ¬
# é…ç½®å®Œæ•´çš„ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

set -euo pipefail

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_step() {
    echo -e "${BLUE}[STEP]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

# é…ç½®
PROMETHEUS_URL=${PROMETHEUS_URL:-http://localhost:9090}
GRAFANA_URL=${GRAFANA_URL:-http://localhost:3000}
ALERTMANAGER_URL=${ALERTMANAGER_URL:-http://localhost:9093}
ENVIRONMENT=${ENVIRONMENT:-production}
SLACK_WEBHOOK=${SLACK_WEBHOOK:-}
EMAIL_SMTP=${EMAIL_SMTP:-smtp.gmail.com:587}
EMAIL_USER=${EMAIL_USER:-alerts@footballprediction.com}
EMAIL_PASSWORD=${EMAIL_PASSWORD:-}

# åˆ›å»ºé…ç½®ç›®å½•
create_directories() {
    log_step "åˆ›å»ºç›‘æ§é…ç½®ç›®å½•..."

    mkdir -p monitoring/production/{rules,dashboards,templates}
    mkdir -p config/alertmanager
    mkdir -p scripts/monitoring
    mkdir -p logs/monitoring
}

# é…ç½®Prometheusç”Ÿäº§è§„åˆ™
setup_prometheus_rules() {
    log_step "é…ç½®Prometheusç”Ÿäº§è§„åˆ™..."

    # å¤åˆ¶å‘Šè­¦è§„åˆ™
    cp monitoring/production/alerts.yml monitoring/prometheus/rules/

    # åˆ›å»ºæœåŠ¡å‘ç°é…ç½®
    cat > monitoring/prometheus/file_sd.yml <<EOF
- targets:
  - 'localhost:9090'
  labels:
    job: 'prometheus'
    environment: '$ENVIRONMENT'

- targets:
  - 'localhost:8000'
  labels:
    job: 'football-prediction'
    environment: '$ENVIRONMENT'

- targets:
  - 'localhost:5432'
  labels:
    job: 'postgres'
    environment: '$ENVIRONMENT'

- targets:
  - 'localhost:6379'
  labels:
    job: 'redis'
    environment: '$ENVIRONMENT'

- targets:
  - 'localhost:9100'
  labels:
    job: 'node-exporter'
    environment: '$ENVIRONMENT'

- targets:
  - 'localhost:9121'
  labels:
    job: 'redis-exporter'
    environment: '$ENVIRONMENT'

- targets:
  - 'localhost:9187'
  labels:
    job: 'postgres-exporter'
    environment: '$ENVIRONMENT'
EOF

    log_info "Prometheusè§„åˆ™å·²é…ç½®"
}

# é…ç½®Alertmanager
setup_alertmanager() {
    log_step "é…ç½®Alertmanager..."

    cat > config/alertmanager/alertmanager.yml <<EOF
global:
  smtp_smarthost: '$EMAIL_SMTP'
  smtp_from: '$EMAIL_USER'
  smtp_auth_username: '$EMAIL_USER'
  smtp_auth_password: '$EMAIL_PASSWORD'

templates:
  - '/etc/alertmanager/templates/*.tmpl'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
    # Criticalå‘Šè­¦ç«‹å³å‘é€
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true
      group_wait: 0s
      repeat_interval: 5m

    # å®‰å…¨å‘Šè­¦ç«‹å³å‘é€
    - match:
        service: security
      receiver: 'security-alerts'
      continue: true
      group_wait: 0s
      repeat_interval: 5m

    # ä¸šåŠ¡å‘Šè­¦å·¥ä½œæ—¶é—´å‘é€
    - match:
        service: business
      receiver: 'business-alerts'
      active_time_intervals:
        - business-hours

    # ç³»ç»Ÿå‘Šè­¦
    - match:
        service: system
      receiver: 'ops-alerts'

receivers:
  - name: 'default'
    email_configs:
      - to: '$EMAIL_USER'
        subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          å‘Šè­¦åç§°: {{ .Annotations.summary }}
          å‘Šè­¦æè¿°: {{ .Annotations.description }}
          ä¸¥é‡çº§åˆ«: {{ .Labels.severity }}
          å¼€å§‹æ—¶é—´: {{ .StartsAt }}
          è·³è½¬é“¾æ¥: {{ .GeneratorURL }}
          {{ end }}

    # Slacké€šçŸ¥ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    ${SLACK_WEBHOOK:+slack_configs:}
    ${SLACK_WEBHOOK:+  - api_url: '$SLACK_WEBHOOK'}
    ${SLACK_WEBHOOK:+    channel: '#alerts'}
    ${SLACK_WEBHOOK:+    title: 'Football Prediction Alert'}
    ${SLASH_WEBHOOK:+    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'}

  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@footballprediction.com,$EMAIL_USER'
        subject: 'ğŸš¨ [CRITICAL] {{ .GroupLabels.alertname }}'
        body: |
          ğŸš¨ CRITICAL ALERT ğŸš¨

          {{ range .Alerts }}
          å‘Šè­¦: {{ .Annotations.summary }}
          è¯¦æƒ…: {{ .Annotations.description }}
          å®ä¾‹: {{ .Labels.instance }}
          æ—¶é—´: {{ .StartsAt }}
          è·³è½¬: {{ .GeneratorURL }}
          {{ end }}

    ${SLACK_WEBHOOK:+slack_configs:}
    ${SLACK_WEBHOOK:+  - api_url: '$SLACK_WEBHOOK'}
    ${SLASH_WEBHOOK:+    channel: '#alerts-critical'}
    ${SLASH_WEBHOOK:+    title: 'ğŸš¨ Critical Alert'}
    ${SLASH_WEBHOOK:+    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'}
    ${SLASH_WEBHOOK:+    color: 'danger'}

  - name: 'security-alerts'
    email_configs:
      - to: 'security@footballprediction.com'
        subject: 'ğŸ”’ [SECURITY] {{ .GroupLabels.alertname }}'
        body: |
          ğŸ”’ SECURITY ALERT ğŸ”’

          {{ range .Alerts }}
          å®‰å…¨äº‹ä»¶: {{ .Annotations.summary }}
          è¯¦æƒ…: {{ .Annotations.description }}
          æ¥æº: {{ .Labels.instance }}
          æ—¶é—´: {{ .StartsAt }}
          {{ end }}

    ${SLACK_WEBHOOK:+slack_configs:}
    ${SLASH_WEBHOOK:+  - api_url: '$SLACK_WEBHOOK'}
    ${SLASH_WEBHOOK:+    channel: '#security-alerts'}
    ${SLASH_WEBHOOK:+    title: 'Security Alert'}
    ${SLASH_WEBHOOK:+    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'}
    ${SLASH_WEBHOOK:+    color: 'warning'}

  - name: 'ops-alerts'
    email_configs:
      - to: 'ops@footballprediction.com'
        subject: '[OPS] {{ .GroupLabels.alertname }}'

    ${SLACK_WEBHOOK:+slack_configs:}
    ${SLASH_WEBHOOK:+  - api_url: '$SLACK_WEBHOOK'}
    ${SLASH_WEBHOOK:+    channel: '#ops-alerts'}
    ${SLASH_WEBHOOK:+    title: 'Ops Alert'}
    ${SLASH_WEBHOOK:+    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'}
    ${SLASH_WEBHOOK:+    color: 'warning'}

  - name: 'business-alerts'
    email_configs:
      - to: 'product@footballprediction.com'
        subject: '[PRODUCT] {{ .GroupLabels.alertname }}'

    ${SLACK_WEBHOOK:+slack_configs:}
    ${SLASH_WEBHOOK:+  - api_url: '$SLACK_WEBHOOK'}
    ${SLASH_WEBHOOK:+    channel: '#product-alerts'}
    ${SLASH_WEBHOOK:+    title: 'Product Alert'}
    ${SLASH_WEBHOOK:+    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'}
    ${SLASH_WEBHOOK:+    color: 'good'}

inhibit_rules:
  # å¦‚æœAPIæœåŠ¡å®Œå…¨å®•æœºï¼ŒæŠ‘åˆ¶å…¶ä»–APIç›¸å…³å‘Šè­¦
  - source_match:
      - alertname: ServiceDown
      service: api
    target_match:
      service: api
    equal: ['alertname']

time_intervals:
  - name: business-hours
    time_intervals:
      - times:
          - start_time: '09:00'
          end_time: '18:00'
        weekdays: ['monday:friday']
EOF

    log_info "Alertmanagerå·²é…ç½®"
}

# åˆ›å»ºå‘Šè­¦æ¨¡æ¿
create_alert_templates() {
    log_step "åˆ›å»ºå‘Šè­¦æ¨¡æ¿..."

    cat > config/alertmanager/templates/email.tmpl <<'EOF'
{{ define "email.default.subject" }}
[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}
{{ end }}

{{ define "email.default.body" }}
{{ range .Alerts }}
<strong>å‘Šè­¦åç§°:</strong> {{ .Annotations.summary }}<br>
<strong>å‘Šè­¦æè¿°:</strong> {{ .Annotations.description }}<br>
<strong>ä¸¥é‡çº§åˆ«:</strong> {{ .Labels.severity }}<br>
<strong>å¼€å§‹æ—¶é—´:</strong> {{ .StartsAt.Format "2006-01-02 15:04:05" }}<br>
<strong>å®ä¾‹:</strong> {{ .Labels.instance }}<br>
<strong>æœåŠ¡:</strong> {{ .Labels.service }}<br>
<br>
{{ end }}
{{ end }}

{{ define "email.critical.subject" }}
ğŸš¨ CRITICAL: {{ .GroupLabels.alertname }}
{{ end }}

{{ define "email.critical.body" }}
<h2 style="color: red;">ğŸš¨ CRITICAL ALERT ğŸš¨</h2>
{{ range .Alerts }}
<p><strong>å‘Šè­¦:</strong> {{ .Annotations.summary }}</p>
<p><strong>è¯¦æƒ…:</strong> {{ .Annotations.description }}</p>
<p><strong>å®ä¾‹:</strong> {{ .Labels.instance }}</p>
<p><strong>æ—¶é—´:</strong> {{ .StartsAt.Format "2006-01-02 15:04:05" }}</p>
<p><strong>è·³è½¬:</strong> <a href="{{ .GeneratorURL }}">æŸ¥çœ‹è¯¦æƒ…</a></p>
<hr>
{{ end }}
{{ end }}
EOF

    log_info "å‘Šè­¦æ¨¡æ¿å·²åˆ›å»º"
}

# é…ç½®Node Exporter
setup_node_exporter() {
    log_step "é…ç½®Node Exporter..."

    # åˆ›å»ºsystemdæœåŠ¡
    sudo tee /etc/systemd/system/node-exporter.service > /dev/null <<EOF
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter \
  --web.listen-address=0.0.0.0:9100 \
  --path.rootfs=/host \
  --path.procfs=/host/proc \
  --path.sysfs=/host/sys \
  --collector.filesystem \
  --collector.cpu \
  --collector.meminfo \
  --collector.diskstats \
  --collector.netdev \
  --collector.netstat \
  --collector.stat \
  --collector.systemd \
  --collector.textfile \
  --collector.textfile.directory=/var/lib/node_exporter

[Install]
WantedBy=multi-user.target
EOF

    # åˆ›å»ºç”¨æˆ·
    sudo useradd --no-create-home --shell /bin/false node_exporter || true

    # ä¸‹è½½å¹¶å®‰è£…
    NODE_EXPORTER_VERSION="1.6.1"
    cd /tmp
    wget https://github.com/prometheus/node_exporter/releases/download/v${NODE_EXPORTER_VERSION}/node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz
    tar xvfz node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz
    sudo mv node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64/node_exporter /usr/local/bin/

    # è®¾ç½®æƒé™
    sudo chown node_exporter:node_exporter /usr/local/bin/node_exporter

    # å¯åŠ¨æœåŠ¡
    sudo systemctl daemon-reload
    sudo systemctl enable node-exporter
    sudo systemctl start node-exporter

    log_info "Node Exporterå·²é…ç½®å¹¶å¯åŠ¨"
}

# é…ç½®è¿›ç¨‹ç›‘æ§
setup_process_monitoring() {
    log_step "é…ç½®è¿›ç¨‹ç›‘æ§..."

    # åˆ›å»ºè¿›ç¨‹ç›‘æ§è„šæœ¬
    cat > scripts/monitoring/process_monitor.py <<'EOF'
#!/usr/bin/env python3
"""
è¿›ç¨‹ç›‘æ§è„šæœ¬
ç›‘æ§å…³é”®è¿›ç¨‹å¹¶ç”ŸæˆPrometheusæŒ‡æ ‡
"""

import psutil
import time
from prometheus_client import start_http_server, Gauge, Counter
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®šä¹‰æŒ‡æ ‡
PROCESS_COUNT = Gauge('process_count', 'Number of processes', ['process_name'])
PROCESS_CPU = Gauge('process_cpu_percent', 'Process CPU usage', ['process_name'])
PROCESS_MEMORY = Gauge('process_memory_bytes', 'Process memory usage', ['process_name'])
PROCESS_RESTARTS = Counter('process_restarts_total', 'Process restarts', ['process_name'])

# è¦ç›‘æ§çš„è¿›ç¨‹
PROCESSES = {
    'uvicorn': ['uvicorn'],
    'postgres': ['postgres'],
    'redis': ['redis-server'],
    'nginx': ['nginx'],
    'celery': ['celery'],
}

def monitor_processes():
    """ç›‘æ§è¿›ç¨‹"""
    process_states = {}

    while True:
        try:
            for name, patterns in PROCESSES.items():
                found = False
                total_cpu = 0
                total_memory = 0
                count = 0

                for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                    try:
                        cmdline = ' '.join(proc.info['cmdline'] or [])
                        if any(pattern in cmdline for pattern in patterns):
                            found = True
                            count += 1
                            total_cpu += proc.cpu_percent()
                            total_memory += proc.memory_info().rss
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        pass

                if found:
                    PROCESS_COUNT.labels(process_name=name).set(count)
                    PROCESS_CPU.labels(process_name=name).set(total_cpu)
                    PROCESS_MEMORY.labels(process_name=name).set(total_memory)

                    # æ£€æŸ¥è¿›ç¨‹é‡å¯
                    if name not in process_states or process_states[name] != count:
                        PROCESS_RESTARTS.labels(process_name=name).inc()
                    process_states[name] = count
                else:
                    PROCESS_COUNT.labels(process_name=name).set(0)
                    PROCESS_CPU.labels(process_name=name).set(0)
                    PROCESS_MEMORY.labels(process_name=name).set(0)

            time.sleep(10)

        except Exception as e:
            logger.error(f"ç›‘æ§é”™è¯¯: {e}")
            time.sleep(10)

if __name__ == "__main__":
    # å¯åŠ¨HTTPæœåŠ¡å™¨
    start_http_server(9101)

    # å¼€å§‹ç›‘æ§
    logger.info("è¿›ç¨‹ç›‘æ§å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£9101")
    monitor_processes()
EOF

    chmod +x scripts/monitoring/process_monitor.py

    # åˆ›å»ºsystemdæœåŠ¡
    sudo tee /etc/systemd/system/process-monitor.service > /dev/null <<EOF
[Unit]
Description=Process Monitor
After=network.target

[Service]
Type=simple
User=monitoring
WorkingDirectory=$(pwd)
ExecStart=$(pwd)/scripts/monitoring/process_monitor.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

    # åˆ›å»ºç”¨æˆ·
    sudo useradd --no-create-home --shell /bin/false monitoring || true

    # å¯åŠ¨æœåŠ¡
    sudo systemctl daemon-reload
    sudo systemctl enable process-monitor
    sudo systemctl start process-monitor

    log_info "è¿›ç¨‹ç›‘æ§å·²é…ç½®å¹¶å¯åŠ¨"
}

# é…ç½®æ—¥å¿—ç›‘æ§
setup_log_monitoring() {
    log_step "é…ç½®æ—¥å¿—ç›‘æ§..."

    # åˆ›å»ºæ—¥å¿—ç›‘æ§è„šæœ¬
    cat > scripts/monitoring/log_monitor.py <<'EOF'
#!/usr/bin/env python3
"""
æ—¥å¿—ç›‘æ§è„šæœ¬
ç›‘æ§æ—¥å¿—æ–‡ä»¶å¹¶ç”ŸæˆæŒ‡æ ‡
"""

import re
import time
from prometheus_client import start_http_server, Counter, Histogram
import logging
from pathlib import Path
import tailer

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®šä¹‰æŒ‡æ ‡
LOG_ERRORS = Counter('log_errors_total', 'Number of errors in logs', ['service'])
LOG_WARNINGS = Counter('log_warnings_total', 'Number of warnings in logs', ['service'])
LOG_REQUESTS = Counter('log_requests_total', 'Number of requests', ['service', 'method', 'status'])
LOG_DURATION = Histogram('log_request_duration_seconds', 'Request duration', ['service'])

# æ—¥å¿—æ–‡ä»¶è·¯å¾„
LOG_FILES = {
    'api': 'logs/api/app.log',
    'celery': 'logs/celery/celery.log',
    'nginx': '/var/log/nginx/access.log',
}

# æ—¥å¿—æ¨¡å¼
PATTERNS = {
    'error': re.compile(r'ERROR'),
    'warning': re.compile(r'WARNING'),
    'request': re.compile(r'(\w+)\s+([A-Z]+)\s+(/\S+)\s+(\d+)\s+(\d+\.\d+)'),
}

def monitor_logs():
    """ç›‘æ§æ—¥å¿—"""
    log_positions = {}

    while True:
        try:
            for service, log_file in LOG_FILES.items():
                path = Path(log_file)

                if not path.exists():
                    continue

                # è·å–æ–‡ä»¶å¤§å°
                current_size = path.stat().st_size

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«è½®è½¬
                if service in log_positions and log_positions[service] > current_size:
                    # æ–‡ä»¶è¢«è½®è½¬ï¼Œä»å¤´å¼€å§‹è¯»
                    log_positions[service] = 0

                # è®°å½•å½“å‰ä½ç½®
                if service not in log_positions:
                    log_positions[service] = current_size

                # è¯»å–æ–°è¡Œ
                with open(path, 'r') as f:
                    f.seek(log_positions[service])
                    lines = f.readlines()
                    log_positions[service] = f.tell()

                # å¤„ç†æ¯è¡Œ
                for line in lines:
                    # é”™è¯¯æ—¥å¿—
                    if PATTERNS['error'].search(line):
                        LOG_ERRORS.labels(service=service).inc()

                    # è­¦å‘Šæ—¥å¿—
                    if PATTERNS['warning'].search(line):
                        LOG_WARNINGS.labels(service=service).inc()

                    # è¯·æ±‚æ—¥å¿—
                    match = PATTERNS['request'].search(line)
                    if match:
                        method, status, path, _, duration = match.groups()
                        LOG_REQUESTS.labels(service=service, method=method, status=status).inc()
                        LOG_DURATION.labels(service=service).observe(float(duration))

            time.sleep(5)

        except Exception as e:
            logger.error(f"æ—¥å¿—ç›‘æ§é”™è¯¯: {e}")
            time.sleep(5)

if __name__ == "__main__":
    # å¯åŠ¨HTTPæœåŠ¡å™¨
    start_http_server(9102)

    # å¼€å§‹ç›‘æ§
    logger.info("æ—¥å¿—ç›‘æ§å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£9102")
    monitor_logs()
EOF

    chmod +x scripts/monitoring/log_monitor.py

    # åˆ›å»ºsystemdæœåŠ¡
    sudo tee /etc/systemd/system/log-monitor.service > /dev/null <<EOF
[Unit]
Description=Log Monitor
After=network.target

[Service]
Type=simple
User=monitoring
WorkingDirectory=$(pwd)
ExecStart=$(pwd)/scripts/monitoring/log_monitor.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

    # å¯åŠ¨æœåŠ¡
    sudo systemctl daemon-reload
    sudo systemctl enable log-monitor
    sudo systemctl start log-monitor

    log_info "æ—¥å¿—ç›‘æ§å·²é…ç½®å¹¶å¯åŠ¨"
}

# é…ç½®å¥åº·æ£€æŸ¥
setup_health_checks() {
    log_step "é…ç½®å¥åº·æ£€æŸ¥..."

    # åˆ›å»ºå¥åº·æ£€æŸ¥è„šæœ¬
    cat > scripts/monitoring/health_check.py <<'EOF'
#!/usr/bin/env python3
"""
å¥åº·æ£€æŸ¥è„šæœ¬
æ£€æŸ¥æ‰€æœ‰æœåŠ¡å¥åº·çŠ¶æ€å¹¶ç”ŸæˆæŒ‡æ ‡
"""

import asyncio
import aiohttp
import time
from prometheus_client import start_http_server, Gauge
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®šä¹‰æŒ‡æ ‡
HEALTH_STATUS = Gauge('service_health_status', 'Service health status', ['service', 'instance'])
HEALTH_CHECK_DURATION = Gauge('health_check_duration_seconds', 'Health check duration', ['service'])

# æœåŠ¡ç«¯ç‚¹
SERVICES = {
    'api': 'http://localhost:8000/api/health',
    'prometheus': 'http://localhost:9090/-/healthy',
    'grafana': 'http://localhost:3000/api/health',
    'alertmanager': 'http://localhost:9093/-/healthy',
    'redis': 'redis://localhost:6379',
}

async def check_http_service(session, name, url):
    """æ£€æŸ¥HTTPæœåŠ¡"""
    start_time = time.time()
    try:
        async with session.get(url, timeout=5) as response:
            status = 1 if response.status == 200 else 0
            HEALTH_STATUS.labels(service=name, instance='localhost').set(status)
    except Exception as e:
        logger.error(f"{name} å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        HEALTH_STATUS.labels(service=name, instance='localhost').set(0)
    finally:
        HEALTH_CHECK_DURATION.labels(service=name).set(time.time() - start_time)

async def check_redis():
    """æ£€æŸ¥Redis"""
    import redis
    start_time = time.time()
    try:
        r = redis.Redis(host='localhost', port=6379, decode_responses=True)
        r.ping()
        HEALTH_STATUS.labels(service='redis', instance='localhost').set(1)
    except Exception as e:
        logger.error(f"Redis å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        HEALTH_STATUS.labels(service='redis', instance='localhost').set(0)
    finally:
        HEALTH_CHECK_DURATION.labels(service='redis').set(time.time() - start_time)

async def monitor_health():
    """ç›‘æ§å¥åº·çŠ¶æ€"""
    async with aiohttp.ClientSession() as session:
        while True:
            try:
                # æ£€æŸ¥HTTPæœåŠ¡
                tasks = []
                for name, url in SERVICES.items():
                    if url.startswith('http'):
                        tasks.append(check_http_service(session, name, url))

                # æ£€æŸ¥Redis
                tasks.append(check_redis())

                await asyncio.gather(*tasks)

                # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                await asyncio.sleep(30)

            except Exception as e:
                logger.error(f"å¥åº·æ£€æŸ¥é”™è¯¯: {e}")
                await asyncio.sleep(30)

if __name__ == "__main__":
    # å¯åŠ¨HTTPæœåŠ¡å™¨
    start_http_server(9103)

    # å¼€å§‹ç›‘æ§
    logger.info("å¥åº·ç›‘æ§å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£9103")
    asyncio.run(monitor_health())
EOF

    chmod +x scripts/monitoring/health_check.py

    # åˆ›å»ºsystemdæœåŠ¡
    sudo tee /etc/systemd/system/health-monitor.service > /dev/null <<EOF
[Unit]
Description=Health Monitor
After=network.target

[Service]
Type=simple
User=monitoring
WorkingDirectory=$(pwd)
ExecStart=$(pwd)/scripts/monitoring/health_check.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

    # å¯åŠ¨æœåŠ¡
    sudo systemctl daemon-reload
    sudo systemctl enable health-monitor
    sudo systemctl start health-monitor

    log_info "å¥åº·ç›‘æ§å·²é…ç½®å¹¶å¯åŠ¨"
}

# æµ‹è¯•å‘Šè­¦
test_alerts() {
    log_step "æµ‹è¯•å‘Šè­¦ç³»ç»Ÿ..."

    # åˆ›å»ºæµ‹è¯•è„šæœ¬
    cat > scripts/monitoring/test_alerts.py <<'EOF'
#!/usr/bin/env python3
"""
æµ‹è¯•å‘Šè­¦ç³»ç»Ÿ
"""

import requests
import time

def test_prometheus_alerts():
    """æµ‹è¯•Prometheuså‘Šè­¦"""
    print("æµ‹è¯•Prometheuså‘Šè­¦è§„åˆ™...")

    # æŸ¥è¯¢å½“å‰å‘Šè­¦
    response = requests.get('http://localhost:9090/api/v1/alerts')
    if response.status_code == 200:
        alerts = response.json()
        print(f"å½“å‰æ´»è·ƒå‘Šè­¦æ•°: {len(alerts['data']['alerts'])}")
    else:
        print("æ— æ³•è·å–å‘Šè­¦ä¿¡æ¯")

def test_alertmanager():
    """æµ‹è¯•Alertmanager"""
    print("æµ‹è¯•Alertmanager...")

    # æ£€æŸ¥AlertmanagerçŠ¶æ€
    response = requests.get('http://localhost:9093/api/v1/status')
    if response.status_code == 200:
        print("âœ“ Alertmanagerè¿è¡Œæ­£å¸¸")
    else:
        print("âœ— Alertmanageræ— æ³•è®¿é—®")

if __name__ == "__main__":
    test_prometheus_alerts()
    test_alertmanager()
EOF

    chmod +x scripts/monitoring/test_alerts.py

    # è¿è¡Œæµ‹è¯•
    python3 scripts/monitoring/test_alerts.py

    log_info "å‘Šè­¦ç³»ç»Ÿæµ‹è¯•å®Œæˆ"
}

# åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿
create_monitoring_dashboard() {
    log_step "åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿..."

    # åˆ›å»ºç³»ç»Ÿæ¦‚è§ˆä»ªè¡¨æ¿
    cat > monitoring/production/dashboards/system-overview.json <<'EOF'
{
  "dashboard": {
    "id": null,
    "title": "Production System Overview",
    "tags": ["production", "system"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Service Status",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=~\"football-prediction|postgres|redis|nginx\"}",
            "legendFormat": "{{ job }}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "green", "value": 1}
              ]
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{ method }} {{ endpoint }}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 4,
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      }
    ],
    "time": {"from": "now-1h", "to": "now"},
    "refresh": "30s"
  }
}
EOF

    log_info "ç›‘æ§ä»ªè¡¨æ¿å·²åˆ›å»º"
}

# ä¸»å‡½æ•°
main() {
    echo ""
    echo "=========================================="
    echo "é…ç½®ç”Ÿäº§ç¯å¢ƒç›‘æ§ç³»ç»Ÿ"
    echo "=========================================="
    echo ""

    # æ£€æŸ¥æ˜¯å¦ä¸ºrootç”¨æˆ·
    if [[ $EUID -eq 0 ]]; then
        log_error "è¯·ä¸è¦ä»¥rootç”¨æˆ·è¿è¡Œæ­¤è„šæœ¬"
        exit 1
    fi

    # æ£€æŸ¥å¿…è¦å·¥å…·
    for tool in wget tar systemctl; do
        if ! command -v "$tool" &> /dev/null; then
            log_error "ç¼ºå°‘å¿…è¦å·¥å…·: $tool"
            exit 1
        fi
    done

    # æ‰§è¡Œé…ç½®æ­¥éª¤
    create_directories
    setup_prometheus_rules
    setup_alertmanager
    create_alert_templates
    setup_node_exporter
    setup_process_monitoring
    setup_log_monitoring
    setup_health_checks
    create_monitoring_dashboard
    test_alerts

    echo ""
    echo "=========================================="
    echo "ç”Ÿäº§ç¯å¢ƒç›‘æ§é…ç½®å®Œæˆï¼"
    echo "=========================================="
    echo ""
    echo "è®¿é—®åœ°å€ï¼š"
    echo "  â€¢ Prometheus:   http://localhost:9090"
    echo "  â€¢ Grafana:      http://localhost:3000"
    echo "  â€¢ Alertmanager: http://localhost:9093"
    echo ""
    echo "ç›‘æ§æŒ‡æ ‡ï¼š"
    echo "  â€¢ Node Exporter: http://localhost:9100/metrics"
    echo "  â€¢ Process Monitor: http://localhost:9101/metrics"
    echo "  â€¢ Log Monitor:    http://localhost:9102/metrics"
    echo "  â€¢ Health Monitor: http://localhost:9103/metrics"
    echo ""
    echo "ç®¡ç†å‘½ä»¤ï¼š"
    echo "  â€¢ æŸ¥çœ‹å‘Šè­¦: curl $ALERTMANAGER_URL/api/v1/alerts"
    echo "  â€¢ æŸ¥çœ‹è§„åˆ™: curl $PROMETHEUS_URL/api/v1/rules"
    echo ""
    echo "æœåŠ¡çŠ¶æ€ï¼š"
    sudo systemctl status node-exporter process-monitor log-monitor health-monitor
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
