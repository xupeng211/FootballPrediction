#!/usr/bin/env python3
"""
ç´§æ€¥ä»£ç è´¨é‡ä¿®å¤å·¥å…·
Emergency Code Quality Fixer

å¿«é€Ÿä¿®å¤å…³é”®çš„æœªå®šä¹‰åç§°å’Œå¯¼å…¥é”™è¯¯ï¼Œç¡®ä¿ä»£ç å¯æ­£å¸¸è¿è¡Œã€‚
"""

import re
import subprocess
from pathlib import Path


class EmergencyQualityFixer:
    """ç´§æ€¥ä»£ç è´¨é‡ä¿®å¤å™¨"""

    def __init__(self, source_dir: str = "src"):
        self.source_dir = Path(source_dir)
        self.fix_count = 0
        self.error_files = {}

    def find_files_with_errors(self) -> list[Path]:
        """æŸ¥æ‰¾æœ‰é”™è¯¯çš„æ–‡ä»¶"""
        try:
            # ä½¿ç”¨ruffæ£€æŸ¥F821é”™è¯¯
            result = subprocess.run(
                ["ruff", "check", str(self.source_dir), "--select=F821", "--output-format=text"],
                capture_output=True,
                text=True,
                timeout=60
            )

            error_files = set()
            for line in result.stdout.split('\n'):
                if ':' in line and 'F821' in line:
                    file_path = line.split(':')[0]
                    if Path(file_path).exists():
                        error_files.add(Path(file_path))

            return list(error_files)

        except Exception as e:
            print(f"é”™è¯¯æ£€æŸ¥å¤±è´¥: {e}")
            return []

    def analyze_missing_imports(self, file_path: Path) -> set[str]:
        """åˆ†æç¼ºå¤±çš„å¯¼å…¥"""
        try:
            result = subprocess.run(
                ["ruff", "check", str(file_path), "--select=F821", "--output-format=text"],
                capture_output=True,
                text=True,
                timeout=30
            )

            missing_names = set()
            for line in result.stdout.split('\n'):
                if 'F821' in line and 'Undefined name' in line:
                    # æå–æœªå®šä¹‰çš„åç§°
                    match = re.search(r'`([^`]+)`', line)
                    if match:
                        missing_names.add(match.group(1))

            return missing_names

        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return set()

    def fix_file_imports(self, file_path: Path) -> bool:
        """ä¿®å¤æ–‡ä»¶çš„å¯¼å…¥é—®é¢˜"""
        try:
            with open(file_path, encoding='utf-8') as f:
                content = f.read()

            # åˆ†æç¼ºå¤±çš„å¯¼å…¥
            missing_names = self.analyze_missing_imports(file_path)
            if not missing_names:
                return True

            # ç”Ÿæˆéœ€è¦çš„å¯¼å…¥è¯­å¥
            imports_to_add = []
            for name in missing_names:
                if name in ['APIRouter', 'Depends', 'HTTPException', 'Query', 'BackgroundTasks']:
                    imports_to_add.append(f"from fastapi import {name}")
                elif name in ['Dict', 'List', 'Optional', 'Any', 'Union', 'Callable']:
                    imports_to_add.append(f"from typing import {name}")
                elif name in ['datetime', 'os', 'sys', 'json', 're', 'pathlib']:
                    imports_to_add.append(f"import {name}")
                elif name == 'e':
                    # è¿™æ˜¯ä¸€ä¸ªå¼‚å¸¸å˜é‡ï¼Œéœ€è¦æ£€æŸ¥ä¸Šä¸‹æ–‡
                    continue
                else:
                    # å…¶ä»–å¯èƒ½çš„å¯¼å…¥
                    imports_to_add.append(f"# TODO: éœ€è¦å¯¼å…¥ {name}")

            if not imports_to_add:
                return True

            # æ‰¾åˆ°æ’å…¥ä½ç½®ï¼ˆæ–‡ä»¶å¼€å¤´ï¼Œåœ¨æ–‡æ¡£å­—ç¬¦ä¸²ä¹‹åï¼‰
            lines = content.split('\n')
            insert_index = 0

            # è·³è¿‡æ–‡ä»¶å¼€å¤´çš„æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²
            for i, line in enumerate(lines):
                if line.strip().startswith('"""') or line.strip().startswith("'''"):
                    # æ‰¾åˆ°æ–‡æ¡£å­—ç¬¦ä¸²ç»“æŸ
                    quote_type = line.strip()[:3]
                    for j in range(i + 1, len(lines)):
                        if quote_type in lines[j]:
                            insert_index = j + 1
                            break
                    break
                elif line.strip().startswith('import') or line.strip().startswith('from'):
                    # æ‰¾åˆ°ç°æœ‰å¯¼å…¥çš„ç»“æŸä½ç½®
                    for j in range(i, len(lines)):
                        if not (lines[j].strip().startswith('import') or
                               lines[j].strip().startswith('from') or
                               lines[j].strip() == '' or
                               lines[j].strip().startswith('#')):
                            insert_index = j
                            break
                    break
            else:
                insert_index = 0

            # æ’å…¥æ–°çš„å¯¼å…¥è¯­å¥
            for import_stmt in reversed(imports_to_add):
                lines.insert(insert_index, import_stmt)

            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(lines))

            print(f"âœ… ä¿®å¤æ–‡ä»¶: {file_path} (æ·»åŠ äº† {len(imports_to_add)} ä¸ªå¯¼å…¥)")
            self.fix_count += 1
            return True

        except Exception as e:
            print(f"âŒ ä¿®å¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False

    def fix_fastapi_specific_issues(self, file_path: Path) -> bool:
        """ä¿®å¤FastAPIç‰¹å®šçš„å¯¼å…¥é—®é¢˜"""
        try:
            with open(file_path, encoding='utf-8') as f:
                content = f.read()

            original_content = content

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†FastAPIç›¸å…³çš„ç±»å‹ä½†ç¼ºå°‘å¯¼å…¥
            fastapi_patterns = [
                (r'\bAPIRouter\b', 'from fastapi import APIRouter'),
                (r'\bDepends\b', 'from fastapi import Depends'),
                (r'\bHTTPException\b', 'from fastapi import HTTPException'),
                (r'\bQuery\b', 'from fastapi import Query'),
                (r'\bBackgroundTasks\b', 'from fastapi import BackgroundTasks'),
                (r'\bStatusCodes\b', 'from fastapi import status'),
                (r'\bRequest\b', 'from fastapi import Request'),
                (r'\bResponse\b', 'from fastapi import Response'),
            ]

            lines = content.split('\n')
            imports_needed = set()

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿™äº›å¯¼å…¥
            for pattern, import_stmt in fastapi_patterns:
                if re.search(pattern, content) and import_stmt not in content:
                    imports_needed.add(import_stmt)

            if imports_needed:
                # æ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®
                insert_index = 0
                for i, line in enumerate(lines):
                    if line.strip().startswith('from fastapi import'):
                        # å·²æœ‰FastAPIå¯¼å…¥ï¼Œåˆå¹¶åˆ°åŒä¸€è¡Œ
                        fastapi_imports = line.strip()
                        for import_stmt in imports_needed:
                            if import_stmt not in fastapi_imports:
                                fastapi_imports += f", {import_stmt.split('import ')[1]}"
                        lines[i] = fastapi_imports
                        imports_needed.clear()
                        break
                    elif line.strip().startswith('import') and 'fastapi' not in line:
                        insert_index = i
                        break
                else:
                    # åœ¨æ–‡ä»¶å¼€å¤´æ’å…¥
                    insert_index = 0

                # æ’å…¥æ–°çš„å¯¼å…¥
                for import_stmt in sorted(imports_needed):
                    lines.insert(insert_index, import_stmt)
                    insert_index += 1

                content = '\n'.join(lines)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦typingå¯¼å…¥
            typing_patterns = [
                (r'\bDict\b', 'from typing import Dict'),
                (r'\bList\b', 'from typing import List'),
                (r'\bOptional\b', 'from typing import Optional'),
                (r'\bAny\b', 'from typing import Any'),
                (r'\bUnion\b', 'from typing import Union'),
                (r'\bCallable\b', 'from typing import Callable'),
            ]

            for pattern, import_stmt in typing_patterns:
                if re.search(pattern, content) and import_stmt not in content:
                    if 'from typing import' in content:
                        # åˆå¹¶åˆ°ç°æœ‰typingå¯¼å…¥
                        for i, line in enumerate(lines):
                            if line.strip().startswith('from typing import'):
                                lines[i] = line.strip() + f", {import_stmt.split('import ')[1]}"
                                break
                    else:
                        # æ·»åŠ æ–°çš„typingå¯¼å…¥
                        for i, line in enumerate(lines):
                            if line.strip().startswith('import') and 'typing' not in line:
                                lines.insert(i, import_stmt)
                                break
                        else:
                            lines.insert(0, import_stmt)

            content = '\n'.join(lines)

            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… ä¿®å¤FastAPIå¯¼å…¥: {file_path}")
                self.fix_count += 1
                return True

            return True

        except Exception as e:
            print(f"âŒ ä¿®å¤FastAPIå¯¼å…¥å¤±è´¥ {file_path}: {e}")
            return False

    def run_emergency_fix(self) -> dict:
        """è¿è¡Œç´§æ€¥ä¿®å¤"""
        print("ğŸš¨ å¼€å§‹ç´§æ€¥ä»£ç è´¨é‡ä¿®å¤...")

        # æŸ¥æ‰¾æœ‰é”™è¯¯çš„æ–‡ä»¶
        error_files = self.find_files_with_errors()
        print(f"ğŸ“Š å‘ç° {len(error_files)} ä¸ªæ–‡ä»¶æœ‰é”™è¯¯")

        if not error_files:
            print("âœ… æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„é”™è¯¯")
            return {"fixed_files": 0, "total_files": 0}

        # é€ä¸ªä¿®å¤æ–‡ä»¶
        fixed_count = 0
        for file_path in error_files:
            print(f"\nğŸ”§ ä¿®å¤æ–‡ä»¶: {file_path}")

            # ä¿®å¤FastAPIç‰¹å®šé—®é¢˜
            if self.fix_fastapi_specific_issues(file_path):
                fixed_count += 1

        print("\nğŸ“Š ä¿®å¤å®Œæˆ:")
        print(f"  ä¿®å¤æ–‡ä»¶æ•°: {fixed_count}/{len(error_files)}")
        print(f"  æ€»ä¿®å¤æ“ä½œ: {self.fix_count}")

        return {
            "fixed_files": fixed_count,
            "total_files": len(error_files),
            "total_fixes": self.fix_count
        }

    def verify_fixes(self) -> bool:
        """éªŒè¯ä¿®å¤ç»“æœ"""
        print("\nğŸ” éªŒè¯ä¿®å¤ç»“æœ...")

        try:
            result = subprocess.run(
                ["ruff", "check", str(self.source_dir), "--select=F821", "--output-format=text"],
                capture_output=True,
                text=True,
                timeout=60
            )

            remaining_errors = len([line for line in result.stdout.split('\n') if 'F821' in line])

            if remaining_errors == 0:
                print("âœ… æ‰€æœ‰F821é”™è¯¯å·²ä¿®å¤!")
                return True
            else:
                print(f"âš ï¸  è¿˜æœ‰ {remaining_errors} ä¸ªF821é”™è¯¯éœ€è¦å¤„ç†")
                return False

        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ç´§æ€¥ä»£ç è´¨é‡ä¿®å¤")
    parser.add_argument(
        "--source-dir",
        default="src",
        help="æºä»£ç ç›®å½• (é»˜è®¤: src)"
    )
    parser.add_argument(
        "--verify-only",
        action="store_true",
        help="ä»…éªŒè¯ï¼Œä¸ä¿®å¤"
    )

    args = parser.parse_args()

    fixer = EmergencyQualityFixer(args.source_dir)

    if args.verify_only:
        fixer.verify_fixes()
    else:
        # è¿è¡Œä¿®å¤
        result = fixer.run_emergency_fix()

        # éªŒè¯ç»“æœ
        success = fixer.verify_fixes()

        if success:
            print("\nğŸ‰ ç´§æ€¥ä¿®å¤å®Œæˆ!")
            print("ğŸ’¡ å»ºè®®è¿è¡Œ: ruff check src/ --fix æ¥ä¿®å¤å…¶ä»–æ ¼å¼é—®é¢˜")
        else:
            print("\nâš ï¸ éƒ¨åˆ†é—®é¢˜æœªèƒ½è‡ªåŠ¨ä¿®å¤ï¼Œå»ºè®®æ‰‹åŠ¨æ£€æŸ¥")


if __name__ == "__main__":
    main()
