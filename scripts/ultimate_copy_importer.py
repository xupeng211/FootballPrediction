#!/usr/bin/env python3
"""
é¦–å¸­æ•°æ®åº“æ¶æ„å¸ˆä¸“ç”¨ç»ˆæCOPYå¯¼å…¥å™¨
å®Œç¾å¤„ç†æ‰€æœ‰åˆ—åæ˜ å°„å’ŒSQLè¯­æ³•é—®é¢˜
"""

import subprocess
import logging
import csv
import io
from pathlib import Path
from datetime import datetime

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class UltimateCopyImporter:
    """é¦–å¸­æ•°æ®åº“æ¶æ„å¸ˆä¸“ç”¨ç»ˆæCOPYå¯¼å…¥å™¨"""

    def __init__(self):
        self.csv_dir = Path("data/fbref")
        self.stats = {
            "total_files": 0,
            "success_files": 0,
            "failed_files": 0,
            "total_rows": 0,
            "start_time": datetime.now(),
        }

    def analyze_csv_structure(self, csv_file: Path) -> dict:
        """åˆ†æCSVæ–‡ä»¶ç»“æ„"""
        with open(csv_file, encoding="utf-8") as f:
            reader = csv.reader(f)
            headers = next(reader)

            # æ£€æŸ¥xGç›¸å…³åˆ—
            has_xg = any("xG" in h for h in headers if h)
            has_xg_away = any("xG.1" in h for h in headers if h)

            return {
                "headers": headers,
                "has_xg": has_xg,
                "has_xg_away": has_xg_away,
                "col_count": len(headers),
            }

    def create_perfect_csv_data(self, csv_file: Path, structure: dict) -> io.StringIO:
        """åˆ›å»ºä¸æ•°æ®åº“è¡¨å®Œç¾åŒ¹é…çš„CSVæ•°æ®"""
        output = io.StringIO()

        with open(csv_file, encoding="utf-8") as f:
            reader = csv.DictReader(f)

            # å®šä¹‰æ ‡å‡†åˆ—åï¼ˆä¸æ•°æ®åº“è¡¨å®Œå…¨ä¸€è‡´ï¼‰
            fieldnames = [
                "wk",
                "Day",
                "Date",
                "Time",
                "Home",
                "xG",
                "Score",
                "xG.1",
                "Away",
                "Attendance",
                "Venue",
                "Referee",
                "Match Report",
                "Notes",
                "source_file",
            ]

            writer = csv.DictWriter(output, fieldnames=fieldnames)
            writer.writeheader()

            # è½¬æ¢æ¯ä¸€è¡Œæ•°æ®
            for row in reader:
                # æ ‡å‡†åŒ–æ•°æ®
                csv_row = {
                    "wk": row.get("Wk", ""),
                    "Day": row.get("Day", ""),
                    "Date": row.get("Date", ""),
                    "Time": row.get("Time", ""),
                    "Home": row.get("Home", ""),
                    "Score": row.get("Score", ""),
                    "Away": row.get("Away", ""),
                    "Attendance": row.get("Attendance", ""),
                    "Venue": row.get("Venue", ""),
                    "Referee": row.get("Referee", ""),
                    "Match Report": row.get("Match Report", ""),
                    "Notes": row.get("Notes", ""),
                    "source_file": csv_file.name,
                }

                # å¤„ç†xGæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if structure["has_xg"]:
                    csv_row["xG"] = row.get("xG", "")
                    csv_row["xG.1"] = row.get("xG.1", "")
                else:
                    csv_row["xG"] = ""
                    csv_row["xG.1"] = ""

                writer.writerow(csv_row)

        output.seek(0)
        return output

    def execute_perfect_copy(self, csv_file: Path) -> bool:
        """æ‰§è¡Œå®Œç¾çš„COPYå¯¼å…¥"""
        try:
            filename = csv_file.name
            logger.info(f"ğŸ“„ å¼€å§‹å¯¼å…¥: {filename}")

            # åˆ†æCSVç»“æ„
            structure = self.analyze_csv_structure(csv_file)
            logger.info(
                f"ğŸ“Š ç»“æ„åˆ†æ: {structure['col_count']}åˆ—, xG={structure['has_xg']}"
            )

            # åˆ›å»ºå®Œç¾çš„CSVæ•°æ®
            perfect_csv = self.create_perfect_csv_data(csv_file, structure)

            # æ„å»ºå®Œç¾çš„COPY SQLï¼ˆæ‰€æœ‰åˆ—åéƒ½ç”¨åŒå¼•å·ï¼‰
            copy_sql = f"""
            -- æ¸…ç†ä¹‹å‰çš„ç›¸åŒæ–‡ä»¶æ•°æ®
            DELETE FROM stg_fbref_matches WHERE source_file = '{filename}';

            -- æ‰§è¡Œå®Œç¾çš„COPYå¯¼å…¥
            COPY stg_fbref_matches ("wk", "Day", "Date", "Time", "Home", "xG", "Score", "xG.1", "Away",
                                   "Attendance", "Venue", "Referee", "Match Report", "Notes", "source_file")
            FROM STDIN WITH CSV HEADER;
            """

            # ä½¿ç”¨Dockeræ‰§è¡ŒCOPY
            cmd = [
                "docker-compose",
                "exec",
                "-T",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-c",
                copy_sql,
            ]

            process = subprocess.Popen(
                cmd,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
            stdout, stderr = process.communicate(input=perfect_csv.getvalue())

            if process.returncode == 0:
                # è·å–å¯¼å…¥è¡Œæ•°
                count_cmd = [
                    "docker-compose",
                    "exec",
                    "db",
                    "psql",
                    "-U",
                    "postgres",
                    "-d",
                    "football_prediction",
                    "-tAc",
                    f"SELECT COUNT(*) FROM stg_fbref_matches WHERE source_file = '{filename}';",
                ]

                count_result = subprocess.run(count_cmd, capture_output=True, text=True)
                if count_result.returncode == 0:
                    rows = int(count_result.stdout.strip())
                    self.stats["total_rows"] += rows
                    logger.info(f"âœ… å¯¼å…¥æˆåŠŸ: {rows:,} è¡Œ")
                    return True
                else:
                    logger.error(f"âŒ è·å–è¡Œæ•°å¤±è´¥: {count_result.stderr}")
                    return False
            else:
                logger.error(f"âŒ COPYå¤±è´¥: {stderr}")
                return False

        except Exception as e:
            logger.error(f"âŒ å¯¼å…¥å¼‚å¸¸ {filename}: {e}")
            import traceback

            traceback.print_exc()
            return False

    def run(self):
        """æ‰§è¡Œç»ˆæCOPYå¯¼å…¥"""
        logger.info("ğŸš€ å¯åŠ¨é¦–å¸­æ•°æ®åº“æ¶æ„å¸ˆä¸“ç”¨ç»ˆæCOPYå¯¼å…¥å™¨")

        # æ‰«æCSVæ–‡ä»¶
        csv_files = list(self.csv_dir.glob("*.csv"))
        self.stats["total_files"] = len(csv_files)

        logger.info(f"ğŸ“ å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")

        if not csv_files:
            logger.error("âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶!")
            return self.stats

        # é¦–å…ˆç¡®ä¿è¡¨å­˜åœ¨å¹¶æ¸…ç©º
        init_cmd = [
            "docker-compose",
            "exec",
            "db",
            "psql",
            "-U",
            "postgres",
            "-d",
            "football_prediction",
            "-c",
            "TRUNCATE TABLE stg_fbref_matches RESTART IDENTITY;",
        ]

        result = subprocess.run(init_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("ğŸ§¹ ä¸´æ—¶è¡¨å·²æ¸…ç©º")
        else:
            logger.error(f"âŒ æ¸…ç©ºè¡¨å¤±è´¥: {result.stderr}")
            return self.stats

        # é€ä¸ªå¯¼å…¥æ–‡ä»¶
        for i, csv_file in enumerate(csv_files, 1):
            logger.info(f"ğŸ”„ è¿›åº¦: {i}/{len(csv_files)} ({i/len(csv_files)*100:.1f}%)")

            success = self.execute_perfect_copy(csv_file)

            if success:
                self.stats["success_files"] += 1
            else:
                self.stats["failed_files"] += 1

        # è·å–æœ€ç»ˆç»Ÿè®¡
        final_stats_cmd = [
            "docker-compose",
            "exec",
            "db",
            "psql",
            "-U",
            "postgres",
            "-d",
            "football_prediction",
            "-c",
            """
            SELECT
                COUNT(*) as total_rows,
                COUNT(DISTINCT source_file) as unique_files,
                COUNT(DISTINCT "Home") as unique_home_teams,
                COUNT(DISTINCT "Away") as unique_away_teams,
                COUNT(CASE WHEN "xG" IS NOT NULL AND "xG" != '' THEN 1 END) as xg_matches,
                COUNT(CASE WHEN "xG" IS NULL OR "xG" = '' THEN 1 END) as no_xg_matches
            FROM stg_fbref_matches;
            """,
        ]

        result = subprocess.run(final_stats_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("ğŸ“Š æœ€ç»ˆæ•°æ®åº“ç»Ÿè®¡:")
            for line in result.stdout.strip().split("\n"):
                if "|" in line and not line.startswith("---"):
                    logger.info(f"   {line}")

        # æ˜¾ç¤ºå¯¼å…¥æ–‡ä»¶æ ·æœ¬
        sample_cmd = [
            "docker-compose",
            "exec",
            "db",
            "psql",
            "-U",
            "postgres",
            "-d",
            "football_prediction",
            "-c",
            """
            SELECT source_file, COUNT(*) as rows
            FROM stg_fbref_matches
            GROUP BY source_file
            ORDER BY rows DESC
            LIMIT 5;
            """,
        ]

        result = subprocess.run(sample_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("ğŸ“ˆ å¯¼å…¥æ–‡ä»¶TOP5:")
            for line in result.stdout.strip().split("\n"):
                if "|" in line and not line.startswith("---"):
                    logger.info(f"   {line}")

        # è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
        end_time = datetime.now()
        duration = (end_time - self.stats["start_time"]).total_seconds()

        logger.info("=" * 60)
        logger.info("ğŸ‰ ç»ˆæCOPYå¯¼å…¥å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’")
        logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶: {self.stats['total_files']}")
        logger.info(f"âœ… æˆåŠŸæ–‡ä»¶: {self.stats['success_files']}")
        logger.info(f"âŒ å¤±è´¥æ–‡ä»¶: {self.stats['failed_files']}")
        logger.info(f"âš½ æ€»æ•°æ®è¡Œ: {self.stats['total_rows']:,}")
        if duration > 0 and self.stats["total_rows"] > 0:
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {self.stats['total_rows']/duration:.0f} è¡Œ/ç§’")

        # æˆåŠŸç‡
        success_rate = (
            self.stats["success_files"] / self.stats["total_files"] * 100
            if self.stats["total_files"] > 0
            else 0
        )
        logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")

        return self.stats


def main():
    """ä¸»å‡½æ•°"""
    try:
        importer = UltimateCopyImporter()
        stats = importer.run()

        if stats["success_files"] > 0:
            logger.info(
                f"âœ… ç»ˆæå¯¼å…¥æˆåŠŸ! {stats['success_files']} ä¸ªæ–‡ä»¶, {stats['total_rows']:,} è¡Œæ•°æ®"
            )
            return 0
        else:
            logger.error("âŒ ç»ˆæå¯¼å…¥å¤±è´¥!")
            return 1

    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
