#!/usr/bin/env python3
"""P1-7 é‡‡é›†å™¨å‹æµ‹è„šæœ¬
P1-7 Collector Load Testing Script.

å¯¹FotMobCollectorV2è¿›è¡Œå¹¶å‘å‹åŠ›æµ‹è¯•ï¼ŒéªŒè¯RateLimiteræ€§èƒ½ã€‚
Stress test FotMobCollectorV2 with concurrent requests to verify RateLimiter performance.

Author: Claude Code
Version: 1.0.0
"""

import asyncio
import time
import sys
import statistics
from datetime import datetime
from typing import Optional
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, "/app")

from src.collectors.fotmob.collector_v2 import FotMobCollectorV2
from src.collectors.rate_limiter import RateLimiter


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ."""

    total_requests: int
    successful_requests: int
    failed_requests: int
    total_time: float
    min_response_time: float
    max_response_time: float
    avg_response_time: float
    p50_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float
    error_rate: float
    error_messages: list[str]


@dataclass
class RequestMetric:
    """å•ä¸ªè¯·æ±‚æŒ‡æ ‡."""

    request_id: int
    start_time: float
    end_time: float
    response_time: float
    success: bool
    error_message: Optional[str] = None
    data_size: int = 0


class CollectorBenchmarker:
    """é‡‡é›†å™¨åŸºå‡†æµ‹è¯•å™¨."""

    def __init__(self):
        """åˆå§‹åŒ–åŸºå‡†æµ‹è¯•å™¨."""
        self.collector = None
        self.rate_limiter = None
        self.results: list[RequestMetric] = []

    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ."""
        print("ğŸ”§ åˆå§‹åŒ–é‡‡é›†å™¨å‹æµ‹ç¯å¢ƒ...")

        try:
            # åˆå§‹åŒ–RateLimiter - è®¾ç½®è¾ƒä½çš„QPSç”¨äºæµ‹è¯•
            rate_limit_config = {
                "fotmob.com": {
                    "rate": 5.0,  # 5 QPSé™åˆ¶
                    "burst": 10,  # çªå‘é™åˆ¶
                    "max_wait_time": 30.0,  # æœ€å¤§ç­‰å¾…30ç§’
                },
                "default": {
                    "rate": 1.0,  # é»˜è®¤1 QPS
                    "burst": 2,  # çªå‘é™åˆ¶
                    "max_wait_time": 30.0,
                },
            }
            self.rate_limiter = RateLimiter(rate_limit_config)

            # åˆå§‹åŒ–FotMobCollectorV2
            self.collector = FotMobCollectorV2(rate_limiter=self.rate_limiter)

            print("âœ… é‡‡é›†å™¨å’Œé™æµå™¨åˆå§‹åŒ–å®Œæˆ")
            print("   ğŸ“Š RateLimiteré…ç½®: 5 QPS (fotmob.com)")

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def collect_single_match(self, match_id: int) -> RequestMetric:
        """æ”¶é›†å•ä¸ªæ¯”èµ›æ•°æ®."""
        request_id = match_id
        start_time = time.time()
        success = False
        error_message = None
        data_size = 0

        try:
            # æ¨¡æ‹Ÿæ•°æ®æ”¶é›†
            result = await self.collector.collect_match_details(match_id)
            end_time = time.time()

            if result:
                success = True
                data_size = len(str(result)) if result else 0
                # print(f"   âœ… Match {match_id}: æˆåŠŸæ”¶é›† (å¤§å°: {data_size} bytes)")
            else:
                error_message = "No data returned"
                # print(f"   âš ï¸  Match {match_id}: æ— æ•°æ®è¿”å›")

        except Exception as e:
            end_time = time.time()
            success = False
            error_message = str(e)
            # print(f"   âŒ Match {match_id}: æ”¶é›†å¤±è´¥ - {error_message}")

        response_time = end_time - start_time

        return RequestMetric(
            request_id=request_id,
            start_time=start_time,
            end_time=end_time,
            response_time=response_time,
            success=success,
            error_message=error_message,
            data_size=data_size,
        )

    async def run_concurrent_test(self, concurrent_count: int = 50) -> BenchmarkResult:
        """è¿è¡Œå¹¶å‘æµ‹è¯•."""
        print(f"\nğŸš€ å¼€å§‹å¹¶å‘æµ‹è¯•: {concurrent_count} ä¸ªå¹¶å‘è¯·æ±‚")
        print("-" * 50)

        # ç”Ÿæˆæµ‹è¯•ç”¨çš„match_idåˆ—è¡¨
        test_match_ids = list(range(1, min(concurrent_count + 1, 1000)))

        # å¦‚æœè¯·æ±‚æ•°è¶…è¿‡å¯ç”¨match_idï¼Œé‡å¤ä½¿ç”¨
        while len(test_match_ids) < concurrent_count:
            test_match_ids.extend(
                range(1, min(concurrent_count - len(test_match_ids) + 1, 1000))
            )

        print(f"   ğŸ“Š æµ‹è¯•match_idèŒƒå›´: {min(test_match_ids)}-{max(test_match_ids)}")
        print(f"   ğŸ“Š è¯·æ±‚åˆ†å¸ƒ: {len(test_match_ids)} ä¸ªå”¯ä¸€ID")

        # æ¸…ç©ºä¹‹å‰çš„ç»“æœ
        self.results.clear()

        # è®°å½•å¼€å§‹æ—¶é—´
        overall_start = time.time()

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i, match_id in enumerate(test_match_ids):
            task = asyncio.create_task(
                self.collect_single_match(match_id), name=f"request_{i + 1}"
            )
            tasks.append(task)

        # æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        print(f"   â³ æ‰§è¡Œ {len(tasks)} ä¸ªå¹¶å‘è¯·æ±‚...")
        completed_tasks = await asyncio.gather(*tasks, return_exceptions=True)

        # è®°å½•ç»“æŸæ—¶é—´
        overall_end = time.time()

        # å¤„ç†ç»“æœ
        for i, task_result in enumerate(completed_tasks):
            if isinstance(task_result, RequestMetric):
                self.results.append(task_result)
            else:
                # å¤„ç†å¼‚å¸¸
                self.results.append(
                    RequestMetric(
                        request_id=i + 1,
                        start_time=overall_start,
                        end_time=time.time(),
                        response_time=time.time() - overall_start,
                        success=False,
                        error_message=f"Task exception: {str(task_result)}",
                    )
                )

        # è®¡ç®—åŸºå‡†ç»“æœ
        total_time = overall_end - overall_start
        successful_requests = len([r for r in self.results if r.success])
        failed_requests = len(self.results) - successful_requests

        response_times = [r.response_time for r in self.results]
        min_response_time = min(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p50_response_time = statistics.median(response_times) if response_times else 0

        if len(response_times) >= 20:
            sorted_times = sorted(response_times)
            p95_index = int(len(sorted_times) * 0.95)
            p99_index = int(len(sorted_times) * 0.99)
            p95_response_time = sorted_times[p95_index]
            p99_response_time = sorted_times[p99_index]
        else:
            p95_response_time = max_response_time
            p99_response_time = max_response_time

        requests_per_second = len(self.results) / total_time if total_time > 0 else 0
        error_rate = (failed_requests / len(self.results)) * 100 if self.results else 0
        error_messages = [
            r.error_message for r in self.results if not r.success and r.error_message
        ]

        return BenchmarkResult(
            total_requests=len(self.results),
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            total_time=total_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            avg_response_time=avg_response_time,
            p50_response_time=p50_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=requests_per_second,
            error_rate=error_rate,
            error_messages=error_messages,
        )

    async def run_rate_limiter_test(self):
        """ä¸“é—¨æµ‹è¯•RateLimiteræ•ˆæœ."""
        print("\nğŸ¯ RateLimiterä¸“é¡¹æµ‹è¯•")
        print("-" * 30)

        # æµ‹è¯•æ— RateLimiterçš„å“åº”æ—¶é—´
        print("   ğŸ“Š æµ‹è¯•æ— é™æµæ—¶çš„å“åº”æ—¶é—´...")
        start_time = time.time()
        time.time() - start_time

        # æµ‹è¯•æœ‰RateLimiterçš„é™åˆ¶æ•ˆæœ
        print("   ğŸ“Š æµ‹è¯•æœ‰é™æµæ—¶çš„è¯·æ±‚é—´éš”...")
        rate_limited_times = []

        for i in range(5):  # æµ‹è¯•5ä¸ªè¿ç»­è¯·æ±‚
            start = time.time()
            await self.rate_limiter.acquire()
            end = time.time()
            rate_limited_times.append(end - start)
            print(f"      è¯·æ±‚ {i + 1}: é—´éš” {(end - start) * 1000:.2f}ms")

        avg_interval = statistics.mean(rate_limited_times) if rate_limited_times else 0
        expected_interval = 1000 / 5.0  # 200ms for 5 QPS

        print("   âœ… RateLimiteréªŒè¯:")
        print(f"      ç†è®ºé—´éš”: {expected_interval:.0f}ms")
        print(f"      å®é™…å¹³å‡é—´éš”: {avg_interval * 1000:.1f}ms")
        print(
            f"      é™æµæ•ˆæœ: {'æœ‰æ•ˆ' if avg_interval >= expected_interval * 0.8 else 'æ— æ•ˆ'}"
        )

    async def generate_report(self, results: list[BenchmarkResult]) -> str:
        """ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š."""
        print("\nğŸ“‹ ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print("-" * 50)

        report_lines = [
            "# P1-7 é‡‡é›†å™¨åŸºå‡†æµ‹è¯•æŠ¥å‘Š",
            "# P1-7 Collector Benchmark Report",
            "",
            f"**æµ‹è¯•æ—¶é—´**: {datetime.now().isoformat()}",
            "**æµ‹è¯•ç‰ˆæœ¬**: P1-7 v1.0.0",
            "",
            "## ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦",
            "",
            "| æµ‹è¯•åœºæ™¯ | æ€»è¯·æ±‚æ•° | æˆåŠŸæ•° | å¤±è´¥æ•° | æˆåŠŸç‡ | RPS | å¹³å‡å“åº”æ—¶é—´ | P95å“åº”æ—¶é—´ | é”™è¯¯ç‡ |",
            "|----------|----------|--------|--------|--------|-----|-------------|-------------|--------|",
        ]

        for i, result in enumerate(results):
            report_lines.append(
                f"| åœºæ™¯ {i + 1} | {result.total_requests} | "
                f"{result.successful_requests} | {result.failed_requests} | "
                f"{(result.successful_requests / result.total_requests) * 100:.1f}% | "
                f"{result.requests_per_second:.2f} | "
                f"{result.avg_response_time * 1000:.1f}ms | "
                f"{result.p95_response_time * 1000:.1f}ms | "
                f"{result.error_rate:.2f}% |"
            )

        report_lines.extend(
            [
                "",
                "## ğŸ¯ æ€§èƒ½æŒ‡æ ‡åˆ†æ",
                "",
                f"- **å¹³å‡RPS**: {statistics.mean([r.requests_per_second for r in results]):.2f}",
                f"- **å¹³å‡å“åº”æ—¶é—´**: {statistics.mean([r.avg_response_time * 1000 for r in results]):.1f}ms",
                f"- **å¹³å‡P95å“åº”æ—¶é—´**: {statistics.mean([r.p95_response_time * 1000 for r in results]):.1f}ms",
                f"- **å¹³å‡æˆåŠŸç‡**: {statistics.mean([(r.successful_requests / r.total_requests) * 100 for r in results]):.2f}%",
                "",
                "## ğŸ” ç“¶é¢ˆåˆ†æ",
                "",
            ]
        )

        # ç“¶é¢ˆåˆ†æ
        avg_rps = statistics.mean([r.requests_per_second for r in results])
        if avg_rps < 10:
            report_lines.append("- **æ€§èƒ½ç“¶é¢ˆ**: RPSè¾ƒä½ï¼Œå¯èƒ½å—RateLimiteré™åˆ¶å½±å“")
            report_lines.append("- **å»ºè®®**: è°ƒæ•´RateLimiteré…ç½®æˆ–ä¼˜åŒ–é‡‡é›†é€»è¾‘")

        avg_error_rate = statistics.mean([r.error_rate for r in results])
        if avg_error_rate > 10:
            report_lines.append("- **ç¨³å®šæ€§ç“¶é¢ˆ**: é”™è¯¯ç‡è¾ƒé«˜")
            report_lines.append("- **å»ºè®®**: æ£€æŸ¥å¤–éƒ¨APIå¯ç”¨æ€§å’Œç½‘ç»œè¿æ¥")

        avg_p95 = statistics.mean([r.p95_response_time * 1000 for r in results])
        if avg_p95 > 5000:
            report_lines.append("- **å»¶è¿Ÿç“¶é¢ˆ**: P95å“åº”æ—¶é—´è¾ƒé«˜")
            report_lines.append("- **å»ºè®®**: ä¼˜åŒ–æ•°æ®é‡‡é›†é€»è¾‘æˆ–å¢åŠ ç¼“å­˜")

        report_lines.extend(
            [
                "",
                "## ğŸ“ˆ å‹æµ‹å»ºè®®",
                "",
                "1. **å¹¶å‘æ•°ä¼˜åŒ–**: æ ¹æ®ç³»ç»Ÿèµ„æºè°ƒæ•´å¹¶å‘è¯·æ±‚æ•°",
                "2. **é™æµç­–ç•¥**: æ ¹æ®APIé™åˆ¶è°ƒæ•´RateLimiteré…ç½®",
                "3. **é”™è¯¯å¤„ç†**: å¢å¼ºé‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤",
                "4. **ç›‘æ§å‘Šè­¦**: è®¾ç½®æ€§èƒ½é˜ˆå€¼ç›‘æ§å’Œå‘Šè­¦",
                "",
                f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().isoformat()}",
            ]
        )

        return "\n".join(report_lines)

    async def run_benchmark(self):
        """è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•."""
        print("ğŸš€ å¼€å§‹P1-7é‡‡é›†å™¨åŸºå‡†æµ‹è¯•")
        print("=" * 60)

        try:
            # è®¾ç½®ç¯å¢ƒ
            await self.setup()

            # RateLimiterä¸“é¡¹æµ‹è¯•
            await self.run_rate_limiter_test()

            # å¹¶å‘æµ‹è¯• - ä¸åŒçš„å¹¶å‘çº§åˆ«
            test_scenarios = [10, 25, 50]  # ä¸åŒçš„å¹¶å‘æ•°
            all_results = []

            for concurrent_count in test_scenarios:
                print(f"\nğŸ¯ æµ‹è¯•åœºæ™¯: {concurrent_count} å¹¶å‘è¯·æ±‚")
                print("=" * 40)

                result = await self.run_concurrent_test(concurrent_count)
                all_results.append(result)

                # æ‰“å°å³æ—¶ç»“æœ
                print("\nğŸ“Š å³æ—¶ç»“æœ:")
                print(f"   âœ… æ€»è¯·æ±‚æ•°: {result.total_requests}")
                print(f"   âœ… æˆåŠŸè¯·æ±‚: {result.successful_requests}")
                print(f"   âŒ å¤±è´¥è¯·æ±‚: {result.failed_requests}")
                print(
                    f"   ğŸ“ˆ æˆåŠŸç‡: {(result.successful_requests / result.total_requests) * 100:.2f}%"
                )
                print(f"   âš¡ RPS: {result.requests_per_second:.2f}")
                print(f"   â±ï¸  å¹³å‡å“åº”æ—¶é—´: {result.avg_response_time * 1000:.1f}ms")
                print(f"   â±ï¸  P95å“åº”æ—¶é—´: {result.p95_response_time * 1000:.1f}ms")
                print(f"   âŒ é”™è¯¯ç‡: {result.error_rate:.2f}%")

                # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…ï¼ˆå¦‚æœæœ‰ï¼‰
                if result.error_messages:
                    print(f"   ğŸš¨ é”™è¯¯è¯¦æƒ…: {len(result.error_messages)} ä¸ªé”™è¯¯")
                    for i, error in enumerate(result.error_messages[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"      {i + 1}. {error}")
                    if len(result.error_messages) > 3:
                        print(f"      ... è¿˜æœ‰ {len(result.error_messages) - 3} ä¸ªé”™è¯¯")

                # æµ‹è¯•é—´éš”
                if concurrent_count != test_scenarios[-1]:
                    print("\nâ³ ç­‰å¾… 3 ç§’åè¿›è¡Œä¸‹ä¸€ä¸ªæµ‹è¯•...")
                    await asyncio.sleep(3)

            # ç”ŸæˆæŠ¥å‘Š
            report = await self.generate_report(all_results)

            # ä¿å­˜æŠ¥å‘Š
            report_path = "/app/reports/benchmark_collector_baseline.md"
            try:
                with open(report_path, "w", encoding="utf-8") as f:
                    f.write(report)
                print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            except Exception as e:
                print(f"\nâš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

            return report, all_results

        except Exception as e:
            print(f"\nâŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return None, []


async def main():
    """ä¸»å‡½æ•°."""
    benchmarker = CollectorBenchmarker()
    report, results = await benchmarker.run_benchmark()

    if report and results:
        print("\n" + "=" * 60)
        print("ğŸ¯ P1-7é‡‡é›†å™¨åŸºå‡†æµ‹è¯•å®Œæˆ")
        print("=" * 60)

        # æ€»ç»“
        avg_rps = statistics.mean([r.requests_per_second for r in results])
        avg_success_rate = statistics.mean(
            [(r.successful_requests / r.total_requests) * 100 for r in results]
        )
        avg_p95 = statistics.mean([r.p95_response_time * 1000 for r in results])

        print(f"ğŸ“Š å¹³å‡RPS: {avg_rps:.2f}")
        print(f"ğŸ“Š å¹³å‡æˆåŠŸç‡: {avg_success_rate:.2f}%")
        print(f"ğŸ“Š å¹³å‡P95å“åº”æ—¶é—´: {avg_p95:.1f}ms")

        # æ€§èƒ½è¯„ä¼°
        if avg_rps >= 5 and avg_success_rate >= 90 and avg_p95 <= 5000:
            print("ğŸ† æ€§èƒ½è¯„çº§: ä¼˜ç§€")
        elif avg_rps >= 3 and avg_success_rate >= 80 and avg_p95 <= 10000:
            print("ğŸ‘ æ€§èƒ½è¯„çº§: è‰¯å¥½")
        else:
            print("âš ï¸ æ€§èƒ½è¯„çº§: éœ€è¦ä¼˜åŒ–")

        return True
    else:
        print("âŒ æµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
