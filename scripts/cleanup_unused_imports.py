#!/usr/bin/env python3
"""
æœªä½¿ç”¨å¯¼å…¥æ¸…ç†å·¥å…·
Unused Imports Cleanup Tool

è‡ªåŠ¨æ£€æµ‹å’Œç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥è¯­å¥ï¼Œæ”¯æŒå®‰å…¨æ¸…ç†ã€‚
"""

import ast
import os
import re
from pathlib import Path
from typing import List, Set, Tuple

import subprocess


class UnusedImportsCleaner:
    """æœªä½¿ç”¨å¯¼å…¥æ¸…ç†å™¨"""

    def __init__(self, source_dir: str = "src"):
        self.source_dir = Path(source_dir)
        self.python_files = []
        self.cleanup_results = {}

    def find_python_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []
        for file_path in self.source_dir.rglob("*.py"):
            if not any(skip in str(file_path) for skip in [
                "__pycache__",
                ".git",
                ".pytest_cache",
                "venv",
                ".venv"
            ]):
                python_files.append(file_path)
        return python_files

    def get_unused_imports_ruff(self, file_path: Path) -> List[str]:
        """ä½¿ç”¨ruffè·å–æœªä½¿ç”¨çš„å¯¼å…¥"""
        try:
            # è¿è¡Œruffæ£€æŸ¥
            result = subprocess.run(
                ["ruff", "check", str(file_path), "--select=F401", "--output-format=json"],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                return []  # æ²¡æœ‰æœªä½¿ç”¨çš„å¯¼å…¥

            # è§£æJSONè¾“å‡º
            import json
            try:
                issues = json.loads(result.stdout)
                unused_imports = []
                for issue in issues:
                    if issue.get("code") == "F401":
                        unused_imports.append(issue.get("message", ""))
                return unused_imports
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„æ–‡æœ¬è§£æ
                unused_imports = []
                for line in result.stdout.split('\n'):
                    if 'F401' in line and 'imported but unused' in line:
                        # æå–å¯¼å…¥åç§°
                        match = re.search(r'`([^`]+)` imported but unused', line)
                        if match:
                            unused_imports.append(match.group(1))
                return unused_imports

        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
            print(f"è­¦å‘Š: æ— æ³•æ£€æŸ¥æ–‡ä»¶ {file_path}")
            return []

    def extract_import_info(self, file_path: Path) -> Tuple[List[ast.Import], List[ast.ImportFrom]]:
        """æå–æ–‡ä»¶ä¸­çš„å¯¼å…¥ä¿¡æ¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)
            imports = []
            imports_from = []

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    imports.append(node)
                elif isinstance(node, ast.ImportFrom):
                    imports_from.append(node)

            return imports, imports_from

        except (SyntaxError, UnicodeDecodeError) as e:
            print(f"è­¦å‘Š: æ— æ³•è§£ææ–‡ä»¶ {file_path}: {e}")
            return [], []

    def remove_unused_imports(self, file_path: Path, unused_names: Set[str]) -> bool:
        """ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            imports, imports_from = self.extract_import_info(file_path)
            lines_to_remove = set()

            # æ£€æŸ¥å¯¼å…¥è¯­å¥
            for imp in imports + imports_from:
                for alias in imp.names:
                    name = alias.asname if alias.asname else alias.name
                    if name in unused_names:
                        # æ ‡è®°è¦åˆ é™¤çš„è¡Œ
                        line_num = imp.lineno - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                        if 0 <= line_num < len(lines):
                            lines_to_remove.add(line_num)

            # æ£€æŸ¥å¤šè¡Œå¯¼å…¥
            for imp in imports_from:
                if imp.lineno in [line + 1 for line in lines_to_remove]:
                    # å¦‚æœæ˜¯fromå¯¼å…¥ï¼Œæ£€æŸ¥æ˜¯å¦æ‰€æœ‰åç§°éƒ½æœªä½¿ç”¨
                    all_unused = all(
                        (alias.asname if alias.asname else alias.name) in unused_names
                        for alias in imp.names
                    )
                    if all_unused:
                        line_num = imp.lineno - 1
                        if 0 <= line_num < len(lines):
                            lines_to_remove.add(line_num)

            # ç§»é™¤æ ‡è®°çš„è¡Œ
            new_lines = [
                line for i, line in enumerate(lines)
                if i not in lines_to_remove
            ]

            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            cleaned_lines = []
            prev_empty = False
            for line in new_lines:
                is_empty = line.strip() == ""
                if not (is_empty and prev_empty):
                    cleaned_lines.append(line)
                prev_empty = is_empty

            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(cleaned_lines)

            return len(lines_to_remove) > 0

        except Exception as e:
            print(f"é”™è¯¯: æ¸…ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            return False

    def analyze_unused_imports(self, file_path: Path) -> dict:
        """åˆ†ææ–‡ä»¶çš„æœªä½¿ç”¨å¯¼å…¥"""
        unused_imports = self.get_unused_imports_ruff(file_path)

        if not unused_imports:
            return {"unused_count": 0, "unused_names": [], "safe_to_remove": []}

        # æå–å¯¼å…¥åç§°
        unused_names = set()
        for import_msg in unused_imports:
            # ä»ruffæ¶ˆæ¯ä¸­æå–åç§°
            match = re.search(r'`([^`]+)`', import_msg)
            if match:
                name = match.group(1)
                # å¤„ç†æ¨¡å—å¯¼å…¥çš„æƒ…å†µ
                if '.' in name and not name.endswith('.*'):
                    unused_names.add(name.split('.')[-1])
                else:
                    unused_names.add(name)

        # è¯†åˆ«å¯ä»¥å®‰å…¨ç§»é™¤çš„å¯¼å…¥
        safe_to_remove = []
        dangerous_to_remove = []

        for name in unused_names:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯èƒ½çš„å‰¯ä½œç”¨å¯¼å…¥
            dangerous_patterns = [
                'settings', 'config', 'models', 'signals', 'apps',
                'admin', 'urlpatterns', 'wsgi', 'asgi'
            ]
            if any(pattern in name.lower() for pattern in dangerous_patterns):
                dangerous_to_remove.append(name)
            else:
                safe_to_remove.append(name)

        return {
            "unused_count": len(unused_names),
            "unused_names": list(unused_names),
            "safe_to_remove": safe_to_remove,
            "dangerous_to_remove": dangerous_to_remove
        }

    def cleanup_file(self, file_path: Path, dry_run: bool = True) -> dict:
        """æ¸…ç†å•ä¸ªæ–‡ä»¶"""
        print(f"\nå¤„ç†æ–‡ä»¶: {file_path}")

        analysis = self.analyze_unused_imports(file_path)

        if analysis["unused_count"] == 0:
            print("  âœ… æ²¡æœ‰å‘ç°æœªä½¿ç”¨çš„å¯¼å…¥")
            return {"cleaned": False, "removed_count": 0}

        print(f"  ğŸ“Š å‘ç° {analysis['unused_count']} ä¸ªæœªä½¿ç”¨çš„å¯¼å…¥:")
        for name in analysis["unused_names"]:
            marker = "âš ï¸" if name in analysis["dangerous_to_remove"] else "âœ…"
            print(f"    {marker} {name}")

        if analysis["dangerous_to_remove"]:
            print(f"  âš ï¸ {len(analysis['dangerous_to_remove'])} ä¸ªå¯èƒ½æœ‰å‰¯ä½œç”¨çš„å¯¼å…¥ï¼Œè·³è¿‡æ¸…ç†")
            safe_names = set(analysis["safe_to_remove"])
        else:
            safe_names = set(analysis["unused_names"])

        if not safe_names:
            print("  â„¹ï¸ æ²¡æœ‰å¯ä»¥å®‰å…¨ç§»é™¤çš„å¯¼å…¥")
            return {"cleaned": False, "removed_count": 0}

        if dry_run:
            print(f"  ğŸ§ª é¢„è®¡å°†ç§»é™¤ {len(safe_names)} ä¸ªå¯¼å…¥")
            return {"cleaned": False, "removed_count": len(safe_names), "dry_run": True}

        # å®é™…æ¸…ç†
        success = self.remove_unused_imports(file_path, safe_names)
        if success:
            print(f"  âœ… æˆåŠŸç§»é™¤ {len(safe_names)} ä¸ªæœªä½¿ç”¨çš„å¯¼å…¥")
            return {"cleaned": True, "removed_count": len(safe_names)}
        else:
            print("  âŒ æ¸…ç†å¤±è´¥")
            return {"cleaned": False, "removed_count": 0}

    def cleanup_all_files(self, dry_run: bool = True) -> dict:
        """æ¸…ç†æ‰€æœ‰æ–‡ä»¶"""
        print("ğŸ§¹ å¼€å§‹æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥...")
        print(f"ğŸ“ æœç´¢ç›®å½•: {self.source_dir}")

        python_files = self.find_python_files()
        print(f"ğŸ“„ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

        if not python_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°Pythonæ–‡ä»¶")
            return {"total_files": 0, "cleaned_files": 0, "total_removed": 0}

        total_removed = 0
        cleaned_files = 0

        for file_path in python_files:
            result = self.cleanup_file(file_path, dry_run)
            if result.get("cleaned", False):
                cleaned_files += 1
                total_removed += result.get("removed_count", 0)

        summary = {
            "total_files": len(python_files),
            "cleaned_files": cleaned_files,
            "total_removed": total_removed,
            "dry_run": dry_run
        }

        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ¸…ç†å®Œæˆ ({'é¢„è§ˆæ¨¡å¼' if dry_run else 'å®é™…æ¸…ç†'})")
        print(f"{'='*60}")
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {summary['total_files']}")
        print(f"ğŸ§¹ æ¸…ç†æ–‡ä»¶æ•°: {summary['cleaned_files']}")
        print(f"ğŸ—‘ï¸ ç§»é™¤å¯¼å…¥æ•°: {summary['total_removed']}")

        if dry_run and summary['total_removed'] > 0:
            print(f"\nğŸ’¡ è¦å®é™…æ‰§è¡Œæ¸…ç†ï¼Œè¯·ä½¿ç”¨ --no-dry-run å‚æ•°")

        return summary


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥")
    parser.add_argument(
        "--source-dir",
        default="src",
        help="æºä»£ç ç›®å½• (é»˜è®¤: src)"
    )
    parser.add_argument(
        "--no-dry-run",
        action="store_true",
        help="å®é™…æ‰§è¡Œæ¸…ç† (é»˜è®¤ä¸ºé¢„è§ˆæ¨¡å¼)"
    )
    parser.add_argument(
        "--file",
        help="åªå¤„ç†æŒ‡å®šæ–‡ä»¶"
    )

    args = parser.parse_args()

    cleaner = UnusedImportsCleaner(args.source_dir)

    if args.file:
        # å¤„ç†å•ä¸ªæ–‡ä»¶
        file_path = Path(args.file)
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return

        result = cleaner.cleanup_file(file_path, dry_run=not args.no_dry_run)
        print(f"\nç»“æœ: {'æ¸…ç†æˆåŠŸ' if result.get('cleaned') else 'æ— éœ€æ¸…ç†'}")
    else:
        # å¤„ç†æ‰€æœ‰æ–‡ä»¶
        summary = cleaner.cleanup_all_files(dry_run=not args.no_dry_run)

        if not args.no_dry_run and summary['total_removed'] > 0:
            print(f"\nâœ… æ¸…ç†å®Œæˆï¼å»ºè®®è¿è¡Œä»£ç æ£€æŸ¥ç¡®è®¤æ¸…ç†ç»“æœ:")
            print(f"   ruff check {args.source_dir}/")
            print(f"   python -m py_compile {args.source_dir}/")


if __name__ == "__main__":
    main()