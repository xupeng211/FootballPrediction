#!/usr/bin/env python3
"""
åŸºç¡€æµ‹è¯•æ¡†æ¶æ„å»ºå·¥å…·
Basic Test Framework Builder

åŸºäºIssue #194éœ€æ±‚ï¼Œå»ºç«‹å®Œæ•´çš„åŸºç¡€æµ‹è¯•æ¡†æ¶å’ŒCI/CDè´¨é‡é—¨ç¦ï¼Œ
è§£å†³ç°æœ‰æµ‹è¯•é—®é¢˜ï¼Œä¼˜åŒ–pytesté…ç½®ï¼Œç¡®ä¿ä»£ç è´¨é‡ã€‚

ä½œè€…: Claude AI Assistant
ç‰ˆæœ¬: v1.0
åˆ›å»ºæ—¶é—´: 2025-11-03
"""

import json
import sys
import os
import subprocess
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

class TestFrameworkStatus(Enum):
    """æµ‹è¯•æ¡†æ¶çŠ¶æ€æšä¸¾"""
    BUILDING = "building"
    READY = "ready"
    ERROR = "error"
    OPTIMIZED = "optimized"

class QualityGateStatus(Enum):
    """è´¨é‡é—¨ç¦çŠ¶æ€æšä¸¾"""
    DISABLED = "disabled"
    WARNING = "warning"
    ENFORCED = "enforced"
    STRICT = "strict"

@dataclass
class TestIssue:
    """æµ‹è¯•é—®é¢˜æ•°æ®ç»“æ„"""
    file_path: str
    issue_type: str
    description: str
    severity: str
    suggested_fix: str

@dataclass
class TestFrameworkReport:
    """æµ‹è¯•æ¡†æ¶æŠ¥å‘Šæ•°æ®ç»“æ„"""
    timestamp: str
    status: TestFrameworkStatus
    total_tests_found: int
    runnable_tests: int
    error_tests: int
    skipped_tests: int
    issues_found: List[TestIssue]
    fixes_applied: List[str]
    coverage_threshold: float
    quality_gate_status: QualityGateStatus
    recommendations: List[str]

class TestFrameworkBuilder:
    """åŸºç¡€æµ‹è¯•æ¡†æ¶æ„å»ºå™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.timestamp = datetime.now().isoformat()

        # é…ç½®å‚æ•°
        self.config = {
            "coverage_threshold": 30.0,  # ç›®æ ‡è¦†ç›–ç‡30%
            "max_test_duration": 300,   # æœ€å¤§æµ‹è¯•æ—¶é—´5åˆ†é’Ÿ
            "parallel_jobs": 4,         # å¹¶è¡Œæµ‹è¯•ä½œä¸šæ•°
            "quality_gate_strict": False, # è´¨é‡é—¨ç¦ä¸¥æ ¼æ¨¡å¼
            "test_markers": [
                "unit", "integration", "api", "domain", "services",
                "smoke", "critical", "health"
            ]
        }

        # å·²çŸ¥æµ‹è¯•é—®é¢˜æ¨¡å¼
        self.test_issue_patterns = {
            "import_error": [
                "ImportError", "ModuleNotFoundError", "cannot import name"
            ],
            "circular_import": [
                "circular import", "most likely due to a circular import"
            ],
            "file_conflict": [
                "import file mismatch", "not the same as the test file"
            ],
            "missing_dependency": [
                "No module named", "ModuleNotFoundError"
            ]
        }

    def analyze_test_framework(self) -> TestFrameworkReport:
        """åˆ†æå½“å‰æµ‹è¯•æ¡†æ¶çŠ¶æ€"""
        print("ğŸ” åˆ†æå½“å‰æµ‹è¯•æ¡†æ¶çŠ¶æ€...")

        # æ‰«ææµ‹è¯•æ–‡ä»¶
        test_files = self._scan_test_files()
        total_tests = len(test_files)

        # å°è¯•æ”¶é›†æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿpytestæ”¶é›†è¿‡ç¨‹ï¼‰
        try:
            collection_result = self._dry_run_pytest_collection()
            runnable_tests = collection_result["collected"]
            error_tests = collection_result["errors"]
            skipped_tests = collection_result["skipped"]
        except Exception as e:
            print(f"âš ï¸ æµ‹è¯•æ”¶é›†å¤±è´¥: {e}")
            runnable_tests = 0
            error_tests = total_tests
            skipped_tests = 0

        # è¯†åˆ«æµ‹è¯•é—®é¢˜
        issues = self._identify_test_issues(test_files)

        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_framework_recommendations(issues, total_tests)

        return TestFrameworkReport(
            timestamp=self.timestamp,
            status=TestFrameworkStatus.BUILDING,
            total_tests_found=total_tests,
            runnable_tests=runnable_tests,
            error_tests=error_tests,
            skipped_tests=skipped_tests,
            issues_found=issues,
            fixes_applied=[],
            coverage_threshold=self.config["coverage_threshold"],
            quality_gate_status=QualityGateStatus.DISABLED,
            recommendations=recommendations
        )

    def _scan_test_files(self) -> List[Path]:
        """æ‰«ææµ‹è¯•æ–‡ä»¶"""
        test_patterns = ["test_*.py", "*_test.py"]
        test_files = []

        tests_dir = self.project_root / "tests"
        if tests_dir.exists():
            for pattern in test_patterns:
                test_files.extend(tests_dir.rglob(pattern))

        return test_files

    def _dry_run_pytest_collection(self) -> Dict[str, int]:
        """å¹²è¿è¡Œpytestæ”¶é›†"""
        try:
            result = subprocess.run(
                ["pytest", "--collect-only", "-q"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=60
            )

            # è§£æè¾“å‡º
            lines = result.stdout.strip().split('\n')
            collected = 0
            errors = 0
            skipped = 0

            for line in lines:
                if "collected" in line.lower():
                    try:
                        collected = int(line.split()[-2])
                    except (IndexError, ValueError):
                        pass
                elif "error" in line.lower():
                    errors += 1
                elif "skipped" in line.lower():
                    try:
                        skipped = int(line.split()[-2])
                    except (IndexError, ValueError):
                        pass

            return {"collected": collected, "errors": errors, "skipped": skipped}

        except (subprocess.TimeoutExpired,
    subprocess.CalledProcessError,
    FileNotFoundError):
            return {"collected": 0, "errors": 0, "skipped": 0}

    def _identify_test_issues(self, test_files: List[Path]) -> List[TestIssue]:
        """è¯†åˆ«æµ‹è¯•é—®é¢˜"""
        issues = []

        for test_file in test_files:
            try:
                with open(test_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # æ£€æŸ¥å¯¼å…¥é—®é¢˜
                file_issues = self._check_file_imports(test_file, content)
                issues.extend(file_issues)

            except Exception as e:
                issues.append(TestIssue(
                    file_path=str(test_file.relative_to(self.project_root)),
                    issue_type="file_access",
                    description=f"æ— æ³•è¯»å–æµ‹è¯•æ–‡ä»¶: {e}",
                    severity="high",
                    suggested_fix="æ£€æŸ¥æ–‡ä»¶æƒé™æˆ–æ–‡ä»¶å®Œæ•´æ€§"
                ))

        return issues

    def _check_file_imports(self, test_file: Path, content: str) -> List[TestIssue]:
        """æ£€æŸ¥æ–‡ä»¶å¯¼å…¥é—®é¢˜"""
        issues = []
        file_path = str(test_file.relative_to(self.project_root))

        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            line = line.strip()
            if not line.startswith('from ') and not line.startswith('import '):
                continue

            # æ£€æŸ¥å·²çŸ¥çš„å¯¼å…¥é—®é¢˜æ¨¡å¼
            for issue_type, patterns in self.test_issue_patterns.items():
                for pattern in patterns:
                    if pattern in line:
                        severity = "high" if issue_type in ["import_error", "circular_import"] else "medium"
                        suggested_fix = self._get_suggested_fix(issue_type,
    line,
    file_path)

                        issues.append(TestIssue(
                            file_path=file_path,
                            issue_type=issue_type,
                            description=f"ç¬¬{i}è¡Œ: {line}",
                            severity=severity,
                            suggested_fix=suggested_fix
                        ))

        return issues

    def _get_suggested_fix(self,
    issue_type: str,
    problematic_line: str,
    file_path: str) -> str:
        """è·å–å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ"""
        fixes = {
            "import_error": "æ£€æŸ¥å¯¼å…¥çš„æ¨¡å—æ˜¯å¦å­˜åœ¨ï¼Œæˆ–åˆ›å»ºç¼ºå¤±çš„æ¨¡å—æ–‡ä»¶",
            "circular_import": "é‡æ„ä»£ç ä»¥é¿å…å¾ªç¯å¯¼å…¥ï¼Œæˆ–å°†å¯¼å…¥ç§»åˆ°å‡½æ•°å†…éƒ¨",
            "file_conflict": "é‡å‘½åæµ‹è¯•æ–‡ä»¶ä»¥é¿å…å‘½åå†²çªï¼Œæˆ–æ¸…ç†__pycache__",
            "missing_dependency": "å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…æˆ–æ£€æŸ¥æ¨¡å—è·¯å¾„é…ç½®",
            "file_access": "æ£€æŸ¥æ–‡ä»¶æƒé™å’Œæ–‡ä»¶å®Œæ•´æ€§"
        }

        base_fix = fixes.get(issue_type, "æ£€æŸ¥å¯¼å…¥è¯­æ³•å’Œæ¨¡å—å¯ç”¨æ€§")

        # æ·»åŠ å…·ä½“çš„ä¿®å¤å»ºè®®
        if "src.services" in problematic_line:
            base_fix += f"ã€‚è€ƒè™‘æ£€æŸ¥ services/ ç›®å½•æ˜¯å¦å­˜åœ¨ç›¸åº”çš„æœåŠ¡æ–‡ä»¶"
        elif "src.database.models" in problematic_line:
            base_fix += f"ã€‚è€ƒè™‘æ£€æŸ¥ database/models/ ç›®å½•æ˜¯å¦å­˜åœ¨ç›¸åº”çš„æ¨¡å‹æ–‡ä»¶"
        elif "src.domain.events" in problematic_line:
            base_fix += f"ã€‚è€ƒè™‘æ£€æŸ¥ domain/events/ ç›®å½•æ˜¯å¦å­˜åœ¨ç›¸åº”çš„äº‹ä»¶æ–‡ä»¶"

        return base_fix

    def _generate_framework_recommendations(self,
    issues: List[TestIssue],
    total_tests: int) -> List[str]:
        """ç”Ÿæˆæ¡†æ¶æ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºé—®é¢˜ç±»å‹ç”Ÿæˆå»ºè®®
        issue_types = [issue.issue_type for issue in issues]
        error_count = len([i for i in issues if i.severity == "high"])

        if error_count > 0:
            recommendations.append(f"ğŸš¨ **ç´§æ€¥ä¿®å¤**: å‘ç°{error_count}ä¸ªé«˜ä¸¥é‡æ€§é—®é¢˜ï¼Œéœ€è¦ä¼˜å…ˆè§£å†³")

        if "import_error" in issue_types:
            recommendations.append("ğŸ“¦ **ä¾èµ–ç®¡ç†**: ä¿®å¤æ¨¡å—å¯¼å…¥é”™è¯¯ï¼Œç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—éƒ½å­˜åœ¨")

        if "circular_import" in issue_types:
            recommendations.append("ğŸ”„ **ä»£ç é‡æ„**: è§£å†³å¾ªç¯å¯¼å…¥é—®é¢˜ï¼Œä¼˜åŒ–æ¨¡å—ç»“æ„")

        if "file_conflict" in issue_types:
            recommendations.append("ğŸ§¹ **æ–‡ä»¶æ•´ç†**: æ¸…ç†æµ‹è¯•æ–‡ä»¶å‘½åå†²çªï¼Œåˆ é™¤ç¼“å­˜æ–‡ä»¶")

        # åŸºäºæµ‹è¯•æ•°é‡ç”Ÿæˆå»ºè®®
        if total_tests < 50:
            recommendations.append("ğŸ“ˆ **æµ‹è¯•æ‰©å±•**: å½“å‰æµ‹è¯•æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ æ›´å¤šå•å…ƒæµ‹è¯•")
        elif total_tests < 100:
            recommendations.append("ğŸ“Š **æµ‹è¯•å®Œå–„**: ç»§ç»­å¢åŠ æµ‹è¯•è¦†ç›–ç‡ï¼Œç‰¹åˆ«æ˜¯APIå’Œé›†æˆæµ‹è¯•")
        else:
            recommendations.append("ğŸ¯ **æµ‹è¯•ä¼˜åŒ–**: æµ‹è¯•æ•°é‡å……è¶³ï¼Œå¯ä»¥ä¸“æ³¨äºæµ‹è¯•è´¨é‡å’Œæ€§èƒ½ä¼˜åŒ–")

        # è¦†ç›–ç‡å»ºè®®
        recommendations.append(f"ğŸ¯ **è¦†ç›–ç‡ç›®æ ‡**: å½“å‰ç›®æ ‡è¦†ç›–ç‡{self.config['coverage_threshold']}%ï¼Œå»ºè®®é€æ­¥æå‡")

        return recommendations

    def build_basic_test_framework(self) -> TestFrameworkReport:
        """æ„å»ºåŸºç¡€æµ‹è¯•æ¡†æ¶"""
        print("ğŸ—ï¸ æ„å»ºåŸºç¡€æµ‹è¯•æ¡†æ¶...")

        # 1. åˆ†æç°çŠ¶
        report = self.analyze_test_framework()

        # 2. ä¿®å¤æµ‹è¯•é—®é¢˜
        fixes = self._apply_test_fixes(report.issues_found)
        report.fixes_applied = fixes

        # 3. åˆ›å»ºåŸºç¡€æµ‹è¯•
        self._create_basic_tests()

        # 4. ä¼˜åŒ–pytesté…ç½®
        self._optimize_pytest_config()

        # 5. è®¾ç½®è´¨é‡é—¨ç¦
        self._setup_quality_gates()

        # 6. åˆ›å»ºæµ‹è¯•è„šæœ¬
        self._create_test_scripts()

        # æ›´æ–°çŠ¶æ€
        report.status = TestFrameworkStatus.READY
        report.quality_gate_status = QualityGateStatus.WARNING

        return report

def __apply_test_fixes_handle_error():
                        shutil.rmtree(cache_path)
                        fixes.append(f"æ¸…ç†ç¼“å­˜ç›®å½•: {cache_path.relative_to(self.project_root)}")
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•æ¸…ç†ç¼“å­˜ç›®å½• {cache_path}: {e}")

        # ä¿®å¤æ–‡ä»¶å†²çª
        duplicate_files = []

def __apply_test_fixes_check_condition():
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å†²çª
                other_config = test_file.parent / "core" / "test_config.py"

def __apply_test_fixes_check_condition():
                    duplicate_files.append(test_file)


def __apply_test_fixes_handle_error():
                backup_path = dup_file.with_suffix(f".backup{datetime.now().strftime('%Y%m%d_%H%M%S')}.py")
                dup_file.rename(backup_path)
                fixes.append(f"ä¿®å¤æ–‡ä»¶å†²çª: {dup_file.name} -> {backup_path.name}")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ä¿®å¤æ–‡ä»¶å†²çª {dup_file}: {e}")

        # åˆ›å»ºç¼ºå¤±çš„åŸºç¡€æ¨¡å—
        missing_modules = [
            "src/domain/events/__init__.py",
            "src/services/__init__.py",
            "src/database/models/__init__.py"
        ]


def __apply_test_fixes_manage_resource():
                        f.write(f'"""{module_path}"""\n')
                    fixes.append(f"åˆ›å»ºç¼ºå¤±æ¨¡å—: {module_path}")
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•åˆ›å»ºæ¨¡å— {module_path}: {e}")

        return fixes

    def _apply_test_fixes(self, issues: List[TestIssue]) -> List[str]:
        """åº”ç”¨æµ‹è¯•ä¿®å¤"""
        fixes = []

        # æ¸…ç†ç¼“å­˜æ–‡ä»¶
        cache_dirs = [".pytest_cache", "__pycache__"]
        for cache_dir in cache_dirs:
            for cache_path in self.project_root.rglob(cache_dir):
                if cache_path.is_dir():
                    __apply_test_fixes_handle_error()
                        shutil.rmtree(cache_path)
                        fixes.append(f"æ¸…ç†ç¼“å­˜ç›®å½•: {cache_path.relative_to(self.project_root)}")
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•æ¸…ç†ç¼“å­˜ç›®å½• {cache_path}: {e}")

        # ä¿®å¤æ–‡ä»¶å†²çª
        duplicate_files = []
        for test_file in self._scan_test_files():
            __apply_test_fixes_check_condition()
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å†²çª
                other_config = test_file.parent / "core" / "test_config.py"
                __apply_test_fixes_check_condition()
                    duplicate_files.append(test_file)

        for dup_file in duplicate_files:
            __apply_test_fixes_handle_error()
                backup_path = dup_file.with_suffix(f".backup{datetime.now().strftime('%Y%m%d_%H%M%S')}.py")
                dup_file.rename(backup_path)
                fixes.append(f"ä¿®å¤æ–‡ä»¶å†²çª: {dup_file.name} -> {backup_path.name}")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ä¿®å¤æ–‡ä»¶å†²çª {dup_file}: {e}")

        # åˆ›å»ºç¼ºå¤±çš„åŸºç¡€æ¨¡å—
        missing_modules = [
            "src/domain/events/__init__.py",
            "src/services/__init__.py",
            "src/database/models/__init__.py"
        ]

        for module_path in missing_modules:
            full_path = self.project_root / module_path
            if not full_path.exists():
                try:
                    full_path.parent.mkdir(parents=True, exist_ok=True)
                    __apply_test_fixes_manage_resource()
                        f.write(f'"""{module_path}"""\n')
                    fixes.append(f"åˆ›å»ºç¼ºå¤±æ¨¡å—: {module_path}")
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•åˆ›å»ºæ¨¡å— {module_path}: {e}")

        return fixes

    def _create_basic_tests(self):
        """åˆ›å»ºåŸºç¡€æµ‹è¯•æ–‡ä»¶"""
        basic_tests = {
            "test_health_check.py": self._generate_health_check_test(),
            "test_config_basic.py": self._generate_config_test(),
            "test_api_endpoints.py": self._generate_api_test(),
            "test_domain_models.py": self._generate_domain_test(),
        }

        tests_dir = self.project_root / "tests" / "unit"
        tests_dir.mkdir(parents=True, exist_ok=True)

        for filename, content in basic_tests.items():
            test_file = tests_dir / filename
            if not test_file.exists():
                with open(test_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… åˆ›å»ºåŸºç¡€æµ‹è¯•: {filename}")

    def _generate_health_check_test(self) -> str:
        """ç”Ÿæˆå¥åº·æ£€æŸ¥æµ‹è¯•"""
        return '''"""
å¥åº·æ£€æŸ¥åŸºç¡€æµ‹è¯•
Basic Health Check Tests
"""

import pytest
from fastapi.testclient import TestClient
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from src.main import app
    client = TestClient(app)
    APP_AVAILABLE = True
except ImportError:
    APP_AVAILABLE = False
    print("âš ï¸ ä¸»åº”ç”¨ä¸å¯ç”¨ï¼Œè·³è¿‡å¥åº·æ£€æŸ¥æµ‹è¯•")


@pytest.mark.health
@pytest.mark.smoke
@pytest.mark.skipif(not APP_AVAILABLE, reason="ä¸»åº”ç”¨ä¸å¯ç”¨")
def test_health_endpoint():
    """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    response = client.get("/health")
    assert response.status_code == 200

    data = response.json()
    assert "status" in data
    assert data["status"] == "healthy"


@pytest.mark.health
@pytest.mark.skipif(not APP_AVAILABLE, reason="ä¸»åº”ç”¨ä¸å¯ç”¨")
def test_root_endpoint():
    """æµ‹è¯•æ ¹ç«¯ç‚¹"""
    response = client.get("/")
    assert response.status_code == 200


@pytest.mark.health
@pytest.mark.unit
def test_basic_imports():
    """æµ‹è¯•åŸºç¡€æ¨¡å—å¯¼å…¥"""
    try:
        import src.core.config
        assert True
    except ImportError:
        pytest.skip("é…ç½®æ¨¡å—ä¸å¯ç”¨")


@pytest.mark.health
@pytest.mark.unit
def test_project_structure():
    """æµ‹è¯•é¡¹ç›®ç»“æ„"""
    project_root = Path(__file__).parent.parent.parent

    # æ£€æŸ¥å…³é”®ç›®å½•
    required_dirs = ["src", "tests", "scripts"]
    for dir_name in required_dirs:
        assert (project_root / dir_name).exists(), f"ç¼ºå°‘ç›®å½•: {dir_name}"

    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files = ["README.md", "pytest.ini", "requirements.txt"]
    for file_name in required_files:
        assert (project_root / file_name).exists(), f"ç¼ºå°‘æ–‡ä»¶: {file_name}"
'''

    def _generate_config_test(self) -> str:
        """ç”Ÿæˆé…ç½®æµ‹è¯•"""
        return '''"""
é…ç½®åŸºç¡€æµ‹è¯•
Basic Configuration Tests
"""

import pytest
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


@pytest.mark.unit
@pytest.mark.smoke
def test_pytest_config_exists():
    """æµ‹è¯•pytesté…ç½®æ–‡ä»¶å­˜åœ¨"""
    project_root = Path(__file__).parent.parent.parent
    config_file = project_root / "pytest.ini"

    assert config_file.exists(), "pytest.inié…ç½®æ–‡ä»¶ä¸å­˜åœ¨"

    # æ£€æŸ¥å…³é”®é…ç½®
    content = config_file.read_text()
    assert "[pytest]" in content, "pytesté…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯"
    assert "testpaths = tests" in content, "æµ‹è¯•è·¯å¾„é…ç½®ç¼ºå¤±"


@pytest.mark.unit
def test_test_directory_structure():
    """æµ‹è¯•ç›®å½•ç»“æ„"""
    project_root = Path(__file__).parent.parent.parent
    tests_root = project_root / "tests"

    assert tests_root.exists(), "testsç›®å½•ä¸å­˜åœ¨"

    # æ£€æŸ¥æµ‹è¯•å­ç›®å½•
    subdirs = ["unit", "integration", "api"]
    for subdir in subdirs:
        subdir_path = tests_root / subdir
        if subdir_path.exists():
            assert subdir_path.is_dir(), f"{subdir}ä¸æ˜¯ç›®å½•"


@pytest.mark.unit
def test_python_path_config():
    """æµ‹è¯•Pythonè·¯å¾„é…ç½®"""
    # æµ‹è¯•å½“å‰æ–‡ä»¶èƒ½å¦å¯¼å…¥é¡¹ç›®æ¨¡å—
    try:
        import src
        assert hasattr(src, '__path__'), "srcåŒ…è·¯å¾„é…ç½®é”™è¯¯"
    except ImportError as e:
        pytest.skip(f"æ— æ³•å¯¼å…¥srcæ¨¡å—: {e}")


@pytest.mark.unit
def test_environment_variables():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    import os

    # æ£€æŸ¥Pythonè·¯å¾„
    python_path = os.environ.get('PYTHONPATH', '')
    assert 'src' in python_path or str(Path(__file__).parent.parent.parent) in python_path,
    
    \
        "PYTHONPATHæœªæ­£ç¡®é…ç½®"


@pytest.mark.unit
def test_dependencies_available():
    """æµ‹è¯•åŸºç¡€ä¾èµ–å¯ç”¨æ€§"""
    required_packages = ['pytest', 'fastapi']

    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            pytest.skip(f"ä¾èµ–åŒ… {package} ä¸å¯ç”¨")
'''

    def _generate_api_test(self) -> str:
        """ç”ŸæˆAPIæµ‹è¯•"""
        return '''"""
APIç«¯ç‚¹åŸºç¡€æµ‹è¯•
Basic API Endpoint Tests
"""

import pytest
from fastapi.testclient import TestClient
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from src.main import app
    client = TestClient(app)
    APP_AVAILABLE = True
except ImportError:
    APP_AVAILABLE = False
    client = None


@pytest.mark.api
@pytest.mark.integration
@pytest.mark.skipif(not APP_AVAILABLE, reason="ä¸»åº”ç”¨ä¸å¯ç”¨")
class TestAPIEndpoints:
    """APIç«¯ç‚¹æµ‹è¯•ç±»"""

    def test_health_response_format(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥å“åº”æ ¼å¼"""
        response = client.get("/health")
        assert response.status_code == 200

        data = response.json()
        required_fields = ["status", "timestamp"]

        for field in required_fields:
            assert field in data, f"å“åº”ç¼ºå°‘å­—æ®µ: {field}"

    def test_api_root_response(self):
        """æµ‹è¯•APIæ ¹ç«¯ç‚¹å“åº”"""
        response = client.get("/")
        assert response.status_code in [200, 404]  # å…è®¸404ä½œä¸ºæ­£å¸¸å“åº”

    def test_response_headers(self):
        """æµ‹è¯•å“åº”å¤´"""
        response = client.get("/health")
        assert response.status_code == 200

        # æ£€æŸ¥å†…å®¹ç±»å‹
        content_type = response.headers.get("content-type", "")
        assert "application/json" in content_type, "å“åº”å¤´content-typeé”™è¯¯"

    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æµ‹è¯•ä¸å­˜åœ¨çš„ç«¯ç‚¹
        response = client.get("/nonexistent-endpoint")
        assert response.status_code == 404


@pytest.mark.api
@pytest.mark.unit
def test_api_imports():
    """æµ‹è¯•APIç›¸å…³å¯¼å…¥"""
    try:
        from src.api.routes import health
        assert True
    except ImportError:
        pytest.skip("APIè·¯ç”±æ¨¡å—ä¸å¯ç”¨")


@pytest.mark.api
@pytest.mark.unit
def test_fastapi_app_creation():
    """æµ‹è¯•FastAPIåº”ç”¨åˆ›å»º"""
    try:
        from fastapi import FastAPI
        test_app = FastAPI()
        assert test_app is not None
    except ImportError:
        pytest.skip("FastAPIä¸å¯ç”¨")
'''

    def _generate_domain_test(self) -> str:
        """ç”Ÿæˆé¢†åŸŸå±‚æµ‹è¯•"""
        return '''"""
é¢†åŸŸå±‚åŸºç¡€æµ‹è¯•
Basic Domain Layer Tests
"""

import pytest
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


@pytest.mark.domain
@pytest.mark.unit
def test_domain_structure():
    """æµ‹è¯•é¢†åŸŸå±‚ç»“æ„"""
    project_root = Path(__file__).parent.parent.parent
    domain_dir = project_root / "src" / "domain"

    if domain_dir.exists():
        assert domain_dir.is_dir(), "domainç›®å½•å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•"

        # æ£€æŸ¥é¢†åŸŸå±‚å­æ¨¡å—
        submodules = ["models", "services", "events", "strategies"]
        for module in submodules:
            module_path = domain_dir / module
            if module_path.exists():
                init_file = module_path / "__init__.py"
                if not init_file.exists():
                    pytest.skip(f"é¢†åŸŸæ¨¡å— {module} ç¼ºå°‘ __init__.py æ–‡ä»¶")


@pytest.mark.domain
@pytest.mark.unit
def test_domain_models_import():
    """æµ‹è¯•é¢†åŸŸæ¨¡å‹å¯¼å…¥"""
    try:
        # å°è¯•å¯¼å…¥åŸºç¡€æ¨¡å‹
        from src.domain.models.base import BaseModel
        assert True
    except ImportError:
        pytest.skip("åŸºç¡€æ¨¡å‹ä¸å¯ç”¨")


@pytest.mark.domain
@pytest.mark.unit
def test_domain_services_import():
    """æµ‹è¯•é¢†åŸŸæœåŠ¡å¯¼å…¥"""
    try:
        # å°è¯•å¯¼å…¥æœåŠ¡åŸºç±»
        from src.domain.services.base import BaseService
        assert True
    except ImportError:
        pytest.skip("é¢†åŸŸæœåŠ¡åŸºç±»ä¸å¯ç”¨")


@pytest.mark.domain
@pytest.mark.unit
def test_prediction_domain_logic():
    """æµ‹è¯•é¢„æµ‹é¢†åŸŸé€»è¾‘åŸºç¡€"""
    try:
        from src.domain.models.prediction import Prediction
        # åŸºç¡€å®ä¾‹åŒ–æµ‹è¯•
        assert True
    except ImportError:
        pytest.skip("é¢„æµ‹æ¨¡å‹ä¸å¯ç”¨")


@pytest.mark.domain
@pytest.mark.unit
def test_strategy_pattern_implementation():
    """æµ‹è¯•ç­–ç•¥æ¨¡å¼å®ç°"""
    try:
        from src.domain.strategies.factory import StrategyFactory
        assert True
    except ImportError:
        pytest.skip("ç­–ç•¥å·¥å‚ä¸å¯ç”¨")
'''

    def _optimize_pytest_config(self):
        """ä¼˜åŒ–pytesté…ç½®"""
        config_file = self.project_root / "pytest.ini"

        if config_file.exists():
            content = config_file.read_text()

            # ä¼˜åŒ–è¦†ç›–ç‡é…ç½®
            if "--cov-fail-under=5" in content:
                content = content.replace("--cov-fail-under=5", "--cov-fail-under=30")
                print("âœ… è¦†ç›–ç‡é˜ˆå€¼æ›´æ–°ä¸º30%")

            # æ·»åŠ å¹¶è¡Œæµ‹è¯•é…ç½®
            if "-n auto" not in content and "--dist" not in content:
                addopts_section = content.find("[tool:pytest]")
                if addopts_section == -1:
                    # æ·»åŠ æ–°çš„é…ç½®èŠ‚
                    content += "\n\n[tool:pytest]\naddopts = -n auto --dist=loadscope\n"
                else:
                    print("â„¹ï¸ pytesté…ç½®å·²åŒ…å«å¹¶è¡Œæµ‹è¯•é…ç½®")

            # å†™å›æ–‡ä»¶
            config_file.write_text(content)

    def _setup_quality_gates(self):
        """è®¾ç½®è´¨é‡é—¨ç¦"""
        # åˆ›å»ºGitHub Actionsè´¨é‡é—¨ç¦é…ç½®
        quality_gate_content = '''name: Quality Gate

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  quality-check:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-xdist
        pip install -r requirements.txt

    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=src --cov-report=xml --cov-fail-under=30

    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --maxfail=3

    - name: Check code quality
      run: |
        pip install ruff mypy
        ruff check src/ tests/
        mypy src/ --ignore-missing-imports

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
'''

        workflows_dir = self.project_root / ".github" / "workflows"
        workflows_dir.mkdir(parents=True, exist_ok=True)

        quality_gate_file = workflows_dir / "quality-gate.yml"
        if not quality_gate_file.exists():
            with open(quality_gate_file, 'w') as f:
                f.write(quality_gate_content)
            print("âœ… åˆ›å»ºè´¨é‡é—¨ç¦é…ç½®")

    def _create_test_scripts(self):
        """åˆ›å»ºæµ‹è¯•è„šæœ¬"""
        scripts = {
            "run_tests.sh": '''#!/bin/bash
# è¿è¡Œæµ‹è¯•è„šæœ¬

set -e

echo "ğŸ§ª å¼€å§‹è¿è¡Œæµ‹è¯•å¥—ä»¶..."

# æ¸…ç†ç¼“å­˜
echo "ğŸ§¹ æ¸…ç†æµ‹è¯•ç¼“å­˜..."
find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
find . -name ".pytest_cache" -type d -exec rm -rf {} + 2>/dev/null || true

# è¿è¡Œå•å…ƒæµ‹è¯•
echo "ğŸ” è¿è¡Œå•å…ƒæµ‹è¯•..."
pytest tests/unit/ -v --cov=src --cov-report=html --cov-report=term-missing --cov-fail-under=30

# è¿è¡Œé›†æˆæµ‹è¯•
echo "ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•..."
pytest tests/integration/ -v --maxfail=5

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
echo "ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š..."
pytest --html=reports/test_report.html --self-contained-html

echo "âœ… æµ‹è¯•å®Œæˆï¼"
echo "ğŸ“ˆ è¦†ç›–ç‡æŠ¥å‘Š: htmlcov/index.html"
echo "ğŸ“„ HTMLæµ‹è¯•æŠ¥å‘Š: reports/test_report.html"
''',

            "quick_test.sh": '''#!/bin/bash
# å¿«é€Ÿæµ‹è¯•è„šæœ¬

echo "âš¡ è¿è¡Œå¿«é€Ÿæµ‹è¯•..."

# åªè¿è¡Œå…³é”®æµ‹è¯•
pytest tests/unit/ -v -m "smoke or critical" --maxfail=3

echo "âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼"
''',

            "test_health.sh": '''#!/bin/bash
# æµ‹è¯•å¥åº·æ£€æŸ¥è„šæœ¬

echo "ğŸ¥ è¿è¡Œæµ‹è¯•å¥åº·æ£€æŸ¥..."

# æ£€æŸ¥æµ‹è¯•ç¯å¢ƒ
python -c "import pytest; print('pytestç‰ˆæœ¬:', pytest.__version__)" || {
    echo "âŒ pytestä¸å¯ç”¨"
    exit 1
}

# æ£€æŸ¥é¡¹ç›®ç»“æ„
if [ ! -d "tests" ]; then
    echo "âŒ testsç›®å½•ä¸å­˜åœ¨"
    exit 1
fi

# å¹²è¿è¡Œæµ‹è¯•æ”¶é›†
echo "ğŸ” æ£€æŸ¥æµ‹è¯•å¯æ”¶é›†æ€§..."
pytest --collect-only -q > /dev/null || {
    echo "âš ï¸ æµ‹è¯•æ”¶é›†å­˜åœ¨é—®é¢˜"
}

echo "âœ… æµ‹è¯•å¥åº·æ£€æŸ¥é€šè¿‡ï¼"
'''
        }

        scripts_dir = self.project_root / "scripts"
        scripts_dir.mkdir(exist_ok=True)

        for filename, content in scripts.items():
            script_file = scripts_dir / filename
            with open(script_file, 'w') as f:
                f.write(content)
            script_file.chmod(0o755)
            print(f"âœ… åˆ›å»ºæµ‹è¯•è„šæœ¬: {filename}")

    def export_framework_report(self,
    report: TestFrameworkReport,
    output_file: Optional[Path] = None) -> Path:
        """å¯¼å‡ºæ¡†æ¶æŠ¥å‘Š"""
        if output_file is None:
            output_file = self.project_root / "reports" / f"test_framework_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        output_file.parent.mkdir(parents=True, exist_ok=True)

        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        report_dict = asdict(report)
        report_dict["status"] = report.status.value
        report_dict["quality_gate_status"] = report.quality_gate_status.value
        report_dict["issues_found"] = [asdict(issue) for issue in report.issues_found]

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_dict, f, indent=2, ensure_ascii=False)

        return output_file

def _main_check_condition():
        builder.config["coverage_threshold"] = args.coverage_threshold


def _main_check_condition():
            # ä»…åˆ†æå½“å‰çŠ¶æ€
            print("ğŸ” åˆ†ææµ‹è¯•æ¡†æ¶ç°çŠ¶...")
            report = builder.analyze_test_framework()

            print(f"\nğŸ“Š æµ‹è¯•æ¡†æ¶åˆ†æç»“æœ:")
            print(f"   æ€»æµ‹è¯•æ–‡ä»¶: {report.total_tests_found}")
            print(f"   å¯è¿è¡Œæµ‹è¯•: {report.runnable_tests}")
            print(f"   é”™è¯¯æµ‹è¯•: {report.error_tests}")
            print(f"   é—®é¢˜å‘ç°: {len(report.issues_found)}ä¸ª")
            print(f"   çŠ¶æ€: {report.status.value.upper()}")


def _main_iterate_items():
                    print(f"   - {issue.file_path}: {issue.description}")


def _main_check_condition():
                report_file = builder.export_framework_report(report)
                print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")


def _main_check_condition():
            # æ„å»ºå®Œæ•´æµ‹è¯•æ¡†æ¶
            print("ğŸ—ï¸ æ„å»ºåŸºç¡€æµ‹è¯•æ¡†æ¶...")
            report = builder.build_basic_test_framework()

            print(f"\nğŸ“Š æµ‹è¯•æ¡†æ¶æ„å»ºç»“æœ:")
            print(f"   çŠ¶æ€: {report.status.value.upper()}")
            print(f"   åº”ç”¨çš„ä¿®å¤: {len(report.fixes_applied)}ä¸ª")
            print(f"   è¦†ç›–ç‡ç›®æ ‡: {report.coverage_threshold}%")
            print(f"   è´¨é‡é—¨ç¦: {report.quality_gate_status.value.upper()}")


def _main_iterate_items():
                    print(f"   âœ… {fix}")


def _main_check_condition():
                report_file = builder.export_framework_report(report)
                print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")

            print(f"\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ:")
            print(f"   1. è¿è¡Œæµ‹è¯•: ./scripts/run_tests.sh")
            print(f"   2. å¿«é€Ÿæ£€æŸ¥: ./scripts/test_health.sh")
            print(f"   3. æŸ¥çœ‹è¦†ç›–ç‡: open htmlcov/index.html")

        else:
            # é»˜è®¤æ‰§è¡Œåˆ†æå’Œæ„å»º
            print("ğŸš€ å¼€å§‹æµ‹è¯•æ¡†æ¶æ„å»ºæµç¨‹...")

            # åˆ†æç°çŠ¶
            report = builder.analyze_test_framework()


def _main_check_condition():
                print(f"âš ï¸ å‘ç°{report.error_tests}ä¸ªæµ‹è¯•é—®é¢˜ï¼Œå¼€å§‹ä¿®å¤...")

                # æ„å»ºæ¡†æ¶
                report = builder.build_basic_test_framework()

                print(f"âœ… æµ‹è¯•æ¡†æ¶æ„å»ºå®Œæˆï¼")
                print(f"ğŸ“Š ä¿®å¤äº†{len(report.fixes_applied)}ä¸ªé—®é¢˜")

            else:
                print(f"âœ… æµ‹è¯•æ¡†æ¶çŠ¶æ€è‰¯å¥½ï¼Œæ— éœ€ä¿®å¤")

            # è¿è¡ŒéªŒè¯æµ‹è¯•
            print(f"\nğŸ§ª è¿è¡ŒéªŒè¯æµ‹è¯•...")

def _main_handle_error():
                subprocess.run([
                    "python", "-m", "pytest",
                    "tests/unit/test_health_check.py",
                    "-v", "--tb=short"
                ], check=False, cwd=project_root)
            except Exception as e:
                print(f"âš ï¸ éªŒè¯æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
        sys.exit(130)
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="åŸºç¡€æµ‹è¯•æ¡†æ¶æ„å»ºå·¥å…·")
    parser.add_argument(
        "--project-root",
        type=Path,
        help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--analyze-only",
        action="store_true",
        help="ä»…åˆ†æå½“å‰çŠ¶æ€"
    )
    parser.add_argument(
        "--build-framework",
        action="store_true",
        help="æ„å»ºå®Œæ•´æµ‹è¯•æ¡†æ¶"
    )
    parser.add_argument(
        "--coverage-threshold",
        type=float,
        default=30.0,
        help="è¦†ç›–ç‡é˜ˆå€¼"
    )
    parser.add_argument(
        "--output-report",
        action="store_true",
        help="è¾“å‡ºæ¡†æ¶æŠ¥å‘Š"
    )

    args = parser.parse_args()

    # åˆ›å»ºæ¡†æ¶æ„å»ºå™¨å®ä¾‹
    project_root = args.project_root or Path(__file__).parent.parent
    builder = TestFrameworkBuilder(project_root)

    _main_check_condition()
        builder.config["coverage_threshold"] = args.coverage_threshold

    try:
        _main_check_condition()
            # ä»…åˆ†æå½“å‰çŠ¶æ€
            print("ğŸ” åˆ†ææµ‹è¯•æ¡†æ¶ç°çŠ¶...")
            report = builder.analyze_test_framework()

            print(f"\nğŸ“Š æµ‹è¯•æ¡†æ¶åˆ†æç»“æœ:")
            print(f"   æ€»æµ‹è¯•æ–‡ä»¶: {report.total_tests_found}")
            print(f"   å¯è¿è¡Œæµ‹è¯•: {report.runnable_tests}")
            print(f"   é”™è¯¯æµ‹è¯•: {report.error_tests}")
            print(f"   é—®é¢˜å‘ç°: {len(report.issues_found)}ä¸ª")
            print(f"   çŠ¶æ€: {report.status.value.upper()}")

            if report.issues_found:
                print(f"\nğŸš¨ å‘ç°çš„ä¸»è¦é—®é¢˜:")
                _main_iterate_items()
                    print(f"   - {issue.file_path}: {issue.description}")

            _main_check_condition()
                report_file = builder.export_framework_report(report)
                print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")

        _main_check_condition()
            # æ„å»ºå®Œæ•´æµ‹è¯•æ¡†æ¶
            print("ğŸ—ï¸ æ„å»ºåŸºç¡€æµ‹è¯•æ¡†æ¶...")
            report = builder.build_basic_test_framework()

            print(f"\nğŸ“Š æµ‹è¯•æ¡†æ¶æ„å»ºç»“æœ:")
            print(f"   çŠ¶æ€: {report.status.value.upper()}")
            print(f"   åº”ç”¨çš„ä¿®å¤: {len(report.fixes_applied)}ä¸ª")
            print(f"   è¦†ç›–ç‡ç›®æ ‡: {report.coverage_threshold}%")
            print(f"   è´¨é‡é—¨ç¦: {report.quality_gate_status.value.upper()}")

            if report.fixes_applied:
                print(f"\nğŸ”§ åº”ç”¨çš„ä¿®å¤:")
                _main_iterate_items()
                    print(f"   âœ… {fix}")

            _main_check_condition()
                report_file = builder.export_framework_report(report)
                print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")

            print(f"\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ:")
            print(f"   1. è¿è¡Œæµ‹è¯•: ./scripts/run_tests.sh")
            print(f"   2. å¿«é€Ÿæ£€æŸ¥: ./scripts/test_health.sh")
            print(f"   3. æŸ¥çœ‹è¦†ç›–ç‡: open htmlcov/index.html")

        else:
            # é»˜è®¤æ‰§è¡Œåˆ†æå’Œæ„å»º
            print("ğŸš€ å¼€å§‹æµ‹è¯•æ¡†æ¶æ„å»ºæµç¨‹...")

            # åˆ†æç°çŠ¶
            report = builder.analyze_test_framework()

            _main_check_condition()
                print(f"âš ï¸ å‘ç°{report.error_tests}ä¸ªæµ‹è¯•é—®é¢˜ï¼Œå¼€å§‹ä¿®å¤...")

                # æ„å»ºæ¡†æ¶
                report = builder.build_basic_test_framework()

                print(f"âœ… æµ‹è¯•æ¡†æ¶æ„å»ºå®Œæˆï¼")
                print(f"ğŸ“Š ä¿®å¤äº†{len(report.fixes_applied)}ä¸ªé—®é¢˜")

            else:
                print(f"âœ… æµ‹è¯•æ¡†æ¶çŠ¶æ€è‰¯å¥½ï¼Œæ— éœ€ä¿®å¤")

            # è¿è¡ŒéªŒè¯æµ‹è¯•
            print(f"\nğŸ§ª è¿è¡ŒéªŒè¯æµ‹è¯•...")
            _main_handle_error()
                subprocess.run([
                    "python", "-m", "pytest",
                    "tests/unit/test_health_check.py",
                    "-v", "--tb=short"
                ], check=False, cwd=project_root)
            except Exception as e:
                print(f"âš ï¸ éªŒè¯æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
        sys.exit(130)
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()