#!/usr/bin/env python3
"""
æ¯èµ›è¡¥å…¨è„šæœ¬
æ•°æ®å·¥ç¨‹ä¸»ç®¡ä¸“ç”¨å·¥å…·

Purpose: è¡¥å…¨è±ªé—¨çƒé˜Ÿçš„æ¯èµ›æ•°æ®ï¼ˆæ¬§å† ã€æ¬§è”ã€è¶³æ€»æ¯ç­‰ï¼‰
ä½¿ç”¨FBrefTeamCollectoré‡‡é›†æ‰€æœ‰èµ›äº‹æ•°æ®
"""

import asyncio
import logging
import sys
from pathlib import Path
from sqlalchemy import create_engine, text

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.data.collectors.fbref_team_collector import FBrefTeamScheduleCollector

# æ•°æ®åº“è¿æ¥
db_url = (
    "postgresql://postgres:postgres-dev-password@localhost:5432/football_prediction"
)
engine = create_engine(db_url)

# è±ªé—¨çƒé˜Ÿåˆ—è¡¨ï¼ˆä»æ•°æ®åº“æŸ¥è¯¢å¾—åˆ°çš„å‰20æ”¯ï¼‰
BIG_TEAMS = [
    "Liverpool",
    "Manchester City",
    "Aston Villa",
    "Newcastle Utd",
    "Bournemouth",
    "Brighton",
    "Fulham",
    "Chelsea",
    "Crystal Palace",
    "Nott'ham Forest",
    "Manchester Utd",
    "Leeds United",
    "West Ham",
    "Tottenham",
    "Wolves",
    "Brentford",
    "Burnley",
    "Sunderland",
    "Arsenal",
    "Everton",
]

# é¢å¤–çš„é‡è¦çƒé˜Ÿï¼ˆæœªåœ¨å‰20ä¸­ä½†å¾ˆé‡è¦ï¼‰- æš‚æ—¶è·³è¿‡é¿å…äº‹åŠ¡é”™è¯¯
EXTRA_TEAMS = []

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("cup_backfill.log"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)


async def backfill_team_cups(team_name: str, season: str = "2023-2024") -> dict:
    """
    ä¸ºå•ä¸ªçƒé˜Ÿè¡¥å…¨æ¯èµ›æ•°æ®

    Args:
        team_name: çƒé˜Ÿåç§°
        season: èµ›å­£

    Returns:
        é‡‡é›†ç»Ÿè®¡ä¿¡æ¯
    """
    collector = FBrefTeamScheduleCollector(db_url)

    logger.info(f"å¼€å§‹é‡‡é›† {team_name} çš„æ‰€æœ‰èµ›äº‹æ•°æ®...")
    logger.info("=" * 80)

    try:
        # é‡‡é›†æ‰€æœ‰æ¯”èµ›
        matches = await collector.collect_team_schedule(team_name, season)

        if matches:
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await collector.save_matches_to_database(matches)

            result = {
                "team": team_name,
                "collected": len(matches),
                "saved": saved_count,
                "status": "success",
            }

            logger.info(f"âœ… {team_name} é‡‡é›†å®Œæˆ:")
            logger.info(f"   é‡‡é›†æ¯”èµ›: {len(matches)} åœº")
            logger.info(f"   ä¿å­˜æ¯”èµ›: {saved_count} åœº")
            logger.info("=" * 80)

        else:
            result = {
                "team": team_name,
                "collected": 0,
                "saved": 0,
                "status": "no_data",
            }
            logger.warning(f"âš ï¸ {team_name} æœªé‡‡é›†åˆ°æ•°æ®")

        # æ·»åŠ å»¶è¿Ÿé¿å…è¢«å°
        await asyncio.sleep(3)

    except Exception as e:
        logger.error(f"âŒ {team_name} é‡‡é›†å¤±è´¥: {e}")
        result = {
            "team": team_name,
            "collected": 0,
            "saved": 0,
            "status": "error",
            "error": str(e),
        }

    return result


async def backfill_all_teams_concurrent(teams: list, max_concurrent: int = 3):
    """
    å¹¶å‘é‡‡é›†å¤šä¸ªçƒé˜Ÿæ•°æ®

    Args:
        teams: çƒé˜Ÿåç§°åˆ—è¡¨
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
    """
    logger.info(f"ğŸš€ å¼€å§‹æ¯èµ›è¡¥å…¨è®¡åˆ’")
    logger.info(f"ğŸ“‹ è®¡åˆ’é‡‡é›† {len(teams)} æ”¯çƒé˜Ÿ")
    logger.info(f"ğŸ”§ æœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
    logger.info("=" * 80)

    # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_team(team):
        async with semaphore:
            return await backfill_team_cups(team)

    # å¹¶å‘æ‰§è¡Œ
    results = await asyncio.gather(*[process_team(team) for team in teams])

    # ç»Ÿè®¡ç»“æœ
    successful = [r for r in results if r["status"] == "success"]
    failed = [r for r in results if r["status"] == "error"]
    no_data = [r for r in results if r["status"] == "no_data"]

    total_collected = sum(r["collected"] for r in results)
    total_saved = sum(r["saved"] for r in results)

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š æ¯èµ›è¡¥å…¨å®Œæˆç»Ÿè®¡")
    logger.info("=" * 80)

    logger.info(f"\nâœ… æˆåŠŸçƒé˜Ÿ: {len(successful)}")
    logger.info(f"âŒ å¤±è´¥çƒé˜Ÿ: {len(failed)}")
    logger.info(f"âš ï¸ æ— æ•°æ®çƒé˜Ÿ: {len(no_data)}")

    logger.info(f"\nğŸ“ˆ æ€»è®¡ç»Ÿè®¡:")
    logger.info(f"   é‡‡é›†æ¯”èµ›: {total_collected}")
    logger.info(f"   ä¿å­˜æ¯”èµ›: {total_saved}")

    # åˆ—å‡ºæˆåŠŸçš„çƒé˜Ÿ
    if successful:
        logger.info(f"\nâœ… æˆåŠŸçƒé˜Ÿåˆ—è¡¨:")
        for r in successful:
            logger.info(f"   â€¢ {r['team']:25s}: {r['saved']:3d} åœºæ¯”èµ›")

    # åˆ—å‡ºå¤±è´¥çš„çƒé˜Ÿ
    if failed:
        logger.info(f"\nâŒ å¤±è´¥çƒé˜Ÿåˆ—è¡¨:")
        for r in failed:
            logger.info(f"   â€¢ {r['team']:25s}: {r['error']}")

    logger.info("\n" + "=" * 80)
    logger.info("âœ… æ¯èµ›è¡¥å…¨è®¡åˆ’æ‰§è¡Œå®Œæˆ")
    logger.info("=" * 80)

    return results


def verify_cup_data():
    """
    éªŒè¯æ¯èµ›æ•°æ®æ˜¯å¦æˆåŠŸå…¥åº“
    """
    logger.info("\nğŸ” éªŒè¯æ¯èµ›æ•°æ®å…¥åº“...")

    with engine.connect() as conn:
        # æŸ¥è¯¢æ˜¯å¦æœ‰æ¯èµ›æ•°æ®
        result = conn.execute(
            text(
                """
            SELECT DISTINCT l.name as league_name, COUNT(*) as match_count
            FROM matches m
            JOIN leagues l ON m.league_id = l.id
            WHERE l.name IS NOT NULL
              AND l.name NOT LIKE '%Premier League%'
              AND l.name NOT LIKE '%Championship%'
              AND l.name NOT LIKE '%League One%'
              AND l.name NOT LIKE '%League Two%'
            GROUP BY l.name
            ORDER BY match_count DESC
        """
            )
        )

        cup_matches = result.fetchall()

        if cup_matches:
            logger.info("âœ… å‘ç°æ¯èµ›æ•°æ®:")
            for league_name, match_count in cup_matches:
                logger.info(f"   ğŸ† {league_name}: {match_count} åœºæ¯”èµ›")
        else:
            logger.warning("âš ï¸ æœªå‘ç°æ¯èµ›æ•°æ®")

        # æŸ¥è¯¢æ˜¯å¦æœ‰æ¬§å† ã€è¶³æ€»æ¯ç­‰å…³é”®è¯
        result = conn.execute(
            text(
                """
            SELECT DISTINCT data_source
            FROM matches
            WHERE data_source LIKE '%cup%'
               OR data_source LIKE '%champion%'
               OR data_source LIKE '%europa%'
        """
            )
        )

        source_matches = result.fetchall()

        if source_matches:
            logger.info(f"\nğŸ“Š å‘ç°ç›¸å…³æ•°æ®æº:")
            for (source,) in source_matches:
                logger.info(f"   â€¢ {source}")

    logger.info("âœ… éªŒè¯å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ† æ¯èµ›è¡¥å…¨è®¡åˆ’å¯åŠ¨")
    logger.info(f"æ—¶é—´: {asyncio.get_event_loop().time()}")

    # Step 1: é‡‡é›†BIG_TEAMS
    logger.info("\nğŸ“‹ Phase 1: é‡‡é›†è‹±è¶…å‰20çƒé˜Ÿ")
    results1 = await backfill_all_teams_concurrent(BIG_TEAMS, max_concurrent=1)

    # Step 2: éªŒè¯æ•°æ®
    logger.info("\nğŸ“‹ Phase 2: éªŒè¯æ•°æ®")
    verify_cup_data()

    logger.info("\nğŸ‰ æ¯èµ›è¡¥å…¨è®¡åˆ’å®Œæˆï¼")

    return 0


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        sys.exit(0)
    except Exception as e:
        logger.error(f"\nâŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}", exc_info=True)
        sys.exit(1)
