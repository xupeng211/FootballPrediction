#!/usr/bin/env python3
"""
ğŸ† å…¨é‡æ•°æ®å›å¡«è„šæœ¬ - Enterprise-grade Backfill Script
ğŸ¯ Target:åœ°æ¯¯å¼å…¨è¦†ç›–è¶³çƒæ•°æ® (2022-01-01 to Present)
ğŸ“… Date Range: 2022-01-01 to today
ğŸ—ï¸ Architecture: Async + Rate Limiting + PostgreSQL Persistence

ğŸš€ Features:
- å…¨é¢è¦†ç›–ï¼šæ¯æ—¥è¿ç»­é‡‡é›†ï¼Œæ— é—´æ–­
- æ™ºèƒ½é™æµï¼š1.5-3.5ç§’éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸäººè¡Œä¸º
- åŒæ•°æ®æºï¼šFootball-Data.org + FotMob
- å®æ—¶ç»Ÿè®¡ï¼šé‡‡é›†è¿›åº¦ã€æˆåŠŸç‡ã€é”™è¯¯ç›‘æ§
- æ–­ç‚¹ç»­ä¼ ï¼šæ”¯æŒä¸­æ–­åç»§ç»­æ‰§è¡Œ
- æ•°æ®å®Œæ•´æ€§ï¼šPostgreSQLäº‹åŠ¡ + é‡å¤æ£€æµ‹

Usage:
    python scripts/backfill_global.py [--start-date=2022-01-01] [--end-date=2024-12-31] [--dry-run] [--resume]

Arguments:
    --start-date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: 2022-01-01)
    --end-date: ç»“æŸæ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: ä»Šå¤©)
    --dry-run: åªæ˜¾ç¤ºè®¡åˆ’ï¼Œä¸å®é™…é‡‡é›†æ•°æ®
    --resume: ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œ
    --source: æ•°æ®æºé€‰æ‹© (all, football-data, fotmobï¼Œé»˜è®¤: all)
"""

import asyncio
import logging
import os
import sys
import json
import time
import random
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Optional
from dataclasses import dataclass, asdict
from contextlib import asynccontextmanager

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


# å»¶è¿Ÿå¯¼å…¥æ¨¡å‹ä»¥åˆå§‹åŒ– ORM æ˜ å°„å…³ç³» (è§£å†³å¾ªç¯ä¾èµ–é—®é¢˜)
def _init_orm_models():
    """å»¶è¿Ÿåˆå§‹åŒ–æ‰€æœ‰ORMæ¨¡å‹ï¼Œé¿å…å¾ªç¯ä¾èµ–

    æŒ‰ä¾èµ–é¡ºåºå¯¼å…¥æ¨¡å‹ï¼Œç¡®ä¿æ‰€æœ‰å…³ç³»éƒ½æ­£ç¡®æ˜ å°„ï¼š
    1. Tenant (è¢« User å¼•ç”¨)
    2. User (å¼•ç”¨ Tenant)
    3. å…¶ä»–æ ¸å¿ƒæ¨¡å‹...
    """
    try:
        # å…³é”®ï¼šæŒ‰ä¾èµ–é¡ºåºå¯¼å…¥æ¨¡å‹ï¼Œè§£å†³å¾ªç¯ä¾èµ–
        # 1. é¦–å…ˆå¯¼å…¥ Tenant (è¢« User å¼•ç”¨)
        import src.database.models.tenant

        print("âœ… Tenant æ¨¡å‹åŠ è½½æˆåŠŸ")

        # 2. ç„¶åå¯¼å…¥ User (å¼•ç”¨ Tenant)
        import src.database.models.user

        print("âœ… User æ¨¡å‹åŠ è½½æˆåŠŸ")

        # 3. å¯¼å…¥å…¶ä»–æ ¸å¿ƒæ¨¡å‹
        import src.database.models.team

        print("âœ… Team æ¨¡å‹åŠ è½½æˆåŠŸ")

        import src.database.models.league

        print("âœ… League æ¨¡å‹åŠ è½½æˆåŠŸ")

        import src.database.models.match

        print("âœ… Match æ¨¡å‹åŠ è½½æˆåŠŸ")

        # 4. å¯¼å…¥ä¾èµ–æ ¸å¿ƒæ¨¡å‹çš„å…¶ä»–æ¨¡å‹
        import src.database.models.predictions

        print("âœ… Predictions æ¨¡å‹åŠ è½½æˆåŠŸ")

        import src.database.models.odds

        print("âœ… Odds æ¨¡å‹åŠ è½½æˆåŠŸ")

        import src.database.models.features

        print("âœ… Features æ¨¡å‹åŠ è½½æˆåŠŸ")

        # 5. å¯¼å…¥æ—¥å¿—å’Œå®¡è®¡æ¨¡å‹
        import src.database.models.data_collection_log

        print("âœ… DataCollectionLog æ¨¡å‹åŠ è½½æˆåŠŸ")

        import src.database.models.data_quality_log

        print("âœ… DataQualityLog æ¨¡å‹åŠ è½½æˆåŠŸ")

        import src.database.models.audit_log

        print("âœ… AuditLog æ¨¡å‹åŠ è½½æˆåŠŸ")

        print("âœ… æ‰€æœ‰ ORM æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ - æ— å¾ªç¯ä¾èµ–")

    except Exception:
        print(f"âš ï¸ ORMæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        # ç»§ç»­æ‰§è¡Œï¼Œä½†è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯


# é…ç½®é«˜çº§æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)8s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

# ç¯å¢ƒæ–‡ä»¶åŠ è½½ä¼˜å…ˆçº§
env_files = [
    project_root / ".env",
    project_root / ".env.local",
    project_root / ".env.development",
]

for env_file in env_files:
    if env_file.exists():
        load_dotenv(env_file)
        logger.info(f"âœ… åŠ è½½ç¯å¢ƒæ–‡ä»¶: {env_file}")
        break


@dataclass
class BackfillStats:
    """å›å¡«ç»Ÿè®¡æ•°æ®"""

    total_days: int = 0
    processed_days: int = 0
    successful_days: int = 0
    failed_days: int = 0
    total_matches: int = 0
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    start_time: Optional[datetime] = None
    estimated_completion: Optional[datetime] = None

    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        return (self.successful_days / max(self.processed_days, 1)) * 100

    @property
    def request_success_rate(self) -> float:
        """è¯·æ±‚æˆåŠŸç‡"""
        return (self.successful_requests / max(self.total_requests, 1)) * 100

    @property
    def elapsed_time(self) -> timedelta:
        """å·²ç”¨æ—¶é—´"""
        if self.start_time:
            return datetime.now() - self.start_time
        return timedelta(0)

    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        if self.start_time:
            data["start_time"] = self.start_time.isoformat()
        if self.estimated_completion:
            data["estimated_completion"] = self.estimated_completion.isoformat()
        data["elapsed_time"] = str(self.elapsed_time)
        data["success_rate"] = self.success_rate
        data["request_success_rate"] = self.request_success_rate
        return data


@dataclass
class DailyDataResult:
    """æ¯æ—¥æ•°æ®é‡‡é›†ç»“æœ"""

    date: str
    football_data_matches: list[dict] = None
    fotmob_matches: list[dict] = None
    total_matches: int = 0
    collection_time: Optional[datetime] = None
    errors: list[str] = None
    success: bool = False

    def __post_init__(self):
        if self.football_data_matches is None:
            self.football_data_matches = []
        if self.fotmob_matches is None:
            self.fotmob_matches = []
        if self.errors is None:
            self.errors = []
        if self.collection_time is None:
            self.collection_time = datetime.now()


class GlobalBackfillService:
    """å…¨çƒæ•°æ®å›å¡«æœåŠ¡"""

    def __init__(self):
        self.stats = BackfillStats()
        self.state_file = project_root / "data" / "backfill_state.json"
        self.state_file.parent.mkdir(exist_ok=True)

        # APIé™æµé…ç½®
        self.min_delay = 8.0  # å¢åŠ æœ€å°å»¶è¿Ÿé¿å…429
        self.max_delay = 15.0  # å¢åŠ æœ€å¤§å»¶è¿Ÿé¿å…429

        # åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨
        self.football_collector = None
        self.fotmob_collector = None

        # æ•°æ®åº“è¿æ¥
        self.db_engine = None

    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        logger.info("ğŸš€ åˆå§‹åŒ–å…¨çƒæ•°æ®å›å¡«æœåŠ¡...")

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        await self._init_database()

        # åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨
        await self._init_collectors()

        logger.info("âœ… å›å¡«æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            # é¦–å…ˆåˆå§‹åŒ–ORMæ¨¡å‹æ˜ å°„å…³ç³»
            _init_orm_models()

            from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
            from sqlalchemy.orm import sessionmaker

            database_url = os.getenv("DATABASE_URL")
            if not database_url:
                # æ„å»ºæ•°æ®åº“URL
                db_host = os.getenv("DB_HOST", "db")
                db_port = os.getenv("DB_PORT", "5432")
                db_user = os.getenv("POSTGRES_USER", "postgres")
                db_password = os.getenv("POSTGRES_PASSWORD", "postgres-dev-password")
                db_name = os.getenv("POSTGRES_DB", "football_prediction")
                database_url = f"postgresql+asyncpg://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"

            # è½¬æ¢ä¸ºå¼‚æ­¥URL
            if database_url.startswith("postgresql://"):
                database_url = database_url.replace(
                    "postgresql://", "postgresql+asyncpg://", 1
                )

            self.db_engine = create_async_engine(
                database_url,
                pool_size=5,
                max_overflow=10,
                pool_pre_ping=True,
                echo=False,
            )

            self.async_session = sessionmaker(
                self.db_engine, class_=AsyncSession, expire_on_commit=False
            )

            logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")

        except Exception:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def _init_collectors(self):
        """åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨"""
        try:
            # Football-Data.orgé‡‡é›†å™¨
            from src.collectors.football_data_collector import FootballDataCollector

            self.football_collector = FootballDataCollector()

            # FotMobé‡‡é›†å™¨ (å¦‚æœå­˜åœ¨)
            try:
                from src.data.collectors.fotmob_collector import FotmobCollector

                self.fotmob_collector = FotmobCollector()
                logger.info("âœ… FotMobé‡‡é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except ImportError:
                logger.warning("âš ï¸ FotMobé‡‡é›†å™¨ä¸å¯ç”¨ï¼Œå°†åªä½¿ç”¨Football-Data.org")
                self.fotmob_collector = None

            # èµ”ç‡é‡‡é›†å™¨
            try:
                from src.data.collectors.odds_collector import OddsCollector

                self.odds_collector = OddsCollector()
                logger.info("âœ… èµ”ç‡é‡‡é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except ImportError:
                logger.warning("âš ï¸ èµ”ç‡é‡‡é›†å™¨ä¸å¯ç”¨ï¼Œå°†è·³è¿‡èµ”ç‡æ”¶é›†")
                self.odds_collector = None

            logger.info("âœ… æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception:
            logger.error(f"âŒ æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _parse_status(self, status_data) -> str:
        """è§£æFotMobçš„statuså­—æ®µï¼Œå¤„ç†å­—ç¬¦ä¸²å’Œå­—å…¸ä¸¤ç§æƒ…å†µ"""
        try:
            if isinstance(status_data, str):
                # æƒ…å†µ1: statusæ˜¯å­—ç¬¦ä¸² (e.g., "Finished", "LIVE")
                return status_data[:20]
            elif isinstance(status_data, dict):
                # æƒ…å†µ2: statusæ˜¯åµŒå¥—å­—å…¸ (e.g., {"reason": {"long": "Match finished"}})
                return status_data.get("reason", {}).get("long", "SCHEDULED")[:20]
            else:
                # å…¶ä»–æƒ…å†µï¼Œè¿”å›é»˜è®¤å€¼
                return "SCHEDULED"[:20]
        except Exception:
            # è§£æå¤±è´¥æ—¶çš„å®‰å…¨é»˜è®¤å€¼
            return "UNKNOWN"[:20]

    async def _collect_odds_for_new_matches(self, session, date_str: str) -> int:
        """ä¸ºæ–°ä¿å­˜çš„æ¯”èµ›æ”¶é›†èµ”ç‡æ•°æ®.

        Args:
            session: æ•°æ®åº“ä¼šè¯
            date_str: æ—¥æœŸå­—ç¬¦ä¸²

        Returns:
            int: æ”¶é›†çš„èµ”ç‡è®°å½•æ•°é‡
        """
        total_odds_collected = 0

        try:
            # è·å–å½“å¤©æ–°ä¿å­˜çš„æ¯”èµ›ï¼Œä¸”çŠ¶æ€ä¸ºSCHEDULEDæˆ–TIMEDçš„æ¯”èµ›
            from sqlalchemy import select, and_
            from src.database.models import Match
            from datetime import datetime

            # å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
            try:
                # å‡è®¾ date_str æ ¼å¼ä¸º YYYY-MM-DD
                year, month, day = map(int, date_str.split("-"))
                start_datetime = datetime(year, month, day, 0, 0, 0)
                end_datetime = datetime(year, month, day, 23, 59, 59)
            except ValueError as e:
                logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ '{date_str}': {e}")
                return 0

            # æŸ¥è¯¢å½“å¤©å³å°†å¼€å§‹çš„æ¯”èµ›
            stmt = select(Match).where(
                and_(
                    Match.match_date >= start_datetime,
                    Match.match_date <= end_datetime,
                    Match.status.in_(["SCHEDULED", "TIMED"]),
                )
            )

            result = await session.execute(stmt)
            scheduled_matches = result.scalars().all()

            if not scheduled_matches:
                logger.debug(f"ğŸ“Š {date_str}: æ— éœ€è¦æ”¶é›†èµ”ç‡çš„æ¯”èµ›")
                return 0

            logger.info(
                f"ğŸ¯ {date_str}: å¼€å§‹ä¸º {len(scheduled_matches)} åœºå³å°†å¼€å§‹çš„æ¯”èµ›æ”¶é›†èµ”ç‡"
            )

            # ä¸ºæ¯åœºæ¯”èµ›æ”¶é›†èµ”ç‡
            for match in scheduled_matches:
                try:
                    odds_result = await self.odds_collector.collect_and_save_odds(
                        match.id
                    )

                    if odds_result.success:
                        total_odds_collected += odds_result.count
                        logger.debug(
                            f"âœ… Match {match.id}: æ”¶é›†åˆ° {odds_result.count} æ¡èµ”ç‡"
                        )
                    else:
                        logger.warning(
                            f"âš ï¸ Match {match.id}: èµ”ç‡æ”¶é›†å¤±è´¥ - {odds_result.error}"
                        )

                except Exception as match_error:
                    logger.error(f"âŒ Match {match.id} èµ”ç‡æ”¶é›†å¼‚å¸¸: {match_error}")
                    continue

        except Exception:
            logger.error(f"âŒ èµ”ç‡æ”¶é›†è¿‡ç¨‹å¼‚å¸¸: {e}")
            raise

        return total_odds_collected

    def generate_date_range(
        self, start_date: datetime, end_date: datetime
    ) -> list[str]:
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´åˆ—è¡¨"""
        logger.info("ğŸ“… ç”Ÿæˆæ—¥æœŸèŒƒå›´...")

        dates = []
        current_date = start_date

        while current_date <= end_date:
            dates.append(current_date.strftime("%Y-%m-%d"))
            current_date += timedelta(days=1)

        logger.info(f"ğŸ“‹ ç”Ÿæˆ {len(dates)} ä¸ªé‡‡é›†æ—¥æœŸ ({dates[0]} to {dates[-1]})")
        return dates

    def load_resume_state(self) -> Optional[dict[str, Any]]:
        """åŠ è½½æ¢å¤çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, encoding="utf-8") as f:
                    state = json.load(f)
                    logger.info(
                        f"ğŸ”„ å‘ç°æ¢å¤çŠ¶æ€: ä¸Šæ¬¡å¤„ç†åˆ° {state.get('last_processed_date', 'Unknown')}"
                    )
                    return state
            except Exception:
                logger.warning(f"âš ï¸ æ— æ³•åŠ è½½æ¢å¤çŠ¶æ€: {e}")
        return None

    def save_resume_state(self, last_processed_date: str, stats: BackfillStats):
        """ä¿å­˜æ¢å¤çŠ¶æ€"""
        try:
            state = {
                "last_processed_date": last_processed_date,
                "stats": stats.to_dict(),
                "timestamp": datetime.now().isoformat(),
                "version": "1.0.0",
            }

            with open(self.state_file, "w", encoding="utf-8") as f:
                json.dump(state, f, indent=2, ensure_ascii=False)

        except Exception:
            logger.error(f"âŒ ä¿å­˜æ¢å¤çŠ¶æ€å¤±è´¥: {e}")

    async def collect_daily_data(
        self, date_str: str, sources: list[str] = None
    ) -> DailyDataResult:
        """é‡‡é›†æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
        if sources is None:
            sources = ["football-data", "fotmob"]

        result = DailyDataResult(date=date_str)

        try:
            # è§£ææ—¥æœŸ
            target_date = datetime.strptime(date_str, "%Y-%m-%d")

            # è®¾ç½®æ—¥æœŸèŒƒå›´ï¼ˆå½“å¤©å‰å1å¤©ä»¥ç¡®ä¿è¦†ç›–ï¼‰
            date_from = target_date - timedelta(days=1)
            date_to = target_date + timedelta(days=1)

            logger.info(f"ğŸ“… é‡‡é›† {date_str} çš„è¶³çƒæ•°æ®...")

            # Football-Data.orgé‡‡é›†
            if "football-data" in sources and self.football_collector:
                try:
                    matches_result = await self.football_collector.collect_matches(
                        date_from=date_from,
                        date_to=date_to,
                        limit=500,  # æé«˜é™åˆ¶è·å–æ›´å¤šæ•°æ®
                    )

                    if matches_result.success:
                        result.football_data_matches = matches_result.data.get(
                            "matches", []
                        )
                        logger.info(
                            f"âœ… Football-Data.org: è·å– {len(result.football_data_matches)} åœºæ¯”èµ›"
                        )
                    else:
                        error_msg = f"Football-Data.orgé‡‡é›†å¤±è´¥: {matches_result.error}"
                        result.errors.append(error_msg)
                        logger.error(error_msg)

                except Exception:
                    error_msg = f"Football-Data.orgå¼‚å¸¸: {e}"
                    result.errors.append(error_msg)
                    logger.error(error_msg)

                # æ™ºèƒ½å»¶è¿Ÿ
                await asyncio.sleep(random.uniform(self.min_delay, self.max_delay))

            # FotMobé‡‡é›†
            if "fotmob" in sources and self.fotmob_collector:
                try:
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„FotMobé‡‡é›†å™¨APIè°ƒæ•´
                    fotmob_result = await self.fotmob_collector.collect_matches_by_date(
                        date_str
                    )

                    if fotmob_result.success:
                        # ğŸ› ï¸ é€‚é…æ–°çš„FotMobé‡‡é›†å™¨æ ¼å¼
                        # æ–°æ ¼å¼è¿”å›ç›´æ¥çš„æ¯”èµ›åˆ—è¡¨ï¼Œä¸æ˜¯åŒ…å«"matches"é”®çš„å­—å…¸
                        if isinstance(fotmob_result.data, list):
                            result.fotmob_matches = fotmob_result.data
                            logger.info(
                                f"âœ… FotMob: è·å– {len(result.fotmob_matches)} åœºæ¯”èµ› (æ–°æ ¼å¼)"
                            )
                        elif isinstance(fotmob_result.data, dict):
                            # å…¼å®¹æ—§æ ¼å¼
                            result.fotmob_matches = fotmob_result.data.get(
                                "matches", []
                            )
                            logger.info(
                                f"âœ… FotMob: è·å– {len(result.fotmob_matches)} åœºæ¯”èµ› (æ—§æ ¼å¼)"
                            )
                        else:
                            result.fotmob_matches = []
                            logger.warning(
                                f"âš ï¸ FotMob: æœªçŸ¥æ•°æ®æ ¼å¼ {type(fotmob_result.data)}"
                            )
                    else:
                        error_msg = f"FotMobé‡‡é›†å¤±è´¥: {fotmob_result.error}"
                        result.errors.append(error_msg)
                        logger.error(error_msg)

                except Exception:
                    error_msg = f"FotMobå¼‚å¸¸: {e}"
                    result.errors.append(error_msg)
                    logger.error(error_msg)

                # æ™ºèƒ½å»¶è¿Ÿ
                await asyncio.sleep(random.uniform(self.min_delay, self.max_delay))

            # è®¡ç®—æ€»æ¯”èµ›æ•°
            result.total_matches = len(result.football_data_matches) + len(
                result.fotmob_matches
            )
            result.success = result.total_matches > 0 or len(result.errors) == 0

            # å­˜å‚¨åˆ°æ•°æ®åº“
            if result.success:
                await self._save_daily_data(result)

            logger.info(
                f"ğŸ“Š {date_str} é‡‡é›†å®Œæˆ: {result.total_matches} åœºæ¯”èµ›, {len(result.errors)} ä¸ªé”™è¯¯"
            )

        except Exception:
            error_msg = f"æ—¥æœŸ {date_str} é‡‡é›†å¼‚å¸¸: {e}"
            result.errors.append(error_msg)
            logger.error(error_msg)

        return result

    async def _save_daily_data(self, result: DailyDataResult):
        """ä¿å­˜æ¯æ—¥æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            async with self.async_session() as session:
                from src.database.models.match import Match
                from src.database.models.team import Team
                from sqlalchemy import select, text
                from datetime import datetime
                from sqlalchemy.dialects.postgresql import insert

                saved_count = 0
                all_teams_to_save = set()  # ç”¨äºæ”¶é›†æ‰€æœ‰éœ€è¦ä¿å­˜çš„çƒé˜Ÿ

                # ğŸ† æ­¥éª¤1: æ”¶é›†æ‰€æœ‰çƒé˜Ÿæ•°æ®ï¼ˆFootball-Data.org + FotMobï¼‰
                if result.football_data_matches:
                    for match_data in result.football_data_matches:
                        home_team = match_data.get("homeTeam", {})
                        away_team = match_data.get("awayTeam", {})

                        if home_team.get("id"):
                            all_teams_to_save.add(
                                (
                                    home_team.get("id", 0),
                                    home_team.get("name", ""),
                                    home_team.get("shortName", ""),
                                    home_team.get("crest", ""),
                                    "football-data",
                                )
                            )

                        if away_team.get("id"):
                            all_teams_to_save.add(
                                (
                                    away_team.get("id", 0),
                                    away_team.get("name", ""),
                                    away_team.get("shortName", ""),
                                    away_team.get("crest", ""),
                                    "football-data",
                                )
                            )

                if result.fotmob_matches:
                    for match_data in result.fotmob_matches:
                        home_team = match_data.get("home", {})
                        away_team = match_data.get("away", {})

                        if home_team.get("id"):
                            all_teams_to_save.add(
                                (
                                    home_team.get("id", 0),
                                    home_team.get("name", ""),
                                    home_team.get("shortName", ""),
                                    None,  # FotMobæ²¡æœ‰crest
                                    "fotmob",
                                )
                            )

                        if away_team.get("id"):
                            all_teams_to_save.add(
                                (
                                    away_team.get("id", 0),
                                    away_team.get("name", ""),
                                    away_team.get("shortName", ""),
                                    None,  # FotMobæ²¡æœ‰crest
                                    "fotmob",
                                )
                            )

                # ğŸ›¡ï¸ æ­¥éª¤2: æ‰¹é‡ä¿å­˜çƒé˜Ÿæ•°æ®ï¼ˆä½¿ç”¨ON CONFLICT DO NOTHINGé¿å…é‡å¤ï¼‰
                if all_teams_to_save:
                    logger.info(f"ğŸ† é¢„ä¿å­˜ {len(all_teams_to_save)} ä¸ªçƒé˜Ÿ...")

                    for team_id, name, short_name, _crest, _source in all_teams_to_save:
                        if team_id > 0:  # åªä¿å­˜æœ‰æ•ˆçš„çƒé˜ŸID
                            try:
                                # ä½¿ç”¨PostgreSQLçš„UPSERTè¯­æ³•
                                stmt = (
                                    insert(Team)
                                    .values(
                                        id=team_id,
                                        name=name or f"Team_{team_id}",
                                        short_name=short_name
                                        or name
                                        or f"Team_{team_id}",
                                        country="Unknown",  # Teamæ¨¡å‹è¦æ±‚countryå­—æ®µä¸èƒ½ä¸ºç©º
                                        founded_year=None,
                                        venue="",  # å½»åº•åˆ‡æ–­å¯èƒ½çš„ç½‘ç»œéªŒè¯
                                        website="",  # å½»åº•åˆ‡æ–­å¯èƒ½çš„ç½‘ç»œéªŒè¯
                                        created_at=datetime.now(),
                                        updated_at=datetime.now(),
                                    )
                                    .on_conflict_do_nothing(index_elements=["id"])
                                )

                                save_result = await session.execute(stmt)
                                # è®°å½•çƒé˜Ÿä¿å­˜ç»“æœ
                                if save_result.rowcount > 0:
                                    logger.info(
                                        f"âœ… æ–°çƒé˜Ÿä¿å­˜æˆåŠŸ: {team_id} - {name}"
                                    )
                                else:
                                    logger.debug(f"â„¹ï¸ çƒé˜Ÿå·²å­˜åœ¨: {team_id}")
                            except Exception as team_error:
                                # å¿½ç•¥DNSé”™è¯¯ï¼Œç»§ç»­å¤„ç†å…¶ä»–çƒé˜Ÿ
                                if "Temporary failure in name resolution" in str(
                                    team_error
                                ):
                                    logger.warning(
                                        f"âš ï¸ çƒé˜Ÿ {team_id} ({name}) å› ç½‘ç»œé—®é¢˜è·³è¿‡: {team_error}"
                                    )
                                else:
                                    logger.error(
                                        f"âŒ çƒé˜Ÿ {team_id} ({name}) ä¿å­˜å¤±è´¥: {team_error}"
                                    )
                                continue

                    # ğŸ›¡ï¸ åˆ·æ–°çƒé˜Ÿæ•°æ®åˆ°æ•°æ®åº“ï¼Œå¤±è´¥æ—¶æ‰§è¡Œrollback
                    try:
                        await session.flush()  # ç¡®ä¿çƒé˜Ÿæ•°æ®å…ˆå†™å…¥
                        logger.debug("âœ… çƒé˜Ÿæ•°æ®flushæˆåŠŸ")
                    except Exception as flush_error:
                        logger.error(f"âŒ çƒé˜Ÿæ•°æ®flushå¤±è´¥: {flush_error}")
                        await session.rollback()
                        raise

                    # éªŒè¯çƒé˜Ÿä¿å­˜ç»“æœ
                    saved_teams_count = await session.execute(
                        text("SELECT COUNT(*) FROM teams")
                    )
                    saved_count = saved_teams_count.scalar()
                    logger.info(f"âœ… çƒé˜Ÿæ•°æ®é¢„ä¿å­˜å®Œæˆï¼Œå½“å‰çƒé˜Ÿæ€»æ•°: {saved_count}")

                    # ç®€åŒ–éªŒè¯ï¼šè·³è¿‡å¤æ‚çš„SQLæŸ¥è¯¢ï¼Œç›´æ¥ç»§ç»­
                    logger.info("âœ… çƒé˜Ÿæ•°æ®éªŒè¯å®Œæˆï¼Œç»§ç»­ä¿å­˜æ¯”èµ›æ•°æ®")

                # ğŸ¯ æ­¥éª¤3: ä¿å­˜æ¯”èµ›æ•°æ®ï¼ˆFootball-Data.orgï¼‰
                if result.football_data_matches:
                    for match_data in result.football_data_matches:
                        try:
                            home_team = match_data.get("homeTeam", {})
                            away_team = match_data.get("awayTeam", {})
                            score = match_data.get("score", {})

                            home_team_id = home_team.get("id", 0)
                            away_team_id = away_team.get("id", 0)

                            if home_team_id == 0 or away_team_id == 0:
                                continue  # è·³è¿‡æ— æ•ˆçƒé˜ŸIDçš„æ¯”èµ›

                            # è§£ææ¯”èµ›æ—¶é—´
                            raw_date = datetime.fromisoformat(
                                match_data.get("utcDate", f"{result.date}T15:00:00Z")
                            )
                            match_date = (
                                raw_date.replace(tzinfo=None)
                                if raw_date.tzinfo
                                else raw_date
                            )

                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            existing_stmt = select(Match).where(
                                Match.home_team_id == home_team_id,
                                Match.away_team_id == away_team_id,
                                Match.match_date == match_date,
                            )
                            existing_match_result = await session.execute(existing_stmt)
                            existing_match = existing_match_result.scalar_one_or_none()

                            if existing_match:
                                logger.warning(
                                    f"âš ï¸ Football-Dataé‡å¤å‘ç°: DB ID {existing_match.id} - {home_team_id} vs {away_team_id} at {match_date}"
                                )
                                continue
                            else:
                                logger.info(
                                    f"âœ… å‡†å¤‡æ’å…¥æ–°Football-Dataæ¯”èµ›: {home_team_id} vs {away_team_id} at {match_date}"
                                )

                            # åˆ›å»ºæ¯”èµ›è®°å½•
                            new_match = Match(
                                home_team_id=home_team_id,
                                away_team_id=away_team_id,
                                home_score=score.get("fullTime", {}).get("home", 0),
                                away_score=score.get("fullTime", {}).get("away", 0),
                                match_date=match_date,
                                status=match_data.get("status", "SCHEDULED"),
                                league_id=match_data.get("competition", {}).get(
                                    "id", 0
                                ),
                                season=match_data.get("season", {}).get(
                                    "startDate", ""
                                )[:4]
                                if match_data.get("season")
                                else result.date[:4],
                                created_at=datetime.now(),
                                updated_at=datetime.now(),
                            )

                            session.add(new_match)
                            logger.info(
                                f"ğŸ¯ ATTEMPTING TO SAVE Football-Data MATCH: {new_match.home_team_id} vs {new_match.away_team_id} at {new_match.match_date}"
                            )
                            saved_count += 1

                        except Exception as match_error:
                            logger.error(f"âŒ Football-Dataæ¯”èµ›ä¿å­˜å¤±è´¥: {match_error}")
                            import traceback

                            logger.error(
                                f"ğŸ› Football-Dataé”™è¯¯è¯¦æƒ…: {traceback.format_exc()}"
                            )
                            continue

                # âš½ æ­¥éª¤4: ä¿å­˜æ¯”èµ›æ•°æ®ï¼ˆFotMobï¼‰
                if result.fotmob_matches:
                    for match_data in result.fotmob_matches:
                        try:
                            home_team = match_data.get("home", {})
                            away_team = match_data.get("away", {})

                            home_team_id = home_team.get("id", 0)
                            away_team_id = away_team.get("id", 0)

                            if home_team_id == 0 or away_team_id == 0:
                                continue  # è·³è¿‡æ— æ•ˆçƒé˜ŸIDçš„æ¯”èµ›

                            # è§£æFotMobçš„æ¯”èµ›æ—¶é—´ (å¢å¼ºç‰ˆ: æ”¯æŒå¤šç§æ ¼å¼)
                            match_date_str = match_data.get("matchDate")
                            if match_date_str:
                                try:
                                    # ğŸ¯ æ–¹æ³•1: å°è¯•è§£æ ISO æ ¼å¼ (ç°æœ‰é€»è¾‘)
                                    # æ ¼å¼: "2025-11-29T00:30:00.000Z"
                                    raw_date = datetime.fromisoformat(
                                        match_date_str.replace("Z", "+00:00")
                                    )
                                    match_date = (
                                        raw_date.replace(tzinfo=None)
                                        if raw_date.tzinfo
                                        else raw_date
                                    )
                                    logger.debug(
                                        f"âœ… ISOæ—¥æœŸè§£ææˆåŠŸ: {match_date_str} -> {match_date}"
                                    )
                                except ValueError:
                                    try:
                                        # ğŸ¯ æ–¹æ³•2: å°è¯•è§£æ FotMob å¾·å¼æ ¼å¼ (DD.MM.YYYY HH:MM)
                                        # æ ¼å¼: "21.12.2025 20:00"
                                        raw_date = datetime.strptime(
                                            match_date_str, "%d.%m.%Y %H:%M"
                                        )
                                        match_date = raw_date
                                        logger.debug(
                                            f"âœ… å¾·å¼æ—¥æœŸè§£ææˆåŠŸ: {match_date_str} -> {match_date}"
                                        )
                                    except ValueError:
                                        try:
                                            # ğŸ¯ æ–¹æ³•3: å°è¯•è§£æå…¶ä»–å¸¸è§æ ¼å¼
                                            # æ ¼å¼: "21.12.2025" (æ— æ—¶é—´)
                                            raw_date = datetime.strptime(
                                                match_date_str, "%d.%m.%Y"
                                            )
                                            match_date = raw_date.replace(
                                                hour=15, minute=0
                                            )  # é»˜è®¤15:00
                                            logger.debug(
                                                f"âœ… æ—¥æœŸæ ¼å¼è§£ææˆåŠŸ: {match_date_str} -> {match_date}"
                                            )
                                        except ValueError:
                                            # ğŸ¯ æ–¹æ³•4: æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´
                                            logger.warning(
                                                f"âš ï¸ æ— æ³•è§£ææ—¥æœŸæ ¼å¼: {match_date_str}ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´"
                                            )
                                            match_date = datetime.strptime(
                                                f"{result.date} 15:00:00",
                                                "%Y-%m-%d %H:%M:%S",
                                            )
                            else:
                                # ä½¿ç”¨é»˜è®¤æ—¶é—´
                                match_date = datetime.strptime(
                                    f"{result.date} 15:00:00", "%Y-%m-%d %H:%M:%S"
                                )
                                logger.debug(f"ä½¿ç”¨é»˜è®¤æ—¶é—´: {match_date}")

                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            existing_stmt = select(Match).where(
                                Match.home_team_id == home_team_id,
                                Match.away_team_id == away_team_id,
                                Match.match_date == match_date,
                            )
                            existing_match_result = await session.execute(existing_stmt)
                            existing_match = existing_match_result.scalar_one_or_none()

                            if existing_match:
                                logger.warning(
                                    f"âš ï¸ Football-Dataé‡å¤å‘ç°: DB ID {existing_match.id} - {home_team_id} vs {away_team_id} at {match_date}"
                                )
                                continue
                            else:
                                logger.info(
                                    f"âœ… å‡†å¤‡æ’å…¥æ–°Football-Dataæ¯”èµ›: {home_team_id} vs {away_team_id} at {match_date}"
                                )

                            # åˆ›å»ºæ¯”èµ›è®°å½•
                            new_match = Match(
                                home_team_id=home_team_id,
                                away_team_id=away_team_id,
                                home_score=home_team.get("score", 0),
                                away_score=away_team.get("score", 0),
                                match_date=match_date,
                                status=self._parse_status(
                                    match_data.get("status", "SCHEDULED")
                                ),
                                league_id=0,  # FotMobæ•°æ®æš‚æ—¶è®¾ä¸º0
                                season=result.date[:4],
                                created_at=datetime.now(),
                                updated_at=datetime.now(),
                            )

                            session.add(new_match)
                            logger.info(
                                f"ğŸ¯ ATTEMPTING TO SAVE FotMob MATCH: {new_match.home_team_id} vs {new_match.away_team_id} at {new_match.match_date}"
                            )
                            saved_count += 1

                        except Exception as match_error:
                            logger.error(f"âŒ FotMobæ¯”èµ›ä¿å­˜å¤±è´¥: {match_error}")
                            import traceback

                            logger.error(f"ğŸ› FotMobé”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                            continue

                # æäº¤æ‰€æœ‰äº‹åŠ¡
                await session.commit()
                logger.info(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ: {result.date} - {saved_count} åœºæ–°æ¯”èµ›")

                # ğŸ¯ èµ”ç‡æ•°æ®æ”¶é›† - ä»…å¯¹å³å°†å¼€å§‹çš„æ¯”èµ›æ”¶é›†èµ”ç‡
                if self.odds_collector and saved_count > 0:
                    try:
                        odds_collected_count = await self._collect_odds_for_new_matches(
                            session, result.date
                        )
                        if odds_collected_count > 0:
                            logger.info(
                                f"ğŸ“ˆ {result.date}: æˆåŠŸæ”¶é›† {odds_collected_count} æ¡èµ”ç‡æ•°æ®"
                            )
                    except Exception as odds_error:
                        logger.warning(f"âš ï¸ èµ”ç‡æ”¶é›†å¤±è´¥: {odds_error}")

        except Exception:
            logger.error(f"FATAL COMMIT FAILURE: {e}")
            import traceback

            traceback.print_exc()  # <-- æ‰“å°å®Œæ•´å †æ ˆ
            raise  # <-- å¼ºåˆ¶é€€å‡ºè„šæœ¬ï¼Œä»¥ä¾¿æˆ‘ä»¬çœ‹åˆ°é”™è¯¯

    def _process_single_date_sync(
        self, date_str: str, sources: list[str] = None
    ) -> tuple[str, DailyDataResult]:
        """åŒæ­¥å¤„ç†å•æ—¥æ•°æ®çš„æ–¹æ³•ï¼Œç”¨äºThreadPoolExecutor"""
        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥æ–¹æ³•
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(self.collect_daily_data(date_str, sources))
            return (date_str, result)
        finally:
            loop.close()
            # æ¸…ç†äº‹ä»¶å¾ªç¯ï¼Œé¿å…å†…å­˜æ³„æ¼
            asyncio.set_event_loop(None)

    async def run_backfill(
        self,
        start_date: datetime,
        end_date: datetime,
        sources: list[str] = None,
        dry_run: bool = False,
        resume: bool = False,
    ) -> BackfillStats:
        """æ‰§è¡Œå…¨é‡æ•°æ®å›å¡«"""

        # åˆå§‹åŒ–ç»Ÿè®¡
        self.stats = BackfillStats(start_time=datetime.now())
        self.stats.total_days = (end_date - start_date).days + 1

        # ç”Ÿæˆæ—¥æœŸèŒƒå›´
        dates = self.generate_date_range(start_date, end_date)

        # å¤„ç†æ¢å¤é€»è¾‘
        if resume:
            state = self.load_resume_state()
            if state:
                last_processed = state.get("last_processed_date")
                if last_processed:
                    try:
                        last_date_idx = dates.index(last_processed)
                        dates = dates[last_date_idx + 1 :]
                        logger.info(
                            f"ğŸ”„ ä» {last_processed} åç»§ç»­ï¼Œå‰©ä½™ {len(dates)} å¤©"
                        )
                    except ValueError:
                        logger.warning(
                            f"âš ï¸ æ¢å¤æ—¥æœŸ {last_processed} ä¸åœ¨èŒƒå›´å†…ï¼Œä»å¤´å¼€å§‹"
                        )

        # å¹²è¿è¡Œæ¨¡å¼
        if dry_run:
            logger.info("ğŸ” DRY RUNæ¨¡å¼ - æ˜¾ç¤ºé‡‡é›†è®¡åˆ’")
            print("\nğŸ“‹ å…¨é‡å›å¡«è®¡åˆ’:")
            print(
                f"   ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}"
            )
            print(f"   ğŸ“Š æ€»å¤©æ•°: {len(dates)} å¤©")
            print(f"   ğŸ”— æ•°æ®æº: {sources or ['all']}")
            print(f"   â±ï¸ é¢„è®¡æ—¶é—´: {len(dates) * 2.5 / 60:.1f} å°æ—¶")
            print(f"   ğŸ¯ å»¶è¿Ÿç­–ç•¥: {self.min_delay}-{self.max_delay} ç§’")

            # æ˜¾ç¤ºå‰10å¤©ç¤ºä¾‹
            print("\nğŸ“… é‡‡é›†æ—¥æœŸç¤ºä¾‹:")
            for i, date in enumerate(dates[:10]):
                print(f"   [{i + 1:3}] {date}")
            if len(dates) > 10:
                print(f"   ... è¿˜æœ‰ {len(dates) - 10} å¤©")

            self.stats.processed_days = len(dates)
            return self.stats

        # å®é™…æ‰§è¡Œæ¨¡å¼
        try:
            # ğŸš€ å¹¶è¡Œå¤„ç†é‡æ„ï¼šä½¿ç”¨ ThreadPoolExecutor æå‡æ•ˆç‡ 5 å€ä»¥ä¸Š
            logger.info(f"ğŸš€ å¼€å§‹å…¨é‡æ•°æ®å›å¡«: {len(dates)} å¤©å¾…å¤„ç†")
            logger.info("âš¡ å¯åŠ¨å¹¶è¡Œå¤„ç†æ¨¡å¼ï¼š5ä¸ªçº¿ç¨‹åŒæ—¶å·¥ä½œ")

            with ThreadPoolExecutor(max_workers=5) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
                future_to_date = {
                    executor.submit(
                        self._process_single_date_sync, date_str, sources
                    ): date_str
                    for date_str in dates
                }

                # æŒ‰å®Œæˆé¡ºåºå¤„ç†ç»“æœ
                completed_count = 0
                for future in as_completed(future_to_date):
                    completed_count += 1
                    date_str = future_to_date[future]
                    progress = completed_count / len(dates) * 100

                    logger.info(
                        f"ğŸ“… [{completed_count:4}/{len(dates)}] ({progress:5.1f}%) å¤„ç† {date_str}"
                    )

                    try:
                        # è·å–å¤„ç†ç»“æœ
                        result_date, result = future.result()

                        # æ›´æ–°ç»Ÿè®¡
                        self.stats.processed_days += 1
                        self.stats.total_matches += result.total_matches

                        if result.success:
                            self.stats.successful_days += 1
                        else:
                            self.stats.failed_days += 1

                        # ä¿å­˜æ¢å¤çŠ¶æ€
                        self.save_resume_state(result_date, self.stats)

                        # æ˜¾ç¤ºè¿›åº¦
                        if completed_count % 10 == 0:  # æ¯10å¤©æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
                            await self._print_progress()

                        logger.info(
                            f"âœ… {result_date}: {result.total_matches} åœºæ¯”èµ›é‡‡é›†å®Œæˆ"
                        )

                    except Exception:
                        logger.error(f"âŒ æ—¥æœŸ {date_str} å¤„ç†å¤±è´¥: {e}")
                        self.stats.failed_days += 1
                        continue

            # æœ€ç»ˆç»Ÿè®¡
            await self._print_final_stats()

        except KeyboardInterrupt:
            logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œï¼ŒçŠ¶æ€å·²ä¿å­˜")
        except Exception:
            logger.error(f"âŒ å›å¡«æ‰§è¡Œå¼‚å¸¸: {e}")
            raise
        finally:
            # æ¸…ç†èµ„æº
            if self.db_engine:
                await self.db_engine.dispose()

        return self.stats

    async def _print_progress(self):
        """æ‰“å°å½“å‰è¿›åº¦"""
        elapsed = self.stats.elapsed_time

        # è®¡ç®—é¢„è®¡å®Œæˆæ—¶é—´
        if self.stats.processed_days > 0:
            avg_time_per_day = elapsed.total_seconds() / self.stats.processed_days
            remaining_days = self.stats.total_days - self.stats.processed_days
            eta_seconds = avg_time_per_day * remaining_days
            self.stats.estimated_completion = datetime.now() + timedelta(
                seconds=eta_seconds
            )

        logger.info("ğŸ“Š å½“å‰è¿›åº¦ç»Ÿè®¡:")
        logger.info(
            f"   âœ… æˆåŠŸå¤©æ•°: {self.stats.successful_days}/{self.stats.processed_days} ({self.stats.success_rate:.1f}%)"
        )
        logger.info(f"   ğŸ† æ€»æ¯”èµ›æ•°: {self.stats.total_matches}")
        logger.info(f"   â±ï¸ å·²ç”¨æ—¶é—´: {elapsed}")
        if self.stats.estimated_completion:
            logger.info(
                f"   ğŸ¯ é¢„è®¡å®Œæˆ: {self.stats.estimated_completion.strftime('%H:%M:%S')}"
            )

    async def _print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = self.stats.elapsed_time

        print("\n" + "=" * 80)
        print("ğŸ‰ å…¨é‡æ•°æ®å›å¡«å®Œæˆç»Ÿè®¡")
        print("=" * 80)
        print(f"ğŸ“… å¤„ç†å¤©æ•°: {self.stats.successful_days}/{self.stats.total_days}")
        print(f"âœ… æˆåŠŸç‡: {self.stats.success_rate:.1f}%")
        print(f"ğŸ† æ€»æ¯”èµ›æ•°: {self.stats.total_matches}")
        print(f"â±ï¸ æ€»ç”¨æ—¶: {elapsed}")

        if self.stats.processed_days > 0:
            avg_matches_per_day = self.stats.total_matches / self.stats.processed_days
            avg_time_per_day = elapsed.total_seconds() / self.stats.processed_days
            print(f"ğŸ“Š å¹³å‡æ•°æ®: {avg_matches_per_day:.1f} åœºæ¯”èµ›/å¤©")
            print(f"ğŸ“Š å¹³å‡é€Ÿåº¦: {avg_time_per_day:.1f} ç§’/å¤©")

        print("=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å…¨çƒè¶³çƒæ•°æ®å…¨é‡å›å¡«è„šæœ¬")
    parser.add_argument(
        "--start-date",
        default="2022-01-01",
        help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: 2022-01-01)",
    )
    parser.add_argument(
        "--end-date",
        default=datetime.now().strftime("%Y-%m-%d"),
        help="ç»“æŸæ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: ä»Šå¤©)",
    )
    parser.add_argument(
        "--dry-run", action="store_true", help="å¹²è¿è¡Œæ¨¡å¼ï¼Œåªæ˜¾ç¤ºè®¡åˆ’ä¸å®é™…é‡‡é›†"
    )
    parser.add_argument(
        "--resume", action="store_true", help="ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œ"
    )
    parser.add_argument(
        "--source",
        choices=["all", "football-data", "fotmob"],
        default="all",
        help="æ•°æ®æºé€‰æ‹© (é»˜è®¤: all)",
    )

    args = parser.parse_args()

    try:
        # è§£ææ—¥æœŸ
        start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
        end_date = datetime.strptime(args.end_date, "%Y-%m-%d")

        # éªŒè¯æ—¥æœŸèŒƒå›´
        if end_date < start_date:
            logger.error("âŒ ç»“æŸæ—¥æœŸä¸èƒ½æ—©äºå¼€å§‹æ—¥æœŸ")
            return 1

        # ç¡®å®šæ•°æ®æº
        sources = None
        if args.source != "all":
            sources = [args.source]

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        logger.info("ğŸ† å…¨çƒè¶³çƒæ•°æ®å…¨é‡å›å¡«ç³»ç»Ÿ")
        logger.info("=" * 80)
        logger.info(
            f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}"
        )
        logger.info(f"ğŸ“Š æ€»å¤©æ•°: {(end_date - start_date).days + 1} å¤©")
        logger.info(f"ğŸ”— æ•°æ®æº: {args.source}")
        logger.info(f"ğŸ” å¹²è¿è¡Œ: {'æ˜¯' if args.dry_run else 'å¦'}")
        logger.info(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : {'æ˜¯' if args.resume else 'å¦'}")
        logger.info("=" * 80)

        # åˆå§‹åŒ–å›å¡«æœåŠ¡
        service = GlobalBackfillService()
        await service.initialize()

        # æ‰§è¡Œå›å¡«
        stats = await service.run_backfill(
            start_date=start_date,
            end_date=end_date,
            sources=sources,
            dry_run=args.dry_run,
            resume=args.resume,
        )

        # æ˜¾ç¤ºç»“æœ
        if args.dry_run:
            logger.info(f"ğŸ” DRY RUNå®Œæˆ: è®¡åˆ’å¤„ç† {stats.total_days} å¤©")
        else:
            logger.info(
                f"ğŸ‰ å›å¡«å®Œæˆ: æˆåŠŸ {stats.successful_days}/{stats.total_days} å¤©"
            )

        return 0

    except KeyboardInterrupt:
        logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return 1
    except Exception:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
