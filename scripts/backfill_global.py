#!/usr/bin/env python3
"""
ğŸ† å…¨é‡æ•°æ®å›å¡«è„šæœ¬ - Enterprise-grade Backfill Script
ğŸ¯ Target:åœ°æ¯¯å¼å…¨è¦†ç›–è¶³çƒæ•°æ® (2022-01-01 to Present)
ğŸ“… Date Range: 2022-01-01 to today
ğŸ—ï¸ Architecture: Async + Rate Limiting + PostgreSQL Persistence

ğŸš€ Features:
- å…¨é¢è¦†ç›–ï¼šæ¯æ—¥è¿ç»­é‡‡é›†ï¼Œæ— é—´æ–­
- æ™ºèƒ½é™æµï¼š1.5-3.5ç§’éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸäººè¡Œä¸º
- åŒæ•°æ®æºï¼šFootball-Data.org + FotMob
- å®æ—¶ç»Ÿè®¡ï¼šé‡‡é›†è¿›åº¦ã€æˆåŠŸç‡ã€é”™è¯¯ç›‘æ§
- æ–­ç‚¹ç»­ä¼ ï¼šæ”¯æŒä¸­æ–­åç»§ç»­æ‰§è¡Œ
- æ•°æ®å®Œæ•´æ€§ï¼šPostgreSQLäº‹åŠ¡ + é‡å¤æ£€æµ‹

Usage:
    python scripts/backfill_global.py [--start-date=2022-01-01] [--end-date=2024-12-31] [--dry-run] [--resume]

Arguments:
    --start-date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: 2022-01-01)
    --end-date: ç»“æŸæ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: ä»Šå¤©)
    --dry-run: åªæ˜¾ç¤ºè®¡åˆ’ï¼Œä¸å®é™…é‡‡é›†æ•°æ®
    --resume: ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œ
    --source: æ•°æ®æºé€‰æ‹© (all, football-data, fotmobï¼Œé»˜è®¤: all)
"""

import asyncio
import logging
import os
import sys
import json
import time
import random
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from contextlib import asynccontextmanager

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å»¶è¿Ÿå¯¼å…¥æ¨¡å‹ä»¥åˆå§‹åŒ– ORM æ˜ å°„å…³ç³» (è§£å†³å¾ªç¯ä¾èµ–é—®é¢˜)
def _init_orm_models():
    """å»¶è¿Ÿåˆå§‹åŒ–æ‰€æœ‰ORMæ¨¡å‹ï¼Œé¿å…å¾ªç¯ä¾èµ–"""
    try:
        # å¯¼å…¥æ ¸å¿ƒæ¨¡å‹ï¼Œç¡®ä¿ORMæ˜ å°„æ­£ç¡®åˆå§‹åŒ–
        import src.database.models.tenant
        import src.database.models.user
        import src.database.models.team
        import src.database.models.league
        import src.database.models.match
        import src.database.models.predictions
        import src.database.models.odds
        import src.database.models.features
        import src.database.models.data_collection_log
        import src.database.models.data_quality_log
        import src.database.models.audit_log
        print("âœ… ORMæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ ORMæ¨¡å‹åˆå§‹åŒ–è­¦å‘Š: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œæ ¸å¿ƒMatchæ¨¡å‹åº”è¯¥ä»ç„¶å¯ç”¨

# é…ç½®é«˜çº§æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)8s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

# ç¯å¢ƒæ–‡ä»¶åŠ è½½ä¼˜å…ˆçº§
env_files = [
    project_root / ".env",
    project_root / ".env.local",
    project_root / ".env.development",
]

for env_file in env_files:
    if env_file.exists():
        load_dotenv(env_file)
        logger.info(f"âœ… åŠ è½½ç¯å¢ƒæ–‡ä»¶: {env_file}")
        break


@dataclass
class BackfillStats:
    """å›å¡«ç»Ÿè®¡æ•°æ®"""
    total_days: int = 0
    processed_days: int = 0
    successful_days: int = 0
    failed_days: int = 0
    total_matches: int = 0
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    start_time: Optional[datetime] = None
    estimated_completion: Optional[datetime] = None

    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        return (self.successful_days / max(self.processed_days, 1)) * 100

    @property
    def request_success_rate(self) -> float:
        """è¯·æ±‚æˆåŠŸç‡"""
        return (self.successful_requests / max(self.total_requests, 1)) * 100

    @property
    def elapsed_time(self) -> timedelta:
        """å·²ç”¨æ—¶é—´"""
        if self.start_time:
            return datetime.now() - self.start_time
        return timedelta(0)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        if self.start_time:
            data['start_time'] = self.start_time.isoformat()
        if self.estimated_completion:
            data['estimated_completion'] = self.estimated_completion.isoformat()
        data['elapsed_time'] = str(self.elapsed_time)
        data['success_rate'] = self.success_rate
        data['request_success_rate'] = self.request_success_rate
        return data


@dataclass
class DailyDataResult:
    """æ¯æ—¥æ•°æ®é‡‡é›†ç»“æœ"""
    date: str
    football_data_matches: List[Dict] = None
    fotmob_matches: List[Dict] = None
    total_matches: int = 0
    collection_time: Optional[datetime] = None
    errors: List[str] = None
    success: bool = False

    def __post_init__(self):
        if self.football_data_matches is None:
            self.football_data_matches = []
        if self.fotmob_matches is None:
            self.fotmob_matches = []
        if self.errors is None:
            self.errors = []
        if self.collection_time is None:
            self.collection_time = datetime.now()


class GlobalBackfillService:
    """å…¨çƒæ•°æ®å›å¡«æœåŠ¡"""

    def __init__(self):
        self.stats = BackfillStats()
        self.state_file = project_root / "data" / "backfill_state.json"
        self.state_file.parent.mkdir(exist_ok=True)

        # APIé™æµé…ç½®
        self.min_delay = 8.0   # å¢åŠ æœ€å°å»¶è¿Ÿé¿å…429
        self.max_delay = 15.0  # å¢åŠ æœ€å¤§å»¶è¿Ÿé¿å…429

        # åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨
        self.football_collector = None
        self.fotmob_collector = None

        # æ•°æ®åº“è¿æ¥
        self.db_engine = None

    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        logger.info("ğŸš€ åˆå§‹åŒ–å…¨çƒæ•°æ®å›å¡«æœåŠ¡...")

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        await self._init_database()

        # åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨
        await self._init_collectors()

        logger.info("âœ… å›å¡«æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            # é¦–å…ˆåˆå§‹åŒ–ORMæ¨¡å‹æ˜ å°„å…³ç³»
            _init_orm_models()

            from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
            from sqlalchemy.orm import sessionmaker

            database_url = os.getenv("DATABASE_URL")
            if not database_url:
                # æ„å»ºæ•°æ®åº“URL
                db_host = os.getenv("DB_HOST", "db")
                db_port = os.getenv("DB_PORT", "5432")
                db_user = os.getenv("POSTGRES_USER", "postgres")
                db_password = os.getenv("POSTGRES_PASSWORD", "postgres-dev-password")
                db_name = os.getenv("POSTGRES_DB", "football_prediction")
                database_url = f"postgresql+asyncpg://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"

            # è½¬æ¢ä¸ºå¼‚æ­¥URL
            if database_url.startswith("postgresql://"):
                database_url = database_url.replace("postgresql://", "postgresql+asyncpg://", 1)

            self.db_engine = create_async_engine(
                database_url,
                pool_size=5,
                max_overflow=10,
                pool_pre_ping=True,
                echo=False
            )

            self.async_session = sessionmaker(
                self.db_engine, class_=AsyncSession, expire_on_commit=False
            )

            logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def _init_collectors(self):
        """åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨"""
        try:
            # Football-Data.orgé‡‡é›†å™¨
            from src.collectors.football_data_collector import FootballDataCollector
            self.football_collector = FootballDataCollector()

            # FotMobé‡‡é›†å™¨ (å¦‚æœå­˜åœ¨)
            try:
                from src.data.collectors.fotmob_collector import FotmobCollector
                self.fotmob_collector = FotmobCollector()
                logger.info("âœ… FotMobé‡‡é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except ImportError:
                logger.warning("âš ï¸ FotMobé‡‡é›†å™¨ä¸å¯ç”¨ï¼Œå°†åªä½¿ç”¨Football-Data.org")
                self.fotmob_collector = None

            logger.info("âœ… æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def generate_date_range(self, start_date: datetime, end_date: datetime) -> List[str]:
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´åˆ—è¡¨"""
        logger.info("ğŸ“… ç”Ÿæˆæ—¥æœŸèŒƒå›´...")

        dates = []
        current_date = start_date

        while current_date <= end_date:
            dates.append(current_date.strftime("%Y-%m-%d"))
            current_date += timedelta(days=1)

        logger.info(f"ğŸ“‹ ç”Ÿæˆ {len(dates)} ä¸ªé‡‡é›†æ—¥æœŸ ({dates[0]} to {dates[-1]})")
        return dates

    def load_resume_state(self) -> Optional[Dict[str, Any]]:
        """åŠ è½½æ¢å¤çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                    logger.info(f"ğŸ”„ å‘ç°æ¢å¤çŠ¶æ€: ä¸Šæ¬¡å¤„ç†åˆ° {state.get('last_processed_date', 'Unknown')}")
                    return state
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•åŠ è½½æ¢å¤çŠ¶æ€: {e}")
        return None

    def save_resume_state(self, last_processed_date: str, stats: BackfillStats):
        """ä¿å­˜æ¢å¤çŠ¶æ€"""
        try:
            state = {
                "last_processed_date": last_processed_date,
                "stats": stats.to_dict(),
                "timestamp": datetime.now().isoformat(),
                "version": "1.0.0"
            }

            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ¢å¤çŠ¶æ€å¤±è´¥: {e}")

    async def collect_daily_data(self, date_str: str, sources: List[str] = None) -> DailyDataResult:
        """é‡‡é›†æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
        if sources is None:
            sources = ["football-data", "fotmob"]

        result = DailyDataResult(date=date_str)

        try:
            # è§£ææ—¥æœŸ
            target_date = datetime.strptime(date_str, "%Y-%m-%d")

            # è®¾ç½®æ—¥æœŸèŒƒå›´ï¼ˆå½“å¤©å‰å1å¤©ä»¥ç¡®ä¿è¦†ç›–ï¼‰
            date_from = target_date - timedelta(days=1)
            date_to = target_date + timedelta(days=1)

            logger.info(f"ğŸ“… é‡‡é›† {date_str} çš„è¶³çƒæ•°æ®...")

            # Football-Data.orgé‡‡é›†
            if "football-data" in sources and self.football_collector:
                try:
                    matches_result = await self.football_collector.collect_matches(
                        date_from=date_from,
                        date_to=date_to,
                        limit=500  # æé«˜é™åˆ¶è·å–æ›´å¤šæ•°æ®
                    )

                    if matches_result.success:
                        result.football_data_matches = matches_result.data.get("matches", [])
                        logger.info(f"âœ… Football-Data.org: è·å– {len(result.football_data_matches)} åœºæ¯”èµ›")
                    else:
                        error_msg = f"Football-Data.orgé‡‡é›†å¤±è´¥: {matches_result.error}"
                        result.errors.append(error_msg)
                        logger.error(error_msg)

                except Exception as e:
                    error_msg = f"Football-Data.orgå¼‚å¸¸: {e}"
                    result.errors.append(error_msg)
                    logger.error(error_msg)

                # æ™ºèƒ½å»¶è¿Ÿ
                await asyncio.sleep(random.uniform(self.min_delay, self.max_delay))

            # FotMobé‡‡é›†
            if "fotmob" in sources and self.fotmob_collector:
                try:
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„FotMobé‡‡é›†å™¨APIè°ƒæ•´
                    fotmob_result = await self.fotmob_collector.collect_matches_by_date(date_str)

                    if fotmob_result.success:
                        # ğŸ› ï¸ é€‚é…æ–°çš„FotMobé‡‡é›†å™¨æ ¼å¼
                        # æ–°æ ¼å¼è¿”å›ç›´æ¥çš„æ¯”èµ›åˆ—è¡¨ï¼Œä¸æ˜¯åŒ…å«"matches"é”®çš„å­—å…¸
                        if isinstance(fotmob_result.data, list):
                            result.fotmob_matches = fotmob_result.data
                            logger.info(f"âœ… FotMob: è·å– {len(result.fotmob_matches)} åœºæ¯”èµ› (æ–°æ ¼å¼)")
                        elif isinstance(fotmob_result.data, dict):
                            # å…¼å®¹æ—§æ ¼å¼
                            result.fotmob_matches = fotmob_result.data.get("matches", [])
                            logger.info(f"âœ… FotMob: è·å– {len(result.fotmob_matches)} åœºæ¯”èµ› (æ—§æ ¼å¼)")
                        else:
                            result.fotmob_matches = []
                            logger.warning(f"âš ï¸ FotMob: æœªçŸ¥æ•°æ®æ ¼å¼ {type(fotmob_result.data)}")
                    else:
                        error_msg = f"FotMobé‡‡é›†å¤±è´¥: {fotmob_result.error}"
                        result.errors.append(error_msg)
                        logger.error(error_msg)

                except Exception as e:
                    error_msg = f"FotMobå¼‚å¸¸: {e}"
                    result.errors.append(error_msg)
                    logger.error(error_msg)

                # æ™ºèƒ½å»¶è¿Ÿ
                await asyncio.sleep(random.uniform(self.min_delay, self.max_delay))

            # è®¡ç®—æ€»æ¯”èµ›æ•°
            result.total_matches = len(result.football_data_matches) + len(result.fotmob_matches)
            result.success = result.total_matches > 0 or len(result.errors) == 0

            # å­˜å‚¨åˆ°æ•°æ®åº“
            if result.success:
                await self._save_daily_data(result)

            logger.info(f"ğŸ“Š {date_str} é‡‡é›†å®Œæˆ: {result.total_matches} åœºæ¯”èµ›, {len(result.errors)} ä¸ªé”™è¯¯")

        except Exception as e:
            error_msg = f"æ—¥æœŸ {date_str} é‡‡é›†å¼‚å¸¸: {e}"
            result.errors.append(error_msg)
            logger.error(error_msg)

        return result

    async def _save_daily_data(self, result: DailyDataResult):
        """ä¿å­˜æ¯æ—¥æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            async with self.async_session() as session:
                from src.database.models.match import Match
                from src.database.models.team import Team
                from sqlalchemy import select
                from datetime import datetime
                from sqlalchemy.dialects.postgresql import insert

                saved_count = 0
                all_teams_to_save = set()  # ç”¨äºæ”¶é›†æ‰€æœ‰éœ€è¦ä¿å­˜çš„çƒé˜Ÿ

                # ğŸ† æ­¥éª¤1: æ”¶é›†æ‰€æœ‰çƒé˜Ÿæ•°æ®ï¼ˆFootball-Data.org + FotMobï¼‰
                if result.football_data_matches:
                    for match_data in result.football_data_matches:
                        home_team = match_data.get('homeTeam', {})
                        away_team = match_data.get('awayTeam', {})

                        if home_team.get('id'):
                            all_teams_to_save.add((
                                home_team.get('id', 0),
                                home_team.get('name', ''),
                                home_team.get('shortName', ''),
                                home_team.get('crest', ''),
                                'football-data'
                            ))

                        if away_team.get('id'):
                            all_teams_to_save.add((
                                away_team.get('id', 0),
                                away_team.get('name', ''),
                                away_team.get('shortName', ''),
                                away_team.get('crest', ''),
                                'football-data'
                            ))

                if result.fotmob_matches:
                    for match_data in result.fotmob_matches:
                        home_team = match_data.get('home', {})
                        away_team = match_data.get('away', {})

                        if home_team.get('id'):
                            all_teams_to_save.add((
                                home_team.get('id', 0),
                                home_team.get('name', ''),
                                home_team.get('shortName', ''),
                                None,  # FotMobæ²¡æœ‰crest
                                'fotmob'
                            ))

                        if away_team.get('id'):
                            all_teams_to_save.add((
                                away_team.get('id', 0),
                                away_team.get('name', ''),
                                away_team.get('shortName', ''),
                                None,  # FotMobæ²¡æœ‰crest
                                'fotmob'
                            ))

                # ğŸ›¡ï¸ æ­¥éª¤2: æ‰¹é‡ä¿å­˜çƒé˜Ÿæ•°æ®ï¼ˆä½¿ç”¨ON CONFLICT DO NOTHINGé¿å…é‡å¤ï¼‰
                if all_teams_to_save:
                    logger.info(f"ğŸ† é¢„ä¿å­˜ {len(all_teams_to_save)} ä¸ªçƒé˜Ÿ...")

                    for team_id, name, short_name, crest, source in all_teams_to_save:
                        if team_id > 0:  # åªä¿å­˜æœ‰æ•ˆçš„çƒé˜ŸID
                            try:
                                # ä½¿ç”¨PostgreSQLçš„UPSERTè¯­æ³•
                                stmt = insert(Team).values(
                                    id=team_id,
                                    name=name or f"Team_{team_id}",
                                    short_name=short_name or name or f"Team_{team_id}",
                                    crest=crest,
                                    created_at=datetime.now(),
                                    updated_at=datetime.now()
                                ).on_conflict_do_nothing(
                                    index_elements=['id']
                                )

                                await session.execute(stmt)
                            except Exception as team_error:
                                logger.debug(f"çƒé˜Ÿ {team_id} ä¿å­˜å¤±è´¥: {team_error}")
                                continue

                    await session.flush()  # ç¡®ä¿çƒé˜Ÿæ•°æ®å…ˆå†™å…¥
                    logger.info(f"âœ… çƒé˜Ÿæ•°æ®é¢„ä¿å­˜å®Œæˆ")

                # ğŸ¯ æ­¥éª¤3: ä¿å­˜æ¯”èµ›æ•°æ®ï¼ˆFootball-Data.orgï¼‰
                if result.football_data_matches:
                    for match_data in result.football_data_matches:
                        try:
                            home_team = match_data.get('homeTeam', {})
                            away_team = match_data.get('awayTeam', {})
                            score = match_data.get('score', {})

                            home_team_id = home_team.get('id', 0)
                            away_team_id = away_team.get('id', 0)

                            if home_team_id == 0 or away_team_id == 0:
                                continue  # è·³è¿‡æ— æ•ˆçƒé˜ŸIDçš„æ¯”èµ›

                            # è§£ææ¯”èµ›æ—¶é—´
                            raw_date = datetime.fromisoformat(match_data.get('utcDate', f"{result.date}T15:00:00Z"))
                            match_date = raw_date.replace(tzinfo=None) if raw_date.tzinfo else raw_date

                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            existing_stmt = select(Match).where(
                                Match.home_team_id == home_team_id,
                                Match.away_team_id == away_team_id,
                                Match.match_date == match_date
                            )
                            existing_result = await session.execute(existing_stmt)
                            existing_match = existing_result.scalar_one_or_none()

                            if existing_match:
                                continue

                            # åˆ›å»ºæ¯”èµ›è®°å½•
                            new_match = Match(
                                home_team_id=home_team_id,
                                away_team_id=away_team_id,
                                home_score=score.get('fullTime', {}).get('home', 0),
                                away_score=score.get('fullTime', {}).get('away', 0),
                                match_date=match_date,
                                status=match_data.get('status', 'SCHEDULED'),
                                league_id=match_data.get('competition', {}).get('id', 0),
                                season=match_data.get('season', {}).get('startDate', '')[:4] if match_data.get('season') else result.date[:4],
                                created_at=datetime.now(),
                                updated_at=datetime.now()
                            )

                            session.add(new_match)
                            logger.info(f"ğŸ¯ ATTEMPTING TO SAVE Football-Data MATCH: {new_match.home_team_id} vs {new_match.away_team_id} at {new_match.match_date}")
                            saved_count += 1

                        except Exception as match_error:
                            logger.error(f"âŒ Football-Dataæ¯”èµ›ä¿å­˜å¤±è´¥: {match_error}")
                            import traceback
                            logger.error(f"ğŸ› Football-Dataé”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                            continue

                # âš½ æ­¥éª¤4: ä¿å­˜æ¯”èµ›æ•°æ®ï¼ˆFotMobï¼‰
                if result.fotmob_matches:
                    for match_data in result.fotmob_matches:
                        try:
                            home_team = match_data.get('home', {})
                            away_team = match_data.get('away', {})

                            home_team_id = home_team.get('id', 0)
                            away_team_id = away_team.get('id', 0)

                            if home_team_id == 0 or away_team_id == 0:
                                continue  # è·³è¿‡æ— æ•ˆçƒé˜ŸIDçš„æ¯”èµ›

                            # è§£æFotMobçš„æ¯”èµ›æ—¶é—´ (å¢å¼ºç‰ˆ: æ”¯æŒå¤šç§æ ¼å¼)
                            match_date_str = match_data.get('matchDate')
                            if match_date_str:
                                try:
                                    # ğŸ¯ æ–¹æ³•1: å°è¯•è§£æ ISO æ ¼å¼ (ç°æœ‰é€»è¾‘)
                                    # æ ¼å¼: "2025-11-29T00:30:00.000Z"
                                    raw_date = datetime.fromisoformat(match_date_str.replace('Z', '+00:00'))
                                    match_date = raw_date.replace(tzinfo=None) if raw_date.tzinfo else raw_date
                                    logger.debug(f"âœ… ISOæ—¥æœŸè§£ææˆåŠŸ: {match_date_str} -> {match_date}")
                                except ValueError:
                                    try:
                                        # ğŸ¯ æ–¹æ³•2: å°è¯•è§£æ FotMob å¾·å¼æ ¼å¼ (DD.MM.YYYY HH:MM)
                                        # æ ¼å¼: "21.12.2025 20:00"
                                        raw_date = datetime.strptime(match_date_str, '%d.%m.%Y %H:%M')
                                        match_date = raw_date
                                        logger.debug(f"âœ… å¾·å¼æ—¥æœŸè§£ææˆåŠŸ: {match_date_str} -> {match_date}")
                                    except ValueError:
                                        try:
                                            # ğŸ¯ æ–¹æ³•3: å°è¯•è§£æå…¶ä»–å¸¸è§æ ¼å¼
                                            # æ ¼å¼: "21.12.2025" (æ— æ—¶é—´)
                                            raw_date = datetime.strptime(match_date_str, '%d.%m.%Y')
                                            match_date = raw_date.replace(hour=15, minute=0)  # é»˜è®¤15:00
                                            logger.debug(f"âœ… æ—¥æœŸæ ¼å¼è§£ææˆåŠŸ: {match_date_str} -> {match_date}")
                                        except ValueError:
                                            # ğŸ¯ æ–¹æ³•4: æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´
                                            logger.warning(f"âš ï¸ æ— æ³•è§£ææ—¥æœŸæ ¼å¼: {match_date_str}ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´")
                                            match_date = datetime.strptime(f"{result.date} 15:00:00", "%Y-%m-%d %H:%M:%S")
                            else:
                                # ä½¿ç”¨é»˜è®¤æ—¶é—´
                                match_date = datetime.strptime(f"{result.date} 15:00:00", "%Y-%m-%d %H:%M:%S")
                                logger.debug(f"ä½¿ç”¨é»˜è®¤æ—¶é—´: {match_date}")

                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            existing_stmt = select(Match).where(
                                Match.home_team_id == home_team_id,
                                Match.away_team_id == away_team_id,
                                Match.match_date == match_date
                            )
                            existing_result = await session.execute(existing_stmt)
                            existing_match = existing_result.scalar_one_or_none()

                            if existing_match:
                                continue

                            # åˆ›å»ºæ¯”èµ›è®°å½•
                            new_match = Match(
                                home_team_id=home_team_id,
                                away_team_id=away_team_id,
                                home_score=home_team.get('score', 0),
                                away_score=away_team.get('score', 0),
                                match_date=match_date,
                                status=match_data.get('status', {}).get('reason', {}).get('long', 'SCHEDULED')[:20],
                                league_id=0,  # FotMobæ•°æ®æš‚æ—¶è®¾ä¸º0
                                season=result.date[:4],
                                created_at=datetime.now(),
                                updated_at=datetime.now()
                            )

                            session.add(new_match)
                            logger.info(f"ğŸ¯ ATTEMPTING TO SAVE FotMob MATCH: {new_match.home_team_id} vs {new_match.away_team_id} at {new_match.match_date}")
                            saved_count += 1

                        except Exception as match_error:
                            logger.error(f"âŒ FotMobæ¯”èµ›ä¿å­˜å¤±è´¥: {match_error}")
                            import traceback
                            logger.error(f"ğŸ› FotMobé”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                            continue

                # æäº¤æ‰€æœ‰äº‹åŠ¡
                await session.commit()
                logger.info(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ: {result.date} - {saved_count} åœºæ–°æ¯”èµ›")

        except Exception as e:
            logger.error(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥ {result.date}: {e}")
            import traceback
            logger.error(f"ğŸ› æ•°æ®ä¿å­˜å¤±è´¥è¯¦æƒ…: {traceback.format_exc()}")
            raise

    async def run_backfill(
        self,
        start_date: datetime,
        end_date: datetime,
        sources: List[str] = None,
        dry_run: bool = False,
        resume: bool = False
    ) -> BackfillStats:
        """æ‰§è¡Œå…¨é‡æ•°æ®å›å¡«"""

        # åˆå§‹åŒ–ç»Ÿè®¡
        self.stats = BackfillStats(start_time=datetime.now())
        self.stats.total_days = (end_date - start_date).days + 1

        # ç”Ÿæˆæ—¥æœŸèŒƒå›´
        dates = self.generate_date_range(start_date, end_date)

        # å¤„ç†æ¢å¤é€»è¾‘
        if resume:
            state = self.load_resume_state()
            if state:
                last_processed = state.get("last_processed_date")
                if last_processed:
                    try:
                        last_date_idx = dates.index(last_processed)
                        dates = dates[last_date_idx + 1:]
                        logger.info(f"ğŸ”„ ä» {last_processed} åç»§ç»­ï¼Œå‰©ä½™ {len(dates)} å¤©")
                    except ValueError:
                        logger.warning(f"âš ï¸ æ¢å¤æ—¥æœŸ {last_processed} ä¸åœ¨èŒƒå›´å†…ï¼Œä»å¤´å¼€å§‹")

        # å¹²è¿è¡Œæ¨¡å¼
        if dry_run:
            logger.info("ğŸ” DRY RUNæ¨¡å¼ - æ˜¾ç¤ºé‡‡é›†è®¡åˆ’")
            print(f"\nğŸ“‹ å…¨é‡å›å¡«è®¡åˆ’:")
            print(f"   ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
            print(f"   ğŸ“Š æ€»å¤©æ•°: {len(dates)} å¤©")
            print(f"   ğŸ”— æ•°æ®æº: {sources or ['all']}")
            print(f"   â±ï¸ é¢„è®¡æ—¶é—´: {len(dates) * 2.5 / 60:.1f} å°æ—¶")
            print(f"   ğŸ¯ å»¶è¿Ÿç­–ç•¥: {self.min_delay}-{self.max_delay} ç§’")

            # æ˜¾ç¤ºå‰10å¤©ç¤ºä¾‹
            print(f"\nğŸ“… é‡‡é›†æ—¥æœŸç¤ºä¾‹:")
            for i, date in enumerate(dates[:10]):
                print(f"   [{i+1:3}] {date}")
            if len(dates) > 10:
                print(f"   ... è¿˜æœ‰ {len(dates) - 10} å¤©")

            self.stats.processed_days = len(dates)
            return self.stats

        # å®é™…æ‰§è¡Œæ¨¡å¼
        logger.info(f"ğŸš€ å¼€å§‹å…¨é‡æ•°æ®å›å¡«: {len(dates)} å¤©å¾…å¤„ç†")

        try:
            for i, date_str in enumerate(dates):
                progress = (i + 1) / len(dates) * 100

                logger.info(f"ğŸ“… [{i+1:4}/{len(dates)}] ({progress:5.1f}%) å¤„ç† {date_str}")

                # é‡‡é›†å½“æ—¥æ•°æ®
                result = await self.collect_daily_data(date_str, sources)

                # æ›´æ–°ç»Ÿè®¡
                self.stats.processed_days += 1
                self.stats.total_matches += result.total_matches

                if result.success:
                    self.stats.successful_days += 1
                else:
                    self.stats.failed_days += 1

                # ä¿å­˜æ¢å¤çŠ¶æ€
                self.save_resume_state(date_str, self.stats)

                # æ˜¾ç¤ºè¿›åº¦
                if i % 10 == 0:  # æ¯10å¤©æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
                    await self._print_progress()

                # æ™ºèƒ½å»¶è¿Ÿï¼ˆæœ€åä¸€ä¸ªä¸éœ€è¦å»¶è¿Ÿï¼‰
                if i < len(dates) - 1:
                    # æ ¹æ®æˆåŠŸç‡åŠ¨æ€è°ƒæ•´å»¶è¿Ÿ
                    if self.stats.success_rate < 80:
                        delay = random.uniform(self.max_delay, self.max_delay + 1)
                    else:
                        delay = random.uniform(self.min_delay, self.max_delay)

                    await asyncio.sleep(delay)

            # æœ€ç»ˆç»Ÿè®¡
            await self._print_final_stats()

        except KeyboardInterrupt:
            logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œï¼ŒçŠ¶æ€å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"âŒ å›å¡«æ‰§è¡Œå¼‚å¸¸: {e}")
            raise
        finally:
            # æ¸…ç†èµ„æº
            if self.db_engine:
                await self.db_engine.dispose()

        return self.stats

    async def _print_progress(self):
        """æ‰“å°å½“å‰è¿›åº¦"""
        elapsed = self.stats.elapsed_time

        # è®¡ç®—é¢„è®¡å®Œæˆæ—¶é—´
        if self.stats.processed_days > 0:
            avg_time_per_day = elapsed.total_seconds() / self.stats.processed_days
            remaining_days = self.stats.total_days - self.stats.processed_days
            eta_seconds = avg_time_per_day * remaining_days
            self.stats.estimated_completion = datetime.now() + timedelta(seconds=eta_seconds)

        logger.info("ğŸ“Š å½“å‰è¿›åº¦ç»Ÿè®¡:")
        logger.info(f"   âœ… æˆåŠŸå¤©æ•°: {self.stats.successful_days}/{self.stats.processed_days} ({self.stats.success_rate:.1f}%)")
        logger.info(f"   ğŸ† æ€»æ¯”èµ›æ•°: {self.stats.total_matches}")
        logger.info(f"   â±ï¸ å·²ç”¨æ—¶é—´: {elapsed}")
        if self.stats.estimated_completion:
            logger.info(f"   ğŸ¯ é¢„è®¡å®Œæˆ: {self.stats.estimated_completion.strftime('%H:%M:%S')}")

    async def _print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡"""
        elapsed = self.stats.elapsed_time

        print("\n" + "="*80)
        print("ğŸ‰ å…¨é‡æ•°æ®å›å¡«å®Œæˆç»Ÿè®¡")
        print("="*80)
        print(f"ğŸ“… å¤„ç†å¤©æ•°: {self.stats.successful_days}/{self.stats.total_days}")
        print(f"âœ… æˆåŠŸç‡: {self.stats.success_rate:.1f}%")
        print(f"ğŸ† æ€»æ¯”èµ›æ•°: {self.stats.total_matches}")
        print(f"â±ï¸ æ€»ç”¨æ—¶: {elapsed}")

        if self.stats.processed_days > 0:
            avg_matches_per_day = self.stats.total_matches / self.stats.processed_days
            avg_time_per_day = elapsed.total_seconds() / self.stats.processed_days
            print(f"ğŸ“Š å¹³å‡æ•°æ®: {avg_matches_per_day:.1f} åœºæ¯”èµ›/å¤©")
            print(f"ğŸ“Š å¹³å‡é€Ÿåº¦: {avg_time_per_day:.1f} ç§’/å¤©")

        print("="*80)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å…¨çƒè¶³çƒæ•°æ®å…¨é‡å›å¡«è„šæœ¬")
    parser.add_argument(
        "--start-date",
        default="2022-01-01",
        help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: 2022-01-01)"
    )
    parser.add_argument(
        "--end-date",
        default=datetime.now().strftime("%Y-%m-%d"),
        help="ç»“æŸæ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤: ä»Šå¤©)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="å¹²è¿è¡Œæ¨¡å¼ï¼Œåªæ˜¾ç¤ºè®¡åˆ’ä¸å®é™…é‡‡é›†"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œ"
    )
    parser.add_argument(
        "--source",
        choices=["all", "football-data", "fotmob"],
        default="all",
        help="æ•°æ®æºé€‰æ‹© (é»˜è®¤: all)"
    )

    args = parser.parse_args()

    try:
        # è§£ææ—¥æœŸ
        start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
        end_date = datetime.strptime(args.end_date, "%Y-%m-%d")

        # éªŒè¯æ—¥æœŸèŒƒå›´
        if end_date < start_date:
            logger.error("âŒ ç»“æŸæ—¥æœŸä¸èƒ½æ—©äºå¼€å§‹æ—¥æœŸ")
            return 1

        # ç¡®å®šæ•°æ®æº
        sources = None
        if args.source != "all":
            sources = [args.source]

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        logger.info("ğŸ† å…¨çƒè¶³çƒæ•°æ®å…¨é‡å›å¡«ç³»ç»Ÿ")
        logger.info("="*80)
        logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
        logger.info(f"ğŸ“Š æ€»å¤©æ•°: {(end_date - start_date).days + 1} å¤©")
        logger.info(f"ğŸ”— æ•°æ®æº: {args.source}")
        logger.info(f"ğŸ” å¹²è¿è¡Œ: {'æ˜¯' if args.dry_run else 'å¦'}")
        logger.info(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : {'æ˜¯' if args.resume else 'å¦'}")
        logger.info("="*80)

        # åˆå§‹åŒ–å›å¡«æœåŠ¡
        service = GlobalBackfillService()
        await service.initialize()

        # æ‰§è¡Œå›å¡«
        stats = await service.run_backfill(
            start_date=start_date,
            end_date=end_date,
            sources=sources,
            dry_run=args.dry_run,
            resume=args.resume
        )

        # æ˜¾ç¤ºç»“æœ
        if args.dry_run:
            logger.info(f"ğŸ” DRY RUNå®Œæˆ: è®¡åˆ’å¤„ç† {stats.total_days} å¤©")
        else:
            logger.info(f"ğŸ‰ å›å¡«å®Œæˆ: æˆåŠŸ {stats.successful_days}/{stats.total_days} å¤©")

        return 0

    except KeyboardInterrupt:
        logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return 1
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)