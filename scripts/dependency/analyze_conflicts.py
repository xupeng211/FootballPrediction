#!/usr/bin/env python3
"""
ä¾èµ–å†²çªæ·±åº¦åˆ†æå·¥å…·
æ‰¾å‡ºå†²çªçš„æ ¹æœ¬åŸå› å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
"""

import subprocess
import sys
import json
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass
import networkx as nx


@dataclass
class Package:
    """åŒ…ä¿¡æ¯"""

    name: str
    version: str
    requirements: Dict[str, str]
    required_by: List[str]
    conflicts: List[str]


class DependencyAnalyzer:
    """ä¾èµ–åˆ†æå™¨"""

    def __init__(self):
        self.packages = {}
        self.conflicts = []
        self.dependency_graph = nx.DiGraph()

    def analyze_dependencies(self) -> Dict:
        """æ·±åº¦åˆ†æä¾èµ–å…³ç³»"""
        print("ğŸ” æ·±åº¦åˆ†æä¾èµ–å…³ç³»...")

        # 1. è·å–æ‰€æœ‰å·²å®‰è£…çš„åŒ…
        self._get_installed_packages()

        # 2. åˆ†æå†²çª
        self._analyze_conflicts()

        # 3. æ„å»ºä¾èµ–å›¾
        self._build_dependency_graph()

        # 4. è¯†åˆ«é—®é¢˜åŒ…
        problematic = self._identify_problematic_packages()

        # 5. ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
        solutions = self._generate_solutions(problematic)

        return {
            "total_packages": len(self.packages),
            "conflicts": self.conflicts,
            "problematic_packages": problematic,
            "solutions": solutions,
            "dependency_graph": self._export_graph(),
        }

    def _get_installed_packages(self):
        """è·å–å·²å®‰è£…çš„åŒ…"""
        print("  - è·å–å·²å®‰è£…åŒ…...")

        # è·å–åŒ…åˆ—è¡¨
        result = subprocess.run(
            [sys.executable, "-m", "pip", "list", "--format=json"],
            capture_output=True,
            text=True,
        )

        if result.returncode == 0:
            packages = json.loads(result.stdout)
            for pkg in packages:
                self.packages[pkg["name"].lower()] = {
                    "name": pkg["name"],
                    "version": pkg["version"],
                    "requirements": {},
                    "required_by": [],
                    "conflicts": [],
                }

    def _analyze_conflicts(self):
        """åˆ†æå†²çª"""
        print("  - åˆ†æä¾èµ–å†²çª...")

        # è¿è¡Œpip check
        result = subprocess.run(
            [sys.executable, "-m", "pip", "check"], capture_output=True, text=True
        )

        if result.returncode != 0:
            # è§£æå†²çª
            lines = result.stderr.split("\n")
            for line in lines:
                if "has requirement" in line and "but you have" in line:
                    conflict = self._parse_conflict_line(line)
                    if conflict:
                        self.conflicts.append(conflict)

    def _parse_conflict_line(self, line: str) -> Optional[Dict]:
        """è§£æå†²çªè¡Œ"""
        # ç¤ºä¾‹: "rich-toolkit 0.15.0 has requirement rich>=13.7.1, but you have rich 13.5.2"
        try:
            parts = line.split(" has requirement ")
            if len(parts) != 2:
                return None

            pkg_part = parts[0].split(" ")
            pkg_name = pkg_part[0]
            pkg_version = pkg_part[1]

            req_part = parts[1].split(", but you have ")
            if len(req_part) != 2:
                return None

            requirement = req_part[0]
            have_part = req_part[1].split(" ")
            conflict_pkg = have_part[0]
            conflict_version = have_part[1]

            return {
                "package": pkg_name,
                "version": pkg_version,
                "requires": requirement,
                "conflicts_with": conflict_pkg,
                "current_version": conflict_version,
                "severity": self._calculate_severity(pkg_name, conflict_pkg),
            }
        except Exception:
            return None

    def _calculate_severity(self, pkg1: str, pkg2: str) -> str:
        """è®¡ç®—å†²çªä¸¥é‡ç¨‹åº¦"""
        # æ ¸å¿ƒä¾èµ–
        core_packages = {
            "fastapi",
            "uvicorn",
            "sqlalchemy",
            "alembic",
            "pydantic",
            "pandas",
            "numpy",
            "redis",
        }

        # å¼€å‘å·¥å…·
        dev_tools = {
            "semgrep",
            "rich-toolkit",
            "pipdeptree",
            "pyproject-api",
            "checkov",
            "fastmcp",
            "mypy",
            "black",
            "flake8",
        }

        pkg1_lower = pkg1.lower()
        pkg2_lower = pkg2.lower()

        if pkg1_lower in core_packages or pkg2_lower in core_packages:
            return "critical"
        elif pkg1_lower in dev_tools or pkg2_lower in dev_tools:
            return "low"
        else:
            return "medium"

    def _build_dependency_graph(self):
        """æ„å»ºä¾èµ–å›¾"""
        print("  - æ„å»ºä¾èµ–å›¾...")

        for pkg_name, pkg_info in self.packages.items():
            # æ·»åŠ èŠ‚ç‚¹
            self.dependency_graph.add_node(pkg_name, **pkg_info)

            # æ·»åŠ ä¾èµ–è¾¹
            for req_name, req_version in pkg_info.get("requirements", {}).items():
                self.dependency_graph.add_edge(pkg_name, req_name, requirement=req_version)

    def _identify_problematic_packages(self) -> List[Dict]:
        """è¯†åˆ«é—®é¢˜åŒ…"""
        print("  - è¯†åˆ«é—®é¢˜åŒ…...")

        problematic = []

        for conflict in self.conflicts:
            pkg_name = conflict["conflicts_with"]

            # æ£€æŸ¥æ˜¯å¦åœ¨é—®é¢˜åŒ…åˆ—è¡¨ä¸­
            if not any(p["name"] == pkg_name for p in problematic):
                pkg_info = {
                    "name": pkg_name,
                    "current_version": conflict["current_version"],
                    "conflicts": [],
                    "required_by": [],
                    "category": self._categorize_package(pkg_name),
                    "removable": self._is_removable(pkg_name),
                }
                problematic.append(pkg_info)

            # æ·»åŠ å†²çªä¿¡æ¯
            for p in problematic:
                if p["name"] == pkg_name:
                    p["conflicts"].append(
                        {
                            "from": conflict["package"],
                            "requires": conflict["requires"],
                            "severity": conflict["severity"],
                        }
                    )
                    break

        return problematic

    def _categorize_package(self, pkg_name: str) -> str:
        """åˆ†ç±»åŒ…"""
        pkg_name = pkg_name.lower()

        if pkg_name in {
            "fastapi",
            "uvicorn",
            "sqlalchemy",
            "alembic",
            "pydantic",
            "asyncpg",
            "psycopg2",
        }:
            return "core"
        elif pkg_name in {"pytest", "black", "flake8", "mypy", "semgrep", "pipdeptree"}:
            return "dev_tool"
        elif pkg_name in {"rich", "click", "typer", "colorama"}:
            return "cli_utility"
        elif pkg_name in {"numpy", "pandas", "scikit-learn", "mlflow"}:
            return "ml"
        else:
            return "other"

    def _is_removable(self, pkg_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥ç§»é™¤"""
        category = self._categorize_package(pkg_name)
        return category in {"dev_tool", "cli_utility"}

    def _generate_solutions(self, problematic: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆè§£å†³æ–¹æ¡ˆ"""
        print("  - ç”Ÿæˆè§£å†³æ–¹æ¡ˆ...")

        solutions = []

        # æ–¹æ¡ˆ1: ç§»é™¤å†²çªçš„å¼€å‘å·¥å…·
        dev_tools = [p for p in problematic if p["category"] == "dev_tool" and p["removable"]]
        if dev_tools:
            solutions.append(
                {
                    "name": "remove_dev_tools",
                    "description": "ç§»é™¤å†²çªçš„å¼€å‘å·¥å…·ï¼ˆç”Ÿäº§ç¯å¢ƒä¸éœ€è¦ï¼‰",
                    "packages": [p["name"] for p in dev_tools],
                    "impact": "low",
                    "commands": [f"pip uninstall {' '.join([p['name'] for p in dev_tools])} -y"],
                }
            )

        # æ–¹æ¡ˆ2: ç‰ˆæœ¬é”å®š
        core_conflicts = [p for p in problematic if p["category"] in {"core", "ml"}]
        if core_conflicts:
            solutions.append(
                {
                    "name": "version_lock",
                    "description": "é”å®šæ ¸å¿ƒåŒ…ç‰ˆæœ¬",
                    "packages": [p["name"] for p in core_conflicts],
                    "impact": "medium",
                    "commands": self._generate_version_commands(core_conflicts),
                }
            )

        # æ–¹æ¡ˆ3: åˆ›å»ºç‹¬ç«‹çš„å¼€å‘ç¯å¢ƒ
        solutions.append(
            {
                "name": "separate_envs",
                "description": "åˆ›å»ºç‹¬ç«‹çš„å¼€å‘å’Œç”Ÿäº§ç¯å¢ƒ",
                "packages": [],
                "impact": "high",
                "commands": [
                    "python -m venv venv-dev",
                    "python -m venv venv-prod",
                    "# åˆ†åˆ«æ¿€æ´»å¹¶å®‰è£…ä¸åŒä¾èµ–",
                ],
            }
        )

        return solutions

    def _generate_version_commands(self, packages: List[Dict]) -> List[str]:
        """ç”Ÿæˆç‰ˆæœ¬å‘½ä»¤"""
        commands = []

        # åŸºäºå†²çªç”Ÿæˆå…¼å®¹ç‰ˆæœ¬
        for pkg in packages:
            if pkg["name"] == "numpy":
                # numpyæ˜¯æœ€å¤§å†²çªæº
                commands.append("pip install 'numpy>=1.26.4,<2.0.0'  # å…¼å®¹pandas")
            elif pkg["name"] == "pydantic":
                commands.append("pip install 'pydantic>=2.10.0,<2.12.0'")
            elif pkg["name"] == "rich":
                commands.append("pip install 'rich>=13.5.0,<14.0.0'")
            elif pkg["name"] == "urllib3":
                commands.append("pip install 'urllib3>=1.26.0,<2.1.0'")

        return commands

    def _export_graph(self) -> Dict:
        """å¯¼å‡ºä¾èµ–å›¾"""
        return {
            "nodes": len(self.dependency_graph.nodes()),
            "edges": len(self.dependency_graph.edges()),
            "cycles": list(nx.simple_cycles(self.dependency_graph))[:5],  # å‰5ä¸ªå¾ªç¯
        }


def main():
    """ä¸»å‡½æ•°"""
    analyzer = DependencyAnalyzer()
    analysis = analyzer.analyze_dependencies()

    print("\n" + "=" * 60)
    print("ğŸ“Š ä¾èµ–åˆ†æç»“æœ")
    print(f"æ€»åŒ…æ•°: {analysis['total_packages']}")
    print(f"å†²çªæ•°: {len(analysis['conflicts'])}")
    print(f"é—®é¢˜åŒ…: {len(analysis['problematic_packages'])}")

    print("\nğŸ”¥ ä¸¥é‡å†²çª:")
    critical_conflicts = [c for c in analysis["conflicts"] if c["severity"] == "critical"]
    for conflict in critical_conflicts:
        print(
            f"  - {conflict['package']} éœ€è¦ {conflict['requires']} ä½† {conflict['conflicts_with']} æ˜¯ {conflict['current_version']}"
        )

    print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    for i, sol in enumerate(analysis["solutions"], 1):
        print(f"\næ–¹æ¡ˆ{i}: {sol['name']}")
        print(f"  æè¿°: {sol['description']}")
        print(f"  å½±å“: {sol['impact']}")
        if sol["commands"]:
            print("  å‘½ä»¤:")
            for cmd in sol["commands"]:
                print(f"    {cmd}")

    # ä¿å­˜åˆ†æç»“æœ
    output_file = Path("docs/_reports/DEPENDENCY_ANALYSIS.json")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, "w") as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    main()
