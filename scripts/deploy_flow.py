#!/usr/bin/env python3
"""
Titan007 Prefect Flow éƒ¨ç½²è„šæœ¬
Titan007 Prefect Flow Deployment Script

å°†Titan007æ•°æ®é‡‡é›†å·¥ä½œæµæ³¨å†Œåˆ°Prefect Serverï¼Œæ”¯æŒï¼š
- è‡ªåŠ¨æ£€æµ‹å’Œæ³¨å†Œæ‰€æœ‰Flow
- è°ƒåº¦é…ç½®ç®¡ç†
- éƒ¨ç½²éªŒè¯
- å¥åº·æ£€æŸ¥

ä½¿ç”¨æ–¹æ³•:
    python scripts/deploy_flow.py --register  # æ³¨å†Œæ‰€æœ‰Flow
    python scripts/deploy_flow.py --deploy    # æ³¨å†Œå¹¶å¯åŠ¨è°ƒåº¦
    python scripts/deploy_flow.py --verify    # éªŒè¯éƒ¨ç½²çŠ¶æ€
    python scripts/deploy_flow.py --list      # åˆ—å‡ºå·²æ³¨å†Œçš„Flow
    python scripts/deploy_flow.py --clean     # æ¸…ç†è¿‡æœŸçš„Flow
"""

import asyncio
import sys
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
import argparse
from pathlib import Path

import httpx
from prefect.client.orchestration import get_client

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.flows.titan_flow import (
    titan_regular_flow,
    titan_live_flow,
    titan_hybrid_flow,
    titan_regular_schedule,
    titan_live_schedule,
    titan_weekend_schedule,
    titan_peak_season_schedule,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class PrefectDeploymentManager:
    """Prefectéƒ¨ç½²ç®¡ç†å™¨"""

    def __init__(self):
        self.client = None
        self.deployment_configs = self._get_deployment_configs()

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.client = get_client()
        await self.client.__aenter__()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.client:
            await self.client.__aexit__(exc_type, exc_val, exc_tb)

    def _get_deployment_configs(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰éƒ¨ç½²é…ç½®"""
        return [
            {
                "name": "titan-regular-deployment",
                "flow": titan_regular_flow,
                "schedule": titan_regular_schedule,
                "description": "Titan007å¸¸è§„æ•°æ®é‡‡é›† - æ¯å¤©æ—©ä¸Š8ç‚¹è¿è¡Œ",
                "tags": ["titan", "regular", "daily"],
                "params": {"days_ahead": 1, "batch_size": 20, "max_concurrency": 15},
            },
            {
                "name": "titan-live-deployment",
                "flow": titan_live_flow,
                "schedule": titan_live_schedule,
                "description": "Titan007ä¸´åœºæ•°æ®é‡‡é›† - æ¯10åˆ†é’Ÿè¿è¡Œ",
                "tags": ["titan", "live", "realtime"],
                "params": {"hours_ahead": 2, "batch_size": 10, "max_concurrency": 8},
            },
            {
                "name": "titan-hybrid-deployment",
                "flow": titan_hybrid_flow,
                "schedule": None,  # æ‰‹åŠ¨è§¦å‘
                "description": "Titan007æ··åˆæ•°æ®é‡‡é›† - ç»“åˆå¸¸è§„å’Œä¸´åœºæ¨¡å¼",
                "tags": ["titan", "hybrid", "manual"],
                "params": {
                    "regular_hours_ahead": 1,
                    "live_hours_ahead": 2,
                    "enable_live": True,
                    "cleanup_days": 7,
                },
            },
            {
                "name": "titan-weekend-deployment",
                "flow": titan_regular_flow,
                "schedule": titan_weekend_schedule,
                "description": "Titan007å‘¨æœ«æ•°æ®é‡‡é›† - å‘¨å…­æ—©ä¸Š9ç‚¹è¿è¡Œ",
                "tags": ["titan", "weekend", "saturday"],
                "params": {
                    "days_ahead": 2,  # å‘¨æœ«é‡‡é›†æ›´å¤šå¤©æ•°çš„æ¯”èµ›
                    "batch_size": 25,
                    "max_concurrency": 20,
                },
            },
            {
                "name": "titan-peak-season-deployment",
                "flow": titan_hybrid_flow,
                "schedule": titan_peak_season_schedule,
                "description": "Titan007é«˜å³°æœŸæ•°æ®é‡‡é›† - èµ›å­£å…³é”®æ—¶æœŸå¯†é›†é‡‡é›†",
                "tags": ["titan", "peak", "season"],
                "params": {
                    "regular_hours_ahead": 2,
                    "live_hours_ahead": 3,
                    "enable_live": True,
                    "cleanup_days": 14,
                },
            },
        ]

    async def register_flows(self) -> Dict[str, Any]:
        """æ³¨å†Œæ‰€æœ‰Flowåˆ°Prefect Server"""
        logger.info("ğŸš€ å¼€å§‹æ³¨å†ŒTitan007 Prefect Flows...")

        results = {
            "success_count": 0,
            "error_count": 0,
            "deployments": [],
            "errors": [],
        }

        for config in self.deployment_configs:
            try:
                logger.info(f"ğŸ“¦ æ³¨å†Œéƒ¨ç½²: {config['name']}")

                # åˆ›å»ºDeploymentå¯¹è±¡
                deployment = Deployment.build_from_flow(
                    flow=config["flow"],
                    name=config["name"],
                    schedule=config["schedule"],
                    description=config["description"],
                    tags=config["tags"],
                    parameters=config["params"],
                    version=f"v{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                )

                # æ³¨å†Œéƒ¨ç½²
                deployment_id = await deployment.apply()

                results["success_count"] += 1
                results["deployments"].append(
                    {
                        "name": config["name"],
                        "deployment_id": deployment_id,
                        "flow_name": config["flow"].name,
                        "schedule": config["schedule"] is not None,
                        "description": config["description"],
                    }
                )

                logger.info(f"âœ… æˆåŠŸæ³¨å†Œ: {config['name']} (ID: {deployment_id})")

            except Exception as e:
                results["error_count"] += 1
                error_info = {
                    "name": config["name"],
                    "error": str(e),
                    "error_type": type(e).__name__,
                }
                results["errors"].append(error_info)

                logger.error(f"âŒ æ³¨å†Œå¤±è´¥: {config['name']} - {error_info['error']}")

        logger.info(
            f"ğŸ“Š Flowæ³¨å†Œå®Œæˆ: æˆåŠŸ {results['success_count']}, å¤±è´¥ {results['error_count']}"
        )
        return results

    async def list_deployments(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„éƒ¨ç½²"""
        logger.info("ğŸ“‹ è·å–å·²æ³¨å†Œçš„éƒ¨ç½²åˆ—è¡¨...")

        try:
            deployments = await self.client.read_deployments()

            deployment_list = []
            for deployment in deployments:
                deployment_info = {
                    "id": deployment.id,
                    "name": deployment.name,
                    "flow_id": deployment.flow_id,
                    "schedule": deployment.schedule is not None,
                    "is_active": deployment.is_active,
                    "created": deployment.created,
                    "updated": deployment.updated,
                    "tags": deployment.tags,
                }
                deployment_list.append(deployment_info)

            logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(deployment_list)} ä¸ªéƒ¨ç½²")
            return deployment_list

        except Exception as e:
            logger.error(f"âŒ è·å–éƒ¨ç½²åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []

    async def verify_deployment(self, deployment_name: str) -> Dict[str, Any]:
        """éªŒè¯æŒ‡å®šéƒ¨ç½²çš„å¥åº·çŠ¶æ€"""
        logger.info(f"ğŸ” éªŒè¯éƒ¨ç½²: {deployment_name}")

        try:
            # è·å–éƒ¨ç½²ä¿¡æ¯
            deployments = await self.client.read_deployments()
            target_deployment = None

            for deployment in deployments:
                if deployment.name == deployment_name:
                    target_deployment = deployment
                    break

            if not target_deployment:
                return {
                    "status": "not_found",
                    "message": f"éƒ¨ç½² '{deployment_name}' æœªæ‰¾åˆ°",
                }

            # è·å–Flow Runså†å²
            flow_runs = await self.client.read_flow_runs(
                deployment_id=target_deployment.id, limit=10
            )

            # åˆ†æè¿è¡ŒçŠ¶æ€
            if not flow_runs:
                status_info = {
                    "status": "no_runs",
                    "message": "éƒ¨ç½²å­˜åœ¨ä½†ä»æœªè¿è¡Œ",
                    "recent_runs": [],
                    "success_rate": 0.0,
                }
            else:
                successful_runs = sum(
                    1 for run in flow_runs if run.state.is_completed()
                )
                total_runs = len(flow_runs)
                success_rate = successful_runs / total_runs if total_runs > 0 else 0.0

                recent_runs = []
                for run in flow_runs[:5]:  # æœ€è¿‘5æ¬¡è¿è¡Œ
                    recent_runs.append(
                        {
                            "id": run.id,
                            "state": run.state.name,
                            "start_time": run.start_time,
                            "end_time": run.end_time,
                            "duration_seconds": (
                                run.end_time - run.start_time
                            ).total_seconds()
                            if run.end_time
                            else None,
                        }
                    )

                status_info = {
                    "status": "healthy" if success_rate >= 0.8 else "unhealthy",
                    "message": f"æœ€è¿‘æˆåŠŸç‡: {success_rate:.1%} ({successful_runs}/{total_runs})",
                    "success_rate": success_rate,
                    "recent_runs": recent_runs,
                }

            # æ·»åŠ éƒ¨ç½²åŸºæœ¬ä¿¡æ¯
            status_info.update(
                {
                    "deployment_id": target_deployment.id,
                    "deployment_name": target_deployment.name,
                    "flow_name": target_deployment.flow_name,
                    "is_active": target_deployment.is_active,
                    "schedule": target_deployment.schedule is not None,
                }
            )

            logger.info(f"âœ… éƒ¨ç½²éªŒè¯å®Œæˆ: {deployment_name} - {status_info['status']}")
            return status_info

        except Exception as e:
            logger.error(f"âŒ éªŒè¯éƒ¨ç½²å¤±è´¥: {deployment_name} - {str(e)}")
            return {
                "status": "error",
                "message": f"éªŒè¯å¤±è´¥: {str(e)}",
                "error_type": type(e).__name__,
            }

    async def cleanup_old_deployments(self, days_to_keep: int = 30) -> Dict[str, Any]:
        """æ¸…ç†æ—§çš„éƒ¨ç½²"""
        logger.info(f"ğŸ§¹ æ¸…ç† {days_to_keep} å¤©å‰çš„æ—§éƒ¨ç½²...")

        try:
            cutoff_date = datetime.now().timestamp() - (days_to_keep * 24 * 3600)
            deployments = await self.client.read_deployments()

            old_deployments = []
            for deployment in deployments:
                if deployment.created.timestamp() < cutoff_date:
                    old_deployments.append(deployment)

            cleanup_results = {
                "total_deployments": len(deployments),
                "old_deployments_found": len(old_deployments),
                "deleted_count": 0,
                "failed_count": 0,
                "errors": [],
            }

            for deployment in old_deployments:
                try:
                    await self.client.delete_deployment(deployment.id)
                    cleanup_results["deleted_count"] += 1
                    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§éƒ¨ç½²: {deployment.name}")

                except Exception as e:
                    cleanup_results["failed_count"] += 1
                    error_info = {"deployment_name": deployment.name, "error": str(e)}
                    cleanup_results["errors"].append(error_info)
                    logger.error(f"âŒ åˆ é™¤éƒ¨ç½²å¤±è´¥: {deployment.name} - {str(e)}")

            logger.info(
                f"ğŸ§¹ æ¸…ç†å®Œæˆ: åˆ é™¤ {cleanup_results['deleted_count']}, å¤±è´¥ {cleanup_results['failed_count']}"
            )
            return cleanup_results

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†éƒ¨ç½²å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def trigger_deployment(
        self, deployment_name: str, parameters: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """æ‰‹åŠ¨è§¦å‘éƒ¨ç½²è¿è¡Œ"""
        logger.info(f"ğŸš€ æ‰‹åŠ¨è§¦å‘éƒ¨ç½²: {deployment_name}")

        try:
            # è·å–éƒ¨ç½²ä¿¡æ¯
            deployments = await self.client.read_deployments()
            target_deployment = None

            for deployment in deployments:
                if deployment.name == deployment_name:
                    target_deployment = deployment
                    break

            if not target_deployment:
                return {
                    "status": "not_found",
                    "message": f"éƒ¨ç½² '{deployment_name}' æœªæ‰¾åˆ°",
                }

            # åˆ›å»ºFlow Run
            flow_run = await self.client.create_flow_run_from_deployment(
                deployment.id, parameters=parameters or {}
            )

            result = {
                "status": "triggered",
                "flow_run_id": flow_run.id,
                "flow_run_name": flow_run.name,
                "deployment_name": deployment_name,
                "state": flow_run.state.name,
                "expected_start_time": flow_run.expected_start_time,
            }

            logger.info(f"âœ… æˆåŠŸè§¦å‘: {deployment_name} (Run ID: {flow_run.id})")
            return result

        except Exception as e:
            logger.error(f"âŒ è§¦å‘éƒ¨ç½²å¤±è´¥: {deployment_name} - {str(e)}")
            return {
                "status": "error",
                "message": f"è§¦å‘å¤±è´¥: {str(e)}",
                "error_type": type(e).__name__,
            }


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Titan007 Prefect Flow éƒ¨ç½²ç®¡ç†å·¥å…·")
    parser.add_argument(
        "--register", action="store_true", help="æ³¨å†Œæ‰€æœ‰Flowåˆ°Prefect Server"
    )
    parser.add_argument("--deploy", action="store_true", help="æ³¨å†Œå¹¶å¯åŠ¨è°ƒåº¦")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºå·²æ³¨å†Œçš„éƒ¨ç½²")
    parser.add_argument("--verify", type=str, help="éªŒè¯æŒ‡å®šéƒ¨ç½²çš„å¥åº·çŠ¶æ€")
    parser.add_argument("--trigger", type=str, help="æ‰‹åŠ¨è§¦å‘æŒ‡å®šéƒ¨ç½²")
    parser.add_argument(
        "--clean", type=int, metavar="DAYS", help="æ¸…ç†æŒ‡å®šå¤©æ•°å‰çš„æ—§éƒ¨ç½²"
    )
    parser.add_argument(
        "--health", action="store_true", help="æ£€æŸ¥Prefect Serverå¥åº·çŠ¶æ€"
    )

    args = parser.parse_args()

    if not any(vars(args).values()):
        parser.print_help()
        return

    # å¥åº·æ£€æŸ¥
    if args.health:
        logger.info("ğŸ¥ æ£€æŸ¥Prefect Serverå¥åº·çŠ¶æ€...")
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get("http://localhost:4200/api/health")
                if response.status_code == 200:
                    logger.info("âœ… Prefect Serverå¥åº·çŠ¶æ€è‰¯å¥½")
                    print("Prefect UI: http://localhost:4200")
                else:
                    logger.error(f"âŒ Prefect ServerçŠ¶æ€å¼‚å¸¸: {response.status_code}")
        except Exception as e:
            logger.error(f"âŒ æ— æ³•è¿æ¥åˆ°Prefect Server: {str(e)}")
        return

    # å…¶ä»–æ“ä½œéœ€è¦éƒ¨ç½²ç®¡ç†å™¨
    async with PrefectDeploymentManager() as manager:
        if args.register or args.deploy:
            results = await manager.register_flows()

            # æ‰“å°è¯¦ç»†ç»“æœ
            print("\n" + "=" * 60)
            print("ğŸ“Š FLOWæ³¨å†Œç»“æœ")
            print("=" * 60)
            print(f"âœ… æˆåŠŸæ³¨å†Œ: {results['success_count']}")
            print(f"âŒ æ³¨å†Œå¤±è´¥: {results['error_count']}")

            if results["deployments"]:
                print("\nğŸ“‹ å·²æ³¨å†Œçš„éƒ¨ç½²:")
                for dep in results["deployments"]:
                    status = "ğŸŸ¢ è°ƒåº¦å·²å¯ç”¨" if dep["schedule"] else "ğŸ”µ æ‰‹åŠ¨è§¦å‘"
                    print(f"  â€¢ {dep['name']}: {dep['description']} {status}")

            if results["errors"]:
                print("\nâŒ æ³¨å†Œé”™è¯¯:")
                for error in results["errors"]:
                    print(f"  â€¢ {error['name']}: {error['error']}")

            print("\nğŸ“ˆ Prefect UI: http://localhost:4200")
            print("ğŸ“‹ Flowç›‘æ§: http://localhost:4200/flows")

        if args.list:
            deployments = await manager.list_deployments()

            print("\n" + "=" * 60)
            print("ğŸ“‹ å·²æ³¨å†Œçš„éƒ¨ç½²åˆ—è¡¨")
            print("=" * 60)

            if not deployments:
                print("ğŸ“­ æš‚æ— å·²æ³¨å†Œçš„éƒ¨ç½²")
            else:
                for dep in deployments:
                    schedule_status = "ğŸŸ¢ å·²è°ƒåº¦" if dep["schedule"] else "ğŸ”µ æ‰‹åŠ¨"
                    active_status = "âœ… æ´»è·ƒ" if dep["is_active"] else "âŒ éæ´»è·ƒ"

                    print(f"\nğŸ“¦ {dep['name']}")
                    print(f"   ID: {dep['id']}")
                    print(f"   çŠ¶æ€: {active_status} | {schedule_status}")
                    print(f"   åˆ›å»ºæ—¶é—´: {dep['created']}")
                    if dep["tags"]:
                        print(f"   æ ‡ç­¾: {', '.join(dep['tags'])}")

        if args.verify:
            verification = await manager.verify_deployment(args.verify)

            print("\n" + "=" * 60)
            print(f"ğŸ” éƒ¨ç½²éªŒè¯: {args.verify}")
            print("=" * 60)

            status_icon = (
                "âœ…" if verification["status"] in ["healthy", "no_runs"] else "âŒ"
            )
            print(f"{status_icon} çŠ¶æ€: {verification['status']}")
            print(f"ğŸ“ æ¶ˆæ¯: {verification['message']}")

            if "deployment_id" in verification:
                print("\nğŸ“¦ éƒ¨ç½²ä¿¡æ¯:")
                print(f"   ID: {verification['deployment_id']}")
                print(f"   Flow: {verification['flow_name']}")
                print(f"   æ´»è·ƒ: {'æ˜¯' if verification['is_active'] else 'å¦'}")
                print(f"   è°ƒåº¦: {'æ˜¯' if verification['schedule'] else 'å¦'}")

            if "recent_runs" in verification and verification["recent_runs"]:
                print("\nğŸ“Š æœ€è¿‘è¿è¡Œè®°å½•:")
                for run in verification["recent_runs"]:
                    duration = (
                        f"{run['duration_seconds']:.1f}s"
                        if run["duration_seconds"]
                        else "è¿è¡Œä¸­"
                    )
                    print(f"   â€¢ {run['state']}: {duration}")

            if "success_rate" in verification:
                rate = verification["success_rate"] * 100
                print(f"\nğŸ“ˆ æˆåŠŸç‡: {rate:.1f}%")

        if args.trigger:
            result = await manager.trigger_deployment(args.trigger)

            print("\n" + "=" * 60)
            print(f"ğŸš€ è§¦å‘éƒ¨ç½²: {args.trigger}")
            print("=" * 60)

            if result["status"] == "triggered":
                print("âœ… è§¦å‘æˆåŠŸ!")
                print(f"ğŸƒ è¿è¡ŒID: {result['flow_run_id']}")
                print(f"ğŸ“Š çŠ¶æ€: {result['state']}")
                print(
                    f"\nğŸ“ˆ ç›‘æ§åœ°å€: http://localhost:4200/flow-run/{result['flow_run_id']}"
                )
            else:
                print(f"âŒ è§¦å‘å¤±è´¥: {result['message']}")

        if args.clean:
            results = await manager.cleanup_old_deployments(args.clean)

            print("\n" + "=" * 60)
            print(f"ğŸ§¹ æ¸…ç† {args.clean} å¤©å‰çš„éƒ¨ç½²")
            print("=" * 60)

            if "total_deployments" in results:
                print(f"ğŸ“Š æ€»éƒ¨ç½²æ•°: {results['total_deployments']}")
                print(f"ğŸ” æ‰¾åˆ°æ—§éƒ¨ç½²: {results['old_deployments_found']}")
                print(f"âœ… æˆåŠŸåˆ é™¤: {results['deleted_count']}")
                print(f"âŒ åˆ é™¤å¤±è´¥: {results['failed_count']}")

            if results.get("errors"):
                print("\nâŒ åˆ é™¤é”™è¯¯:")
                for error in results["errors"]:
                    print(f"  â€¢ {error['deployment_name']}: {error['error']}")


if __name__ == "__main__":
    # æ£€æŸ¥Prefect Serveræ˜¯å¦è¿è¡Œ
    try:
        import asyncio

        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ éƒ¨ç½²æ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        logger.error(f"âŒ éƒ¨ç½²è„šæœ¬æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)
