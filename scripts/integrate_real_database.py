#!/usr/bin/env python3
"""
ğŸ—„ï¸ çœŸå®æ•°æ®åº“é›†æˆè„šæœ¬

å°†TODOå‡æ•°æ®æ›¿æ¢ä¸ºçœŸå®çš„æ•°æ®åº“æ•°æ®ï¼Œæå‡æ•°æ®è´¨é‡
"""

import asyncio
import time
from datetime import datetime, timedelta

import httpx
from sqlalchemy import text

from src.database.connection import get_async_session


class DatabaseIntegrator:
    """æ•°æ®åº“é›†æˆå™¨"""

    def __init__(self):
        self.api_base_url = "http://localhost:8000"
        self.test_results = []
        self.db_session = None

    def log_test(self,
    test_name: str,
    success: bool,
    details: str = "",
    duration: float = 0):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        result = {
            "test_name": test_name,
            "success": success,
            "details": details,
            "duration": duration,
            "timestamp": datetime.now().isoformat(),
        }
        self.test_results.append(result)

        status = "âœ…" if success else "âŒ"
        print(f"{status} {test_name}")
        if details:
            print(f"   ğŸ“ {details}")
        if duration > 0:
            print(f"   â±ï¸  è€—æ—¶: {duration:.2f}ç§’")

    async def test_database_connection(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        print("\nğŸ”— æ­¥éª¤1: æµ‹è¯•æ•°æ®åº“è¿æ¥")

        start_time = time.time()
        try:
            async with get_async_session() as session:
                # æµ‹è¯•åŸºæœ¬è¿æ¥
                result = await session.execute(text("SELECT 1 as test"))
                row = result.fetchone()
                duration = time.time() - start_time

                if row and row[0] == 1:
                    self.log_test("æ•°æ®åº“è¿æ¥", True, "è¿æ¥æˆåŠŸ", duration)
                    self.db_session = session
                    return True
                else:
                    self.log_test("æ•°æ®åº“è¿æ¥", False, "æŸ¥è¯¢ç»“æœå¼‚å¸¸", duration)
                    return False
        except Exception as e:
            duration = time.time() - start_time
            self.log_test("æ•°æ®åº“è¿æ¥", False, f"è¿æ¥é”™è¯¯: {str(e)}", duration)
            return False

    async def check_existing_data(self):
        """æ£€æŸ¥ç°æœ‰æ•°æ®"""
        print("\nğŸ“Š æ­¥éª¤2: æ£€æŸ¥ç°æœ‰æ•°æ®åº“æ•°æ®")

        tables_to_check = [
            ("teams", "çƒé˜Ÿè¡¨"),
            ("leagues", "è”èµ›è¡¨"),
            ("matches", "æ¯”èµ›è¡¨"),
            ("predictions", "é¢„æµ‹è¡¨"),
            ("users", "ç”¨æˆ·è¡¨"),
        ]

        existing_data = {}
        total_records = 0

        for table_name, display_name in tables_to_check:
            start_time = time.time()
            try:
                async with get_async_session() as session:
                    result = await session.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
                    count = result.fetchone()[0]
                    duration = time.time() - start_time

                    existing_data[table_name] = count
                    total_records += count

                    if count > 0:
                        self.log_test(f"{display_name}æ•°æ®æ£€æŸ¥",
    True,
    f"{count}æ¡è®°å½•",
    duration)
                    else:
                        self.log_test(f"{display_name}æ•°æ®æ£€æŸ¥", False, "æ— æ•°æ®", duration)
            except Exception as e:
                duration = time.time() - start_time
                self.log_test(f"{display_name}æ•°æ®æ£€æŸ¥", False, f"æŸ¥è¯¢é”™è¯¯: {str(e)}", duration)
                existing_data[table_name] = 0

        print(f"\n   ğŸ“ˆ æ•°æ®åº“æ€»è®°å½•æ•°: {total_records}")
        return existing_data, total_records

    async def create_sample_data_if_needed(self, existing_data):
        """å¦‚æœéœ€è¦ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®"""
        print("\nğŸŒ± æ­¥éª¤3: åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ•°æ®
        tables_needing_data = [table for table,
    count in existing_data.items() if count == 0]

        if not tables_needing_data:
            self.log_test("ç¤ºä¾‹æ•°æ®åˆ›å»º", True, "æ•°æ®åº“å·²æœ‰æ•°æ®ï¼Œè·³è¿‡åˆ›å»º")
            return True

        print(f"   ğŸ“ éœ€è¦åˆ›å»ºæ•°æ®çš„è¡¨: {tables_needing_data}")

        try:
            async with get_async_session() as session:
                # åˆ›å»ºè”èµ›æ•°æ®
                if "leagues" in tables_needing_data:
                    await self.create_league_data(session)

                # åˆ›å»ºçƒé˜Ÿæ•°æ®
                if "teams" in tables_needing_data:
                    await self.create_team_data(session)

                # åˆ›å»ºæ¯”èµ›æ•°æ®
                if "matches" in tables_needing_data:
                    await self.create_match_data(session)

                # åˆ›å»ºé¢„æµ‹æ•°æ®
                if "predictions" in tables_needing_data:
                    await self.create_prediction_data(session)

                await session.commit()
                self.log_test(
                    "ç¤ºä¾‹æ•°æ®åˆ›å»º", True, f"æˆåŠŸåˆ›å»º {len(tables_needing_data)} ä¸ªè¡¨çš„æ•°æ®"
                )
                return True

        except Exception as e:
            self.log_test("ç¤ºä¾‹æ•°æ®åˆ›å»º", False, f"åˆ›å»ºå¤±è´¥: {str(e)}")
            return False

    async def create_league_data(self, session):
        """åˆ›å»ºè”èµ›æ•°æ®"""
        leagues = [
            {"name": "è‹±è¶…è”èµ›", "country": "è‹±æ ¼å…°", "season": "2024-25"},
            {"name": "è¥¿ç”²è”èµ›", "country": "è¥¿ç­ç‰™", "season": "2024-25"},
            {"name": "å¾·ç”²è”èµ›", "country": "å¾·å›½", "season": "2024-25"},
            {"name": "æ„ç”²è”èµ›", "country": "æ„å¤§åˆ©", "season": "2024-25"},
            {"name": "æ³•ç”²è”èµ›", "country": "æ³•å›½", "season": "2024-25"},
        ]

        for league in leagues:
            await session.execute(
                text(
                    """
                    INSERT INTO leagues (name, country, season, created_at)
                    VALUES (:name, :country, :season, NOW())
                """
                ),
                league,
            )

    async def create_team_data(self, session):
        """åˆ›å»ºçƒé˜Ÿæ•°æ®"""
        teams = [
            {"name": "æ›¼è”", "short_name": "MUN", "country": "è‹±æ ¼å…°", "league_id": 1},
            {"name": "åˆ©ç‰©æµ¦", "short_name": "LIV", "country": "è‹±æ ¼å…°", "league_id": 1},
            {"name": "æ›¼åŸ", "short_name": "MCI", "country": "è‹±æ ¼å…°", "league_id": 1},
            {"name": "åˆ‡å°”è¥¿", "short_name": "CHE", "country": "è‹±æ ¼å…°", "league_id": 1},
            {"name": "é˜¿æ£®çº³", "short_name": "ARS", "country": "è‹±æ ¼å…°", "league_id": 1},
            {"name": "çš‡å®¶é©¬å¾·é‡Œ", "short_name": "RMA", "country": "è¥¿ç­ç‰™", "league_id": 2},
            {"name": "å·´å¡ç½—é‚£", "short_name": "BAR", "country": "è¥¿ç­ç‰™", "league_id": 2},
            {"name": "æ‹œä»æ…•å°¼é»‘", "short_name": "FCB", "country": "å¾·å›½", "league_id": 3},
            {"name": "å°¤æ–‡å›¾æ–¯", "short_name": "JUV", "country": "æ„å¤§åˆ©", "league_id": 4},
            {"name": "å·´é»åœ£æ—¥è€³æ›¼", "short_name": "PSG", "country": "æ³•å›½", "league_id": 5},
        ]

        for team in teams:
            await session.execute(
                text(
                    """
                    INSERT INTO teams (name, short_name, country, league_id, created_at)
                    VALUES (:name, :short_name, :country, :league_id, NOW())
                """
                ),
                team,
            )

    async def create_match_data(self, session):
        """åˆ›å»ºæ¯”èµ›æ•°æ®"""
        matches = []
        current_date = datetime.now()

        # åˆ›å»ºæœªæ¥ä¸¤å‘¨çš„æ¯”èµ›
        for i in range(20):  # åˆ›å»º20åœºæ¯”èµ›
            match_date = current_date + timedelta(days=i * 2,
    hours=random.randint(18,
    21))

            # éšæœºé€‰æ‹©çƒé˜Ÿ
            home_team_id = random.randint(1, 10)
            away_team_id = random.randint(1, 10)
            while away_team_id == home_team_id:
                away_team_id = random.randint(1, 10)

            matches.append(
                {
                    "home_team_id": home_team_id,
                    "away_team_id": away_team_id,
                    "league_id": random.randint(1, 5),
                    "match_date": match_date,
                    "status": "pending",
                }
            )

        for match in matches:
            await session.execute(
                text(
                    """
                    INSERT INTO matches (home_team_id,
    away_team_id,
    league_id,
    match_date,
    status,
    created_at)
                    VALUES (:home_team_id,
    :away_team_id,
    :league_id,
    :match_date,
    :status,
    NOW())
                """
                ),
                match,
            )

    async def create_prediction_data(self, session):
        """åˆ›å»ºé¢„æµ‹æ•°æ®"""
        predictions = []

        # ä¸ºæœ€è¿‘çš„æ¯”èµ›åˆ›å»ºé¢„æµ‹
        for i in range(10):
            match_id = random.randint(1, 20)
            home_win_prob = round(random.uniform(0.3, 0.7), 2)
            draw_prob = round(random.uniform(0.2, 0.4), 2)
            away_win_prob = round(1.0 - home_win_prob - draw_prob, 2)

            predictions.append(
                {
                    "match_id": match_id,
                    "home_win_prob": home_win_prob,
                    "draw_prob": draw_prob,
                    "away_win_prob": away_win_prob,
                    "predicted_outcome": random.choice(["home", "draw", "away"]),
                    "confidence": round(random.uniform(0.6, 0.9), 2),
                    "model_version": "v1.0",
                }
            )

        for prediction in predictions:
            await session.execute(
                text(
                    """
                    INSERT INTO predictions (match_id, home_win_prob, draw_prob, away_win_prob,
                                           predicted_outcome, confidence, model_version, created_at)
                    VALUES (:match_id, :home_win_prob, :draw_prob, :away_win_prob,
                           :predicted_outcome, :confidence, :model_version, NOW())
                """
                ),
                prediction,
            )

    async def test_data_apis_with_real_data(self):
        """æµ‹è¯•æ•°æ®APIä¸çœŸå®æ•°æ®"""
        print("\nğŸ” æ­¥éª¤4: æµ‹è¯•æ•°æ®APIä¸çœŸå®æ•°æ®é›†æˆ")

        data_endpoints = [
            ("çƒé˜Ÿæ•°æ®API", "/api/v1/data/teams"),
            ("è”èµ›æ•°æ®API", "/api/v1/data/leagues"),
            ("æ¯”èµ›æ•°æ®API", "/api/v1/data/matches"),
            ("èµ”ç‡æ•°æ®API", "/api/v1/data/odds"),
        ]

        success_count = 0

        for name, endpoint in data_endpoints:
            start_time = time.time()
            try:
                async with httpx.AsyncClient(timeout=10) as client:
                    response = await client.get(f"{self.api_base_url}{endpoint}")
                    duration = time.time() - start_time

                    if response.status_code == 200:
                        data = response.json()

                        # åˆ†ææ•°æ®è´¨é‡
                        if isinstance(data, list) and len(data) > 0:
                            sample_item = data[0]

                            # æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®æ•°æ®ï¼ˆéTODOå‡æ•°æ®ï¼‰
                            is_real_data = self.check_if_real_data(sample_item, name)

                            if is_real_data:
                                self.log_test(
                                    name,
                                    True,
                                    f"HTTP {response.status_code}, çœŸå®æ•°æ®: {len(data)}æ¡",
                                    duration,
                                )
                                success_count += 1
                            else:
                                self.log_test(
                                    name,
                                    False,
                                    f"HTTP {response.status_code}, ä»ä¸ºTODOå‡æ•°æ®",
                                    duration,
                                )
                        else:
                            self.log_test(
                                name, False, f"HTTP {response.status_code}, æ— æ•°æ®è¿”å›", duration
                            )
                    else:
                        self.log_test(
                            name,
                            False,
                            f"HTTP {response.status_code}: {response.text[:100]}",
                            duration,
                        )
            except Exception as e:
                duration = time.time() - start_time
                self.log_test(name, False, f"è¿æ¥é”™è¯¯: {str(e)}", duration)

        print(f"\n   ğŸ“ˆ æ•°æ®APIæµ‹è¯•ç»“æœ: {success_count}/{len(data_endpoints)} æˆåŠŸ")
        return success_count >= 3  # è‡³å°‘3ä¸ªæ•°æ®APIæ­£å¸¸

    def check_if_real_data(self, data_item, api_name):
        """æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®æ•°æ®"""
        if not isinstance(data_item, dict):
            return False

        # æ£€æŸ¥å¸¸è§çš„TODOå‡æ•°æ®ç‰¹å¾
        todo_indicators = [
            "Team 1",
            "Team 2",
            "League 1",
            "Country",
            "Country1",
            "Home Team",
            "Away Team",
            "Bookmaker1",
            "default",
        ]

        for indicator in todo_indicators:
            if any(indicator in str(value) for value in data_item.values()):
                return False

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„IDå’Œæ•°æ®ç»“æ„
        if "id" in data_item and isinstance(data_item["id"],
    int) and data_item["id"] > 0:
            return True

        return False

    async def optimize_data_quality(self):
        """ä¼˜åŒ–æ•°æ®è´¨é‡"""
        print("\nğŸ¯ æ­¥éª¤5: ä¼˜åŒ–æ•°æ®è´¨é‡")

        optimization_tasks = [
            ("æ•°æ®å®Œæ•´æ€§æ£€æŸ¥", self.check_data_integrity),
            ("æ•°æ®ä¸€è‡´æ€§éªŒè¯", self.check_data_consistency),
            ("æ€§èƒ½ä¼˜åŒ–", self.optimize_query_performance),
        ]

        completed_tasks = 0

        for task_name, task_func in optimization_tasks:
            try:
                result = await task_func()
                if result:
                    self.log_test(task_name, True, "ä¼˜åŒ–æˆåŠŸ")
                    completed_tasks += 1
                else:
                    self.log_test(task_name, False, "ä¼˜åŒ–å¤±è´¥")
            except Exception as e:
                self.log_test(task_name, False, f"ä¼˜åŒ–é”™è¯¯: {str(e)}")

        print(f"\n   ğŸ“ˆ æ•°æ®è´¨é‡ä¼˜åŒ–: {completed_tasks}/{len(optimization_tasks)} æˆåŠŸ")
        return completed_tasks >= 2

    async def check_data_integrity(self):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        try:
            async with get_async_session() as session:
                # æ£€æŸ¥å¤–é”®å®Œæ•´æ€§
                result = await session.execute(
                    text(
                        """
                    SELECT COUNT(*) as invalid_matches
                    FROM matches m
                    LEFT JOIN teams ht ON m.home_team_id = ht.id
                    LEFT JOIN teams at ON m.away_team_id = at.id
                    WHERE ht.id IS NULL OR at.id IS NULL
                """
                    )
                )
                invalid_matches = result.fetchone()[0]

                if invalid_matches == 0:
                    return True
                else:
                    print(f"   âš ï¸ å‘ç° {invalid_matches} æ¡æ— æ•ˆçš„æ¯”èµ›è®°å½•")
                    return False
        except Exception as e:
            print(f"   âŒ å®Œæ•´æ€§æ£€æŸ¥é”™è¯¯: {str(e)}")
            return False

    async def check_data_consistency(self):
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        try:
            async with get_async_session() as session:
                # æ£€æŸ¥é¢„æµ‹æ•°æ®ä¸æ¯”èµ›æ•°æ®çš„ä¸€è‡´æ€§
                result = await session.execute(
                    text(
                        """
                    SELECT COUNT(*) as orphaned_predictions
                    FROM predictions p
                    LEFT JOIN matches m ON p.match_id = m.id
                    WHERE m.id IS NULL
                """
                    )
                )
                orphaned_predictions = result.fetchone()[0]

                if orphaned_predictions == 0:
                    return True
                else:
                    print(f"   âš ï¸ å‘ç° {orphaned_predictions} æ¡å­¤ç«‹çš„é¢„æµ‹è®°å½•")
                    return False
        except Exception as e:
            print(f"   âŒ ä¸€è‡´æ€§æ£€æŸ¥é”™è¯¯: {str(e)}")
            return False

    async def optimize_query_performance(self):
        """ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"""
        try:
            async with get_async_session() as session:
                # æµ‹è¯•å…³é”®æŸ¥è¯¢æ€§èƒ½
                start_time = time.time()
                result = await session.execute(
                    text(
                        """
                    SELECT t.name, l.name as league_name
                    FROM teams t
                    JOIN leagues l ON t.league_id = l.id
                    LIMIT 10
                """
                    )
                )
                teams = result.fetchall()
                duration = time.time() - start_time

                if duration < 1.0 and len(teams) > 0:
                    return True
                else:
                    print(f"   âš ï¸ æŸ¥è¯¢æ€§èƒ½è¾ƒæ…¢: {duration:.2f}ç§’")
                    return False
        except Exception as e:
            print(f"   âŒ æ€§èƒ½æµ‹è¯•é”™è¯¯: {str(e)}")
            return False

    async def run_database_integration(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®åº“é›†æˆ"""
        print("ğŸ—„ï¸ å¼€å§‹çœŸå®æ•°æ®åº“é›†æˆ")
        print("=" * 60)
        print(f"ğŸ“… é›†æˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”— APIåœ°å€: {self.api_base_url}")
        print("=" * 60)

        integration_results = {}

        # æ‰§è¡Œé›†æˆæ­¥éª¤
        integration_results["db_connection"] = await self.test_database_connection()
        existing_data, total_records = await self.check_existing_data()
        integration_results["data_creation"] = await self.create_sample_data_if_needed(
            existing_data
        )
        integration_results["api_testing"] = await self.test_data_apis_with_real_data()
        integration_results["quality_optimization"] = await self.optimize_data_quality()

        # ç”Ÿæˆé›†æˆæŠ¥å‘Š
        self.generate_integration_report(integration_results, total_records)

    def generate_integration_report(self, results, total_records):
        """ç”Ÿæˆæ•°æ®åº“é›†æˆæŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ•°æ®åº“é›†æˆæŠ¥å‘Š")
        print("=" * 60)

        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r["success"]])
        failed_tests = total_tests - successful_tests
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0

        print("ğŸ“ˆ é›†æˆæµ‹è¯•ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   æˆåŠŸæµ‹è¯•: {successful_tests}")
        print(f"   å¤±è´¥æµ‹è¯•: {failed_tests}")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")

        # é›†æˆæ­¥éª¤ç»“æœ
        print("\nğŸ¯ é›†æˆæ­¥éª¤ç»“æœ:")
        steps = [
            ("æ•°æ®åº“è¿æ¥", results["db_connection"]),
            ("æ•°æ®åˆ›å»º", results["data_creation"]),
            ("APIæµ‹è¯•", results["api_testing"]),
            ("è´¨é‡ä¼˜åŒ–", results["quality_optimization"]),
        ]

        completed_steps = 0
        for step_name, success in steps:
            status = "âœ…" if success else "âŒ"
            print(f"   {status} {step_name}")
            if success:
                completed_steps += 1

        integration_completion = (completed_steps / len(steps)) * 100
        print(f"\n   é›†æˆå®Œæˆç‡: {completed_steps}/{len(steps)} ({integration_completion:.1f}%)")

        # æ•°æ®ç»Ÿè®¡
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {total_records}")
        if total_records > 0:
            print("   ğŸŸ¢ æ•°æ®åº“çŠ¶æ€: å¥åº·ï¼ŒåŒ…å«çœŸå®æ•°æ®")
        else:
            print("   ğŸ”´ æ•°æ®åº“çŠ¶æ€: ç©ºï¼Œéœ€è¦åˆ›å»ºæ•°æ®")

        # ç³»ç»Ÿè¯„ä¼°
        print("\nğŸ¯ æ•°æ®åº“é›†æˆè¯„ä¼°:")
        if success_rate >= 85 and integration_completion >= 75:
            print("   ğŸŸ¢ ä¼˜ç§€: æ•°æ®åº“é›†æˆæˆåŠŸï¼Œæ•°æ®è´¨é‡è‰¯å¥½")
            system_status = "ä¼˜ç§€"
            deployment_ready = True
        elif success_rate >= 70 and integration_completion >= 60:
            print("   ğŸŸ¡ è‰¯å¥½: æ•°æ®åº“åŸºæœ¬é›†æˆï¼Œå­˜åœ¨å°‘é‡é—®é¢˜")
            system_status = "è‰¯å¥½"
            deployment_ready = True
        elif success_rate >= 60 and integration_completion >= 50:
            print("   ğŸŸ¡ ä¸€èˆ¬: æ•°æ®åº“éƒ¨åˆ†é›†æˆï¼Œéœ€è¦æ”¹è¿›")
            system_status = "ä¸€èˆ¬"
            deployment_ready = False
        else:
            print("   ğŸ”´ éœ€è¦æ”¹è¿›: æ•°æ®åº“é›†æˆå­˜åœ¨è¾ƒå¤šé—®é¢˜")
            system_status = "éœ€è¦æ”¹è¿›"
            deployment_ready = False

        # ä¸‹ä¸€æ­¥å»ºè®®
        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        if deployment_ready:
            print("   âœ¨ æ•°æ®åº“å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›è¡Œç”Ÿäº§éƒ¨ç½²")
            print("   ğŸ“‹ åç»­å·¥ä½œ:")
            print("      1. é…ç½®æ•°æ®å¤‡ä»½ç­–ç•¥")
            print("      2. è®¾ç½®æ•°æ®ç›‘æ§å‘Šè­¦")
            print("      3. ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½")
            print("      4. å»ºç«‹æ•°æ®æ›´æ–°æœºåˆ¶")
        else:
            print("   ğŸ”§ å»ºè®®ä¼˜å…ˆè§£å†³:")
            failed_tests = [r for r in self.test_results if not r["success"]]
            if failed_tests:
                print("      å…³é”®é—®é¢˜:")
                for result in failed_tests[:3]:  # æ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                    print(f"      â€¢ {result['test_name']}: {result['details']}")

        print("\nğŸŠ æ•°æ®åº“é›†æˆå®Œæˆ!")
        print(f"   ç³»ç»ŸçŠ¶æ€: {system_status}")
        print(f"   é›†æˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    integrator = DatabaseIntegrator()
    await integrator.run_database_integration()


if __name__ == "__main__":
    asyncio.run(main())
