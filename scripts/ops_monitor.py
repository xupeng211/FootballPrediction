#!/usr/bin/env python3
"""
FBrefæ•°æ®å·¥å‚è¿ç»´ç›‘æ§è„šæœ¬
SRE + DBA è”åˆå·¡æ£€å·¥å…·

SRE/DBA: ç”Ÿäº§ç³»ç»Ÿå¥åº·ç›‘æ§ä¸“å®¶
Purpose: å…¨æ–¹ä½ç›‘æ§æ•°æ®ç®¡é“å¥åº·çŠ¶æ€å’Œæ•°æ®è´¨é‡
"""

import asyncio
import logging
import sys
import os
import time
import json
import subprocess
import psutil
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# å¯¼å…¥æ•°æ®åº“è¿æ¥
try:
    from src.database.connection import get_async_session
    from src.database.models.match import Match
    from sqlalchemy import text, select, func
    from sqlalchemy.ext.asyncio import AsyncSession

    DB_AVAILABLE = True
except ImportError as e:
    logging.warning(f"æ•°æ®åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    DB_AVAILABLE = False

logging.basicConfig(
    level=logging.INFO
    format="%(asctime)s [%(levelname)8s] %(name)s: %(message)s"
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


class OpsMonitor:
    """
    è¿ç»´ç›‘æ§ä»ªè¡¨ç›˜

    ç›‘æ§ç»´åº¦ï¼š
    1. è¿›ç¨‹å¥åº·æ£€æŸ¥
    2. æ—¥å¿—åˆ†æç»Ÿè®¡
    3. æ•°æ®åº“è´¨é‡éªŒè¯
    4. ç³»ç»Ÿèµ„æºçŠ¶æ€
    5. æ•°æ®é‡‡é›†è¿›åº¦
    """

    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.log_file = self.project_root / "logs" / "fbref_final_backfill.log"
        self.process_name = "final_fbref_backfill.py"
        self.check_time = datetime.now()

    def find_process(self) -> Optional[dict]:
        """æŸ¥æ‰¾ç›®æ ‡è¿›ç¨‹ä¿¡æ¯"""
        logger.info(f"ğŸ” æŸ¥æ‰¾è¿›ç¨‹: {self.process_name}")

        try:
            # æ–¹æ³•1: é€šè¿‡psutilæŸ¥æ‰¾
            for proc in psutil.process_iter(
                [
                    "pid"
                    "name"
                    "cmdline"
                    "cpu_percent"
                    "memory_percent"
                    "create_time"
                ]
            ):
                try:
                    cmdline = " ".join(proc.info["cmdline"] or [])
                    if self.process_name in cmdline:
                        return {
                            "pid": proc.info["pid"]
                            "name": proc.info["name"]
                            "cmdline": cmdline
                            "cpu_percent": proc.info["cpu_percent"]
                            "memory_percent": proc.info["memory_percent"]
                            "memory_mb": proc.memory_info().rss / 1024 / 1024
                            "create_time": datetime.fromtimestamp(
                                proc.info["create_time"]
                            )
                            "status": proc.status()
                            "running_time": datetime.now()
                            - datetime.fromtimestamp(proc.info["create_time"])
                        }
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            # æ–¹æ³•2: é€šè¿‡pgrepæŸ¥æ‰¾
            try:
                result = subprocess.run(
                    ["pgrep", "-f", self.process_name], capture_output=True, text=True
                )
                if result.stdout.strip():
                    pids = [int(pid) for pid in result.stdout.strip().split("\n")]
                    for pid in pids:
                        try:
                            proc = psutil.Process(pid)
                            cmdline = " ".join(proc.cmdline() or [])
                            if self.process_name in cmdline:
                                return {
                                    "pid": pid
                                    "name": proc.name()
                                    "cmdline": cmdline
                                    "cpu_percent": proc.cpu_percent()
                                    "memory_percent": proc.memory_percent()
                                    "memory_mb": proc.memory_info().rss / 1024 / 1024
                                    "create_time": datetime.fromtimestamp(
                                        proc.create_time()
                                    )
                                    "status": proc.status()
                                    "running_time": datetime.now()
                                    - datetime.fromtimestamp(proc.create_time())
                                }
                        except (psutil.NoSuchProcess, psutil.AccessDenied):
                            continue
            except FileNotFoundError:
                pass

        except Exception as e:
            logger.error(f"âŒ è¿›ç¨‹æŸ¥æ‰¾å¼‚å¸¸: {e}")

        return None

    def analyze_logs(self) -> dict:
        """åˆ†ææ—¥å¿—æ–‡ä»¶"""
        logger.info("ğŸ“‹ åˆ†ææ—¥å¿—æ–‡ä»¶...")

        if not self.log_file.exists():
            return {
                "file_exists": False
                "error": "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"
                "last_50_lines": []
                "success_count": 0
                "error_count": 0
                "last_timestamp": None
            }

        try:
            with open(self.log_file, encoding="utf-8") as f:
                lines = f.readlines()

            # è·å–æœ€å50è¡Œ
            last_50_lines = lines[-50:] if len(lines) >= 50 else lines

            # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥æ¬¡æ•°
            success_count = sum(1 for line in lines if "âœ…" in line)
            error_count = sum(1 for line in lines if "âŒ" in line)
            warning_count = sum(1 for line in lines if "âš ï¸" in line)

            # æå–æœ€åä¸€æ¡æœ‰æ„ä¹‰çš„æ—¥å¿—æ—¶é—´æˆ³
            last_timestamp = None
            for line in reversed(lines):
                if line.strip() and "INFO" in line:
                    try:
                        # æå–æ—¶é—´æˆ³æ ¼å¼: 2025-12-02 00:38:07
                        timestamp_str = line.split(" [")[0]
                        last_timestamp = datetime.strptime(
                            timestamp_str, "%Y-%m-%d %H:%M:%S"
                        )
                        break
                    except (ValueError, IndexError):
                        continue

            return {
                "file_exists": True
                "total_lines": len(lines)
                "last_50_lines": [line.strip() for line in last_50_lines]
                "success_count": success_count
                "error_count": error_count
                "warning_count": warning_count
                "last_timestamp": last_timestamp
                "log_age_minutes": (
                    (datetime.now() - last_timestamp).total_seconds() / 60
                    if last_timestamp
                    else None
                )
            }

        except Exception as e:
            return {
                "file_exists": True
                "error": str(e)
                "last_50_lines": []
                "success_count": 0
                "error_count": 0
                "last_timestamp": None
            }

    async def check_database(self) -> dict:
        """æ£€æŸ¥æ•°æ®åº“çŠ¶æ€å’Œæ•°æ®è´¨é‡"""
        logger.info("ğŸ—„ï¸ æ£€æŸ¥æ•°æ®åº“çŠ¶æ€...")

        if not DB_AVAILABLE:
            return {
                "connected": False
                "error": "æ•°æ®åº“æ¨¡å—ä¸å¯ç”¨"
                "total_matches": 0
                "fbref_matches": 0
                "matches_with_stats": 0
                "matches_with_xg": 0
                "latest_match": None
            }

        try:
            async with get_async_session() as session:
                # 1. æ€»é‡ç»Ÿè®¡
                total_result = await session.execute(
                    text("SELECT COUNT(*) FROM matches")
                )
                total_matches = total_result.scalar() or 0

                # 2. FBrefæ•°æ®ç»Ÿè®¡
                fbref_result = await session.execute(
                    text(
                        "SELECT COUNT(*) FROM matches WHERE data_source LIKE '%fbref%'"
                    )
                )
                fbref_matches = fbref_result.scalar() or 0

                # 3. æœ‰æ·±åº¦æ•°æ®çš„æ¯”èµ›ç»Ÿè®¡
                stats_result = await session.execute(
                    text(
                        "SELECT COUNT(*) FROM matches WHERE stats IS NOT NULL OR lineups IS NOT NULL"
                    )
                )
                matches_with_stats = stats_result.scalar() or 0

                # 4. xGæ•°æ®ç»Ÿè®¡ (æ£€æŸ¥JSONå­—æ®µ)
                xg_result = await session.execute(
                    text(
                        "SELECT COUNT(*) FROM matches WHERE (stats->>'home_xg') IS NOT NULL OR (stats->>'away_xg') IS NOT NULL OR (stats->>'xg_home') IS NOT NULL OR (stats->>'xg_away') IS NOT NULL)"
                    )
                )
                matches_with_xg = xg_result.scalar() or 0

                # 5. æœ€æ–°å…¥åº“çš„æ¯”èµ›
                latest_result = await session.execute(
                    text(
                        """
                        SELECT match_date, home_team, away_team, score, data_source, created_at
                        FROM matches
                        ORDER BY created_at DESC
                        LIMIT 1
                    """
                    )
                )
                latest_row = latest_result.fetchone()

                latest_match = None
                if latest_row:
                    latest_match = {
                        "match_date": latest_row[0]
                        "home_team": latest_row[1]
                        "away_team": latest_row[2]
                        "score": latest_row[3]
                        "data_source": latest_row[4]
                        "created_at": latest_row[5]
                    }

                # 6. æœ€è¿‘ä¸€å°æ—¶çš„æ•°æ®å¢é•¿
                recent_result = await session.execute(
                    text(
                        """
                        SELECT COUNT(*) FROM matches
                        WHERE created_at >= NOW() - INTERVAL '1 hour'
                    """
                    )
                )
                recent_matches = recent_result.scalar() or 0

                return {
                    "connected": True
                    "total_matches": total_matches
                    "fbref_matches": fbref_matches
                    "matches_with_stats": matches_with_stats
                    "matches_with_xg": matches_with_xg
                    "latest_match": latest_match
                    "recent_matches_1h": recent_matches
                    "fbref_percentage": (
                        (fbref_matches / total_matches * 100)
                        if total_matches > 0
                        else 0
                    )
                    "stats_percentage": (
                        (matches_with_stats / total_matches * 100)
                        if total_matches > 0
                        else 0
                    )
                    "xg_percentage": (
                        (matches_with_xg / total_matches * 100)
                        if total_matches > 0
                        else 0
                    )
                }

        except Exception as e:
            return {
                "connected": False
                "error": str(e)
                "total_matches": 0
                "fbref_matches": 0
                "matches_with_stats": 0
                "matches_with_xg": 0
                "latest_match": None
            }

    def get_system_resources(self) -> dict:
        """è·å–ç³»ç»Ÿèµ„æºçŠ¶æ€"""
        try:
            # CPUä¿¡æ¯
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()

            # å†…å­˜ä¿¡æ¯
            memory = psutil.virtual_memory()

            # ç£ç›˜ä¿¡æ¯
            disk = psutil.disk_usage("/")

            # ç½‘ç»œä¿¡æ¯
            network = psutil.net_io_counters()

            return {
                "cpu_percent": cpu_percent
                "cpu_count": cpu_count
                "memory_total_gb": memory.total / (1024**3)
                "memory_used_gb": memory.used / (1024**3)
                "memory_available_gb": memory.available / (1024**3)
                "memory_percent": memory.percent
                "disk_total_gb": disk.total / (1024**3)
                "disk_used_gb": disk.used / (1024**3)
                "disk_free_gb": disk.free / (1024**3)
                "disk_percent": disk.percent
                "network_bytes_sent": network.bytes_sent
                "network_bytes_recv": network.bytes_recv
            }
        except Exception as e:
            return {"error": str(e)}

    def calculate_progress(self, log_analysis: dict, db_stats: dict) -> dict:
        """è®¡ç®—æ•°æ®é‡‡é›†è¿›åº¦"""
        if not log_analysis.get("success_count", 0):
            return {"estimated_progress": 0, "status": "Not Started"}

        # åŸºäºæ—¥å¿—æˆåŠŸæ¬¡æ•°ä¼°ç®—è¿›åº¦
        total_tasks = 15  # 5è”èµ› Ã— 3èµ›å­£
        completed_tasks = log_analysis["success_count"]
        estimated_progress = min(100, (completed_tasks / total_tasks) * 100)

        # åŸºäºæ•°æ®åº“æ•°æ®éªŒè¯è¿›åº¦
        if db_stats.get("fbref_matches", 0) > 0:
            fbref_matches = db_stats["fbref_matches"]
            expected_matches = total_tasks * 380  # ä¼°ç®—æ¯èµ›å­£380åœºæ¯”èµ›
            db_progress = min(100, (fbref_matches / expected_matches) * 100)

            # å–ä¸¤ç§æ–¹æ³•çš„å¹³å‡å€¼
            final_progress = (estimated_progress + db_progress) / 2
        else:
            final_progress = estimated_progress

        # åˆ¤æ–­çŠ¶æ€
        if final_progress >= 95:
            status = "Completed"
        elif final_progress >= 50:
            status = "In Progress"
        elif final_progress > 0:
            status = "Starting"
        else:
            status = "Not Started"

        return {
            "estimated_progress": round(final_progress, 1)
            "status": status
            "log_based_progress": round(estimated_progress, 1)
            "db_based_progress": (
                round(db_progress, 1) if db_stats.get("fbref_matches", 0) > 0 else 0
            )
        }

    async def generate_dashboard(self) -> str:
        """ç”Ÿæˆè¿ç»´ç›‘æ§ä»ªè¡¨ç›˜"""
        logger.info("ğŸ“Š ç”Ÿæˆè¿ç»´ç›‘æ§ä»ªè¡¨ç›˜...")

        # æ‰§è¡Œå„é¡¹æ£€æŸ¥
        process_info = self.find_process()
        log_analysis = self.analyze_logs()
        db_stats = await self.check_database()
        system_resources = self.get_system_resources()
        progress_info = self.calculate_progress(log_analysis, db_stats)

        # ç”ŸæˆæŠ¥å‘Š
        timestamp = self.check_time.strftime("%Y-%m-%d %H:%M:%S")

        dashboard = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    FBrefæ•°æ®å·¥å‚ - è¿ç»´ç›‘æ§ä»ªè¡¨ç›˜                               â•‘
â•‘                           SRE + DBA è”åˆå·¡æ£€                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ• å·¡æ£€æ—¶é—´: {timestamp}
ğŸ“‹ æ£€æŸ¥èŒƒå›´: è¿›ç¨‹å¥åº· | æ—¥å¿—åˆ†æ | æ•°æ®åº“è´¨é‡ | ç³»ç»Ÿèµ„æº

â”Œâ”€ ğŸ”„ è¿›ç¨‹å¥åº·çŠ¶æ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if process_info:
            status_emoji = "ğŸŸ¢" if process_info["status"] == "running" else "ğŸŸ¡"
            dashboard += f"""
â”‚ çŠ¶æ€: {status_emoji} {process_info['status'].upper()}
â”‚ PID: {process_info['pid']}
â”‚ è¿è¡Œæ—¶é—´: {process_info['running_time']}
â”‚ CPUä½¿ç”¨ç‡: {process_info['cpu_percent']:.1f}%
â”‚ å†…å­˜ä½¿ç”¨: {process_info['memory_mb']:.1f} MB ({process_info['memory_percent']:.1f}%)
â”‚ è¿›ç¨‹å¹´é¾„: {process_info['create_time'].strftime('%Y-%m-%d %H:%M:%S')}
â”‚ å‘½ä»¤è¡Œ: {process_info['cmdline'][:80]}..."""
        else:
            dashboard += """
â”‚ çŠ¶æ€: ğŸ”´ NOT RUNNING
â”‚ è¯¦æƒ…: æœªæ‰¾åˆ°ç›®æ ‡è¿›ç¨‹ 'final_fbref_backfill.py'"""

        dashboard += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ“‹ æ—¥å¿—åˆ†ææŠ¥å‘Š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if log_analysis["file_exists"]:
            log_age = log_analysis["log_age_minutes"]
            age_status = "ğŸŸ¢" if log_age < 10 else "ğŸŸ¡" if log_age < 60 else "ğŸ”´"

            dashboard += f"""
â”‚ æ—¥å¿—çŠ¶æ€: {age_status} æ­£å¸¸
â”‚ æ€»è¡Œæ•°: {log_analysis['total_lines']:,}
â”‚ æˆåŠŸæ ‡è®°: âœ… {log_analysis['success_count']} æ¬¡
â”‚ å¤±è´¥æ ‡è®°: âŒ {log_analysis['error_count']} æ¬¡
â”‚ è­¦å‘Šæ ‡è®°: âš ï¸ {log_analysis['warning_count']} æ¬¡
â”‚ æœ€åæ›´æ–°: {log_age:.1f} åˆ†é’Ÿå‰ ({log_analysis['last_timestamp'] or 'Unknown'})"""
        else:
            dashboard += f"""
â”‚ æ—¥å¿—çŠ¶æ€: ğŸ”´ æ–‡ä»¶ä¸å­˜åœ¨
â”‚ é”™è¯¯: {log_analysis.get('error', 'Unknown')}"""

        dashboard += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ—„ï¸ æ•°æ®åº“è´¨é‡æŠ¥å‘Š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if db_stats["connected"]:
            db_status = "ğŸŸ¢" if db_stats["fbref_matches"] > 0 else "ğŸŸ¡"
            dashboard += f"""
â”‚ æ•°æ®åº“è¿æ¥: {db_status} æ­£å¸¸
â”‚ æ€»æ¯”èµ›æ•°: {db_stats['total_matches']:,}
â”‚ FBrefæ•°æ®: {db_stats['fbref_matches']:,} ({db_stats['fbref_percentage']:.1f}%)
â”‚ æœ‰ç»Ÿè®¡æ•°æ®: {db_stats['matches_with_stats']:,} ({db_stats['stats_percentage']:.1f}%)
â”‚ æœ‰xGæ•°æ®: {db_stats['matches_with_xg']:,} ({db_stats['xg_percentage']:.1f}%)"""

            if db_stats["latest_match"]:
                latest = db_stats["latest_match"]
                dashboard += f"""
â”‚ æœ€æ–°å…¥åº“: {latest['match_date']} {latest['home_team']} vs {latest['away_team']} ({latest['score']})
â”‚ æ•°æ®æ¥æº: {latest['data_source']}"""

            dashboard += f"""
â”‚ æœ€è¿‘1å°æ—¶: +{db_stats['recent_matches_1h']} åœºæ¯”èµ›"""
        else:
            dashboard += f"""
â”‚ æ•°æ®åº“è¿æ¥: ğŸ”´ å¤±è´¥
â”‚ é”™è¯¯: {db_stats.get('error', 'Unknown')}"""

        dashboard += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ“ˆ é‡‡é›†è¿›åº¦è¯„ä¼° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        progress_status = progress_info["status"]
        progress_emoji = {
            "Completed": "ğŸŸ¢"
            "In Progress": "ğŸŸ¡"
            "Starting": "ğŸŸ "
            "Not Started": "ğŸ”´"
        }.get(progress_status, "âšª")

        dashboard += f"""
â”‚ æ•´ä½“è¿›åº¦: {progress_emoji} {progress_info['estimated_progress']}% ({progress_status})
â”‚ åŸºäºæ—¥å¿—: {progress_info['log_based_progress']}%
â”‚ åŸºäºæ•°æ®åº“: {progress_info['db_based_progress']}%
â”‚ é¢„è®¡å‰©ä½™: {(100 - progress_info['estimated_progress']) / 20 * 5:.1f} åˆ†é’Ÿ (ä¼°ç®—)"""

        dashboard += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ’» ç³»ç»Ÿèµ„æºçŠ¶æ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        if "error" not in system_resources:
            cpu_status = (
                "ğŸŸ¢"
                if system_resources["cpu_percent"] < 80
                else "ğŸŸ¡" if system_resources["cpu_percent"] < 90 else "ğŸ”´"
            )
            mem_status = (
                "ğŸŸ¢"
                if system_resources["memory_percent"] < 80
                else "ğŸŸ¡" if system_resources["memory_percent"] < 90 else "ğŸ”´"
            )
            disk_status = (
                "ğŸŸ¢"
                if system_resources["disk_percent"] < 80
                else "ğŸŸ¡" if system_resources["disk_percent"] < 90 else "ğŸ”´"
            )

            dashboard += f"""
â”‚ CPU: {cpu_status} {system_resources['cpu_percent']:.1f}% ({system_resources['cpu_count']} æ ¸)
â”‚ å†…å­˜: {mem_status} {system_resources['memory_used_gb']:.1f}GB / {system_resources['memory_total_gb']:.1f}GB ({system_resources['memory_percent']:.1f}%)
â”‚ ç£ç›˜: {disk_status} {system_resources['disk_used_gb']:.1f}GB / {system_resources['disk_total_gb']:.1f}GB ({system_resources['disk_percent']:.1f}%)
â”‚ å¯ç”¨å†…å­˜: {system_resources['memory_available_gb']:.1f}GB"""
        else:
            dashboard += f"""
â”‚ ç³»ç»Ÿç›‘æ§: ğŸ”´ å¼‚å¸¸
â”‚ é”™è¯¯: {system_resources['error']}"""

        dashboard += """
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ¯ SREå»ºè®® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"""

        recommendations = []

        if not process_info:
            recommendations.append("ğŸš¨ ç«‹å³é‡å¯æ•°æ®é‡‡é›†è¿›ç¨‹")

        if log_analysis.get("log_age_minutes", 0) > 30:
            recommendations.append("âš ï¸ æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å‡æ­»")

        if db_stats.get("fbref_percentage", 0) == 0:
            recommendations.append("ğŸ“Š ç¡®è®¤æ•°æ®æ˜¯å¦æˆåŠŸå…¥åº“")

        if system_resources.get("memory_percent", 0) > 85:
            recommendations.append("ğŸ’¾ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–")

        if system_resources.get("disk_percent", 0) > 85:
            recommendations.append("ğŸ’¿ ç£ç›˜ç©ºé—´ä¸è¶³")

        if recommendations:
            for rec in recommendations:
                dashboard += f"â”‚ {rec}\n"
        else:
            dashboard += "â”‚ âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæ— éœ€å¹²é¢„\n"

        dashboard += f"""â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Šå·¡æ£€å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ”„ä¸‹æ¬¡å·¡æ£€å»ºè®®: {(datetime.now() + timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M:%S')}
"""

        return dashboard

    async def run_monitoring(self):
        """è¿è¡Œå®Œæ•´çš„è¿ç»´ç›‘æ§"""
        logger.info("ğŸš€ å¯åŠ¨FBrefæ•°æ®å·¥å‚è¿ç»´ç›‘æ§")

        try:
            dashboard = await self.generate_dashboard()
            print(dashboard)

            # ä¿å­˜ç›‘æ§æŠ¥å‘Š
            report_file = (
                self.project_root
                / "logs"
                / f'ops_monitor_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
            )
            with open(report_file, "w", encoding="utf-8") as f:
                f.write(dashboard)

            logger.info(f"ğŸ“‹ ç›‘æ§æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        except Exception as e:
            logger.error(f"âŒ ç›‘æ§æ‰§è¡Œå¤±è´¥: {e}")
            import traceback

            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    monitor = OpsMonitor()
    await monitor.run_monitoring()


if __name__ == "__main__":
    asyncio.run(main())
