#!/usr/bin/env python3
"""
å¢å¼ºF821è§„æ¨¡åŒ–ä¿®å¤å™¨
Enhanced F821 Scaler

åŸºäºæˆåŠŸéªŒè¯çš„ç­–ç•¥ï¼Œè§„æ¨¡åŒ–å¤„ç†F821æœªå®šä¹‰åç§°é”™è¯¯
é‡‡ç”¨æ™ºèƒ½åˆ†ç»„ã€æ‰¹é‡å¤„ç†ã€å®‰å…¨éªŒè¯çš„æ–¹æ³•
"""

import ast
import json
import logging
import re
import subprocess
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EnhancedF821Scaler:
    """å¢å¼ºF821è§„æ¨¡åŒ–ä¿®å¤å™¨"""

    def __init__(self):
        self.fixes_applied = 0
        self.files_processed = 0
        self.files_fixed = 0

        # å¢å¼ºçš„å¯¼å…¥æ˜ å°„æ•°æ®åº“
        self.import_mappings = {
            # FastAPI - é«˜é¢‘ä½¿ç”¨
            'APIRouter': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.95},
            'HTTPException': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.95},
            'Query': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.95},
            'Depends': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.95},
            'BackgroundTasks': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.95},
            'Body': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.90},
            'Path': {'module': 'fastapi', 'import_type': 'from', 'confidence': 0.90},

            # Pydantic - é«˜é¢‘ä½¿ç”¨
            'BaseModel': {'module': 'pydantic', 'import_type': 'from', 'confidence': 0.98},
            'Field': {'module': 'pydantic', 'import_type': 'from', 'confidence': 0.98},
            'validator': {'module': 'pydantic', 'import_type': 'from', 'confidence': 0.90},

            # Typing - é«˜é¢‘ä½¿ç”¨
            'Dict': {'module': 'typing', 'import_type': 'from', 'confidence': 0.99},
            'List': {'module': 'typing', 'import_type': 'from', 'confidence': 0.99},
            'Optional': {'module': 'typing', 'import_type': 'from', 'confidence': 0.99},
            'Union': {'module': 'typing', 'import_type': 'from', 'confidence': 0.90},
            'Any': {'module': 'typing', 'import_type': 'from', 'confidence': 0.90},
            'Callable': {'module': 'typing', 'import_type': 'from', 'confidence': 0.85},
            'Tuple': {'module': 'typing', 'import_type': 'from', 'confidence': 0.85},

            # æ ‡å‡†åº“ - ä¸­é¢‘ä½¿ç”¨
            'datetime': {'module': 'datetime', 'import_type': 'from', 'confidence': 0.95},
            'Path': {'module': 'pathlib', 'import_type': 'from', 'confidence': 0.90},
            're': {'module': 're', 'import_type': 'import', 'confidence': 0.95},
            'json': {'module': 'json', 'import_type': 'import', 'confidence': 0.95},
            'os': {'module': 'os', 'import_type': 'import', 'confidence': 0.95},
            'sys': {'module': 'sys', 'import_type': 'import', 'confidence': 0.95},
            'time': {'module': 'time', 'import_type': 'import', 'confidence': 0.85},
            'uuid': {'module': 'uuid', 'import_type': 'import', 'confidence': 0.85},

            # Logging - ä¸­é¢‘ä½¿ç”¨
            'logger': {'module': 'logging', 'import_type': 'from', 'name': 'get_logger', 'confidence': 0.90},
            'logging': {'module': 'logging', 'import_type': 'import', 'confidence': 0.90},

            # SQLAlchemy - ä½é¢‘ä½¿ç”¨
            'Column': {'module': 'sqlalchemy', 'import_type': 'from', 'confidence': 0.85},
            'Integer': {'module': 'sqlalchemy', 'import_type': 'from', 'confidence': 0.85},
            'String': {'module': 'sqlalchemy', 'import_type': 'from', 'confidence': 0.85},

            # æµ‹è¯•ç›¸å…³
            'pytest': {'module': 'pytest', 'import_type': 'import', 'confidence': 0.80},
            'Mock': {'module': 'unittest.mock', 'import_type': 'from', 'confidence': 0.85},
            'patch': {'module': 'unittest.mock', 'import_type': 'from', 'confidence': 0.85},

            # HTTPç›¸å…³
            'requests': {'module': 'requests', 'import_type': 'import', 'confidence': 0.85},
            'httpx': {'module': 'httpx', 'import_type': 'import', 'confidence': 0.80},

            # æ•°æ®å¤„ç†
            'pandas': {'module': 'pandas', 'import_type': 'import', 'confidence': 0.80},
            'numpy': {'module': 'numpy', 'import_type': 'import', 'confidence': 0.80},
        }

    def analyze_f821_errors(self) -> Dict:
        """æ·±åº¦åˆ†æF821é”™è¯¯å¹¶ç”Ÿæˆæ™ºèƒ½åˆ†ç»„"""
        logger.info("ğŸ” å¼€å§‹æ·±åº¦åˆ†æF821é”™è¯¯...")

        try:
            result = subprocess.run(
                ['ruff', 'check', '--select=F821', '--format=json'],
                capture_output=True,
                text=True,
                timeout=120
            )

            if not result.stdout.strip():
                logger.info("âœ… æ²¡æœ‰å‘ç°F821é”™è¯¯")
                return {'total_errors': 0, 'high_confidence_errors': []}

            error_data = json.loads(result.stdout)
            f821_errors = [e for e in error_data if e.get('code') == 'F821']

            logger.info(f"ğŸ“Š å‘ç° {len(f821_errors)} ä¸ªF821é”™è¯¯")

            # åˆ†ææ¯ä¸ªé”™è¯¯
            high_confidence_errors = []
            medium_confidence_errors = []
            low_confidence_errors = []

            for error in f821_errors:
                file_path = error['filename']
                line_num = error['location']['row']
                message = error['message']

                # æå–æœªå®šä¹‰åç§°
                undefined_name = self.extract_undefined_name(message)

                # ç¡®å®šä¿®å¤ç­–ç•¥å’Œç½®ä¿¡åº¦
                fix_strategy = self.determine_fix_strategy(undefined_name, file_path)

                error_info = {
                    'file': file_path,
                    'line': line_num,
                    'name': undefined_name,
                    'strategy': fix_strategy['strategy'],
                    'confidence': fix_strategy['confidence'],
                    'suggested_import': fix_strategy.get('suggested_import'),
                    'module_type': self.get_module_type(file_path)
                }

                # æŒ‰ç½®ä¿¡åº¦åˆ†ç±»
                if fix_strategy['confidence'] >= 0.9:
                    high_confidence_errors.append(error_info)
                elif fix_strategy['confidence'] >= 0.7:
                    medium_confidence_errors.append(error_info)
                else:
                    low_confidence_errors.append(error_info)

            logger.info(f"ğŸ“ˆ åˆ†æç»“æœ: é«˜ç½®ä¿¡åº¦ {len(high_confidence_errors)}, ä¸­ç½®ä¿¡åº¦ {len(medium_confidence_errors)}, ä½ç½®ä¿¡åº¦ {len(low_confidence_errors)}")

            return {
                'total_errors': len(f821_errors),
                'high_confidence_errors': high_confidence_errors,
                'medium_confidence_errors': medium_confidence_errors,
                'low_confidence_errors': low_confidence_errors
            }

        except Exception as e:
            logger.error(f"F821é”™è¯¯åˆ†æå¤±è´¥: {e}")
            return {'total_errors': 0, 'high_confidence_errors': []}

    def extract_undefined_name(self, message: str) -> str:
        """ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–æœªå®šä¹‰åç§°"""
        match = re.search(r"undefined name '([^']+)'", message)
        return match.group(1) if match else ""

    def get_module_type(self, file_path: str) -> str:
        """è·å–æ¨¡å—ç±»å‹"""
        if '/test' in file_path:
            return 'test'
        elif '/src/api/' in file_path:
            return 'api'
        elif '/src/core/' in file_path:
            return 'core'
        elif '/src/utils/' in file_path:
            return 'utils'
        elif '/src/models/' in file_path:
            return 'models'
        elif '/src/database/' in file_path:
            return 'database'
        elif '/src/services/' in file_path:
            return 'services'
        else:
            return 'other'

    def determine_fix_strategy(self, undefined_name: str, file_path: str) -> Dict:
        """ç¡®å®šä¿®å¤ç­–ç•¥å’Œç½®ä¿¡åº¦"""
        # é«˜ç½®ä¿¡åº¦ï¼šå¸¸è§å¯¼å…¥æ˜ å°„
        if undefined_name in self.import_mappings:
            mapping = self.import_mappings[undefined_name]
            return {
                'strategy': 'add_common_import',
                'confidence': mapping['confidence'],
                'suggested_import': mapping
            }

        # ä¸­ç­‰ç½®ä¿¡åº¦ï¼šæ£€æŸ¥æ–‡ä»¶ç±»å‹ç‰¹å®šæ¨¡å¼
        module_type = self.get_module_type(file_path)

        if module_type == 'test':
            # æµ‹è¯•æ–‡ä»¶çš„ç‰¹æ®Šå¤„ç†
            if undefined_name in ['Mock', 'patch', 'pytest', 'fixture']:
                return {
                    'strategy': 'add_test_import',
                    'confidence': 0.85,
                    'suggested_import': self.get_test_import(undefined_name)
                }

        elif module_type == 'api':
            # APIæ–‡ä»¶çš„ç‰¹æ®Šå¤„ç†
            if undefined_name in ['router', 'app', 'service']:
                return {
                    'strategy': 'add_api_import',
                    'confidence': 0.8,
                    'suggested_import': self.get_api_import(undefined_name)
                }

        # ä½ç½®ä¿¡åº¦ï¼šéœ€è¦æ‰‹åŠ¨å®¡æŸ¥
        return {
            'strategy': 'manual_review',
            'confidence': 0.3,
            'suggested_action': 'manual_inspection_required'
        }

    def get_test_import(self, name: str) -> Dict:
        """è·å–æµ‹è¯•ç›¸å…³çš„å¯¼å…¥"""
        test_imports = {
            'Mock': {'module': 'unittest.mock', 'import_type': 'from'},
            'patch': {'module': 'unittest.mock', 'import_type': 'from'},
            'pytest': {'module': 'pytest', 'import_type': 'import'},
            'fixture': {'module': 'pytest', 'import_type': 'from'},
        }
        return test_imports.get(name, {})

    def get_api_import(self, name: str) -> Dict:
        """è·å–APIç›¸å…³çš„å¯¼å…¥"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®é¡¹ç›®çš„å®é™…æƒ…å†µæ‰©å±•
        return {}

    def execute_batch_fix(self, batch_size: int = 50, confidence_threshold: float = 0.9) -> Dict:
        """æ‰§è¡Œæ‰¹é‡ä¿®å¤"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡F821ä¿®å¤...")

        # åˆ†æé”™è¯¯
        analysis = self.analyze_f821_errors()
        if analysis['total_errors'] == 0:
            return {
                'success': True,
                'total_errors': 0,
                'fixed_errors': 0,
                'message': 'æ²¡æœ‰F821é”™è¯¯éœ€è¦ä¿®å¤'
            }

        # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„é”™è¯¯
        target_errors = []
        for error in analysis['high_confidence_errors']:
            if error['confidence'] >= confidence_threshold:
                target_errors.append(error)

        # å¦‚æœé«˜ç½®ä¿¡åº¦é”™è¯¯ä¸å¤Ÿï¼Œæ·»åŠ ä¸­ç½®ä¿¡åº¦é”™è¯¯
        if len(target_errors) < batch_size:
            remaining_needed = batch_size - len(target_errors)
            target_errors.extend(analysis['medium_confidence_errors'][:remaining_needed])

        # é™åˆ¶æ‰¹æ¬¡å¤§å°
        target_errors = target_errors[:batch_size]

        logger.info(f"ğŸ“‹ å‡†å¤‡ä¿®å¤ {len(target_errors)} ä¸ªé”™è¯¯")

        # æŒ‰æ–‡ä»¶åˆ†ç»„å¤„ç†
        errors_by_file = defaultdict(list)
        for error in target_errors:
            errors_by_file[error['file']].append(error)

        # æ‰§è¡Œä¿®å¤
        files_fixed = 0
        total_errors_fixed = 0

        for file_path, file_errors in errors_by_file.items():
            logger.info(f"ğŸ”§ ä¿®å¤æ–‡ä»¶: {file_path} ({len(file_errors)}ä¸ªé”™è¯¯)")

            if self.fix_file_smartly(file_path, file_errors):
                files_fixed += 1
                total_errors_fixed += len(file_errors)
                self.fixes_applied += len(file_errors)

            self.files_processed += 1

        # éªŒè¯ä¿®å¤æ•ˆæœ
        remaining_errors = self.get_remaining_f821_count()

        result = {
            'success': total_errors_fixed > 0,
            'total_errors_before': analysis['total_errors'],
            'processed_errors': len(target_errors),
            'fixed_errors': total_errors_fixed,
            'files_processed': self.files_processed,
            'files_fixed': files_fixed,
            'remaining_errors': remaining_errors,
            'reduction': analysis['total_errors'] - remaining_errors,
            'fix_rate': f"{(total_errors_fixed / max(len(target_errors), 1)) * 100:.1f}%",
            'message': f'å¤„ç†äº† {len(target_errors)} ä¸ªé”™è¯¯ï¼Œä¿®å¤äº† {total_errors_fixed} ä¸ª'
        }

        logger.info(f"âœ… æ‰¹é‡ä¿®å¤å®Œæˆ: {result}")
        return result

    def get_remaining_f821_count(self) -> int:
        """è·å–å‰©ä½™F821é”™è¯¯æ•°é‡"""
        try:
            result = subprocess.run(
                ['ruff', 'check', '--select=F821'],
                capture_output=True,
                text=True,
                timeout=60
            )

            return result.stdout.count('F821')

        except Exception:
            return -1

    def fix_file_smartly(self, file_path: str, errors: List[Dict]) -> bool:
        """æ™ºèƒ½ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.split('\n')
            original_lines = lines.copy()

            # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„å¤„ç†
            import_fixes = set()

            for error in errors:
                strategy = error['strategy']
                if strategy in ['add_common_import', 'add_test_import']:
                    import_info = error['suggested_import']
                    if import_info:
                        key = f"{import_info['module']}::{import_info.get('name', error['name'])}"
                        import_fixes.add(key)

            # æ™ºèƒ½æ·»åŠ å¯¼å…¥
            if import_fixes:
                lines = self.add_imports_intelligently(lines, list(import_fixes))

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¿®æ”¹
            if lines != original_lines:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(lines))

                logger.info(f"âœ… æ–‡ä»¶ä¿®å¤æˆåŠŸ: {file_path}")
                return True

        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶ä¿®å¤å¤±è´¥ {file_path}: {e}")

        return False

    def add_imports_intelligently(self, lines: List[str], import_keys: List[str]) -> List[str]:
        """æ™ºèƒ½æ·»åŠ å¯¼å…¥è¯­å¥"""
        # è§£æå¯¼å…¥é”®å€¼
        imports_to_add = []
        for key in import_keys:
            module, name = key.split('::')
            if name == module:
                imports_to_add.append(('import', module, None))
            else:
                imports_to_add.append(('from', module, name))

        # æŸ¥æ‰¾å¯¼å…¥åŒºåŸŸ
        import_end = 0
        in_import_section = False

        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped.startswith(('import ', 'from ')):
                import_end = i + 1
                in_import_section = True
            elif stripped and not stripped.startswith('#') and in_import_section:
                break

        # æŒ‰ç±»å‹åˆ†ç»„å¯¼å…¥
        import_stmts = []
        from_imports = defaultdict(list)

        for import_type, module, name in imports_to_add:
            if import_type == 'import':
                import_stmts.append(f"import {module}")
            else:  # from import
                from_imports[module].append(name)

        # ç”Ÿæˆfrom importè¯­å¥
        for module, names in from_imports.items():
            names_str = ', '.join(sorted(names))
            import_stmts.append(f"from {module} import {names_str}")

        # æ’å…¥å¯¼å…¥è¯­å¥
        for import_stmt in sorted(import_stmts):
            if import_stmt not in '\n'.join(lines):
                lines.insert(import_end, import_stmt)
                import_end += 1

        return lines

    def generate_scaler_report(self) -> Dict:
        """ç”Ÿæˆä¿®å¤å™¨æŠ¥å‘Š"""
        return {
            'scaler_name': 'Enhanced F821 Scaler',
            'timestamp': '2025-10-30T02:30:00.000000',
            'target_errors': '6,604 F821 errors',
            'strategy': 'Smart grouping + batch processing + confidence filtering',
            'fixes_applied': self.fixes_applied,
            'files_processed': self.files_processed,
            'files_fixed': self.files_fixed,
            'success_rate': f"{(self.files_fixed / max(self.files_processed, 1)) * 100:.1f}%",
            'next_step': 'Continue with medium confidence errors or F405/F841 cleanup'
        }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºF821è§„æ¨¡åŒ–ä¿®å¤å™¨")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡: 6,604ä¸ªF821é”™è¯¯ â†’ æ™ºèƒ½æ‰¹é‡ä¿®å¤")
    print("ğŸ§  ç­–ç•¥: é«˜ç½®ä¿¡åº¦ä¼˜å…ˆ + å®‰å…¨æ‰¹é‡å¤„ç†")
    print("=" * 60)

    scaler = EnhancedF821Scaler()

    # æ‰§è¡Œæ‰¹é‡ä¿®å¤
    result = scaler.execute_batch_fix(
        batch_size=50,  # æ¯æ‰¹å¤„ç†50ä¸ªé”™è¯¯
        confidence_threshold=0.9  # åªå¤„ç†é«˜ç½®ä¿¡åº¦é”™è¯¯
    )

    # ç”ŸæˆæŠ¥å‘Š
    report = scaler.generate_scaler_report()

    print("\nğŸ“Š è§„æ¨¡åŒ–ä¿®å¤æ‘˜è¦:")
    print(f"   ä¿®å¤å‰é”™è¯¯æ•°: {result['total_errors_before']}")
    print(f"   å¤„ç†é”™è¯¯æ•°: {result['processed_errors']}")
    print(f"   ä¿®å¤é”™è¯¯æ•°: {result['fixed_errors']}")
    print(f"   å‰©ä½™é”™è¯¯æ•°: {result['remaining_errors']}")
    print(f"   é”™è¯¯å‡å°‘é‡: {result['reduction']}")
    print(f"   å¤„ç†æ–‡ä»¶æ•°: {result['files_processed']}")
    print(f"   ä¿®å¤æ–‡ä»¶æ•°: {result['files_fixed']}")
    print(f"   ä¿®å¤ç‡: {result['fix_rate']}")
    print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if result['success'] else 'âš ï¸ éœ€è¦è°ƒæ•´ç­–ç•¥'}")

    # ä¿å­˜æŠ¥å‘Š
    report_file = Path('enhanced_f821_scaler_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            'result': result,
            'report': report
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ è§„æ¨¡åŒ–ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    if result['remaining_errors'] > 5000:
        print("\nğŸ¯ ä¸‹ä¸€æ­¥: ç»§ç»­æ‰§è¡Œè§„æ¨¡åŒ–ä¿®å¤")
        print("ğŸ’¡ å»ºè®®: è¿è¡Œ 'python3 scripts/enhanced_f821_scaler.py' ç»§ç»­å¤„ç†")
    elif result['remaining_errors'] > 1000:
        print("\nğŸ¯ è¿›å±•è‰¯å¥½: å³å°†è¾¾åˆ°<5,000é”™è¯¯ç›®æ ‡")
        print("ğŸ’¡ å»ºè®®: å‡†å¤‡è½¬å‘F405/F841æ¸…ç†")
    else:
        print("\nğŸ‰ å³å°†è¾¾æˆç›®æ ‡: å‡†å¤‡æœ€ç»ˆè´¨é‡é—¨ç¦éªŒè¯")

    return result


if __name__ == '__main__':
    main()