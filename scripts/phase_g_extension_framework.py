#!/usr/bin/env python3
"""
ğŸ”§ Phase Gå·¥å…·é“¾æ‰©å±•æ¡†æ¶
æ”¯æŒæ›´å¤šç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶çš„æ‰©å±•æ€§è®¾è®¡

åŸºäºPhase GæˆåŠŸç»éªŒçš„æ¨¡å—åŒ–æ‰©å±•ç³»ç»Ÿ
"""

import ast
import json
import os
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Any, Type
from abc import ABC, abstractmethod
from dataclasses import dataclass, asdict
from datetime import datetime

@dataclass
class LanguageSupport:
    """è¯­è¨€æ”¯æŒé…ç½®"""
    name: str
    extensions: List[str]
    parser_available: bool
    test_frameworks: List[str]
    coverage_tools: List[str]
    quality_checkers: List[str]

@dataclass
class FrameworkSupport:
    """æ¡†æ¶æ”¯æŒé…ç½®"""
    name: str
    language: str
    patterns: List[str]
    test_generators: List[str]
    coverage_patterns: List[str]

class CodeAnalyzer(ABC):
    """ä»£ç åˆ†æå™¨åŸºç±»"""

    def __init__(self, language: str, source_dir: str):
        self.language = language
        self.source_dir = Path(source_dir)
        self.functions = []

    @abstractmethod
    def analyze_functions(self) -> List[Dict]:
        """åˆ†æå‡½æ•° - å­ç±»å®ç°"""
        pass

    @abstractmethod
    def calculate_complexity(self, function_info: Dict) -> int:
        """è®¡ç®—å¤æ‚åº¦ - å­ç±»å®ç°"""
        pass

class PythonCodeAnalyzer(CodeAnalyzer):
    """Pythonä»£ç åˆ†æå™¨"""

    def analyze_functions(self) -> List[Dict]:
        """åˆ†æPythonå‡½æ•°"""
        functions = []

        for py_file in self.source_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                tree = ast.parse(content)

                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        func_info = {
                            'name': node.name,
                            'file_path': str(py_file),
                            'line_number': node.lineno,
                            'is_async': isinstance(node, ast.AsyncFunctionDef),
                            'args_count': len(node.args.args),
                            'decorators': [d.id if isinstance(d, ast.Name) else str(d) for d in node.decorator_list]
                        }

                        func_info['complexity'] = self.calculate_complexity(func_info)
                        functions.append(func_info)

            except Exception:
                continue

        self.functions = functions
        return functions

    def calculate_complexity(self, function_info: Dict) -> int:
        """è®¡ç®—Pythonå‡½æ•°å¤æ‚åº¦"""
        base_complexity = 1

        # æ ¹æ®å‚æ•°æ•°é‡å¢åŠ å¤æ‚åº¦
        base_complexity += function_info['args_count'] // 2

        # å¼‚æ­¥å‡½æ•°å¢åŠ å¤æ‚åº¦
        if function_info['is_async']:
            base_complexity += 1

        # æ ¹æ®è£…é¥°å™¨å¢åŠ å¤æ‚åº¦
        base_complexity += len(function_info['decorators'])

        return base_complexity

class JavaScriptCodeAnalyzer(CodeAnalyzer):
    """JavaScriptä»£ç åˆ†æå™¨"""

    def analyze_functions(self) -> List[Dict]:
        """åˆ†æJavaScriptå‡½æ•°"""
        functions = []

        for js_file in self.source_dir.rglob("*.js"):
            try:
                with open(js_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ç®€åŒ–çš„JavaScriptå‡½æ•°æ£€æµ‹
                lines = content.split('\n')
                for i, line in enumerate(lines):
                    line = line.strip()

                    # æ£€æµ‹å‡½æ•°å£°æ˜
                    if line.startswith('function ') or line.startswith('const ') and '=>' in line:
                        func_info = {
                            'name': self._extract_function_name(line),
                            'file_path': str(js_file),
                            'line_number': i + 1,
                            'is_async': 'async' in line,
                            'is_arrow': '=>' in line
                        }

                        func_info['complexity'] = self.calculate_complexity(func_info)
                        functions.append(func_info)

            except Exception:
                continue

        self.functions = functions
        return functions

    def _extract_function_name(self, line: str) -> str:
        """æå–å‡½æ•°å"""
        if 'function ' in line:
            return line.split('function ')[1].split('(')[0].strip()
        elif '=>' in line:
            return line.split('=')[0].strip().split()[-1]
        return "anonymous"

    def calculate_complexity(self, function_info: Dict) -> int:
        """è®¡ç®—JavaScriptå‡½æ•°å¤æ‚åº¦"""
        base_complexity = 1

        if function_info['is_async']:
            base_complexity += 1

        if function_info['is_arrow']:
            base_complexity += 1

        return base_complexity

class TestGenerator(ABC):
    """æµ‹è¯•ç”Ÿæˆå™¨åŸºç±»"""

    def __init__(self, language: str, output_dir: str):
        self.language = language
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    @abstractmethod
    def generate_test(self, function_info: Dict) -> str:
        """ç”Ÿæˆæµ‹è¯•ä»£ç  - å­ç±»å®ç°"""
        pass

class PythonTestGenerator(TestGenerator):
    """Pythonæµ‹è¯•ç”Ÿæˆå™¨"""

    def generate_test(self, function_info: Dict) -> str:
        """ç”ŸæˆPythonæµ‹è¯•ä»£ç """
        test_code = f'''#!/usr/bin/env python3
"""
ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶
å‡½æ•°: {function_info['name']}
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
è¯­è¨€: Python
"""

import pytest
from unittest.mock import Mock, patch
import sys
import os

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

class Test{function_info['name'].title()}Generated:
    """ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•ç±»"""

    def test_{function_info['name']}_basic_functionality(self):
        """åŸºç¡€åŠŸèƒ½æµ‹è¯•"""
        # TODO: å®ç°å…·ä½“æµ‹è¯•é€»è¾‘
        pass

    def test_{function_info['name']}_edge_cases(self):
        """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""
        # TODO: å®ç°è¾¹ç•Œæ¡ä»¶æµ‹è¯•
        pass

    def test_{function_info['name']}_error_handling(self):
        """é”™è¯¯å¤„ç†æµ‹è¯•"""
        # TODO: å®ç°é”™è¯¯å¤„ç†æµ‹è¯•
        pass

if __name__ == "__main__":
    pytest.main([__file__])
'''
        return test_code

class JavaScriptTestGenerator(TestGenerator):
    """JavaScriptæµ‹è¯•ç”Ÿæˆå™¨"""

    def generate_test(self, function_info: Dict) -> str:
        """ç”ŸæˆJavaScriptæµ‹è¯•ä»£ç """
        test_code = f'''/**
 * ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶
 * å‡½æ•°: {function_info['name']}
 * ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
 * è¯­è¨€: JavaScript
 */

const {{ function_info['name'] }} = require('../{{ function_info['file_path'].split('/')[-1].replace('.js', '') }}');

describe('{function_info['name']}', () => {{
    test('åŸºç¡€åŠŸèƒ½æµ‹è¯•', () => {{
        // TODO: å®ç°å…·ä½“æµ‹è¯•é€»è¾‘
        expect(true).toBe(true);
    }});

    test('è¾¹ç•Œæ¡ä»¶æµ‹è¯•', () => {{
        // TODO: å®ç°è¾¹ç•Œæ¡ä»¶æµ‹è¯•
        expect(true).toBe(true);
    }});

    test('é”™è¯¯å¤„ç†æµ‹è¯•', () => {{
        // TODO: å®ç°é”™è¯¯å¤„ç†æµ‹è¯•
        expect(true).toBe(true);
    }});
}});
'''
        return test_code

class LanguageExtensionManager:
    """è¯­è¨€æ‰©å±•ç®¡ç†å™¨"""

    def __init__(self):
        self.supported_languages = {
            'python': LanguageSupport(
                name='Python',
                extensions=['.py'],
                parser_available=True,
                test_frameworks=['pytest', 'unittest', 'nose'],
                coverage_tools=['coverage.py', 'pytest-cov'],
                quality_checkers=['ruff', 'mypy', 'pylint', 'flake8']
            ),
            'javascript': LanguageSupport(
                name='JavaScript',
                extensions=['.js', '.jsx', '.ts', '.tsx'],
                parser_available=False,  # éœ€è¦é¢å¤–é…ç½®
                test_frameworks=['jest', 'mocha', 'jasmine', 'vitest'],
                coverage_tools=['istanbul', 'c8', 'nyc'],
                quality_checkers=['eslint', 'jshint', 'typescript']
            ),
            'java': LanguageSupport(
                name='Java',
                extensions=['.java'],
                parser_available=False,  # éœ€è¦é¢å¤–é…ç½®
                test_frameworks=['junit', 'testng', 'spock'],
                coverage_tools=['jacoco', 'cobertura', 'emma'],
                quality_checkers=['checkstyle', 'pmd', 'spotbugs']
            ),
            'go': LanguageSupport(
                name='Go',
                extensions=['.go'],
                parser_available=False,  # éœ€è¦é¢å¤–é…ç½®
                test_frameworks=['testing', 'testify', 'ginkgo'],
                coverage_tools=['go test -cover', 'gocov', 'gover'],
                quality_checkers=['golint', 'go vet', 'staticcheck']
            ),
            'rust': LanguageSupport(
                name='Rust',
                extensions=['.rs'],
                parser_available=False,  # éœ€è¦é¢å¤–é…ç½®
                test_frameworks=['cargo test', 'tarpaulin'],
                coverage_tools=['cargo tarpaulin', 'kcov', 'grcov'],
                quality_checkers=['cargo clippy', 'rustfmt', 'cargo audit']
            )
        }

        self.analyzers = {
            'python': PythonCodeAnalyzer,
            'javascript': JavaScriptCodeAnalyzer
        }

        self.generators = {
            'python': PythonTestGenerator,
            'javascript': JavaScriptTestGenerator
        }

    def get_supported_languages(self) -> Dict[str, LanguageSupport]:
        """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        return self.supported_languages

    def is_language_supported(self, language: str) -> bool:
        """æ£€æŸ¥è¯­è¨€æ˜¯å¦æ”¯æŒ"""
        return language.lower() in self.supported_languages

    def get_analyzer(self, language: str) -> Optional[Type[CodeAnalyzer]]:
        """è·å–ä»£ç åˆ†æå™¨"""
        return self.analyzers.get(language.lower())

    def get_generator(self, language: str) -> Optional[Type[TestGenerator]]:
        """è·å–æµ‹è¯•ç”Ÿæˆå™¨"""
        return self.generators.get(language.lower())

    def detect_project_languages(self, project_path: str) -> List[str]:
        """æ£€æµ‹é¡¹ç›®ä¸­ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€"""
        project_path = Path(project_path)
        detected_languages = set()

        # ç»Ÿè®¡ä¸åŒè¯­è¨€æ–‡ä»¶çš„æ‰©å±•å
        extension_counts = {}
        for file_path in project_path.rglob('*'):
            if file_path.is_file():
                ext = file_path.suffix.lower()
                if ext:
                    extension_counts[ext] = extension_counts.get(ext, 0) + 1

        # æ ¹æ®æ‰©å±•åæ¨æ–­è¯­è¨€
        for ext, count in extension_counts.items():
            if count >= 3:  # è‡³å°‘3ä¸ªæ–‡ä»¶æ‰è®¤ä¸ºæ˜¯è¯¥è¯­è¨€
                for lang, support in self.supported_languages.items():
                    if ext in support.extensions:
                        detected_languages.add(lang)

        return list(detected_languages)

class ExtendedPhaseGSystem:
    """æ‰©å±•çš„Phase Gç³»ç»Ÿ"""

    def __init__(self):
        self.extension_manager = LanguageExtensionManager()
        self.analysis_results = {}
        self.generation_results = {}

    def analyze_multilang_project(self, project_path: str) -> Dict:
        """åˆ†æå¤šè¯­è¨€é¡¹ç›®"""
        print("ğŸ” æ‰©å±•Phase Gå¤šè¯­è¨€é¡¹ç›®åˆ†æ...")
        print("=" * 60)

        detected_languages = self.extension_manager.detect_project_languages(project_path)
        print(f"ğŸ“‚ æ£€æµ‹åˆ°çš„ç¼–ç¨‹è¯­è¨€: {detected_languages}")

        results = {
            'project_path': project_path,
            'detected_languages': detected_languages,
            'language_analysis': {},
            'total_functions': 0,
            'total_complexity': 0,
            'supported_languages': [],
            'unsupported_languages': []
        }

        for language in detected_languages:
            print(f"\nğŸ” åˆ†æ {language} ä»£ç ...")

            if self.extension_manager.is_language_supported(language):
                analyzer_class = self.extension_manager.get_analyzer(language)

                if analyzer_class:
                    try:
                        analyzer = analyzer_class(language, project_path)
                        functions = analyzer.analyze_functions()

                        lang_results = {
                            'functions_found': len(functions),
                            'functions': functions,
                            'total_complexity': sum(f['complexity'] for f in functions),
                            'analyzer_used': analyzer_class.__name__
                        }

                        results['language_analysis'][language] = lang_results
                        results['total_functions'] += len(functions)
                        results['total_complexity'] += lang_results['total_complexity']
                        results['supported_languages'].append(language)

                        print(f"   âœ… å‘ç° {len(functions)} ä¸ªå‡½æ•°")
                        print(f"   ğŸ“Š æ€»å¤æ‚åº¦: {lang_results['total_complexity']}")

                    except Exception as e:
                        print(f"   âŒ åˆ†æå¤±è´¥: {e}")
                        results['unsupported_languages'].append(language)
                else:
                    print(f"   âš ï¸ æš‚ä¸æ”¯æŒ {language} ä»£ç åˆ†æ")
                    results['unsupported_languages'].append(language)
            else:
                print(f"   âŒ ä¸æ”¯æŒçš„è¯­è¨€: {language}")
                results['unsupported_languages'].append(language)

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._generate_multilang_report(results)

        return results

    def generate_multilang_tests(self, analysis_results: Dict, output_dir: str = "tests/generated_multilang") -> Dict:
        """ä¸ºå¤šè¯­è¨€é¡¹ç›®ç”Ÿæˆæµ‹è¯•"""
        print(f"\nğŸ¤– æ‰©å±•Phase Gå¤šè¯­è¨€æµ‹è¯•ç”Ÿæˆ...")
        print("=" * 60)

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        generation_results = {
            'output_directory': str(output_path),
            'language_results': {},
            'total_files_generated': 0,
            'total_tests_generated': 0,
            'supported_languages': [],
            'failed_generations': []
        }

        for language, lang_analysis in analysis_results['language_analysis'].items():
            print(f"\nğŸ¤– ä¸º {language} ç”Ÿæˆæµ‹è¯•...")

            generator_class = self.extension_manager.get_generator(language)

            if generator_class:
                try:
                    generator = generator_class(language, str(output_path / language.lower()))

                    generated_files = 0
                    generated_tests = 0

                    for function_info in lang_analysis['functions']:
                        # ä¸ºæ¯ä¸ªå‡½æ•°ç”Ÿæˆæµ‹è¯•æ–‡ä»¶
                        test_code = generator.generate_test(function_info)

                        test_filename = f"test_{function_info['name']}_generated.{self._get_test_extension(language)}"
                        test_filepath = output_path / language.lower() / test_filename

                        with open(test_filepath, 'w', encoding='utf-8') as f:
                            f.write(test_code)

                        generated_files += 1
                        generated_tests += 3  # å‡è®¾æ¯ä¸ªæ–‡ä»¶åŒ…å«3ä¸ªæµ‹è¯•æ–¹æ³•

                    lang_results = {
                        'files_generated': generated_files,
                        'tests_generated': generated_tests,
                        'generator_used': generator_class.__name__,
                        'output_path': str(output_path / language.lower())
                    }

                    generation_results['language_results'][language] = lang_results
                    generation_results['total_files_generated'] += generated_files
                    generation_results['total_tests_generated'] += generated_tests
                    generation_results['supported_languages'].append(language)

                    print(f"   âœ… ç”Ÿæˆ {generated_files} ä¸ªæµ‹è¯•æ–‡ä»¶")
                    print(f"   ğŸ“Š {generated_tests} ä¸ªæµ‹è¯•æ–¹æ³•")

                except Exception as e:
                    print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
                    generation_results['failed_generations'].append(language)
            else:
                print(f"   âŒ ä¸æ”¯æŒ {language} æµ‹è¯•ç”Ÿæˆ")
                generation_results['failed_generations'].append(language)

        # ç”Ÿæˆç´¢å¼•æ–‡ä»¶
        self._generate_multilang_index(generation_results)

        # ç”Ÿæˆç”ŸæˆæŠ¥å‘Š
        self._generate_generation_report(generation_results)

        return generation_results

    def _get_test_extension(self, language: str) -> str:
        """è·å–æµ‹è¯•æ–‡ä»¶æ‰©å±•å"""
        extensions = {
            'python': 'py',
            'javascript': 'js',
            'java': 'java',
            'go': 'go',
            'rust': 'rs'
        }
        return extensions.get(language.lower(), 'test')

    def _generate_multilang_index(self, results: Dict):
        """ç”Ÿæˆå¤šè¯­è¨€æµ‹è¯•ç´¢å¼•"""
        index_content = f'''"""
ğŸ¤– æ‰©å±•Phase Gå¤šè¯­è¨€æµ‹è¯•ç´¢å¼•
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

MULTILANG_TEST_INDEX = {{
    "generation_summary": {{
        "total_files": {results['total_files_generated']},
        "total_tests": {results['total_tests_generated']},
        "output_directory": "{results['output_directory']}",
        "supported_languages": {results['supported_languages']}
    }},
    "language_results": {{
'''

        for language, lang_results in results['language_results'].items():
            index_content += f'''
        "{language}": {{
            "files_generated": {lang_results['files_generated']},
            "tests_generated": {lang_results['tests_generated']},
            "output_path": "{lang_results['output_path']}"
        }},'''

        index_content += '''
    }
}

# ä½¿ç”¨ç¤ºä¾‹
# from multilang_test_index import MULTILANG_TEST_INDEX
# print(f"ç”Ÿæˆäº† {{MULTILANG_TEST_INDEX['generation_summary']['total_files']}} ä¸ªæµ‹è¯•æ–‡ä»¶")
'''

        index_file = Path(results['output_directory']) / "__init__.py"
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(index_content)

        print(f"ğŸ“‹ ç”Ÿæˆå¤šè¯­è¨€æµ‹è¯•ç´¢å¼•: {index_file}")

    def _generate_multilang_report(self, results: Dict):
        """ç”Ÿæˆå¤šè¯­è¨€åˆ†ææŠ¥å‘Š"""
        report_file = f"phase_g_multilang_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        print(f"ğŸ“„ å¤šè¯­è¨€åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    def _generate_generation_report(self, results: Dict):
        """ç”Ÿæˆæµ‹è¯•ç”ŸæˆæŠ¥å‘Š"""
        report_file = f"phase_g_multilang_generation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        print(f"ğŸ“„ å¤šè¯­è¨€ç”ŸæˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¯åŠ¨Phase Gå·¥å…·é“¾æ‰©å±•æ¡†æ¶")
    print("æ”¯æŒå¤šç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶çš„æ‰©å±•æ€§æ¼”ç¤º")
    print("=" * 60)

    # åˆ›å»ºæ‰©å±•ç³»ç»Ÿ
    extended_system = ExtendedPhaseGSystem()

    # æ˜¾ç¤ºæ”¯æŒçš„è¯­è¨€
    supported_langs = extended_system.extension_manager.get_supported_languages()
    print(f"ğŸŒ æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€: {list(supported_langs.keys())}")

    # åˆ†æå½“å‰é¡¹ç›®ï¼ˆä½œä¸ºæ¼”ç¤ºï¼‰
    current_project = Path.cwd()
    print(f"\nğŸ“‚ åˆ†æå½“å‰é¡¹ç›®: {current_project.name}")

    try:
        # æ£€æµ‹é¡¹ç›®è¯­è¨€
        detected_langs = extended_system.extension_manager.detect_project_languages(str(current_project))
        print(f"ğŸ” æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_langs}")

        if detected_langs:
            # æ‰§è¡Œå¤šè¯­è¨€åˆ†æ
            analysis_results = extended_system.analyze_multilang_project(str(current_project))

            if analysis_results['total_functions'] > 0:
                # ç”Ÿæˆå¤šè¯­è¨€æµ‹è¯•
                generation_results = extended_system.generate_multilang_tests(analysis_results)

                # æ˜¾ç¤ºæ‘˜è¦
                print(f"\n" + "=" * 60)
                print(f"ğŸ“Š æ‰©å±•Phase Gå¤šè¯­è¨€æ”¯æŒæ‘˜è¦")
                print(f"=" * 60)
                print(f"ğŸŒ æ”¯æŒçš„è¯­è¨€: {len(supported_langs)} ä¸ª")
                print(f"ğŸ“‚ æ£€æµ‹åˆ°çš„è¯­è¨€: {len(detected_langs)} ä¸ª")
                print(f"ğŸ“Š åˆ†æçš„å‡½æ•°: {analysis_results['total_functions']} ä¸ª")
                print(f"ğŸ¤– ç”Ÿæˆçš„æµ‹è¯•: {generation_results['total_tests_generated']} ä¸ª")
                print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶: {generation_results['total_files_generated']} ä¸ª")
                print(f"âœ… æˆåŠŸçš„è¯­è¨€: {len(generation_results['supported_languages'])} ä¸ª")

                print(f"\nğŸ¯ æ‰©å±•æ¡†æ¶åŠŸèƒ½:")
                print(f"   âœ… å¤šè¯­è¨€ä»£ç åˆ†æ")
                print(f"   âœ… å¤šè¯­è¨€æµ‹è¯•ç”Ÿæˆ")
                print(f"   âœ… å¯æ‰©å±•æ¶æ„è®¾è®¡")
                print(f"   âœ… ç»Ÿä¸€çš„æ¥å£è§„èŒƒ")

                print(f"\nğŸš€ Phase Gå·¥å…·é“¾å·²æ”¯æŒå¤šè¯­è¨€æ‰©å±•!")
            else:
                print(f"\nâš ï¸ å½“å‰é¡¹ç›®ä¸­æœªå‘ç°å¯åˆ†æçš„å‡½æ•°")
        else:
            print(f"\nâš ï¸ å½“å‰é¡¹ç›®ä¸­æœªæ£€æµ‹åˆ°æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€")

    except Exception as e:
        print(f"\nâŒ æ‰©å±•æ¡†æ¶æ‰§è¡Œå¤±è´¥: {e}")
        return False

    return True

if __name__ == "__main__":
    main()