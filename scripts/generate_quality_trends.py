#!/usr/bin/env python3
"""
è´¨é‡è¶‹åŠ¿åˆ†æå™¨ - åˆ†æå†å²è´¨é‡æ•°æ®å¹¶ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨
"""

import json
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import argparse
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional


class QualityTrendAnalyzer:
    """è´¨é‡è¶‹åŠ¿åˆ†æå™¨"""

    def __init__(self):
        plt.style.use('seaborn-v0_8')
        plt.rcParams['font.family'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

    def load_quality_history(self, history_path: str) -> pd.DataFrame:
        """åŠ è½½è´¨é‡å†å²æ•°æ®"""
        try:
            df = pd.read_csv(history_path)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp')
            return df
        except FileNotFoundError:
            print(f"âŒ è´¨é‡å†å²æ–‡ä»¶æœªæ‰¾åˆ°: {history_path}")
            return pd.DataFrame()
        except Exception as e:
            print(f"âŒ åŠ è½½è´¨é‡å†å²æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†å’Œé¢„å¤„ç†æ•°æ®"""
        if df.empty:
            return df

        # ç§»é™¤é‡å¤çš„æ—¶é—´æˆ³
        df = df.drop_duplicates(subset=['timestamp'])

        # å¤„ç†ç¼ºå¤±å€¼
        numeric_columns = df.select_dtypes(include=['number']).columns
        for col in numeric_columns:
            df[col] = df[col].ffill().bfill()

        # ç§»é™¤å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
        for col in ['coverage_percent', 'quality_score']:
            if col in df.columns:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

        return df

    def generate_coverage_trend(self, df: pd.DataFrame, output_path: str) -> None:
        """ç”Ÿæˆè¦†ç›–ç‡è¶‹åŠ¿å›¾"""
        if df.empty or 'coverage_percent' not in df.columns:
            return

        fig, ax = plt.subplots(figsize=(12, 6))

        # ç»˜åˆ¶è¦†ç›–ç‡è¶‹åŠ¿
        ax.plot(df['timestamp'], df['coverage_percent'],
                marker='o', linewidth=2, markersize=4,
                color='#2ecc71', label='æµ‹è¯•è¦†ç›–ç‡')

        # æ·»åŠ ç›®æ ‡çº¿
        if len(df) > 0:
            target_40 = 40.0
            target_80 = 80.0
            ax.axhline(y=target_40, color='orange', linestyle='--',
                      alpha=0.7, label='å¼€å‘ç›®æ ‡ (40%)')
            ax.axhline(y=target_80, color='red', linestyle='--',
                      alpha=0.7, label='ç”Ÿäº§ç›®æ ‡ (80%)')

        # æ ‡æ³¨é‡è¦ç‚¹
        if len(df) > 1:
            # æ‰¾åˆ°æœ€å¤§æå‡
            df['coverage_diff'] = df['coverage_percent'].diff()
            max_improvement = df['coverage_diff'].max()
            if max_improvement > 0:
                max_row = df[df['coverage_diff'] == max_improvement].iloc[0]
                ax.annotate(f'æœ€å¤§æå‡\n+{max_improvement:.1f}%',
                           xy=(max_row['timestamp'], max_row['coverage_percent']),
                           xytext=(10, 30), textcoords='offset points',
                           bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),
                           arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))

        ax.set_xlabel('æ—¶é—´')
        ax.set_ylabel('è¦†ç›–ç‡ (%)')
        ax.set_title('æµ‹è¯•è¦†ç›–ç‡è¶‹åŠ¿åˆ†æ')
        ax.legend()
        ax.grid(True, alpha=0.3)

        # æ ¼å¼åŒ–xè½´
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        ax.xaxis.set_major_locator(mdates.WeekdayLocator())
        plt.xticks(rotation=45)

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… è¦†ç›–ç‡è¶‹åŠ¿å›¾å·²ç”Ÿæˆ: {output_path}")

    def generate_quality_score_trend(self, df: pd.DataFrame, output_path: str) -> None:
        """ç”Ÿæˆè´¨é‡åˆ†æ•°è¶‹åŠ¿å›¾"""
        if df.empty or 'quality_score' not in df.columns:
            return

        fig, ax = plt.subplots(figsize=(12, 6))

        # ç»˜åˆ¶è´¨é‡åˆ†æ•°è¶‹åŠ¿
        ax.plot(df['timestamp'], df['quality_score'],
                marker='s', linewidth=2, markersize=4,
                color='#3498db', label='è´¨é‡åˆ†æ•°')

        # æ·»åŠ ç›®æ ‡çº¿å’Œè­¦æˆ’çº¿
        target_scores = [80, 60, 40]
        colors = ['green', 'orange', 'red']
        labels = ['ä¼˜ç§€ (80)', 'è‰¯å¥½ (60)', 'åŠæ ¼ (40)']

        for score, color, label in zip(target_scores, colors, labels):
            ax.axhline(y=score, color=color, linestyle='--',
                      alpha=0.7, label=label)

        ax.set_xlabel('æ—¶é—´')
        ax.set_ylabel('è´¨é‡åˆ†æ•°')
        ax.set_title('é¡¹ç›®è´¨é‡åˆ†æ•°è¶‹åŠ¿åˆ†æ')
        ax.legend()
        ax.grid(True, alpha=0.3)

        # æ ¼å¼åŒ–xè½´
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        ax.xaxis.set_major_locator(mdates.WeekdayLocator())
        plt.xticks(rotation=45)

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… è´¨é‡åˆ†æ•°è¶‹åŠ¿å›¾å·²ç”Ÿæˆ: {output_path}")

    def generate_comprehensive_trend(self, df: pd.DataFrame, output_path: str) -> None:
        """ç”Ÿæˆç»¼åˆè´¨é‡è¶‹åŠ¿å›¾"""
        if df.empty:
            return

        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

        # 1. è¦†ç›–ç‡è¶‹åŠ¿
        if 'coverage_percent' in df.columns:
            ax1.plot(df['timestamp'], df['coverage_percent'],
                    marker='o', color='#2ecc71', linewidth=2)
            ax1.axhline(y=40, color='orange', linestyle='--', alpha=0.7)
            ax1.set_title('æµ‹è¯•è¦†ç›–ç‡')
            ax1.set_ylabel('è¦†ç›–ç‡ (%)')
            ax1.grid(True, alpha=0.3)

        # 2. è´¨é‡åˆ†æ•°è¶‹åŠ¿
        if 'quality_score' in df.columns:
            ax2.plot(df['timestamp'], df['quality_score'],
                    marker='s', color='#3498db', linewidth=2)
            ax2.axhline(y=60, color='orange', linestyle='--', alpha=0.7)
            ax2.set_title('è´¨é‡åˆ†æ•°')
            ax2.set_ylabel('åˆ†æ•°')
            ax2.grid(True, alpha=0.3)

        # 3. æµ‹è¯•æ–‡ä»¶æ•°é‡
        if 'auto_generated_tests' in df.columns:
            ax3.plot(df['timestamp'], df['auto_generated_tests'],
                    marker='^', color='#e74c3c', linewidth=2)
            ax3.set_title('è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ–‡ä»¶')
            ax3.set_ylabel('æ–‡ä»¶æ•°é‡')
            ax3.grid(True, alpha=0.3)

        # 4. AIä¿®å¤æˆåŠŸç‡
        if 'ai_fix_success_rate' in df.columns:
            ax4.plot(df['timestamp'], df['ai_fix_success_rate'],
                    marker='d', color='#9b59b6', linewidth=2)
            ax4.set_title('AIä¿®å¤æˆåŠŸç‡')
            ax4.set_ylabel('æˆåŠŸç‡ (%)')
            ax4.grid(True, alpha=0.3)

        # æ ¼å¼åŒ–æ‰€æœ‰å­å›¾çš„xè½´
        for ax in [ax1, ax2, ax3, ax4]:
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)

        plt.suptitle('é¡¹ç›®è´¨é‡ç»¼åˆè¶‹åŠ¿åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… ç»¼åˆè´¨é‡è¶‹åŠ¿å›¾å·²ç”Ÿæˆ: {output_path}")

    def calculate_trend_metrics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è®¡ç®—è¶‹åŠ¿æŒ‡æ ‡"""
        if df.empty:
            return {}

        metrics = {}

        # è¦†ç›–ç‡è¶‹åŠ¿
        if 'coverage_percent' in df.columns and len(df) > 1:
            coverage_values = df['coverage_percent'].dropna()
            if len(coverage_values) > 1:
                first_value = coverage_values.iloc[0]
                last_value = coverage_values.iloc[-1]
                total_change = last_value - first_value
                avg_value = coverage_values.mean()

                # è®¡ç®—è¶‹åŠ¿æ–œç‡
                x = pd.to_numeric(df['timestamp']).astype('int64') // 10**9
                y = coverage_values
                slope = pd.Series([x[i]*y[i] for i in range(len(x))]).cov(pd.Series(x)) / x.var()

                metrics['coverage'] = {
                    'first_value': first_value,
                    'last_value': last_value,
                    'total_change': total_change,
                    'change_percentage': (total_change / first_value * 100) if first_value > 0 else 0,
                    'average_value': avg_value,
                    'trend_slope': slope,
                    'trend_direction': 'improving' if slope > 0 else 'declining' if slope < 0 else 'stable'
                }

        # è´¨é‡åˆ†æ•°è¶‹åŠ¿
        if 'quality_score' in df.columns and len(df) > 1:
            quality_values = df['quality_score'].dropna()
            if len(quality_values) > 1:
                first_value = quality_values.iloc[0]
                last_value = quality_values.iloc[-1]
                total_change = last_value - first_value
                avg_value = quality_values.mean()

                metrics['quality_score'] = {
                    'first_value': first_value,
                    'last_value': last_value,
                    'total_change': total_change,
                    'change_percentage': (total_change / first_value * 100) if first_value > 0 else 0,
                    'average_value': avg_value
                }

        return metrics

    def generate_trend_report(self, df: pd.DataFrame, metrics: Dict[str, Any], output_path: str) -> None:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†ææŠ¥å‘Š"""
        report_lines = []
        report_lines.append("# ğŸ“ˆ è´¨é‡è¶‹åŠ¿åˆ†ææŠ¥å‘Š")
        report_lines.append("")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"**æ•°æ®æœŸé—´**: {df['timestamp'].min().strftime('%Y-%m-%d')} è‡³ {df['timestamp'].max().strftime('%Y-%m-%d')}")
        report_lines.append(f"**æ•°æ®ç‚¹æ•°**: {len(df)}")
        report_lines.append("")

        # æ€»ä½“è¶‹åŠ¿æ‘˜è¦
        report_lines.append("## ğŸ“Š è¶‹åŠ¿æ‘˜è¦")
        report_lines.append("")

        if 'coverage' in metrics:
            cov_metrics = metrics['coverage']
            trend_emoji = "ğŸ“ˆ" if cov_metrics['trend_direction'] == 'improving' else "ğŸ“‰" if cov_metrics['trend_direction'] == 'declining' else "â¡ï¸"

            report_lines.append(f"### ğŸ§ª æµ‹è¯•è¦†ç›–ç‡è¶‹åŠ¿ {trend_emoji}")
            report_lines.append(f"- **åˆå§‹å€¼**: {cov_metrics['first_value']:.1f}%")
            report_lines.append(f"- **å½“å‰å€¼**: {cov_metrics['last_value']:.1f}%")
            report_lines.append(f"- **æ€»å˜åŒ–**: {cov_metrics['total_change']:+.1f}% ({cov_metrics['change_percentage']:+.1f}%)")
            report_lines.append(f"- **å¹³å‡å€¼**: {cov_metrics['average_value']:.1f}%")
            report_lines.append(f"- **è¶‹åŠ¿æ–¹å‘**: {cov_metrics['trend_direction']}")
            report_lines.append("")

        if 'quality_score' in metrics:
            qs_metrics = metrics['quality_score']
            report_lines.append(f"### ğŸ¯ è´¨é‡åˆ†æ•°è¶‹åŠ¿")
            report_lines.append(f"- **åˆå§‹å€¼**: {qs_metrics['first_value']:.1f}/100")
            report_lines.append(f"- **å½“å‰å€¼**: {qs_metrics['last_value']:.1f}/100")
            report_lines.append(f"- **æ€»å˜åŒ–**: {qs_metrics['total_change']:+.1f} ({qs_metrics['change_percentage']:+.1f}%)")
            report_lines.append(f"- **å¹³å‡å€¼**: {qs_metrics['average_value']:.1f}/100")
            report_lines.append("")

        # å…³é”®å‘ç°
        report_lines.append("## ğŸ” å…³é”®å‘ç°")
        report_lines.append("")

        if 'coverage' in metrics:
            cov_metrics = metrics['coverage']
            if cov_metrics['total_change'] > 5:
                report_lines.append("- âœ… **è¦†ç›–ç‡æ˜¾è‘—æå‡**: æµ‹è¯•è¦†ç›–ç‡æå‡äº† {:.1f}%ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„è´¨é‡æ”¹è¿›è¶‹åŠ¿".format(cov_metrics['total_change']))
            elif cov_metrics['total_change'] < -5:
                report_lines.append("- âš ï¸  **è¦†ç›–ç‡ä¸‹é™**: æµ‹è¯•è¦†ç›–ç‡ä¸‹é™äº† {:.1f}%ï¼Œéœ€è¦å…³æ³¨æµ‹è¯•è´¨é‡".format(abs(cov_metrics['total_change'])))
            else:
                report_lines.append("- â¡ï¸ **è¦†ç›–ç‡ç¨³å®š**: æµ‹è¯•è¦†ç›–ç‡å˜åŒ–è¾ƒå°ï¼Œä¿æŒåœ¨ {:.1f}% å·¦å³".format(cov_metrics['average_value']))

        # å»ºè®®å’Œæ”¹è¿›æªæ–½
        report_lines.append("")
        report_lines.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
        report_lines.append("")

        if 'coverage' in metrics and cov_metrics['last_value'] < 40:
            report_lines.append("- **ç»§ç»­æå‡è¦†ç›–ç‡**: å½“å‰è¦†ç›–ç‡ä¸º {:.1f}%ï¼Œå»ºè®®ç»§ç»­è¡¥å……æµ‹è¯•ä»¥è¾¾åˆ°40%çš„å¼€å‘ç›®æ ‡".format(cov_metrics['last_value']))

        if 'quality_score' in metrics:
            qs_metrics = metrics['quality_score']
            if qs_metrics['last_value'] < 60:
                report_lines.append("- **æå‡ä»£ç è´¨é‡**: å½“å‰è´¨é‡åˆ†æ•°ä¸º {:.1f}/100ï¼Œå»ºè®®åŠ å¼ºä»£ç è´¨é‡æ£€æŸ¥å’Œé‡æ„".format(qs_metrics['last_value']))

        report_lines.append("- **å®šæœŸç›‘æ§**: å»ºè®®ä¿æŒæ¯æ—¥è´¨é‡æ•°æ®æ”¶é›†ï¼ŒæŒç»­è·Ÿè¸ªæ”¹è¿›æ•ˆæœ")
        report_lines.append("- **è¶‹åŠ¿åˆ†æ**: å®šæœŸåˆ†æè´¨é‡è¶‹åŠ¿ï¼ŒåŠæ—¶å‘ç°æ½œåœ¨é—®é¢˜")

        # æ•°æ®è´¨é‡è¯´æ˜
        report_lines.append("")
        report_lines.append("## ğŸ“‹ æ•°æ®è¯´æ˜")
        report_lines.append("")
        report_lines.append("- æ•°æ®æ¥æº: è‡ªåŠ¨åŒ–è´¨é‡ç³»ç»Ÿæ¯æ—¥æ”¶é›†")
        report_lines.append("- æ›´æ–°é¢‘ç‡: æ¯æ—¥è‡ªåŠ¨æ›´æ–°")
        report_lines.append("- æ•°æ®å®Œæ•´æ€§: åŸºäºç°æœ‰å¿«ç…§æ•°æ®ï¼Œå¯èƒ½å­˜åœ¨ç¼ºå¤±")
        report_lines.append("- å¯è§†åŒ–å›¾è¡¨: è§ç”Ÿæˆçš„PNGæ–‡ä»¶")

        # ä¿å­˜æŠ¥å‘Š
        report_content = "\n".join(report_lines)
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"âœ… è¶‹åŠ¿åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜è¶‹åŠ¿æŠ¥å‘Šå¤±è´¥: {e}")

    def analyze_trends(self, history_path: str, output_dir: str = ".") -> None:
        """æ‰§è¡Œå®Œæ•´çš„è¶‹åŠ¿åˆ†æ"""
        print("ğŸ” å¼€å§‹è´¨é‡è¶‹åŠ¿åˆ†æ...")

        # åŠ è½½æ•°æ®
        df = self.load_quality_history(history_path)
        if df.empty:
            print("âŒ æ— æ³•åŠ è½½è´¨é‡å†å²æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
            return

        # æ¸…ç†æ•°æ®
        df = self.clean_data(df)
        if df.empty:
            print("âŒ æ•°æ®æ¸…ç†åæ— æœ‰æ•ˆæ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
            return

        print(f"ğŸ“Š åŠ è½½äº† {len(df)} ä¸ªè´¨é‡æ•°æ®ç‚¹")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆå„ç§å›¾è¡¨
        self.generate_coverage_trend(df, str(output_path / "coverage_trend.png"))
        self.generate_quality_score_trend(df, str(output_path / "quality_score_trend.png"))
        self.generate_comprehensive_trend(df, str(output_path / "comprehensive_trends.png"))

        # è®¡ç®—è¶‹åŠ¿æŒ‡æ ‡
        metrics = self.calculate_trend_metrics(df)

        # ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š
        self.generate_trend_report(df, metrics, str(output_path / "quality-trends-report.md"))

        print("âœ… è´¨é‡è¶‹åŠ¿åˆ†æå®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆè´¨é‡è¶‹åŠ¿åˆ†ææŠ¥å‘Š')
    parser.add_argument('history_path', help='è´¨é‡å†å²CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', '-o', default='.',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)')

    args = parser.parse_args()

    analyzer = QualityTrendAnalyzer()
    analyzer.analyze_trends(args.history_path, args.output_dir)


if __name__ == "__main__":
    main()