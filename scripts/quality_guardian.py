#!/usr/bin/env python3
"""
è´¨é‡å®ˆæŠ¤å·¥å…·
Quality Guardian

é›†æˆçš„ä»£ç è´¨é‡å®ˆæŠ¤ç³»ç»Ÿï¼Œæä¾›å…¨é¢çš„è´¨é‡æ£€æŸ¥ã€ä¿®å¤å’Œç›‘æ§åŠŸèƒ½
"""

import os
import sys
import json
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging

# å¯¼å…¥å…¶ä»–ä¿®å¤å·¥å…·
try:
    from quality_standards_optimizer import QualityStandardsOptimizer
    from smart_quality_fixer import SmartQualityFixer
except ImportError as e:
    print(f"å¯¼å…¥å·¥å…·æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class QualityGuardian:
    """è´¨é‡å®ˆæŠ¤è€…"""

    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(__file__).parent.parent
        self.monitoring_dir = self.project_root / "monitoring-data"
        self.reports_dir = self.project_root / "quality-reports"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.monitoring_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–ç»„ä»¶
        self.optimizer = QualityStandardsOptimizer(self.project_root)
        self.fixer = SmartQualityFixer(self.project_root)

        # è´¨é‡çŠ¶æ€
        self.quality_status = {
            "timestamp": datetime.now().isoformat(),
            "overall_score": 0,
            "coverage": 0,
            "code_quality": 0,
            "test_health": 0,
            "security": 0,
            "recommendations": [],
            "action_items": []
        }

    def run_full_quality_check(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„è´¨é‡æ£€æŸ¥"""
        print("ğŸ›¡ï¸ è´¨é‡å®ˆæŠ¤ç³»ç»Ÿ")
        print("=" * 60)
        print("ğŸ“Š æ‰§è¡Œå…¨é¢è´¨é‡æ£€æŸ¥...")
        print()

        # 1. åŸºç¡€è´¨é‡æŒ‡æ ‡æ”¶é›†
        print("1ï¸âƒ£ æ”¶é›†è´¨é‡æŒ‡æ ‡...")
        metrics = self._collect_quality_metrics()

        # 2. ä»£ç è´¨é‡åˆ†æ
        print("2ï¸âƒ£ åˆ†æä»£ç è´¨é‡...")
        code_quality = self._analyze_code_quality()

        # 3. æµ‹è¯•å¥åº·åº¦æ£€æŸ¥
        print("3ï¸âƒ£ æ£€æŸ¥æµ‹è¯•å¥åº·åº¦...")
        test_health = self._check_test_health()

        # 4. å®‰å…¨æ€§æ£€æŸ¥
        print("4ï¸âƒ£ æ‰§è¡Œå®‰å…¨æ€§æ£€æŸ¥...")
        security = self._check_security()

        # 5. ç»¼åˆè¯„ä¼°
        print("5ï¸âƒ£ ç»¼åˆè´¨é‡è¯„ä¼°...")
        self._assess_overall_quality(metrics, code_quality, test_health, security)

        # 6. ç”ŸæˆæŠ¥å‘Š
        print("6ï¸âƒ£ ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
        report = self._generate_quality_report()

        # 7. æä¾›è¡ŒåŠ¨å»ºè®®
        print("7ï¸âƒ£ ç”Ÿæˆè¡ŒåŠ¨å»ºè®®...")
        self._generate_action_items()

        print()
        print("âœ… è´¨é‡æ£€æŸ¥å®Œæˆï¼")
        self._print_quality_summary()

        return self.quality_status

    def _collect_quality_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†åŸºç¡€è´¨é‡æŒ‡æ ‡"""
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "coverage": 0,
            "ruff_errors": 0,
            "mypy_errors": 0,
            "test_count": 0,
            "test_pass_rate": 0,
            "files_count": 0
        }

        # è¦†ç›–ç‡
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest", "tests/unit/api/test_health.py",
                "--cov=src/", "--cov-report=json", "--tb=short", "-q"
            ], capture_output=True, text=True, timeout=60)

            coverage_file = self.project_root / "coverage.json"
            if coverage_file.exists():
                with open(coverage_file) as f:
                    coverage_data = json.load(f)
                metrics["coverage"] = coverage_data.get("totals", {}).get("percent_covered", 0)
        except Exception as e:
            logger.warning(f"è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥: {e}")

        # Ruffé”™è¯¯
        try:
            result = subprocess.run([
                "ruff", "check", "src/", "--output-format=json"
            ], capture_output=True, text=True, timeout=30)
            if result.stdout.strip():
                ruff_data = json.loads(result.stdout)
                metrics["ruff_errors"] = len(ruff_data)
        except Exception as e:
            logger.warning(f"Ruffæ£€æŸ¥å¤±è´¥: {e}")

        # MyPyé”™è¯¯
        try:
            result = subprocess.run([
                sys.executable, "-m", "mypy", "src/", "--show-error-codes"
            ], capture_output=True, text=True, timeout=60)
            mypy_output = result.stderr
            metrics["mypy_errors"] = mypy_output.count("error:")
        except Exception as e:
            logger.warning(f"MyPyæ£€æŸ¥å¤±è´¥: {e}")

        # æ–‡ä»¶æ•°é‡
        metrics["files_count"] = len(list(self.project_root.glob("src/**/*.py")))

        self.quality_status.update(metrics)
        return metrics

    def _analyze_code_quality(self) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        quality = {
            "score": 0,
            "complexity": "unknown",
            "maintainability": "unknown",
            "duplication": "unknown",
            "issues": []
        }

        # åŸºäºRuffå’ŒMyPyç»“æœè®¡ç®—è´¨é‡åˆ†æ•°
        ruff_errors = self.quality_status.get("ruff_errors", 0)
        mypy_errors = self.quality_status.get("mypy_errors", 0)

        # è´¨é‡åˆ†æ•°è®¡ç®— (0-10)
        ruff_score = max(0, 10 - ruff_errors * 0.5)
        mypy_score = max(0, 10 - mypy_errors * 0.01)
        quality["score"] = (ruff_score + mypy_score) / 2

        # è¯†åˆ«è´¨é‡é—®é¢˜
        if ruff_errors > 20:
            quality["issues"].append("Ruffä»£ç é—®é¢˜è¿‡å¤šï¼Œéœ€è¦ä»£ç æ¸…ç†")
        if mypy_errors > 100:
            quality["issues"].append("MyPyç±»å‹é”™è¯¯è¿‡å¤šï¼Œéœ€è¦ç±»å‹æ³¨è§£æ”¹è¿›")

        self.quality_status["code_quality"] = quality["score"]
        return quality

    def _check_test_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥æµ‹è¯•å¥åº·åº¦"""
        health = {
            "score": 0,
            "coverage_adequacy": "insufficient",
            "test_distribution": "unknown",
            "flaky_tests": 0,
            "recommendations": []
        }

        coverage = self.quality_status.get("coverage", 0)

        # è¦†ç›–ç‡è¯„ä¼°
        if coverage >= 80:
            health["coverage_adequacy"] = "excellent"
            health["score"] = 10
        elif coverage >= 60:
            health["coverage_adequacy"] = "good"
            health["score"] = 8
        elif coverage >= 40:
            health["coverage_adequacy"] = "moderate"
            health["score"] = 6
        elif coverage >= 20:
            health["coverage_adequacy"] = "insufficient"
            health["score"] = 4
        else:
            health["coverage_adequacy"] = "poor"
            health["score"] = 2

        # ç”Ÿæˆå»ºè®®
        if coverage < 40:
            health["recommendations"].append("æµ‹è¯•è¦†ç›–ç‡è¿‡ä½ï¼Œéœ€è¦å¢åŠ æµ‹è¯•ç”¨ä¾‹")
        if coverage < 60:
            health["recommendations"].append("é‡ç‚¹å…³æ³¨æ ¸å¿ƒä¸šåŠ¡é€»è¾‘çš„æµ‹è¯•è¦†ç›–")

        self.quality_status["test_health"] = health["score"]
        return health

    def _check_security(self) -> Dict[str, Any]:
        """æ£€æŸ¥å®‰å…¨æ€§"""
        security = {
            "score": 0,
            "vulnerabilities": 0,
            "secrets_found": 0,
            "dependencies_risk": "unknown",
            "recommendations": []
        }

        # åŸºç¡€å®‰å…¨æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
        try:
            # æ£€æŸ¥æ˜æ˜¾çš„å®‰å…¨é—®é¢˜
            result = subprocess.run([
                "bandit", "-r", "src/", "-f", "json"
            ], capture_output=True, text=True, timeout=30)

            if result.stdout.strip():
                try:
                    bandit_data = json.loads(result.stdout)
                    security["vulnerabilities"] = len(bandit_data.get("results", []))
                except:
                    pass
        except Exception as e:
            logger.warning(f"å®‰å…¨æ£€æŸ¥å¤±è´¥: {e}")

        # å®‰å…¨åˆ†æ•°è®¡ç®—
        if security["vulnerabilities"] == 0:
            security["score"] = 10
        elif security["vulnerabilities"] <= 5:
            security["score"] = 8
        elif security["vulnerabilities"] <= 10:
            security["score"] = 6
        else:
            security["score"] = 4

        if security["vulnerabilities"] > 0:
            security["recommendations"].append("å‘ç°å®‰å…¨æ¼æ´ï¼Œéœ€è¦åŠæ—¶ä¿®å¤")

        self.quality_status["security"] = security["score"]
        return security

    def _assess_overall_quality(self, metrics, code_quality, test_health, security):
        """è¯„ä¼°ç»¼åˆè´¨é‡"""
        # è®¡ç®—ç»¼åˆåˆ†æ•°
        weights = {
            "code_quality": 0.3,
            "test_health": 0.4,
            "security": 0.2,
            "coverage": 0.1
        }

        overall_score = (
            code_quality["score"] * weights["code_quality"] +
            test_health["score"] * weights["test_health"] +
            security["score"] * weights["security"] +
            (metrics.get("coverage", 0) / 10) * weights["coverage"]
        )

        self.quality_status["overall_score"] = round(overall_score, 2)

    def _generate_quality_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "quality_status": self.quality_status,
            "trends": self._analyze_quality_trends(),
            "benchmarks": self._compare_with_benchmarks()
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.reports_dir / f"quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return report

    def _analyze_quality_trends(self) -> Dict[str, Any]:
        """åˆ†æè´¨é‡è¶‹åŠ¿"""
        trends = {
            "coverage_trend": "stable",
            "quality_trend": "stable",
            "recommendation": "æŒç»­ç›‘æ§"
        }

        # æŸ¥æ‰¾å†å²æ•°æ®
        history_files = sorted(self.monitoring_dir.glob("quality_optimization_report.json"))
        if len(history_files) >= 2:
            try:
                with open(history_files[-1]) as f:
                    latest_data = json.load(f)
                with open(history_files[-2]) as f:
                    previous_data = json.load(f)

                latest_coverage = latest_data.get("current_status", {}).get("coverage", 0)
                previous_coverage = previous_data.get("current_status", {}).get("coverage", 0)

                if latest_coverage > previous_coverage + 2:
                    trends["coverage_trend"] = "improving"
                elif latest_coverage < previous_coverage - 2:
                    trends["coverage_trend"] = "declining"

            except Exception as e:
                logger.warning(f"è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")

        return trends

    def _compare_with_benchmarks(self) -> Dict[str, Any]:
        """ä¸åŸºå‡†æ¯”è¾ƒ"""
        benchmarks = {
            "industry_average": {
                "coverage": 75,
                "code_quality": 7,
                "security": 8
            },
            "project_targets": {
                "coverage": 40,
                "code_quality": 8,
                "security": 9
            }
        }

        current = {
            "coverage": self.quality_status.get("coverage", 0),
            "code_quality": self.quality_status.get("code_quality", 0),
            "security": self.quality_status.get("security", 0)
        }

        comparison = {
            "vs_industry": {},
            "vs_targets": {}
        }

        for metric in ["coverage", "code_quality", "security"]:
            comparison["vs_industry"][metric] = current[metric] - benchmarks["industry_average"][metric]
            comparison["vs_targets"][metric] = current[metric] - benchmarks["project_targets"][metric]

        return comparison

    def _generate_action_items(self):
        """ç”Ÿæˆè¡ŒåŠ¨é¡¹"""
        action_items = []

        # åŸºäºè´¨é‡åˆ†æ•°ç”Ÿæˆè¡ŒåŠ¨é¡¹
        overall_score = self.quality_status["overall_score"]
        coverage = self.quality_status.get("coverage", 0)
        code_quality = self.quality_status.get("code_quality", 0)
        mypy_errors = self.quality_status.get("mypy_errors", 0)

        if overall_score < 5:
            action_items.append({
                "priority": "HIGH",
                "category": "overall",
                "action": "æ•´ä½“è´¨é‡éœ€è¦é‡å¤§æ”¹è¿›",
                "details": "å»ºè®®åˆ¶å®šè¯¦ç»†çš„è´¨é‡æ”¹è¿›è®¡åˆ’"
            })

        if coverage < 20:
            action_items.append({
                "priority": "HIGH",
                "category": "coverage",
                "action": "æå‡æµ‹è¯•è¦†ç›–ç‡",
                "details": f"å½“å‰è¦†ç›–ç‡{coverage:.1f}%ï¼Œå»ºè®®ä¼˜å…ˆä¸ºæ ¸å¿ƒæ¨¡å—æ·»åŠ æµ‹è¯•"
            })

        if mypy_errors > 500:
            action_items.append({
                "priority": "HIGH",
                "category": "type_safety",
                "action": "ä¿®å¤MyPyç±»å‹é”™è¯¯",
                "details": f"å½“å‰æœ‰{mypy_errors}ä¸ªç±»å‹é”™è¯¯ï¼Œå»ºè®®åˆ†æ‰¹ä¿®å¤"
            })

        if code_quality < 6:
            action_items.append({
                "priority": "MEDIUM",
                "category": "code_quality",
                "action": "æ”¹è¿›ä»£ç è´¨é‡",
                "details": "è¿è¡Œä»£ç æ ¼å¼åŒ–å’Œæ¸…ç†å·¥å…·"
            })

        # æ·»åŠ é¢„é˜²æ€§å»ºè®®
        action_items.extend([
            {
                "priority": "LOW",
                "category": "prevention",
                "action": "å»ºç«‹è´¨é‡é—¨ç¦",
                "details": "åœ¨CI/CDä¸­é›†æˆè´¨é‡æ£€æŸ¥"
            },
            {
                "priority": "LOW",
                "category": "monitoring",
                "action": "å®šæœŸè´¨é‡ç›‘æ§",
                "details": "å»ºç«‹å®šæœŸè´¨é‡æ£€æŸ¥å’ŒæŠ¥å‘Šæœºåˆ¶"
            }
        ])

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"HIGH": 0, "MEDIUM": 1, "LOW": 2}
        action_items.sort(key=lambda x: priority_order.get(x["priority"], 3))

        self.quality_status["action_items"] = action_items
        self.quality_status["recommendations"] = [item["action"] for item in action_items[:5]]

    def _print_quality_summary(self):
        """æ‰“å°è´¨é‡æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š è´¨é‡æ£€æŸ¥æ‘˜è¦")
        print("=" * 60)

        print(f"ğŸ“ˆ ç»¼åˆè´¨é‡åˆ†æ•°: {self.quality_status['overall_score']}/10")
        print(f"ğŸ§ª æµ‹è¯•è¦†ç›–ç‡: {self.quality_status.get('coverage', 0):.1f}%")
        print(f"ğŸ” ä»£ç è´¨é‡åˆ†æ•°: {self.quality_status.get('code_quality', 0):.1f}/10")
        print(f"ğŸ›¡ï¸ å®‰å…¨åˆ†æ•°: {self.quality_status.get('security', 0):.1f}/10")

        print("\nğŸ¯ å…³é”®æŒ‡æ ‡:")
        print(f"  - Ruffé”™è¯¯: {self.quality_status.get('ruff_errors', 0)}")
        print(f"  - MyPyé”™è¯¯: {self.quality_status.get('mypy_errors', 0)}")
        print(f"  - æ–‡ä»¶æ•°é‡: {self.quality_status.get('files_count', 0)}")

        if self.quality_status.get("recommendations"):
            print("\nğŸ’¡ ä¸»è¦å»ºè®®:")
            for rec in self.quality_status["recommendations"][:3]:
                print(f"  â€¢ {rec}")

        if self.quality_status.get("action_items"):
            print("\nğŸ“‹ é«˜ä¼˜å…ˆçº§è¡ŒåŠ¨é¡¹:")
            high_priority_items = [item for item in self.quality_status["action_items"] if item["priority"] == "HIGH"]
            for item in high_priority_items[:3]:
                print(f"  ğŸš¨ {item['action']}: {item['details']}")

        print("\n" + "=" * 60)

    def run_auto_fix(self, fix_types: List[str] = None) -> Dict[str, Any]:
        """è¿è¡Œè‡ªåŠ¨ä¿®å¤"""
        if fix_types is None:
            fix_types = ["syntax", "imports", "mypy", "ruff", "tests"]

        print("ğŸ”§ å¯åŠ¨è‡ªåŠ¨ä¿®å¤...")
        fix_results = {}

        if "syntax" in fix_types:
            print("ä¿®å¤è¯­æ³•é”™è¯¯...")
            fix_results["syntax"] = self.fixer.fix_syntax_errors()

        if "imports" in fix_types:
            print("ä¿®å¤å¯¼å…¥é”™è¯¯...")
            fix_results["imports"] = self.fixer.fix_import_errors()

        if "mypy" in fix_types:
            print("ä¿®å¤MyPyé”™è¯¯...")
            fix_results["mypy"] = self.fixer.fix_mypy_errors()

        if "ruff" in fix_types:
            print("ä¿®å¤Ruffé—®é¢˜...")
            fix_results["ruff"] = self.fixer.fix_ruff_issues()

        if "tests" in fix_types:
            print("ä¿®å¤æµ‹è¯•é—®é¢˜...")
            fix_results["tests"] = self.fixer.fix_test_issues()

        total_fixes = sum(fix_results.values())
        print(f"\nâœ… è‡ªåŠ¨ä¿®å¤å®Œæˆï¼æ€»ä¿®å¤æ•°: {total_fixes}")

        return fix_results

    def optimize_quality_standards(self) -> bool:
        """ä¼˜åŒ–è´¨é‡æ ‡å‡†"""
        print("ğŸ¯ ä¼˜åŒ–è´¨é‡æ ‡å‡†...")
        return self.optimizer.run_optimization()

    def run_guardian_cycle(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å®ˆæŠ¤å‘¨æœŸ"""
        print("ğŸ›¡ï¸ å¯åŠ¨è´¨é‡å®ˆæŠ¤å‘¨æœŸ")
        print("=" * 60)

        # 1. è´¨é‡æ£€æŸ¥
        quality_status = self.run_full_quality_check()

        # 2. è‡ªåŠ¨ä¿®å¤ï¼ˆå¯é€‰ï¼‰
        if quality_status["overall_score"] < 6:
            print("\nğŸ”§ è´¨é‡åˆ†æ•°è¾ƒä½ï¼Œå¯åŠ¨è‡ªåŠ¨ä¿®å¤...")
            fix_results = self.run_auto_fix()
            quality_status["auto_fixes"] = fix_results

        # 3. æ ‡å‡†ä¼˜åŒ–ï¼ˆå¦‚éœ€è¦ï¼‰
        if quality_status.get("mypy_errors", 0) > 1000 or quality_status.get("coverage", 0) < 15:
            print("\nğŸ¯ è´¨é‡æ ‡å‡†éœ€è¦è°ƒæ•´...")
            optimization_success = self.optimize_quality_standards()
            quality_status["standards_optimized"] = optimization_success

        return quality_status


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è´¨é‡å®ˆæŠ¤å·¥å…·")
    parser.add_argument("--project-root", type=Path, help="é¡¹ç›®æ ¹ç›®å½•")
    parser.add_argument("--check-only", action="store_true", help="ä»…æ‰§è¡Œè´¨é‡æ£€æŸ¥")
    parser.add_argument("--fix-only", action="store_true", help="ä»…æ‰§è¡Œè‡ªåŠ¨ä¿®å¤")
    parser.add_argument("--optimize-only", action="store_true", help="ä»…ä¼˜åŒ–è´¨é‡æ ‡å‡†")
    parser.add_argument("--fix-types", nargs="+", choices=["syntax", "imports", "mypy", "ruff", "tests"], help="æŒ‡å®šä¿®å¤ç±»å‹")

    args = parser.parse_args()

    guardian = QualityGuardian(args.project_root)

    if args.check_only:
        guardian.run_full_quality_check()
    elif args.fix_only:
        guardian.run_auto_fix(args.fix_types)
    elif args.optimize_only:
        guardian.optimize_quality_standards()
    else:
        # è¿è¡Œå®Œæ•´å®ˆæŠ¤å‘¨æœŸ
        guardian.run_guardian_cycle()


if __name__ == "__main__":
    main()