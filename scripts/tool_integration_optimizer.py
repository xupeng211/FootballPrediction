#!/usr/bin/env python3
"""
å·¥å…·é›†æˆä¼˜åŒ–å™¨
ä¼˜åŒ–å„ä¸ªè„šæœ¬å·¥å…·ä¹‹é—´çš„ä¾èµ–å…³ç³»å’Œé›†æˆ
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Set
from dataclasses import dataclass
import ast


@dataclass
class ToolInfo:
    """å·¥å…·ä¿¡æ¯"""
    name: str
    path: Path
    dependencies: List[str]
    dependents: List[str]
    functionality: str
    status: str  # working, broken, needs_improvement


class ToolIntegrationOptimizer:
    """å·¥å…·é›†æˆä¼˜åŒ–å™¨"""

    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(__file__).parent.parent
        self.scripts_dir = self.project_root / "scripts"
        self.src_dir = self.project_root / "src"
        self.tools: Dict[str, ToolInfo] = {}

    def discover_tools(self) -> Dict[str, ToolInfo]:
        """å‘ç°æ‰€æœ‰å·¥å…·è„šæœ¬"""
        print("ğŸ” å‘ç°å·¥å…·è„šæœ¬...")

        for script_file in self.scripts_dir.glob("*.py"):
            if script_file.name.startswith("__"):
                continue

            tool_info = self._analyze_tool(script_file)
            if tool_info:
                self.tools[tool_info.name] = tool_info
                print(f"   âœ… å‘ç°å·¥å…·: {tool_info.name}")

        return self.tools

    def _analyze_tool(self, script_path: Path) -> ToolInfo:
        """åˆ†æå·¥å…·è„šæœ¬"""
        try:
            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # è§£æAST
            tree = ast.parse(content)

            # æå–å¯¼å…¥å’Œä¾èµ–
            imports = self._extract_imports(tree)
            dependencies = self._identify_dependencies(imports)

            # æå–åŠŸèƒ½æè¿°
            functionality = self._extract_functionality(content)

            # æ£€æŸ¥å·¥å…·çŠ¶æ€
            status = self._check_tool_status(script_path)

            return ToolInfo(
                name=script_path.stem,
                path=script_path,
                dependencies=dependencies,
                dependents=[],  # ç¨åè®¡ç®—
                functionality=functionality,
                status=status
            )

        except Exception as e:
            print(f"âŒ åˆ†æå·¥å…·å¤±è´¥ {script_path}: {e}")
            return None

    def _extract_imports(self, tree: ast.AST) -> List[str]:
        """æå–å¯¼å…¥è¯­å¥"""
        imports = []

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)

        return imports

    def _identify_dependencies(self, imports: List[str]) -> List[str]:
        """è¯†åˆ«å·¥å…·ä¾èµ–"""
        dependencies = []

        # é¡¹ç›®å†…éƒ¨æ¨¡å—
        for imp in imports:
            if imp.startswith('src.'):
                dependencies.append(imp)
            elif imp in ['requests', 'pandas', 'numpy', 'aiohttp', 'psutil']:
                dependencies.append(imp)

        # å·¥å…·è„šæœ¬ä¾èµ–
        script_dependencies = ['coverage_improvement_executor', 'phase35_ai_coverage_master',
                             'integrated_coverage_improver', 'smart_quality_fixer',
                             'quality_guardian', 'create_api_tests', 'create_service_tests']

        for dep in script_dependencies:
            if dep in imports:
                dependencies.append(dep)

        return list(set(dependencies))

    def _extract_functionality(self, content: str) -> str:
        """æå–åŠŸèƒ½æè¿°"""
        lines = content.split('\n')

        # æŸ¥æ‰¾æ–‡æ¡£å­—ç¬¦ä¸²
        for line in lines:
            if line.strip().startswith('"""'):
                # æå–æ–‡æ¡£å­—ç¬¦ä¸²çš„ç¬¬ä¸€è¡Œ
                doc_start = line.find('"""') + 3
                doc_line = line[doc_start:].strip()
                if doc_line:
                    return doc_line
                break

        # æŸ¥æ‰¾æ³¨é‡Š
        for line in lines[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
            if line.strip().startswith('#') and 'å·¥å…·' in line:
                return line.strip().lstrip('#').strip()

        return "æœªçŸ¥åŠŸèƒ½"

    def _check_tool_status(self, script_path: Path) -> str:
        """æ£€æŸ¥å·¥å…·çŠ¶æ€"""
        try:
            # å°è¯•è¿è¡Œå·¥å…· --help æˆ– --version
            result = subprocess.run(
                [sys.executable, str(script_path), "--help"],
                capture_output=True,
                text=True,
                timeout=10,
                cwd=self.project_root
            )

            if result.returncode == 0:
                return "working"
            else:
                return "needs_improvement"

        except subprocess.TimeoutExpired:
            return "needs_improvement"
        except Exception:
            return "broken"

    def calculate_dependents(self):
        """è®¡ç®—å·¥å…·çš„ä¾èµ–å…³ç³»"""
        print("ğŸ”— è®¡ç®—ä¾èµ–å…³ç³»...")

        for tool_name, tool_info in self.tools.items():
            tool_info.dependents = []

        for tool_name, tool_info in self.tools.items():
            for dep in tool_info.dependencies:
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å·¥å…·ä¾èµ–æ­¤å·¥å…·
                for other_name, other_info in self.tools.items():
                    if other_name != tool_name and tool_name in other_info.dependencies:
                        tool_info.dependents.append(other_name)

    def analyze_integration(self) -> Dict[str, Any]:
        """åˆ†æå·¥å…·é›†æˆæƒ…å†µ"""
        print("ğŸ“Š åˆ†æå·¥å…·é›†æˆ...")

        # ç»Ÿè®¡å·¥å…·çŠ¶æ€
        status_counts = {}
        for tool in self.tools.values():
            status_counts[tool.status] = status_counts.get(tool.status, 0) + 1

        # æ‰¾å‡ºå…³é”®å·¥å…·ï¼ˆè¢«å…¶ä»–å·¥å…·ä¾èµ–ï¼‰
        critical_tools = [
            name for name, tool in self.tools.items()
            if len(tool.dependents) > 0
        ]

        # æ‰¾å‡ºå­¤ç«‹å·¥å…·ï¼ˆæ— ä¾èµ–ä¸”ä¸è¢«ä¾èµ–ï¼‰
        isolated_tools = [
            name for name, tool in self.tools.items()
            if len(tool.dependencies) == 0 and len(tool.dependents) == 0
        ]

        # åˆ†æä¾èµ–é“¾
        dependency_chains = self._find_dependency_chains()

        return {
            'total_tools': len(self.tools),
            'status_distribution': status_counts,
            'critical_tools': critical_tools,
            'isolated_tools': isolated_tools,
            'dependency_chains': dependency_chains,
            'tools': {name: {
                'path': str(tool.path),
                'dependencies': tool.dependencies,
                'dependents': tool.dependents,
                'functionality': tool.functionality,
                'status': tool.status
            } for name, tool in self.tools.items()}
        }

    def _find_dependency_chains(self) -> List[List[str]]:
        """æ‰¾å‡ºä¾èµ–é“¾"""
        chains = []

        for tool_name in self.tools:
            visited = set()
            path = []

            def dfs(current: str):
                if current in visited:
                    return

                visited.add(current)
                path.append(current)

                tool = self.tools.get(current)
                if tool:
                    for dep in tool.dependencies:
                        if dep in self.tools:
                            dfs(dep)

                if len(path) > 1:
                    chains.append(path.copy())

                path.pop()

            dfs(tool_name)

        # å»é‡å¹¶è¿‡æ»¤é•¿é“¾
        unique_chains = []
        for chain in chains:
            if len(chain) > 1 and chain not in unique_chains:
                unique_chains.append(chain)

        return unique_chains[:10]  # è¿”å›å‰10æ¡é“¾

    def generate_optimization_suggestions(self,
    analysis: Dict[str,
    Any]) -> List[Dict[str,
    Any]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # çŠ¶æ€ä¼˜åŒ–å»ºè®®
        broken_tools = [
            name for name, tool in self.tools.items()
            if tool.status == "broken"
        ]

        if broken_tools:
            suggestions.append({
                'priority': 'high',
                'category': 'ä¿®å¤æŸåå·¥å…·',
                'description': f'å‘ç°{len(broken_tools)}ä¸ªæŸåçš„å·¥å…·éœ€è¦ä¿®å¤',
                'items': broken_tools[:5]
            })

        # ä¾èµ–ä¼˜åŒ–å»ºè®®
        complex_tools = [
            name for name, tool in self.tools.items()
            if len(tool.dependencies) > 5
        ]

        if complex_tools:
            suggestions.append({
                'priority': 'medium',
                'category': 'ç®€åŒ–å¤æ‚ä¾èµ–',
                'description': f'å‘ç°{len(complex_tools)}ä¸ªå·¥å…·ä¾èµ–è¿‡å¤šæ¨¡å—',
                'items': complex_tools[:3]
            })

        # é›†æˆä¼˜åŒ–å»ºè®®
        if analysis['isolated_tools']:
            suggestions.append({
                'priority': 'low',
                'category': 'é›†æˆå­¤ç«‹å·¥å…·',
                'description': f'å‘ç°{len(analysis["isolated_tools"])}ä¸ªå­¤ç«‹å·¥å…·å¯ä»¥è€ƒè™‘é›†æˆ',
                'items': analysis['isolated_tools'][:5]
            })

        # å·¥ä½œæµå»ºè®®
        critical_tools = analysis['critical_tools']
        if critical_tools:
            suggestions.append({
                'priority': 'medium',
                'category': 'ä¼˜åŒ–å…³é”®å·¥å…·',
                'description': f'å‘ç°{len(critical_tools)}ä¸ªå…³é”®å·¥å…·ï¼Œå»ºè®®ä¼˜å…ˆä¼˜åŒ–',
                'items': critical_tools[:5]
            })

        return suggestions

    def create_integration_workflow(self) -> Dict[str, List[str]]:
        """åˆ›å»ºé›†æˆå·¥ä½œæµ"""
        workflow = {
            'quality_improvement': [
                'smart_quality_fixer.py',  # è´¨é‡ä¿®å¤
                'quality_guardian.py',      # è´¨é‡å®ˆæŠ¤
                'precise_error_fixer.py'    # ç²¾ç¡®ä¿®å¤
            ],
            'coverage_improvement': [
                'coverage_improvement_executor.py',  # è¦†ç›–ç‡æ‰§è¡Œ
                'phase35_ai_coverage_master.py',     # AIè¦†ç›–ç‡
                'integrated_coverage_improver.py',   # é›†æˆæ”¹è¿›
                'simple_coverage_analyzer.py',       # è¦†ç›–ç‡åˆ†æ
                'coverage_dashboard.py'              # è¦†ç›–ç‡ä»ªè¡¨æ¿
            ],
            'test_generation': [
                'create_api_tests.py',     # APIæµ‹è¯•ç”Ÿæˆ
                'create_service_tests.py'  # æœåŠ¡æµ‹è¯•ç”Ÿæˆ
            ],
            'monitoring': [
                'tool_integration_optimizer.py',  # å·¥å…·é›†æˆä¼˜åŒ–
                'continuous_improvement_engine.py' # æŒç»­æ”¹è¿›
            ]
        }

        return workflow

    def generate_report(self) -> str:
        """ç”Ÿæˆé›†æˆåˆ†ææŠ¥å‘Š"""
        self.discover_tools()
        self.calculate_dependents()
        analysis = self.analyze_integration()
        suggestions = self.generate_optimization_suggestions(analysis)
        workflow = self.create_integration_workflow()

        report_lines = [
            "# å·¥å…·é›†æˆä¼˜åŒ–æŠ¥å‘Š",
            "",
            "## æ¦‚è§ˆ",
            f"- æ€»å·¥å…·æ•°: {analysis['total_tools']}",
            f"- å·¥ä½œçŠ¶æ€: {analysis['status_distribution']}",
            "",
            "## å·¥å…·çŠ¶æ€åˆ†å¸ƒ"
        ]

        for status, count in analysis['status_distribution'].items():
            emoji = {"working": "âœ…", "broken": "âŒ", "needs_improvement": "âš ï¸"}
            report_lines.append(f"- {emoji.get(status, 'â€¢')} {status}: {count}")

        report_lines.extend([
            "",
            "## å…³é”®å·¥å…·",
            ""
        ])

        for tool_name in analysis['critical_tools']:
            tool = self.tools[tool_name]
            report_lines.append(f"- **{tool_name}** ({tool.functionality})")
            report_lines.append(f"  - è¢«ä¾èµ–: {', '.join(tool.dependents)}")

        report_lines.extend([
            "",
            "## ä¼˜åŒ–å»ºè®®",
            ""
        ])

        for i, suggestion in enumerate(suggestions, 1):
            emoji = {"high": "ğŸ”¥", "medium": "âš¡", "low": "ğŸ’¡"}
            report_lines.append(f"{i}. {emoji.get(suggestion['priority'],
    'â€¢')} **{suggestion['category']}** ({suggestion['priority']})")
            report_lines.append(f"   - {suggestion['description']}")
            if suggestion['items']:
                report_lines.append(f"   - æ¶‰åŠå·¥å…·: {', '.join(suggestion['items'])}")

        report_lines.extend([
            "",
            "## æ¨èå·¥ä½œæµ",
            ""
        ])

        for workflow_name, tools in workflow.items():
            report_lines.append(f"### {workflow_name.replace('_', ' ').title()}")
            for tool in tools:
                if tool in self.tools:
                    status_emoji = {"working": "âœ…", "broken": "âŒ", "needs_improvement": "âš ï¸"}
                    status = self.tools[tool].status
                    report_lines.append(f"- {status_emoji.get(status, 'â€¢')} {tool}")

        return "\n".join(report_lines)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å·¥å…·é›†æˆä¼˜åŒ–å™¨")
    print("=" * 40)

    optimizer = ToolIntegrationOptimizer()
    report = optimizer.generate_report()

    # è¾“å‡ºæŠ¥å‘Š
    print(report)

    # ä¿å­˜æŠ¥å‘Š
    report_file = optimizer.project_root / "tool_integration_report.md"
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


if __name__ == "__main__":
    main()