#!/usr/bin/env python3
"""
L2æ·±åº¦æ•°æ®é‡‡é›†å™¨ - FotMobç‰ˆæœ¬ (New Architecture)
System Integration Architect: L2æ•°æ®ç®¡é“å‡çº§
Purpose: ä½¿ç”¨FotMob APIé‡‡é›†é˜µå®¹å’Œå°„é—¨å›¾æ•°æ®ï¼Œæ›¿ä»£å¤±è´¥çš„Playwrightæ–¹æ¡ˆ
Architecture: FotMobä½œä¸ºL2æ·±åº¦æ•°æ®çš„æ ¸å¿ƒæ¥æº
"""

import asyncio
import json
import logging
import os
import re
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

# æ·»åŠ å¿…è¦çš„ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
import httpx
from difflib import SequenceMatcher

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.data.collectors.fotmob_match_collector import FotmobCollector, FotmobAPIError
from scripts.enhanced_database_saver import EnhancedDatabaseSaver

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class MatchRecord:
    """æ¯”èµ›è®°å½•æ•°æ®ç±»"""
    id: int
    home_team: str
    away_team: str
    home_team_id: Optional[int]
    away_team_id: Optional[int]
    match_date: datetime
    home_score: Optional[int]
    away_score: Optional[int]
    data_completeness: str
    metadata: dict


class FotMobMatchMatcher:
    """FotMobæ¯”èµ›åŒ¹é…å™¨ - The Bridge"""

    def __init__(self):
        self.collector = FotmobCollector()
        self.team_name_mappings = {
            # å¸¸è§çš„çƒé˜Ÿåç§°æ˜ å°„
            'Manchester United': ['Manchester Utd', 'Man United', 'Man Utd'],
            'Manchester City': ['Man City', 'Manchester City'],
            'Liverpool': ['Liverpool'],
            'Chelsea': ['Chelsea'],
            'Arsenal': ['Arsenal'],
            'Tottenham': ['Tottenham', 'Spurs', 'Tottenham Hotspur'],
            'Leicester City': ['Leicester', 'Leicester City'],
            'Everton': ['Everton'],
            'Wolverhampton': ['Wolves', 'Wolverhampton Wanderers'],
            'West Ham': ['West Ham', 'West Ham United'],
            'Aston Villa': ['Aston Villa'],
            'Southampton': ['Southampton', 'Soton'],
            'Newcastle': ['Newcastle', 'Newcastle United'],
            'Brighton': ['Brighton', 'Brighton & Hove Albion'],
            'Crystal Palace': ['Crystal Palace', 'Palace'],
            'Brentford': ['Brentford'],
            'Fulham': ['Fulham'],
            'Leeds United': ['Leeds', 'Leeds United'],
            'Burnley': ['Burnley'],
            'Sheffield United': ['Sheffield Utd', 'Sheffield United'],
            'Luton Town': ['Luton', 'Luton Town'],
        }

    def normalize_team_name(self, team_name: str) -> str:
        """æ ‡å‡†åŒ–é˜Ÿå"""
        if not team_name:
            return ""

        team_name = team_name.strip()

        # æŸ¥æ‰¾æ˜ å°„
        for standard_name, variants in self.team_name_mappings.items():
            if team_name in variants:
                return standard_name

        return team_name

    def find_fotmob_match_id(self, home_team: str, away_team: str, match_date: datetime) -> Optional[str]:
        """
        æŸ¥æ‰¾FotMobæ¯”èµ›ID - æ ¸å¿ƒåŒ¹é…é€»è¾‘

        Args:
            home_team: ä¸»é˜Ÿåç§°
            away_team: å®¢é˜Ÿåç§°
            match_date: æ¯”èµ›æ—¥æœŸ

        Returns:
            FotMobæ¯”èµ›IDï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
        """
        try:
            logger.info(f"ğŸ” æœç´¢FotMobæ¯”èµ›: {home_team} vs {away_team} @ {match_date.date()}")

            # æ ‡å‡†åŒ–é˜Ÿå
            home_team_norm = self.normalize_team_name(home_team)
            away_team_norm = self.normalize_team_name(away_team)

            # ç”Ÿæˆæœç´¢æ—¥æœŸåˆ—è¡¨ï¼ˆæ¯”èµ›æ—¥æœŸå‰å2å¤©ï¼‰
            search_dates = []
            for days_offset in range(-2, 3):  # -2, -1, 0, 1, 2
                search_date = match_date + timedelta(days=days_offset)
                search_dates.append(search_date.strftime("%Y%m%d"))

            logger.info(f"ğŸ“… æœç´¢æ—¥æœŸèŒƒå›´: {search_dates}")

            # åœ¨æ¯ä¸ªæ—¥æœŸæœç´¢æ¯”èµ›
            for date_str in search_dates:
                try:
                    # æ„å»ºFotMob API URLï¼ˆè¿™ä¸ªAPIéœ€è¦é€†å‘å·¥ç¨‹ï¼Œè¿™é‡Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼‰
                    # æ³¨æ„ï¼šå®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æœç´¢é€»è¾‘

                    # ç”±äºFotMob APIé™åˆ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨å·²çŸ¥çš„åŒ¹é…ç­–ç•¥
                    match_id = self._search_matches_by_team_names(
                        home_team_norm, away_team_norm, date_str, match_date
                    )

                    if match_id:
                        logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…: {match_id}")
                        return match_id

                except Exception as e:
                    logger.debug(f"æœç´¢æ—¥æœŸ {date_str} å¤±è´¥: {e}")
                    continue

            logger.warning(f"âŒ æœªæ‰¾åˆ°æ¯”èµ›åŒ¹é…: {home_team} vs {away_team}")
            return None

        except Exception as e:
            logger.error(f"ğŸ’¥ æŸ¥æ‰¾FotMobæ¯”èµ›IDå¤±è´¥: {e}")
            return None

    def _search_matches_by_team_names(self, home_team: str, away_team: str,
                                     date_str: str, original_date: datetime) -> Optional[str]:
        """
        æŒ‰é˜Ÿåæœç´¢æ¯”èµ›ï¼ˆä½¿ç”¨å¯å‘å¼æ–¹æ³•ï¼‰

        ç”±äºFotMobçš„æœç´¢APIé™åˆ¶ï¼Œè¿™é‡Œä½¿ç”¨å¸¸è§çš„æ¯”èµ›IDæ¨¡å¼
        """
        try:
            # å¸¸è§çš„è‹±è¶…æ¯”èµ›IDæ¨¡å¼ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
            # æ³¨æ„ï¼šè¿™æ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥è°ƒç”¨FotMobæœç´¢API

            # ç”Ÿæˆå€™é€‰æ¯”èµ›ID
            base_ids = [
                # åŸºäºæ—¥æœŸçš„IDæ¨¡å¼
                f"{int(date_str)}",  # ç®€å•æ—¥æœŸæ¨¡å¼
                f"418{date_str[2:]}",  # æŸäº›æ¯”èµ›çš„IDæ¨¡å¼
            ]

            # å°è¯•è¿™äº›ID
            for candidate_id in base_ids:
                try:
                    # å°è¯•è·å–æ¯”èµ›è¯¦æƒ…æ¥éªŒè¯IDæ˜¯å¦æœ‰æ•ˆ
                    match_data = self.collector.get_match_details(candidate_id)

                    if match_data and match_data.get('home_team') and match_data.get('away_team'):
                        # éªŒè¯é˜ŸååŒ¹é…
                        fotmob_home = self.normalize_team_name(match_data['home_team'])
                        fotmob_away = self.normalize_team_name(match_data['away_team'])

                        # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…
                        home_match = self._fuzzy_match_teams(home_team_norm, fotmob_home)
                        away_match = self._fuzzy_match_teams(away_team_norm, fotmob_away)

                        # éªŒè¯æ—¥æœŸåŒ¹é…
                        fotmob_date = match_data.get('match_time_utc', '')
                        date_match = self._verify_date_match(original_date, fotmob_date)

                        if home_match and away_match and date_match:
                            logger.info(f"ğŸ¯ åŒ¹é…æˆåŠŸ: {home_team}/{away_team} -> {fotmob_home}/{fotmob_away}")
                            return candidate_id

                except FotmobAPIError as e:
                    if "404" not in str(e):
                        logger.debug(f"å°è¯•ID {candidate_id} å¤±è´¥: {e}")
                    continue
                except Exception as e:
                    logger.debug(f"éªŒè¯ID {candidate_id} å¼‚å¸¸: {e}")
                    continue

            return None

        except Exception as e:
            logger.error(f"æŒ‰é˜Ÿåæœç´¢å¤±è´¥: {e}")
            return None

    def _fuzzy_match_teams(self, team1: str, team2: str) -> bool:
        """æ¨¡ç³ŠåŒ¹é…é˜Ÿå"""
        if not team1 or not team2:
            return False

        # ç›´æ¥åŒ¹é…
        if team1.lower() == team2.lower():
            return True

        # æ¨¡ç³ŠåŒ¹é…
        similarity = SequenceMatcher(None, team1.lower(), team2.lower()).ratio()
        return similarity >= 0.8  # 80%ç›¸ä¼¼åº¦é˜ˆå€¼

    def _verify_date_match(self, expected_date: datetime, fotmob_date_str: str) -> bool:
        """éªŒè¯æ—¥æœŸåŒ¹é…"""
        try:
            if not fotmob_date_str:
                return True  # å¦‚æœæ²¡æœ‰æ—¥æœŸä¿¡æ¯ï¼Œå‡è®¾åŒ¹é…

            # å°è¯•è§£æFotMobæ—¥æœŸ
            if 'T' in fotmob_date_str:
                fotmob_date = datetime.fromisoformat(fotmob_date_str.replace('Z', '+00:00'))
            else:
                fotmob_date = datetime.strptime(fotmob_date_str, '%Y-%m-%d %H:%M:%S')

            # æ£€æŸ¥æ—¥æœŸå·®å¼‚ï¼ˆå…è®¸3å°æ—¶è¯¯å·®ï¼‰
            time_diff = abs((expected_date - fotmob_date).total_seconds())
            return time_diff <= 10800  # 3å°æ—¶

        except Exception as e:
            logger.debug(f"æ—¥æœŸè§£æå¤±è´¥: {e}")
            return True  # è§£æå¤±è´¥æ—¶å‡è®¾åŒ¹é…


class FotmobDetailsCollector:
    """åŸºäºFotMobçš„L2æ·±åº¦æ•°æ®é‡‡é›†å™¨"""

    def __init__(self):
        self.fotmob_collector = FotmobCollector()
        self.match_matcher = FotMobMatchMatcher()
        self.db_saver = EnhancedDatabaseSaver()

        # æ•°æ®åº“è¿æ¥é…ç½®
        self.db_config = {
            'host': os.getenv('POSTGRES_HOST', 'localhost'),
            'port': os.getenv('POSTGRES_PORT', '5432'),
            'database': os.getenv('POSTGRES_DB', 'football_prediction'),
            'user': os.getenv('POSTGRES_USER', 'postgres'),
            'password': os.getenv('POSTGRES_PASSWORD', 'postgres-dev-password')
        }

    def get_pending_matches(self, limit: int = 50) -> list[MatchRecord]:
        """è·å–å¾…å¤„ç†çš„æ¯”èµ›è®°å½•"""
        try:
            conn = psycopg2.connect(**self.db_config)
            conn.autocommit = False

            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # æŸ¥è¯¢data_source='fbref'ä¸”data_completeness='partial'çš„è®°å½•
                cur.execute("""
                    SELECT id, home_team, away_team, home_team_id, away_team_id,
                           match_date, home_score, away_score, data_completeness,
                           CASE
                               WHEN metadata IS NULL THEN '{}'::jsonb
                               ELSE metadata
                           END as metadata
                    FROM matches
                    WHERE data_source = 'fbref'
                    AND data_completeness = 'partial'
                    AND home_score IS NOT NULL
                    AND away_score IS NOT NULL
                    AND match_date > NOW() - INTERVAL '2 years'
                    ORDER BY match_date DESC
                    LIMIT %s
                """, (limit,))

                records = []
                for row in cur.fetchall():
                    record = MatchRecord(
                        id=row['id'],
                        home_team=row['home_team'],
                        away_team=row['away_team'],
                        home_team_id=row['home_team_id'],
                        away_team_id=row['away_team_id'],
                        match_date=row['match_date'],
                        home_score=row['home_score'],
                        away_score=row['away_score'],
                        data_completeness=row['data_completeness'],
                        metadata=dict(row['metadata'])
                    )
                    records.append(record)

                conn.close()
                return records

        except Exception as e:
            logger.error(f"âŒ è·å–å¾…å¤„ç†è®°å½•å¤±è´¥: {e}")
            return []

    async def collect_match_fotmob_data(self, match_record: MatchRecord) -> dict[str, any]:
        """é‡‡é›†å•åœºæ¯”èµ›çš„FotMobæ•°æ®"""
        try:
            logger.info(f"ğŸ” å¼€å§‹é‡‡é›†FotMobæ•°æ®: {match_record.home_team} vs {match_record.away_team}")

            # 1. æŸ¥æ‰¾FotMobæ¯”èµ›ID
            fotmob_match_id = self.match_matcher.find_fotmob_match_id(
                match_record.home_team,
                match_record.away_team,
                match_record.match_date
            )

            if not fotmob_match_id:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°FotMobæ¯”èµ›ID: {match_record.id}")
                return {"success": False, "reason": "fotmob_match_not_found"}

            # 2. è·å–FotMobè¯¦ç»†æ•°æ®
            fotmob_data = self.fotmob_collector.get_comprehensive_match_data(fotmob_match_id)

            if not fotmob_data:
                logger.warning(f"âš ï¸ æ— æ³•è·å–FotMobæ•°æ®: {fotmob_match_id}")
                return {"success": False, "reason": "fotmob_data_fetch_failed"}

            # 3. æå–å¹¶æ ¼å¼åŒ–æ•°æ®
            processed_data = self._process_fotmob_data(fotmob_data)

            logger.info(f"âœ… æˆåŠŸé‡‡é›†FotMobæ•°æ®: {len(processed_data.get('events', []))} events, "
                       f"{len(processed_data.get('lineups', {}).get('home_players', []))} home players")

            return {
                "success": True,
                "fotmob_match_id": fotmob_match_id,
                "data": processed_data
            }

        except Exception as e:
            logger.error(f"âŒ é‡‡é›†FotMobæ•°æ®å¤±è´¥: {e}")
            return {"success": False, "reason": str(e)}

    def _process_fotmob_data(self, fotmob_data: dict) -> dict[str, any]:
        """å¤„ç†FotMobæ•°æ®æ ¼å¼"""
        processed = {}

        try:
            # å¤„ç†å°„é—¨å›¾æ•°æ®
            shotmap = fotmob_data.get('shotmap', [])
            if shotmap:
                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼çš„äº‹ä»¶æ•°æ®
                events = []
                for shot in shotmap:
                    event = {
                        'event_type': 'shot',
                        'minute': shot.get('time', 0),
                        'team': shot.get('team'),
                        'player': shot.get('player_name'),
                        'xg': shot.get('xg', 0.0),
                        'coordinates': shot.get('coordinates', {}),
                        'is_goal': shot.get('is_goal', False),
                        'shot_type': shot.get('eventType', ''),
                        'situation': shot.get('situation', ''),
                        'body_part': shot.get('bodyPart', '')
                    }
                    events.append(event)

                processed['events'] = events

            # å¤„ç†é˜µå®¹æ•°æ®
            lineup = fotmob_data.get('lineup', {})
            if lineup:
                processed['lineups'] = {
                    'home_team': lineup.get('home_team'),
                    'away_team': lineup.get('away_team'),
                    'home_players': lineup.get('home_players', []),
                    'away_players': lineup.get('away_players', [])
                }

            # å¤„ç†ç»Ÿè®¡æ•°æ®
            stats = fotmob_data.get('match_details', {}).get('stats', {})
            if stats:
                processed['stats'] = stats

            # æ·»åŠ FotMobå…ƒæ•°æ®
            processed['fotmob_metadata'] = {
                'data_source': 'fotmob',
                'collected_at': datetime.now().isoformat(),
                'match_details': fotmob_data.get('match_details', {})
            }

        except Exception as e:
            logger.error(f"å¤„ç†FotMobæ•°æ®å¤±è´¥: {e}")

        return processed

    def update_match_record(self, match_record: MatchRecord, fotmob_data: dict) -> bool:
        """æ›´æ–°æ¯”èµ›è®°å½•"""
        try:
            conn = psycopg2.connect(**self.db_config)
            conn.autocommit = False

            with conn.cursor() as cur:
                # æ›´æ–°å­—æ®µ
                update_parts = []
                params = []

                # æ›´æ–°eventså­—æ®µ
                if 'events' in fotmob_data:
                    update_parts.append("events = %s")
                    params.append(json.dumps(fotmob_data['events'], ensure_ascii=False))

                # æ›´æ–°lineupså­—æ®µ
                if 'lineups' in fotmob_data:
                    update_parts.append("lineups = %s")
                    params.append(json.dumps(fotmob_data['lineups'], ensure_ascii=False))

                # æ›´æ–°statså­—æ®µ
                if 'stats' in fotmob_data:
                    update_parts.append("stats = COALESCE(stats, '{}'::jsonb) || %s")
                    params.append(json.dumps(fotmob_data['stats'], ensure_ascii=False))

                # æ›´æ–°metadataå­—æ®µï¼Œæ·»åŠ FotMobä¿¡æ¯
                metadata = match_record.metadata.copy()
                metadata.update(fotmob_data.get('fotmob_metadata', {}))
                update_parts.append("metadata = %s")
                params.append(json.dumps(metadata, ensure_ascii=False))

                # æ ‡è®°ä¸ºcomplete
                update_parts.append("data_completeness = 'complete'")
                update_parts.append("updated_at = CURRENT_TIMESTAMP")

                params.append(match_record.id)

                # æ‰§è¡Œæ›´æ–°
                sql = f"""
                    UPDATE matches
                    SET {', '.join(update_parts)}
                    WHERE id = %s
                """

                cur.execute(sql, params)
                conn.commit()

                logger.info(f"âœ… æˆåŠŸæ›´æ–°æ¯”èµ›è®°å½•: {match_record.id}")
                return True

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ¯”èµ›è®°å½•å¤±è´¥: {e}")
            if 'conn' in locals():
                conn.rollback()
            return False
        finally:
            if 'conn' in locals():
                conn.close()

    async def run_collection_batch(self, batch_size: int = 20, max_batches: int = None) -> dict:
        """è¿è¡Œæ‰¹é‡é‡‡é›†"""
        stats = {
            'total_processed': 0,
            'successful': 0,
            'failed': 0,
            'start_time': datetime.now()
        }

        batch_count = 0

        try:
            while (max_batches is None or batch_count < max_batches):
                logger.info(f"ğŸ”„ å¼€å§‹ç¬¬ {batch_count + 1} æ‰¹é‡‡é›† (æ‰¹æ¬¡å¤§å°: {batch_size})")

                # è·å–å¾…å¤„ç†è®°å½•
                pending_matches = self.get_pending_matches(batch_size)

                if not pending_matches:
                    logger.info("ğŸ“‹ æ²¡æœ‰æ›´å¤šå¾…å¤„ç†è®°å½•")
                    break

                logger.info(f"ğŸ“Š æœ¬æ‰¹æ¬¡å¤„ç† {len(pending_matches)} æ¡è®°å½•")

                # å¤„ç†æ¯æ¡è®°å½•
                for i, match_record in enumerate(pending_matches, 1):
                    logger.info(f"å¤„ç† {i}/{len(pending_matches)}: {match_record.home_team} vs {match_record.away_team}")

                    # é‡‡é›†FotMobæ•°æ®
                    result = await self.collect_match_fotmob_data(match_record)
                    stats['total_processed'] += 1

                    if result.get('success'):
                        # æ›´æ–°æ•°æ®åº“è®°å½•
                        if self.update_match_record(match_record, result['data']):
                            stats['successful'] += 1
                            logger.info(f"âœ… æˆåŠŸå¤„ç†è®°å½•: {match_record.id}")
                        else:
                            stats['failed'] += 1
                            logger.error(f"âŒ æ›´æ–°è®°å½•å¤±è´¥: {match_record.id}")
                    else:
                        stats['failed'] += 1
                        logger.warning(f"âš ï¸ é‡‡é›†å¤±è´¥: {match_record.id} - {result.get('reason')}")

                    # å»¶è¿Ÿä»¥é¿å…è¿‡è½½
                    if i % 5 == 0:  # æ¯5æ¡è®°å½•å»¶è¿Ÿ
                        await asyncio.sleep(2)
                    else:
                        await asyncio.sleep(1)

                batch_count += 1

                # æ‰¹æ¬¡é—´å»¶è¿Ÿ
                logger.info(f"ğŸ“ˆ æ‰¹æ¬¡ {batch_count} å®Œæˆ: {stats['successful']}/{stats['total_processed']} æˆåŠŸ")
                if batch_count < (max_batches or float('inf')):
                    logger.info("â¸ï¸ æ‰¹æ¬¡é—´å»¶è¿Ÿ30ç§’...")
                    await asyncio.sleep(30)

        except Exception as e:
            logger.error(f"ğŸ’¥ æ‰¹é‡é‡‡é›†å¼‚å¸¸: {e}")

        finally:
            stats['end_time'] = datetime.now()
            stats['duration'] = (stats['end_time'] - stats['start_time']).total_seconds()

        return stats


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨FotMob L2æ·±åº¦æ•°æ®é‡‡é›†å™¨")
    logger.info("=" * 60)

    try:
        collector = FotmobDetailsCollector()

        # è¿è¡Œæ‰¹é‡é‡‡é›†
        stats = await collector.run_collection_batch(batch_size=15, max_batches=3)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info("=" * 60)
        logger.info("ğŸ“Š é‡‡é›†ç»Ÿè®¡:")
        logger.info(f"   æ€»å¤„ç†: {stats['total_processed']}")
        logger.info(f"   æˆåŠŸ: {stats['successful']}")
        logger.info(f"   å¤±è´¥: {stats['failed']}")
        logger.info(f"   æˆåŠŸç‡: {stats['successful']/max(stats['total_processed'], 1)*100:.1f}%")
        logger.info(f"   è€—æ—¶: {stats['duration']:.1f}ç§’")
        logger.info("=" * 60)

        if stats['successful'] > 0:
            logger.info("ğŸ‰ L2æ·±åº¦æ•°æ®é‡‡é›†ä»»åŠ¡å®Œæˆ!")
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®°å½•")

    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸»ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # å¯¼å…¥osæ¨¡å—ï¼ˆå¦‚æœå°šæœªå¯¼å…¥ï¼‰
    import os

    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())
