#!/usr/bin/env python3
"""
æ™ºèƒ½å·¥å…·ä½“ç³»åˆ†æå’Œä¼˜åŒ–å™¨
Intelligent Tool System Analysis and Optimizer

åˆ†æç°æœ‰çš„600+ä¸ªè„šæœ¬ï¼Œæä¾›åŠŸèƒ½ä¼˜åŒ–å»ºè®®
"""

import os
import re
import ast
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from datetime import datetime
import subprocess

class IntelligentToolAnalyzer:
    """æ™ºèƒ½å·¥å…·åˆ†æå™¨"""

    def __init__(self):
        self.base_dir = Path(".")
        self.scripts_dir = Path("scripts")
        self.analysis_results = {
            "total_scripts": 0,
            "python_scripts": 0,
            "shell_scripts": 0,
            "tool_categories": {},
            "functionality_analysis": {},
            "optimization_suggestions": [],
            "integration_opportunities": [],
            "quality_metrics": {}
        }

    def scan_all_scripts(self) -> Dict:
        """æ‰«ææ‰€æœ‰è„šæœ¬æ–‡ä»¶"""
        print("ğŸ” æ‰«ææ™ºèƒ½å·¥å…·ä½“ç³»...")

        # æ‰«æPythonè„šæœ¬
        python_scripts = list(self.base_dir.rglob("*.py"))
        # æ‰«æShellè„šæœ¬
        shell_scripts = list(self.base_dir.rglob("*.sh"))

        # è¿‡æ»¤æ‰éscriptsç›®å½•çš„æ–‡ä»¶
        python_scripts = [p for p in python_scripts if "scripts" in str(p)]
        shell_scripts = [p for p in shell_scripts if "scripts" in str(p)]

        self.analysis_results["python_scripts"] = len(python_scripts)
        self.analysis_results["shell_scripts"] = len(shell_scripts)
        self.analysis_results["total_scripts"] = len(python_scripts) + len(shell_scripts)

        print(f"ğŸ“Š å‘ç°è„šæœ¬ç»Ÿè®¡:")
        print(f"   Pythonè„šæœ¬: {len(python_scripts)}ä¸ª")
        print(f"   Shellè„šæœ¬: {len(shell_scripts)}ä¸ª")
        print(f"   æ€»è®¡: {self.analysis_results['total_scripts']}ä¸ª")

        return {
            "python_scripts": python_scripts,
            "shell_scripts": shell_scripts
        }

    def analyze_script_functionality(self, script_path: Path) -> Dict:
        """åˆ†æå•ä¸ªè„šæœ¬çš„åŠŸèƒ½"""
        try:
            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()

            analysis = {
                "path": str(script_path),
                "size_lines": len(content.splitlines()),
                "functions": [],
                "imports": [],
                "features": [],
                "quality_score": 0,
                "category": self.categorize_script(script_path, content),
                "complexity": "medium"
            }

            # åˆ†æPythonè„šæœ¬
            if script_path.suffix == ".py":
                analysis.update(self.analyze_python_script(content))
            # åˆ†æShellè„šæœ¬
            elif script_path.suffix == ".sh":
                analysis.update(self.analyze_shell_script(content))

            # è®¡ç®—è´¨é‡åˆ†æ•°
            analysis["quality_score"] = self.calculate_quality_score(analysis)

            return analysis

        except Exception as e:
            return {
                "path": str(script_path),
                "error": str(e),
                "category": "error"
            }

    def analyze_python_script(self, content: str) -> Dict:
        """åˆ†æPythonè„šæœ¬"""
        analysis = {
            "functions": [],
            "imports": [],
            "features": [],
            "has_main": False,
            "has_docstring": False,
            "has_error_handling": False,
            "uses_async": False
        }

        try:
            tree = ast.parse(content)

            # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
            if ast.get_docstring(tree):
                analysis["has_docstring"] = True

            # åˆ†æå¯¼å…¥
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis["imports"].append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        analysis["imports"].append(node.module)

            # åˆ†æå‡½æ•°å’Œç±»
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    analysis["functions"].append(node.name)

                    # æ£€æŸ¥å¼‚æ­¥å‡½æ•°
                    if isinstance(node, ast.AsyncFunctionDef):
                        analysis["uses_async"] = True

                elif isinstance(node, ast.ClassDef):
                    analysis["functions"].append(f"class:{node.name}")

            # æ£€æŸ¥mainå‡½æ•°
            analysis["has_main"] = any("main" in func for func in analysis["functions"])

            # æ£€æŸ¥é”™è¯¯å¤„ç†
            error_handling_keywords = ["try:", "except", "raise", "finally:"]
            analysis["has_error_handling"] = any(keyword in content for keyword in error_handling_keywords)

            # æ£€æµ‹åŠŸèƒ½ç‰¹å¾
            if "pytest" in content:
                analysis["features"].append("testing")
            if "requests" in content or "http" in content:
                analysis["features"].append("networking")
            if "sqlite" in content or "database" in content:
                analysis["features"].append("database")
            if "logging" in content:
                analysis["features"].append("logging")
            if "argparse" in content or "click" in content:
                analysis["features"].append("cli")
            if "schedule" in content or "cron" in content:
                analysis["features"].append("automation")
            if "coverage" in content:
                analysis["features"].append("coverage_analysis")
            if "github" in content or "git" in content:
                analysis["features"].append("git_integration")

        except SyntaxError:
            analysis["syntax_error"] = True

        return analysis

    def analyze_shell_script(self, content: str) -> Dict:
        """åˆ†æShellè„šæœ¬"""
        analysis = {
            "functions": [],
            "imports": [],
            "features": [],
            "has_shebang": False,
            "has_error_handling": False,
            "uses_variables": False
        }

        # æ£€æŸ¥shebang
        if content.startswith("#!"):
            analysis["has_shebang"] = True

        # æå–å‡½æ•°å
        function_matches = re.findall(r'^\s*function\s+(\w+)|^(\w+)\s*\(\s*\)',
    content,
    re.MULTILINE)
        for match in function_matches:
            func_name = match[0] or match[1]
            if func_name:
                analysis["functions"].append(func_name)

        # æ£€æµ‹åŠŸèƒ½ç‰¹å¾
        if "docker" in content:
            analysis["features"].append("docker")
        if "git" in content:
            analysis["features"].append("git")
        if "pytest" in content or "python" in content:
            analysis["features"].append("testing")
        if "npm" in content or "yarn" in content:
            analysis["features"].append("package_manager")
        if "systemctl" in content or "service" in content:
            analysis["features"].append("service_management")

        # æ£€æŸ¥é”™è¯¯å¤„ç†
        analysis["has_error_handling"] = "set -e" in content or "||" in content

        # æ£€æŸ¥å˜é‡ä½¿ç”¨
        analysis["uses_variables"] = "$" in content

        return analysis

    def categorize_script(self, script_path: Path, content: str) -> str:
        """å¯¹è„šæœ¬è¿›è¡Œåˆ†ç±»"""
        path_str = str(script_path).lower()
        content_lower = content.lower()

        # æµ‹è¯•ç›¸å…³
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["test", "pytest", "coverage"]):
            return "testing"

        # éƒ¨ç½²ç›¸å…³
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["deploy", "deployment", "ci", "cd"]):
            return "deployment"

        # è´¨é‡ä¿è¯
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["quality", "lint", "fix", "review", "analyze"]):
            return "quality"

        # ç›‘æ§ç›¸å…³
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["monitor", "metrics", "performance", "health"]):
            return "monitoring"

        # å·¥å…·é›†æˆ
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["integration", "sync", "automation", "tool"]):
            return "integration"

        # GitHubç›¸å…³
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["github", "git", "issue"]):
            return "github"

        # æœºå™¨å­¦ä¹ /æ•°æ®
        if any(keyword in path_str or keyword in content_lower
               for keyword in ["ml", "model", "prediction", "data"]):
            return "ml_data"

        # é»˜è®¤åˆ†ç±»
        return "utility"

    def calculate_quality_score(self, analysis: Dict) -> int:
        """è®¡ç®—è„šæœ¬è´¨é‡åˆ†æ•°"""
        score = 0

        # åŸºç¡€åˆ†æ•°
        if analysis.get("has_docstring", False):
            score += 20
        if analysis.get("has_main", False):
            score += 15
        if analysis.get("has_error_handling", False):
            score += 15
        if analysis.get("has_shebang", False):
            score += 10

        # åŠŸèƒ½å¤æ‚åº¦
        functions = analysis.get("functions", [])
        if len(functions) > 0:
            score += min(20, len(functions) * 2)

        # ç‰¹å¾ä¸°å¯Œåº¦
        features = analysis.get("features", [])
        score += min(20, len(features) * 3)

        return min(100, score)

    def generate_optimization_suggestions(self,
    script_analyses: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # ç»Ÿè®¡åˆ†æ
        categories = {}
        quality_scores = []

        for analysis in script_analyses:
            if "error" not in analysis:
                category = analysis.get("category", "unknown")
                categories[category] = categories.get(category, 0) + 1
                quality_scores.append(analysis.get("quality_score", 0))

        # ç”Ÿæˆå»ºè®®
        if quality_scores:
            avg_quality = sum(quality_scores) / len(quality_scores)
            if avg_quality < 70:
                suggestions.append({
                    "type": "quality_improvement",
                    "priority": "high",
                    "description": f"æ•´ä½“è„šæœ¬è´¨é‡åˆ†æ•°è¾ƒä½({avg_quality:.1f}/100)ï¼Œå»ºè®®æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²ã€é”™è¯¯å¤„ç†å’Œä¸»å‡½æ•°",
    
    
                    "affected_scripts": "multiple"
                })

        # æ£€æŸ¥é‡å¤åŠŸèƒ½
        feature_counts = {}
        for analysis in script_analyses:
            if "features" in analysis:
                for feature in analysis["features"]:
                    feature_counts[feature] = feature_counts.get(feature, 0) + 1

        # è¯†åˆ«å¯ä»¥æ•´åˆçš„é‡å¤åŠŸèƒ½
        for feature, count in feature_counts.items():
            if count > 3:
                suggestions.append({
                    "type": "consolidation",
                    "priority": "medium",
                    "description": f"å‘ç°{count}ä¸ªè„šæœ¬éƒ½æœ‰'{feature}'åŠŸèƒ½ï¼Œè€ƒè™‘åˆ›å»ºç»Ÿä¸€çš„å·¥å…·åº“",
                    "feature": feature,
                    "count": count
                })

        # æ£€æŸ¥ç¼ºå¤±çš„åŠŸèƒ½
        essential_features = ["logging", "error_handling", "configuration", "documentation"]
        for feature in essential_features:
            if feature not in feature_counts:
                suggestions.append({
                    "type": "missing_feature",
                    "priority": "medium",
                    "description": f"ç¼ºå°‘{feature}ç›¸å…³çš„å·¥å…·ï¼Œå»ºè®®æ·»åŠ ç›¸åº”çš„è„šæœ¬",
                    "feature": feature
                })

        return suggestions

    def generate_integration_opportunities(self,
    script_analyses: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆé›†æˆæœºä¼š"""
        opportunities = []

        # åˆ†æè„šæœ¬é—´çš„ä¾èµ–å…³ç³»
        import_map = {}
        for analysis in script_analyses:
            if "imports" in analysis:
                for imp in analysis["imports"]:
                    if "scripts" in imp:
                        import_map[imp] = import_map.get(imp, 0) + 1

        # è¯†åˆ«å¯ä»¥åˆ›å»ºå·¥å…·é“¾çš„è„šæœ¬ç»„
        testing_scripts = []
        deployment_scripts = []
        quality_scripts = []

        for analysis in script_analyses:
            category = analysis.get("category", "")
            if category == "testing":
                testing_scripts.append(analysis["path"])
            elif category == "deployment":
                deployment_scripts.append(analysis["path"])
            elif category == "quality":
                quality_scripts.append(analysis["path"])

        # ç”Ÿæˆé›†æˆå»ºè®®
        if len(testing_scripts) > 2:
            opportunities.append({
                "type": "tool_chain",
                "category": "testing",
                "description": f"å¯ä»¥åˆ›å»ºæµ‹è¯•å·¥å…·é“¾ï¼Œæ•´åˆ{len(testing_scripts)}ä¸ªæµ‹è¯•ç›¸å…³è„šæœ¬",
                "scripts": testing_scripts[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
            })

        if len(deployment_scripts) > 2:
            opportunities.append({
                "type": "tool_chain",
                "category": "deployment",
                "description": f"å¯ä»¥åˆ›å»ºéƒ¨ç½²å·¥å…·é“¾ï¼Œæ•´åˆ{len(deployment_scripts)}ä¸ªéƒ¨ç½²ç›¸å…³è„šæœ¬",
                "scripts": deployment_scripts[:5]
            })

        if len(quality_scripts) > 2:
            opportunities.append({
                "type": "tool_chain",
                "category": "quality",
                "description": f"å¯ä»¥åˆ›å»ºè´¨é‡ä¿è¯å·¥å…·é“¾ï¼Œæ•´åˆ{len(quality_scripts)}ä¸ªè´¨é‡ç›¸å…³è„šæœ¬",
                "scripts": quality_scripts[:5]
            })

        return opportunities

    def create_optimization_plan(self) -> Dict:
        """åˆ›å»ºä¼˜åŒ–è®¡åˆ’"""
        print("ğŸ”§ åˆ›å»ºæ™ºèƒ½å·¥å…·ä¼˜åŒ–è®¡åˆ’...")

        # æ‰«æè„šæœ¬
        scripts = self.scan_all_scripts()

        # åˆ†ææ‰€æœ‰è„šæœ¬
        all_analyses = []

        # åˆ†æPythonè„šæœ¬
        print("ğŸ“ åˆ†æPythonè„šæœ¬...")
        for script_path in scripts["python_scripts"]:
            analysis = self.analyze_script_functionality(script_path)
            all_analyses.append(analysis)

        # åˆ†æShellè„šæœ¬
        print("ğŸš åˆ†æShellè„šæœ¬...")
        for script_path in scripts["shell_scripts"]:
            analysis = self.analyze_script_functionality(script_path)
            all_analyses.append(analysis)

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        print("ğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        optimization_suggestions = self.generate_optimization_suggestions(all_analyses)

        # ç”Ÿæˆé›†æˆæœºä¼š
        print("ğŸ”— è¯†åˆ«é›†æˆæœºä¼š...")
        integration_opportunities = self.generate_integration_opportunities(all_analyses)

        # ç»Ÿè®¡åˆ†ç±»
        categories = {}
        for analysis in all_analyses:
            if "error" not in analysis:
                category = analysis.get("category", "unknown")
                categories[category] = categories.get(category, 0) + 1

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        quality_scores = [a.get("quality_score",
    0) for a in all_analyses if "error" not in a]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0

        # æ›´æ–°åˆ†æç»“æœ
        self.analysis_results.update({
            "tool_categories": categories,
            "functionality_analysis": {a["path"]: a for a in all_analyses if "error" not in a},
            "optimization_suggestions": optimization_suggestions,
            "integration_opportunities": integration_opportunities,
            "quality_metrics": {
                "average_quality_score": avg_quality,
                "high_quality_scripts": len([s for s in quality_scores if s >= 80]),
                "medium_quality_scripts": len([s for s in quality_scores if 60 <= s < 80]),
    
    
                "low_quality_scripts": len([s for s in quality_scores if s < 60])
            }
        })

        return self.analysis_results

    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = f"""
# æ™ºèƒ½å·¥å…·ä½“ç³»åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**åˆ†æè„šæœ¬æ€»æ•°**: {self.analysis_results['total_scripts']}

## ğŸ“Š è„šæœ¬ç»Ÿè®¡

- **Pythonè„šæœ¬**: {self.analysis_results['python_scripts']}ä¸ª
- **Shellè„šæœ¬**: {self.analysis_results['shell_scripts']}ä¸ª
- **æ€»è®¡**: {self.analysis_results['total_scripts']}ä¸ª

## ğŸ—‚ï¸ å·¥å…·åˆ†ç±»åˆ†å¸ƒ

"""

        for category, count in self.analysis_results["tool_categories"].items():
            report += f"- **{category}**: {count}ä¸ª\n"

        report += f"""
## ğŸ“ˆ è´¨é‡æŒ‡æ ‡

- **å¹³å‡è´¨é‡åˆ†æ•°**: {self.analysis_results['quality_metrics']['average_quality_score']:.1f}/100
- **é«˜è´¨é‡è„šæœ¬**: {self.analysis_results['quality_metrics']['high_quality_scripts']}ä¸ª
- **ä¸­ç­‰è´¨é‡è„šæœ¬**: {self.analysis_results['quality_metrics']['medium_quality_scripts']}ä¸ª
- **ä½è´¨é‡è„šæœ¬**: {self.analysis_results['quality_metrics']['low_quality_scripts']}ä¸ª

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

"""

        for i,
    suggestion in enumerate(self.analysis_results["optimization_suggestions"][:10],
    1):
            report += f"### {i}. {suggestion['description']}\n"
            report += f"- **ä¼˜å…ˆçº§**: {suggestion['priority']}\n"
            report += f"- **ç±»å‹**: {suggestion['type']}\n\n"

        report += "## ğŸ”— é›†æˆæœºä¼š\n\n"

        for i,
    opportunity in enumerate(self.analysis_results["integration_opportunities"][:5],
    1):
            report += f"### {i}. {opportunity['description']}\n"
            report += f"- **ç±»åˆ«**: {opportunity['category']}\n"
            report += f"- **ç±»å‹**: {opportunity['type']}\n\n"

        return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ™ºèƒ½å·¥å…·ä½“ç³»åˆ†æ...")

    analyzer = IntelligentToolAnalyzer()

    # åˆ›å»ºä¼˜åŒ–è®¡åˆ’
    optimization_plan = analyzer.create_optimization_plan()

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report()

    # ä¿å­˜æŠ¥å‘Š
    with open("intelligent_tools_analysis_report.md", "w", encoding="utf-8") as f:
        f.write(report)

    # ä¿å­˜è¯¦ç»†æ•°æ®
    with open("intelligent_tools_analysis_data.json", "w", encoding="utf-8") as f:
        json.dump(optimization_plan, f, indent=2, ensure_ascii=False, default=str)

    print(f"\nğŸ“Š åˆ†æå®Œæˆ!")
    print(f"   æ€»è„šæœ¬æ•°: {optimization_plan['total_scripts']}")
    print(f"   å¹³å‡è´¨é‡åˆ†æ•°: {optimization_plan['quality_metrics']['average_quality_score']:.1f}/100")
    print(f"   ä¼˜åŒ–å»ºè®®: {len(optimization_plan['optimization_suggestions'])}ä¸ª")
    print(f"   é›†æˆæœºä¼š: {len(optimization_plan['integration_opportunities'])}ä¸ª")
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜:")
    print(f"   - intelligent_tools_analysis_report.md")
    print(f"   - intelligent_tools_analysis_data.json")

    return optimization_plan

if __name__ == "__main__":
    main()