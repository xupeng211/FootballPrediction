#!/usr/bin/env python3
"""
æ·±åº¦åˆ†æFotMob URLæ¨¡å¼å’Œå‚æ•°
Deep analysis of FotMob URL patterns and parameters
"""

import requests
import re
import json


def test_various_url_patterns():
    """æµ‹è¯•ä¸åŒçš„URLæ¨¡å¼"""
    base_date = "20240217"

    # ä¸åŒçš„URLæ¨¡å¼å°è¯•
    url_patterns = [
        # åŸºç¡€æ¨¡å¼
        f"https://www.fotmob.com/matches?date={base_date}",
        # å¸¦æ—¶åŒº
        f"https://www.fotmob.com/matches?date={base_date}&timezone=Europe/London",
        f"https://www.fotmob.com/matches?date={base_date}&tz=Europe/London",
        # å¸¦åœ°åŒº
        f"https://www.fotmob.com/matches?date={base_date}&ccode3=GBR",
        f"https://www.fotmob.com/matches?date={base_date}&country=GB",
        f"https://www.fotmob.com/matches?date={base_date}&locale=en-GB",
        # ç»„åˆå‚æ•°
        f"https://www.fotmob.com/matches?date={base_date}&timezone=Europe/London&ccode3=GBR",
        f"https://www.fotmob.com/matches?date={base_date}&tz=Europe/London&country=GB",
        f"https://www.fotmob.com/matches?date={base_date}&timezone=GMT&ccode3=GBR",
        # è‹±è¶…ç‰¹å®š
        f"https://www.fotmob.com/matches?date={base_date}&timezone=Europe/London&ccode3=GBR&league=47",
        f"https://www.fotmob.com/en-GB/matches?date={base_date}",
        f"https://www.fotmob.com/uk/matches?date={base_date}",
        # APIæ ¼å¼
        f"https://www.fotmob.com/api/matches?date={base_date}",
        f"https://www.fotmob.com/api/matches?date={base_date}&timezone=Europe/London&ccode3=GBR",
        # å…¶ä»–å¯èƒ½æ¨¡å¼
        f"https://www.fotmob.com/matches/{base_date}",
        f"https://www.fotmob.com/fixtures?date={base_date}",
        f"https://www.fotmob.com/fixtures/{base_date}",
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "en-GB,en;q=0.5",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
    }

    print("ğŸ”¬ æµ‹è¯•ä¸åŒçš„FotMob URLæ¨¡å¼...")
    print("=" * 70)

    best_urls = []

    for i, url in enumerate(url_patterns, 1):
        try:
            print(f"\n{i:2d}. {url}")
            response = requests.get(url, headers=headers, timeout=10, verify=False)

            status_info = (
                f"Status: {response.status_code}, Size: {len(response.text):,}"
            )

            if response.status_code == 200:
                print(f"     âœ… {status_info}")

                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¯”èµ›æ•°æ®
                has_nextjs = "__NEXT_DATA__" in response.text
                size_varies = len(response.text) > 350000 or len(response.text) < 300000
                has_matches = (
                    "match" in response.text.lower()
                    and "premier" in response.text.lower()
                )

                if has_nextjs:
                    print("     ğŸ“Š Next.js: âœ“")
                if size_varies:
                    print("     ğŸ“ å¤§å°å˜åŒ–: âœ“")
                if has_matches:
                    print("     âš½ æ¯”èµ›å…³é”®è¯: âœ“")

                # è¯„åˆ†ç³»ç»Ÿ
                score = 0
                if has_nextjs:
                    score += 3
                if size_varies:
                    score += 2
                if has_matches:
                    score += 2
                if response.status_code == 200:
                    score += 1

                best_urls.append(
                    {
                        "url": url,
                        "score": score,
                        "size": len(response.text),
                        "has_nextjs": has_nextjs,
                        "has_matches": has_matches,
                    }
                )

                print(f"     ğŸ¯ è¯„åˆ†: {score}/8")

            else:
                print(f"     âŒ {status_info}")

        except Exception as e:
            print(f"     âŒ å¼‚å¸¸: {e}")

    # æ˜¾ç¤ºæœ€ä½³URL
    print(f"\n{'=' * 70}")
    print("ğŸ† æœ€ä½³URLæ’å:")
    best_urls.sort(key=lambda x: x["score"], reverse=True)

    for i, url_info in enumerate(best_urls[:5], 1):
        url = url_info["url"]
        score = url_info["score"]
        size = url_info["size"]
        print(f"{i}. [{score}/8] {size:,} bytes")
        print(f"   {url}")
        print()

    return best_urls[0] if best_urls else None


def analyze_response_content(url):
    """åˆ†æç‰¹å®šURLçš„å“åº”å†…å®¹"""
    print(f"\nğŸ” æ·±åº¦åˆ†ææœ€ä½³URL: {url}")
    print("-" * 50)

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.5",
    }

    try:
        response = requests.get(url, headers=headers, timeout=15, verify=False)

        if response.status_code != 200:
            print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
            return

        print(f"âœ… å“åº”å¤§å°: {len(response.text):,} å­—ç¬¦")

        # æ£€æŸ¥å…³é”®æŒ‡æ ‡
        indicators = {
            "Next.jsæ•°æ®": "__NEXT_DATA__" in response.text,
            "æ¯”èµ›å…³é”®è¯": any(
                word in response.text.lower() for word in ["match", "fixture", "game"]
            ),
            "è‹±è¶…å…³é”®è¯": any(
                word in response.text.lower()
                for word in ["premier", "manchester", "london", "arsenal"]
            ),
            "JSONæ•°æ®": "{" in response.text and "}" in response.text,
            "fallback": "fallback" in response.text,
            "matches": '"matches"' in response.text or "'matches'" in response.text,
        }

        print("\nğŸ“Š å†…å®¹æŒ‡æ ‡:")
        for indicator, found in indicators.items():
            status = "âœ…" if found else "âŒ"
            print(f"   {status} {indicator}")

        # å°è¯•æå–Next.jsæ•°æ®
        if "__NEXT_DATA__" in response.text:
            print("\nğŸ”¬ åˆ†æNext.jsæ•°æ®ç»“æ„...")

            nextjs_data = extract_nextjs_data(response.text)
            if nextjs_data:
                print("âœ… Next.jsæ•°æ®è§£ææˆåŠŸ")

                # æ£€æŸ¥æ•°æ®è·¯å¾„
                props = nextjs_data.get("props", {})
                pageProps = props.get("pageProps", {})
                fallback = pageProps.get("fallback", {})

                print(f"   ğŸ“ propså­—æ®µæ•°: {len(props)}")
                print(f"   ğŸ“ pagePropså­—æ®µæ•°: {len(pageProps)}")
                print(f"   ğŸ“ fallbacké”®æ•°: {len(fallback)}")

                if fallback:
                    print(f"   ğŸ”‘ fallbacké”®: {list(fallback.keys())[:3]}")

                    # æ£€æŸ¥æ˜¯å¦æœ‰æ¯”èµ›æ•°æ®
                    matches_found = 0
                    for key, value in fallback.items():
                        if isinstance(value, dict) and "matches" in value:
                            matches_count = len(value.get("matches", []))
                            matches_found += matches_count
                            print(f"   âš½ {key}: {matches_count} åœºæ¯”èµ›")

                    print(f"   ğŸ“Š æ€»æ¯”èµ›æ•°: {matches_found}")
                else:
                    print("   âŒ fallbackä¸ºç©º")
            else:
                print("âŒ Next.jsæ•°æ®è§£æå¤±è´¥")

    except Exception as e:
        print(f"âŒ åˆ†æå¼‚å¸¸: {e}")


def extract_nextjs_data(html):
    """æå–Next.jsæ•°æ®"""
    patterns = [
        r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*type=["\']application/json["\'][^>]*>(.*?)</script>',
        r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*>(.*?)</script>',
        r"window\.__NEXT_DATA__\s*=\s*(\{.*?\});?\s*<\/script>",
    ]

    for pattern in patterns:
        matches = re.findall(pattern, html, re.DOTALL)
        if matches:
            try:
                nextjs_data_str = matches[0].strip()
                if nextjs_data_str.startswith("window.__NEXT_DATA__"):
                    nextjs_data_str = (
                        nextjs_data_str.replace("window.__NEXT_DATA__", "")
                        .replace("=", "")
                        .strip()
                    )
                    if nextjs_data_str.endswith(";"):
                        nextjs_data_str = nextjs_data_str[:-1]
                return json.loads(nextjs_data_str)
            except json.JSONDecodeError:
                continue
    return None


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ FotMob URLæ¨¡å¼æ·±åº¦åˆ†æ")
    print("ğŸ¯ å¯»æ‰¾èƒ½è¿”å›çœŸå®æ¯”èµ›æ•°æ®çš„URLæ ¼å¼")
    print("=" * 70)

    # æµ‹è¯•å„ç§URLæ¨¡å¼
    best_url_info = test_various_url_patterns()

    if best_url_info:
        # æ·±åº¦åˆ†ææœ€ä½³URL
        analyze_response_content(best_url_info["url"])

        print(f"\n{'=' * 70}")
        print("ğŸ¯ ç»“è®º:")
        print(f"æœ€ä½³URL: {best_url_info['url']}")
        print(f"è¯„åˆ†: {best_url_info['score']}/8")
        print("å»ºè®®: ä½¿ç”¨æ­¤URLæ ¼å¼è¿›è¡Œæ•°æ®é‡‡é›†")

    else:
        print(f"\n{'=' * 70}")
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„URLæ¨¡å¼")
        print("å»ºè®®: éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•æˆ–é‡‡ç”¨å…¶ä»–æ–¹æ³•")


if __name__ == "__main__":
    main()
