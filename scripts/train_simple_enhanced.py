#!/usr/bin/env python3
"""
ç®€åŒ–å¢å¼ºç‰¹å¾å®éªŒ
ä¸“æ³¨äºå®‰å…¨çš„åŸºç¡€å¢å¼ºç‰¹å¾

ä½œè€…: Lead Algorithm Engineer
åˆ›å»ºæ—¶é—´: 2025-12-10
"""

import pandas as pd
import numpy as np
import logging
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, log_loss, classification_report
from xgboost import XGBClassifier

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥åŸºçº¿è®­ç»ƒå™¨
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))
from train_baseline import BaselineTrainer


class SimpleEnhancedTrainer(BaselineTrainer):
    """ç®€åŒ–å¢å¼ºç‰¹å¾è®­ç»ƒå™¨"""

    def select_enhanced_features(self, df: pd.DataFrame) -> tuple:
        """é€‰æ‹©åŸºç¡€å¢å¼ºç‰¹å¾"""
        logger.info("ğŸ¯ é€‰æ‹©åŸºç¡€å¢å¼ºç‰¹å¾")

        # åŸºç¡€æ»šåŠ¨ç‰¹å¾
        rolling_features = [col for col in df.columns if 'last_' in col]

        # åŸºç¡€ä¸Šä¸‹æ–‡ç‰¹å¾
        context_features = [
            'year', 'month', 'day_of_week', 'is_weekend'
        ]

        context_features = [col for col in context_features if col in df.columns]

        # ç®€å•å¢å¼ºç‰¹å¾
        simple_enhanced = []

        # 1. ä¸»å®¢åœºxGå¯¹æ¯”
        for window in [3, 5, 10]:
            home_xg_col = f'home_last_{window}_avg_xg'
            away_xg_col = f'away_last_{window}_avg_xg'

            if home_xg_col in df.columns and away_xg_col in df.columns:
                df[f'xg_diff_{window}'] = df[home_xg_col] - df[away_xg_col]
                simple_enhanced.append(f'xg_diff_{window}')

            # 2. ä¸»å®¢åœºè¿›çƒå¯¹æ¯”
            home_goals_col = f'home_last_{window}_avg_goals_scored'
            away_goals_col = f'away_last_{window}_avg_goals_scored'

            if home_goals_col in df.columns and away_goals_col in df.columns:
                df[f'goals_diff_{window}'] = df[home_goals_col] - df[away_goals_col]
                simple_enhanced.append(f'goals_diff_{window}')

            # 3. ä¸»å®¢åœºèƒœç‡å¯¹æ¯”
            home_win_col = f'home_last_{window}_win_rate'
            away_win_col = f'away_last_{window}_win_rate'

            if home_win_col in df.columns and away_win_col in df.columns:
                df[f'win_rate_diff_{window}'] = df[home_win_col] - df[away_win_col]
                simple_enhanced.append(f'win_rate_diff_{window}')

        # 4. æ”»é˜²å¹³è¡¡æŒ‡æ•°
        for window in [3, 5]:
            home_goals_col = f'home_last_{window}_avg_goals_scored'
            home_conceded_col = f'home_last_{window}_avg_goals_conceded'
            away_goals_col = f'away_last_{window}_avg_goals_scored'
            away_conceded_col = f'away_last_{window}_avg_goals_conceded'

            if all(col in df.columns for col in [home_goals_col, home_conceded_col]):
                df[f'home_attack_defense_balance_{window}'] = (
                    df[home_goals_col] - df[home_conceded_col]
                )
                simple_enhanced.append(f'home_attack_defense_balance_{window}')

            if all(col in df.columns for col in [away_goals_col, away_conceded_col]):
                df[f'away_attack_defense_balance_{window}'] = (
                    df[away_goals_col] - df[away_conceded_col]
                )
                simple_enhanced.append(f'away_attack_defense_balance_{window}')

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        all_feature_columns = rolling_features + context_features + simple_enhanced

        logger.info(f"   âœ… æ»šåŠ¨ç‰¹å¾: {len(rolling_features)}")
        logger.info(f"   âš¡ å¢å¼ºç‰¹å¾: {len(simple_enhanced)}")
        logger.info(f"   ğŸ“… ä¸Šä¸‹æ–‡ç‰¹å¾: {len(context_features)}")
        logger.info(f"   ğŸ“‹ æ€»ç‰¹å¾æ•°: {len(all_feature_columns)}")

        # æå–ç‰¹å¾å’Œç›®æ ‡
        X = df[all_feature_columns].copy()
        y = df['true_result'].copy()

        # å¤„ç†ç¼ºå¤±å€¼
        X = X.fillna(0)

        logger.info(f"   ğŸ“Š ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        logger.info(f"   ğŸ¯ ç›®æ ‡å˜é‡å½¢çŠ¶: {y.shape}")

        return X, y, all_feature_columns


def run_enhanced_experiment():
    """è¿è¡Œå¢å¼ºç‰¹å¾å®éªŒ"""
    print("ğŸ”¬ ç®€åŒ–å¢å¼ºç‰¹å¾å®éªŒ")
    print("="*60)

    # 1. åŸºçº¿ç»“æœ
    baseline_acc = 0.5553
    baseline_logloss = 1.0396

    print(f"\nğŸ“Š åŸºçº¿æ¨¡å‹æ€§èƒ½:")
    print(f"   å‡†ç¡®ç‡: {baseline_acc:.4f}")
    print(f"   Log Loss: {baseline_logloss:.4f}")

    # 2. è®­ç»ƒå¢å¼ºæ¨¡å‹
    print(f"\nğŸš€ è®­ç»ƒå¢å¼ºæ¨¡å‹...")

    trainer = SimpleEnhancedTrainer()

    # åŠ è½½å’Œå‡†å¤‡æ•°æ®
    df = trainer.load_and_prepare_data("data/processed/features_v2_rolling.csv")

    # é€‰æ‹©å¢å¼ºç‰¹å¾
    X, y, feature_columns = trainer.select_enhanced_features(df)

    # æ—¶åºåˆ†å‰²
    X_train, X_test, y_train_enc, y_test_enc, y_train_orig, y_test_orig = \
        trainer.split_data_chronological(X, y)

    # è®­ç»ƒæ¨¡å‹
    trainer.feature_names = feature_columns
    trainer.train_xgboost(X_train, y_train_enc)

    # è¯„ä¼°æ¨¡å‹
    results = trainer.evaluate_model(X_test, y_test_enc, y_test_orig)

    # ç‰¹å¾é‡è¦æ€§
    trainer.plot_feature_importance()

    # 3. æ€§èƒ½å¯¹æ¯”
    enhanced_acc = results['accuracy']
    enhanced_logloss = results['log_loss']

    acc_improvement = ((enhanced_acc - baseline_acc) / baseline_acc) * 100
    logloss_improvement = ((baseline_logloss - enhanced_logloss) / baseline_logloss) * 100

    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
    print(f"{'æŒ‡æ ‡':<15} {'åŸºçº¿':<10} {'å¢å¼º':<10} {'æ”¹è¿›':<10}")
    print("-" * 50)
    print(f"{'å‡†ç¡®ç‡':<15} {baseline_acc:<10.4f} {enhanced_acc:<10.4f} {acc_improvement:+.2f}%")
    print(f"{'Log Loss':<15} {baseline_logloss:<10.4f} {enhanced_logloss:<10.4f} {logloss_improvement:+.2f}%")

    if acc_improvement > 0.5:
        print(f"\nğŸ‰ å¢å¼ºç‰¹å¾æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½!")
    elif acc_improvement > 0:
        print(f"\nğŸ“ˆ å¢å¼ºç‰¹å¾è½»å¾®æå‡äº†æ¨¡å‹æ€§èƒ½")
    else:
        print(f"\nâ¡ï¸ å¢å¼ºç‰¹å¾å¯¹æ€§èƒ½å½±å“æœ‰é™")

    return results


if __name__ == "__main__":
    run_enhanced_experiment()