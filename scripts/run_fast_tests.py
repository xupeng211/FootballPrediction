#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è¿è¡Œè„šæœ¬
å®ç°åˆ†å±‚æµ‹è¯•ç­–ç•¥ï¼Œä¼˜åŒ–æµ‹è¯•æ‰§è¡Œé€Ÿåº¦
"""

import os
import sys
import subprocess
import time
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class FastTestRunner:
    """å¿«é€Ÿæµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self):
        self.project_root = project_root
        self.results = {}

    def run_command(self, cmd, description, timeout=60):
        """è¿è¡Œå‘½ä»¤å¹¶è®°å½•ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ {description}")
        print(f"{'='*60}")

        start_time = time.time()
        try:
            result = subprocess.run(
                cmd,
                shell=True,
                capture_output=True,
                text=True,
                timeout=timeout,
                cwd=self.project_root
            )

            elapsed = time.time() - start_time

            # è§£æè¾“å‡º
            if result.returncode == 0:
                print(f"âœ… æˆåŠŸï¼è€—æ—¶: {elapsed:.2f}ç§’")

                # æå–æµ‹è¯•ç»Ÿè®¡
                output = result.stdout
                if "passed" in output:
                    for line in output.split('\n'):
                        if 'passed' in line and ('failed' in line or 'error' in line or 'skipped' in line):
                            print(f"ğŸ“Š {line.strip()}")
                            break

                # æå–è¦†ç›–ç‡
                if "TOTAL" in output:
                    for line in output.split('\n'):
                        if "TOTAL" in line and "%" in line:
                            print(f"ğŸ¯ è¦†ç›–ç‡: {line.strip()}")
                            self.results['coverage'] = line.strip()
                            break

            else:
                print(f"âŒ å¤±è´¥ï¼è€—æ—¶: {elapsed:.2f}ç§’")
                if result.stderr:
                    print(f"é”™è¯¯ä¿¡æ¯: {result.stderr[:200]}...")

            self.results[description] = {
                'success': result.returncode == 0,
                'time': elapsed,
                'output': result.stdout[:500] if result.stdout else ''
            }

            return result.returncode == 0

        except subprocess.TimeoutExpired:
            print(f"â° è¶…æ—¶ï¼è¶…è¿‡ {timeout} ç§’")
            self.results[description] = {
                'success': False,
                'time': timeout,
                'output': 'TIMEOUT'
            }
            return False

        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")
            self.results[description] = {
                'success': False,
                'time': 0,
                'output': str(e)
            }
            return False

    def run_level_1_tests(self):
        """Level 1: æ ¸å¿ƒå•å…ƒæµ‹è¯•ï¼ˆ< 30ç§’ï¼‰"""
        print("\nğŸ” Level 1: è¿è¡Œæ ¸å¿ƒå•å…ƒæµ‹è¯•")

        # æµ‹è¯•é€‚é…å™¨æ¨¡å—
        cmd1 = "python -m pytest tests/unit/adapters/ -q --tb=no"
        self.run_command(cmd1, "é€‚é…å™¨æ¨¡å—æµ‹è¯•", timeout=30)

        # æµ‹è¯•æ ¸å¿ƒå·¥å…·
        cmd2 = "python -m pytest tests/unit/utils/test_class_methods.py tests/unit/utils/test_retry.py -q --tb=no"
        self.run_command(cmd2, "æ ¸å¿ƒå·¥å…·æµ‹è¯•", timeout=30)

        # æµ‹è¯•åŸºç¡€æœåŠ¡
        cmd3 = "python -m pytest tests/unit/services/test_data_processing.py::TestDataProcessor::test_process_batch_data -q --tb=no"
        self.run_command(cmd3, "åŸºç¡€æœåŠ¡æµ‹è¯•", timeout=30)

    def run_level_2_tests(self):
        """Level 2: æ‰©å±•å•å…ƒæµ‹è¯•ï¼ˆ< 60ç§’ï¼‰"""
        print("\nğŸ” Level 2: è¿è¡Œæ‰©å±•å•å…ƒæµ‹è¯•")

        # æµ‹è¯•æ•°æ®åº“æ¨¡å‹
        cmd1 = "python -m pytest tests/unit/database/models/ -q --tb=no"
        self.run_command(cmd1, "æ•°æ®åº“æ¨¡å‹æµ‹è¯•", timeout=60)

        # æµ‹è¯•APIç»„ä»¶
        cmd2 = "python -m pytest tests/unit/api/test_health_check.py tests/unit/api/test_dependencies.py -q --tb=no"
        self.run_command(cmd2, "APIç»„ä»¶æµ‹è¯•", timeout=60)

        # æµ‹è¯•ä»»åŠ¡æ¨¡å—
        cmd3 = "python -m pytest tests/unit/tasks/test_error_logger.py -q --tb=no"
        self.run_command(cmd3, "ä»»åŠ¡æ¨¡å—æµ‹è¯•", timeout=60)

    def run_level_3_tests(self):
        """Level 3: é›†æˆæµ‹è¯•ï¼ˆ< 120ç§’ï¼‰"""
        print("\nğŸ” Level 3: è¿è¡Œé›†æˆæµ‹è¯•")

        # æµ‹è¯•å®Œæ•´çš„æ•°æ®åº“æ¨¡å—
        cmd1 = "python -m pytest tests/unit/database/ -k 'not performance' -q --tb=no"
        self.run_command(cmd1, "æ•°æ®åº“é›†æˆæµ‹è¯•", timeout=120)

        # æµ‹è¯•ç¼“å­˜æ¨¡å—
        cmd2 = "python -m pytest tests/unit/cache/ -q --tb=no --ignore=tests/unit/cache/test_mock_redis.py"
        self.run_command(cmd2, "ç¼“å­˜æ¨¡å—æµ‹è¯•", timeout=120)

    def run_coverage_check(self):
        """è¿è¡Œè¦†ç›–ç‡æ£€æŸ¥"""
        print("\nğŸ“Š è¿è¡Œè¦†ç›–ç‡æ£€æŸ¥")

        # åªå¯¹é€šè¿‡çš„æµ‹è¯•è¿è¡Œè¦†ç›–ç‡
        cmd = "python -m pytest tests/unit/adapters/ tests/unit/utils/test_class_methods.py tests/unit/utils/test_retry.py --cov=src --cov-report=term-missing --tb=no -q"
        self.run_command(cmd, "è¦†ç›–ç‡æ£€æŸ¥", timeout=120)

    def run_all_levels(self, max_level=3):
        """è¿è¡Œæ‰€æœ‰çº§åˆ«çš„æµ‹è¯•"""
        total_start = time.time()

        print(f"\n{'#'*60}")
        print("# ğŸš€ å¿«é€Ÿæµ‹è¯•æ‰§è¡Œå™¨")
        print("# æ‰§è¡Œåˆ†å±‚æµ‹è¯•ç­–ç•¥ï¼Œä¼˜åŒ–é€Ÿåº¦")
        print(f"#{'#'*60}")

        if max_level >= 1:
            self.run_level_1_tests()

        if max_level >= 2:
            self.run_level_2_tests()

        if max_level >= 3:
            self.run_level_3_tests()

        # è¿è¡Œè¦†ç›–ç‡æ£€æŸ¥
        self.run_coverage_check()

        # æ€»ç»“
        total_time = time.time() - total_start
        self.print_summary(total_time)

    def print_summary(self, total_time):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print(f"\n{'='*60}")
        print("ğŸ“Š æµ‹è¯•æ‰§è¡Œæ€»ç»“")
        print(f"{'='*60}")

        success_count = sum(1 for r in self.results.values() if r['success'])
        total_count = len(self.results)

        print(f"âœ… æˆåŠŸ: {success_count}/{total_count}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")

        if 'coverage' in self.results:
            print(f"ğŸ¯ è¦†ç›–ç‡: {self.results['coverage']}")

        print("\nè¯¦ç»†ç»“æœ:")
        for desc, result in self.results.items():
            status = "âœ…" if result['success'] else "âŒ"
            print(f"{status} {desc}: {result['time']:.2f}ç§’")

        # å»ºè®®
        print("\nğŸ’¡ å»ºè®®:")
        if total_time > 300:
            print("- è€ƒè™‘ä½¿ç”¨å¹¶è¡Œæµ‹è¯•: pytest -n auto")
            print("- è€ƒè™‘è·³è¿‡æ…¢é€Ÿæµ‹è¯•: pytest -m 'not slow'")
        if success_count < total_count:
            print("- ä¿®å¤å¤±è´¥çš„æµ‹è¯•ä»¥æå‡ä»£ç è´¨é‡")
        if 'coverage' not in self.results:
            print("- è¿è¡Œè¦†ç›–ç‡æ£€æŸ¥ä»¥äº†è§£æµ‹è¯•è¦†ç›–æƒ…å†µ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¿«é€Ÿæµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument(
        "--level",
        type=int,
        default=3,
        choices=[1, 2, 3],
        help="æµ‹è¯•çº§åˆ« (1: å¿«é€Ÿ, 2: ä¸­ç­‰, 3: å®Œæ•´)"
    )
    parser.add_argument(
        "--coverage",
        action="store_true",
        help="åªè¿è¡Œè¦†ç›–ç‡æ£€æŸ¥"
    )
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œ (éœ€è¦ pytest-xdist)"
    )

    args = parser.parse_args()

    runner = FastTestRunner()

    if args.coverage:
        runner.run_coverage_check()
    else:
        # è®¾ç½®å¹¶è¡Œæ‰§è¡Œå‚æ•°
        if args.parallel:
            os.environ['PYTEST_ADDOPTS'] = '-n auto'

        runner.run_all_levels(max_level=args.level)


if __name__ == "__main__":
    main()