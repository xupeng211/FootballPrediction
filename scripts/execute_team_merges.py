#!/usr/bin/env python3
"""
é¦–å¸­æ•°æ®æ²»ç†ä¸“å®¶ä¸“ç”¨ - çƒé˜Ÿå®ä½“åˆå¹¶æ‰§è¡Œå™¨
æ‰§è¡Œåˆå¹¶è®¡åˆ’ï¼Œå°†é‡å¤çƒé˜Ÿæ•°æ®ç¼åˆ
"""

import subprocess
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class TeamMergeExecutor:
    """çƒé˜Ÿåˆå¹¶æ‰§è¡Œå™¨"""

    def __init__(self):
        self.merge_plan = {}
        self.stats = {
            "total_merges": 0,
            "successful_merges": 0,
            "failed_merges": 0,
            "matches_updated": 0,
            "teams_deleted": 0,
        }

    def load_merge_plan(self, filename: str = "merge_plan.json") -> bool:
        """åŠ è½½åˆå¹¶è®¡åˆ’"""
        try:
            with open(filename, encoding="utf-8") as f:
                self.merge_plan = json.load(f)

            self.stats["total_merges"] = len(self.merge_plan.get("merges", []))
            logger.info(f"ğŸ“‹ åŠ è½½åˆå¹¶è®¡åˆ’: {self.stats['total_merges']} ç»„åˆå¹¶")
            logger.info(
                f"ğŸ“… ç”Ÿæˆæ—¶é—´: {self.merge_plan.get('generated_at', 'Unknown')}"
            )
            logger.info(
                f"ğŸ¯ ç›¸ä¼¼åº¦é˜ˆå€¼: {self.merge_plan.get('similarity_threshold', 'Unknown')}"
            )
            return True

        except Exception as e:
            logger.error(f"âŒ åŠ è½½åˆå¹¶è®¡åˆ’å¤±è´¥: {e}")
            return False

    def execute_team_merge(self, master_id: int, duplicate_id: int) -> tuple[bool, int]:
        """æ‰§è¡Œå•ä¸ªçƒé˜Ÿåˆå¹¶"""
        try:
            # å¼€å§‹äº‹åŠ¡
            logger.info(f"ğŸ”„ åˆå¹¶çƒé˜Ÿ: Master {master_id} â† Duplicate {duplicate_id}")

            # 1. æ›´æ–°matchesè¡¨ä¸­çš„ä¸»é˜ŸID
            update_home_cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-c",
                f"UPDATE matches SET home_team_id = {master_id} WHERE home_team_id = {duplicate_id} AND data_source = 'fbref';",
            ]

            home_result = subprocess.run(
                update_home_cmd, capture_output=True, text=True
            )
            if home_result.returncode != 0:
                logger.error(f"âŒ æ›´æ–°ä¸»é˜ŸIDå¤±è´¥: {home_result.stderr}")
                return False, 0

            # è·å–æ›´æ–°çš„è¡Œæ•° - å¤„ç†psqlè¿”å›çš„"UPDATE N"æ ¼å¼
            home_output = home_result.stdout.strip()
            home_updated = 0
            if home_output:
                # æå–æ•°å­—éƒ¨åˆ†
                import re

                match = re.search(r"\d+", home_output)
                if match:
                    home_updated = int(match.group())

            # 2. æ›´æ–°matchesè¡¨ä¸­çš„å®¢é˜ŸID
            update_away_cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-c",
                f"UPDATE matches SET away_team_id = {master_id} WHERE away_team_id = {duplicate_id} AND data_source = 'fbref';",
            ]

            away_result = subprocess.run(
                update_away_cmd, capture_output=True, text=True
            )
            if away_result.returncode != 0:
                logger.error(f"âŒ æ›´æ–°å®¢é˜ŸIDå¤±è´¥: {away_result.stderr}")
                return False, 0

            # è·å–æ›´æ–°çš„è¡Œæ•° - å¤„ç†psqlè¿”å›çš„"UPDATE N"æ ¼å¼
            away_output = away_result.stdout.strip()
            away_updated = 0
            if away_output:
                # æå–æ•°å­—éƒ¨åˆ†
                match = re.search(r"\d+", away_output)
                if match:
                    away_updated = int(match.group())

            total_updated = home_updated + away_updated

            # 3. åˆ é™¤é‡å¤çƒé˜Ÿè®°å½•
            delete_cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-c",
                f"DELETE FROM teams WHERE id = {duplicate_id};",
            ]

            delete_result = subprocess.run(delete_cmd, capture_output=True, text=True)
            if delete_result.returncode != 0:
                logger.error(f"âŒ åˆ é™¤é‡å¤çƒé˜Ÿå¤±è´¥: {delete_result.stderr}")
                return False, 0

            logger.info(f"âœ… åˆå¹¶æˆåŠŸ: æ›´æ–° {total_updated} åœºæ¯”èµ›ï¼Œåˆ é™¤1ä¸ªé‡å¤çƒé˜Ÿ")
            return True, total_updated

        except Exception as e:
            logger.error(f"âŒ åˆå¹¶å¼‚å¸¸ {master_id} â† {duplicate_id}: {e}")
            return False, 0

    def execute_all_merges(self) -> bool:
        """æ‰§è¡Œæ‰€æœ‰åˆå¹¶æ“ä½œ"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œçƒé˜Ÿå®ä½“åˆå¹¶")
        logger.info(f"ğŸ“Š å°†è¦åˆå¹¶ {self.stats['total_merges']} å¯¹çƒé˜Ÿ")

        merges = self.merge_plan.get("merges", [])

        for i, merge in enumerate(merges, 1):
            master = merge["master"]
            duplicate = merge["duplicate"]
            similarity = merge.get("similarity", 0)

            logger.info(
                f"ğŸ”„ è¿›åº¦: {i}/{self.stats['total_merges']} ({i/self.stats['total_merges']*100:.1f}%)"
            )
            logger.info(f"ğŸ¯ ç›¸ä¼¼åº¦: {similarity:.3f}")
            logger.info(f"ğŸ‘‘ Master: '{master['name']}' (ID: {master['id']})")
            logger.info(f"ğŸ“‹ Duplicate: '{duplicate['name']}' (ID: {duplicate['id']})")

            success, matches_updated = self.execute_team_merge(
                master["id"], duplicate["id"]
            )

            if success:
                self.stats["successful_merges"] += 1
                self.stats["matches_updated"] += matches_updated
                self.stats["teams_deleted"] += 1
            else:
                self.stats["failed_merges"] += 1
                logger.error(f"âŒ åˆå¹¶å¤±è´¥: {master['name']} â† {duplicate['name']}")

        logger.info("=" * 60)
        logger.info("ğŸ‰ çƒé˜Ÿå®ä½“åˆå¹¶æ‰§è¡Œå®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(
            f"âœ… æˆåŠŸåˆå¹¶: {self.stats['successful_merges']}/{self.stats['total_merges']}"
        )
        logger.info(f"âŒ å¤±è´¥åˆå¹¶: {self.stats['failed_merges']}")
        logger.info(f"ğŸ”„ æ›´æ–°æ¯”èµ›: {self.stats['matches_updated']} åœº")
        logger.info(f"ğŸ—‘ï¸ åˆ é™¤çƒé˜Ÿ: {self.stats['teams_deleted']} ä¸ª")

        return self.stats["failed_merges"] == 0

    def verify_merge_results(self) -> dict:
        """éªŒè¯åˆå¹¶ç»“æœ"""
        try:
            logger.info("ğŸ” éªŒè¯åˆå¹¶ç»“æœ...")

            # ç»Ÿè®¡çƒé˜Ÿæ€»æ•°
            team_count_cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-tAc",
                "SELECT COUNT(*) FROM teams;",
            ]

            team_result = subprocess.run(team_count_cmd, capture_output=True, text=True)
            final_team_count = (
                int(team_result.stdout.strip()) if team_result.returncode == 0 else 0
            )

            # æ£€æŸ¥é‡å¤çƒé˜Ÿæ•°é‡
            duplicate_cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-tAc",
                """
                SELECT COUNT(*)
                FROM (
                    SELECT
                        CASE
                            WHEN name ~ '^[a-z]{2}\\s' THEN SUBSTRING(name FROM 4)
                            WHEN name ~ '\\s[a-z]{2}$' THEN SUBSTRING(name FROM 1 FOR LENGTH(name) - 3)
                            ELSE name
                        END as clean_name
                    FROM teams
                    GROUP BY clean_name
                    HAVING COUNT(*) > 1
                ) duplicates;
                """,
            ]

            duplicate_result = subprocess.run(
                duplicate_cmd, capture_output=True, text=True
            )
            remaining_duplicates = (
                int(duplicate_result.stdout.strip())
                if duplicate_result.returncode == 0
                else 0
            )

            # ç»Ÿè®¡æ¯”èµ›è®°å½•æ•°
            match_count_cmd = [
                "docker-compose",
                "exec",
                "db",
                "psql",
                "-U",
                "postgres",
                "-d",
                "football_prediction",
                "-tAc",
                "SELECT COUNT(*) FROM matches WHERE data_source = 'fbref';",
            ]

            match_result = subprocess.run(
                match_count_cmd, capture_output=True, text=True
            )
            final_match_count = (
                int(match_result.stdout.strip()) if match_result.returncode == 0 else 0
            )

            verification_results = {
                "final_team_count": final_team_count,
                "remaining_duplicates": remaining_duplicates,
                "final_match_count": final_match_count,
                "duplicate_reduction_pct": 0,
                "success": remaining_duplicates <= 5,  # å…è®¸å°‘é‡å‰©ä½™
            }

            if self.stats["total_merges"] > 0:
                original_duplicates = self.stats["total_merges"]
                verification_results["duplicate_reduction_pct"] = (
                    (original_duplicates - remaining_duplicates) / original_duplicates
                ) * 100

            logger.info("ğŸ“Š éªŒè¯ç»“æœ:")
            logger.info(f"   æœ€ç»ˆçƒé˜Ÿæ•°: {final_team_count}")
            logger.info(f"   å‰©ä½™é‡å¤: {remaining_duplicates}")
            logger.info(f"   æ¯”èµ›è®°å½•: {final_match_count}")
            logger.info(
                f"   é‡å¤å‡å°‘: {verification_results['duplicate_reduction_pct']:.1f}%"
            )

            return verification_results

        except Exception as e:
            logger.error(f"âŒ éªŒè¯ç»“æœå¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}

    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„åˆå¹¶æµç¨‹"""
        logger.info("ğŸš€ å¯åŠ¨é¦–å¸­æ•°æ®æ²»ç†ä¸“å®¶ - çƒé˜Ÿå®ä½“åˆå¹¶æ‰§è¡Œå™¨")
        start_time = datetime.now()

        # åŠ è½½åˆå¹¶è®¡åˆ’
        if not self.load_merge_plan():
            return False

        # ç¡®è®¤æ‰§è¡Œ
        logger.info(f"âš ï¸  å³å°†æ‰§è¡Œ {self.stats['total_merges']} ç»„çƒé˜Ÿåˆå¹¶")
        logger.info("ğŸ”’ è¿™å°†ä¿®æ”¹æ•°æ®åº“ä¸­çš„matcheså’Œteamsè¡¨")

        # æ‰§è¡Œæ‰€æœ‰åˆå¹¶
        success = self.execute_all_merges()

        # éªŒè¯ç»“æœ
        verification = self.verify_merge_results()

        # è®¡ç®—æ€»è€—æ—¶
        duration = (datetime.now() - start_time).total_seconds()

        logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’")

        # æœ€ç»ˆç»“æœ
        final_success = success and verification.get("success", False)

        if final_success:
            logger.info("ğŸ‰ çƒé˜Ÿå®ä½“åˆå¹¶åœ†æ»¡æˆåŠŸï¼")
            logger.info("âœ… æ•°æ®å·²æ ‡å‡†åŒ–ï¼Œæ¶ˆé™¤äº†å¤§éƒ¨åˆ†é‡å¤çƒé˜Ÿ")
        else:
            logger.error("âŒ çƒé˜Ÿå®ä½“åˆå¹¶å¤±è´¥")
            if not verification.get("success", False):
                logger.error(f"âŒ éªŒè¯å¤±è´¥: {verification.get('error', 'Unknown')}")

        return final_success


def main():
    """ä¸»å‡½æ•°"""
    try:
        executor = TeamMergeExecutor()
        success = executor.run()

        if success:
            logger.info("âœ… çƒé˜Ÿå®ä½“åˆå¹¶æ‰§è¡ŒæˆåŠŸ")
            return 0
        else:
            logger.error("âŒ çƒé˜Ÿå®ä½“åˆå¹¶æ‰§è¡Œå¤±è´¥")
            return 1

    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
