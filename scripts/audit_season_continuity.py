#!/usr/bin/env python3
"""
2023-2024èµ›å­£æ•°æ®å®Œæ•´æ€§å®¡è®¡è„šæœ¬
Data Integrity Auditor - èµ›ç¨‹è¿ç»­æ€§æ£€æŸ¥

Purpose: æ£€æŸ¥è‹±è¶…2023-2024èµ›å­£æ•°æ®æ˜¯å¦å­˜åœ¨æ–­ç‚¹
ç›®æ ‡: ç¡®ä¿æ»šåŠ¨ç‰¹å¾å’Œç–²åŠ³åº¦è®¡ç®—çš„å‡†ç¡®æ€§
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict
import json
import warnings

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sqlalchemy import create_engine, text
import pandas as pd
import numpy as np

# ç¦ç”¨è­¦å‘Šä»¥è·å¾—æ›´æ¸…æ™°çš„è¾“å‡º
warnings.filterwarnings('ignore')

class SeasonContinuityAuditor:
    """èµ›å­£è¿ç»­æ€§å®¡è®¡å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–å®¡è®¡å™¨"""
        self.db_url = "postgresql://postgres:postgres-dev-password@localhost:5432/football_prediction"
        self.season = "2023-2024"
        self.league_id = 2  # Premier League ID
        self.league_name = "Premier League"

        # è¿æ¥æ•°æ®åº“
        try:
            self.engine = create_engine(self.db_url)
            with self.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def get_team_season_stats(self) -> pd.DataFrame:
        """
        è·å–çƒé˜Ÿçš„èµ›å­£ç»Ÿè®¡ä¿¡æ¯
        Returns: DataFrame with columns: team_name, team_id, total_matches, completed_matches
        """
        print(f"ğŸ“Š åˆ†æ {self.league_name} {self.season} èµ›å­£æ•°æ®...")

        query = """
        WITH team_matches AS (
            SELECT
                t.name as team_name,
                t.id as team_id,
                COUNT(*) as total_matches,
                COUNT(CASE WHEN m.status = 'completed' THEN 1 END) as completed_matches
            FROM teams t
            JOIN matches m ON (
                (m.home_team_id = t.id OR m.away_team_id = t.id)
                AND m.league_id = :league_id
                AND COALESCE(m.season, '') = :season
            )
            GROUP BY t.id, t.name
        )
        SELECT * FROM team_matches
        ORDER BY completed_matches DESC
        """

        with self.engine.connect() as conn:
            result = pd.read_sql_query(text(query), conn, params={
                "league_id": self.league_id,
                "season": self.season
            })

        return result

    def check_game_count_completeness(self, team_stats: pd.DataFrame) -> dict:
        """
        æ£€æŸ¥æ¯”èµ›åœºæ¬¡å®Œæ•´æ€§
        Returns: {"incomplete_teams": [...], "expected_count": int, "issues": list}
        """
        print("ğŸ” æ£€æŸ¥æ¯”èµ›åœºæ¬¡å®Œæ•´æ€§...")

        # è‹±è¶…æ ‡å‡†ï¼šæ¯æ”¯çƒé˜Ÿ38åœºæ¯”èµ›
        expected_count = 38
        incomplete_teams = []
        issues = []

        for _, row in team_stats.iterrows():
            team_name = row['team_name']
            completed_matches = row['completed_matches']

            if completed_matches != expected_count:
                issue = f"çƒé˜Ÿ {team_name}: ä»… {completed_matches} åœºæ¯”èµ› (æœŸæœ› {expected_count} åœº)"
                incomplete_teams.append({
                    'team_name': team_name,
                    'team_id': row['team_id'],
                    'completed_matches': completed_matches,
                    'total_matches': row['total_matches']
                })
                issues.append(issue)
                print(f"âŒ {issue}")

        if len(team_stats) == 0:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•çƒé˜Ÿæ•°æ®")
            complete_teams = 0
        else:
            complete_teams = len(team_stats) - len(incomplete_teams)
            print(f"ğŸ“ˆ å®Œæ•´é˜Ÿä¼: {complete_teams}/{len(team_stats)} ({complete_teams/len(team_stats)*100:.1f}%)")

        return {
            "incomplete_teams": incomplete_teams,
            "expected_count": expected_count,
            "issues": issues,
            "complete_teams": complete_teams,
            "total_teams": len(team_stats)
        }

    def get_team_match_timeline(self, team_id: int) -> pd.DataFrame:
        """
        è·å–çƒé˜Ÿçš„æ¯”èµ›æ—¶é—´çº¿
        Returns: DataFrame with match details sorted by date
        """
        query = """
        SELECT
            m.id as match_id,
            m.match_date,
            m.home_team_id = :team_id as is_home,
            m.home_score,
            m.away_score,
            m.status,
            m.raw_file_path,
            CASE
                WHEN m.home_team_id = :team_id THEN (SELECT name FROM teams WHERE id = m.away_team_id)
                ELSE (SELECT name FROM teams WHERE id = m.home_team_id)
            END as opponent_name,
            CASE
                WHEN m.home_team_id = :team_id THEN m.home_score
                ELSE m.away_score
            END as team_score,
            CASE
                WHEN m.home_team_id = :team_id THEN m.away_score
                ELSE m.home_score
            END as opponent_score,
            m.stats
        FROM matches m
        WHERE (
            (m.home_team_id = :team_id OR m.away_team_id = :team_id)
            AND m.league_id = :league_id
            AND COALESCE(m.season, '') = :season
            AND m.status = 'completed'
        )
        ORDER BY m.match_date
        """

        with self.engine.connect() as conn:
            result = pd.read_sql_query(text(query), conn, params={
                "team_id": team_id,
                "league_id": self.league_id,
                "season": self.season
            })

        return result

    def analyze_time_gaps(self, team_timeline: pd.DataFrame, team_name: str) -> list:
        """
        åˆ†ææ—¶é—´é—´éš™
        Returns: List of gap issues
        """
        if len(team_timeline) < 2:
            return []

        gaps = []

        for i in range(1, len(team_timeline)):
            prev_match = team_timeline.iloc[i-1]
            curr_match = team_timeline.iloc[i]

            prev_date = pd.to_datetime(prev_match['match_date'])
            curr_date = pd.to_datetime(curr_match['match_date'])

            gap_days = (curr_date - prev_date).days

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡21å¤© (è€ƒè™‘å›½é™…æ¯”èµ›æ—¥å’Œå†¬æ­‡æœŸ)
            # å†¬æ­‡æœŸé€šå¸¸åœ¨12æœˆä¸­æ—¬åˆ°1æœˆåº•ï¼Œå…è®¸æ›´é•¿é—´éš”
            month_gap = curr_date.month - prev_date.month
            winter_break_possible = (prev_date.month == 12 and curr_date.month >= 2) or \
                                   (prev_date.month == 1 and curr_date.month >= 2 and month_gap >= 2)

            if gap_days > 21 and not winter_break_possible:
                gap_info = {
                    'team': team_name,
                    'gap_days': gap_days,
                    'prev_match_date': prev_date.strftime('%Y-%m-%d'),
                    'curr_match_date': curr_date.strftime('%Y-%m-%d'),
                    'prev_match': f"{prev_match['opponent_name']} ({prev_match['team_score']}-{prev_match['opponent_score']})",
                    'curr_match': f"{curr_match['opponent_name']} ({curr_match['team_score']}-{curr_match['opponent_score']})"
                }
                gaps.append(gap_info)
                print(f"âš ï¸  {team_name}: {gap_days}å¤©é—´éš” ({prev_date.date()} â†’ {curr_date.date()})")

        return gaps

    def extract_week_numbers(self, team_timeline: pd.DataFrame) -> list:
        """
        ä»statså­—æ®µä¸­æå–å‘¨æ¬¡ä¿¡æ¯
        Returns: List of week numbers (sorted)
        """
        week_numbers = []

        for _, row in team_timeline.iterrows():
            try:
                stats = json.loads(row['stats']) if row['stats'] else {}
                raw_data = stats.get('raw_data', {})

                # å°è¯•å¤šç§å¯èƒ½çš„å‘¨æ¬¡å­—æ®µå
                week_field = None
                for possible_field in ['Wk', 'wk', 'Week', 'week', 'week_num']:
                    if possible_field in raw_data:
                        week_field = possible_field
                        break

                if week_field:
                    week_num = raw_data[week_field]
                    if week_num and week_num != '':
                        try:
                            week_int = int(float(week_num))  # å¤„ç† "10.0" è¿™æ ·çš„å€¼
                            week_numbers.append(week_int)
                        except (ValueError, TypeError):
                            continue

            except (json.JSONDecodeError, KeyError):
                continue

        return sorted(list(set(week_numbers)))  # å»é‡å¹¶æ’åº

    def check_week_continuity(self, team_timeline: pd.DataFrame, team_name: str) -> dict:
        """
        æ£€æŸ¥å‘¨æ¬¡è¿ç»­æ€§
        Returns: {"missing_weeks": [...], "available_weeks": [...]}
        """
        week_numbers = self.extract_week_numbers(team_timeline)

        if not week_numbers:
            return {
                "missing_weeks": [],
                "available_weeks": [],
                "issue": "No week data found"
            }

        # æ‰¾å‡ºç¼ºå¤±çš„å‘¨æ¬¡
        missing_weeks = []
        for week in range(1, max(week_numbers) + 1):
            if week not in week_numbers:
                missing_weeks.append(week)

        if missing_weeks:
            print(f"âŒ {team_name}: ç¼ºå¤±å‘¨æ¬¡ {missing_weeks}")

        return {
            "missing_weeks": missing_weeks,
            "available_weeks": week_numbers,
            "total_weeks": len(week_numbers),
            "missing_count": len(missing_weeks)
        }

    def analyze_raw_data_completeness(self, team_timeline: pd.DataFrame) -> dict:
        """
        åˆ†æåŸå§‹æ•°æ®å®Œæ•´æ€§
        Returns: Statistics about raw data preservation
        """
        raw_data_stats = {
            'total_matches': len(team_timeline),
            'with_raw_file': 0,
            'with_stats': 0,
            'with_raw_data': 0,
            'missing_raw_data': []
        }

        for idx, row in team_timeline.iterrows():
            has_raw_file = bool(row['raw_file_path'])
            has_stats = bool(row['stats'])

            if has_raw_file:
                raw_data_stats['with_raw_file'] += 1

            if has_stats:
                raw_data_stats['with_stats'] += 1

                try:
                    stats = json.loads(row['stats']) if row['stats'] else {}
                    if stats.get('raw_data'):
                        raw_data_stats['with_raw_data'] += 1
                    else:
                        raw_data_stats['missing_raw_data'].append(idx)
                except:
                    raw_data_stats['missing_raw_data'].append(idx)

        return raw_data_stats

    def analyze_available_data(self):
        """
        åˆ†æå¯ç”¨çš„æ•°æ®ç»“æ„
        """
        print("ğŸ“Š åˆ†ææ•°æ®åº“ä¸­çš„å¯ç”¨æ•°æ®...")

        # åˆ†ææ‰€æœ‰è”èµ›æ•°æ®
        leagues_query = """
        SELECT
            l.id as league_id,
            l.name as league_name,
            COUNT(*) as total_matches,
            COUNT(CASE WHEN m.status = 'completed' THEN 1 END) as completed_matches,
            COUNT(CASE WHEN m.season IS NOT NULL AND m.season != '' THEN 1 END) as with_season
        FROM matches m
        LEFT JOIN leagues l ON m.league_id = l.id
        GROUP BY l.id, l.name
        ORDER BY completed_matches DESC
        """

        with self.engine.connect() as conn:
            leagues_data = pd.read_sql_query(text(leagues_query), conn)

        print(f"ğŸ“Š å‘ç° {len(leagues_data)} ä¸ªè”èµ›çš„æ•°æ®")
        print("\nğŸ“‹ è”èµ›æ•°æ®æ¦‚å†µ (å‰10):")
        for _, row in leagues_data.head(10).iterrows():
            completion_rate = row['completed_matches'] / row['total_matches'] * 100 if row['total_matches'] > 0 else 0
            season_rate = row['with_season'] / row['total_matches'] * 100 if row['total_matches'] > 0 else 0
            print(f"   {row['league_name']}: {row['completed_matches']}/{row['total_matches']} åœºæ¯”èµ› ({completion_rate:.1f}%), æœ‰èµ›å­£æ ‡è®°: {season_rate:.1f}%")

        # å¯»æ‰¾è‹±è¶…ç›¸å…³æ•°æ® - å¤„ç†NAå€¼
        leagues_data_clean = leagues_data.dropna(subset=['league_name'])
        premier_leagues = leagues_data_clean[leagues_data_clean['league_name'].str.contains('Premier', case=False)]
        if len(premier_leagues) > 0:
            print(f"\nğŸ† æ‰¾åˆ° {len(premier_leagues)} ä¸ªè‹±è¶…ç›¸å…³è”èµ›:")
            for _, row in premier_leagues.iterrows():
                print(f"   {row['league_name']} (ID: {row['league_id']}): {row['completed_matches']} åœºæ¯”èµ›")

        return leagues_data

    def run_comprehensive_audit(self):
        """
        è¿è¡Œå®Œæ•´å®¡è®¡
        """
        print("ğŸ”¬ " + "="*60)
        print("ğŸ”¬ èµ›å­£æ•°æ®å®Œæ•´æ€§å®¡è®¡")
        print("ğŸ”¬ " + "="*60)

        # Step 0: åˆ†æå¯ç”¨æ•°æ®
        available_data = self.analyze_available_data()

        # æ£€æŸ¥æ˜¯å¦æœ‰è‹±è¶…æ•°æ® - å¤„ç†NAå€¼
        available_data_clean = available_data.dropna(subset=['league_name'])
        premier_leagues = available_data_clean[available_data_clean['league_name'].str.contains('Premier', case=False)]
        if len(premier_leagues) == 0:
            print(f"\nâŒ æœªæ‰¾åˆ°è‹±è¶…ç›¸å…³æ•°æ®")
            print(f"   ğŸ” å»ºè®®æ£€æŸ¥è”èµ›è¡¨ä¸­æ˜¯å¦å­˜åœ¨Premier League")
            print(f"   ğŸ” æˆ–è€ƒè™‘åˆ†æå…¶ä»–è”èµ›çš„æ•°æ®å®Œæ•´æ€§")
            return self.generate_no_data_recommendations(available_data)

        # Step 1: è·å–çƒé˜Ÿç»Ÿè®¡æ•°æ®
        team_stats = self.get_team_season_stats()
        print(f"\nğŸ“Š å‘ç° {len(team_stats)} æ”¯çƒé˜Ÿçš„æ•°æ®")

        # Step 2: æ£€æŸ¥æ¯”èµ›åœºæ¬¡å®Œæ•´æ€§
        print(f"\nğŸ“‹ ç¬¬ä¸€æ­¥ï¼šæ¯”èµ›åœºæ¬¡å®Œæ•´æ€§æ£€æŸ¥")
        print("-" * 50)
        game_count_result = self.check_game_count_completeness(team_stats)

        # Step 3: åˆ†æè¿ç»­æ€§é—®é¢˜
        print(f"\nğŸ“‹ ç¬¬äºŒæ­¥ï¼šæ—¶é—´çº¿è¿ç»­æ€§åˆ†æ")
        print("-" * 50)

        all_gaps = []
        all_week_issues = []
        raw_data_summary = []

        # åªåˆ†ææœ‰é—®é¢˜çš„é˜Ÿä¼ä»¥æé«˜æ•ˆç‡
        teams_to_analyze = game_count_result['incomplete_teams'][:5] if game_count_result['incomplete_teams'] else team_stats.head(5).to_dict('records')

        for team in teams_to_analyze:
            team_name = team['team_name']
            team_id = team['team_id']

            print(f"\nğŸ” åˆ†æçƒé˜Ÿ: {team_name} ({team['completed_matches']}åœºæ¯”èµ›)")

            # è·å–çƒé˜Ÿæ—¶é—´çº¿
            timeline = self.get_team_match_timeline(team_id)
            print(f"   ğŸ“… æ¯”èµ›æ—¶é—´çº¿: {timeline['match_date'].min()} â†’ {timeline['match_date'].max()}")

            # åˆ†ææ—¶é—´é—´éš™
            gaps = self.analyze_time_gaps(timeline, team_name)
            all_gaps.extend(gaps)

            # æ£€æŸ¥å‘¨æ¬¡è¿ç»­æ€§
            week_result = self.check_week_continuity(timeline, team_name)
            if week_result['missing_count'] > 0:
                all_week_issues.append({
                    'team': team_name,
                    'missing_weeks': week_result['missing_weeks'],
                    'available_weeks': week_result['available_weeks']
                })

            # åˆ†æåŸå§‹æ•°æ®å®Œæ•´æ€§
            raw_data_stats = self.analyze_raw_data_completeness(timeline)
            raw_data_summary.append({
                'team': team_name,
                **raw_data_stats
            })

            if gaps:
                print(f"   âš ï¸  å‘ç° {len(gaps)} ä¸ªæ—¶é—´é—´éš™é—®é¢˜")
            else:
                print("   âœ… æ—¶é—´é—´éš”æ­£å¸¸")

        # Step 4: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print(f"\nğŸ“‹ ç¬¬ä¸‰æ­¥ï¼šå®¡è®¡ç»“æœæ±‡æ€»")
        print("-" * 50)

        print(f"ğŸ“Š åœºæ¬¡å®Œæ•´æ€§:")
        print(f"   âœ… å®Œæ•´çƒé˜Ÿ: {game_count_result['complete_teams']}/{game_count_result['total_teams']}")
        print(f"   âŒ é—®é¢˜çƒé˜Ÿ: {len(game_count_result['incomplete_teams'])}")

        if game_count_result['incomplete_teams']:
            print(f"\nâš ï¸  é—®é¢˜çƒé˜Ÿè¯¦æƒ…:")
            for team in game_count_result['incomplete_teams']:
                print(f"   - {team['team_name']}: {team['completed_matches']}/38 åœº")

        print(f"\nğŸ“… æ—¶é—´é—´éš™é—®é¢˜: {len(all_gaps)} ä¸ª")
        for gap in all_gaps[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
            print(f"   - {gap['team']}: {gap['gap_days']}å¤©é—´éš” ({gap['prev_match_date']} â†’ {gap['curr_match_date']})")

        print(f"\nğŸ“Š å‘¨æ¬¡è¿ç»­æ€§é—®é¢˜: {len(all_week_issues)} æ”¯çƒé˜Ÿ")
        for issue in all_week_issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
            print(f"   - {issue['team']}: ç¼ºå¤±å‘¨æ¬¡ {issue['missing_weeks']}")

        print(f"\nğŸ“ åŸå§‹æ•°æ®ä¿å­˜ç»Ÿè®¡:")
        if raw_data_summary:
            total_matches = sum(s['total_matches'] for s in raw_data_summary)
            with_raw_file = sum(s['with_raw_file'] for s in raw_data_summary)
            with_stats = sum(s['with_stats'] for s in raw_data_summary)
            with_raw_data = sum(s['with_raw_data'] for s in raw_data_summary)

            print(f"   ğŸ“„ æ€»æ¯”èµ›æ•°: {total_matches}")
            print(f"   ğŸ—‚ï¸ æœ‰åŸå§‹æ–‡ä»¶: {with_raw_file}/{total_matches} ({with_raw_file/total_matches*100:.1f}%)")
            print(f"   ğŸ“Š æœ‰ç»Ÿè®¡æ•°æ®: {with_stats}/{total_matches} ({with_stats/total_matches*100:.1f}%)")
            print(f"   ğŸ“„ æœ‰åŸå§‹å†…å®¹: {with_raw_data}/{total_matches} ({with_raw_data/total_matches*100:.1f}%)")

        # ç”Ÿæˆä¿®å¤å»ºè®®
        self.generate_repair_recommendations(game_count_result, all_gaps, all_week_issues, raw_data_summary)

        return {
            'game_count_result': game_count_result,
            'time_gaps': all_gaps,
            'week_issues': all_week_issues,
            'raw_data_summary': raw_data_summary
        }

    def generate_no_data_recommendations(self, available_data):
        """
        ç”Ÿæˆæ— æ•°æ®æƒ…å†µä¸‹çš„å»ºè®®
        """
        print(f"\nğŸ”§ æ•°æ®é‡‡é›†å»ºè®®")
        print("-" * 50)

        if len(available_data) == 0:
            print(f"âŒ ä¸¥é‡é—®é¢˜: æ•°æ®åº“ä¸­å®Œå…¨æ²¡æœ‰æ¯”èµ›æ•°æ®")
            print(f"   ğŸ¯ ç«‹å³è¡ŒåŠ¨: è¿è¡Œå®Œæ•´çš„FBrefæ•°æ®é‡‡é›†")
            print(f"   ğŸ“ å»ºè®®å‘½ä»¤: python scripts/final_fbref_backfill.py")
            print(f"   âš ï¸  æ³¨æ„: é¦–æ¬¡é‡‡é›†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        else:
            # æ‰¾åˆ°æ•°æ®æœ€å¤šçš„è”èµ›
            best_league = available_data.iloc[0]
            print(f"âœ… å‘ç°æ•°æ®æœ€å¤šçš„è”èµ›: {best_league['league_name']}")
            print(f"   ğŸ“Š æ•°æ®é‡: {best_league['completed_matches']} åœºå·²å®Œæˆæ¯”èµ›")

            print(f"\nğŸ¯ æ›¿ä»£æ–¹æ¡ˆ:")
            print(f"   1. ä½¿ç”¨ç°æœ‰è”èµ›è¿›è¡Œå®Œæ•´æ€§å®¡è®¡")
            print(f"   2. è¿è¡Œé’ˆå¯¹ {best_league['league_name']} çš„è¿ç»­æ€§æ£€æŸ¥")
            print(f"   3. éªŒè¯ELTæ¶æ„åœ¨å®é™…æ•°æ®ä¸Šçš„å·¥ä½œæ•ˆæœ")

        return False

    def generate_repair_recommendations(self, game_count_result, gaps, week_issues, raw_data_summary):
        """
        ç”Ÿæˆä¿®å¤å»ºè®®
        """
        print(f"\nğŸ”§ ç¬¬å››æ­¥ï¼šä¿®å¤å»ºè®®")
        print("-" * 50)

        recommendations = []

        # åœºæ¬¡å®Œæ•´æ€§ä¿®å¤å»ºè®®
        if game_count_result['incomplete_teams']:
            missing_matches = sum(game_count_result['expected_count'] - t['completed_matches']
                                  for t in game_count_result['incomplete_teams'])
            print(f"ğŸ“‹ åœºæ¬¡å®Œæ•´æ€§ä¿®å¤:")
            print(f"   ğŸ“Š å‘ç° {len(game_count_result['incomplete_teams'])} æ”¯çƒé˜Ÿç¼ºå°‘ {missing_matches} åœºæ¯”èµ›")

            # æ£€æŸ¥æ•°æ®è´¨é‡
            teams_with_raw_data = [s for s in raw_data_summary if s['with_raw_file'] > 0]

            if teams_with_raw_data and len(teams_with_raw_data) / len(raw_data_summary) > 0.8:
                print(f"   ğŸ¯ æ¨èæ–¹æ¡ˆ: åŸºäºç°æœ‰åŸå§‹æ–‡ä»¶é‡æ–°è§£æ")
                print(f"   âœ… ä¼˜åŠ¿: åŸå§‹HTMLå·²ä¿å­˜ï¼Œæ”¯æŒé‡æ–°è§£æ")
                print(f"   ğŸ“ æ‰§è¡Œ: ä¿®æ”¹æ¸…æ´—é€»è¾‘ï¼Œé‡æ–°å¤„ç† {len(teams_with_raw_data)} æ”¯çƒé˜Ÿæ•°æ®")
            else:
                print(f"   ğŸ¯ æ¨èæ–¹æ¡ˆ: å¢é‡æ•°æ®é‡‡é›†")
                print(f"   âš ï¸  è­¦å‘Š: åŸå§‹æ–‡ä»¶ä¿å­˜ç‡ä½ï¼Œéœ€è¦è¡¥å……é‡‡é›†")
                print(f"   ğŸ“ æ‰§è¡Œ: é’ˆå¯¹ç¼ºå¤±æ¯”èµ›çš„æ—¥æœŸèŒƒå›´é‡æ–°é‡‡é›†")

        # æ—¶é—´é—´éš™ä¿®å¤å»ºè®®
        if gaps:
            max_gap = max(g['gap_days'] for g in gaps)
            print(f"\nğŸ“… æ—¶é—´é—´éš™ä¿®å¤:")
            print(f"   âš ï¸  å‘ç°æœ€å¤§é—´éš™: {max_gap} å¤©")

            if max_gap > 60:  # è¶…è¿‡2ä¸ªæœˆ
                print(f"   ğŸ¯ ä¸¥é‡é—´éš™: å»ºè®®å®Œå…¨é‡æ–°é‡‡é›†è¯¥èµ›å­£æ•°æ®")
            elif max_gap > 30:  # è¶…è¿‡1ä¸ªæœˆ
                print(f"   ğŸ¯ ä¸­ç­‰é—´éš™: é’ˆå¯¹é—´éš™æ—¶é—´æ®µè¿›è¡Œé‡ç‚¹é‡‡é›†")
            else:
                print(f"   ğŸ¯ è½»å¾®é—´éš™: æ£€æŸ¥æ˜¯å¦ä¸ºæ­£å¸¸çš„å†¬æ­‡æœŸ")

        # å‘¨æ¬¡è¿ç»­æ€§ä¿®å¤å»ºè®®
        if week_issues:
            total_missing_weeks = sum(len(issue['missing_weeks']) for issue in week_issues)
            print(f"\nğŸ“Š å‘¨æ¬¡è¿ç»­æ€§ä¿®å¤:")
            print(f"   ğŸ“Š æ€»ç¼ºå¤±å‘¨æ¬¡: {total_missing_weeks}")
            print(f"   ğŸ¯ å»ºè®®: æ£€æŸ¥è§£æé€»è¾‘æ˜¯å¦æ­£ç¡®æå–Wkå­—æ®µ")
            print(f"   ğŸ“ æ‰§è¡Œ: è°ƒè¯•HTMLè§£æï¼Œç¡®ä¿å‘¨æ¬¡ä¿¡æ¯å®Œæ•´æå–")

        # åŸå§‹æ•°æ®å®Œæ•´æ€§å»ºè®®
        if raw_data_summary:
            avg_raw_data_rate = sum(s['with_raw_data'] for s in raw_data_summary) / sum(s['total_matches'] for s in raw_data_summary) * 100
            print(f"\nğŸ“ åŸå§‹æ•°æ®å®Œæ•´æ€§:")
            print(f"   ğŸ“Š å¹³å‡ä¿å­˜ç‡: {avg_raw_data_rate:.1f}%")

            if avg_raw_data_rate < 50:
                print(f"   âš ï¸  ä¸¥é‡è­¦å‘Š: åŸå§‹æ•°æ®ä¿å­˜ç‡è¿‡ä½")
                print(f"   ğŸ¯ å»ºè®®: æ£€æŸ¥HTMLä¿å­˜æœºåˆ¶ï¼Œç¡®ä¿æ‰€æœ‰æ¯”èµ›éƒ½ä¿å­˜äº†åŸå§‹æ–‡ä»¶")
            elif avg_raw_data_rate < 80:
                print(f"   âš ï¸  éœ€è¦æ”¹è¿›: åŸå§‹æ•°æ®ä¿å­˜ç‡åä½")
                print(f"   ğŸ¯ å»ºè®®: åˆ†æå¤±è´¥åŸå› ï¼Œä¼˜åŒ–æ–‡ä»¶ä¿å­˜æµç¨‹")
            else:
                print(f"   âœ… è‰¯å¥½: åŸå§‹æ•°æ®ä¿å­˜ç‡è¾¾æ ‡")

def main():
    """ä¸»å‡½æ•°"""
    try:
        auditor = SeasonContinuityAuditor()
        results = auditor.run_comprehensive_audit()

        print(f"\n" + "="*60)
        print(f"ğŸ¯ å®¡è®¡å®Œæˆï¼Œå»ºè®®æ ¹æ®ä¸Šè¿°é—®é¢˜åˆ¶å®šä¿®å¤è®¡åˆ’")
        print("="*60)

        # å¤„ç†æ— æ•°æ®æƒ…å†µ
        if not results:
            return 1

        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„å®¡è®¡ç»“æœ
        if isinstance(results, bool) and not results:
            return 1

        # æ­£å¸¸å®¡è®¡ç»“æœå¤„ç†
        incomplete_count = len(results.get('game_count_result', {}).get('incomplete_teams', []))
        return 0 if incomplete_count == 0 else 1

    except Exception as e:
        print(f"âŒ å®¡è®¡è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)