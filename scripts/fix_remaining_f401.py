#!/usr/bin/env python3
"""
ä¿®å¤å‰©ä½™çš„32ä¸ªF401é”™è¯¯
"""

import os
import re
from pathlib import Path


def fix_specific_f401_errors():
    """ä¿®å¤ç‰¹å®šçš„F401é”™è¯¯"""

    # éœ€è¦ä¿®å¤çš„æ–‡ä»¶å’Œå¯¹åº”çš„ä¿®å¤
    fixes = {
        # 1. ç§»é™¤æœªä½¿ç”¨çš„typingå¯¼å…¥
        "src/cache/redis/__init__.py": [(5, "import asyncio")],
        "src/database/connection/core/__init__.py": [(6, "from typing import Any")],
        "src/database/connection/pools/__init__.py": [
            (6, "from typing import Any, Dict, Optional, Union")
        ],
        "src/utils/_retry/__init__.py": [
            (7, "from typing import Any, Callable, Optional, Union, TypeVar")
        ],
        # 2. æ·»åŠ åˆ°__all__æˆ–ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥
        "src/cqrs/__init__.py": "cqrs",
        "src/services/__init__.py": "services",
        "src/services/data_processing_mod/__init__.py": "data_processing_mod",
        "src/streaming/__init__.py": "streaming",
        "src/data/quality/__init__.py": "data_quality",
    }

    fixed_count = 0

    for file_path, fix_info in fixes.items():
        if isinstance(fix_info, str):
            # ç‰¹æ®Šå¤„ç†æŸäº›æ–‡ä»¶
            if fix_info == "cqrs":
                fix_cqrs_init(file_path)
                fixed_count += 1
            elif fix_info == "services":
                fix_services_init(file_path)
                fixed_count += 1
            elif fix_info == "data_processing_mod":
                fix_data_processing_mod_init(file_path)
                fixed_count += 1
            elif fix_info == "streaming":
                fix_streaming_init(file_path)
                fixed_count += 1
            elif fix_info == "data_quality":
                fix_data_quality_init(file_path)
                fixed_count += 1
        else:
            # ç§»é™¤ç‰¹å®šè¡Œçš„å¯¼å…¥
            fix_lines = fix_info
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            for line_num, import_text in fix_lines:
                if line_num <= len(lines):
                    # æ³¨é‡Šæ‰æœªä½¿ç”¨çš„å¯¼å…¥
                    lines[line_num - 1] = f"# {lines[line_num - 1]}"
                    fixed_count += 1

            with open(file_path, "w", encoding="utf-8") as f:
                f.writelines(lines)

    return fixed_count


def fix_cqrs_init(file_path):
    """ä¿®å¤cqrs/__init__.py"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ³¨é‡Šæ‰æœªä½¿ç”¨çš„å¯¼å…¥
    content = content.replace(
        "    GetPredictionAnalyticsQuery,\n    GetLeaderboardQuery,",
        "    # GetPredictionAnalyticsQuery,  # æœªä½¿ç”¨\n    # GetLeaderboardQuery,  # æœªä½¿ç”¨",
    )
    content = content.replace("    CommandResult,", "    # CommandResult,  # æœªä½¿ç”¨")

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)


def fix_services_init(file_path):
    """ä¿®å¤services/__init__.py"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ³¨é‡Šæ‰æœªä½¿ç”¨çš„å¯¼å…¥
    content = content.replace(
        "from .base_unified import SimpleService",
        "# from .base_unified import SimpleService  # æœªä½¿ç”¨",
    )

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)


def fix_data_processing_mod_init(file_path):
    """ä¿®å¤data_processing_mod/__init__.py"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ³¨é‡Šæ‰æœªä½¿ç”¨çš„å¯¼å…¥
    content = content.replace(
        "from ..data_processing.pipeline_mod.stages.SilverToGoldProcessor import SilverToGoldProcessor",
        "# from ..data_processing.pipeline_mod.stages.SilverToGoldProcessor import SilverToGoldProcessor  # æœªä½¿ç”¨",
    )
    content = content.replace(
        "from ..data_processing.pipeline_mod.pipeline.DataPipeline import DataPipeline",
        "# from ..data_processing.pipeline_mod.pipeline.DataPipeline import DataPipeline  # æœªä½¿ç”¨",
    )

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)


def fix_streaming_init(file_path):
    """ä¿®å¤streaming/__init__.py"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ³¨é‡Šæ‰æœªä½¿ç”¨çš„å¯¼å…¥
    content = content.replace(
        "from .kafka_consumer import FootballKafkaConsumer\n        from .kafka_producer import FootballKafkaProducer",
        "# from .kafka_consumer import FootballKafkaConsumer  # æœªä½¿ç”¨\n        # from .kafka_producer import FootballKafkaProducer  # æœªä½¿ç”¨",
    )

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)


def fix_data_quality_init(file_path):
    """ä¿®å¤data/quality/__init__.py"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ³¨é‡Šæ‰æœªä½¿ç”¨çš„å¯¼å…¥
    content = content.replace(
        "from .anomaly_detector.AnomalyDetector import AnomalyDetector",
        "# from .anomaly_detector.AnomalyDetector import AnomalyDetector  # æœªä½¿ç”¨",
    )

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ”§ ä¿®å¤å‰©ä½™çš„32ä¸ªF401é”™è¯¯")
    print("=" * 80)

    # å…ˆç»Ÿè®¡å½“å‰æ•°é‡
    cmd = "ruff check --select F401 src/ 2>&1 | grep 'F401' | wc -l"
    result = os.popen(cmd).read().strip()
    current_count = int(result) if result else 0

    print(f"\nğŸ“Š å½“å‰F401é”™è¯¯æ•°: {current_count}")

    # ä¿®å¤é”™è¯¯
    fixed_count = fix_specific_f401_errors()
    print(f"\nâœ… ä¿®å¤äº† {fixed_count} ä¸ªæ–‡ä»¶")

    # å†æ¬¡ç»Ÿè®¡
    cmd = "ruff check --select F401 src/ 2>&1 | grep 'F401' | wc -l"
    result = os.popen(cmd).read().strip()
    remaining = int(result) if result else 0

    print(f"\nğŸ“Š å‰©ä½™F401é”™è¯¯æ•°: {remaining}")

    if remaining > 0:
        print("\nâš ï¸ ä»æœ‰é”™è¯¯éœ€è¦æ‰‹åŠ¨å¤„ç†:")
        os.system("ruff check --select F401 src/ 2>&1 | grep 'F401' | head -10")
    else:
        print("\nğŸ‰ æ‰€æœ‰F401é”™è¯¯å·²ä¿®å¤ï¼")


if __name__ == "__main__":
    main()
