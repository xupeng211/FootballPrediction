#!/usr/bin/env python3
"""
æ·±åº¦é¡¹ç›®æ¸…ç†è„šæœ¬
æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ã€ç¼“å­˜ã€æŠ¥å‘Šå’Œæ— ç”¨æ•°æ®
"""

import os
import shutil
import json
from pathlib import Path
from datetime import datetime, timedelta

class DeepCleaner:
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.archive_dir = self.project_root / ".cleanup_archive"
        self.stats = {
            'temp_files': 0,
            'cache_dirs': 0,
            'reports': 0,
            'logs': 0,
            'misc': 0
        }
        self.errors = []
        self.dry_run = False

    def log(self, message: str, level: str = "INFO"):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        color = {
            "INFO": "\033[0m",
            "WARN": "\033[0;33m",
            "ERROR": "\033[0;31m",
            "SUCCESS": "\033[0;32m"
        }.get(level, "\033[0m")
        print(f"{color}[{timestamp}] {level}: {message}\033[0m")

    def get_file_size_mb(self, path: Path) -> float:
        """è·å–æ–‡ä»¶å¤§å°(MB)"""
        if path.is_file():
            return path.stat().st_size / (1024 * 1024)
        elif path.is_dir():
            total = 0
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total += os.path.getsize(filepath)
            return total / (1024 * 1024)
        return 0

    def clean_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        self.log("\nğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...", "INFO")

        patterns = [
            "**/*.tmp",
            "**/*_temp*",
            "**/*_backup*",
            "**/*_working*",
            "**/*.bak",
            "**/*.swp",
            "**/*.swo",
            "**/TEMP_*",
            "**/CLAUDE_*.md.bak",
            "**/*.orig",
            "**/*.rej"
        ]

        for pattern in patterns:
            for file_path in self.project_root.glob(pattern):
                # è·³è¿‡é‡è¦ç›®å½•
                if ".git" in str(file_path):
                    continue

                try:
                    size = self.get_file_size_mb(file_path)
                    if self.dry_run:
                        self.log(f"  [DRY] å°†åˆ é™¤: {file_path.relative_to(self.project_root)} ({size:.2f}MB)")
                    else:
                        if file_path.is_file():
                            file_path.unlink()
                        else:
                            shutil.rmtree(file_path)
                        self.stats['temp_files'] += 1
                        self.log(f"  åˆ é™¤: {file_path.relative_to(self.project_root)} ({size:.2f}MB)")
                except Exception as e:
                    self.errors.append(f"åˆ é™¤å¤±è´¥ {file_path}: {e}")

    def clean_cache_dirs(self):
        """æ¸…ç†ç¼“å­˜ç›®å½•"""
        self.log("\nğŸ§¹ æ¸…ç†ç¼“å­˜ç›®å½•...", "INFO")

        cache_dirs = [
            self.project_root / ".pytest_cache",
            self.project_root / ".mypy_cache",
            self.project_root / ".ruff_cache",
            self.project_root / ".coverage",
            self.project_root / "htmlcov",
            self.project_root / ".tox",
            self.project_root / ".nox",
            self.project_root / "build",
            self.project_root / "dist",
        ]

        # æŸ¥æ‰¾æ‰€æœ‰ __pycache__ ç›®å½•
        cache_dirs.extend(self.project_root.rglob("__pycache__"))

        for cache_dir in cache_dirs:
            if cache_dir.exists():
                try:
                    size = self.get_file_size_mb(cache_dir)
                    if self.dry_run:
                        self.log(f"  [DRY] å°†åˆ é™¤: {cache_dir.relative_to(self.project_root)} ({size:.2f}MB)")
                    else:
                        shutil.rmtree(cache_dir)
                        self.stats['cache_dirs'] += 1
                        self.log(f"  åˆ é™¤: {cache_dir.relative_to(self.project_root)} ({size:.2f}MB)")
                except Exception as e:
                    self.errors.append(f"åˆ é™¤ç¼“å­˜å¤±è´¥ {cache_dir}: {e}")

    def clean_reports_and_data(self):
        """æ¸…ç†æŠ¥å‘Šå’Œæ•°æ®æ–‡ä»¶"""
        self.log("\nğŸ“Š æ¸…ç†æŠ¥å‘Šå’Œæ•°æ®æ–‡ä»¶...", "INFO")

        # æ ¹ç›®å½•çš„æŠ¥å‘Šæ–‡ä»¶
        report_files = [
            "coverage.json",
            "audit-report.json",
            "cache_coverage_report.json",
            "dependency_task_board.json",
            "vulnerabilities.csv",
            "vulnerabilities.json",
            "test_results.json",
            "ruff_report.json",
            "bandit_report.json",
            "complexity_report.json",
            "performance_report.json",
        ]

        for report_file in report_files:
            file_path = self.project_root / report_file
            if file_path.exists():
                try:
                    size = self.get_file_size_mb(file_path)
                    if self.dry_run:
                        self.log(f"  [DRY] å°†å½’æ¡£: {file_path.name} ({size:.2f}MB)")
                    else:
                        self.archive_file(file_path, "reports")
                        self.stats['reports'] += 1
                        self.log(f"  å½’æ¡£: {file_path.name} ({size:.2f}MB)")
                except Exception as e:
                    self.errors.append(f"å½’æ¡£å¤±è´¥ {file_path}: {e}")

    def clean_logs(self):
        """æ¸…ç†æ—¥å¿—æ–‡ä»¶"""
        self.log("\nğŸ“ æ¸…ç†æ—¥å¿—æ–‡ä»¶...", "INFO")

        # æŸ¥æ‰¾æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
        log_patterns = [
            "**/*.log",
            "**/*.log.*",
            "logs/*.json",
            ".logs/**/*",
        ]

        for pattern in log_patterns:
            for log_file in self.project_root.glob(pattern):
                if log_file.is_file():
                    try:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯30å¤©å‰çš„
                        mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                        if datetime.now() - mtime > timedelta(days=30):
                            size = self.get_file_size_mb(log_file)
                            if self.dry_run:
                                self.log(f"  [DRY] å°†åˆ é™¤: {log_file.relative_to(self.project_root)} ({size:.2f}MB)")
                            else:
                                log_file.unlink()
                                self.stats['logs'] += 1
                                self.log(f"  åˆ é™¤: {log_file.relative_to(self.project_root)} ({size:.2f}MB)")
                    except Exception as e:
                        self.errors.append(f"åˆ é™¤æ—¥å¿—å¤±è´¥ {log_file}: {e}")

    def clean_misc_files(self):
        """æ¸…ç†å…¶ä»–æ‚é¡¹æ–‡ä»¶"""
        self.log("\nğŸ§¹ æ¸…ç†æ‚é¡¹æ–‡ä»¶...", "INFO")

        misc_files = [
            ".DS_Store",
            "Thumbs.db",
            "desktop.ini",
            "*.pyc",
            "*.pyo",
            "*.pyd",
            ".coverage.*",
            "*.egg-info",
        ]

        for pattern in misc_files:
            for file_path in self.project_root.glob(pattern):
                if ".git" in str(file_path):
                    continue

                try:
                    if file_path.is_file():
                        size = self.get_file_size_mb(file_path)
                        if self.dry_run:
                            self.log(f"  [DRY] å°†åˆ é™¤: {file_path.relative_to(self.project_root)} ({size:.2f}MB)")
                        else:
                            file_path.unlink()
                            self.stats['misc'] += 1
                            self.log(f"  åˆ é™¤: {file_path.relative_to(self.project_root)} ({size:.2f}MB)")
                except Exception as e:
                    self.errors.append(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    def archive_file(self, file_path: Path, category: str):
        """å½’æ¡£æ–‡ä»¶"""
        archive_path = self.archive_dir / category
        archive_path.mkdir(parents=True, exist_ok=True)

        # ä¿ç•™ç›¸å¯¹è·¯å¾„ç»“æ„
        target_path = archive_path / file_path.name

        # é¿å…è¦†ç›–
        counter = 1
        original_target = target_path
        while target_path.exists():
            stem = original_target.stem
            suffix = original_target.suffix
            target_path = archive_path / f"{stem}_{counter}{suffix}"
            counter += 1

        shutil.move(str(file_path), str(target_path))

    def update_gitignore(self):
        """æ›´æ–° .gitignore"""
        self.log("\nğŸ“ æ›´æ–° .gitignore...", "INFO")

        gitignore_path = self.project_root / ".gitignore"

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿™äº›è§„åˆ™
        rules_to_add = [
            "",
            "# æ·±åº¦æ¸…ç†è§„åˆ™",
            "*.tmp",
            "*_temp*",
            "*_backup*",
            "*_working*",
            "*.bak",
            "*.swp",
            "*.swo",
            "TEMP_*",
            "CLAUDE_*.md.bak",
            "*.orig",
            "*.rej",
            "",
            "# æŠ¥å‘Šæ–‡ä»¶",
            "coverage.json",
            "audit-report.json",
            "*_report.json",
            "vulnerabilities.csv",
            "vulnerabilities.json",
            "",
            "# ç¼“å­˜ç›®å½•",
            ".pytest_cache/",
            ".mypy_cache/",
            ".ruff_cache/",
            ".coverage",
            "htmlcov/",
            ".tox/",
            ".nox/",
            "",
            "# æ„å»ºç›®å½•",
            "build/",
            "dist/",
            "*.egg-info/",
        ]

        if not gitignore_path.exists():
            with open(gitignore_path, "w", encoding="utf-8") as f:
                f.write("\n".join(rules_to_add))
            self.log("  åˆ›å»ºæ–°çš„ .gitignore")
        else:
            # è¯»å–ç°æœ‰å†…å®¹
            with open(gitignore_path, "r", encoding="utf-8") as f:
                existing = f.read().splitlines()

            # æ·»åŠ æ–°è§„åˆ™
            new_rules = []
            for rule in rules_to_add:
                if rule and rule not in existing:
                    new_rules.append(rule)

            if new_rules:
                with open(gitignore_path, "a", encoding="utf-8") as f:
                    for rule in new_rules:
                        f.write(rule + "\n")
                self.log(f"  æ·»åŠ äº† {len(new_rules)} æ¡æ–°è§„åˆ™")

    def run_cleanup(self):
        """æ‰§è¡Œå®Œæ•´æ¸…ç†"""
        self.log("=" * 70)
        self.log("å¼€å§‹æ·±åº¦é¡¹ç›®æ¸…ç†...", "SUCCESS")
        self.log(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        self.log("=" * 70)

        if self.dry_run:
            self.log("âš ï¸ è¯•è¿è¡Œæ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶", "WARN")

        # è®¡ç®—å¼€å§‹æ—¶çš„å¤§å°
        start_size = self.get_directory_size(self.project_root)

        # æ‰§è¡Œæ¸…ç†
        self.clean_temp_files()
        self.clean_cache_dirs()
        self.clean_reports_and_data()
        self.clean_logs()
        self.clean_misc_files()
        self.update_gitignore()

        # è®¡ç®—èŠ‚çœçš„ç©ºé—´
        if not self.dry_run:
            end_size = self.get_directory_size(self.project_root)
            saved_space = start_size - end_size
        else:
            saved_space = 0

        # ç”ŸæˆæŠ¥å‘Š
        self.log("\n" + "=" * 70)
        self.log("æ·±åº¦æ¸…ç†å®Œæˆ!", "SUCCESS")
        self.log(f"ä¸´æ—¶æ–‡ä»¶: {self.stats['temp_files']} ä¸ª")
        self.log(f"ç¼“å­˜ç›®å½•: {self.stats['cache_dirs']} ä¸ª")
        self.log(f"æŠ¥å‘Šæ–‡ä»¶: {self.stats['reports']} ä¸ª")
        self.log(f"æ—¥å¿—æ–‡ä»¶: {self.stats['logs']} ä¸ª")
        self.log(f"æ‚é¡¹æ–‡ä»¶: {self.stats['misc']} ä¸ª")
        self.log(f"æ€»è®¡: {sum(self.stats.values())} ä¸ªæ–‡ä»¶/ç›®å½•")

        if saved_space > 0:
            self.log(f"èŠ‚çœç©ºé—´: {saved_space:.2f} MB", "SUCCESS")

        if self.errors:
            self.log(f"\né”™è¯¯æ•°: {len(self.errors)}", "ERROR")
            for error in self.errors[:5]:
                self.log(f"  - {error}", "ERROR")

        self.log("=" * 70)

        # ä¿å­˜æ¸…ç†æŠ¥å‘Š
        if not self.dry_run:
            self.save_cleanup_report(saved_space)

    def get_directory_size(self, path: Path) -> float:
        """è·å–ç›®å½•å¤§å°(MB)"""
        total = 0
        for dirpath, dirnames, filenames in os.walk(path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.exists(filepath):
                    total += os.path.getsize(filepath)
        return total / (1024 * 1024)

    def save_cleanup_report(self, saved_space_mb: float):
        """ä¿å­˜æ¸…ç†æŠ¥å‘Š"""
        report_path = self.project_root / "docs" / "_reports"
        report_path.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = report_path / f"deep_cleanup_report_{timestamp}.md"

        with open(report_file, "w", encoding="utf-8") as f:
            f.write("# æ·±åº¦é¡¹ç›®æ¸…ç†æŠ¥å‘Š\n\n")
            f.write(f"**æ¸…ç†æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**æ¸…ç†å·¥å…·**: scripts/deep_cleanup.py\n\n")

            f.write("## æ¸…ç†ç»Ÿè®¡\n\n")
            f.write("| ç±»åˆ« | æ•°é‡ |\n")
            f.write("|------|------|\n")
            f.write(f"| ä¸´æ—¶æ–‡ä»¶ | {self.stats['temp_files']} |\n")
            f.write(f"| ç¼“å­˜ç›®å½• | {self.stats['cache_dirs']} |\n")
            f.write(f"| æŠ¥å‘Šæ–‡ä»¶ | {self.stats['reports']} |\n")
            f.write(f"| æ—¥å¿—æ–‡ä»¶ | {self.stats['logs']} |\n")
            f.write(f"| æ‚é¡¹æ–‡ä»¶ | {self.stats['misc']} |\n")
            f.write(f"| **æ€»è®¡** | **{sum(self.stats.values())}** |\n\n")

            f.write(f"## ç©ºé—´ä¼˜åŒ–\n\n")
            f.write(f"- èŠ‚çœç©ºé—´: {saved_space_mb:.2f} MB\n")
            f.write(f"- å½’æ¡£ä½ç½®: `.cleanup_archive/`\n\n")

            if self.errors:
                f.write("## é”™è¯¯åˆ—è¡¨\n\n")
                for error in self.errors:
                    f.write(f"- {error}\n")
                f.write("\n")

            f.write("## å»ºè®®\n\n")
            f.write("1. å®šæœŸè¿è¡Œ `python scripts/deep_cleanup.py` æ¸…ç†é¡¹ç›®\n")
            f.write("2. ä½¿ç”¨ `python scripts/deep_cleanup.py --dry-run` é¢„è§ˆå°†è¦åˆ é™¤çš„æ–‡ä»¶\n")
            f.write("3. æ£€æŸ¥ `.cleanup_archive/` ç›®å½•ç¡®è®¤å½’æ¡£å†…å®¹\n")

        self.log(f"\nğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜: {report_file.relative_to(self.project_root)}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description = os.getenv("DEEP_CLEANUP_DESCRIPTION_405"))
    parser.add_argument("--project-root", help = os.getenv("DEEP_CLEANUP_HELP_406"), default=None)
    parser.add_argument("--dry-run", action = os.getenv("DEEP_CLEANUP_ACTION_406"), help = os.getenv("DEEP_CLEANUP_HELP_406"))

    args = parser.parse_args()

    cleaner = DeepCleaner(args.project_root)
    cleaner.dry_run = args.dry_run

    cleaner.run_cleanup()