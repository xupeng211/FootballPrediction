#!/usr/bin/env python3
"""
é•¿æ–‡ä»¶åˆ†æå·¥å…· - Issue #87
è¯†åˆ«å’Œåˆ†æé¡¹ç›®ä¸­éœ€è¦æ‹†åˆ†çš„é•¿æ–‡ä»¶
"""

import os
import ast
from typing import Dict, List, Tuple, Any
from pathlib import Path
import subprocess

class LongFileAnalyzer:
    """é•¿æ–‡ä»¶åˆ†æå™¨"""

    def __init__(self, max_lines: int = 100):
        self.max_lines = max_lines
        self.long_files = []

    def find_long_files(self, directory: str = "src/") -> List[Dict]:
        """æŸ¥æ‰¾é•¿æ–‡ä»¶"""
        print(f"ğŸ” æœç´¢é•¿æ–‡ä»¶ (>{self.max_lines} è¡Œ)...")
        print("=" * 60)

        # ä½¿ç”¨findå‘½ä»¤å¿«é€Ÿè·å–æ–‡ä»¶è¡Œæ•°
        result = subprocess.run([
            'find', directory, '-name', '*.py', '-exec', 'wc', '-l', '{}', '+'
        ], capture_output=True, text=True, cwd='.')

        # è§£æç»“æœ
        lines = result.stdout.strip().split('\n')
        for line in lines:
            if line.strip():
                try:
                    parts = line.strip().split()
                    line_count = int(parts[0])
                    file_path = parts[1]

                    if line_count > self.max_lines:
                        file_info = self.analyze_file_structure(file_path, line_count)
                        self.long_files.append(file_info)
                except (ValueError, IndexError) as e:
                    print(f"è§£æé”™è¯¯: {line} - {e}")

        # æŒ‰è¡Œæ•°æ’åº
        self.long_files.sort(key=lambda x: x['line_count'], reverse=True)
        return self.long_files

    def analyze_file_structure(self, file_path: str, line_count: int) -> Dict:
        """åˆ†ææ–‡ä»¶ç»“æ„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            classes = []
            functions = []
            imports = []
            complexity_score = 0

            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    # è®¡ç®—ç±»å¤æ‚åº¦
                    class_methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
                    class_complexity = len(class_methods) + self._calculate_node_complexity(node)

                    classes.append({
                        'name': node.name,
                        'line_start': node.lineno,
                        'line_end': self._get_end_line(node, content),
                        'methods': len(class_methods),
                        'complexity': class_complexity
                    })
                    complexity_score += class_complexity

                elif isinstance(node, ast.FunctionDef):
                    if not any(cls['line_start'] <= node.lineno <= cls['line_end'] for cls in classes):
                        # ä¸åœ¨ç±»ä¸­çš„å‡½æ•°
                        func_complexity = self._calculate_node_complexity(node)
                        functions.append({
                            'name': node.name,
                            'line_start': node.lineno,
                            'line_end': self._get_end_line(node, content),
                            'complexity': func_complexity
                        })
                        complexity_score += func_complexity

                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    imports.append({
                        'type': 'import' if isinstance(node, ast.Import) else 'from_import',
                        'line': node.lineno
                    })

            # è®¡ç®—æ‹†åˆ†å»ºè®®
            split_suggestions = self._generate_split_suggestions(
                file_path, classes, functions, line_count, complexity_score
            )

            return {
                'path': file_path,
                'line_count': line_count,
                'classes': classes,
                'functions': functions,
                'imports': imports,
                'complexity_score': complexity_score,
                'split_suggestions': split_suggestions,
                'priority': self._calculate_priority(line_count, complexity_score)
            }

        except Exception as e:
            return {
                'path': file_path,
                'line_count': line_count,
                'error': str(e),
                'priority': 'high'
            }

    def _calculate_node_complexity(self, node) -> int:
        """è®¡ç®—ASTèŠ‚ç‚¹çš„å¤æ‚åº¦"""
        complexity = 1
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.For, ast.While, ast.Try)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        return complexity

    def _get_end_line(self, node, content: str) -> int:
        """è·å–èŠ‚ç‚¹ç»“æŸè¡Œå·"""
        lines = content.split('\n')
        if hasattr(node, 'end_lineno') and node.end_lineno:
            return node.end_lineno

        # å›é€€è®¡ç®—ï¼šæŸ¥æ‰¾èŠ‚ç‚¹çš„æœ€åä¸€æ¡è¯­å¥
        max_line = node.lineno
        for child in ast.walk(node):
            if hasattr(child, 'lineno') and child.lineno > max_line:
                max_line = child.lineno

        return max_line

    def _generate_split_suggestions(self, file_path: str, classes: List[Dict],
                                   functions: List[Dict], line_count: int, complexity: int) -> List[str]:
        """ç”Ÿæˆæ‹†åˆ†å»ºè®®"""
        suggestions = []

        if line_count > 500:
            suggestions.append("æ–‡ä»¶è¿‡é•¿(>500è¡Œ)ï¼Œå»ºè®®ç«‹å³æ‹†åˆ†")

        if len(classes) > 5:
            suggestions.append(f"ç±»è¿‡å¤š({len(classes)}ä¸ª)ï¼Œå»ºè®®æŒ‰åŠŸèƒ½æ‹†åˆ†åˆ°å¤šä¸ªæ¨¡å—")

        if len(functions) > 10:
            suggestions.append(f"ç‹¬ç«‹å‡½æ•°è¿‡å¤š({len(functions)}ä¸ª)ï¼Œå»ºè®®æŒ‰èŒè´£åˆ†ç»„")

        if complexity > 100:
            suggestions.append(f"å¤æ‚åº¦è¿‡é«˜({complexity})ï¼Œå»ºè®®æ‹†åˆ†å¤æ‚ç±»å’Œå‡½æ•°")

        # å…·ä½“å»ºè®®
        if classes:
            largest_class = max(classes, key=lambda x: x['complexity'])
            if largest_class['complexity'] > 30:
                suggestions.append(f"ç±»'{largest_class['name']}'è¿‡äºå¤æ‚ï¼Œå»ºè®®æ‹†åˆ†ä¸ºå¤šä¸ªç±»")

        if functions:
            complex_functions = [f for f in functions if f['complexity'] > 10]
            if complex_functions:
                suggestions.append(f"å­˜åœ¨{len(complex_functions)}ä¸ªå¤æ‚å‡½æ•°ï¼Œå»ºè®®æ‹†åˆ†æˆ–é‡æ„")

        # åŸºäºæ–‡ä»¶è·¯å¾„çš„å»ºè®®
        if 'monitoring' in file_path and line_count > 200:
            suggestions.append("ç›‘æ§æ¨¡å—å»ºè®®æŒ‰ç›‘æ§ç±»å‹æ‹†åˆ†ï¼ˆå¼‚å¸¸æ£€æµ‹ã€æ€§èƒ½ç›‘æ§ã€æŒ‡æ ‡æ”¶é›†ç­‰ï¼‰")

        if 'strategies' in file_path and line_count > 200:
            suggestions.append("ç­–ç•¥æ¨¡å—å»ºè®®æŒ‰ç­–ç•¥ç±»å‹æ‹†åˆ†ï¼ˆå†å²ç­–ç•¥ã€MLç­–ç•¥ã€ç»Ÿè®¡ç­–ç•¥ç­‰ï¼‰")

        if 'decorators' in file_path and line_count > 200:
            suggestions.append("è£…é¥°å™¨æ¨¡å—å»ºè®®æŒ‰åŠŸèƒ½æ‹†åˆ†ï¼ˆç¼“å­˜è£…é¥°å™¨ã€éªŒè¯è£…é¥°å™¨ã€ç›‘æ§è£…é¥°å™¨ç­‰ï¼‰")

        return suggestions

    def _calculate_priority(self, line_count: int, complexity: int) -> str:
        """è®¡ç®—æ‹†åˆ†ä¼˜å…ˆçº§"""
        if line_count > 600 or complexity > 150:
            return "critical"
        elif line_count > 400 or complexity > 100:
            return "high"
        elif line_count > 200 or complexity > 50:
            return "medium"
        else:
            return "low"

    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not self.long_files:
            return "æ²¡æœ‰å‘ç°éœ€è¦æ‹†åˆ†çš„é•¿æ–‡ä»¶ã€‚"

        report = f"""
ğŸ“Š é•¿æ–‡ä»¶åˆ†ææŠ¥å‘Š - Issue #87
=============================

å‘ç° {len(self.long_files)} ä¸ªéœ€è¦å…³æ³¨çš„é•¿æ–‡ä»¶ (> {self.max_lines} è¡Œ)

ä¼˜å…ˆçº§åˆ†å¸ƒ:
"""

        # ç»Ÿè®¡ä¼˜å…ˆçº§
        priorities = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}
        for file_info in self.long_files:
            priority = file_info.get('priority', 'low')
            priorities[priority] = priorities.get(priority, 0) + 1

        for priority, count in priorities.items():
            if count > 0:
                report += f"- {priority.capitalize()}: {count} ä¸ªæ–‡ä»¶\n"

        report += "\nè¯¦ç»†åˆ†æ:\n"
        report += "-" * 50 + "\n"

        # è¯¦ç»†ä¿¡æ¯
        for i, file_info in enumerate(self.long_files, 1):
            report += f"\n{i}. {file_info['path']}\n"
            report += f"   è¡Œæ•°: {file_info['line_count']}\n"
            report += f"   ä¼˜å…ˆçº§: {file_info.get('priority', 'unknown').upper()}\n"

            if 'error' in file_info:
                report += f"   é”™è¯¯: {file_info['error']}\n"
                continue

            report += f"   ç±»æ•°: {len(file_info.get('classes', []))}\n"
            report += f"   å‡½æ•°æ•°: {len(file_info.get('functions', []))}\n"
            report += f"   å¤æ‚åº¦: {file_info.get('complexity_score', 0)}\n"

            suggestions = file_info.get('split_suggestions', [])
            if suggestions:
                report += "   æ‹†åˆ†å»ºè®®:\n"
                for suggestion in suggestions:
                    report += f"     - {suggestion}\n"

        return report

    def create_split_plan(self) -> Dict:
        """åˆ›å»ºæ‹†åˆ†è®¡åˆ’"""
        split_plan = {
            'critical_files': [],
            'high_priority_files': [],
            'medium_priority_files': [],
            'low_priority_files': []
        }

        for file_info in self.long_files:
            priority = file_info.get('priority', 'low')
            file_plan = {
                'path': file_info['path'],
                'line_count': file_info['line_count'],
                'suggestions': file_info.get('split_suggestions', []),
                'classes': file_info.get('classes', []),
                'functions': file_info.get('functions', [])
            }

            if priority == 'critical':
                split_plan['critical_files'].append(file_plan)
            elif priority == 'high':
                split_plan['high_priority_files'].append(file_plan)
            elif priority == 'medium':
                split_plan['medium_priority_files'].append(file_plan)
            else:
                split_plan['low_priority_files'].append(file_plan)

        return split_plan

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Issue #87: é•¿æ–‡ä»¶åˆ†æ")
    print("=" * 50)

    analyzer = LongFileAnalyzer(max_lines=100)

    # åˆ†æé•¿æ–‡ä»¶
    long_files = analyzer.find_long_files()

    if long_files:
        # ç”ŸæˆæŠ¥å‘Š
        report = analyzer.generate_report()
        print(report)

        # åˆ›å»ºæ‹†åˆ†è®¡åˆ’
        split_plan = analyzer.create_split_plan()

        # ä¿å­˜æŠ¥å‘Šå’Œè®¡åˆ’
        with open('LONG_FILES_ANALYSIS_REPORT.md', 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: LONG_FILES_ANALYSIS_REPORT.md")

        # æ˜¾ç¤ºä¼˜å…ˆçº§ç»Ÿè®¡
        total_files = len(long_files)
        critical_files = len(split_plan['critical_files'])
        high_files = len(split_plan['high_priority_files'])

        print(f"\nğŸ¯ æ‹†åˆ†ä¼˜å…ˆçº§:")
        print(f"   ç´§æ€¥æ‹†åˆ†: {critical_files} ä¸ªæ–‡ä»¶")
        print(f"   é«˜ä¼˜å…ˆçº§: {high_files} ä¸ªæ–‡ä»¶")
        print(f"   æ€»è®¡: {total_files} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")

        if critical_files > 0:
            print(f"\nâš ï¸ å»ºè®®ä¼˜å…ˆå¤„ç†ç´§æ€¥æ–‡ä»¶:")
            for file_plan in split_plan['critical_files']:
                print(f"   - {file_plan['path']} ({file_plan['line_count']} è¡Œ)")

    else:
        print("âœ… æ²¡æœ‰å‘ç°éœ€è¦æ‹†åˆ†çš„é•¿æ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()