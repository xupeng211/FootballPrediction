#!/usr/bin/env python3
"""
åˆ†æNext.jsæ•°æ®ç»“æ„
Analyze Next.js Data Structure

ä¸“é—¨ç”¨äºåˆ†æFotMobé¡µé¢çš„å®é™…Next.jsæ•°æ®ç»“æ„
"""

import asyncio
import sys
import json
import re
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from src.collectors.html_fotmob_collector import HTMLFotMobCollector

def extract_nextjs_data_from_html(html: str) -> dict:
    """ä»HTMLä¸­æå–Next.jsæ•°æ®"""
    try:
        pattern = r'<script[^>]*id=["\']__NEXT_DATA__["\'][^>]*>(.*?)</script>'
        matches = re.findall(pattern, html, re.DOTALL)

        if not matches:
            return {"error": "No __NEXT_DATA__ found"}

        nextjs_data_str = matches[0].strip()
        try:
            nextjs_data = json.loads(nextjs_data_str)
            return {"success": True, "data": nextjs_data}
        except json.JSONDecodeError as e:
            return {"error": f"JSON decode error: {e}", "preview": nextjs_data_str[:500]}

    except Exception as e:
        return {"error": f"Extraction error: {e}"}

def analyze_data_structure(data: dict, path: str = "") -> None:
    """é€’å½’åˆ†ææ•°æ®ç»“æ„"""
    if isinstance(data, dict):
        print(f"{'  ' * len(path.split('.'))}ğŸ“ Dictionary: {path or 'root'} ({len(data)} keys)")
        for key, value in data.items():
            current_path = f"{path}.{key}" if path else key

            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¯”èµ›ç›¸å…³å…³é”®å­—æ®µ
            if any(keyword in key.lower() for keyword in ['match', 'content', 'data', 'props', 'state']):
                print(f"{'  ' * (len(path.split('.')) + 1)}ğŸ”‘ Key: {key} (type: {type(value).__name__})")

                if isinstance(value, dict):
                    if len(value) <= 10:  # å°å­—å…¸ç›´æ¥æ˜¾ç¤º
                        print(f"{'  ' * (len(path.split('.')) + 2)}ğŸ“‹ Content: {list(value.keys())}")
                    else:
                        print(f"{'  ' * (len(path.split('.')) + 2)}ğŸ“‹ Content: {len(value)} keys")
                        # æ˜¾ç¤ºå‰5ä¸ªé”®
                        first_keys = list(value.keys())[:5]
                        print(f"{'  ' * (len(path.split('.')) + 2)}ğŸ“‹ First 5 keys: {first_keys}...")

                    # é€’å½’åˆ†æé‡è¦çš„æ•°æ®ç»“æ„
                    if key.lower() in ['content', 'data', 'state', 'matchfacts', 'stats', 'lineups']:
                        analyze_data_structure(value, current_path)

                elif isinstance(value, list):
                    print(f"{'  ' * (len(path.split('.')) + 2)}ğŸ“‹ Array: {len(value)} items")
                    if value and isinstance(value[0], dict):
                        print(f"{'  ' * (len(path.split('.')) + 2)}ğŸ“‹ First item keys: {list(value[0].keys())[:5]}...")

            else:
                # å¯¹äºéå…³é”®å­—æ®µï¼Œåªæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                if isinstance(value, dict):
                    print(f"{'  ' * (len(path.split('.')) + 1)}ğŸ“ {key}: Dictionary ({len(value)} keys)")
                elif isinstance(value, list):
                    print(f"{'  ' * (len(path.split('.')) + 1)}ğŸ“„ {key}: Array ({len(value)} items)")
                else:
                    print(f"{'  ' * (len(path.split('.')) + 1)}ğŸ’ {key}: {type(value).__name__}")

    elif isinstance(data, list):
        print(f"{'  ' * len(path.split('.'))}ğŸ“„ Array: {path} ({len(data)} items)")
        if data:
            print(f"{'  ' * (len(path.split('.')) + 1)}ğŸ“‹ First item type: {type(data[0]).__name__}")
            if isinstance(data[0], dict):
                print(f"{'  ' * (len(path.split('.')) + 1)}ğŸ“‹ First item keys: {list(data[0].keys())[:5]}...")
    else:
        print(f"{'  ' * len(path.split('.'))}ğŸ’ {path}: {type(data).__name__} = {str(data)[:100]}")

def search_for_match_data(data: dict, search_path: str = "") -> list:
    """æœç´¢åŒ…å«æ¯”èµ›æ•°æ®çš„è·¯å¾„"""
    results = []

    # æ¯”èµ›æ•°æ®çš„å…³é”®å­—æ®µ
    match_keywords = [
        'matchfacts', 'stats', 'lineups', 'odds', 'shotmap', 'xg', 'expected_goals',
        'hometeam', 'awayteam', 'score', 'minute', 'possession', 'shots'
    ]

    def recursive_search(obj, current_path: str):
        if isinstance(obj, dict):
            for key, value in obj.items():
                new_path = f"{current_path}.{key}" if current_path else key

                # æ£€æŸ¥å½“å‰é”®æ˜¯å¦åŒ…å«æ¯”èµ›æ•°æ®å…³é”®å­—
                if any(keyword in key.lower() for keyword in match_keywords):
                    results.append({
                        "path": new_path,
                        "key": key,
                        "type": type(value).__name__,
                        "size": len(str(value)) if not isinstance(value, (list, dict)) else
                                len(value) if isinstance(value, (list, dict)) else 0,
                        "preview": str(value)[:200] if not isinstance(value, (list, dict)) else None
                    })

                # é€’å½’æœç´¢
                recursive_search(value, new_path)

        elif isinstance(obj, list) and obj:
            # æœç´¢æ•°ç»„ä¸­çš„å¯¹è±¡
            for i, item in enumerate(obj):
                if isinstance(item, dict):
                    recursive_search(item, f"{current_path}[{i}]")

    recursive_search(data, search_path)
    return results

async def analyze_match_nextjs(match_id: str) -> None:
    """åˆ†æç‰¹å®šæ¯”èµ›çš„Next.jsæ•°æ®ç»“æ„"""
    print(f"ğŸ” åˆ†ææ¯”èµ› {match_id} çš„Next.jsæ•°æ®ç»“æ„")
    print("=" * 80)

    collector = HTMLFotMobCollector(enable_stealth=True, enable_proxy=False)

    try:
        await collector.initialize()

        # è·å–HTML
        url = f"https://www.fotmob.com/match/{match_id}"
        session = collector.session_manager.session
        headers = collector.session_manager.current_headers or {}

        print(f"ğŸ”„ è·å–é¡µé¢: {url}")
        response = session.get(url, headers=headers, timeout=30)

        print(f"âœ… å“åº”çŠ¶æ€: {response.status_code}")
        print(f"âœ… å“åº”å¤§å°: {len(response.text):,} å­—ç¬¦")

        # æå–Next.jsæ•°æ®
        print("\nğŸ” æå–Next.jsæ•°æ®...")
        extraction_result = extract_nextjs_data_from_html(response.text)

        if "error" in extraction_result:
            print(f"âŒ æ•°æ®æå–å¤±è´¥: {extraction_result['error']}")
            if "preview" in extraction_result:
                print(f"ğŸ“‹ æ•°æ®é¢„è§ˆ: {extraction_result['preview']}")
            return

        nextjs_data = extraction_result["data"]
        print("âœ… Next.jsæ•°æ®æå–æˆåŠŸ!")

        # åˆ†ææ•´ä½“æ•°æ®ç»“æ„
        print("\nğŸ“Š Next.jsæ•°æ®ç»“æ„åˆ†æ:")
        print("-" * 60)
        analyze_data_structure(nextjs_data)

        # æœç´¢æ¯”èµ›æ•°æ®
        print("\nğŸ¯ æ¯”èµ›æ•°æ®æœç´¢ç»“æœ:")
        print("-" * 60)
        match_data_paths = search_for_match_data(nextjs_data)

        if match_data_paths:
            print(f"âœ… æ‰¾åˆ° {len(match_data_paths)} ä¸ªå¯èƒ½åŒ…å«æ¯”èµ›æ•°æ®çš„è·¯å¾„:")
            for i, result in enumerate(match_data_paths[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"\n{i+1}. ğŸ“ è·¯å¾„: {result['path']}")
                print(f"   ğŸ”‘ é”®å: {result['key']}")
                print(f"   ğŸ“ ç±»å‹: {result['type']}")
                print(f"   ğŸ“ å¤§å°: {result['size']}")
                if result['preview']:
                    print(f"   ğŸ‘ï¸ é¢„è§ˆ: {result['preview']}...")
        else:
            print("âŒ æœªæ‰¾åˆ°æ˜æ˜¾çš„æ¯”èµ›æ•°æ®å­—æ®µ")

        # ç‰¹åˆ«æ£€æŸ¥props.pagePropsç»“æ„
        print("\nğŸ” è¯¦ç»†æ£€æŸ¥props.pagePropsç»“æ„:")
        print("-" * 60)
        props = nextjs_data.get('props', {})
        page_props = props.get('pageProps', {})

        if page_props:
            print(f"âœ… pagePropsåŒ…å« {len(page_props)} ä¸ªé”®: {list(page_props.keys())}")

            # æ£€æŸ¥æ¯ä¸ªé”®çš„è¯¦ç»†ä¿¡æ¯
            for key, value in page_props.items():
                print(f"\nğŸ“‹ é”®: {key}")
                if isinstance(value, dict):
                    print(f"   ç±»å‹: Dictionary ({len(value)} é”®)")
                    print(f"   å†…å®¹: {list(value.keys())[:10]}...")
                elif isinstance(value, list):
                    print(f"   ç±»å‹: Array ({len(value)} é¡¹)")
                    if value and isinstance(value[0], dict):
                        print(f"   é¦–é¡¹é”®: {list(value[0].keys())[:5]}...")
                else:
                    print(f"   ç±»å‹: {type(value).__name__}")
                    print(f"   å€¼: {str(value)[:100]}...")
        else:
            print("âŒ pagePropsä¸ºç©ºæˆ–ä¸å­˜åœ¨")

        # ä¿å­˜å®Œæ•´çš„Next.jsæ•°æ®ç”¨äºè¿›ä¸€æ­¥åˆ†æ
        timestamp = asyncio.get_event_loop().time()
        filename = f"logs/nextjs_data_{match_id}_{int(timestamp)}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(nextjs_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ å®Œæ•´Next.jsæ•°æ®å·²ä¿å­˜: {filename}")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    finally:
        await collector.close()

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Next.jsæ•°æ®ç»“æ„åˆ†æå·¥å…·")
    print("=" * 80)

    # ä»æ—¥å¿—ä¸­æå–çš„å¤±è´¥æ¯”èµ›ID
    failed_match_ids = [
        "4000125",  # 404é¡µé¢
        "4193904",  # 200é¡µé¢
    ]

    for match_id in failed_match_ids:
        await analyze_match_nextjs(match_id)
        print("\n" + "="*80)
        print("\n")

if __name__ == "__main__":
    asyncio.run(main())
