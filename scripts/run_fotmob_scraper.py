#!/usr/bin/env python3
"""
FotMobæ•°æ®é‡‡é›†å™¨è¿è¡Œå·¥å…·
ä¾¿æ·çš„å‘½ä»¤è¡Œæ¥å£ï¼Œç”¨äºæ‰§è¡ŒFotMobæ•°æ®é‡‡é›†
"""

import asyncio
import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.data.collectors.fotmob_browser import FotmobBrowserScraper


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="FotMobæ•°æ®é‡‡é›†å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # é‡‡é›†ä»Šå¤©çš„æ•°æ®
  python run_fotmob_scraper.py --date today

  # é‡‡é›†æŒ‡å®šæ—¥æœŸçš„æ•°æ®
  python run_fotmob_scraper.py --date 20241201

  # é‡‡é›†æœ€è¿‘7å¤©çš„æ•°æ®ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰
  python run_fotmob_scraper.py --batch --days 7

  # é‡‡é›†æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ•°æ®
  python run_fotmob_scraper.py --range 20241201 20241205

  # åªé‡‡é›†æ•°æ®ä¸ä¿å­˜æ–‡ä»¶
  python run_fotmob_scraper.py --date today --no-export
        """,
    )

    # åˆ›å»ºäº’æ–¥çš„æ—¥æœŸå‚æ•°ç»„
    date_group = parser.add_mutually_exclusive_group(required=True)

    date_group.add_argument(
        "--date", type=str, help='æŒ‡å®šé‡‡é›†æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œæˆ–ä½¿ç”¨ "today"'
    )

    date_group.add_argument(
        "--range",
        nargs=2,
        metavar=("START_DATE", "END_DATE"),
        help="æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œæ ¼å¼ YYYYMMDD YYYYMMDD",
    )

    date_group.add_argument("--batch", action="store_true", help="æ‰¹é‡é‡‡é›†æ¨¡å¼")

    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--days",
        type=int,
        default=1,
        help="å½“ä½¿ç”¨--batchæ—¶ï¼Œé‡‡é›†å¤šå°‘å¤©çš„æ•°æ®ï¼ˆé»˜è®¤: 1ï¼‰",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="data/fotmob",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: data/fotmobï¼‰",
    )

    parser.add_argument(
        "--no-export", action="store_true", help="ä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼Œåªæ˜¾ç¤ºé‡‡é›†ç»“æœ"
    )

    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")

    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    try:
        if args.date:
            # å•æ—¥é‡‡é›†
            if args.date.lower() == "today":
                date_str = datetime.now().strftime("%Y%m%d")
                print(f"ğŸš€ å¯åŠ¨å•æ—¥é‡‡é›†ï¼Œé‡‡é›†ä»Šå¤©çš„æ•°æ® ({date_str})")
            else:
                # éªŒè¯æ—¥æœŸæ ¼å¼
                try:
                    datetime.strptime(args.date, "%Y%m%d")
                    date_str = args.date
                    print(f"ğŸš€ å¯åŠ¨å•æ—¥é‡‡é›†ï¼Œé‡‡é›†æŒ‡å®šæ—¥æœŸçš„æ•°æ® ({date_str})")
                except ValueError:
                    print(f"âŒ é”™è¯¯: æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨ YYYYMMDD æ ¼å¼")
                    sys.exit(1)

            async with FotmobBrowserScraper() as scraper:
                if args.no_export:
                    match_data_list = await scraper.scrape_matches(date_str)
                    print(f"\nğŸ“Š é‡‡é›†ç»“æœ:")
                    print(f"  ğŸ“… ç›®æ ‡æ—¥æœŸ: {date_str}")
                    print(f"  âš½ é‡‡é›†æ¯”èµ›: {len(match_data_list)} åœº")
                    print(f"  ğŸ“‹ çŠ¶æ€: {'å®Œæˆ' if match_data_list else 'æ— æ•°æ®'}")

                    if match_data_list:
                        print(f"\nğŸŸï¸ é‡‡é›†åˆ°çš„æ¯”èµ›:")
                        for i, match in enumerate(match_data_list[:5]):
                            print(
                                f"  {i+1}. {match.home_team_name} {match.home_score}-{match.away_score} {match.away_team_name}"
                            )
                            print(f"     è”èµ›: {match.league_name}")
                            print(f"     çŠ¶æ€: {match.status}")
                            print(f"     æ—¶é—´: {match.kickoff_time}")

                        if len(match_data_list) > 5:
                            print(f"  ... è¿˜æœ‰ {len(match_data_list) - 5} åœºæ¯”èµ›")
                else:
                    output_file = (
                        output_dir
                        / f"fotmob_matches_{date_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    )
                    saved_count = await scraper.scrape_and_export_matches(
                        date_str, str(output_file)
                    )

                    print(f"\nğŸ“Š é‡‡é›†ç»“æœ:")
                    print(f"  ğŸ“… ç›®æ ‡æ—¥æœŸ: {date_str}")
                    print(f"  âš½ é‡‡é›†æ¯”èµ›: {saved_count} åœº")
                    print(f"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
                    print(f"  ğŸ“‹ çŠ¶æ€: {'æˆåŠŸ' if saved_count > 0 else 'æ— æ•°æ®'}")

        elif args.range:
            # æ—¥æœŸèŒƒå›´é‡‡é›†
            start_date, end_date = args.range
            print(f"ğŸš€ å¯åŠ¨æ—¥æœŸèŒƒå›´é‡‡é›†ï¼Œä» {start_date} åˆ° {end_date}")

            # éªŒè¯æ—¥æœŸæ ¼å¼
            try:
                start_dt = datetime.strptime(start_date, "%Y%m%d")
                end_dt = datetime.strptime(end_date, "%Y%m%d")

                if start_dt > end_dt:
                    print(f"âŒ é”™è¯¯: å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")
                    sys.exit(1)

                dates = [
                    (start_dt + timedelta(days=i)).strftime("%Y%m%d")
                    for i in range((end_dt - start_dt).days + 1)
                ]

            except ValueError:
                print(f"âŒ é”™è¯¯: æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨ YYYYMMDD æ ¼å¼")
                sys.exit(1)

            total_matches = 0
            async with FotmobBrowserScraper() as scraper:
                for date_str in dates:
                    print(f"\nğŸ“Š å¤„ç†æ—¥æœŸ: {date_str}")

                    if args.no_export:
                        match_data_list = await scraper.scrape_matches(date_str)
                        date_matches = len(match_data_list)
                        print(f"  âœ… é‡‡é›†å®Œæˆ: {date_matches} åœºæ¯”èµ›")
                    else:
                        output_file = (
                            output_dir
                            / f"fotmob_matches_{date_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                        )
                        saved_count = await scraper.scrape_and_export_matches(
                            date_str, str(output_file)
                        )
                        print(f"  âœ… é‡‡é›†å®Œæˆ: {saved_count} åœºæ¯”èµ›")
                        date_matches = saved_count

                    total_matches += date_matches

                print(f"\nğŸ“Š æ—¥æœŸèŒƒå›´é‡‡é›†ç»“æœ:")
                print(f"  ğŸ“… å¤„ç†æ—¥æœŸ: {len(dates)} å¤©")
                print(f"  âš½ æ€»é‡‡é›†æ¯”èµ›: {total_matches} åœº")
                print(f"  ğŸ“‹ çŠ¶æ€: {'æˆåŠŸ' if total_matches > 0 else 'æ— æ•°æ®'}")

        elif args.batch:
            # æ‰¹é‡é‡‡é›†
            print(f"ğŸš€ å¯åŠ¨æ‰¹é‡é‡‡é›†ï¼Œé‡‡é›†è¿‡å» {args.days} å¤©çš„æ•°æ®")

            total_matches = 0
            async with FotmobBrowserScraper() as scraper:
                for i in range(args.days):
                    date = datetime.now() - timedelta(days=i)
                    date_str = date.strftime("%Y%m%d")

                    print(f"\nğŸ“Š å¤„ç†æ—¥æœŸ: {date_str} ({date.strftime('%Y-%m-%d')})")

                    if args.no_export:
                        match_data_list = await scraper.scrape_matches(date_str)
                        date_matches = len(match_data_list)
                        print(f"  âœ… é‡‡é›†å®Œæˆ: {date_matches} åœºæ¯”èµ›")
                    else:
                        output_file = (
                            output_dir
                            / f"fotmob_matches_{date_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                        )
                        saved_count = await scraper.scrape_and_export_matches(
                            date_str, str(output_file)
                        )
                        print(f"  âœ… é‡‡é›†å®Œæˆ: {saved_count} åœºæ¯”èµ›")
                        date_matches = saved_count

                    total_matches += date_matches

            print(f"\nğŸ“Š æ‰¹é‡é‡‡é›†ç»“æœ:")
            print(f"  ğŸ“… å¤„ç†å¤©æ•°: {args.days} å¤©")
            print(f"  âš½ æ€»é‡‡é›†æ¯”èµ›: {total_matches} åœº")
            print(f"  ğŸ“‹ çŠ¶æ€: {'æˆåŠŸ' if total_matches > 0 else 'æ— æ•°æ®'}")

        else:
            print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®šé‡‡é›†å‚æ•°")
            parser.print_help()
            sys.exit(1)

        print(f"\nğŸ é‡‡é›†æ‰§è¡Œå®Œæˆ!")

    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†é‡‡é›†æ‰§è¡Œ")
        sys.exit(130)

    except Exception as e:
        print(f"\nâŒ é‡‡é›†æ‰§è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == "__main__":
    print("ğŸ”§ FotMobæ•°æ®é‡‡é›†å™¨")
    print("ğŸ¯ åŸºäºPlaywrightçš„çœŸå®æ•°æ®é‡‡é›†æ–¹æ¡ˆ")
    print("âš¡ è¿™æ˜¯å”¯ä¸€ç»è¿‡éªŒè¯çš„å¯ç”¨çš„æ•°æ®é‡‡é›†å™¨")
    print()

    asyncio.run(main())
