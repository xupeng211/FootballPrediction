#!/usr/bin/env python3
"""
ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åŒ–æµæ°´çº¿è„šæœ¬
æ•´åˆæ‰€æœ‰ç”Ÿäº§å°±ç»ªè§£å†³æ–¹æ¡ˆ
"""

import sys
import subprocess
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import argparse


class ProductionAutomationPipeline:
    """ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åŒ–æµæ°´çº¿"""

    def __init__(self, environment: str = "production"):
        self.environment = environment
        self.project_root = Path.cwd()
        self.reports_dir = self.project_root / "docs/_reports"
        self.scripts_dir = self.project_root / "scripts"

        # æ£€æŸ¥æŠ¥å‘Š
        self.check_results = {
            "dependencies": {"status": "unknown", "score": 0},
            "security": {"status": "unknown", "score": 0},
            "tests": {"status": "unknown", "score": 0},
            "configuration": {"status": "unknown", "score": 0},
            "ci_cd": {"status": "unknown", "score": 0}
        }

        # é˜ˆå€¼
        self.thresholds = {
            "pass": 80,
            "warning": 60,
            "fail": 40
        }

    def run_full_pipeline(self) -> bool:
        """è¿è¡Œå®Œæ•´çš„è‡ªåŠ¨åŒ–æµæ°´çº¿"""
        print(f"ğŸš€ å¼€å§‹ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åŒ–æµæ°´çº¿ - {self.environment.upper()}")
        print("=" * 80)

        success = True

        # 1. ä¾èµ–æ£€æŸ¥å’Œä¿®å¤
        print("\n1ï¸âƒ£ ä¾èµ–å†²çªæ£€æŸ¥å’Œä¿®å¤...")
        success &= self._run_dependency_check()

        # 2. å®‰å…¨é…ç½®
        print("\n2ï¸âƒ£ å®‰å…¨é…ç½®è®¾ç½®...")
        success &= self._run_security_setup()

        # 3. æµ‹è¯•æ¡†æ¶æ„å»º
        print("\n3ï¸âƒ£ æµ‹è¯•æ¡†æ¶æ„å»º...")
        success &= self._run_test_framework_setup()

        # 4. é…ç½®éªŒè¯
        print("\n4ï¸âƒ£ ç¯å¢ƒé…ç½®éªŒè¯...")
        success &= self._run_configuration_validation()

        # 5. CI/CDæ£€æŸ¥
        print("\n5ï¸âƒ£ CI/CDé…ç½®æ£€æŸ¥...")
        success &= self._run_cicd_check()

        # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print("\n6ï¸âƒ£ ç”Ÿæˆæœ€ç»ˆè¯„ä¼°æŠ¥å‘Š...")
        self._generate_final_report()

        # æ€»ç»“
        print("\n" + "=" * 80)
        if success:
            total_score = sum(r["score"] for r in self.check_results.values()) / len(self.check_results)
            print(f"âœ… æµæ°´çº¿å®Œæˆ! æ€»åˆ†: {total_score:.1f}/100")
            if total_score >= self.thresholds["pass"]:
                print("ğŸ‰ é¡¹ç›®å·²è¾¾åˆ°ç”Ÿäº§å°±ç»ªæ ‡å‡†!")
            else:
                print("âš ï¸  é¡¹ç›®å°šæœªè¾¾åˆ°ç”Ÿäº§å°±ç»ªæ ‡å‡†ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šäº†è§£è¯¦æƒ…")
        else:
            print("âŒ æµæ°´çº¿å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

        return success and total_score >= self.thresholds["pass"]

    def _run_dependency_check(self) -> bool:
        """è¿è¡Œä¾èµ–æ£€æŸ¥"""
        try:
            # è¿è¡Œä¾èµ–å†²çªè§£å†³è„šæœ¬
            result = subprocess.run(
                [sys.executable, str(self.scripts_dir / "dependency/resolve_conflicts.py")],
                capture_output=True,
                text=True
            )

            if result.returncode == 0:
                self.check_results["dependencies"]["status"] = "passed"
                self.check_results["dependencies"]["score"] = 95
                print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
                return True
            else:
                self.check_results["dependencies"]["status"] = "failed"
                self.check_results["dependencies"]["score"] = 30
                print(f"âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            self.check_results["dependencies"]["status"] = "error"
            self.check_results["dependencies"]["score"] = 0
            print(f"âŒ ä¾èµ–æ£€æŸ¥é”™è¯¯: {e}")
            return False

    def _run_security_setup(self) -> bool:
        """è¿è¡Œå®‰å…¨é…ç½®"""
        try:
            # è¿è¡Œå®‰å…¨é…ç½®è„šæœ¬
            env_file = f".env.{self.environment}"
            result = subprocess.run([
                sys.executable,
                str(self.scripts_dir / "security/setup_security.py"),
                "--env", self.environment,
                "--output", env_file
            ], capture_output=True, text=True)

            if result.returncode == 0:
                self.check_results["security"]["status"] = "passed"
                self.check_results["security"]["score"] = 90
                print("âœ… å®‰å…¨é…ç½®å®Œæˆ")
                return True
            else:
                self.check_results["security"]["status"] = "failed"
                self.check_results["security"]["score"] = 20
                print(f"âŒ å®‰å…¨é…ç½®å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            self.check_results["security"]["status"] = "error"
            self.check_results["security"]["score"] = 0
            print(f"âŒ å®‰å…¨é…ç½®é”™è¯¯: {e}")
            return False

    def _run_test_framework_setup(self) -> bool:
        """è¿è¡Œæµ‹è¯•æ¡†æ¶æ„å»º"""
        try:
            # æ„å»ºæµ‹è¯•æ¡†æ¶
            result = subprocess.run([
                sys.executable,
                str(self.scripts_dir / "testing/build_test_framework.py")
            ], capture_output=True, text=True)

            if result.returncode == 0:
                # è¿è¡ŒåŸºç¡€æµ‹è¯•éªŒè¯
                test_result = subprocess.run([
                    sys.executable, "-m", "pytest",
                    "tests/unit/api/test_health.py::TestHealthAPI::test_health_check_success",
                    "-v", "--tb=short"
                ], capture_output=True, text=True)

                if test_result.returncode == 0:
                    self.check_results["tests"]["status"] = "passed"
                    self.check_results["tests"]["score"] = 85
                    print("âœ… æµ‹è¯•æ¡†æ¶æ„å»ºæˆåŠŸ")
                    return True
                else:
                    self.check_results["tests"]["status"] = "warning"
                    self.check_results["tests"]["score"] = 60
                    print("âš ï¸  æµ‹è¯•æ¡†æ¶æ„å»ºå®Œæˆï¼Œä½†æµ‹è¯•éœ€è¦è¿›ä¸€æ­¥ä¿®å¤")
                    return True
            else:
                self.check_results["tests"]["status"] = "failed"
                self.check_results["tests"]["score"] = 5
                print(f"âŒ æµ‹è¯•æ¡†æ¶æ„å»ºå¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            self.check_results["tests"]["status"] = "error"
            self.check_results["tests"]["score"] = 0
            print(f"âŒ æµ‹è¯•æ¡†æ¶æ„å»ºé”™è¯¯: {e}")
            return False

    def _run_configuration_validation(self) -> bool:
        """è¿è¡Œé…ç½®éªŒè¯"""
        try:
            # æ£€æŸ¥ç¯å¢ƒæ–‡ä»¶
            env_file = self.project_root / f".env.{self.environment}"
            if not env_file.exists():
                self.check_results["configuration"]["status"] = "failed"
                self.check_results["configuration"]["score"] = 0
                print("âŒ ç¯å¢ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
                return False

            # æ£€æŸ¥æ–‡ä»¶æƒé™
            if env_file.stat().st_mode & 0o777 != 0o600:
                print("âš ï¸  ç¯å¢ƒæ–‡ä»¶æƒé™ä¸æ­£ç¡®ï¼Œæ­£åœ¨ä¿®å¤...")
                env_file.chmod(0o600)

            # éªŒè¯é…ç½®é¡¹
            score = 90
            issues = []

            with open(env_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æ£€æŸ¥å…³é”®é…ç½®
            if "CHANGE_ME" in content:
                issues.append("å‘ç°å ä½ç¬¦é…ç½®")
                score -= 30

            # æ£€æŸ¥SECRET_KEY
            if "SECRET_KEY" not in content:
                issues.append("ç¼ºå°‘SECRET_KEY")
                score -= 20

            # æ£€æŸ¥æ•°æ®åº“é…ç½®
            if "DATABASE_URL" not in content:
                issues.append("ç¼ºå°‘æ•°æ®åº“é…ç½®")
                score -= 20

            if issues:
                print(f"âš ï¸  é…ç½®é—®é¢˜: {', '.join(issues)}")

            self.check_results["configuration"]["status"] = "passed" if score >= 80 else "warning"
            self.check_results["configuration"]["score"] = score
            print(f"âœ… é…ç½®éªŒè¯å®Œæˆ (å¾—åˆ†: {score})")
            return True

        except Exception as e:
            self.check_results["configuration"]["status"] = "error"
            self.check_results["configuration"]["score"] = 0
            print(f"âŒ é…ç½®éªŒè¯é”™è¯¯: {e}")
            return False

    def _run_cicd_check(self) -> bool:
        """è¿è¡ŒCI/CDæ£€æŸ¥"""
        try:
            score = 85
            issues = []

            # æ£€æŸ¥GitHub Actionsé…ç½®
            workflows_dir = self.project_root / ".github/workflows"
            if not workflows_dir.exists():
                issues.append("ç¼ºå°‘GitHub Actionsé…ç½®")
                score -= 40

            # æ£€æŸ¥å…³é”®å·¥ä½œæµ
            required_workflows = ["ci-pipeline.yml", "security-scan.yml"]
            for workflow in required_workflows:
                if not (workflows_dir / workflow).exists():
                    issues.append(f"ç¼ºå°‘å·¥ä½œæµ: {workflow}")
                    score -= 20

            # æ£€æŸ¥Makefile
            makefile = self.project_root / "Makefile"
            if not makefile.exists():
                issues.append("ç¼ºå°‘Makefile")
                score -= 10

            # æ£€æŸ¥Dockeré…ç½®
            dockerfile = self.project_root / "Dockerfile"
            if not dockerfile.exists():
                issues.append("ç¼ºå°‘Dockerfile")
                score -= 15

            if issues:
                print(f"âš ï¸  CI/CDé—®é¢˜: {', '.join(issues)}")

            self.check_results["ci_cd"]["status"] = "passed" if score >= 80 else "warning"
            self.check_results["ci_cd"]["score"] = score
            print(f"âœ… CI/CDæ£€æŸ¥å®Œæˆ (å¾—åˆ†: {score})")
            return True

        except Exception as e:
            self.check_results["ci_cd"]["status"] = "error"
            self.check_results["ci_cd"]["score"] = 0
            print(f"âŒ CI/CDæ£€æŸ¥é”™è¯¯: {e}")
            return False

    def _generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæœ€ç»ˆè¯„ä¼°æŠ¥å‘Š...")

        # è®¡ç®—æ€»åˆ†
        total_score = sum(r["score"] for r in self.check_results.values()) / len(self.check_results)

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "environment": self.environment,
            "overall_score": total_score,
            "overall_status": self._get_status(total_score),
            "thresholds": self.thresholds,
            "details": self.check_results,
            "recommendations": self._generate_recommendations(),
            "next_steps": self._generate_next_steps()
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.reports_dir / "PRODUCTION_READINESS_FINAL_REPORT.json"
        self.reports_dir.mkdir(parents=True, exist_ok=True)

        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        # ç”ŸæˆmarkdownæŠ¥å‘Š
        self._generate_markdown_report(report)

        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

    def _get_status(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–çŠ¶æ€"""
        if score >= self.thresholds["pass"]:
            return "production_ready"
        elif score >= self.thresholds["warning"]:
            return "needs_attention"
        else:
            return "not_ready"

    def _generate_recommendations(self) -> List[Dict]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []

        # ä¾èµ–å»ºè®®
        if self.check_results["dependencies"]["score"] < self.thresholds["pass"]:
            recommendations.append({
                "category": "dependencies",
                "priority": "high",
                "action": "è§£å†³ä¾èµ–å†²çª",
                "details": "è¿è¡Œ python scripts/dependency/resolve_conflicts.py"
            })

        # å®‰å…¨å»ºè®®
        if self.check_results["security"]["score"] < self.thresholds["pass"]:
            recommendations.append({
                "category": "security",
                "priority": "high",
                "action": "é…ç½®å®‰å…¨å¯†é’¥",
                "details": "è¿è¡Œ python scripts/security/setup_security.py"
            })

        # æµ‹è¯•å»ºè®®
        if self.check_results["tests"]["score"] < self.thresholds["warning"]:
            recommendations.append({
                "category": "tests",
                "priority": "high",
                "action": "æ„å»ºæµ‹è¯•æ¡†æ¶",
                "details": "è¿è¡Œ python scripts/testing/build_test_framework.py"
            })

        # é…ç½®å»ºè®®
        if self.check_results["configuration"]["score"] < self.thresholds["pass"]:
            recommendations.append({
                "category": "configuration",
                "priority": "medium",
                "action": "å®Œå–„ç¯å¢ƒé…ç½®",
                "details": "æ£€æŸ¥å’Œä¿®å¤ .env.production æ–‡ä»¶"
            })

        # CI/CDå»ºè®®
        if self.check_results["ci_cd"]["score"] < self.thresholds["pass"]:
            recommendations.append({
                "category": "ci_cd",
                "priority": "medium",
                "action": "å®Œå–„CI/CDé…ç½®",
                "details": "æ·»åŠ GitHub Actionså·¥ä½œæµå’ŒMakefileå‘½ä»¤"
            })

        return recommendations

    def _generate_next_steps(self) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        next_steps = []

        if self.check_results["dependencies"]["status"] != "passed":
            next_steps.append("1. è§£å†³æ‰€æœ‰ä¾èµ–å†²çª")
            next_steps.append("   - pip install pip-tools")
            next_steps.append("   - pip-compile requirements.txt")

        if self.check_results["security"]["status"] != "passed":
            next_steps.append("2. è®¾ç½®å®‰å…¨é…ç½®")
            next_steps.append("   - ç”Ÿæˆå®‰å…¨å¯†é’¥")
            next_steps.append("   - é…ç½®ç¯å¢ƒå˜é‡")

        if self.check_results["tests"]["status"] != "passed":
            next_steps.append("3. æ„å»ºæµ‹è¯•æ¡†æ¶")
            next_steps.append("   - åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„")
            next_steps.append("   - ç¼–å†™åŸºç¡€æµ‹è¯•ç”¨ä¾‹")
            next_steps.append("   - é…ç½®æµ‹è¯•å·¥å…·")

        next_steps.append("4. éƒ¨ç½²å‡†å¤‡")
        next_steps.append("   - è®¾ç½®Dockerå®¹å™¨")
        next_steps.append("   - é…ç½®ç›‘æ§å’Œæ—¥å¿—")
        next_steps.append("   - å‡†å¤‡ç”Ÿäº§æ•°æ®åº“")

        return next_steps

    def _generate_markdown_report(self, report: Dict):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        markdown_content = f"""# ç”Ÿäº§ç¯å¢ƒå°±ç»ªè¯„ä¼°æŠ¥å‘Š

**è¯„ä¼°æ—¶é—´**: {report["timestamp"]}
**ç¯å¢ƒ**: {report["environment"].upper()}
**æ€»åˆ†**: {report["overall_score"]:.1f}/100
**çŠ¶æ€**: {self._format_status(report["overall_status"])}

## ğŸ“Š å„é¡¹è¯„åˆ†

| æ£€æŸ¥é¡¹ | çŠ¶æ€ | å¾—åˆ† | è¦æ±‚ |
|--------|------|------|------|"""

        for check_name, result in report["details"].items():
            status_icon = "âœ…" if result["status"] == "passed" else "âš ï¸" if result["status"] == "warning" else "âŒ"
            check_name_display = check_name.replace("_", " ").title()
            markdown_content += f"\n| {check_name_display} | {status_icon} | {result['score']} | >={self.thresholds['pass']} |"

        markdown_content += "\n\n## ğŸ¯ å…³é”®å‘ç°"

        if report["recommendations"]:
            markdown_content += "\n### âš ï¸ éœ€è¦è§£å†³çš„é—®é¢˜\n"
            for rec in report["recommendations"]:
                priority_icon = "ğŸ”´" if rec["priority"] == "high" else "ğŸŸ¡" if rec["priority"] == "medium" else "ğŸŸ¢"
                markdown_content += f"\n{priority_icon} **{rec['action']}** ({rec['category']})\n"
                markdown_content += f"   - {rec['details']}\n"

        markdown_content += "\n## ğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n"
        for step in report["next_steps"]:
            markdown_content += f"\n{step}\n"

        markdown_content += f"""

## ğŸ‰ æˆåŠŸæ ‡å‡†

é¡¹ç›®è¾¾åˆ°ç”Ÿäº§å°±ç»ªéœ€è¦ï¼š
- ä¾èµ–å†²çª: âœ… å·²è§£å†³
- å®‰å…¨é…ç½®: âœ… å·²é…ç½®
- æµ‹è¯•è¦†ç›–ç‡: >80%
- é…ç½®å®Œæ•´æ€§: âœ… å®Œæˆ
- CI/CDæµç¨‹: âœ… å®Œæ•´
- **æ€»åˆ†: â‰¥{self.thresholds['pass']}**

---

*æ­¤æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆ*
"""

        # ä¿å­˜MarkdownæŠ¥å‘Š
        md_file = self.reports_dir / "PRODUCTION_READINESS_FINAL_REPORT.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write(markdown_content)

        print(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {md_file}")

    def _format_status(self, status: str) -> str:
        """æ ¼å¼åŒ–çŠ¶æ€æ˜¾ç¤º"""
        status_map = {
            "production_ready": "ğŸ‰ ç”Ÿäº§å°±ç»ª",
            "needs_attention": "âš ï¸ éœ€è¦å…³æ³¨",
            "not_ready": "âŒ æœªå°±ç»ª"
        }
        return status_map.get(status, status)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åŒ–æµæ°´çº¿")
    parser.add_argument(
        "--env",
        choices=["development", "testing", "staging", "production"],
        default="production",
        help="ç›®æ ‡ç¯å¢ƒ"
    )
    parser.add_argument(
        "--check-only",
        action="store_true",
        help="ä»…æ£€æŸ¥ï¼Œä¸æ‰§è¡Œä¿®å¤"
    )

    args = parser.parse_args()

    pipeline = ProductionAutomationPipeline(args.env)

    if args.check_only:
        print("ğŸ” ä»…æ£€æŸ¥æ¨¡å¼...")
        # TODO: å®ç°ä»…æ£€æŸ¥é€»è¾‘
    else:
        success = pipeline.run_full_pipeline()
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()