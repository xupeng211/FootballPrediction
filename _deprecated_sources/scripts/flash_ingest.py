#!/usr/bin/env python3
"""
æé€Ÿå…¥åº“å™¨ - é¦–å¸­æ•°æ®åº“æ¶æ„å¸ˆä¸“ç”¨
ä½¿ç”¨PostgreSQLåŸç”ŸCOPYå‘½ä»¤å®ç°CSVæ–‡ä»¶æé€Ÿå…¥åº“
ç›®æ ‡ï¼š5åˆ†é’Ÿå†…å°†29ä¸ªCSVæ–‡ä»¶å…¨éƒ¨å…¥åº“
"""

import psycopg2
import logging
import sys
from pathlib import Path
from datetime import datetime
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("logs/flash_ingest.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class FlashIngester:
    """æé€Ÿå…¥åº“å™¨"""

    def __init__(self):
        # æ•°æ®åº“è¿æ¥é…ç½® - ä½¿ç”¨Dockerå®¹å™¨è¿æ¥
        self.db_config = {
            "host": "localhost",  # å®¹å™¨ç«¯å£æ˜ å°„
            "port": 5432,
            "database": "football_prediction",
            "user": "postgres",
            "password": "",  # PostgreSQLå®¹å™¨é»˜è®¤æ— å¯†ç 
        }

        self.csv_dir = Path("data/fbref")
        self.stats = {
            "total_files": 0,
            "successful_files": 0,
            "failed_files": 0,
            "total_rows": 0,
            "start_time": datetime.now(),
        }

        # åˆ›å»ºæ—¥å¿—ç›®å½•
        Path("logs").mkdir(exist_ok=True)

    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            conn = psycopg2.connect(**self.db_config)
            conn.autocommit = False
            return conn
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def ingest_csv_file(self, csv_file: Path, conn):
        """ä½¿ç”¨COPYå‘½ä»¤å¿«é€Ÿå¯¼å…¥å•ä¸ªCSVæ–‡ä»¶"""
        try:
            logger.info(f"ğŸ“„ å¼€å§‹å¯¼å…¥: {csv_file.name}")

            # è·å–æ–‡ä»¶å¤§å°å’Œè¡Œæ•°
            file_size = csv_file.stat().st_size
            with open(csv_file, encoding="utf-8") as f:
                # å¿«é€Ÿä¼°ç®—è¡Œæ•°
                sample_size = 1024
                sample = f.read(sample_size)
                estimated_rows = sample.count("\n") * (file_size // sample_size)

            logger.info(
                f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} bytes, é¢„ä¼°è¡Œæ•°: {estimated_rows:,}"
            )

            cursor = conn.cursor()

            # æ¸…ç†æ–‡ä»¶åä½œä¸ºæºæ ‡è¯†
            source_file = csv_file.name

            # ä½¿ç”¨COPYå‘½ä»¤å¯¼å…¥ - PostgreSQLæœ€å¿«çš„æ‰¹é‡å¯¼å…¥æ–¹å¼
            with open(csv_file, encoding="utf-8") as f:
                # å…ˆæ·»åŠ source_fileåˆ—
                cursor.execute(
                    """
                    ALTER TABLE stg_fbref_matches
                    ADD COLUMN IF NOT EXISTS source_file TEXT,
                    ADD COLUMN IF NOT EXISTS loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    ADD COLUMN IF NOT EXISTS processed BOOLEAN DEFAULT FALSE
                """
                )

                # ä½¿ç”¨COPYå‘½ä»¤å¯¼å…¥ï¼ˆPostgreSQLå†…éƒ¨ä¼˜åŒ–ï¼Œæå¿«ï¼‰
                copy_sql = """
                COPY stg_fbref_matches (wk, "Day", "Date", "Time", "Home", "xG", "Score", "xG.1", "Away",
                                         "Attendance", "Venue", "Referee", "Match Report", "Notes", source_file)
                FROM STDIN WITH CSV HEADER
                """

                cursor.copy_expert(copy_sql, f)

            # æ›´æ–°source_fileå­—æ®µ
            cursor.execute(
                f"""
                UPDATE stg_fbref_matches
                SET source_file = '{source_file}'
                WHERE source_file IS NULL OR loaded_at >= CURRENT_TIMESTAMP - INTERVAL '1 second'
            """
            )

            conn.commit()

            # è·å–å®é™…å¯¼å…¥çš„è¡Œæ•°
            cursor.execute(
                f"""
                SELECT COUNT(*) FROM stg_fbref_matches
                WHERE source_file = '{source_file}'
            """
            )
            actual_rows = cursor.fetchone()[0]

            logger.info(f"âœ… å¯¼å…¥å®Œæˆ: {actual_rows:,} è¡Œ")
            self.stats["total_rows"] += actual_rows

            return True

        except Exception as e:
            logger.error(f"âŒ å¯¼å…¥å¤±è´¥ {csv_file.name}: {e}")
            conn.rollback()
            return False

    def run(self):
        """æ‰§è¡Œæé€Ÿå…¥åº“"""
        logger.info("ğŸš€ å¯åŠ¨æé€Ÿå…¥åº“å™¨ - é¦–å¸­æ•°æ®åº“æ¶æ„å¸ˆæ¨¡å¼")
        start_time = datetime.now()

        # æ‰«ææ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(self.csv_dir.glob("*.csv"))
        self.stats["total_files"] = len(csv_files)

        logger.info(f"ğŸ“ å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        logger.info("ğŸ“‹ ç›®æ ‡: ä½¿ç”¨PostgreSQL COPYå‘½ä»¤æé€Ÿå¯¼å…¥")

        # è·å–æ•°æ®åº“è¿æ¥
        conn = self.get_connection()

        try:
            # é€ä¸ªå¤„ç†CSVæ–‡ä»¶
            for i, csv_file in enumerate(csv_files, 1):
                logger.info(
                    f"ğŸ”„ è¿›åº¦: {i}/{len(csv_files)} ({i/len(csv_files)*100:.1f}%)"
                )

                success = self.ingest_csv_file(csv_file, conn)

                if success:
                    self.stats["successful_files"] += 1
                else:
                    self.stats["failed_files"] += 1

            # è·å–æœ€ç»ˆç»Ÿè®¡
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM stg_fbref_matches")
            final_count = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(DISTINCT source_file) FROM stg_fbref_matches")
            file_count = cursor.fetchone()[0]

            # æ›´æ–°ç»Ÿè®¡
            self.stats["total_rows"] = final_count
            self.stats["successful_files"] = file_count

            conn.commit()

        finally:
            conn.close()

        # è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        logger.info("=" * 60)
        logger.info("ğŸ‰ æé€Ÿå…¥åº“å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’")
        logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶: {self.stats['total_files']}")
        logger.info(f"âœ… æˆåŠŸæ–‡ä»¶: {self.stats['successful_files']}")
        logger.info(f"âŒ å¤±è´¥æ–‡ä»¶: {self.stats['failed_files']}")
        logger.info(f"âš½ æ€»æ•°æ®è¡Œ: {self.stats['total_rows']:,}")
        logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {self.stats['total_rows']/duration:.0f} è¡Œ/ç§’")
        logger.info("")
        logger.info("ğŸ“‹ ä¸‹ä¸€æ­¥: æ‰§è¡Œæ•°æ®æ¸…æ´—ä¸è¿ç§»SQL")

        return self.stats


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ”§ å¯åŠ¨æé€Ÿå…¥åº“å™¨")

    try:
        ingester = FlashIngester()
        stats = ingester.run()

        # è¾“å‡ºæˆåŠŸä¿¡æ¯
        if stats["successful_files"] > 0:
            logger.info(
                f"âœ… å…¥åº“æˆåŠŸ! {stats['successful_files']} ä¸ªæ–‡ä»¶, {stats['total_rows']:,} è¡Œæ•°æ®"
            )
            return 0
        else:
            logger.error("âŒ å…¥åº“å¤±è´¥!")
            return 1

    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
