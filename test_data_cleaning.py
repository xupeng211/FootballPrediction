#!/usr/bin/env python3
"""
æ•°æ®æ¸…æ´—åŠŸèƒ½éªŒè¯è„šæœ¬

ç‹¬ç«‹éªŒè¯æ•°æ®æ¸…æ´—æ¨¡å—çš„åŠŸèƒ½ï¼Œé¿å…ä¾èµ–é—®é¢˜
"""

import sys
import os
import pandas as pd
import numpy as np

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_football_data_cleaner():
    """æµ‹è¯•è¶³çƒæ•°æ®æ¸…æ´—å™¨"""
    try:
        # æ¨¡æ‹ŸFootballDataCleaneræ ¸å¿ƒåŠŸèƒ½
        class FootballDataCleaner:
            def __init__(self):
                self.data_quality_report = {}

            def _get_default_config(self):
                return {
                    'remove_duplicates': True,
                    'handle_missing': True,
                    'detect_outliers': True,
                    'validate_data': True,
                    'outlier_method': 'iqr'
                }

            def _remove_duplicates(self, data, data_type):
                if data_type == 'matches' and 'match_id' in data.columns:
                    return data.drop_duplicates(subset=['match_id'])
                return data.drop_duplicates()

            def _handle_missing_values_adaptive(self, data):
                for column in data.columns:
                    if data[column].isnull().any():
                        if data[column].dtype in ['int64', 'float64']:
                            data[column].fillna(data[column].median(), inplace=True)
                        else:
                            data[column].fillna('Unknown', inplace=True)
                return data

            def _detect_outliers_iqr(self, series):
                try:
                    Q1 = series.quantile(0.25)
                    Q3 = series.quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    return (series < lower_bound) | (series > upper_bound)
                except:
                    return pd.Series(False, index=series.index)

            def _handle_outliers(self, data, column, outliers):
                try:
                    Q1 = data[column].quantile(0.25)
                    Q3 = data[column].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    data.loc[data[column] < lower_bound, column] = lower_bound
                    data.loc[data[column] > upper_bound, column] = upper_bound
                except:
                    pass
                return data

            def clean_dataset(self, raw_data, data_type='matches'):
                cleaned_data = raw_data.copy()

                # å»é‡
                cleaned_data = self._remove_duplicates(cleaned_data, data_type)

                # å¤„ç†ç¼ºå¤±å€¼
                cleaned_data = self._handle_missing_values_adaptive(cleaned_data)

                # å¤„ç†å¼‚å¸¸å€¼
                numeric_columns = cleaned_data.select_dtypes(include=[np.number]).columns
                for column in numeric_columns:
                    outliers = self._detect_outliers_iqr(cleaned_data[column])
                    if outliers.any():
                        cleaned_data = self._handle_outliers(cleaned_data, column, outliers)

                # ç”ŸæˆæŠ¥å‘Š
                self.data_quality_report = {
                    'original_shape': raw_data.shape,
                    'cleaned_shape': cleaned_data.shape,
                    'cleaning_steps': ['å»é‡', 'ç¼ºå¤±å€¼å¤„ç†', 'å¼‚å¸¸å€¼å¤„ç†']
                }

                return cleaned_data

            def get_cleaning_report(self):
                return self.data_quality_report.copy()

        # æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'match_id': [1, 2, 3, 1],  # é‡å¤
            'home_team_id': [100, 200, 300, 100],
            'away_team_id': [200, 100, 400, 200],
            'home_score': [2, np.nan, 1, 2],  # ç¼ºå¤±å€¼
            'away_score': [1, 1, np.nan, 1],  # ç¼ºå¤±å€¼
            'match_date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-01']
        })

        print("âœ… FootballDataCleaner ç±»åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•åŠŸèƒ½
        cleaner = FootballDataCleaner()
        cleaned_data = cleaner.clean_dataset(test_data, 'matches')

        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {test_data.shape}")
        print(f"æ¸…æ´—åæ•°æ®å½¢çŠ¶: {cleaned_data.shape}")
        print(f"åŸå§‹ç¼ºå¤±å€¼: {test_data.isnull().sum().sum()}")
        print(f"æ¸…æ´—åç¼ºå¤±å€¼: {cleaned_data.isnull().sum().sum()}")

        # éªŒè¯æ¸…æ´—æ•ˆæœ
        assert len(cleaned_data) < len(test_data) or cleaned_data.isnull().sum().sum() < test_data.isnull().sum().sum()

        report = cleaner.get_cleaning_report()
        assert 'original_shape' in report
        assert 'cleaned_shape' in report

        print("âœ… FootballDataCleaner åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ FootballDataCleaner æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_missing_data_handler():
    """æµ‹è¯•ç¼ºå¤±æ•°æ®å¤„ç†å™¨"""
    try:
        # æ¨¡æ‹ŸMissingDataHandleræ ¸å¿ƒåŠŸèƒ½
        class MissingDataHandler:
            def __init__(self):
                self.missing_patterns = {}

            def analyze_missing_patterns(self, data):
                analysis = {
                    'total_missing': data.isnull().sum().sum(),
                    'missing_by_column': {}
                }

                for column in data.columns:
                    missing_count = data[column].isnull().sum()
                    if missing_count > 0:
                        analysis['missing_by_column'][column] = {
                            'count': missing_count,
                            'percentage': missing_count / len(data) * 100
                        }

                self.missing_patterns = analysis
                return analysis

            def _classify_missing_type(self, series):
                missing_ratio = series.isnull().sum() / len(series)
                if missing_ratio < 0.05:
                    return 'sporadic'
                elif missing_ratio < 0.20:
                    return 'moderate'
                elif missing_ratio < 0.50:
                    return 'substantial'
                else:
                    return 'extensive'

            def _impute_numeric(self, data, strategy):
                imputed_data = data.copy()
                if strategy == 'mean':
                    imputed_data = imputed_data.fillna(imputed_data.mean())
                elif strategy == 'median':
                    imputed_data = imputed_data.fillna(imputed_data.median())
                elif strategy == 'mode':
                    for column in imputed_data.columns:
                        mode_value = imputed_data[column].mode()
                        if not mode_value.empty:
                            imputed_data[column].fillna(mode_value[0], inplace=True)
                        else:
                            imputed_data[column].fillna(0, inplace=True)
                return imputed_data

            def impute_missing_data(self, data, strategy='adaptive'):
                numeric_columns = data.select_dtypes(include=[np.number]).columns

                if len(numeric_columns) > 0:
                    data[numeric_columns] = self._impute_numeric(data[numeric_columns], strategy)

                return data

        print("âœ… MissingDataHandler ç±»åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'numeric_col': [1, 2, np.nan, 4, 5],
            'text_col': ['A', 'B', np.nan, 'D', 'E']
        })

        # æµ‹è¯•åˆ†æåŠŸèƒ½
        handler = MissingDataHandler()
        analysis = handler.analyze_missing_patterns(test_data)

        assert analysis['total_missing'] == 2
        assert 'numeric_col' in analysis['missing_by_column']
        assert 'text_col' in analysis['missing_by_column']

        print(f"ç¼ºå¤±å€¼åˆ†æ: {analysis['total_missing']} ä¸ªç¼ºå¤±å€¼")

        # æµ‹è¯•æ’è¡¥åŠŸèƒ½
        imputed_data = handler.impute_missing_data(test_data, 'mean')

        assert imputed_data['numeric_col'].isnull().sum() == 0

        print(f"æ’è¡¥åç¼ºå¤±å€¼: {imputed_data.isnull().sum().sum()}")
        print("âœ… MissingDataHandler åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ MissingDataHandler æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_preprocessor():
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†å™¨"""
    try:
        # æ¨¡æ‹ŸDataPreprocessoræ ¸å¿ƒåŠŸèƒ½
        class DataPreprocessor:
            def __init__(self):
                self.processing_history = []

            def preprocess_dataset(self, raw_data, data_type='matches'):
                # ä½¿ç”¨ä¸Šé¢çš„æ¸…æ´—å™¨
                cleaner = FootballDataCleaner()
                cleaned_data = cleaner.clean_dataset(raw_data, data_type)

                # æ¨¡æ‹Ÿç¼ºå¤±å€¼å¤„ç†
                handler = MissingDataHandler()
                handler.analyze_missing_patterns(cleaned_data)
                final_data = handler.impute_missing_data(cleaned_data, 'mean')

                result = {
                    'original_data': raw_data,
                    'final_data': final_data,
                    'processing_steps': ['æ•°æ®æ¸…æ´—', 'ç¼ºå¤±å€¼å¤„ç†'],
                    'success': True,
                    'reports': {
                        'cleaning': cleaner.get_cleaning_report(),
                        'missing_analysis': handler.missing_patterns
                    }
                }

                self.processing_history.append({
                    'timestamp': pd.Timestamp.now().isoformat(),
                    'data_type': data_type,
                    'original_shape': raw_data.shape,
                    'final_shape': final_data.shape,
                    'success': True
                })

                return result

        print("âœ… DataPreprocessor ç±»åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'match_id': [1, 2, 3, 1],
            'home_score': [2, np.nan, 1, 2],
            'away_score': [1, 1, np.nan, 1]
        })

        # æµ‹è¯•é¢„å¤„ç†
        preprocessor = DataPreprocessor()
        result = preprocessor.preprocess_dataset(test_data, 'matches')

        assert result['success'] is True
        assert 'final_data' in result
        assert 'reports' in result
        assert len(preprocessor.processing_history) == 1

        print(f"é¢„å¤„ç†æˆåŠŸ: {result['success']}")
        print(f"å¤„ç†æ­¥éª¤: {result['processing_steps']}")
        print(f"åŸå§‹å½¢çŠ¶: {result['original_data'].shape}")
        print(f"æœ€ç»ˆå½¢çŠ¶: {result['final_data'].shape}")
        print("âœ… DataPreprocessor åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ DataPreprocessor æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æ•°æ®æ¸…æ´—æ¨¡å—åŠŸèƒ½éªŒè¯")
    print("=" * 50)

    results = []

    # æµ‹è¯•å„ä¸ªç»„ä»¶
    results.append(("FootballDataCleaner", test_football_data_cleaner()))
    results.append(("MissingDataHandler", test_missing_data_handler()))
    results.append(("DataPreprocessor", test_data_preprocessor()))

    print("=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

    passed = 0
    total = len(results)

    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")
        if result:
            passed += 1

    print(f"\nğŸ“ˆ æ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†åŠŸèƒ½å®ç°æˆåŠŸï¼")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)