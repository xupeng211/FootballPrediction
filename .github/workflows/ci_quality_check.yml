name: Unified CI Quality Check

# ç»Ÿä¸€çš„CI/CDè´¨é‡æ£€æŸ¥å·¥ä½œæµ
# æ•´åˆäº†æµ‹è¯•ã€è´¨é‡æ£€æŸ¥ã€å®‰å…¨æ‰«æå’Œè¦†ç›–ç‡é—¨ç¦
# å¼ºåˆ¶è¦æ±‚æœ€ä½10%æµ‹è¯•è¦†ç›–ç‡

permissions:
  contents: read
  checks: write
  pull-requests: write
  issues: write

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      strict_mode:
        description: 'å¯ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆè­¦å‘Šä¹Ÿä¼šå¤±è´¥ï¼‰'
        required: false
        default: 'false'
        type: boolean
      python_version:
        description: 'æŒ‡å®šPythonç‰ˆæœ¬ï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤çŸ©é˜µï¼‰'
        required: false
        default: ''
        type: choice
        options:
          - ''
          - '3.10'
          - '3.11'
          - '3.12'

env:
  COVERAGE_THRESHOLD: 10  # å¼ºåˆ¶è¦†ç›–ç‡é˜ˆå€¼
  NODE_VERSION: '18'
  # æ•°æ®åº“ç¯å¢ƒå˜é‡ - æä¾›æµ‹è¯•å®‰å…¨çš„é»˜è®¤å€¼
  DATABASE_URL: "sqlite:///./football_prediction.db"
  ASYNC_DATABASE_URL: "sqlite+aiosqlite:///./football_prediction.db"

jobs:
  # å˜æ›´æ£€æµ‹ä½œä¸š
  detect-changes:
    name: ğŸ“‹ Detect Changes
    runs-on: ubuntu-22.04
    outputs:
      src-changed: ${{ steps.changes.outputs.src }}
      test-changed: ${{ steps.changes.outputs.test }}
      ci-changed: ${{ steps.changes.outputs.ci }}
      python-version: ${{ steps.python-version.outputs.version }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 2

    - name: Detect file changes
      uses: dorny/paths-filter@v2
      id: changes
      with:
        filters: |
          src:
            - 'src/**/*.py'
            - 'requirements/**/*'
          test:
            - 'tests/**/*.py'
            - 'pytest.ini'
            - 'pyproject.toml'
          ci:
            - '.github/workflows/**/*'
            - 'Makefile'

    - name: Determine Python version
      id: python-version
      run: |
        if [ -n "${{ github.event.inputs.python_version }}" ]; then
          echo "version=[${{ github.event.inputs.python_version }}]" >> $GITHUB_OUTPUT
        else
          echo "version=[3.10, 3.11, 3.12]" >> $GITHUB_OUTPUT
        fi

  # å¹¶è¡Œè´¨é‡æ£€æŸ¥ä½œä¸š
  quality-checks:
    name: ğŸ” Quality Checks
    runs-on: ubuntu-22.04
    needs: detect-changes
    if: always() && (needs.detect-changes.outputs.src-changed == 'true' || needs.detect-changes.outputs.ci-changed == 'true' || github.event_name == 'workflow_dispatch')

    strategy:
      fail-fast: false
      matrix:
        python-version: ${{ fromJson(needs.detect-changes.outputs.python-version) }}
        check: [format, lint, type-check, security]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          .venv
        key: ${{ runner.os }}-python${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-python${{ matrix.python-version }}-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pip-tools
        if [ -f "requirements/dev.txt" ]; then
          pip-sync requirements/dev.txt
        elif [ -f "pyproject.toml" ]; then
          pip install -e ".[dev]"
        else
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio ruff mypy bandit black isort
        fi

        # Install make if not available
        if ! command -v make &> /dev/null; then
          sudo apt-get update && sudo apt-get install -y make
        fi

    - name: Code Format Check
      if: matrix.check == 'format'
      run: |
        echo "ğŸ¨ æ£€æŸ¥ä»£ç æ ¼å¼..."

        # Black format check
        if command -v black &> /dev/null; then
          black --check --diff src/ tests/ || {
            echo "âŒ ä»£ç æ ¼å¼æ£€æŸ¥å¤±è´¥"
            echo "è¿è¡Œ 'black src/ tests/' ä¿®å¤æ ¼å¼é—®é¢˜"
            exit 1
          }
        fi

        # isort import check
        if command -v isort &> /dev/null; then
          isort --check-only src/ tests/ || {
            echo "âŒ å¯¼å…¥æ’åºæ£€æŸ¥å¤±è´¥"
            echo "è¿è¡Œ 'isort src/ tests/' ä¿®å¤å¯¼å…¥æ’åº"
            exit 1
          }
        fi

        echo "âœ… ä»£ç æ ¼å¼æ£€æŸ¥é€šè¿‡"

    - name: Code Linting
      if: matrix.check == 'lint'
      run: |
        echo "ğŸ” è¿è¡Œä»£ç æ£€æŸ¥..."

        # Ruff linting
        if command -v ruff &> /dev/null; then
          ruff check src/ tests/ --output-format=github --exit-zero || {
            echo "âŒ ä»£ç æ£€æŸ¥å‘ç°é—®é¢˜"
            ruff check src/ tests/ --output-format=full
            exit 1
          }
        fi

        echo "âœ… ä»£ç æ£€æŸ¥é€šè¿‡"

    - name: Type Checking
      if: matrix.check == 'type-check'
      run: |
        echo "ğŸ”¬ è¿è¡Œç±»å‹æ£€æŸ¥..."

        # MyPy type checking with relaxed settings for CI
        if command -v mypy &> /dev/null; then
          mypy src/ \
            --ignore-missing-imports \
            --no-strict-optional \
            --disable-error-code=assignment,attr-defined \
            --hide-error-context \
            || {
            echo "âš ï¸ ç±»å‹æ£€æŸ¥å‘ç°é—®é¢˜ï¼Œä½†ä¸é˜»æ­¢CI"
            echo "è¯·æŸ¥çœ‹mypyè¾“å‡ºå¹¶ä¿®å¤ç±»å‹é—®é¢˜"
          }
        fi

        echo "âœ… ç±»å‹æ£€æŸ¥å®Œæˆ"

    - name: Security Scan
      if: matrix.check == 'security'
      run: |
        echo "ğŸ›¡ï¸ è¿è¡Œå®‰å…¨æ‰«æ..."

        # Bandit security scan
        if command -v bandit &> /dev/null; then
          bandit -r src/ -f json -o bandit-report.json || {
            echo "âš ï¸ å‘ç°å®‰å…¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æŠ¥å‘Š"
          }

          # Fail on high severity issues
          python3 scripts/check_security_report.py --report-path bandit-report.json || {
            echo "âš ï¸ å®‰å…¨æ£€æŸ¥è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š"
          }
        fi

        # Dependency audit
        if command -v safety &> /dev/null; then
          safety check --json --output safety-report.json || {
            echo "âš ï¸ å‘ç°ä¾èµ–å®‰å…¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æŠ¥å‘Š"
          }
        fi

        echo "âœ… å®‰å…¨æ‰«æå®Œæˆ"

    - name: Upload security reports
      if: matrix.check == 'security'
      uses: actions/upload-artifact@v4
      with:
        name: security-reports-py${{ matrix.python-version }}
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # æµ‹è¯•ä½œä¸š - å¤šPythonç‰ˆæœ¬çŸ©é˜µ
  test-suite:
    name: ğŸ§ª Test Suite
    runs-on: ubuntu-22.04
    needs: detect-changes
    if: always() && (needs.detect-changes.outputs.src-changed == 'true' || needs.detect-changes.outputs.test-changed == 'true' || github.event_name == 'workflow_dispatch')

    strategy:
      fail-fast: false
      matrix:
        python-version: ${{ fromJson(needs.detect-changes.outputs.python-version) }}

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_football_prediction
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Cache dependencies and test cache
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          .venv
          .pytest_cache
        key: ${{ runner.os }}-test-${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml', '**/pytest.ini') }}
        restore-keys: |
          ${{ runner.os }}-test-${{ matrix.python-version }}-
          ${{ runner.os }}-test-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pip-tools
        if [ -f "requirements/dev.txt" ]; then
          pip-sync requirements/dev.txt
        elif [ -f "pyproject.toml" ]; then
          pip install -e ".[dev]"
        else
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-mock pytest-benchmark
        fi

        # Install make if not available
        if ! command -v make &> /dev/null; then
          sudo apt-get update && sudo apt-get install -y make
        fi

    - name: Set up test environment
      run: |
        # Create test environment file
        cat > .env.test << EOF
        DATABASE_URL=postgresql://postgres:postgres@localhost:5432/test_football_prediction
        REDIS_URL=redis://localhost:6379/0
        ENV=testing
        DEBUG=false
        LOG_LEVEL=WARNING
        PYTHONPATH=$PWD:$PYTHONPATH
        EOF

        # Export environment variables
        export $(cat .env.test | xargs)
        echo "æµ‹è¯•ç¯å¢ƒå·²è®¾ç½®"

    - name: Run P0-P1 Safety Net Tests
      run: |
        echo "ğŸ›¡ï¸ è¿è¡ŒP0-P1å®‰å…¨ç½‘æµ‹è¯•..."
        export $(cat .env.test | xargs)

        # Run critical safety tests if they exist
        if [ -d "tests/unit/core" ]; then
          pytest tests/unit/core/ -v -m "critical or safety" --cov=src --cov-report=term-missing --maxfail=3 || {
            echo "âš ï¸ å®‰å…¨ç½‘æµ‹è¯•å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶"
          }
        fi

    - name: Run Unit Tests with Coverage
      run: |
        echo "ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š..."
        export $(cat .env.test | xargs)

        # Run unit tests with coverage
        if [ -f "Makefile" ] && grep -q "test.unit" Makefile; then
          make test.unit
        else
          pytest tests/unit/ \
            -v \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-report=html \
            --junit-xml=test-results.xml \
            --maxfail=5 \
            -x
        fi

        # Generate coverage summary
        python -m coverage report --show-missing > coverage-summary.txt

    - name: Run Integration Tests
      run: |
        echo "ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•..."
        export $(cat .env.test | xargs)

        # Run integration tests if they exist
        if [ -d "tests/integration" ]; then
          if [ -f "Makefile" ] && grep -q "test.integration" Makefile; then
            make test.integration
          else
            pytest tests/integration/ \
              -v \
              --junit-xml=integration-test-results.xml \
              --maxfail=3
          fi
        else
          echo "â„¹ï¸ æœªæ‰¾åˆ°é›†æˆæµ‹è¯•ç›®å½•"
        fi

    - name: ğŸšª COVERAGE GATE ENFORCEMENT
      run: |
        echo "ğŸšª æ£€æŸ¥è¦†ç›–ç‡é—¨ç¦ (é˜ˆå€¼: ${{ env.COVERAGE_THRESHOLD }}%)..."

        # Extract coverage percentage from coverage report
        COVERAGE_PERCENTAGE=$(python -m coverage report | grep TOTAL | awk '{print $4}' | sed 's/%//')
        THRESHOLD=${{ env.COVERAGE_THRESHOLD }}

        echo "å½“å‰è¦†ç›–ç‡: ${COVERAGE_PERCENTAGE}%"
        echo "è¦æ±‚é˜ˆå€¼: ${THRESHOLD}%"

        # Check if coverage meets threshold
        if (( $(echo "$COVERAGE_PERCENTAGE >= $THRESHOLD" | bc -l) )); then
          echo "âœ… è¦†ç›–ç‡æ£€æŸ¥é€šè¿‡: ${COVERAGE_PERCENTAGE}% >= ${THRESHOLD}%"
        else
          echo "âŒ è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥: ${COVERAGE_PERCENTAGE}% < ${THRESHOLD}%"
          echo ""
          echo "ğŸ”§ æå‡è¦†ç›–ç‡å»ºè®®:"
          echo "1. ä¸ºæœªè¦†ç›–çš„æ ¸å¿ƒæ¨¡å—æ·»åŠ å•å…ƒæµ‹è¯•"
          echo "2. è¿è¡Œ 'pytest --cov=src --cov-report=term-missing' æŸ¥çœ‹æœªè¦†ç›–ä»£ç "
          echo "3. é‡ç‚¹å…³æ³¨ adapters, collectors, database, cache ç­‰æ ¸å¿ƒæ¨¡å—"
          echo ""
          echo "ğŸ“Š å½“å‰è¦†ç›–ç‡è¯¦æƒ…:"
          python -m coverage report --show-missing || true
          exit 1
        fi

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-py${{ matrix.python-version }}
        path: |
          test-results.xml
          integration-test-results.xml
          htmlcov/
          coverage-summary.txt
          coverage.xml
        retention-days: 30

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.python-version == '3.11'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        token: ${{ secrets.CODECOV_TOKEN }}

  # æ€§èƒ½æµ‹è¯•ä½œä¸š
  performance-test:
    name: âš¡ Performance Test
    runs-on: ubuntu-22.04
    needs: [detect-changes, test-suite]
    if: always() && ((needs.detect-changes.outputs.src-changed == 'true' || github.event_name == 'workflow_dispatch') && needs.test-suite.result == 'success')

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f "requirements/dev.txt" ]; then
          pip-sync requirements/dev.txt
        else
          pip install pytest pytest-benchmark
        fi

    - name: Run performance tests
      run: |
        echo "âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•..."

        if [ -d "tests/performance" ]; then
          pytest tests/performance/ \
            --benchmark-json=benchmark.json \
            --benchmark-only \
            --benchmark-min-rounds=5 || {
            echo "âš ï¸ æ€§èƒ½æµ‹è¯•å®Œæˆï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½é—®é¢˜"
          }
        else
          echo "â„¹ï¸ æœªæ‰¾åˆ°æ€§èƒ½æµ‹è¯•ç›®å½•"
        fi

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: benchmark.json
        retention-days: 30

  # è´¨é‡é—¨ç¦æ±‡æ€»ä½œä¸š
  quality-gate-summary:
    name: ğŸ“Š Quality Gate Summary
    runs-on: ubuntu-22.04
    needs: [detect-changes, quality-checks, test-suite]
    if: always()

    steps:
    - name: Quality Gate Summary
      run: |
        echo "ğŸ“Š è´¨é‡é—¨ç¦æ±‡æ€»æŠ¥å‘Š"
        echo "================================"
        echo ""

        QUALITY_STATUS="${{ needs.quality-checks.result }}"
        TEST_STATUS="${{ needs.test-suite.result }}"

        echo "ğŸ” ä»£ç è´¨é‡æ£€æŸ¥: $QUALITY_STATUS"
        echo "ğŸ§ª æµ‹è¯•å¥—ä»¶: $TEST_STATUS"
        echo ""

        if [ "$QUALITY_STATUS" = "success" ] && [ "$TEST_STATUS" = "success" ]; then
          echo "âœ… æ‰€æœ‰è´¨é‡æ£€æŸ¥é€šè¿‡!"
          echo "ğŸ¯ é¡¹ç›®è´¨é‡çŠ¶æ€: å¥åº·"
          exit 0
        else
          echo "âŒ è´¨é‡æ£€æŸ¥æœªå®Œå…¨é€šè¿‡"
          echo ""

          if [ "$QUALITY_STATUS" != "success" ]; then
            echo "ğŸ” ä»£ç è´¨é‡æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š"
          fi

          if [ "$TEST_STATUS" != "success" ]; then
            echo "ğŸ§ª æµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æµ‹è¯•æ—¥å¿—"
          fi

          exit 1
        fi

    - name: Generate Quality Badge
      if: always()
      id: badge
      run: |
        QUALITY_STATUS="${{ needs.quality-checks.result }}"
        TEST_STATUS="${{ needs.test-suite.result }}"

        if [ "$QUALITY_STATUS" = "success" ] && [ "$TEST_STATUS" = "success" ]; then
          COLOR="brightgreen"
          MESSAGE="Pass"
          SCORE="100"
        else
          COLOR="red"
          MESSAGE="Fail"
          SCORE="0"
        fi

        # Create badge JSON
        cat << EOF > quality-badge.json
        {
          "schemaVersion": 1,
          "label": "Quality Gate",
          "message": "$MESSAGE",
          "color": "$COLOR"
        }
        EOF

        echo "badge_color=$COLOR" >> $GITHUB_OUTPUT
        echo "badge_message=$MESSAGE" >> $GITHUB_OUTPUT
        echo "badge_score=$SCORE" >> $GITHUB_OUTPUT

    - name: Create Quality Report
      if: always()
      run: |
        cat << EOF > quality-report.md
        # ğŸš¦ è´¨é‡é—¨ç¦æ£€æŸ¥æŠ¥å‘Š

        ## ğŸ“Š æ£€æŸ¥ç»“æœ

        - **ä»£ç è´¨é‡æ£€æŸ¥**: ${{ needs.quality-checks.result }}
        - **æµ‹è¯•å¥—ä»¶**: ${{ needs.test-suite.result }}
        - **è¦†ç›–ç‡é˜ˆå€¼**: ${{ env.COVERAGE_THRESHOLD }}%
        - **æ£€æŸ¥æ—¶é—´**: $(date)

        ## ğŸ¯ è´¨é‡ç›®æ ‡

        - âœ… ä»£ç æ ¼å¼: é€šè¿‡Blackå’Œisortæ£€æŸ¥
        - âœ… ä»£ç è´¨é‡: é€šè¿‡Ruffæ£€æŸ¥
        - âœ… ç±»å‹æ£€æŸ¥: é€šè¿‡MyPyæ£€æŸ¥
        - âœ… å®‰å…¨æ‰«æ: é€šè¿‡Banditæ£€æŸ¥
        - âœ… æµ‹è¯•è¦†ç›–: è¾¾åˆ°${{ env.COVERAGE_THRESHOLD }}%è¦†ç›–ç‡
        - âœ… æ€§èƒ½æµ‹è¯•: è¿è¡ŒåŸºå‡†æµ‹è¯•

        ## ğŸ“ˆ è¯¦ç»†æŠ¥å‘Š

        - [GitHub Actionsæ—¥å¿—](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
        - [CodecovæŠ¥å‘Š](https://codecov.io/gh/${{ github.repository }})

        ---
        *æŠ¥å‘Šç”Ÿæˆæ—¶é—´: $(date)*
        EOF

    - name: Upload quality report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: quality-report
        path: |
          quality-report.md
          quality-badge.json
        retention-days: 30

    - name: Comment on PR
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');

          try {
            const qualityStatus = '${{ needs.quality-checks.result }}';
            const testStatus = '${{ needs.test-suite.result }}';
            const badgeMessage = '${{ steps.badge.outputs.badge_message }}';
            const badgeColor = '${{ steps.badge.outputs.badge_color }}';

            let emoji = 'âœ…';
            let status = 'é€šè¿‡';

            if (qualityStatus !== 'success' || testStatus !== 'success') {
              emoji = 'âŒ';
              status = 'æœªé€šè¿‡';
            }

            const comment = `
            ## ğŸš¦ è´¨é‡é—¨ç¦æ£€æŸ¥ç»“æœ

            **çŠ¶æ€**: ${emoji} ${status}
            **è¦†ç›–ç‡è¦æ±‚**: ${{ env.COVERAGE_THRESHOLD }}%
            **æ£€æŸ¥æ—¶é—´**: ${new Date().toLocaleString('zh-CN')}

            ### ğŸ“Š æ£€æŸ¥ç»“æœ
            - ğŸ” ä»£ç è´¨é‡æ£€æŸ¥: ${qualityStatus === 'success' ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥'}
            - ğŸ§ª æµ‹è¯•å¥—ä»¶: ${testStatus === 'success' ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥'}
            - ğŸ“Š è¦†ç›–ç‡é—¨ç¦: ${{ env.COVERAGE_THRESHOLD }}%

            ### ğŸ“„ è¯¦ç»†æŠ¥å‘Š
            - [å®Œæ•´æ—¥å¿—](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - [è´¨é‡æŠ¥å‘Š](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}?artifacts)

            ---
            ğŸ¤– æ­¤æŠ¥å‘Šç”±ç»Ÿä¸€çš„CIè´¨é‡æ£€æŸ¥å·¥ä½œæµç”Ÿæˆ
            `;

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.error('Failed to create PR comment:', error);
          }

    - name: Final Status Check
      if: needs.quality-checks.result != 'success' || needs.test-suite.result != 'success'
      run: |
        echo "âŒ è´¨é‡é—¨ç¦æ£€æŸ¥å¤±è´¥"
        echo "è¯·æŸ¥çœ‹ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜"
        exit 1