name: 🚪 Enhanced Quality Gate

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  MIN_COVERAGE_THRESHOLD: 25
  MAX_RUFF_ISSUES: 50
  MAX_SECURITY_ISSUES: 5

jobs:
  # 1. 预检查
  pre-checks:
    name: 🔍 Pre-Quality Checks
    runs-on: ubuntu-latest
    outputs:
      should-continue: ${{ steps.changes.outputs.should-continue }}

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: 🔍 Detect Changes
      id: changes
      run: |
        # 检查是否有重要的代码变更
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          echo "should-continue=true" >> $GITHUB_OUTPUT
        elif [ "${{ github.event_name }}" = "push" ]; then
          # 检查最近提交是否有Python文件变更
          if git diff --name-only HEAD~1 HEAD | grep -E '\.(py|yml|yaml|toml|ini)$'; then
            echo "should-continue=true" >> $GITHUB_OUTPUT
          else
            echo "should-continue=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "should-continue=true" >> $GITHUB_OUTPUT
        fi

    - name: 📋 Changes Summary
      run: |
        echo "📋 Changed files in this push/PR:"
        git diff --name-only HEAD~1 HEAD | head -10 || echo "No changes detected"

  # 2. 代码风格检查
  style-check:
    name: 🎨 Code Style Check
    runs-on: ubuntu-latest
    needs: pre-checks
    if: needs.pre-checks.outputs.should-continue == 'true'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install Ruff
      run: pip install ruff

    - name: 🔍 Ruff Linting
      run: |
        echo "🔍 Running Ruff linting..."
        ruff check src/ tests/ --output-format=github --show-fixes

        # 统计问题数量
        issues=$(ruff check src/ tests/ --output-format=json | python -c "import json, sys; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
        echo "📊 Found $issues Ruff issues"

        if [ $issues -gt ${{ env.MAX_RUFF_ISSUES }} ]; then
          echo "❌ Too many Ruff issues ($issues > ${{ env.MAX_RUFF_ISSUES }})"
          echo "💡 Consider running 'ruff check --fix' to auto-fix issues"
          exit 1
        fi

    - name: 🎨 Ruff Formatting Check
      run: |
        echo "🎨 Checking code formatting..."
        ruff format --check src/ tests/

  # 3. 类型检查
  type-check:
    name: 🔤 Type Checking
    runs-on: ubuntu-latest
    needs: pre-checks
    if: needs.pre-checks.outputs.should-continue == 'true'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install MyPy
      run: pip install mypy

    - name: 🔤 MyPy Type Checking
      run: |
        echo "🔤 Running MyPy type checking..."

        # 检查是否有mypy配置
        if [ -f "pyproject.toml" ] && grep -q "\[tool.mypy\]" pyproject.toml; then
          echo "📋 Found MyPy configuration"
          mypy src/ --no-error-summary || echo "⚠️ MyPy found type issues"
        else
          echo "📋 No MyPy config found, running basic check"
          mypy src/ --ignore-missing-imports --no-error-summary || echo "⚠️ MyPy found type issues"
        fi

  # 4. 安全检查
  security-check:
    name: 🛡️ Security Check
    runs-on: ubuntu-latest
    needs: pre-checks
    if: needs.pre-checks.outputs.should-continue == 'true'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install Security Tools
      run: pip install bandit safety

    - name: 🛡️ Bandit Security Scan
      run: |
        echo "🛡️ Running Bandit security scan..."
        bandit -r src/ -f json -o bandit-report.json || true

        # 检查安全问题数量
        high_issues=$(cat bandit-report.json | python -c "
import json, sys
try:
    data = json.load(sys.stdin)
    high = len([r for r in data.get('results', []) if r.get('issue_severity') == 'HIGH'])
    print(high)
except:
    print(0)
" 2>/dev/null || echo "0")

        medium_issues=$(cat bandit-report.json | python -c "
import json, sys
try:
    data = json.load(sys.stdin)
    medium = len([r for r in data.get('results', []) if r.get('issue_severity') == 'MEDIUM'])
    print(medium)
except:
    print(0)
" 2>/dev/null || echo "0")

        echo "🔒 Security Issues - High: $high_issues, Medium: $medium_issues"

        total_issues=$((high_issues + medium_issues))
        if [ $high_issues -gt 0 ] || [ $total_issues -gt ${{ env.MAX_SECURITY_ISSUES }} ]; then
          echo "❌ Security issues found that need attention"
          echo "🚨 High severity issues: $high_issues"
          echo "⚠️ Total security issues: $total_issues"
          exit 1
        fi

    - name: 🔒 Dependency Safety Check
      run: |
        echo "🔒 Checking dependency safety..."
        safety check --json --output safety-report.json || echo "⚠️ Safety check found vulnerabilities"

    - name: 📤 Upload Security Reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # 5. 测试质量检查
  test-quality:
    name: 🧪 Test Quality Check
    runs-on: ubuntu-latest
    needs: pre-checks
    if: needs.pre-checks.outputs.should-continue == 'true'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install Test Dependencies
      run: |
        pip install --upgrade pip
        pip install pytest pytest-cov pytest-mock

    - name: 🧪 Test Collection Check
      run: |
        echo "🧪 Checking test collection..."

        # 检查是否能成功收集测试
        if pytest --collect-only -q tests/ 2>/dev/null | grep -q "test session starts"; then
          echo "✅ Tests can be collected successfully"
        else
          echo "⚠️ Some test collection issues detected"
        fi

        # 统计测试数量
        test_count=$(pytest --collect-only -q tests/ 2>/dev/null | grep -c "def test_" || echo "0")
        echo "📊 Found $test_count test functions"

        if [ $test_count -eq 0 ]; then
          echo "⚠️ No tests found. Consider adding tests for new code."
        fi

    - name: 🏃 Quick Test Run (Sample)
      run: |
        echo "🏃 Running quick sample tests..."
        timeout 300 pytest tests/ --maxfail=3 -x --tb=short || echo "⚠️ Some tests failed, but continuing..."

  # 6. 覆盖率检查
  coverage-check:
    name: 📊 Coverage Check
    runs-on: ubuntu-latest
    needs: pre-checks
    if: needs.pre-checks.outputs.should-continue == 'true'

    steps:
    - name: 📥 Checkout Code
      uses: actions/checkout@v4

    - name: 🐍 Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: 📦 Install Coverage Tools
      run: |
        pip install --upgrade pip
        pip install pytest pytest-cov

    - name: 📊 Coverage Measurement
      run: |
        echo "📊 Measuring test coverage..."

        # 运行覆盖率测试（带超时）
        timeout 600 pytest --cov=src --cov-report=xml --cov-report=term-missing tests/ || echo "⚠️ Coverage measurement incomplete"

        # 检查覆盖率报告
        if [ -f "coverage.xml" ]; then
          coverage_percent=$(python -c "
import xml.etree.ElementTree as ET
try:
    tree = ET.parse('coverage.xml')
    root = tree.getroot()
    coverage = root.find('.//coverage')
    if coverage is not None:
        print(coverage.get('line-rate', '0'))
    else:
        print('0')
except:
    print('0')
" | python -c "import sys; print(float(sys.stdin.read()) * 100)")

          echo "📊 Current coverage: ${coverage_percent}%"
          echo "🎯 Minimum required: ${{ env.MIN_COVERAGE_THRESHOLD }}%"

          if (( $(echo "$coverage_percent < ${{ env.MIN_COVERAGE_THRESHOLD }}" | bc -l) )); then
            echo "⚠️ Coverage below threshold (${coverage_percent}% < ${{ env.MIN_COVERAGE_THRESHOLD }}%)"
            echo "💡 Consider adding more tests to improve coverage"
            # 不阻止构建，只是警告
          else
            echo "✅ Coverage meets minimum requirements"
          fi
        else
          echo "⚠️ Coverage report not generated"
        fi

    - name: 📤 Upload Coverage Reports
      uses: actions/upload-artifact@v3
      with:
        name: coverage-reports
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  # 7. 质量门控决策
  quality-gate-decision:
    name: 🚪 Quality Gate Decision
    runs-on: ubuntu-latest
    needs: [pre-checks, style-check, type-check, security-check, test-quality, coverage-check]
    if: always() && needs.pre-checks.outputs.should-continue == 'true'

    steps:
    - name: 🚪 Quality Gate Evaluation
      run: |
        echo "🚪 Quality Gate Evaluation"
        echo "=========================="

        # 收集各阶段结果
        style_result="${{ needs.style-check.result }}"
        type_result="${{ needs.type-check.result }}"
        security_result="${{ needs.security-check.result }}"
        test_result="${{ needs.test-quality.result }}"
        coverage_result="${{ needs.coverage-check.result }}"

        echo "📋 Quality Check Results:"
        echo "  🎨 Code Style: $style_result"
        echo "  🔤 Type Checking: $type_result"
        echo "  🛡️ Security: $security_result"
        echo "  🧪 Test Quality: $test_result"
        echo "  📊 Coverage: $coverage_result"

        # 计算质量分数
        total_checks=5
        passed_checks=0

        [ "$style_result" = "success" ] && passed_checks=$((passed_checks + 1))
        [ "$type_result" = "success" ] && passed_checks=$((passed_checks + 1))
        [ "$security_result" = "success" ] && passed_checks=$((passed_checks + 1))
        [ "$test_result" = "success" ] && passed_checks=$((passed_checks + 1))
        [ "$coverage_result" = "success" ] && passed_checks=$((passed_checks + 1))

        quality_score=$((passed_checks * 100 / total_checks))
        echo "📊 Overall Quality Score: $quality_score% ($passed_checks/$total_checks checks passed)"

        # 质量门控决策
        if [ $quality_score -eq 100 ]; then
          echo "🎉 EXCELLENT: All quality checks passed!"
          echo "✅ Code is ready for production"
          exit 0
        elif [ $quality_score -ge 80 ]; then
          echo "✅ GOOD: Most quality checks passed"
          echo "💡 Code is acceptable, consider fixing remaining issues"
          exit 0
        elif [ $quality_score -ge 60 ]; then
          echo "⚠️ ACCEPTABLE: Some quality issues found"
          echo "🔧 Code can proceed but should be improved"
          exit 0
        else
          echo "❌ POOR: Multiple quality issues found"
          echo "🚨 Code quality below acceptable standards"
          echo "🛠️ Please address quality issues before merging"
          exit 1
        fi

    - name: 📋 Quality Recommendations
      if: always()
      run: |
        echo "💡 Quality Improvement Recommendations:"
        echo ""

        if [ "${{ needs.style-check.result }}" != "success" ]; then
          echo "🎨 Run 'ruff check --fix' to auto-fix style issues"
        fi

        if [ "${{ needs.type-check.result }}" != "success" ]; then
          echo "🔤 Add type hints to improve type checking"
        fi

        if [ "${{ needs.security-check.result }}" != "success" ]; then
          echo "🛡️ Address security vulnerabilities immediately"
        fi

        if [ "${{ needs.test-quality.result }}" != "success" ]; then
          echo "🧪 Fix failing tests and improve test coverage"
        fi

        if [ "${{ needs.coverage-check.result }}" != "success" ]; then
          echo "📊 Add more tests to improve code coverage"
        fi