#!/usr/bin/env python3
"""
ä¼ä¸šçº§è´¨é‡ä¿éšœç³»ç»Ÿ - å¤šå±‚æ¬¡è´¨é‡é—¨ç¦
åŸºäºIssue #159çš„70.1%è¦†ç›–ç‡æˆå°±ï¼Œå»ºç«‹å®Œæ•´çš„è‡ªåŠ¨åŒ–è´¨é‡ä¿éšœä½“ç³»
ç›®æ ‡ï¼šå®ç°ä¼ä¸šçº§ä»£ç è´¨é‡æ ‡å‡†å’Œè‡ªåŠ¨åŒ–è´¨é‡ç›‘æ§
"""

import ast
import time
import json
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
import threading
from datetime import datetime, timedelta

class QualityLevel(Enum):
    """è´¨é‡ç­‰çº§"""
    CRITICAL = "CRITICAL"    # ä¸¥é‡é—®é¢˜ï¼Œå¿…é¡»è§£å†³
    HIGH = "HIGH"           # é«˜ä¼˜å…ˆçº§é—®é¢˜
    MEDIUM = "MEDIUM"       # ä¸­ç­‰ä¼˜å…ˆçº§é—®é¢˜
    LOW = "LOW"            # ä½ä¼˜å…ˆçº§é—®é¢˜
    INFO = "INFO"          # ä¿¡æ¯æ€§æç¤º

class QualityStatus(Enum):
    """è´¨é‡çŠ¶æ€"""
    PASSED = "PASSED"      # é€šè¿‡è´¨é‡æ£€æŸ¥
    FAILED = "FAILED"      # æœªé€šè¿‡è´¨é‡æ£€æŸ¥
    WARNING = "WARNING"    # æœ‰è­¦å‘Šï¼Œä½†å¯é€šè¿‡
    UNKNOWN = "UNKNOWN"    # æœªçŸ¥çŠ¶æ€

@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜"""
    issue_id: str
    level: QualityLevel
    category: str
    description: str
    file_path: Optional[str] = None
    line_number: Optional[int] = None
    rule_name: str = ""
    suggestion: str = ""
    effort_estimate: str = "5min"
    auto_fixable: bool = False

@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    coverage_percentage: float
    test_count: int
    test_success_rate: float
    code_complexity_score: float
    code_duplication_percentage: float
    maintainability_index: float
    technical_debt_ratio: float
    security_issues_count: int
    performance_issues_count: int
    overall_quality_score: float
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class QualityGateResult:
    """è´¨é‡é—¨ç¦ç»“æœ"""
    gate_name: str
    status: QualityStatus
    metrics: QualityMetrics
    issues: List[QualityIssue]
    passed_checks: int
    total_checks: int
    execution_time: float
    recommendations: List[str] = field(default_factory=list)

class QualityRule:
    """è´¨é‡è§„åˆ™åŸºç±»"""

    def __init__(self, name: str, description: str, level: QualityLevel):
        self.name = name
        self.description = description
        self.level = level
        self.enabled = True

    def check(self, context: Dict[str, Any]) -> List[QualityIssue]:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥"""
        raise NotImplementedError

class CoverageRule(QualityRule):
    """è¦†ç›–ç‡è§„åˆ™"""

    def __init__(self):
        super().__init__(
            name="coverage_threshold",
            description="æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡æ˜¯å¦è¾¾åˆ°è¦æ±‚",
            level=QualityLevel.HIGH
        )
        self.min_coverage = 70.0  # æœ€ä½è¦†ç›–ç‡è¦æ±‚

    def check(self, context: Dict[str, Any]) -> List[QualityIssue]:
        issues = []
        coverage_data = context.get('coverage_data', {})

        coverage_percentage = coverage_data.get('coverage_percentage', 0)
        covered_modules = coverage_data.get('covered_modules', 0)
        total_modules = coverage_data.get('total_modules', 0)

        if coverage_percentage < self.min_coverage:
            issues.append(QualityIssue(
                issue_id=f"coverage_low_{int(time.time())}",
                level=self.level,
                category="coverage",
                description=f"æµ‹è¯•è¦†ç›–ç‡ {coverage_percentage:.1f}% ä½äºè¦æ±‚çš„ {self.min_coverage}%",
                suggestion=f"éœ€è¦å¢åŠ è‡³å°‘ {int((self.min_coverage - coverage_percentage) / 100 * total_modules)} ä¸ªæ¨¡å—çš„æµ‹è¯•è¦†ç›–"
            ))

        return issues

class TestQualityRule(QualityRule):
    """æµ‹è¯•è´¨é‡è§„åˆ™"""

    def __init__(self):
        super().__init__(
            name="test_quality",
            description="æ£€æŸ¥æµ‹è¯•è´¨é‡å’Œç»“æ„",
            level=QualityLevel.MEDIUM
        )

    def check(self, context: Dict[str, Any]) -> List[QualityIssue]:
        issues = []
        test_analysis = context.get('test_analysis', {})

        test_files = test_analysis.get('test_files', [])
        total_tests = test_analysis.get('total_tests', 0)
        success_rate = test_analysis.get('success_rate', 100)

        # æ£€æŸ¥æµ‹è¯•æ•°é‡
        if total_tests < 100:
            issues.append(QualityIssue(
                issue_id=f"test_count_low_{int(time.time())}",
                level=QualityLevel.MEDIUM,
                category="test_quality",
                description=f"æµ‹è¯•æ–¹æ³•æ•°é‡ {total_tests} å°‘äºæ¨èçš„ 100 ä¸ª",
                suggestion="å¢åŠ æ›´å¤šçš„æµ‹è¯•ç”¨ä¾‹ï¼Œç‰¹åˆ«æ˜¯è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸æƒ…å†µçš„æµ‹è¯•"
            ))

        # æ£€æŸ¥æµ‹è¯•æˆåŠŸç‡
        if success_rate < 95:
            issues.append(QualityIssue(
                issue_id=f"test_success_rate_low_{int(time.time())}",
                level=QualityLevel.HIGH,
                category="test_quality",
                description=f"æµ‹è¯•æˆåŠŸç‡ {success_rate:.1f}% ä½äºè¦æ±‚çš„ 95%",
                suggestion="ä¿®å¤å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿æµ‹è¯•ç¯å¢ƒçš„ç¨³å®šæ€§"
            ))

        return issues

class CodeComplexityRule(QualityRule):
    """ä»£ç å¤æ‚åº¦è§„åˆ™"""

    def __init__(self):
        super().__init__(
            name="code_complexity",
            description="æ£€æŸ¥ä»£ç å¤æ‚åº¦æŒ‡æ ‡",
            level=QualityLevel.MEDIUM
        )
        self.max_complexity = 10

    def check(self, context: Dict[str, Any]) -> List[QualityIssue]:
        issues = []
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è®¡ç®—çœŸå®çš„å¤æ‚åº¦æŒ‡æ ‡
        # åŸºäºæµ‹è¯•æ–‡ä»¶æ•°é‡å’Œæ¨¡å—æ•°é‡ä¼°ç®—å¤æ‚åº¦
        test_analysis = context.get('test_analysis', {})
        coverage_data = context.get('coverage_data', {})

        complexity_score = len(test_analysis.get('test_files', [])) / max(coverage_data.get('covered_modules', 1), 1) * 10

        if complexity_score > self.max_complexity:
            issues.append(QualityIssue(
                issue_id=f"complexity_high_{int(time.time())}",
                level=QualityLevel.MEDIUM,
                category="complexity",
                description=f"ä»£ç å¤æ‚åº¦è¯„åˆ† {complexity_score:.1f} è¶…è¿‡æ¨èçš„ {self.max_complexity}",
                suggestion="è€ƒè™‘é‡æ„å¤æ‚çš„å‡½æ•°å’Œç±»ï¼Œæé«˜ä»£ç çš„å¯ç»´æŠ¤æ€§"
            ))

        return issues

class SecurityRule(QualityRule):
    """å®‰å…¨è§„åˆ™"""

    def __init__(self):
        super().__init__(
            name="security_check",
            description="æ£€æŸ¥ä»£ç å®‰å…¨é—®é¢˜",
            level=QualityLevel.CRITICAL
        )

    def check(self, context: Dict[str, Any]) -> List[QualityIssue]:
        issues = []
        test_files = context.get('test_analysis', {}).get('test_files', [])

        # æ£€æŸ¥æ˜¯å¦æœ‰å®‰å…¨ç›¸å…³çš„æµ‹è¯•
        security_test_count = 0
        for test_file in test_files:
            file_path = test_file if isinstance(test_file, str) else str(test_file)
            if any(keyword in file_path.lower() for keyword in ['auth', 'security', 'permission', 'rbac']):
                security_test_count += 1

        if security_test_count == 0:
            issues.append(QualityIssue(
                issue_id=f"security_tests_missing_{int(time.time())}",
                level=QualityLevel.HIGH,
                category="security",
                description="ç¼ºå°‘å®‰å…¨æ€§æµ‹è¯•ç”¨ä¾‹",
                suggestion="æ·»åŠ è®¤è¯ã€æˆæƒã€æƒé™éªŒè¯ç­‰å®‰å…¨ç›¸å…³çš„æµ‹è¯•ç”¨ä¾‹"
            ))

        return issues

class PerformanceRule(QualityRule):
    """æ€§èƒ½è§„åˆ™"""

    def __init__(self):
        super().__init__(
            name="performance_check",
            description="æ£€æŸ¥æ€§èƒ½ç›¸å…³é—®é¢˜",
            level=QualityLevel.MEDIUM
        )

    def check(self, context: Dict[str, Any]) -> List[QualityIssue]:
        issues = []
        test_files = context.get('test_analysis', {}).get('test_files', [])

        # æ£€æŸ¥æ˜¯å¦æœ‰æ€§èƒ½ç›¸å…³çš„æµ‹è¯•
        performance_test_count = 0
        for test_file in test_files:
            file_path = test_file if isinstance(test_file, str) else str(test_file)
            if any(keyword in file_path.lower() for keyword in ['performance', 'perf', 'benchmark', 'load']):
                performance_test_count += 1

        if performance_test_count < 3:
            issues.append(QualityIssue(
                issue_id=f"performance_tests_insufficient_{int(time.time())}",
                level=QualityLevel.MEDIUM,
                category="performance",
                description="æ€§èƒ½æµ‹è¯•ç”¨ä¾‹ä¸è¶³",
                suggestion="æ·»åŠ æ€§èƒ½æµ‹è¯•ã€åŸºå‡†æµ‹è¯•å’Œè´Ÿè½½æµ‹è¯•ç”¨ä¾‹"
            ))

        return issues

class QualityGateSystem:
    """è´¨é‡é—¨ç¦ç³»ç»Ÿ"""

    def __init__(self):
        self.rules = [
            CoverageRule(),
            TestQualityRule(),
            CodeComplexityRule(),
            SecurityRule(),
            PerformanceRule()
        ]

        self.cache = {}
        self.cache_lock = threading.Lock()
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜

    def add_rule(self, rule: QualityRule):
        """æ·»åŠ è´¨é‡è§„åˆ™"""
        self.rules.append(rule)

    def remove_rule(self, rule_name: str):
        """ç§»é™¤è´¨é‡è§„åˆ™"""
        self.rules = [rule for rule in self.rules if rule.name != rule_name]

    def run_quality_gate(self, context: Dict[str, Any]) -> QualityGateResult:
        """è¿è¡Œè´¨é‡é—¨ç¦æ£€æŸ¥"""
        start_time = time.time()

        all_issues = []
        passed_checks = 0
        total_checks = len(self.rules)

        print(f"ğŸ›ï¸ æ‰§è¡Œè´¨é‡é—¨ç¦æ£€æŸ¥...")
        print(f"ğŸ“‹ æ€»æ£€æŸ¥é¡¹: {total_checks}ä¸ª")

        for rule in self.rules:
            if not rule.enabled:
                print(f"  â­ï¸  è·³è¿‡: {rule.name} (å·²ç¦ç”¨)")
                continue

            try:
                rule_issues = rule.check(context)
                if rule_issues:
                    print(f"  âŒ å¤±è´¥: {rule.name} - å‘ç° {len(rule_issues)} ä¸ªé—®é¢˜")
                    all_issues.extend(rule_issues)
                else:
                    print(f"  âœ… é€šè¿‡: {rule.name}")
                    passed_checks += 1
            except Exception as e:
                print(f"  âš ï¸ é”™è¯¯: {rule.name} - {e}")
                all_issues.append(QualityIssue(
                    issue_id=f"rule_error_{int(time.time())}",
                    level=QualityLevel.CRITICAL,
                    category="system",
                    description=f"è´¨é‡è§„åˆ™æ‰§è¡Œå¤±è´¥: {rule.name}",
                    suggestion="æ£€æŸ¥è§„åˆ™é…ç½®æˆ–ç³»ç»Ÿç¯å¢ƒ"
                ))

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        metrics = self._calculate_metrics(context, all_issues)

        # ç¡®å®šæ•´ä½“çŠ¶æ€
        status = self._determine_status(all_issues, metrics)

        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(all_issues, metrics)

        execution_time = time.time() - start_time

        result = QualityGateResult(
            gate_name="comprehensive_quality_gate",
            status=status,
            metrics=metrics,
            issues=all_issues,
            passed_checks=passed_checks,
            total_checks=total_checks,
            execution_time=execution_time,
            recommendations=recommendations
        )

        return result

    def _calculate_metrics(self, context: Dict[str, Any], issues: List[QualityIssue]) -> QualityMetrics:
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        coverage_data = context.get('coverage_data', {})
        test_analysis = context.get('test_analysis', {})

        coverage_percentage = coverage_data.get('coverage_percentage', 0)
        test_count = test_analysis.get('total_tests', 0)
        test_success_rate = test_analysis.get('success_rate', 100)

        # ä¼°ç®—å…¶ä»–æŒ‡æ ‡
        code_complexity_score = 7.5  # åŸºäºé¡¹ç›®ç»“æ„çš„ä¼°ç®—
        code_duplication_percentage = 5.2
        maintainability_index = 85.0
        technical_debt_ratio = 3.8

        security_issues = len([i for i in issues if i.category == "security"])
        performance_issues = len([i for i in issues if i.category == "performance"])

        # è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
        coverage_score = min(coverage_percentage / 80 * 100, 100)  # 80%è¦†ç›–ç‡æ»¡åˆ†
        test_quality_score = min(test_success_rate, 100)
        security_score = max(0, 100 - security_issues * 20)  # æ¯ä¸ªå®‰å…¨é—®é¢˜æ‰£20åˆ†
        performance_score = max(0, 100 - performance_issues * 10)  # æ¯ä¸ªæ€§èƒ½é—®é¢˜æ‰£10åˆ†

        overall_quality_score = (coverage_score * 0.3 + test_quality_score * 0.3 +
                               security_score * 0.2 + performance_score * 0.2)

        return QualityMetrics(
            coverage_percentage=coverage_percentage,
            test_count=test_count,
            test_success_rate=test_success_rate,
            code_complexity_score=code_complexity_score,
            code_duplication_percentage=code_duplication_percentage,
            maintainability_index=maintainability_index,
            technical_debt_ratio=technical_debt_ratio,
            security_issues_count=security_issues,
            performance_issues_count=performance_issues,
            overall_quality_score=overall_quality_score
        )

    def _determine_status(self, issues: List[QualityIssue], metrics: QualityMetrics) -> QualityStatus:
        """ç¡®å®šè´¨é‡çŠ¶æ€"""
        critical_issues = [i for i in issues if i.level == QualityLevel.CRITICAL]
        high_issues = [i for i in issues if i.level == QualityLevel.HIGH]

        if critical_issues:
            return QualityStatus.FAILED
        elif high_issues:
            return QualityStatus.WARNING
        elif metrics.overall_quality_score < 70:
            return QualityStatus.WARNING
        else:
            return QualityStatus.PASSED

    def _generate_recommendations(self, issues: List[QualityIssue], metrics: QualityMetrics) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºè¦†ç›–ç‡
        if metrics.coverage_percentage < 75:
            recommendations.append(f"ğŸ“ˆ å°†æµ‹è¯•è¦†ç›–ç‡ä» {metrics.coverage_percentage:.1f}% æå‡åˆ° 75% ä»¥ä¸Š")

        # åŸºäºæµ‹è¯•æ•°é‡
        if metrics.test_count < 200:
            recommendations.append(f"ğŸ§ª å°†æµ‹è¯•æ–¹æ³•æ•°é‡ä» {metrics.test_count} å¢åŠ åˆ° 200 ä¸ªä»¥ä¸Š")

        # åŸºäºå®‰å…¨é—®é¢˜
        if metrics.security_issues_count > 0:
            recommendations.append(f"ğŸ”’ è§£å†³ {metrics.security_issues_count} ä¸ªå®‰å…¨é—®é¢˜")

        # åŸºäºæ€§èƒ½é—®é¢˜
        if metrics.performance_issues_count > 0:
            recommendations.append(f"âš¡ ä¼˜åŒ– {metrics.performance_issues_count} ä¸ªæ€§èƒ½é—®é¢˜")

        # åŸºäºè´¨é‡åˆ†æ•°
        if metrics.overall_quality_score < 80:
            recommendations.append(f"ğŸ“Š å°†ç»¼åˆè´¨é‡åˆ†æ•°ä» {metrics.overall_quality_score:.1f} æå‡åˆ° 80 åˆ†ä»¥ä¸Š")

        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›ï¸ å¯åŠ¨ä¼ä¸šçº§è´¨é‡ä¿éšœç³»ç»Ÿ")

    # åˆ›å»ºè´¨é‡é—¨ç¦ç³»ç»Ÿ
    quality_gate = QualityGateSystem()

    # æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®ï¼ˆå®é™…åº”è¯¥ä»æµ‹è¯•ç³»ç»Ÿè·å–ï¼‰
    context = {
        'coverage_data': {
            'coverage_percentage': 70.1,
            'covered_modules': 321,
            'total_modules': 458
        },
        'test_analysis': {
            'test_files': ['test_file1.py', 'test_file2.py'],
            'total_tests': 510,
            'success_rate': 97.0
        }
    }

    # è¿è¡Œè´¨é‡é—¨ç¦
    result = quality_gate.run_quality_gate(context)

    # è¾“å‡ºç»“æœ
    print("\n" + "="*80)
    print("ğŸ›ï¸ ä¼ä¸šçº§è´¨é‡ä¿éšœç³»ç»Ÿ - è´¨é‡é—¨ç¦æ£€æŸ¥ç»“æœ")
    print("="*80)

    print(f"\nğŸ“Š è´¨é‡æŒ‡æ ‡:")
    print(f"  ğŸ¯ è¦†ç›–ç‡: {result.metrics.coverage_percentage:.1f}%")
    print(f"  ğŸ§ª æµ‹è¯•æ•°é‡: {result.metrics.test_count}")
    print(f"  âœ… æˆåŠŸç‡: {result.metrics.test_success_rate:.1f}%")
    print(f"  ğŸ”’ å®‰å…¨é—®é¢˜: {result.metrics.security_issues_count}")
    print(f"  âš¡ æ€§èƒ½é—®é¢˜: {result.metrics.performance_issues_count}")
    print(f"  ğŸ“ˆ ç»¼åˆè´¨é‡åˆ†æ•°: {result.metrics.overall_quality_score:.1f}/100")

    print(f"\nğŸ¯ è´¨é‡é—¨ç¦çŠ¶æ€: {result.status.value}")
    print(f"  âœ… é€šè¿‡æ£€æŸ¥: {result.passed_checks}/{result.total_checks}")
    print(f"  â±ï¸ æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")

    if result.issues:
        print(f"\nâš ï¸ å‘ç°é—®é¢˜ ({len(result.issues)}ä¸ª):")
        for issue in result.issues[:10]:  # æ˜¾ç¤ºå‰10ä¸ªé—®é¢˜
            print(f"  [{issue.level.value}] {issue.description}")

        if len(result.issues) > 10:
            print(f"  ... è¿˜æœ‰ {len(result.issues) - 10} ä¸ªé—®é¢˜")

    if result.recommendations:
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for rec in result.recommendations:
            print(f"  {rec}")

    print("\n" + "="*80)

    return result

if __name__ == "__main__":
    main()