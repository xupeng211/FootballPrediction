# ðŸ¤– é›†æˆæœºå™¨å­¦ä¹ é¢„æµ‹ç®—æ³•æ¨¡åž‹

## é—®é¢˜æè¿°
åŸºäºŽåŽ†å²æ¯”èµ›æ•°æ®å®žçŽ°å®žé™…çš„é¢„æµ‹ç®—æ³•ï¼ŒåŒ…æ‹¬ç»Ÿè®¡æ¨¡åž‹å’Œæœºå™¨å­¦ä¹ æ¨¡åž‹ï¼Œæä¾›å‡†ç¡®çš„æ¯”èµ›ç»“æžœé¢„æµ‹ã€‚

## å½“å‰çŠ¶æ€
- âœ… æœ¬åœ°Dockerè¯•è¿è¥çŽ¯å¢ƒå·²æˆåŠŸéƒ¨ç½²
- âœ… PostgreSQLæ•°æ®åº“é›†æˆå®Œæˆ (ç«¯å£5433)
- âœ… åŸºç¡€çš„é¢„æµ‹CRUDåŠŸèƒ½å·²å®žçŽ°
- âœ… Issue #001: è¶³çƒæ•°æ®APIé›†æˆå·²è§„åˆ’
- âŒ ç¼ºå°‘å®žé™…çš„é¢„æµ‹ç®—æ³•æ¨¡åž‹

## éªŒæ”¶æ ‡å‡†
- [ ] å®žçŽ°åŸºç¡€ç»Ÿè®¡é¢„æµ‹æ¨¡åž‹ (æ³Šæ¾åˆ†å¸ƒã€ELOè¯„åˆ†ç­‰)
- [ ] é›†æˆæœºå™¨å­¦ä¹ æ¨¡åž‹ (éšæœºæ£®æž—ã€XGBoostç­‰)
- [ ] å®žçŽ°æ¨¡åž‹è®­ç»ƒå’Œè¯„ä¼°ç®¡é“
- [ ] æ·»åŠ é¢„æµ‹ç½®ä¿¡åº¦è®¡ç®—
- [ ] é€šè¿‡å›žæµ‹éªŒè¯æ¨¡åž‹å‡†ç¡®æ€§ (ç›®æ ‡å‡†ç¡®çŽ‡ > 55%)

## æŠ€æœ¯æ ˆé€‰æ‹©
- **æœºå™¨å­¦ä¹ æ¡†æž¶**: scikit-learn, XGBoost, LightGBM
- **æ•°æ®å¤„ç†**: pandas, numpy
- **æ¨¡åž‹å­˜å‚¨**: joblib, pickle
- **ç‰¹å¾å·¥ç¨‹**: åŸºäºŽåŽ†å²æ•°æ®çš„ç»Ÿè®¡ç‰¹å¾
- **æ¨¡åž‹è¯„ä¼°**: å‡†ç¡®çŽ‡ã€ç²¾ç¡®çŽ‡ã€å¬å›žçŽ‡ã€AUC

## å®žçŽ°æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µï¼šç‰¹å¾å·¥ç¨‹è®¾è®¡ (2-3å¤©)
1. åˆ†æžåŽ†å²æ¯”èµ›æ•°æ®ç‰¹å¾
2. è®¾è®¡ä»¥ä¸‹ç‰¹å¾ç±»åˆ«ï¼š
   - çƒé˜ŸåŽ†å²è¡¨çŽ°ç‰¹å¾
   - ä¸»å®¢åœºä¼˜åŠ¿ç‰¹å¾
   - è¿‘æœŸçŠ¶æ€ç‰¹å¾
   - å¯¹æˆ˜åŽ†å²ç‰¹å¾
3. å®žçŽ°ç‰¹å¾æå–å’Œè®¡ç®—é€»è¾‘
4. åˆ›å»ºç‰¹å¾å­˜å‚¨å’Œç®¡ç†ç³»ç»Ÿ

### ç¬¬äºŒé˜¶æ®µï¼šç»Ÿè®¡æ¨¡åž‹å®žçŽ° (2-3å¤©)
1. å®žçŽ°æ³Šæ¾åˆ†å¸ƒé¢„æµ‹æ¨¡åž‹
2. å®žçŽ°ELOè¯„åˆ†ç³»ç»Ÿ
3. å®žçŽ°çº¿æ€§å›žå½’æ¨¡åž‹
4. æ·»åŠ æ¨¡åž‹é›†æˆé€»è¾‘
5. åˆ›å»ºæ¨¡åž‹è¯„ä¼°æ¡†æž¶

### ç¬¬ä¸‰é˜¶æ®µï¼šæœºå™¨å­¦ä¹ æ¨¡åž‹å®žçŽ° (3-4å¤©)
1. å®žçŽ°éšæœºæ£®æž—åˆ†ç±»å™¨
2. å®žçŽ°XGBoostæ¢¯åº¦æå‡æ¨¡åž‹
3. å®žçŽ°ç¥žç»ç½‘ç»œæ¨¡åž‹ (å¯é€‰)
4. æ·»åŠ è¶…å‚æ•°è°ƒä¼˜
5. å®žçŽ°æ¨¡åž‹é€‰æ‹©å’Œé›†æˆ

### ç¬¬å››é˜¶æ®µï¼šé¢„æµ‹æœåŠ¡é›†æˆ (2-3å¤©)
1. åˆ›å»ºé¢„æµ‹æœåŠ¡API
2. é›†æˆæ¨¡åž‹é¢„æµ‹ç®¡é“
3. æ·»åŠ é¢„æµ‹ç»“æžœå­˜å‚¨
4. å®žçŽ°é¢„æµ‹ç½®ä¿¡åº¦è®¡ç®—
5. åˆ›å»ºé¢„æµ‹ç»“æžœå±•ç¤ºæŽ¥å£

### ç¬¬äº”é˜¶æ®µï¼šæ¨¡åž‹è¯„ä¼°å’Œä¼˜åŒ– (2-3å¤©)
1. è¿›è¡ŒåŽ†å²æ•°æ®å›žæµ‹
2. åˆ†æžæ¨¡åž‹æ€§èƒ½æŒ‡æ ‡
3. ä¼˜åŒ–æ¨¡åž‹å‚æ•°
4. åˆ›å»ºæ¨¡åž‹ç›‘æŽ§æœºåˆ¶
5. å®žçŽ°æ¨¡åž‹è‡ªåŠ¨æ›´æ–°

## æ–‡ä»¶ç»“æž„è®¡åˆ’
```
src/
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_model.py              # åŸºç¡€æ¨¡åž‹ç±»
â”‚   â”‚   â”œâ”€â”€ poisson_model.py           # æ³Šæ¾åˆ†å¸ƒæ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ elo_model.py               # ELOè¯„åˆ†æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ random_forest_model.py     # éšæœºæ£®æž—æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py           # XGBoostæ¨¡åž‹
â”‚   â”‚   â””â”€â”€ ensemble_model.py          # é›†æˆæ¨¡åž‹
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py       # ç‰¹å¾æå–å™¨
â”‚   â”‚   â”œâ”€â”€ team_features.py           # çƒé˜Ÿç‰¹å¾
â”‚   â”‚   â”œâ”€â”€ match_features.py          # æ¯”èµ›ç‰¹å¾
â”‚   â”‚   â””â”€â”€ historical_features.py     # åŽ†å²ç‰¹å¾
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_preprocessor.py       # æ•°æ®é¢„å¤„ç†
â”‚   â”‚   â”œâ”€â”€ model_trainer.py           # æ¨¡åž‹è®­ç»ƒå™¨
â”‚   â”‚   â””â”€â”€ model_evaluator.py         # æ¨¡åž‹è¯„ä¼°å™¨
â”‚   â”œâ”€â”€ prediction/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prediction_service.py      # é¢„æµ‹æœåŠ¡
â”‚   â”‚   â””â”€â”€ confidence_calculator.py   # ç½®ä¿¡åº¦è®¡ç®—
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ model_utils.py             # æ¨¡åž‹å·¥å…·
â”‚       â””â”€â”€ metrics.py                 # è¯„ä¼°æŒ‡æ ‡
```

## ç‰¹å¾å·¥ç¨‹è¯¦ç»†è®¾è®¡

### çƒé˜ŸåŽ†å²ç‰¹å¾
```python
def extract_team_historical_features(team_id, date, lookback_days=30):
    """
    æå–çƒé˜ŸåŽ†å²ç‰¹å¾
    """
    features = {
        # è¿›æ”»ç‰¹å¾
        'avg_goals_scored': calculate_avg_goals_scored(team_id, lookback_days),
        'avg_shots_on_target': calculate_avg_shots_on_target(team_id, lookback_days),
        'avg_possession': calculate_avg_possession(team_id, lookback_days),

        # é˜²å®ˆç‰¹å¾
        'avg_goals_conceded': calculate_avg_goals_conceded(team_id, lookback_days),
        'avg_clean_sheets': calculate_avg_clean_sheets(team_id, lookback_days),
        'avg_tackles': calculate_avg_tackles(team_id, lookback_days),

        # çŠ¶æ€ç‰¹å¾
        'recent_form': calculate_recent_form(team_id, lookback_days),
        'home_performance': calculate_home_performance(team_id, lookback_days),
        'away_performance': calculate_away_performance(team_id, lookback_days),

        # ä¼¤ç—…æƒ…å†µ
        'key_players_available': calculate_available_key_players(team_id),
        'injury_impact': calculate_injury_impact(team_id)
    }
    return features
```

### æ¯”èµ›ç‰¹å¾
```python
def extract_match_features(home_team_id, away_team_id, match_date):
    """
    æå–æ¯”èµ›ç‰¹å¾
    """
    features = {
        # ä¸»å®¢åœºä¼˜åŠ¿
        'home_advantage': calculate_home_advantage(home_team_id),

        # å¯¹æˆ˜åŽ†å²
        'head_to_head_wins': calculate_head_to_head_wins(home_team_id, away_team_id),
        'head_to_head_goals': calculate_head_to_head_goals(home_team_id, away_team_id),
        'last_meeting_result': get_last_meeting_result(home_team_id, away_team_id),

        # å®žåŠ›å¯¹æ¯”
        'team_strength_diff': calculate_team_strength_diff(home_team_id, away_team_id),
        'form_diff': calculate_form_diff(home_team_id, away_team_id),
        'ranking_diff': calculate_ranking_diff(home_team_id, away_team_id)
    }
    return features
```

## æ¨¡åž‹å®žçŽ°ç¤ºä¾‹

### æ³Šæ¾åˆ†å¸ƒæ¨¡åž‹
```python
import numpy as np
from scipy.stats import poisson
from sklearn.base import BaseEstimator

class PoissonModel(BaseEstimator):
    """
    åŸºäºŽæ³Šæ¾åˆ†å¸ƒçš„è¶³çƒé¢„æµ‹æ¨¡åž‹
    """
    def __init__(self):
        self.home_avg_goals = None
        self.away_avg_goals = None

    def fit(self, X, y):
        """
        è®­ç»ƒæ¨¡åž‹ï¼šè®¡ç®—å¹³å‡è¿›çƒæ•°
        """
        # è¿™é‡Œç®€åŒ–å®žçŽ°ï¼Œå®žé™…åº”è¯¥åŸºäºŽåŽ†å²æ•°æ®è®¡ç®—
        self.home_avg_goals = np.mean(y['home_goals'])
        self.away_avg_goals = np.mean(y['away_goals'])
        return self

    def predict(self, X):
        """
        é¢„æµ‹æ¯”èµ›ç»“æžœ
        """
        predictions = []
        for _, match in X.iterrows():
            # ä½¿ç”¨ç‰¹å¾è°ƒæ•´åŸºç¡€è¿›çƒçŽ‡
            home_exp_goals = self.home_avg_goals * match['home_attack_factor']
            away_exp_goals = self.away_avg_goals * match['away_attack_factor']

            # è®¡ç®—å„ç§ç»“æžœçš„æ¦‚çŽ‡
            prob_home_win = self._calculate_poisson_probability(
                home_exp_goals, away_exp_goals, 'home_win'
            )
            prob_draw = self._calculate_poisson_probability(
                home_exp_goals, away_exp_goals, 'draw'
            )
            prob_away_win = self._calculate_poisson_probability(
                home_exp_goals, away_exp_goals, 'away_win'
            )

            predictions.append({
                'home_win_prob': prob_home_win,
                'draw_prob': prob_draw,
                'away_win_prob': prob_away_win,
                'predicted_outcome': np.argmax([prob_home_win, prob_draw, prob_away_win])
            })

        return predictions

    def _calculate_poisson_probability(self, home_goals, away_goals, outcome):
        """
        åŸºäºŽæ³Šæ¾åˆ†å¸ƒè®¡ç®—ç»“æžœæ¦‚çŽ‡
        """
        max_goals = 10
        total_prob = 0

        for hg in range(max_goals):
            for ag in range(max_goals):
                prob = poisson.pmf(hg, home_goals) * poisson.pmf(ag, away_goals)

                if outcome == 'home_win' and hg > ag:
                    total_prob += prob
                elif outcome == 'draw' and hg == ag:
                    total_prob += prob
                elif outcome == 'away_win' and hg < ag:
                    total_prob += prob

        return total_prob
```

### XGBoostæ¨¡åž‹
```python
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler

class XGBoostModel(BaseEstimator):
    """
    åŸºäºŽXGBoostçš„è¶³çƒé¢„æµ‹æ¨¡åž‹
    """
    def __init__(self, n_estimators=100, max_depth=6, learning_rate=0.1):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.learning_rate = learning_rate
        self.model = None
        self.scaler = StandardScaler()

    def fit(self, X, y):
        """
        è®­ç»ƒXGBoostæ¨¡åž‹
        """
        # æ•°æ®é¢„å¤„ç†
        X_scaled = self.scaler.fit_transform(X)

        # åˆå§‹åŒ–æ¨¡åž‹
        self.model = xgb.XGBClassifier(
            n_estimators=self.n_estimators,
            max_depth=self.max_depth,
            learning_rate=self.learning_rate,
            random_state=42,
            eval_metric='mlogloss'
        )

        # è®­ç»ƒæ¨¡åž‹
        self.model.fit(X_scaled, y)
        return self

    def predict_proba(self, X):
        """
        é¢„æµ‹æ¦‚çŽ‡
        """
        X_scaled = self.scaler.transform(X)
        return self.model.predict_proba(X_scaled)

    def predict(self, X):
        """
        é¢„æµ‹ç»“æžœ
        """
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)

    def get_feature_importance(self):
        """
        èŽ·å–ç‰¹å¾é‡è¦æ€§
        """
        if self.model:
            return self.model.feature_importances_
        return None
```

## æ¨¡åž‹è¯„ä¼°æ¡†æž¶
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

class ModelEvaluator:
    """
    æ¨¡åž‹è¯„ä¼°å™¨
    """
    def __init__(self):
        self.metrics = {}

    def evaluate_model(self, model, X_test, y_test):
        """
        è¯„ä¼°æ¨¡åž‹æ€§èƒ½
        """
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)

        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, average='weighted'),
            'recall': recall_score(y_test, y_pred, average='weighted'),
            'f1_score': f1_score(y_test, y_pred, average='weighted'),
            'roc_auc': roc_auc_score(y_test, y_pred_proba, multi_class='ovr')
        }

        return metrics

    def cross_validate_model(self, model, X, y, cv=5):
        """
        äº¤å‰éªŒè¯
        """
        from sklearn.model_selection import cross_val_score

        scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
        return {
            'mean_score': scores.mean(),
            'std_score': scores.std(),
            'scores': scores.tolist()
        }
```

## æ•°æ®åº“è®¾è®¡
```sql
-- æ¨¡åž‹è¡¨
CREATE TABLE ml_models (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    type VARCHAR(50) NOT NULL,
    version VARCHAR(20) NOT NULL,
    file_path VARCHAR(255),
    parameters JSONB,
    accuracy FLOAT,
    precision_score FLOAT,
    recall_score FLOAT,
    f1_score FLOAT,
    is_active BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç‰¹å¾æ•°æ®è¡¨
CREATE TABLE match_features (
    id SERIAL PRIMARY KEY,
    match_id INTEGER,
    features JSONB NOT NULL,
    feature_version VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (match_id) REFERENCES matches(id)
);

-- é¢„æµ‹ç»“æžœè¡¨
CREATE TABLE predictions (
    id SERIAL PRIMARY KEY,
    match_id INTEGER NOT NULL,
    model_id INTEGER NOT NULL,
    predicted_outcome VARCHAR(20),
    home_win_prob FLOAT,
    draw_prob FLOAT,
    away_win_prob FLOAT,
    confidence FLOAT,
    actual_outcome VARCHAR(20),
    is_correct BOOLEAN,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (match_id) REFERENCES matches(id),
    FOREIGN KEY (model_id) REFERENCES ml_models(id)
);
```

## APIæŽ¥å£è®¾è®¡
```python
from fastapi import APIRouter, Depends, HTTPException
from typing import List, Optional

router = APIRouter(prefix="/ml", tags=["æœºå™¨å­¦ä¹ "])

@router.post("/predict/{match_id}")
async def predict_match(match_id: int, model_name: Optional[str] = None):
    """
    é¢„æµ‹æ¯”èµ›ç»“æžœ
    """
    prediction_service = PredictionService()
    prediction = await prediction_service.predict(match_id, model_name)
    return prediction

@router.get("/models")
async def get_available_models():
    """
    èŽ·å–å¯ç”¨æ¨¡åž‹åˆ—è¡¨
    """
    model_service = ModelService()
    models = await model_service.get_active_models()
    return models

@router.post("/models/{model_id}/train")
async def train_model(model_id: int):
    """
    è®­ç»ƒæ¨¡åž‹
    """
    training_service = ModelTrainingService()
    result = await training_service.train_model(model_id)
    return result
```

## æµ‹è¯•è®¡åˆ’
1. **å•å…ƒæµ‹è¯•**: æµ‹è¯•ç‰¹å¾æå–ã€æ¨¡åž‹è®­ç»ƒã€é¢„æµ‹é€»è¾‘
2. **é›†æˆæµ‹è¯•**: æµ‹è¯•å®Œæ•´çš„é¢„æµ‹æµç¨‹
3. **æ€§èƒ½æµ‹è¯•**: æµ‹è¯•æ¨¡åž‹å“åº”æ—¶é—´å’Œå†…å­˜ä½¿ç”¨
4. **å›žæµ‹éªŒè¯**: ä½¿ç”¨åŽ†å²æ•°æ®éªŒè¯æ¨¡åž‹å‡†ç¡®æ€§

## å®Œæˆæ—¶é—´é¢„ä¼°
- **æ€»æ—¶é—´**: 12-16å¤©
- **å…³é”®è·¯å¾„**: ç‰¹å¾å·¥ç¨‹ â†’ æ¨¡åž‹å®žçŽ° â†’ é¢„æµ‹æœåŠ¡é›†æˆ

## é£Žé™©å’Œç¼“è§£æŽªæ–½
1. **æ•°æ®è´¨é‡**: æ·»åŠ æ•°æ®éªŒè¯å’Œæ¸…æ´—
2. **è¿‡æ‹Ÿåˆ**: ä½¿ç”¨äº¤å‰éªŒè¯å’Œæ­£åˆ™åŒ–
3. **æ¨¡åž‹æ€§èƒ½**: é›†æˆå¤šä¸ªæ¨¡åž‹æé«˜å‡†ç¡®æ€§
4. **è®¡ç®—èµ„æº**: ä¼˜åŒ–æ¨¡åž‹å¤æ‚åº¦å’ŒæŽ¨ç†é€Ÿåº¦

## åŽç»­é›†æˆ
å®ŒæˆåŽå¯ä»¥æŽ¥å…¥ï¼š
- Issue #1: è¶³çƒæ•°æ®APIé›†æˆ (æ•°æ®æº)
- Issue #8: ç³»ç»Ÿç›‘æŽ§å’Œå‘Šè­¦ (æ¨¡åž‹ç›‘æŽ§)
- Issue #13: APIæ–‡æ¡£å®Œå–„ (é¢„æµ‹æŽ¥å£æ–‡æ¡£)

---

**ä¼˜å…ˆçº§**: High
**æ ‡ç­¾**: feature, machine-learning, prediction, core-functionality
**è´Ÿè´£äºº**: å¾…åˆ†é…
**åˆ›å»ºæ—¶é—´**: 2025-10-31
**é¢„è®¡å®Œæˆ**: 2025-11-16