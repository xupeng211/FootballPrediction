#!/usr/bin/env python3
"""
P0-4 ML Pipeline ç›‘æ§éƒ¨ç½²è„šæœ¬
é…ç½®å’Œå¯åŠ¨ç›‘æ§ã€æ—¥å¿—ã€æŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def setup_monitoring_structure():
    """è®¾ç½®ç›‘æ§ç›®å½•ç»“æ„"""
    print("ğŸ”§ è®¾ç½®ç›‘æ§ç›®å½•ç»“æ„...")

    monitoring_dirs = [
        "artifacts/logs",
        "artifacts/metrics",
        "artifacts/models",
        "artifacts/reports",
        "monitoring/dashboards",
        "monitoring/alerts",
        "monitoring/configs"
    ]

    for dir_path in monitoring_dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"  âœ… åˆ›å»ºç›®å½•: {dir_path}")

    print("âœ… ç›‘æ§ç›®å½•ç»“æ„è®¾ç½®å®Œæˆ")

def create_monitoring_config():
    """åˆ›å»ºç›‘æ§é…ç½®æ–‡ä»¶"""
    print("\nâš™ï¸ åˆ›å»ºç›‘æ§é…ç½®æ–‡ä»¶...")

    config = {
        "monitoring": {
            "enabled": True,
            "log_level": "INFO",
            "metrics_retention_days": 30,
            "dashboard_refresh_interval": 60,
            "alert_thresholds": {
                "training_accuracy_min": 0.7,
                "training_time_max": 300,
                "memory_usage_max": 0.8,
                "cpu_usage_max": 0.9
            }
        },
        "logging": {
            "file_rotation": "daily",
            "max_file_size_mb": 100,
            "backup_count": 7,
            "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        },
        "alerts": {
            "email_enabled": False,
            "slack_enabled": False,
            "webhook_url": "",
            "alert_channels": ["email", "slack", "webhook"]
        },
        "dashboard": {
            "title": "P0-4 ML Pipeline ç›‘æ§é¢æ¿",
            "refresh_interval": 30,
            "charts": [
                "training_accuracy_trend",
                "training_time_distribution",
                "algorithm_performance",
                "system_resource_usage"
            ]
        }
    }

    config_file = Path("monitoring/configs/monitoring_config.json")
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)

    print(f"  âœ… ç›‘æ§é…ç½®å·²ä¿å­˜: {config_file}")

def create_prometheus_config():
    """åˆ›å»ºPrometheusé…ç½®"""
    print("\nğŸ“Š åˆ›å»ºPrometheusé…ç½®...")

    prometheus_config = {
        "global": {
            "scrape_interval": "15s",
            "evaluation_interval": "15s"
        },
        "rule_files": [
            "monitoring/configs/alert_rules.yml"
        ],
        "scrape_configs": [
            {
                "job_name": "ml_pipeline",
                "static_configs": [
                    {
                        "targets": ["localhost:8000"],
                        "labels": {
                            "service": "ml_pipeline",
                            "version": "p0-4"
                        }
                    }
                ]
            }
        ],
        "alerting": {
            "alertmanagers": [
                {
                    "static_configs": [
                        {
                            "targets": ["localhost:9093"]
                        }
                    ]
                }
            ]
        }
    }

    prometheus_file = Path("monitoring/configs/prometheus.yml")
    with open(prometheus_file, 'w', encoding='utf-8') as f:
        yaml.dump(prometheus_config, f, default_flow_style=False)

    print(f"  âœ… Prometheusé…ç½®å·²ä¿å­˜: {prometheus_file}")

def create_alert_rules():
    """åˆ›å»ºå‘Šè­¦è§„åˆ™"""
    print("\nğŸš¨ åˆ›å»ºå‘Šè­¦è§„åˆ™...")

    alert_rules = """
groups:
- name: ml_pipeline_alerts
  rules:
  - alert: HighTrainingTime
    expr: training_duration_seconds > 300
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "è®­ç»ƒæ—¶é—´è¿‡é•¿"
      description: "æ¨¡å‹è®­ç»ƒæ—¶é—´è¶…è¿‡5åˆ†é’Ÿ"

  - alert: LowTrainingAccuracy
    expr: training_accuracy < 0.7
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "è®­ç»ƒå‡†ç¡®ç‡è¿‡ä½"
      description: "æ¨¡å‹è®­ç»ƒå‡†ç¡®ç‡ä½äº70%"

  - alert: HighMemoryUsage
    expr: memory_usage_percent > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      description: "ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%"

  - alert: HighCpuUsage
    expr: cpu_usage_percent > 90
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
      description: "ç³»ç»ŸCPUä½¿ç”¨ç‡è¶…è¿‡90%"

  - alert: TrainingFailure
    expr: training_status == "failed"
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "æ¨¡å‹è®­ç»ƒå¤±è´¥"
      description: "æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
"""

    rules_file = Path("monitoring/configs/alert_rules.yml")
    with open(rules_file, 'w', encoding='utf-8') as f:
        f.write(alert_rules)

    print(f"  âœ… å‘Šè­¦è§„åˆ™å·²ä¿å­˜: {rules_file}")

def create_grafana_dashboard():
    """åˆ›å»ºGrafanaä»ªè¡¨æ¿é…ç½®"""
    print("\nğŸ“ˆ åˆ›å»ºGrafanaä»ªè¡¨æ¿é…ç½®...")

    dashboard = {
        "dashboard": {
            "title": "P0-4 ML Pipeline ç›‘æ§é¢æ¿",
            "tags": ["ml", "pipeline", "p0-4"],
            "timezone": "browser",
            "panels": [
                {
                    "title": "è®­ç»ƒå‡†ç¡®ç‡è¶‹åŠ¿",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "training_accuracy",
                            "legendFormat": "{{algorithm}}"
                        }
                    ],
                    "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
                },
                {
                    "title": "è®­ç»ƒæ—¶é—´åˆ†å¸ƒ",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "training_duration_seconds",
                            "legendFormat": "{{algorithm}}"
                        }
                    ],
                    "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
                },
                {
                    "title": "ç®—æ³•æ€§èƒ½æ¯”è¾ƒ",
                    "type": "table",
                    "targets": [
                        {
                            "expr": "algorithm_performance",
                            "format": "table"
                        }
                    ],
                    "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
                },
                {
                    "title": "ç³»ç»Ÿèµ„æºä½¿ç”¨",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "memory_usage_percent",
                            "legendFormat": "å†…å­˜ä½¿ç”¨ç‡"
                        },
                        {
                            "expr": "cpu_usage_percent",
                            "legendFormat": "CPUä½¿ç”¨ç‡"
                        }
                    ],
                    "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16}
                }
            ],
            "time": {"from": "now-1h", "to": "now"},
            "refresh": "30s"
        }
    }

    dashboard_file = Path("monitoring/dashboards/ml_pipeline_dashboard.json")
    with open(dashboard_file, 'w', encoding='utf-8') as f:
        json.dump(dashboard, f, indent=2, ensure_ascii=False)

    print(f"  âœ… Grafanaä»ªè¡¨æ¿å·²ä¿å­˜: {dashboard_file}")

def create_docker_compose_monitoring():
    """åˆ›å»ºç›‘æ§æœåŠ¡çš„Docker Composeé…ç½®"""
    print("\nğŸ³ åˆ›å»ºç›‘æ§Docker Composeé…ç½®...")

    docker_compose = """
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: ml_pipeline_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/configs/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/configs/alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: ml_pipeline_grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/configs:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    container_name: ml_pipeline_alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/configs/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:

networks:
  monitoring:
    driver: bridge
"""

    compose_file = Path("docker-compose.monitoring.yml")
    with open(compose_file, 'w', encoding='utf-8') as f:
        f.write(docker_compose)

    print(f"  âœ… Docker Composeé…ç½®å·²ä¿å­˜: {compose_file}")

def create_startup_script():
    """åˆ›å»ºç›‘æ§æœåŠ¡å¯åŠ¨è„šæœ¬"""
    print("\nğŸš€ åˆ›å»ºå¯åŠ¨è„šæœ¬...")

    startup_script = """#!/bin/bash

# P0-4 ML Pipeline ç›‘æ§æœåŠ¡å¯åŠ¨è„šæœ¬

echo "ğŸš€ å¯åŠ¨P0-4 ML Pipelineç›‘æ§æœåŠ¡..."

# æ£€æŸ¥Dockeræ˜¯å¦è¿è¡Œ
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Dockeræœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨Docker"
    exit 1
fi

# å¯åŠ¨ç›‘æ§æœåŠ¡
echo "ğŸ“Š å¯åŠ¨Prometheus..."
docker-compose -f docker-compose.monitoring.yml up -d prometheus

echo "ğŸ“ˆ å¯åŠ¨Grafana..."
docker-compose -f docker-compose.monitoring.yml up -d grafana

echo "ğŸš¨ å¯åŠ¨AlertManager..."
docker-compose -f docker-compose.monitoring.yml up -d alertmanager

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose -f docker-compose.monitoring.yml ps

# æ˜¾ç¤ºè®¿é—®åœ°å€
echo ""
echo "âœ… ç›‘æ§æœåŠ¡å¯åŠ¨å®Œæˆ!"
echo "ğŸ“Š Prometheus: http://localhost:9090"
echo "ğŸ“ˆ Grafana: http://localhost:3000 (admin/admin123)"
echo "ğŸš¨ AlertManager: http://localhost:9093"
echo ""
echo "ğŸ’¡ ä½¿ç”¨ './stop_monitoring.sh' åœæ­¢ç›‘æ§æœåŠ¡"
"""

    script_file = Path("start_monitoring.sh")
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(startup_script)

    # è®¾ç½®æ‰§è¡Œæƒé™
    script_file.chmod(0o755)

    print(f"  âœ… å¯åŠ¨è„šæœ¬å·²ä¿å­˜: {script_file}")

def create_stop_script():
    """åˆ›å»ºç›‘æ§æœåŠ¡åœæ­¢è„šæœ¬"""
    print("\nğŸ›‘ åˆ›å»ºåœæ­¢è„šæœ¬...")

    stop_script = """#!/bin/bash

# P0-4 ML Pipeline ç›‘æ§æœåŠ¡åœæ­¢è„šæœ¬

echo "ğŸ›‘ åœæ­¢P0-4 ML Pipelineç›‘æ§æœåŠ¡..."

# åœæ­¢ç›‘æ§æœåŠ¡
docker-compose -f docker-compose.monitoring.yml down

echo "âœ… ç›‘æ§æœåŠ¡å·²åœæ­¢"

# å¯é€‰: æ¸…ç†æ•°æ®å·
read -p "æ˜¯å¦æ¸…ç†ç›‘æ§æ•°æ®? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    docker-compose -f docker-compose.monitoring.yml down -v
    echo "ğŸ—‘ï¸ ç›‘æ§æ•°æ®å·²æ¸…ç†"
fi
"""

    script_file = Path("stop_monitoring.sh")
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(stop_script)

    # è®¾ç½®æ‰§è¡Œæƒé™
    script_file.chmod(0o755)

    print(f"  âœ… åœæ­¢è„šæœ¬å·²ä¿å­˜: {script_file}")

def create_health_check_script():
    """åˆ›å»ºå¥åº·æ£€æŸ¥è„šæœ¬"""
    print("\nğŸ¥ åˆ›å»ºå¥åº·æ£€æŸ¥è„šæœ¬...")

    health_check_script = """#!/bin/bash

# P0-4 ML Pipeline ç›‘æ§å¥åº·æ£€æŸ¥è„šæœ¬

echo "ğŸ¥ æ‰§è¡Œç›‘æ§å¥åº·æ£€æŸ¥..."

# æ£€æŸ¥Prometheus
echo "ğŸ“Š æ£€æŸ¥Prometheus..."
if curl -s http://localhost:9090/-/healthy > /dev/null; then
    echo "  âœ… Prometheuså¥åº·"
else
    echo "  âŒ Prometheuså¼‚å¸¸"
fi

# æ£€æŸ¥Grafana
echo "ğŸ“ˆ æ£€æŸ¥Grafana..."
if curl -s http://localhost:3000/api/health > /dev/null; then
    echo "  âœ… Grafanaå¥åº·"
else
    echo "  âŒ Grafanaå¼‚å¸¸"
fi

# æ£€æŸ¥AlertManager
echo "ğŸš¨ æ£€æŸ¥AlertManager..."
if curl -s http://localhost:9093/-/healthy > /dev/null; then
    echo "  âœ… AlertManagerå¥åº·"
else
    echo "  âŒ AlertManagerå¼‚å¸¸"
fi

# æ£€æŸ¥ç£ç›˜ç©ºé—´
echo "ğŸ’¾ æ£€æŸ¥ç£ç›˜ç©ºé—´..."
DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
if [ $DISK_USAGE -lt 80 ]; then
    echo "  âœ… ç£ç›˜ç©ºé—´å……è¶³ (${DISK_USAGE}%)"
else
    echo "  âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³ (${DISK_USAGE}%)"
fi

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
echo "ğŸ§  æ£€æŸ¥å†…å­˜ä½¿ç”¨..."
MEMORY_USAGE=$(free | grep Mem | awk '{printf("%.1f", $3/$2 * 100.0)}')
if (( $(echo "$MEMORY_USAGE < 80" | bc -l) )); then
    echo "  âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸ (${MEMORY_USAGE}%)"
else
    echo "  âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜ (${MEMORY_USAGE}%)"
fi

echo "ğŸ¥ å¥åº·æ£€æŸ¥å®Œæˆ"
"""

    script_file = Path("health_check_monitoring.sh")
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(health_check_script)

    # è®¾ç½®æ‰§è¡Œæƒé™
    script_file.chmod(0o755)

    print(f"  âœ… å¥åº·æ£€æŸ¥è„šæœ¬å·²ä¿å­˜: {script_file}")

def main():
    """ä¸»éƒ¨ç½²å‡½æ•°"""
    print("ğŸš€ P0-4 ML Pipeline ç›‘æ§éƒ¨ç½²")
    print("é…ç½®å’Œå¯åŠ¨ç›‘æ§ã€æ—¥å¿—ã€æŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ")
    print("=" * 60)

    try:
        # è®¾ç½®ç›®å½•ç»“æ„
        setup_monitoring_structure()

        # åˆ›å»ºé…ç½®æ–‡ä»¶
        create_monitoring_config()

        # åˆ›å»ºç›‘æ§é…ç½® (éœ€è¦yamlæ¨¡å—ï¼Œæš‚æ—¶è·³è¿‡)
        print("\nğŸ“Š è·³è¿‡Prometheusé…ç½®åˆ›å»º (éœ€è¦PyYAML)")
        print("ğŸš¨ è·³è¿‡å‘Šè­¦è§„åˆ™åˆ›å»º (éœ€è¦PyYAML)")

        # åˆ›å»ºGrafanaä»ªè¡¨æ¿
        create_grafana_dashboard()

        # åˆ›å»ºDockeré…ç½®
        create_docker_compose_monitoring()

        # åˆ›å»ºè„šæœ¬
        create_startup_script()
        create_stop_script()
        create_health_check_script()

        print("\n" + "=" * 60)
        print("ğŸ‰ ç›‘æ§éƒ¨ç½²å®Œæˆ!")
        print("=" * 60)

        print("\nğŸ“‹ éƒ¨ç½²æ–‡ä»¶:")
        print("  ğŸ“Š ç›‘æ§é…ç½®: monitoring/configs/monitoring_config.json")
        print("  ğŸ“ˆ Grafanaä»ªè¡¨æ¿: monitoring/dashboards/ml_pipeline_dashboard.json")
        print("  ğŸ³ Dockeré…ç½®: docker-compose.monitoring.yml")
        print("  ğŸš€ å¯åŠ¨è„šæœ¬: start_monitoring.sh")
        print("  ğŸ›‘ åœæ­¢è„šæœ¬: stop_monitoring.sh")
        print("  ğŸ¥ å¥åº·æ£€æŸ¥: health_check_monitoring.sh")

        print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")
        print("  1. å¯åŠ¨ç›‘æ§: ./start_monitoring.sh")
        print("  2. è®¿é—®Grafana: http://localhost:3000 (admin/admin123)")
        print("  3. è®¿é—®Prometheus: http://localhost:9090")
        print("  4. å¥åº·æ£€æŸ¥: ./health_check_monitoring.sh")
        print("  5. åœæ­¢ç›‘æ§: ./stop_monitoring.sh")

        print("\nğŸ”§ æ³¨æ„äº‹é¡¹:")
        print("  - éœ€è¦å®‰è£…Dockerå’ŒDocker Compose")
        print("  - éœ€è¦å®‰è£…PyYAMLæ¥åˆ›å»ºå®Œæ•´é…ç½®")
        print("  - ç›‘æ§æ•°æ®å­˜å‚¨åœ¨Dockerå·ä¸­")
        print("  - å»ºè®®å®šæœŸå¤‡ä»½ç›‘æ§æ•°æ®")

        return True

    except Exception as e:
        print(f"\nâŒ ç›‘æ§éƒ¨ç½²å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    import yaml
    success = main()
    sys.exit(0 if success else 1)
