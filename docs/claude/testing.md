# æµ‹è¯•ä½“ç³»è¯¦è§£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»FootballPredictioné¡¹ç›®çš„å®Œæ•´æµ‹è¯•ä½“ç³»ï¼ŒåŒ…æ‹¬47ä¸ªæ ‡å‡†åŒ–æµ‹è¯•æ ‡è®°ã€Smart Testsç­–ç•¥å’Œæµ‹è¯•æœ€ä½³å®è·µã€‚

---

## ğŸ“‹ ç›®å½•

- [ğŸ§ª æµ‹è¯•æ¶æ„æ¦‚è§ˆ](#-æµ‹è¯•æ¶æ„æ¦‚è§ˆ)
- [ğŸ¯ Smart Testsç­–ç•¥](#-smart-testsç­–ç•¥)
- [ğŸ·ï¸ 47ä¸ªæ ‡å‡†åŒ–æµ‹è¯•æ ‡è®°](#ï¸-47ä¸ªæ ‡å‡†åŒ–æµ‹è¯•æ ‡è®°)
- [ğŸ“Š æµ‹è¯•ç±»å‹è¯¦è§£](#-æµ‹è¯•ç±»å‹è¯¦è§£)
- [ğŸ› ï¸ æµ‹è¯•å·¥å…·é“¾](#ï¸-æµ‹è¯•å·¥å…·é“¾)
- [ğŸ“ˆ è¦†ç›–ç‡ç®¡ç†](#-è¦†ç›–ç‡ç®¡ç†)
- [ğŸš€ æµ‹è¯•æ‰§è¡Œç­–ç•¥](#-æµ‹è¯•æ‰§è¡Œç­–ç•¥)
- [ğŸ”§ æµ‹è¯•é…ç½®è¯¦è§£](#-æµ‹è¯•é…ç½®è¯¦è§£)
- [ğŸ› æµ‹è¯•è°ƒè¯•æŠ€å·§](#-æµ‹è¯•è°ƒè¯•æŠ€å·§)
- [ğŸ“ æµ‹è¯•æœ€ä½³å®è·µ](#-æµ‹è¯•æœ€ä½³å®è·µ)

---

## ğŸ§ª æµ‹è¯•æ¶æ„æ¦‚è§ˆ

### æµ‹è¯•ç›®å½•ç»“æ„

```
tests/
â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯• (85%)
â”‚   â”œâ”€â”€ api/                # APIå±‚æµ‹è¯•
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—æµ‹è¯•
â”‚   â”œâ”€â”€ domain/             # é¢†åŸŸé€»è¾‘æµ‹è¯•
â”‚   â”œâ”€â”€ services/           # åº”ç”¨æœåŠ¡æµ‹è¯•
â”‚   â”œâ”€â”€ database/           # æ•°æ®è®¿é—®å±‚æµ‹è¯•
â”‚   â”œâ”€â”€ cache/              # ç¼“å­˜æµ‹è¯•
â”‚   â”œâ”€â”€ utils/              # å·¥å…·ç±»æµ‹è¯•
â”‚   â””â”€â”€ fixtures/           # æµ‹è¯•æ•°æ®
â”œâ”€â”€ integration/             # é›†æˆæµ‹è¯• (12%)
â”‚   â”œâ”€â”€ api/                # APIé›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ database/           # æ•°æ®åº“é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ cache/              # ç¼“å­˜é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ external/           # å¤–éƒ¨æœåŠ¡é›†æˆæµ‹è¯•
â”œâ”€â”€ e2e/                     # ç«¯åˆ°ç«¯æµ‹è¯• (2%)
â”‚   â”œâ”€â”€ api/                # APIç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â””â”€â”€ workflows/          # ä¸šåŠ¡æµç¨‹æµ‹è¯•
â”œâ”€â”€ performance/             # æ€§èƒ½æµ‹è¯• (1%)
â”‚   â”œâ”€â”€ load/               # è´Ÿè½½æµ‹è¯•
â”‚   â”œâ”€â”€ stress/             # å‹åŠ›æµ‹è¯•
â”‚   â””â”€â”€ benchmarks/         # åŸºå‡†æµ‹è¯•
â””â”€â”€ conftest.py              # pytesté…ç½®æ–‡ä»¶
```

### æµ‹è¯•æ¯”ä¾‹å’Œæ‰§è¡Œæ—¶é—´

| æµ‹è¯•ç±»å‹ | æ¯”ä¾‹ | æ‰§è¡Œæ—¶é—´ | å¹¶å‘åº¦ | ä¼˜å…ˆçº§ |
|---------|------|----------|--------|--------|
| å•å…ƒæµ‹è¯• | 85% | <5åˆ†é’Ÿ | é«˜ | ğŸ”¥ critical |
| é›†æˆæµ‹è¯• | 12% | <15åˆ†é’Ÿ | ä¸­ | âš¡ important |
| ç«¯åˆ°ç«¯æµ‹è¯• | 2% | <30åˆ†é’Ÿ | ä½ | ğŸ’¡ optional |
| æ€§èƒ½æµ‹è¯• | 1% | >30åˆ†é’Ÿ | ä¸²è¡Œ | ğŸ¯ special |

---

## ğŸ¯ Smart Testsç­–ç•¥

### æ ¸å¿ƒç†å¿µ

**Smart Tests** æ˜¯ä¸€ä¸ªåŸºäºç¨³å®šæ€§å’Œæ‰§è¡Œæ—¶é—´çš„æ™ºèƒ½æµ‹è¯•ä¼˜åŒ–ç­–ç•¥ï¼Œæ—¨åœ¨ï¼š

1. **æé«˜å¼€å‘æ•ˆç‡** - ä¼˜å…ˆæ‰§è¡Œå¿«é€Ÿç¨³å®šçš„æµ‹è¯•
2. **é™ä½åé¦ˆå»¶è¿Ÿ** - å¿«é€Ÿå‘ç°å’Œä¿®å¤é—®é¢˜
3. **ä¼˜åŒ–CI/CDæµæ°´çº¿** - åˆ†é˜¶æ®µæ‰§è¡Œä¸åŒç±»å‹çš„æµ‹è¯•
4. **ä¿éšœæµ‹è¯•è´¨é‡** - ç¡®ä¿æ ¸å¿ƒåŠŸèƒ½çš„æµ‹è¯•è¦†ç›–ç‡

### ç­–ç•¥é…ç½®ï¼ˆpytest.iniï¼‰

```ini
[tool:pytest]
# Smart Tests é…ç½®
addopts =
    --strict-markers
    --strict-config
    --tb=short
    -ra
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-fail-under=40

# Smart Tests æ ¸å¿ƒæ¨¡å—ï¼ˆå¿«é€Ÿç¨³å®šï¼‰
testpaths =
    tests/unit/utils
    tests/unit/cache
    tests/unit/core

# è‡ªåŠ¨æ’é™¤çš„é—®é¢˜æµ‹è¯•æ–‡ä»¶
norecursedirs =
    tests/unit/services/test_prediction_service.py
    tests/unit/core/test_di.py
    tests/unit/core/test_path_manager_enhanced.py
    tests/unit/scripts/test_create_service_tests.py
```

### Smart Tests æ‰§è¡Œå‘½ä»¤

```bash
# æ ¸å¿ƒç¨³å®šæµ‹è¯•ï¼ˆæ‰§è¡Œæ—¶é—´<2åˆ†é’Ÿï¼Œé€šè¿‡ç‡>90%ï¼‰
make test.smart              # æ™ºèƒ½æµ‹è¯•ç»„åˆ
pytest tests/unit/utils tests/unit/cache tests/unit/core

# å¿«é€ŸéªŒè¯ï¼ˆ<5åˆ†é’Ÿï¼‰
make test.smart-extended     # æ‰©å±•æ™ºèƒ½æµ‹è¯•

# å®Œæ•´éªŒè¯ï¼ˆ<30åˆ†é’Ÿï¼‰
make test.unit              # æ‰€æœ‰å•å…ƒæµ‹è¯•
make test.integration       # é›†æˆæµ‹è¯•
```

### æ ¸å¿ƒç¨³å®šæµ‹è¯•æ¨¡å—

**1. utilsæ¨¡å—** - æœ€ç¨³å®šçš„å·¥å…·ç±»æµ‹è¯•
```bash
tests/unit/utils/
â”œâ”€â”€ test_date_utils.py      # æ—¥æœŸå·¥å…·å‡½æ•°
â”œâ”€â”€ test_string_utils.py    # å­—ç¬¦ä¸²å¤„ç†å·¥å…·
â”œâ”€â”€ test_validation_utils.py # æ•°æ®éªŒè¯å·¥å…·
â”œâ”€â”€ test_formatting_utils.py # æ ¼å¼åŒ–å·¥å…·
â””â”€â”€ test_calculation_utils.py # è®¡ç®—å·¥å…·
```

**2. cacheæ¨¡å—** - ä¾èµ–å°‘ã€æ‰§è¡Œå¿«
```bash
tests/unit/cache/
â”œâ”€â”€ test_decorators.py      # ç¼“å­˜è£…é¥°å™¨
â”œâ”€â”€ test_redis_client.py    # Rediså®¢æˆ·ç«¯
â”œâ”€â”€ test_cache_manager.py   # ç¼“å­˜ç®¡ç†å™¨
â””â”€â”€ test_cache_strategies.py # ç¼“å­˜ç­–ç•¥
```

**3. coreæ¨¡å—** - åŸºç¡€åŠŸèƒ½æµ‹è¯•
```bash
tests/unit/core/
â”œâ”€â”€ test_config.py          # é…ç½®ç®¡ç†
â”œâ”€â”€ test_exceptions.py      # å¼‚å¸¸å¤„ç†
â”œâ”€â”€ test_logger.py          # æ—¥å¿—ç³»ç»Ÿ
â””â”€â”€ test_base_classes.py    # åŸºç¡€ç±»æµ‹è¯•
```

### è‡ªåŠ¨æ’é™¤çš„é—®é¢˜æ–‡ä»¶

**å¤æ‚ä¾èµ–æµ‹è¯•**
- `test_prediction_service.py` - æœåŠ¡å±‚å¤æ‚ä¾èµ–
- `test_di.py` - ä¾èµ–æ³¨å…¥æµ‹è¯•
- `test_path_manager_enhanced.py` - è·¯å¾„ç®¡ç†æµ‹è¯•
- `test_create_service_tests.py` - è„šæœ¬æµ‹è¯•

**æ’é™¤åŸå› **
- ğŸ”§ **ä¾èµ–å¤æ‚** - éœ€è¦å¤§é‡Mockå’Œé…ç½®
- â±ï¸ **æ‰§è¡Œç¼“æ…¢** - å•ä¸ªæµ‹è¯•è€—æ—¶è¿‡é•¿
- ğŸ”„ **ä¸ç¨³å®š** - å¶å‘æ€§å¤±è´¥å½±å“CIç¨³å®šæ€§
- ğŸ—ï¸ **æ¶æ„å˜æ›´** - é¢‘ç¹é‡æ„å¯¼è‡´æµ‹è¯•å¤±æ•ˆ

---

## ğŸ·ï¸ 47ä¸ªæ ‡å‡†åŒ–æµ‹è¯•æ ‡è®°

### æ ¸å¿ƒç±»å‹æ ‡è®°ï¼ˆ8ä¸ªï¼‰

```bash
pytest -m "unit"              # å•å…ƒæµ‹è¯• - å•ä¸ªå‡½æ•°/ç±»æµ‹è¯•
pytest -m "integration"       # é›†æˆæµ‹è¯• - å¤šç»„ä»¶äº¤äº’æµ‹è¯•
pytest -m "e2e"              # ç«¯åˆ°ç«¯æµ‹è¯• - å®Œæ•´ç”¨æˆ·æµç¨‹æµ‹è¯•
pytest -m "performance"       # æ€§èƒ½æµ‹è¯• - åŸºå‡†å’Œæ€§èƒ½åˆ†æ
pytest -m "smoke"            # å†’çƒŸæµ‹è¯• - åŸºç¡€åŠŸèƒ½éªŒè¯
pytest -m "regression"       # å›å½’æµ‹è¯• - é˜²æ­¢åŠŸèƒ½å›é€€
pytest -m "security"         # å®‰å…¨æµ‹è¯• - å®‰å…¨æ¼æ´æ£€æµ‹
pytest -m "compatibility"    # å…¼å®¹æ€§æµ‹è¯• - ç‰ˆæœ¬å…¼å®¹æ€§
```

### æ‰§è¡Œç‰¹å¾æ ‡è®°ï¼ˆ12ä¸ªï¼‰

```bash
# æ—¶é—´ç›¸å…³æ ‡è®°
pytest -m "slow"             # æ…¢é€Ÿæµ‹è¯• (>30s)
pytest -m "fast"             # å¿«é€Ÿæµ‹è¯• (<1s)
pytest -m "medium"           # ä¸­ç­‰é€Ÿåº¦æµ‹è¯• (1s-30s)

# ç¨³å®šæ€§æ ‡è®°
pytest -m "stable"           # ç¨³å®šæµ‹è¯• (é€šè¿‡ç‡>95%)
pytest -m "flaky"            # ä¸ç¨³å®šæµ‹è¯• (å¶å‘æ€§å¤±è´¥)
pytest -m "critical"         # å…³é”®åŠŸèƒ½æµ‹è¯• (å¿…é¡»é€šè¿‡)
pytest -m "optional"         # å¯é€‰æµ‹è¯• (å…è®¸å¤±è´¥)

# æ‰§è¡Œç¯å¢ƒæ ‡è®°
pytest -m "local"            # ä»…æœ¬åœ°ç¯å¢ƒæ‰§è¡Œ
pytest -m "ci"               # ä»…CIç¯å¢ƒæ‰§è¡Œ
pytest -m "production"       # ç”Ÿäº§ç¯å¢ƒæµ‹è¯•
pytest -m "debug"            # è°ƒè¯•æµ‹è¯•
```

### åŠŸèƒ½åŸŸæ ‡è®°ï¼ˆ15ä¸ªï¼‰

```bash
# ä¸šåŠ¡åŠŸèƒ½æ ‡è®°
pytest -m "api"              # APIæ¥å£æµ‹è¯•
pytest -m "domain"           # é¢†åŸŸé€»è¾‘æµ‹è¯•
pytest -m "services"         # åº”ç”¨æœåŠ¡æµ‹è¯•
pytest -m "database"         # æ•°æ®åº“ç›¸å…³æµ‹è¯•
pytest -m "cache"            # ç¼“å­˜ç›¸å…³æµ‹è¯•
pytest -m "ml"               # æœºå™¨å­¦ä¹ æ¨¡å—æµ‹è¯•
pytest -m "utils"            # å·¥å…·ç±»æµ‹è¯•
pytest -m "decorators"       # è£…é¥°å™¨æµ‹è¯•
pytest -m "config"           # é…ç½®ç›¸å…³æµ‹è¯•
pytest -m "di"               # ä¾èµ–æ³¨å…¥æµ‹è¯•
pytest -m "cqrs"             # CQRSæ¨¡å¼æµ‹è¯•
pytest -m "events"           # äº‹ä»¶ç³»ç»Ÿæµ‹è¯•
pytest -m "strategies"       # ç­–ç•¥æ¨¡å¼æµ‹è¯•
pytest -m "adapters"         # é€‚é…å™¨æ¨¡å¼æµ‹è¯•
pytest -m "monitoring"       # ç›‘æ§ç›¸å…³æµ‹è¯•
```

### ä¾èµ–ç¯å¢ƒæ ‡è®°ï¼ˆ8ä¸ªï¼‰

```bash
pytest -m "docker"           # éœ€è¦Dockerç¯å¢ƒ
pytest -m "network"          # éœ€è¦ç½‘ç»œè¿æ¥
pytest -m "external_api"     # éœ€è¦å¤–éƒ¨APIè°ƒç”¨
pytest -m "database"         # éœ€è¦æ•°æ®åº“è¿æ¥
pytest -m "redis"            # éœ€è¦Redisè¿æ¥
pytest -m "filesystem"       # éœ€è¦æ–‡ä»¶ç³»ç»Ÿè®¿é—®
pytest -m "memory"           # éœ€è¦å¤§é‡å†…å­˜
pytest -m "gpu"              # éœ€è¦GPUæ”¯æŒ
```

### æ•°æ®çŠ¶æ€æ ‡è®°ï¼ˆ4ä¸ªï¼‰

```bash
pytest -m "requires_data"    # éœ€è¦æµ‹è¯•æ•°æ®
pytest -m "generates_data"   # ç”Ÿæˆæµ‹è¯•æ•°æ®
pytest -m "cleanup_required" # éœ€è¦æ¸…ç†æ•°æ®
pytest -m "stateful"         # çŠ¶æ€ç›¸å…³æµ‹è¯•
```

### ä½¿ç”¨ç¤ºä¾‹

```bash
# å¤åˆæ ‡è®°æŸ¥è¯¢
pytest -m "unit and api and critical"          # APIå…³é”®åŠŸèƒ½å•å…ƒæµ‹è¯•
pytest -m "integration and database"           # æ•°æ®åº“é›†æˆæµ‹è¯•
pytest -m "slow or external_api"               # æ…¢é€Ÿæˆ–å¤–éƒ¨APIæµ‹è¯•
pytest -m "unit and not slow and stable"      # ç¨³å®šå¿«é€Ÿå•å…ƒæµ‹è¯•

# æ’é™¤ç‰¹å®šæ ‡è®°
pytest -m "unit and not slow"                  # æ’é™¤æ…¢é€Ÿæµ‹è¯•
pytest -m "not docker and not network"         # æ’é™¤ä¾èµ–å¤–éƒ¨æœåŠ¡çš„æµ‹è¯•
```

---

## ğŸ“Š æµ‹è¯•ç±»å‹è¯¦è§£

### å•å…ƒæµ‹è¯•ï¼ˆUnit Tests - 85%ï¼‰

**å®šä¹‰**ï¼šæµ‹è¯•å•ä¸ªå‡½æ•°ã€æ–¹æ³•æˆ–ç±»çš„åŠŸèƒ½

**ç‰¹ç‚¹**ï¼š
- âš¡ æ‰§è¡Œå¿«é€Ÿï¼ˆ<1ç§’ï¼‰
- ğŸ”§ ä¾èµ–éš”ç¦»ï¼ˆä½¿ç”¨Mockï¼‰
- ğŸ¯ èŒè´£å•ä¸€
- ğŸ“ˆ è¦†ç›–ç‡é©±åŠ¨

**ç¤ºä¾‹**ï¼š
```python
# tests/unit/utils/test_date_utils.py
import pytest
from src.utils.date_utils import DateUtils

class TestDateUtils:
    def test_format_date_success(self):
        """æµ‹è¯•æ—¥æœŸæ ¼å¼åŒ–æˆåŠŸåœºæ™¯"""
        date_str = "2023-12-25"
        result = DateUtils.format_date(date_str, "%Y-%m-%d")
        assert result == "2023-12-25"

    def test_format_date_invalid_input(self):
        """æµ‹è¯•æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥åœºæ™¯"""
        with pytest.raises(ValueError):
            DateUtils.format_date("invalid-date", "%Y-%m-%d")

    @pytest.mark.parametrize("date_str,expected", [
        ("2023-01-01", "2023-01-01"),
        ("2023/01/01", "2023-01-01"),
        ("01-01-2023", "2023-01-01"),
    ])
    def test_parse_date_various_formats(self, date_str, expected):
        """å‚æ•°åŒ–æµ‹è¯•å¤šç§æ—¥æœŸæ ¼å¼"""
        result = DateUtils.parse_date(date_str)
        assert result.strftime("%Y-%m-%d") == expected
```

### é›†æˆæµ‹è¯•ï¼ˆIntegration Tests - 12%ï¼‰

**å®šä¹‰**ï¼šæµ‹è¯•å¤šä¸ªç»„ä»¶ä¹‹é—´çš„äº¤äº’

**ç‰¹ç‚¹**ï¼š
- ğŸ”— ç»„ä»¶äº¤äº’æµ‹è¯•
- ğŸŒ çœŸå®ç¯å¢ƒé…ç½®
- ğŸ“Š ç«¯åˆ°ç«¯æ•°æ®æµ
- â±ï¸ æ‰§è¡Œæ—¶é—´ä¸­ç­‰ï¼ˆ1-30ç§’ï¼‰

**ç¤ºä¾‹**ï¼š
```python
# tests/integration/database/test_prediction_repository.py
import pytest
from src.database.repositories.prediction_repository import PredictionRepository
from src.database.adapters.postgresql_adapter import PostgreSQLAdapter

@pytest.mark.integration
@pytest.mark.database
class TestPredictionRepositoryIntegration:
    @pytest.fixture
    async def repository(self):
        """è®¾ç½®é›†æˆæµ‹è¯•ç¯å¢ƒ"""
        adapter = PostgreSQLAdapter("postgresql://test:test@localhost/test_db")
        await adapter.connect()
        return PredictionRepository(adapter)

    async def test_create_and_retrieve_prediction(self, repository):
        """æµ‹è¯•åˆ›å»ºå’Œè·å–é¢„æµ‹"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        prediction = Prediction(
            id="test-pred-123",
            match_id="test-match-456",
            strategy_type="ml_model",
            prediction_data={"home_win": 0.6, "draw": 0.3, "away_win": 0.1}
        )

        # æµ‹è¯•åˆ›å»º
        created = await repository.create(prediction)
        assert created.id == prediction.id

        # æµ‹è¯•è·å–
        retrieved = await repository.get_by_id(prediction.id)
        assert retrieved.id == prediction.id
        assert retrieved.prediction_data == prediction.prediction_data
```

### ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆE2E Tests - 2%ï¼‰

**å®šä¹‰**ï¼šæµ‹è¯•å®Œæ•´çš„ç”¨æˆ·åœºæ™¯å’Œä¸šåŠ¡æµç¨‹

**ç‰¹ç‚¹**ï¼š
- ğŸ­ çœŸå®ç”¨æˆ·åœºæ™¯
- ğŸŒ å®Œæ•´ç³»ç»Ÿæµ‹è¯•
- â±ï¸ æ‰§è¡Œæ—¶é—´é•¿ï¼ˆ>30ç§’ï¼‰
- ğŸ’¡ ä¸šåŠ¡ä»·å€¼é©±åŠ¨

**ç¤ºä¾‹**ï¼š
```python
# tests/e2e/api/test_prediction_workflow.py
import pytest
from httpx import AsyncClient
from src.main import app

@pytest.mark.e2e
@pytest.mark.api
class TestPredictionWorkflowE2E:
    async def test_complete_prediction_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„é¢„æµ‹å·¥ä½œæµ"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            # 1. è·å–æ¯”èµ›åˆ—è¡¨
            response = await client.get("/api/matches")
            assert response.status_code == 200
            matches = response.json()
            assert len(matches) > 0

            # 2. é€‰æ‹©æ¯”èµ›åˆ›å»ºé¢„æµ‹
            match_id = matches[0]["id"]
            prediction_request = {
                "match_id": match_id,
                "strategy_type": "ml_model"
            }

            response = await client.post("/api/predictions", json=prediction_request)
            assert response.status_code == 201
            prediction = response.json()
            assert prediction["match_id"] == match_id

            # 3. è·å–é¢„æµ‹ç»“æœ
            prediction_id = prediction["id"]
            response = await client.get(f"/api/predictions/{prediction_id}")
            assert response.status_code == 200
            result = response.json()
            assert "prediction_data" in result
```

### æ€§èƒ½æµ‹è¯•ï¼ˆPerformance Tests - 1%ï¼‰

**å®šä¹‰**ï¼šæµ‹è¯•ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡

**ç‰¹ç‚¹**ï¼š
- âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•
- ğŸ“Š è´Ÿè½½å’Œå‹åŠ›æµ‹è¯•
- ğŸ“ˆ æ€§èƒ½ç›‘æ§
- ğŸ” æ€§èƒ½å›å½’æ£€æµ‹

**ç¤ºä¾‹**ï¼š
```python
# tests/performance/load/test_prediction_api.py
import pytest
import asyncio
import time
from httpx import AsyncClient

@pytest.mark.performance
@pytest.mark.load
class TestPredictionAPILoad:
    async def test_concurrent_prediction_requests(self):
        """æµ‹è¯•å¹¶å‘é¢„æµ‹è¯·æ±‚æ€§èƒ½"""
        async def make_request(client):
            start_time = time.time()
            response = await client.post(
                "/api/predictions",
                json={
                    "match_id": "test-match",
                    "strategy_type": "ml_model"
                }
            )
            end_time = time.time()
            return {
                "status": response.status_code,
                "response_time": end_time - start_time
            }

        async with AsyncClient(app=app, base_url="http://test") as client:
            # å¹¶å‘æ‰§è¡Œ100ä¸ªè¯·æ±‚
            tasks = [make_request(client) for _ in range(100)]
            results = await asyncio.gather(*tasks)

            # æ€§èƒ½æ–­è¨€
            successful_requests = [r for r in results if r["status"] == 200]
            avg_response_time = sum(r["response_time"] for r in successful_requests) / len(successful_requests)

            assert len(successful_requests) >= 95  # 95%æˆåŠŸç‡
            assert avg_response_time < 1.0         # å¹³å‡å“åº”æ—¶é—´<1ç§’
```

---

## ğŸ› ï¸ æµ‹è¯•å·¥å…·é“¾

### æ ¸å¿ƒæµ‹è¯•æ¡†æ¶

**pytest** - ä¸»è¦æµ‹è¯•æ¡†æ¶
```bash
# å®‰è£…
pip install pytest pytest-asyncio pytest-cov pytest-mock

# åŸºæœ¬ä½¿ç”¨
pytest                           # è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest -v                        # è¯¦ç»†è¾“å‡º
pytest -x                        # é¦–æ¬¡å¤±è´¥ååœæ­¢
pytest --maxfail=5              # æœ€å¤šå…è®¸5ä¸ªå¤±è´¥
pytest -k "test_prediction"      # è¿è¡Œåç§°åŒ¹é…çš„æµ‹è¯•
```

**pytest-asyncio** - å¼‚æ­¥æµ‹è¯•æ”¯æŒ
```python
import pytest
import asyncio

@pytest.mark.asyncio
async def test_async_prediction_service():
    service = PredictionService()
    prediction = await service.create_prediction(match_data)
    assert prediction is not None
```

**pytest-mock** - Mockå’ŒPatchæ”¯æŒ
```python
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_prediction_service_with_mock():
    with patch('src.services.prediction_service.PredictionStrategy') as mock_strategy:
        mock_strategy.predict.return_value = {"home_win": 0.7}

        service = PredictionService()
        result = await service.make_prediction(match_data)

        assert result["home_win"] == 0.7
        mock_strategy.predict.assert_called_once_with(match_data)
```

### è¦†ç›–ç‡å·¥å…·

**pytest-cov** - è¦†ç›–ç‡æµ‹é‡
```bash
# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src --cov-report=term-missing
pytest --cov=src --cov-report=html:htmlcov

# è¦†ç›–ç‡é…ç½®
# pytest.ini
[tool:pytest]
addopts = --cov=src --cov-fail-under=40
```

**Coverage.py** - è¦†ç›–ç‡åˆ†æ
```bash
# è¯¦ç»†è¦†ç›–ç‡åˆ†æ
coverage run -m pytest
coverage report -m                    # æ˜¾ç¤ºæœªè¦†ç›–è¡Œ
coverage html                         # ç”ŸæˆHTMLæŠ¥å‘Š
coverage xml                          # ç”ŸæˆXMLæŠ¥å‘Šï¼ˆCIé›†æˆï¼‰
```

### Mockå·¥å…·

**unittest.mock** - Pythonæ ‡å‡†Mockåº“
```python
from unittest.mock import Mock, patch, AsyncMock

# Mockå¯¹è±¡
mock_service = Mock()
mock_service.get_prediction.return_value = {"id": "123"}

# å¼‚æ­¥Mock
async_mock = AsyncMock()
async_mock.create_prediction.return_value = prediction

# Patchè£…é¥°å™¨
@patch('src.repositories.prediction_repository.PredictionRepository')
async def test_with_patch(mock_repo_class):
    mock_repo = mock_repo_class.return_value
    mock_repo.create.return_value = prediction

    service = PredictionService(mock_repo)
    result = await service.create_prediction(data)

    mock_repo.create.assert_called_once_with(data)
```

**responses** - HTTPè¯·æ±‚Mock
```python
import responses
import requests

@responses.activate
def test_api_call():
    responses.add(
        responses.GET,
        "https://api.football-data.org/matches",
        json={"matches": []},
        status=200
    )

    response = requests.get("https://api.football-data.org/matches")
    assert response.json() == {"matches": []}
```

### æµ‹è¯•æ•°æ®ç®¡ç†

**factory-boy** - æµ‹è¯•æ•°æ®å·¥å‚
```python
import factory
from src.domain.entities import Match, Team

class TeamFactory(factory.Factory):
    class Meta:
        model = Team

    id = factory.Faker('uuid4')
    name = factory.Faker('company')

class MatchFactory(factory.Factory):
    class Meta:
        model = Match

    id = factory.Faker('uuid4')
    home_team = factory.SubFactory(TeamFactory)
    away_team = factory.SubFactory(TeamFactory)
    match_date = factory.Faker('date_time')

# ä½¿ç”¨ç¤ºä¾‹
def test_with_factory():
    match = MatchFactory()
    assert match.home_team.name is not None
```

**pytest fixtures** - æµ‹è¯•æ•°æ®å’Œè®¾ç½®
```python
@pytest.fixture
def sample_match():
    """æä¾›ç¤ºä¾‹æ¯”èµ›æ•°æ®"""
    return Match(
        id="test-match-123",
        home_team=Team(id="team-1", name="Team A"),
        away_team=Team(id="team-2", name="Team B"),
        match_date=datetime.now()
    )

@pytest.fixture
async def prediction_service():
    """æä¾›é¢„æµ‹æœåŠ¡å®ä¾‹"""
    return PredictionService()

def test_with_fixtures(sample_match, prediction_service):
    prediction = prediction_service.create_prediction(sample_match)
    assert prediction.match_id == sample_match.id
```

---

## ğŸ“ˆ è¦†ç›–ç‡ç®¡ç†

### è¦†ç›–ç‡ç›®æ ‡ç­–ç•¥

**æ¸è¿›å¼è¦†ç›–ç‡æå‡**
```bash
# å½“å‰çŠ¶æ€ï¼š29% â†’ ç›®æ ‡çŠ¶æ€ï¼š40%
# é˜¶æ®µ1ï¼šè¾¾åˆ°30%ï¼ˆSmart Testsæ ¸å¿ƒæ¨¡å—ï¼‰
# é˜¶æ®µ2ï¼šè¾¾åˆ°35%ï¼ˆæ‰©å±•åˆ°ä¸»è¦ä¸šåŠ¡é€»è¾‘ï¼‰
# é˜¶æ®µ3ï¼šè¾¾åˆ°40%ï¼ˆå…¨é¢è¦†ç›–ï¼‰
```

### è¦†ç›–ç‡é…ç½®è¯¦è§£

**pytest.ini é…ç½®**
```ini
[tool:pytest]
# è¦†ç›–ç‡é…ç½®
addopts = --cov=src --cov-report=term-missing --cov-report=html:htmlcov

# è¦†ç›–ç‡é˜ˆå€¼
--cov-fail-under=40

# åŒ…å«çš„æºç ç›®å½•
--cov-branch

# å¿½ç•¥çš„æ–‡ä»¶
--cov-ignore-errors

# è¦†ç›–ç‡æŠ¥å‘Šæ ¼å¼
--cov-report=term-missing:skip-covered
--cov-report=html:htmlcov
--cov-report=xml
```

### è¦†ç›–ç‡åˆ†æå‘½ä»¤

**åŸºç¡€è¦†ç›–ç‡æŠ¥å‘Š**
```bash
make coverage                # ç”ŸæˆåŸºç¡€è¦†ç›–ç‡æŠ¥å‘Š
make coverage-unit          # å•å…ƒæµ‹è¯•è¦†ç›–ç‡
make coverage-integration   # é›†æˆæµ‹è¯•è¦†ç›–ç‡
make cov.html               # HTMLè¯¦ç»†æŠ¥å‘Š
```

**å¢å¼ºè¦†ç›–ç‡åˆ†æ**
```bash
make test-enhanced-coverage    # å¢å¼ºè¦†ç›–ç‡åˆ†æ
make test-coverage-monitor     # è¦†ç›–ç‡è¶‹åŠ¿ç›‘æ§
make cov.enforce              # å¼ºåˆ¶æ‰§è¡Œè¦†ç›–ç‡é˜ˆå€¼
```

### è¦†ç›–ç‡ä¼˜åŒ–ç­–ç•¥

**1. æ™ºèƒ½è¦†ç›–ç‡æŠ¥å‘Š**
```bash
# æŒ‰æ¨¡å—åˆ†æè¦†ç›–ç‡
pytest --cov=src.domain --cov-report=term-missing
pytest --cov=src.api --cov-report=term-missing

# æŒ‰æ–‡ä»¶åˆ†æè¦†ç›–ç‡
pytest --cov=src/utils/date_utils.py --cov-report=term-missing
```

**2. è¦†ç›–ç‡è¶‹åŠ¿ç›‘æ§**
```bash
# ç”Ÿæˆè¦†ç›–ç‡è¶‹åŠ¿æŠ¥å‘Š
python3 scripts/coverage_trend_analyzer.py

# è®¾ç½®è¦†ç›–ç‡ç›‘æ§
make test-coverage-monitor
```

**3. è¦†ç›–ç‡é—¨æ§›æ‰§è¡Œ**
```bash
# ä¸¥æ ¼æ‰§è¡Œè¦†ç›–ç‡é˜ˆå€¼
make cov.enforce

# æ¸è¿›å¼æå‡è¦†ç›–ç‡
make improve-coverage
```

---

## ğŸš€ æµ‹è¯•æ‰§è¡Œç­–ç•¥

### å¼€å‘é˜¶æ®µæµ‹è¯•

**å¿«é€Ÿåé¦ˆå¾ªç¯ï¼ˆ<2åˆ†é’Ÿï¼‰**
```bash
# Smart Tests - æ ¸å¿ƒç¨³å®šæµ‹è¯•
make test.smart

# å¢é‡æµ‹è¯• - ä»…è¿è¡Œå˜æ›´ç›¸å…³æµ‹è¯•
pytest --testmon               # åŸºäºä»£ç å˜æ›´è¿è¡Œæµ‹è¯•

# æœ€å°éªŒè¯ - å…³é”®åŠŸèƒ½æµ‹è¯•
pytest -m "critical and unit and fast"
```

**åŠŸèƒ½éªŒè¯ï¼ˆ<5åˆ†é’Ÿï¼‰**
```bash
# æ‰©å±•æ™ºèƒ½æµ‹è¯•
make test.smart-extended

# APIæ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
pytest -m "api and critical"

# ä¸šåŠ¡é€»è¾‘æµ‹è¯•
pytest -m "domain or services"
```

### ä»£ç æäº¤å‰æµ‹è¯•

**å®Œæ•´éªŒè¯ï¼ˆ<15åˆ†é’Ÿï¼‰**
```bash
# å®Œæ•´å•å…ƒæµ‹è¯•
make test.unit

# ä»£ç è´¨é‡æ£€æŸ¥
make check-quality

# è¦†ç›–ç‡éªŒè¯
make coverage

# å®Œæ•´CIæ¨¡æ‹Ÿ
make prepush
```

### CI/CDæµæ°´çº¿æµ‹è¯•

**å¹¶è¡Œæ‰§è¡Œç­–ç•¥**
```yaml
# .github/workflows/test.yml
jobs:
  test-unit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run unit tests
        run: make test.unit

  test-integration:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
    steps:
      - uses: actions/checkout@v3
      - name: Run integration tests
        run: make test.integration

  test-coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Generate coverage report
        run: make coverage
      - name: Upload to codecov
        uses: codecov/codecov-action@v3
```

### æ€§èƒ½æµ‹è¯•ç­–ç•¥

**å®šæœŸæ€§èƒ½æµ‹è¯•**
```bash
# æ¯æ—¥æ€§èƒ½åŸºå‡†æµ‹è¯•
make test-performance-daily

# æ€§èƒ½å›å½’æ£€æµ‹
make test-performance-regression

# è´Ÿè½½æµ‹è¯•
make test-load
```

---

## ğŸ”§ æµ‹è¯•é…ç½®è¯¦è§£

### pytest.ini å®Œæ•´é…ç½®

```ini
[tool:pytest]
# åŸºç¡€é…ç½®
minversion = 6.0
addopts =
    --strict-markers
    --strict-config
    --tb=short
    -ra
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-fail-under=40
    --import-mode=importlib

# æµ‹è¯•ç›®å½•
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# æ ‡è®°å®šä¹‰
markers =
    # æµ‹è¯•ç±»å‹æ ‡è®°
    unit: å•å…ƒæµ‹è¯•
    integration: é›†æˆæµ‹è¯•
    e2e: ç«¯åˆ°ç«¯æµ‹è¯•
    performance: æ€§èƒ½æµ‹è¯•
    smoke: å†’çƒŸæµ‹è¯•
    regression: å›å½’æµ‹è¯•
    security: å®‰å…¨æµ‹è¯•
    compatibility: å…¼å®¹æ€§æµ‹è¯•

    # æ‰§è¡Œç‰¹å¾æ ‡è®°
    slow: æ…¢é€Ÿæµ‹è¯• (>30s)
    fast: å¿«é€Ÿæµ‹è¯• (<1s)
    medium: ä¸­ç­‰é€Ÿåº¦æµ‹è¯• (1s-30s)
    stable: ç¨³å®šæµ‹è¯• (é€šè¿‡ç‡>95%)
    flaky: ä¸ç¨³å®šæµ‹è¯• (å¶å‘æ€§å¤±è´¥)
    critical: å…³é”®åŠŸèƒ½æµ‹è¯• (å¿…é¡»é€šè¿‡)
    optional: å¯é€‰æµ‹è¯• (å…è®¸å¤±è´¥)
    local: ä»…æœ¬åœ°ç¯å¢ƒæ‰§è¡Œ
    ci: ä»…CIç¯å¢ƒæ‰§è¡Œ
    production: ç”Ÿäº§ç¯å¢ƒæµ‹è¯•
    debug: è°ƒè¯•æµ‹è¯•

    # åŠŸèƒ½åŸŸæ ‡è®°
    api: APIæ¥å£æµ‹è¯•
    domain: é¢†åŸŸé€»è¾‘æµ‹è¯•
    services: åº”ç”¨æœåŠ¡æµ‹è¯•
    database: æ•°æ®åº“ç›¸å…³æµ‹è¯•
    cache: ç¼“å­˜ç›¸å…³æµ‹è¯•
    ml: æœºå™¨å­¦ä¹ æ¨¡å—æµ‹è¯•
    utils: å·¥å…·ç±»æµ‹è¯•
    decorators: è£…é¥°å™¨æµ‹è¯•
    config: é…ç½®ç›¸å…³æµ‹è¯•
    di: ä¾èµ–æ³¨å…¥æµ‹è¯•
    cqrs: CQRSæ¨¡å¼æµ‹è¯•
    events: äº‹ä»¶ç³»ç»Ÿæµ‹è¯•
    strategies: ç­–ç•¥æ¨¡å¼æµ‹è¯•
    adapters: é€‚é…å™¨æ¨¡å¼æµ‹è¯•
    monitoring: ç›‘æ§ç›¸å…³æµ‹è¯•

    # ä¾èµ–ç¯å¢ƒæ ‡è®°
    docker: éœ€è¦Dockerç¯å¢ƒ
    network: éœ€è¦ç½‘ç»œè¿æ¥
    external_api: éœ€è¦å¤–éƒ¨APIè°ƒç”¨
    filesystem: éœ€è¦æ–‡ä»¶ç³»ç»Ÿè®¿é—®
    memory: éœ€è¦å¤§é‡å†…å­˜
    gpu: éœ€è¦GPUæ”¯æŒ

    # æ•°æ®çŠ¶æ€æ ‡è®°
    requires_data: éœ€è¦æµ‹è¯•æ•°æ®
    generates_data: ç”Ÿæˆæµ‹è¯•æ•°æ®
    cleanup_required: éœ€è¦æ¸…ç†æ•°æ®
    stateful: çŠ¶æ€ç›¸å…³æµ‹è¯•

# å¼‚æ­¥æµ‹è¯•é…ç½®
asyncio_mode = auto

# æ—¥å¿—é…ç½®
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s

# è¿‡æ»¤è­¦å‘Š
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
```

### conftest.py é…ç½®

```python
# tests/conftest.py
import pytest
import asyncio
from unittest.mock import AsyncMock
from src.database.adapters.postgresql_adapter import PostgreSQLAdapter
from src.cache.redis_client import RedisClient

@pytest.fixture(scope="session")
def event_loop():
    """åˆ›å»ºäº‹ä»¶å¾ªç¯"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
async def test_database():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    adapter = PostgreSQLAdapter("postgresql://test:test@localhost/test_db")
    await adapter.connect()
    yield adapter
    await adapter.disconnect()

@pytest.fixture
async def test_redis():
    """æµ‹è¯•Redisè¿æ¥"""
    redis_client = RedisClient("redis://localhost:6379/1")
    await redis_client.connect()
    yield redis_client
    await redis_client.disconnect()

@pytest.fixture
def mock_prediction_service():
    """Mocké¢„æµ‹æœåŠ¡"""
    return AsyncMock()

@pytest.fixture
def sample_prediction_data():
    """ç¤ºä¾‹é¢„æµ‹æ•°æ®"""
    return {
        "match_id": "test-match-123",
        "strategy_type": "ml_model",
        "prediction_data": {
            "home_win": 0.6,
            "draw": 0.3,
            "away_win": 0.1
        }
    }
```

---

## ğŸ› æµ‹è¯•è°ƒè¯•æŠ€å·§

### è°ƒè¯•å‘½ä»¤

**è¯¦ç»†è°ƒè¯•è¾“å‡º**
```bash
# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest -v -s

# æ˜¾ç¤ºæœ€é•¿10ä¸ªå¤±è´¥æµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯
pytest --tb=long --maxfail=10

# è¿›å…¥è°ƒè¯•å™¨
pytest --pdb

# ä»…åœ¨å¤±è´¥æ—¶è¿›å…¥è°ƒè¯•å™¨
pytest --pdb -x
```

**é€‰æ‹©æ€§æµ‹è¯•æ‰§è¡Œ**
```bash
# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/unit/api/test_predictions.py

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
pytest tests/unit/api/test_predictions.py::test_create_prediction

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»
pytest tests/unit/api/test_predictions.py::TestPredictionAPI

# åŸºäºåç§°æ¨¡å¼è¿è¡Œæµ‹è¯•
pytest -k "prediction"
```

### è°ƒè¯•æŠ€å·§

**1. ä½¿ç”¨printè°ƒè¯•**
```python
def test_complex_logic():
    data = get_complex_data()
    print(f"Debug: data = {data}")  # æ·»åŠ è°ƒè¯•è¾“å‡º
    result = process_data(data)
    print(f"Debug: result = {result}")
    assert result["status"] == "success"
```

**2. ä½¿ç”¨pytest hooks**
```python
# conftest.py
@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):
    """åœ¨æµ‹è¯•å¤±è´¥æ—¶æ‰§è¡Œé¢å¤–è°ƒè¯•"""
    outcome = yield
    rep = outcome.get_result()
    if rep.when == "call" and rep.failed:
        # æ‰§è¡Œè°ƒè¯•é€»è¾‘
        print(f"Test failed: {item.name}")
        print(f"Error: {rep.longrepr}")
```

**3. æ¡ä»¶æ–­ç‚¹**
```python
def test_with_conditional_breakpoint():
    for i, data in enumerate(test_data):
        result = process_data(data)
        if i == 42:  # åœ¨ç¬¬43æ¬¡è¿­ä»£æ—¶ä¸­æ–­
            import pdb; pdb.set_trace()
        assert result is not None
```

### å¸¸è§é—®é¢˜è§£å†³

**1. å¼‚æ­¥æµ‹è¯•é—®é¢˜**
```python
# é—®é¢˜ï¼šå¼‚æ­¥å‡½æ•°æœªæ­£ç¡®æ‰§è¡Œ
@pytest.mark.asyncio
async def test_async_function():
    result = await async_function()  # ç¡®ä¿ä½¿ç”¨await
    assert result is not None
```

**2. Mocké—®é¢˜**
```python
# é—®é¢˜ï¼šMockæœªæ­£ç¡®æ›¿æ¢
@patch('module.ClassName')  # ç¡®ä¿è·¯å¾„æ­£ç¡®
def test_with_mock(mock_class):
    instance = mock_class.return_value
    instance.method.return_value = "mocked_value"

    result = function_that_uses_class()
    assert result == "mocked_value"
```

**3. å¼‚å¸¸æµ‹è¯•**
```python
# é—®é¢˜ï¼šå¼‚å¸¸æœªæ­£ç¡®æ•è·
def test_exception_raised():
    with pytest.raises(ValueError, match="specific error message"):
        function_that_raises_value_error()
```

---

## ğŸ“ æµ‹è¯•æœ€ä½³å®è·µ

### 1. æµ‹è¯•å‘½åè§„èŒƒ

**æè¿°æ€§æµ‹è¯•åç§°**
```python
def test_prediction_service_creates_prediction_successfully():
    """æµ‹è¯•é¢„æµ‹æœåŠ¡æˆåŠŸåˆ›å»ºé¢„æµ‹"""
    pass

def test_prediction_service_raises_error_when_match_data_invalid():
    """æµ‹è¯•å½“æ¯”èµ›æ•°æ®æ— æ•ˆæ—¶é¢„æµ‹æœåŠ¡æŠ›å‡ºé”™è¯¯"""
    pass

def test_prediction_service_returns_correct_confidence_score():
    """æµ‹è¯•é¢„æµ‹æœåŠ¡è¿”å›æ­£ç¡®çš„ç½®ä¿¡åº¦åˆ†æ•°"""
    pass
```

### 2. æµ‹è¯•ç»“æ„ï¼ˆAAAæ¨¡å¼ï¼‰

**Arrange - Act - Assert**
```python
def test_prediction_creation():
    # Arrange - å‡†å¤‡æµ‹è¯•æ•°æ®å’Œç¯å¢ƒ
    match_data = {
        "home_team": "Team A",
        "away_team": "Team B",
        "match_date": "2023-12-25"
    }
    service = PredictionService()

    # Act - æ‰§è¡Œè¢«æµ‹è¯•çš„æ“ä½œ
    prediction = service.create_prediction(match_data)

    # Assert - éªŒè¯ç»“æœ
    assert prediction is not None
    assert prediction.home_team == "Team A"
    assert prediction.away_team == "Team B"
```

### 3. æµ‹è¯•æ•°æ®ç®¡ç†

**ä½¿ç”¨å·¥å‚æ¨¡å¼**
```python
class PredictionFactory:
    @staticmethod
    def create_basic():
        return Prediction(
            id="test-123",
            match=MatchFactory.create_basic(),
            strategy_type="ml_model",
            prediction_data={"home_win": 0.6}
        )

    @staticmethod
    def create_with_high_confidence():
        prediction = PredictionFactory.create_basic()
        prediction.confidence_score = 0.95
        return prediction
```

### 4. æµ‹è¯•éš”ç¦»

**æ¯ä¸ªæµ‹è¯•ç‹¬ç«‹**
```python
@pytest.fixture
async def isolated_database():
    """ä¸ºæ¯ä¸ªæµ‹è¯•æä¾›ç‹¬ç«‹çš„æ•°æ®åº“"""
    # åˆ›å»ºä¸´æ—¶æ•°æ®åº“
    temp_db_name = f"test_db_{uuid.uuid4().hex[:8]}"

    # è®¾ç½®æ•°æ®åº“
    await setup_temp_database(temp_db_name)

    yield temp_db_name

    # æ¸…ç†æ•°æ®åº“
    await cleanup_temp_database(temp_db_name)
```

### 5. æµ‹è¯•è¦†ç›–ç­–ç•¥

**æ ¸å¿ƒè·¯å¾„ä¼˜å…ˆ**
```python
# ä¼˜å…ˆæµ‹è¯•æ ¸å¿ƒä¸šåŠ¡æµç¨‹
def test_prediction_workflow_core():
    """æµ‹è¯•é¢„æµ‹æ ¸å¿ƒå·¥ä½œæµ"""
    # 1. è·å–æ¯”èµ›æ•°æ®
    # 2. é€‰æ‹©é¢„æµ‹ç­–ç•¥
    # 3. ç”Ÿæˆé¢„æµ‹
    # 4. ä¿å­˜é¢„æµ‹ç»“æœ
    # 5. è¿”å›é¢„æµ‹ç»“æœ
    pass

# å…¶æ¬¡æµ‹è¯•è¾¹ç•Œæ¡ä»¶
def test_prediction_with_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæ¡ä»¶"""
    # 1. ç©ºæ•°æ®
    # 2. æ— æ•ˆæ ¼å¼
    # 3. æç«¯å€¼
    # 4. å¹¶å‘åœºæ™¯
    pass
```

### 6. æµ‹è¯•æ€§èƒ½ä¼˜åŒ–

**é¿å…é‡å¤è®¾ç½®**
```pytest
@pytest.fixture(scope="module")
def expensive_service():
    """æ¨¡å—çº§åˆ«çš„æ˜‚è´µæœåŠ¡è®¾ç½®"""
    return ExpensiveService()

def test1(expensive_service):
    result1 = expensive_service.method1()
    assert result1 is not None

def test2(expensive_service):
    result2 = expensive_service.method2()
    assert result2 is not None
```

### 7. æµ‹è¯•æ–‡æ¡£åŒ–

**æ–‡æ¡£å­—ç¬¦ä¸²**
```python
def test_ml_prediction_strategy():
    """æµ‹è¯•MLé¢„æµ‹ç­–ç•¥

    éªŒè¯MLç­–ç•¥èƒ½å¤Ÿï¼š
    1. æ­£ç¡®æå–ç‰¹å¾
    2. è°ƒç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    3. è¿”å›æ ¼å¼åŒ–çš„é¢„æµ‹ç»“æœ
    4. å¤„ç†æ¨¡å‹é¢„æµ‹å¤±è´¥çš„æƒ…å†µ

    Args:
        None

    Returns:
        None

    Raises:
        AssertionError: å½“é¢„æµ‹ç»“æœä¸ç¬¦åˆé¢„æœŸæ—¶
    """
    pass
```

---

## ğŸ¯ æµ‹è¯•ç­–ç•¥æ€»ç»“

### å¼€å‘é˜¶æ®µå»ºè®®

**1. æ—¥å¸¸å¼€å‘**
```bash
# å¿«é€ŸéªŒè¯ï¼ˆ<2åˆ†é’Ÿï¼‰
make test.smart

# åŠŸèƒ½éªŒè¯ï¼ˆ<5åˆ†é’Ÿï¼‰
pytest -m "critical and fast"
```

**2. æäº¤å‰**
```bash
# å®Œæ•´éªŒè¯ï¼ˆ<15åˆ†é’Ÿï¼‰
make prepush

# è´¨é‡æ£€æŸ¥
make check-quality
```

**3. å‘å¸ƒå‰**
```bash
# å…¨é¢æµ‹è¯•ï¼ˆ<1å°æ—¶ï¼‰
make test.ci-full

# æ€§èƒ½æµ‹è¯•
make test.performance-release
```

### è´¨é‡ä¿è¯ç­–ç•¥

**1. è¦†ç›–ç‡ç›®æ ‡**
- å½“å‰ï¼š29%
- çŸ­æœŸç›®æ ‡ï¼š35%
- é•¿æœŸç›®æ ‡ï¼š40%

**2. æµ‹è¯•ç¨³å®šæ€§**
- ç›®æ ‡é€šè¿‡ç‡ï¼š>95%
- å…³é”®æµ‹è¯•é€šè¿‡ç‡ï¼š100%

**3. æ‰§è¡Œæ•ˆç‡**
- Smart Testsï¼š<2åˆ†é’Ÿ
- å®Œæ•´å•å…ƒæµ‹è¯•ï¼š<10åˆ†é’Ÿ
- å…¨å¥—æµ‹è¯•ï¼š<30åˆ†é’Ÿ

---

*æ–‡æ¡£ç‰ˆæœ¬: v1.0 | æ›´æ–°æ—¶é—´: 2025-11-16*