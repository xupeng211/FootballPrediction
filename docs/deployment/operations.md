# è¿ç»´æ‰‹å†Œ

## ç›®å½•

1. [æ—¥å¸¸è¿ç»´](#æ—¥å¸¸è¿ç»´)
2. [ç›‘æ§ç®¡ç†](#ç›‘æ§ç®¡ç†)
3. [æ—¥å¿—ç®¡ç†](#æ—¥å¿—ç®¡ç†)
4. [å¤‡ä»½ç®¡ç†](#å¤‡ä»½ç®¡ç†)
5. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
6. [å®‰å…¨ç®¡ç†](#å®‰å…¨ç®¡ç†)
7. [æ•…éšœå¤„ç†](#æ•…éšœå¤„ç†)
8. [ç»´æŠ¤è®¡åˆ’](#ç»´æŠ¤è®¡åˆ’)

## æ—¥å¸¸è¿ç»´

### æ¯æ—¥æ£€æŸ¥æ¸…å•

#### ç³»ç»Ÿå¥åº·æ£€æŸ¥

```bash
#!/bin/bash
# daily_health_check.sh

echo "=== ç³»ç»Ÿå¥åº·æ£€æŸ¥ $(date) ==="

# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "1. æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose ps

# 2. æ£€æŸ¥ç£ç›˜ç©ºé—´
echo "2. æ£€æŸ¥ç£ç›˜ç©ºé—´..."
df -h

# 3. æ£€æŸ¥å†…å­˜ä½¿ç”¨
echo "3. æ£€æŸ¥å†…å­˜ä½¿ç”¨..."
free -h

# 4. æ£€æŸ¥è´Ÿè½½
echo "4. æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½..."
uptime

# 5. æ£€æŸ¥ç½‘ç»œè¿æ¥
echo "5. æ£€æŸ¥ç½‘ç»œè¿æ¥..."
netstat -tuln | grep LISTEN

# 6. æ£€æŸ¥æ—¥å¿—é”™è¯¯
echo "6. æ£€æŸ¥é”™è¯¯æ—¥å¿—..."
tail -n 100 logs/api/*.log | grep ERROR

# 7. æ£€æŸ¥å¤‡ä»½
echo "7. æ£€æŸ¥å¤‡ä»½çŠ¶æ€..."
ls -la backups/database/ | grep "$(date +%Y%m%d)"

echo "=== æ£€æŸ¥å®Œæˆ ==="
```

#### åº”ç”¨å¥åº·æ£€æŸ¥

```bash
# APIå¥åº·æ£€æŸ¥
curl -f http://localhost:8000/api/health || echo "APIæœåŠ¡å¼‚å¸¸"

# æ•°æ®åº“è¿æ¥æ£€æŸ¥
docker-compose exec -T api python -c "
import asyncio
from src.database.base import get_db_session
asyncio.run(get_db_session())
echo 'æ•°æ®åº“è¿æ¥æ­£å¸¸'
"

# Redisè¿æ¥æ£€æŸ¥
redis-cli -a $REDIS_PASSWORD ping || echo "Redisè¿æ¥å¼‚å¸¸"
```

### æ¯å‘¨ç»´æŠ¤ä»»åŠ¡

#### 1. æ—¥å¿—æ¸…ç†

```bash
#!/bin/bash
# weekly_cleanup.sh

# æ¸…ç†åº”ç”¨æ—¥å¿—ï¼ˆä¿ç•™7å¤©ï¼‰
find logs/ -name "*.log" -mtime +7 -delete

# æ¸…ç†Dockeræ—¥å¿—
docker system prune -f

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
find /tmp -name "football_*" -mtime +1 -delete

# æ¸…ç†Nginxæ—¥å¿—
sudo logrotate -f /etc/logrotate.d/nginx
```

#### 2. æ€§èƒ½åˆ†æ

```bash
# åˆ†ææ•°æ®åº“æ€§èƒ½
python scripts/analyze-db-performance.py

# åˆ†æAPIæ€§èƒ½
python scripts/analyze-api-performance.py

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
python scripts/generate-performance-report.py
```

#### 3. å®‰å…¨æ£€æŸ¥

```bash
#!/bin/bash
# security_check.sh

# æ£€æŸ¥ç³»ç»Ÿæ›´æ–°
sudo apt list --upgradable

# æ£€æŸ¥å¼€æ”¾ç«¯å£
nmap -sT -O localhost

# æ£€æŸ¥å¤±è´¥çš„ç™»å½•å°è¯•
sudo grep "Failed password" /var/log/auth.log | tail -20

# æ£€æŸ¥SSLè¯ä¹¦æœ‰æ•ˆæœŸ
openssl x509 -in config/ssl/server.crt -noout -dates
```

### æ¯æœˆç»´æŠ¤ä»»åŠ¡

#### 1. ç³»ç»Ÿæ›´æ–°

```bash
#!/bin/bash
# monthly_update.sh

# æ›´æ–°ç³»ç»ŸåŒ…
sudo apt update && sudo apt upgrade -y

# æ›´æ–°Dockeré•œåƒ
docker-compose pull

# é‡å¯æœåŠ¡ï¼ˆå¦‚éœ€è¦ï¼‰
docker-compose up -d
```

#### 2. å®¹é‡è§„åˆ’

```bash
# æ£€æŸ¥å­˜å‚¨è¶‹åŠ¿
df -h | grep -E "(Filesystem|/dev/)"

# æ£€æŸ¥æ•°æ®åº“å¢é•¿
docker-compose exec postgres psql -U postgres -d football_prediction -c "
SELECT pg_size_pretty(pg_database_size('football_prediction'));
"

# æ£€æŸ¥ç”¨æˆ·å¢é•¿
docker-compose exec api python -c "
from src.database.repositories.user import UserRepository
repo = UserRepository()
count = asyncio.run(repo.count())
print(f'ç”¨æˆ·æ•°: {count}')
"
```

## ç›‘æ§ç®¡ç†

### Prometheusç›‘æ§

#### æŸ¥è¯¢å¸¸ç”¨æŒ‡æ ‡

```bash
# æŸ¥çœ‹APIè¯·æ±‚ç‡
curl -G "http://localhost:9090/api/v1/query" \
  --data-urlencode 'query=rate(http_requests_total[5m])'

# æŸ¥çœ‹APIå“åº”æ—¶é—´
curl -G "http://localhost:9090/api/v1/query" \
  --data-urlencode 'query=histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))'

# æŸ¥çœ‹é”™è¯¯ç‡
curl -G "http://localhost:9090/api/v1/query" \
  --data-urlencode 'query=rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])'

# æŸ¥çœ‹æ•°æ®åº“è¿æ¥æ•°
curl -G "http://localhost:9090/api/v1/query" \
  --data-urlencode 'query=pg_stat_database_numbackends'
```

#### æ·»åŠ è‡ªå®šä¹‰ç›‘æ§æŒ‡æ ‡

```python
# src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# å®šä¹‰æŒ‡æ ‡
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Active database connections')

# ä½¿ç”¨ç¤ºä¾‹
@REQUEST_DURATION.time()
def handle_request():
    REQUEST_COUNT.labels(method='GET', endpoint='/api/health', status='200').inc()
    return "OK"
```

### Grafanaä»ªè¡¨æ¿

#### å¯¼å…¥é¢„é…ç½®ä»ªè¡¨æ¿

```bash
# ä½¿ç”¨Grafana APIå¯¼å…¥ä»ªè¡¨æ¿
curl -X POST \
  http://admin:admin@localhost:3000/api/dashboards/db \
  -H 'Content-Type: application/json' \
  -d @monitoring/grafana/dashboards/football-prediction-overview.json
```

#### è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™

```yaml
# monitoring/prometheus/rules/custom-alerts.yml
groups:
  - name: custom-alerts
    rules:
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 90% for more than 5 minutes"
```

### æ—¥å¿—ç®¡ç†

### Lokiæ—¥å¿—æŸ¥è¯¢

```bash
# æŸ¥è¯¢æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
curl -G "http://localhost:3100/loki/api/v1/query_range" \
  --data-urlencode 'query={level="ERROR"}' \
  --data-urlencode 'start=2024-03-15T00:00:00Z' \
  --data-urlencode 'end=2024-03-15T23:59:59Z'

# æŸ¥è¯¢ç‰¹å®šæœåŠ¡çš„æ—¥å¿—
curl -G "http://localhost:3100/loki/api/v1/query_range" \
  --data-urlencode 'query={job="football-prediction"}' \
  --data-urlencode 'limit=100'
```

### æ—¥å¿—åˆ†æè„šæœ¬

```python
# scripts/analyze_logs.py
import json
import re
from collections import defaultdict
from datetime import datetime

def analyze_api_logs(log_file):
    """åˆ†æAPIè®¿é—®æ—¥å¿—"""
    stats = {
        'total_requests': 0,
        'error_count': 0,
        'slow_requests': 0,
        'endpoints': defaultdict(int),
        'status_codes': defaultdict(int)
    }

    with open(log_file) as f:
        for line in f:
            try:
                log_entry = json.loads(line)

                stats['total_requests'] += 1

                # ç»Ÿè®¡ç«¯ç‚¹
                endpoint = log_entry.get('path', 'unknown')
                stats['endpoints'][endpoint] += 1

                # ç»Ÿè®¡çŠ¶æ€ç 
                status = log_entry.get('status_code', 0)
                stats['status_codes'][status] += 1

                # ç»Ÿè®¡é”™è¯¯
                if status >= 400:
                    stats['error_count'] += 1

                # ç»Ÿè®¡æ…¢è¯·æ±‚
                duration = log_entry.get('duration', 0)
                if duration > 1.0:
                    stats['slow_requests'] += 1

            except json.JSONDecodeError:
                continue

    return stats

if __name__ == "__main__":
    stats = analyze_api_logs("logs/api/app.log")
    print(json.dumps(stats, indent=2))
```

## å¤‡ä»½ç®¡ç†

### å¤‡ä»½è„šæœ¬æ‰§è¡Œ

```bash
# æ‰§è¡Œæ•°æ®åº“å¤‡ä»½
python scripts/backup-database.py backup --type full --compress --encrypt

# æŸ¥çœ‹å¤‡ä»½åˆ—è¡¨
python scripts/backup-database.py list

# éªŒè¯å¤‡ä»½
python scripts/backup-database.py verify --file backups/database/full_20240315_020000.sql

# æ¢å¤æµ‹è¯•ï¼ˆåœ¨æµ‹è¯•ç¯å¢ƒï¼‰
python scripts/backup-database.py restore --file backups/database/full_20240315_020000.sql --test
```

### è‡ªåŠ¨å¤‡ä»½é…ç½®

```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹å…¨é‡å¤‡ä»½
0 2 * * * cd /opt/football-prediction && python scripts/backup-database.py backup --type full --compress --encrypt

# æ¯6å°æ—¶å¢é‡å¤‡ä»½
0 */6 * * * cd /opt/football-prediction && python scripts/backup-database.py backup --type incremental

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹æ¸…ç†æ—§å¤‡ä»½
0 3 * * 0 cd /opt/football-prediction && python scripts/backup-database.py cleanup
```

### å¤‡ä»½éªŒè¯

```bash
#!/bin/bash
# verify_backups.sh

# éªŒè¯æœ€è¿‘çš„å¤‡ä»½
LATEST_BACKUP=$(ls -t backups/database/*.sql | head -1)

echo "éªŒè¯å¤‡ä»½: $LATEST_BACKUP"

# 1. æ£€æŸ¥æ–‡ä»¶å¤§å°
if [ $(stat -c%s "$LATEST_BACKUP") -lt 1000000 ]; then
    echo "è­¦å‘Š: å¤‡ä»½æ–‡ä»¶è¿‡å°"
fi

# 2. éªŒè¯å¤‡ä»½å®Œæ•´æ€§
python scripts/backup-database.py verify --file "$LATEST_BACKUP"

# 3. æµ‹è¯•æ¢å¤ï¼ˆåˆ°æµ‹è¯•æ•°æ®åº“ï¼‰
echo "æµ‹è¯•æ¢å¤åˆ°æµ‹è¯•æ•°æ®åº“..."
TEST_DB="football_prediction_test"
createdb $TEST_DB
pg_restore -d $TEST_DB "$LATEST_BACKUP"
dropdb $TEST_DB

echo "å¤‡ä»½éªŒè¯å®Œæˆ"
```

## æ€§èƒ½ä¼˜åŒ–

### æ•°æ®åº“ä¼˜åŒ–

```bash
# è¿è¡Œæ•°æ®åº“ä¼˜åŒ–
python scripts/optimize-database.py

# æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯
docker-compose exec postgres psql -U postgres -d football_prediction -c "ANALYZE;"

# é‡å»ºç´¢å¼•
docker-compose exec postgres psql -U postgres -d football_prediction -c "REINDEX DATABASE football_prediction;"

# æŸ¥çœ‹æ…¢æŸ¥è¯¢
docker-compose exec postgres psql -U postgres -d football_prediction -c "
SELECT query, mean_time, calls
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;
"
```

### Redisä¼˜åŒ–

```bash
# ç›‘æ§Redisæ€§èƒ½
redis-cli -a $REDIS_PASSWORD info stats

# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
redis-cli -a $REDIS_PASSWORD info memory

# æ¸…ç†è¿‡æœŸé”®
redis-cli -a $REDIS_PASSWORD --scan --pattern "*:EXPIRED*" | xargs redis-cli -a $REDIS_PASSWORD del

# ä¼˜åŒ–å†…å­˜ä½¿ç”¨
python scripts/optimize-redis.py
```

### APIæ€§èƒ½ä¼˜åŒ–

```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
./scripts/run-performance-tests.sh basic

# åˆ†ææ…¢ç«¯ç‚¹
python scripts/analyze-slow-endpoints.py

# ä¼˜åŒ–ç¼“å­˜é…ç½®
python scripts/optimize-cache.py
```

## å®‰å…¨ç®¡ç†

### è¯ä¹¦ç®¡ç†

```bash
# æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
openssl x509 -in config/ssl/server.crt -noout -dates

# è‡ªåŠ¨ç»­æœŸLet's Encryptè¯ä¹¦
echo "0 2 1 * * certbot renew --quiet" | sudo crontab -

# ç”Ÿæˆæ–°è¯ä¹¦
openssl req -x509 -newkey rsa:4096 -keyout config/ssl/server.key -out config/ssl/server.crt -days 365 -nodes
```

### å¯†é’¥è½®æ¢

```bash
#!/bin/bash
# rotate_secrets.sh

# ç”Ÿæˆæ–°çš„JWTå¯†é’¥
NEW_JWT_SECRET=$(openssl rand -base64 32)
echo "JWT_SECRET_KEY=$NEW_JWT_SECRET" >> .env.new

# ç”Ÿæˆæ–°çš„æ•°æ®åº“å¯†ç 
NEW_DB_PASSWORD=$(openssl rand -base64 16)
echo "DB_PASSWORD=$NEW_DB_PASSWORD" >> .env.new

# æ›´æ–°åº”ç”¨é…ç½®
docker-compose down
mv .env .env.old
mv .env.new .env
docker-compose up -d

# æ›´æ–°æ•°æ®åº“å¯†ç 
docker-compose exec postgres psql -U postgres -c "ALTER USER postgres PASSWORD '$NEW_DB_PASSWORD';"
```

### å®‰å…¨å®¡è®¡

```bash
#!/bin/bash
# security_audit.sh

# 1. æ£€æŸ¥å¼€æ”¾ç«¯å£
echo "=== å¼€æ”¾ç«¯å£ ==="
nmap -sT -O localhost

# 2. æ£€æŸ¥ç”¨æˆ·æƒé™
echo "=== ç”¨æˆ·æƒé™ ==="
sudo -l

# 3. æ£€æŸ¥æ–‡ä»¶æƒé™
echo "=== æ•æ„Ÿæ–‡ä»¶æƒé™ ==="
ls -la config/ssl/
ls -la .env*

# 4. æ£€æŸ¥Dockerå®‰å…¨é…ç½®
echo "=== Dockerå®‰å…¨ ==="
docker system info | grep -i security
```

## æ•…éšœå¤„ç†

### å¸¸è§æ•…éšœå¤„ç†æµç¨‹

#### 1. APIæœåŠ¡æ— å“åº”

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps api

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs api

# é‡å¯æœåŠ¡
docker-compose restart api

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tulpn | grep 8000

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
top
```

#### 2. æ•°æ®åº“è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker-compose exec postgres pg_isready

# æŸ¥çœ‹è¿æ¥æ•°
docker-compose exec postgres psql -U postgres -c "SELECT count(*) FROM pg_stat_activity;"

# æ£€æŸ¥æ…¢æŸ¥è¯¢
docker-compose exec postgres psql -U postgres -c "
SELECT pid, now() - pg_stat_activity.query_start AS duration, query
FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes';
"

# ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
docker-compose exec postgres psql -U postgres -c "SELECT pg_terminate_backend(pid);"
```

#### 3. Redisè¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥RedisçŠ¶æ€
redis-cli -a $REDIS_PASSWORD ping

# æŸ¥çœ‹Redisæ—¥å¿—
docker-compose logs redis

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
redis-cli -a $REDIS_PASSWORD info memory

# æ¸…ç†Redis
redis-cli -a $REDIS_PASSWORD flushdb
```

#### 4. é«˜CPUä½¿ç”¨ç‡

```bash
# æŸ¥çœ‹CPUä½¿ç”¨æƒ…å†µ
top -p $(pgrep -f "football-prediction")

# æŸ¥çœ‹è¿›ç¨‹è¯¦æƒ…
ps aux | grep football

# åˆ†æCPUçƒ­ç‚¹
perf top -p $(pgrep -f "uvicorn")

# é‡å¯æœåŠ¡
docker-compose restart api
```

### æ•…éšœæ¢å¤è„šæœ¬

```bash
#!/bin/bash
# emergency_recovery.sh

echo "=== ç´§æ€¥æ•…éšœæ¢å¤ç¨‹åº ==="

# 1. åœæ­¢æ‰€æœ‰æœåŠ¡
echo "åœæ­¢æœåŠ¡..."
docker-compose down

# 2. å¤‡ä»½å½“å‰çŠ¶æ€
echo "å¤‡ä»½å½“å‰çŠ¶æ€..."
mkdir -p emergency_backup/$(date +%Y%m%d_%H%M%S)
cp -r logs/ emergency_backup/$(date +%Y%m%d_%H%M%S)/
docker-compose logs --no-color > emergency_backup/$(date +%Y%m%d_%H%M%S)/docker_logs.log

# 3. æ¢å¤åˆ°æœ€åå·²çŸ¥è‰¯å¥½çŠ¶æ€
echo "æ¢å¤æœåŠ¡..."
docker-compose up -d

# 4. ç­‰å¾…æœåŠ¡å¯åŠ¨
sleep 30

# 5. å¥åº·æ£€æŸ¥
echo "å¥åº·æ£€æŸ¥..."
if curl -f http://localhost:8000/api/health; then
    echo "âœ“ æœåŠ¡æ¢å¤æˆåŠŸ"
else
    echo "âœ— æœåŠ¡æ¢å¤å¤±è´¥ï¼Œéœ€è¦äººå·¥å¹²é¢„"
    exit 1
fi

echo "=== æ¢å¤å®Œæˆ ==="
```

## ç»´æŠ¤è®¡åˆ’

### ç»´æŠ¤çª—å£ç®¡ç†

```bash
#!/bin/bash
# maintenance_mode.sh

# å¯ç”¨ç»´æŠ¤æ¨¡å¼
enable_maintenance() {
    echo "å¯ç”¨ç»´æŠ¤æ¨¡å¼..."

    # 1. æ›´æ–°Nginxé…ç½®è¿”å›503
    sudo cp config/nginx/maintenance.conf /etc/nginx/sites-available/football-prediction
    sudo nginx -s reload

    # 2. åœæ­¢åº”ç”¨æœåŠ¡ï¼ˆä¿ç•™æ•°æ®åº“å’Œç¼“å­˜ï¼‰
    docker-compose stop api celery-worker celery-beat

    # 3. é€šçŸ¥ç”¨æˆ·
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"ğŸ”§ ç³»ç»Ÿç»´æŠ¤ä¸­ï¼Œé¢„è®¡30åˆ†é’Ÿ"}' \
        $SLACK_WEBHOOK
}

# ç¦ç”¨ç»´æŠ¤æ¨¡å¼
disable_maintenance() {
    echo "ç¦ç”¨ç»´æŠ¤æ¨¡å¼..."

    # 1. å¯åŠ¨åº”ç”¨æœåŠ¡
    docker-compose start api celery-worker celery-beat

    # 2. æ¢å¤Nginxé…ç½®
    sudo cp config/nginx/nginx.conf /etc/nginx/sites-available/football-prediction
    sudo nginx -s reload

    # 3. ç­‰å¾…æœåŠ¡å°±ç»ª
    sleep 10

    # 4. å¥åº·æ£€æŸ¥
    if curl -f http://localhost:8000/api/health; then
        curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"âœ… ç³»ç»Ÿç»´æŠ¤å®Œæˆ"}' \
            $SLACK_WEBHOOK
    fi
}

case "$1" in
    enable)
        enable_maintenance
        ;;
    disable)
        disable_maintenance
        ;;
    *)
        echo "Usage: $0 {enable|disable}"
        exit 1
        ;;
esac
```

### å®šæœŸç»´æŠ¤ä»»åŠ¡

```yaml
# .github/workflows/maintenance.yml
name: Scheduled Maintenance

on:
  schedule:
    - cron: '0 3 * * 0'  # æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹
  workflow_dispatch:

jobs:
  maintenance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run maintenance tasks
        run: |
          # ç³»ç»Ÿæ¸…ç†
          docker system prune -f

          # æ—¥å¿—è½®è½¬
          ./scripts/rotate-logs.sh

          # å¤‡ä»½éªŒè¯
          ./scripts/verify-backups.sh

          # æ€§èƒ½æŠ¥å‘Š
          ./scripts/generate-performance-report.py
```

---

**æ›´æ–°æ—¶é—´**: 2024-03-15
**ç‰ˆæœ¬**: 1.0.0
**ç»´æŠ¤è€…**: Football Prediction DevOps Team
