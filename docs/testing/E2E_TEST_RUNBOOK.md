# ğŸš€ ç«¯åˆ°ç«¯æµ‹è¯•è¿è¡Œæ‰‹å†Œï¼ˆE2E Test Runbookï¼‰

**ç›®æ ‡ï¼š**
éªŒè¯ä»å‰ç«¯æ¥å£è¯·æ±‚ â†’ åç«¯æœåŠ¡å¤„ç† â†’ æ•°æ®è½åº“ â†’ è¿”å›å“åº”çš„å…¨æµç¨‹å¯ç”¨æ€§ã€‚

## ğŸ“‹ æµ‹è¯•èŒƒå›´

### æµ‹è¯•ç›®å½•ç»“æ„
```
tests/e2e/
â”œâ”€â”€ api/                     # APIç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ test_health_check.py
â”‚   â”œâ”€â”€ test_prediction_workflow.py
â”‚   â””â”€â”€ test_user_management.py
â”œâ”€â”€ workflows/               # ä¸šåŠ¡æµç¨‹æµ‹è¯•
â”‚   â”œâ”€â”€ test_match_prediction_flow.py
â”‚   â”œâ”€â”€ test_batch_processing.py
â”‚   â””â”€â”€ test_real_time_updates.py
â”œâ”€â”€ performance/            # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_load_simulation.py
â”‚   â””â”€â”€ test_stress_testing.py
â””â”€â”€ fixtures/              # æµ‹è¯•æ•°æ®
    â”œâ”€â”€ match_data.json
    â”œâ”€â”€ user_data.json
    â””â”€â”€ prediction_data.json
```

### å…¸å‹æµ‹è¯•ç”¨ä¾‹
1. **test_health_check.py** - ç³»ç»Ÿå¥åº·æ£€æŸ¥
2. **test_prediction_workflow.py** - é¢„æµ‹å®Œæ•´æµç¨‹
3. **test_audit_event_chain.py** - å®¡è®¡äº‹ä»¶é“¾
4. **test_batch_processing.py** - æ‰¹é‡å¤„ç†
5. **test_real_time_updates.py** - å®æ—¶æ›´æ–°

## ğŸŒ è¿è¡Œç¯å¢ƒ

### 1. ç¯å¢ƒé€‰æ‹©
```bash
# æ¨èåœ¨ä»¥ä¸‹ç¯å¢ƒè¿è¡Œï¼š
# 1. Stagingç¯å¢ƒï¼ˆæ¨èæ—¥å¸¸ä½¿ç”¨ï¼‰
# 2. Nightly Jobï¼ˆè‡ªåŠ¨åŒ–æ‰§è¡Œï¼‰
# 3. æœ¬åœ°Dockerç¯å¢ƒï¼ˆå¼€å‘è°ƒè¯•ï¼‰

# ç¯å¢ƒå˜é‡
export TEST_ENV=e2e
export E2E_MODE=full  # full | smoke | regression
```

### 2. Stagingç¯å¢ƒé…ç½®
```yaml
# docker-compose.staging.yml
version: '3.8'
services:
  app:
    image: football-prediction:staging
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/football_staging
      - REDIS_URL=redis://redis:6379/0
      - KAFKA_BROKER=kafka:9092
      - ENVIRONMENT=staging
    depends_on:
      - db
      - redis
      - kafka
```

### 3. æµ‹è¯•æ•°æ®åº“é…ç½®
```sql
-- ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•schema
CREATE SCHEMA IF NOT EXISTS e2e_test;
SET search_path TO e2e_test, public;

-- åˆ›å»ºæµ‹è¯•ç”¨æˆ·
CREATE USER e2e_user WITH PASSWORD 'e2e_pass_2024';
GRANT ALL ON SCHEMA e2e_test TO e2e_user;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA e2e_test TO e2e_user;
```

## ğŸš€ æ‰§è¡Œæµ‹è¯•

### 1. å®Œæ•´E2Eæµ‹è¯•å¥—ä»¶
```bash
# è¿è¡Œæ‰€æœ‰E2Eæµ‹è¯•
pytest tests/e2e/ \
  -v \
  --maxfail=1 \
  --disable-warnings \
  --timeout=300 \
  --junit-xml=reports/e2e-results.xml \
  --html=reports/e2e-report.html \
  --self-contained-html

# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
pytest tests/e2e/ --json-report --json-report-file=reports/e2e.json
python scripts/generate_e2e_report.py reports/e2e.json
```

### 2. å¿«é€Ÿå†’çƒŸæµ‹è¯•
```bash
# åªè¿è¡Œå…³é”®è·¯å¾„æµ‹è¯•ï¼ˆ5åˆ†é’Ÿå†…å®Œæˆï¼‰
pytest tests/e2e/api/test_health_check.py \
  tests/e2e/workflows/test_match_prediction_flow.py \
  -v \
  --tb=short \
  --timeout=60 \
  --maxfail=1
```

### 3. å›å½’æµ‹è¯•
```bash
# è¿è¡Œå†å²ç”¨ä¾‹ï¼Œç¡®ä¿æ–°æ›´æ–°æ²¡æœ‰ç ´ååŠŸèƒ½
pytest tests/e2e/ -m "regression" \
  -v \
  --maxfail=0 \
  --disable-warnings
```

### 4. æ€§èƒ½æµ‹è¯•
```bash
# è´Ÿè½½æµ‹è¯•
pytest tests/e2e/performance/test_load_simulation.py \
  -v \
  --benchmark-only \
  --benchmark-json=reports/e2e-performance.json

# å‹åŠ›æµ‹è¯•
pytest tests/e2e/performance/test_stress_testing.py \
  -v \
  --maxfail=1 \
  --timeout=600
```

## ğŸ§ª æµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹

### 1. APIç«¯åˆ°ç«¯æµ‹è¯•
```python
# tests/e2e/api/test_prediction_workflow.py
import pytest
from httpx import AsyncClient
import asyncio

class TestPredictionWorkflow:
    """é¢„æµ‹å·¥ä½œæµç¨‹ç«¯åˆ°ç«¯æµ‹è¯•"""

    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_complete_prediction_flow(self):
        """æµ‹è¯•å®Œæ•´çš„é¢„æµ‹æµç¨‹"""
        async with AsyncClient() as client:
            # 1. ç”¨æˆ·è®¤è¯
            auth_response = await client.post("/api/v1/auth/login", json={
                "username": "test_user",
                "password": "test_pass"
            })
            assert auth_response.status_code == 200
            token = auth_response.json()["access_token"]
            headers = {"Authorization": f"Bearer {token}"}

            # 2. è·å–æ¯”èµ›åˆ—è¡¨
            matches_response = await client.get(
                "/api/v1/matches?status=UPCOMING",
                headers=headers
            )
            assert matches_response.status_code == 200
            matches = matches_response.json()["data"]
            assert len(matches) > 0

            # 3. åˆ›å»ºé¢„æµ‹
            match_id = matches[0]["id"]
            prediction_response = await client.post(
                "/api/v1/predictions",
                json={
                    "match_id": match_id,
                    "prediction": "HOME_WIN",
                    "confidence": 0.85
                },
                headers=headers
            )
            assert prediction_response.status_code == 201
            prediction_id = prediction_response.json()["id"]

            # 4. éªŒè¯é¢„æµ‹ä¿å­˜
            get_response = await client.get(
                f"/api/v1/predictions/{prediction_id}",
                headers=headers
            )
            assert get_response.status_code == 200
            prediction = get_response.json()
            assert prediction["match_id"] == match_id
            assert prediction["status"] == "PENDING"

            # 5. æ¨¡æ‹Ÿæ¯”èµ›ç»“æœæ›´æ–°
            # è¿™é‡Œå¯èƒ½éœ€è¦å†…éƒ¨APIæˆ–ç›´æ¥æ•°æ®åº“æ›´æ–°
            update_response = await client.post(
                "/api/v1/admin/matches/update-result",
                json={
                    "match_id": match_id,
                    "home_score": 2,
                    "away_score": 1,
                    "status": "FINISHED"
                },
                headers=headers
            )
            assert update_response.status_code == 200

            # 6. éªŒè¯é¢„æµ‹ç»“æœ
            await asyncio.sleep(5)  # ç­‰å¾…å¼‚æ­¥å¤„ç†
            final_response = await client.get(
                f"/api/v1/predictions/{prediction_id}",
                headers=headers
            )
            assert final_response.status_code == 200
            final_prediction = final_response.json()
            assert final_prediction["status"] == "COMPLETED"
            assert final_prediction["is_correct"] == True

            # 7. éªŒè¯å®¡è®¡æ—¥å¿—
            audit_response = await client.get(
                f"/api/v1/audit/predictions/{prediction_id}",
                headers=headers
            )
            assert audit_response.status_code == 200
            audit_logs = audit_response.json()
            assert len(audit_logs) >= 3  # åˆ›å»ºã€æ›´æ–°ã€å®Œæˆ
```

### 2. æ‰¹é‡å¤„ç†æµ‹è¯•
```python
# tests/e2e/workflows/test_batch_processing.py
class TestBatchProcessing:
    """æ‰¹é‡å¤„ç†ç«¯åˆ°ç«¯æµ‹è¯•"""

    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_batch_prediction_import(self):
        """æµ‹è¯•æ‰¹é‡å¯¼å…¥é¢„æµ‹"""
        async with AsyncClient() as client:
            # 1. è®¤è¯
            token = await self._get_auth_token(client)
            headers = {"Authorization": f"Bearer {token}"}

            # 2. ä¸Šä¼ CSVæ–‡ä»¶
            with open("tests/fixtures/batch_predictions.csv", "rb") as f:
                upload_response = await client.post(
                    "/api/v1/batch/predictions/upload",
                    files={"file": ("predictions.csv", f, "text/csv")},
                    headers=headers
                )
            assert upload_response.status_code == 202
            batch_id = upload_response.json()["batch_id"]

            # 3. ç›‘æ§æ‰¹å¤„ç†è¿›åº¦
            for _ in range(30):  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
                status_response = await client.get(
                    f"/api/v1/batch/predictions/{batch_id}/status",
                    headers=headers
                )
                status = status_response.json()

                if status["status"] == "COMPLETED":
                    break
                elif status["status"] == "FAILED":
                    pytest.fail(f"Batch processing failed: {status['error']}")

                await asyncio.sleep(10)

            # 4. éªŒè¯ç»“æœ
            result_response = await client.get(
                f"/api/v1/batch/predictions/{batch_id}/results",
                headers=headers
            )
            assert result_response.status_code == 200
            results = result_response.json()
            assert results["total"] == 1000
            assert results["successful"] >= 990
            assert results["failed"] <= 10
```

### 3. å®æ—¶æ›´æ–°æµ‹è¯•
```python
# tests/e2e/workflows/test_real_time_updates.py
class TestRealTimeUpdates:
    """å®æ—¶æ›´æ–°ç«¯åˆ°ç«¯æµ‹è¯•"""

    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_websocket_match_updates(self):
        """æµ‹è¯•WebSocketå®æ—¶æ›´æ–°"""
        import websockets
        import json

        async with websockets.connect("ws://localhost:8000/ws/matches") as websocket:
            # 1. è®¢é˜…æ¯”èµ›æ›´æ–°
            await websocket.send(json.dumps({
                "action": "subscribe",
                "match_id": "12345"
            }))

            # 2. è§¦å‘æ¯”èµ›çŠ¶æ€æ›´æ–°
            async with AsyncClient() as client:
                token = await self._get_auth_token(client)
                headers = {"Authorization": f"Bearer {token}"}

                await client.post(
                    "/api/v1/admin/matches/12345/update",
                    json={
                        "minute": 45,
                        "score": {"home": 1, "away": 0},
                        "events": ["GOAL", "YELLOW_CARD"]
                    },
                    headers=headers
                )

            # 3. æ¥æ”¶WebSocketæ›´æ–°
            message = await websocket.recv()
            update = json.loads(message)
            assert update["match_id"] == "12345"
            assert update["minute"] == 45
            assert "GOAL" in update["events"]
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

### 1. è´Ÿè½½æµ‹è¯•é…ç½®
```python
# tests/e2e/performance/test_load_simulation.py
import pytest
import asyncio
from concurrent.futures import ThreadPoolExecutor
import statistics

class TestLoadSimulation:
    """è´Ÿè½½æ¨¡æ‹Ÿæµ‹è¯•"""

    @pytest.mark.performance
    @pytest.mark.e2e
    async def test_concurrent_prediction_requests(self):
        """æµ‹è¯•å¹¶å‘é¢„æµ‹è¯·æ±‚"""
        async with AsyncClient() as client:
            # è·å–è®¤è¯token
            token = await self._get_auth_token(client)
            headers = {"Authorization": f"Bearer {token}"}

            # å¹¶å‘å‚æ•°
            concurrent_users = 50
            requests_per_user = 10
            total_requests = concurrent_users * requests_per_user

            # æ”¶é›†å“åº”æ—¶é—´
            response_times = []

            async def make_request(session_id):
                """å•ä¸ªç”¨æˆ·è¯·æ±‚"""
                user_times = []
                for i in range(requests_per_user):
                    start_time = time.time()

                    response = await client.post(
                        "/api/v1/predictions",
                        json={
                            "match_id": f"match_{session_id}_{i}",
                            "prediction": "HOME_WIN"
                        },
                        headers=headers
                    )

                    end_time = time.time()
                    response_time = (end_time - start_time) * 1000
                    user_times.append(response_time)

                    assert response.status_code in [200, 201]

                return user_times

            # æ‰§è¡Œå¹¶å‘æµ‹è¯•
            tasks = [
                make_request(user_id)
                for user_id in range(concurrent_users)
            ]

            all_times = await asyncio.gather(*tasks)
            response_times = [time for user_times in all_times for time in user_times]

            # æ€§èƒ½æ–­è¨€
            assert len(response_times) == total_requests
            assert statistics.mean(response_times) < 500  # å¹³å‡å“åº”æ—¶é—´ < 500ms
            assert statistics.stdev(response_times) < 200  # æ ‡å‡†å·® < 200ms
            assert max(response_times) < 2000  # æœ€å¤§å“åº”æ—¶é—´ < 2s

            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            self._generate_performance_report(response_times, {
                "concurrent_users": concurrent_users,
                "requests_per_user": requests_per_user,
                "total_requests": total_requests
            })
```

### 2. å‹åŠ›æµ‹è¯•
```python
# tests/e2e/performance/test_stress_testing.py
class TestStressTesting:
    """å‹åŠ›æµ‹è¯•"""

    @pytest.mark.slow
    @pytest.mark.e2e
    async def test_sustained_load(self):
        """æµ‹è¯•æŒç»­è´Ÿè½½"""
        duration_seconds = 300  # 5åˆ†é’Ÿ
        target_rps = 100  # æ¯ç§’100ä¸ªè¯·æ±‚

        async with AsyncClient() as client:
            token = await self._get_auth_token(client)
            headers = {"Authorization": f"Bearer {token}"}

            start_time = time.time()
            request_count = 0
            error_count = 0
            response_times = []

            async def continuous_requests():
                nonlocal request_count, error_count
                while time.time() - start_time < duration_seconds:
                    try:
                        req_start = time.time()
                        response = await client.post(
                            "/api/v1/predictions",
                            json={
                                "match_id": f"stress_{request_count}",
                                "prediction": "DRAW"
                            },
                            headers=headers,
                            timeout=5
                        )
                        req_end = time.time()

                        if response.status_code in [200, 201]:
                            response_times.append((req_end - req_start) * 1000)
                        else:
                            error_count += 1

                        request_count += 1

                        # æ§åˆ¶è¯·æ±‚é€Ÿç‡
                        await asyncio.sleep(1.0 / target_rps)

                    except Exception as e:
                        error_count += 1
                        await asyncio.sleep(0.1)

            # å¯åŠ¨å¤šä¸ªå¹¶å‘è¯·æ±‚æµ
            tasks = [continuous_requests() for _ in range(10)]
            await asyncio.gather(*tasks)

            # å‹åŠ›æµ‹è¯•æ–­è¨€
            total_time = time.time() - start_time
            actual_rps = request_count / total_time
            error_rate = error_count / request_count

            assert actual_rps >= target_rps * 0.9  # è‡³å°‘è¾¾åˆ°90%çš„ç›®æ ‡RPS
            assert error_rate < 0.01  # é”™è¯¯ç‡ä½äº1%
            assert statistics.mean(response_times) < 1000  # å¹³å‡å“åº”æ—¶é—´ < 1s
```

## ğŸ“ˆ æŠ¥å‘Šç”Ÿæˆ

### 1. E2Eæµ‹è¯•æŠ¥å‘Šæ¨¡æ¿
```markdown
# E2Eæµ‹è¯•æŠ¥å‘Š - 2025-01-13

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ
- ç¯å¢ƒï¼šStaging
- æ‰§è¡Œæ—¶é—´ï¼š2025-01-13 22:00 - 22:45
- æ€»æµ‹è¯•æ•°ï¼š85
- é€šè¿‡ï¼š82 (96.5%)
- å¤±è´¥ï¼š3 (3.5%)
- è·³è¿‡ï¼š0

## ğŸ” æµ‹è¯•ç±»åˆ«
### APIç«¯åˆ°ç«¯æµ‹è¯•
- é€šè¿‡ï¼š45/48
- å¤±è´¥ï¼š3
- å¹³å‡å“åº”æ—¶é—´ï¼š234ms
- å¤±è´¥è¯¦æƒ…ï¼š
  - test_prediction_timeout - è¶…æ—¶(>5s)
  - test_concurrent_users - 503é”™è¯¯
  - test_websocket_disconnect - è¿æ¥æ–­å¼€

### ä¸šåŠ¡æµç¨‹æµ‹è¯•
- é€šè¿‡ï¼š25/25
- æˆåŠŸç‡ï¼š100%
- å¹³å‡è€—æ—¶ï¼š1.2s

### æ€§èƒ½æµ‹è¯•
- è´Ÿè½½æµ‹è¯•ï¼šé€šè¿‡
  - 100å¹¶å‘ç”¨æˆ·ï¼Œ10è¯·æ±‚/ç”¨æˆ·
  - å¹³å‡å“åº”æ—¶é—´ï¼š456ms
  - 99.9åˆ†ä½ï¼š1.2s
- å‹åŠ›æµ‹è¯•ï¼šé€šè¿‡
  - 5åˆ†é’ŸæŒç»­è´Ÿè½½
  - ç›®æ ‡RPSï¼š100ï¼Œå®é™…ï¼š98.5
  - é”™è¯¯ç‡ï¼š0.12%

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… | çŠ¶æ€ |
|------|------|------|------|
| å¹³å‡å“åº”æ—¶é—´ | < 500ms | 234ms | âœ… |
| 99åˆ†ä½å“åº”æ—¶é—´ | < 2s | 1.2s | âœ… |
| é”™è¯¯ç‡ | < 1% | 0.5% | âœ… |
| å¹¶å‘ç”¨æˆ·æ•° | > 100 | 150 | âœ… |
| ååé‡ | > 500 RPS | 520 RPS | âœ… |

## ğŸš¨ å¤±è´¥åˆ†æ
### 1. test_prediction_timeout
- **åŸå› **ï¼šæ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–é—®é¢˜
- **å½±å“**ï¼š3/45 APIæµ‹è¯•å¤±è´¥
- **å»ºè®®**ï¼šæ·»åŠ æŸ¥è¯¢ç´¢å¼•ï¼Œä¼˜åŒ–æ…¢æŸ¥è¯¢

### 2. test_concurrent_users
- **åŸå› **ï¼šè¿æ¥æ± è€—å°½
- **å½±å“**ï¼šé«˜å¹¶å‘åœºæ™¯ä¸ç¨³å®š
- **å»ºè®®**ï¼šå¢åŠ è¿æ¥æ± å¤§å°

## ğŸ¯ æ”¹è¿›å»ºè®®
1. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
2. è°ƒæ•´è¿æ¥æ± é…ç½®
3. æ·»åŠ WebSocketé‡è¿æœºåˆ¶
4. å®æ–½æ›´ç»†ç²’åº¦çš„ç›‘æ§

## ğŸ“… å†å²è¶‹åŠ¿
[å›¾è¡¨å±•ç¤ºï¼šæµ‹è¯•é€šè¿‡ç‡è¶‹åŠ¿]
```

### 2. è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆè„šæœ¬
```python
# scripts/generate_e2e_report.py
import json
import datetime
from pathlib import Path

def generate_report(result_file):
    with open(result_file) as f:
        data = json.load(f)

    report = f"""
# E2Eæµ‹è¯•æŠ¥å‘Š - {datetime.date.today()}

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ
- æ€»æµ‹è¯•æ•°ï¼š{data['total']}
- é€šè¿‡ï¼š{data['passed']} ({data['passed']/data['total']*100:.1f}%)
- å¤±è´¥ï¼š{data['failed']} ({data['failed']/data['total']*100:.1f}%)
- è€—æ—¶ï¼š{data['duration']}s

## ğŸ” è¯¦ç»†ç»“æœ
"""

    # æ·»åŠ æ›´å¤šæŠ¥å‘Šå†…å®¹...

    report_file = Path(f"docs/_reports/E2E_RESULT_{datetime.date.today()}.md")
    report_file.write_text(report)
```

## ğŸŒ™ Nightly Job é…ç½®

### GitHub Actionsé…ç½®
```yaml
# .github/workflows/e2e-test.yml
name: E2E Test

on:
  schedule:
    - cron: "0 22 * * *"  # æ¯æ™š22:00æ‰§è¡Œ
  workflow_dispatch:  # æ‰‹åŠ¨è§¦å‘

jobs:
  e2e:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: [staging, production]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-html

      - name: Setup test environment
        run: |
          cp .env.example .env.test
          echo "E2E_MODE=full" >> .env.test

      - name: Run E2E tests
        run: |
          pytest tests/e2e/ \
            -v \
            --maxfail=1 \
            --disable-warnings \
            --junit-xml=e2e-results.xml \
            --html=e2e-report.html \
            --self-contained-html
        env:
          E2E_ENV: ${{ matrix.environment }}

      - name: Generate report
        run: |
          python scripts/generate_e2e_report.py e2e-results.json
          mv e2e-report.md docs/_reports/E2E_RESULT_$(date +%F).md

      - name: Upload results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results-${{ matrix.environment }}
          path: |
            e2e-results.xml
            e2e-report.html

      - name: Notify on failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#alerts'
          text: 'E2Eæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æŠ¥å‘Šï¼'
```

### æœ¬åœ°Croné…ç½®
```bash
# æ·»åŠ åˆ°crontab
# æ¯æ™š22:00æ‰§è¡ŒE2Eæµ‹è¯•
0 22 * * * cd /path/to/project && source .venv/bin/activate && python scripts/run_e2e_nightly.py
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### 1. æµ‹è¯•è¶…æ—¶
```bash
# å¢åŠ è¶…æ—¶æ—¶é—´
pytest tests/e2e/ --timeout=600

# ä½¿ç”¨å¼‚æ­¥è¶…æ—¶
pytest tests/e2e/ --asyncio-mode=auto
```

### 2. æœåŠ¡ä¸å¯ç”¨
```bash
# æ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€
docker compose -f docker-compose.staging.yml ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker compose -f docker-compose.staging.yml logs -f app

# é‡å¯æœåŠ¡
docker compose -f docker-compose.staging.yml restart
```

### 3. æµ‹è¯•æ•°æ®é—®é¢˜
```bash
# é‡æ–°åŠ è½½æµ‹è¯•æ•°æ®
python scripts/load_e2e_test_data.py --reset

# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker exec -it football-staging-db psql -U postgres -d football -c "SELECT COUNT(*) FROM e2e_test.predictions;"
```

## ğŸ“‹ æµ‹è¯•æ¸…å•

### æ‰§è¡Œå‰
- [ ] ç¯å¢ƒå˜é‡å·²é…ç½®
- [ ] æµ‹è¯•æ•°æ®åº“å·²åˆå§‹åŒ–
- [ ] æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ
- [ ] æµ‹è¯•æ•°æ®å·²åŠ è½½

### æ‰§è¡Œä¸­
- [ ] ç›‘æ§æµ‹è¯•æ‰§è¡Œè¿›åº¦
- [ ] æ³¨æ„è§‚å¯Ÿé”™è¯¯ç‡
- [ ] è®°å½•å¼‚å¸¸æƒ…å†µ

### æ‰§è¡Œå
- [ ] ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
- [ ] åˆ†æå¤±è´¥åŸå› 
- [ ] åˆ›å»ºä¿®å¤ä»»åŠ¡
- [ ] æ›´æ–°çœ‹æ¿çŠ¶æ€

## ğŸ”„ æ¸…ç†æ“ä½œ

```bash
# æ¸…ç†æµ‹è¯•æ•°æ®
python scripts/cleanup_e2e_data.py

# æ¸…ç†æ—¥å¿—
rm -f logs/e2e-*.log

# æ¸…ç†æŠ¥å‘Š
rm -f reports/e2e-*.xml reports/e2e-*.html

# é‡ç½®æµ‹è¯•ç¯å¢ƒ
docker compose -f docker-compose.staging.yml down -v
```

## ğŸ“ æœ€ä½³å®è·µ

1. **æµ‹è¯•ç‹¬ç«‹æ€§**
   - æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹åº”è¯¥æ˜¯ç‹¬ç«‹çš„
   - ä¸ä¾èµ–å…¶ä»–æµ‹è¯•çš„çŠ¶æ€
   - ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•æ•°æ®

2. **æ•°æ®ç®¡ç†**
   - ä½¿ç”¨äº‹åŠ¡éš”ç¦»æµ‹è¯•æ•°æ®
   - æµ‹è¯•åæ¸…ç†æ•°æ®
   - ä½¿ç”¨ç¡®å®šæ€§æ•°æ®

3. **é”™è¯¯å¤„ç†**
   - æ˜ç¡®çš„é”™è¯¯æ–­è¨€
   - è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
   - ä¼˜é›…çš„å¤±è´¥å¤„ç†

4. **æ€§èƒ½è€ƒè™‘**
   - è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
   - é¿å…ä¸å¿…è¦çš„ç­‰å¾…
   - ä½¿ç”¨å¹¶å‘æµ‹è¯•æé«˜æ•ˆç‡

---

**æ³¨æ„äº‹é¡¹ï¼š**
- E2Eæµ‹è¯•è¿è¡Œæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®åœ¨éå·¥ä½œæ—¶é—´æ‰§è¡Œ
- ç¡®ä¿æµ‹è¯•ç¯å¢ƒç¨³å®šï¼Œé¿å…å¤–éƒ¨å› ç´ å½±å“
- å®šæœŸæ›´æ–°æµ‹è¯•æ•°æ®å’Œé¢„æœŸç»“æœ
- ä¿æŒæµ‹è¯•ç”¨ä¾‹ä¸å®é™…ä¸šåŠ¡åœºæ™¯ä¸€è‡´
