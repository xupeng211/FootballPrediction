# ğŸ§± é›†æˆæµ‹è¯•è¿è¡Œæ‰‹å†Œï¼ˆIntegration Test Runbookï¼‰

**ç›®æ ‡ï¼š**
éªŒè¯æ¨¡å—é—´äº¤äº’é€»è¾‘ï¼ˆAPI â†” DB â†” Kafka â†” Redisï¼‰æ˜¯å¦æ­£å¸¸ã€‚

**æµ‹è¯•èŒƒå›´ï¼š**
- `tests/integration/` ç›®å½•ä¸‹æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ã€‚
- é‡ç‚¹æ¨¡å—ï¼š
  - `src/api/`
  - `src/services/`
  - `src/data/`
  - `src/streaming/`

## ğŸ“‹ è¿è¡Œå‰å‡†å¤‡

### 1. ç¯å¢ƒè¦æ±‚
- Python 3.11+
- Docker & Docker Compose
- è‡³å°‘ 8GB å¯ç”¨å†…å­˜

### 2. ä¾èµ–æœåŠ¡é…ç½®

#### 2.1 å¯åŠ¨æµ‹è¯•åŸºç¡€è®¾æ–½
```bash
# ä½¿ç”¨æµ‹è¯•ä¸“ç”¨çš„ Docker Compose
docker compose -f docker-compose.test.yml up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker compose -f docker-compose.test.yml ps
```

#### 2.2 æœåŠ¡åˆ—è¡¨
| æœåŠ¡ | ç«¯å£ | æè¿° | æµ‹è¯•æ•°æ®åº“ |
|------|------|------|------------|
| PostgreSQL | 5432 | ä¸»æ•°æ®åº“ | football_test |
| Redis | 6379 | ç¼“å­˜/ä¼šè¯ | test_redis |
| Kafka | 9092 | æ¶ˆæ¯é˜Ÿåˆ— | test_topics |
| MLflow | 5000 | æ¨¡å‹è·Ÿè¸ª | mlflow_test |
| Zookeeper | 2181 | Kafkaåè°ƒ | - |

#### 2.3 ç¯å¢ƒå˜é‡é…ç½®
```bash
# å¤åˆ¶æµ‹è¯•ç¯å¢ƒé…ç½®
cp .env.example .env.test

# ç¼–è¾‘æµ‹è¯•ç¯å¢ƒå˜é‡
cat > .env.test << EOF
# æµ‹è¯•ç¯å¢ƒé…ç½®
TEST_ENV=integration
TESTING=true

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://test_user:test_pass@localhost:5432/football_test
DB_HOST=localhost
DB_PORT=5432
DB_NAME=football_test
DB_USER=test_user
DB_PASSWORD=test_pass

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Kafkaé…ç½®
KAFKA_BROKER=localhost:9092
KAFKA_TOPIC_PREFIX=test_
KAFKA_GROUP_ID=test_group

# MLflowé…ç½®
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=test_experiment

# æ—¥å¿—é…ç½®
LOG_LEVEL=DEBUG
LOG_FORMAT=json

# å…¶ä»–é…ç½®
SECRET_KEY=test-secret-key-for-integration-only
ALLOWED_HOSTS=localhost,127.0.0.1
EOF

# åŠ è½½ç¯å¢ƒå˜é‡
export $(cat .env.test | xargs)
```

### 3. æ•°æ®åº“åˆå§‹åŒ–
```bash
# åˆ›å»ºæµ‹è¯•æ•°æ®åº“
docker exec -it football-pg-test psql -U postgres -c "CREATE DATABASE football_test;"

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker exec -it football-app-test alembic upgrade head

# åŠ è½½æµ‹è¯•æ•°æ®
python scripts/load_test_data.py --env=test
```

## ğŸš€ æ‰§è¡Œæµ‹è¯•

### 1. è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•
```bash
# è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•å¥—ä»¶
pytest tests/integration/ \
  --maxfail=5 \
  --disable-warnings \
  --cov-append \
  --cov-report=term \
  --cov-report=html \
  --junit-xml=reports/integration-results.xml \
  -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
open htmlcov/index.html
```

### 2. è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
```bash
# APIé›†æˆæµ‹è¯•
pytest tests/integration/api/ \
  -v \
  --disable-warnings \
  --maxfail=3

# æœåŠ¡å±‚é›†æˆæµ‹è¯•
pytest tests/integration/services/ \
  -v \
  --disable-warnings \
  --maxfail=3

# æ•°æ®åº“é›†æˆæµ‹è¯•
pytest tests/integration/database/ \
  -v \
  --disable-warnings \
  --maxfail=3

# æµå¤„ç†é›†æˆæµ‹è¯•
pytest tests/integration/streaming/ \
  -v \
  --disable-warnings \
  --maxfail=3
```

### 3. è¿è¡Œæ€§èƒ½ç›¸å…³çš„é›†æˆæµ‹è¯•
```bash
# åŒ…å«æ€§èƒ½åŸºå‡†çš„é›†æˆæµ‹è¯•
pytest tests/integration/ -m "performance" \
  --benchmark-only \
  --benchmark-json=reports/integration-benchmark.json \
  -v

# å‹åŠ›æµ‹è¯•
pytest tests/integration/stress/ \
  --maxfail=1 \
  -v
```

## ğŸ“Š æµ‹è¯•ç±»åˆ«

### 1. APIé›†æˆæµ‹è¯• (`tests/integration/api/`)
```python
# å…¸å‹æµ‹è¯•ç¤ºä¾‹
class TestAPIIntegration:
    """APIé›†æˆæµ‹è¯•"""

    async def test_prediction_api_workflow(self):
        """æµ‹è¯•é¢„æµ‹APIå®Œæ•´æµç¨‹"""
        # 1. åˆ›å»ºé¢„æµ‹è¯·æ±‚
        response = await client.post("/api/v1/predictions", json={
            "match_id": 12345,
            "home_team": "Team A",
            "away_team": "Team B",
            "prediction": "HOME_WIN"
        })
        assert response.status_code == 201

        # 2. éªŒè¯æ•°æ®åº“ä¿å­˜
        prediction = await db.get_prediction(12345)
        assert prediction is not None
        assert prediction.result == "HOME_WIN"

        # 3. éªŒè¯Kafkaæ¶ˆæ¯å‘é€
        message = await kafka.consume("predictions")
        assert message["match_id"] == 12345

        # 4. éªŒè¯ç¼“å­˜æ›´æ–°
        cached = await redis.get(f"prediction:{12345}")
        assert cached is not None
```

### 2. æ•°æ®åº“é›†æˆæµ‹è¯• (`tests/integration/database/`)
```python
# æµ‹è¯•æ•°æ®åº“äº‹åŠ¡ã€è¿æ¥æ± ã€æŸ¥è¯¢ä¼˜åŒ–
class TestDatabaseIntegration:
    """æ•°æ®åº“é›†æˆæµ‹è¯•"""

    async def test_transaction_rollback(self):
        """æµ‹è¯•äº‹åŠ¡å›æ»š"""
        async with db.transaction():
            # æ’å…¥æ•°æ®
            await db.insert_prediction(data)
            # æ•…æ„æŠ›å‡ºå¼‚å¸¸
            raise Exception("Rollback")

        # éªŒè¯æ•°æ®æœªä¿å­˜
        count = await db.count_predictions()
        assert count == initial_count
```

### 3. æµå¤„ç†é›†æˆæµ‹è¯• (`tests/integration/streaming/`)
```python
# æµ‹è¯•Kafkaæ¶ˆè´¹è€…ã€ç”Ÿäº§è€…
class TestStreamingIntegration:
    """æµå¤„ç†é›†æˆæµ‹è¯•"""

    async def test_kafka_message_flow(self):
        """æµ‹è¯•Kafkaæ¶ˆæ¯å®Œæ•´æµç¨‹"""
        # 1. ç”Ÿäº§æ¶ˆæ¯
        await kafka.produce("predictions", test_message)

        # 2. æ¶ˆè´¹æ¶ˆæ¯
        consumed = await kafka.consume("predictions", timeout=5)
        assert consumed["match_id"] == test_message["match_id"]

        # 3. éªŒè¯å¤„ç†ç»“æœ
        result = await db.get_processed_prediction(test_message["match_id"])
        assert result is not None
```

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥PostgreSQLçŠ¶æ€
docker logs football-pg-test

# é‡å¯æœåŠ¡
docker restart football-pg-test

# æ£€æŸ¥è¿æ¥
docker exec -it football-pg-test psql -U test_user -d football_test
```

#### 2. Kafkaæ— æ³•è¿æ¥
```bash
# æ£€æŸ¥KafkaçŠ¶æ€
docker logs football-kafka-test

# æ£€æŸ¥ä¸»é¢˜åˆ—è¡¨
docker exec -it football-kafka kafka-topics --bootstrap-server localhost:9092 --list

# åˆ›å»ºæµ‹è¯•ä¸»é¢˜
docker exec -it football-kafka kafka-topics --bootstrap-server localhost:9092 --create --topic test_predictions
```

#### 3. Redisè¿æ¥è¶…æ—¶
```bash
# æ£€æŸ¥RedisçŠ¶æ€
docker logs football-redis-test

# æµ‹è¯•è¿æ¥
docker exec -it football-redis redis-cli ping

# æ¸…ç©ºæµ‹è¯•æ•°æ®
docker exec -it football-redis redis-cli flushall
```

### æµ‹è¯•å¤±è´¥å¤„ç†

#### 1. æŸ¥çœ‹è¯¦ç»†é”™è¯¯
```bash
# æ˜¾ç¤ºå®Œæ•´é”™è¯¯å †æ ˆ
pytest tests/integration/ -v --tb=long

# åªçœ‹å¤±è´¥æµ‹è¯•
pytest tests/integration/ --lf -v

# æŸ¥çœ‹å‰3ä¸ªå¤±è´¥
pytest tests/integration/ --maxfail=3 -v
```

#### 2. è°ƒè¯•æ¨¡å¼
```bash
# è¿›å…¥è°ƒè¯•æ¨¡å¼
pytest tests/integration/test_api.py::TestAPIIntegration::test_prediction_api_workflow -s

# ä½¿ç”¨pdbè°ƒè¯•
pytest --pdb tests/integration/test_api.py::TestAPIIntegration::test_prediction_api_workflow
```

## ğŸ“ˆ æŠ¥å‘Šè¾“å‡º

### 1. æŠ¥å‘Šç”Ÿæˆ
```bash
# è¿è¡Œæµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š
pytest tests/integration/ \
  --junit-xml=reports/integration-results.xml \
  --html=reports/integration-report.html \
  --self-contained-html

# ç”ŸæˆMarkdownæŠ¥å‘Š
pytest tests/integration/ --json-report --json-report-file=reports/integration.json
python scripts/generate_integration_report.py reports/integration.json
```

### 2. æŠ¥å‘Šå†…å®¹ç»“æ„
```markdown
# é›†æˆæµ‹è¯•æŠ¥å‘Š - 2025-01-13

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ
- æ€»æµ‹è¯•æ•°ï¼š42
- é€šè¿‡ï¼š38 (90.5%)
- å¤±è´¥ï¼š4 (9.5%)
- è€—æ—¶ï¼š3åˆ†24ç§’

## ğŸ”§ æ¨¡å—çŠ¶æ€
### APIé›†æˆ
- âœ… é€šè¿‡ï¼š12/15
- âŒ å¤±è´¥ï¼š3
- å¹³å‡å“åº”æ—¶é—´ï¼š125ms

### æ•°æ®åº“é›†æˆ
- âœ… é€šè¿‡ï¼š15/15
- å¹³å‡æŸ¥è¯¢æ—¶é—´ï¼š45ms

### æµå¤„ç†é›†æˆ
- âœ… é€šè¿‡ï¼š11/12
- å¹³å‡å»¶è¿Ÿï¼š78ms

## ğŸš¨ å¤±è´¥è¯¦æƒ…
1. test_api_timeout_error - å“åº”æ—¶é—´ > 5s
2. test_kafka_consumer_error - æ¶ˆè´¹è¶…æ—¶
...

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡
- 90åˆ†ä½å“åº”æ—¶é—´ï¼š450ms
- æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡ï¼š65%
- Kafkaæ¶ˆæ¯ååé‡ï¼š1200 msg/s
```

## ğŸ¤– AI ååŒè§„åˆ™

### 1. è‡ªåŠ¨æ£€æµ‹è§„åˆ™
- Claude Code è‡ªåŠ¨è¯»å– `INTEGRATION_RESULT_<date>.md`
- æ£€æµ‹è¿ç»­å¤±è´¥æ¨¡å¼
- è‡ªåŠ¨æ ‡æ³¨åœ¨ `TEST_ACTIVATION_KANBAN.md`

### 2. ä¼˜å…ˆä¿®å¤å»ºè®®
```markdown
### ä¿®å¤ä¼˜å…ˆçº§
1. ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼šæ•°æ®åº“å†™å…¥å¤±è´¥ã€Kafkaé˜»å¡
2. ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼šAPIå“åº”æ…¢ã€ç¼“å­˜æœªå‘½ä¸­
3. ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼šæ—¥å¿—æ ¼å¼ã€æ€§èƒ½è­¦å‘Š
```

### 3. è‡ªåŠ¨åŒ–å»ºè®®
```python
# Claude Code å¯ä»¥æ‰§è¡Œçš„è‡ªåŠ¨ä¿®å¤å»ºè®®
if integration_failures > 3:
    # å»ºè®®åˆ›å»ºä¿®å¤è„šæœ¬
    create_fix_script(failure_pattern)

if performance_issues:
    # å»ºè®®ä¼˜åŒ–
    suggest_performance_optimizations()
```

## ğŸ·ï¸ æ ‡ç­¾ç³»ç»Ÿ

ä½¿ç”¨ pytest æ ‡è®°æ¥åˆ†ç±»æµ‹è¯•ï¼š
```python
@pytest.mark.integration
@pytest.mark.database
@pytest.mark.kafka
@pytest.mark.redis
@pytest.mark.performance
@pytest.mark.slow  # > 1ç§’
```

è¿è¡Œç‰¹å®šæ ‡ç­¾ï¼š
```bash
# åªè¿è¡Œæ•°æ®åº“é›†æˆæµ‹è¯•
pytest tests/integration/ -m "database"

# æ’é™¤æ€§èƒ½æµ‹è¯•
pytest tests/integration/ -m "not performance"

# è¿è¡Œå¿«é€Ÿæµ‹è¯•
pytest tests/integration/ -m "not slow" -x
```

## ğŸ“… å®šæœŸæ‰§è¡Œå»ºè®®

### 1. CI/CDé›†æˆ
```yaml
# .github/workflows/integration-test.yml
name: Integration Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹

jobs:
  integration:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_pass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4
      - name: Start test services
        run: docker-compose -f docker-compose.test.yml up -d
      - name: Wait for services
        run: sleep 30
      - name: Run integration tests
        run: |
          pytest tests/integration/ \
            --junit-xml=integration-results.xml \
            --cov=src \
            --cov-report=xml
      - name: Stop test services
        run: docker-compose -f docker-compose.test.yml down
```

### 2. æœ¬åœ°å¼€å‘æµç¨‹
```bash
# æ¯æ—¥å¼€å§‹
make test-integration

# æäº¤å‰
make test-integration-quick

# å®Œæ•´æµ‹è¯•
make test-all
```

## ğŸ“ æµ‹è¯•æ¸…å•

### æ‰§è¡Œå‰æ£€æŸ¥
- [ ] DockeræœåŠ¡å·²å¯åŠ¨
- [ ] ç¯å¢ƒå˜é‡å·²é…ç½®
- [ ] æ•°æ®åº“å·²åˆå§‹åŒ–
- [ ] æµ‹è¯•æ•°æ®å·²åŠ è½½

### æ‰§è¡ŒåéªŒè¯
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æŠ¥å‘Šå·²ç”Ÿæˆ
- [ ] è¦†ç›–ç‡è¾¾æ ‡
- [ ] æ— é˜»å¡é—®é¢˜

## ğŸ”„ æ¸…ç†æ“ä½œ

```bash
# åœæ­¢æ‰€æœ‰æœåŠ¡
docker compose -f docker-compose.test.yml down

# æ¸…ç†æµ‹è¯•æ•°æ®
docker volume rm football_postgres_test_data

# æ¸…ç†ç¼“å­˜
pytest --cache-clear

# æ¸…ç†æŠ¥å‘Š
rm -rf reports/* htmlcov/
```

---

**ç»´æŠ¤è¯´æ˜ï¼š**
- æ¯æ¬¡æµ‹è¯•åæ›´æ–°æ­¤æ–‡æ¡£
- æ–°å¢é›†æˆæµ‹è¯•æ—¶æ›´æ–°èŒƒå›´è¯´æ˜
- ä¿æŒç¯å¢ƒå˜é‡åŒæ­¥æ›´æ–°
