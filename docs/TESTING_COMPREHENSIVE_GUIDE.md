# æµ‹è¯•ç»¼åˆæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

è¶³çƒæ¯”èµ›ç»“æœé¢„æµ‹ç³»ç»Ÿçš„å®Œæ•´æµ‹è¯•æŒ‡å—ï¼Œæ¶µç›–å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€ç«¯åˆ°ç«¯æµ‹è¯•å’Œæ€§èƒ½æµ‹è¯•çš„æœ€ä½³å®è·µã€‚

## ğŸ§ª æµ‹è¯•æ¶æ„

### æµ‹è¯•é‡‘å­—å¡”

```
    /\
   /  \     E2E Tests (2%)
  /____\
 /      \   Integration Tests (12%)
/________\  Unit Tests (85%)
```

### æµ‹è¯•åˆ†ç±»

| ç±»å‹ | å æ¯” | ç›®æ ‡ | å·¥å…· |
|------|------|------|------|
| **å•å…ƒæµ‹è¯•** | 85% | æµ‹è¯•å•ä¸ªå‡½æ•°/ç±» | pytest, unittest.mock |
| **é›†æˆæµ‹è¯•** | 12% | æµ‹è¯•ç»„ä»¶äº¤äº’ | pytest, testcontainers |
| **ç«¯åˆ°ç«¯æµ‹è¯•** | 2% | å®Œæ•´ç”¨æˆ·æµç¨‹ | Playwright, Selenium |
| **æ€§èƒ½æµ‹è¯•** | 1% | åŸºå‡†æµ‹è¯•å’Œæ€§èƒ½åˆ†æ | pytest-benchmark, locust |

## ğŸ—ï¸ æµ‹è¯•é¡¹ç›®ç»“æ„

```
tests/
â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯• (85%)
â”‚   â”œâ”€â”€ api/                # APIå±‚æµ‹è¯•
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—æµ‹è¯•
â”‚   â”œâ”€â”€ database/           # æ•°æ®åº“æµ‹è¯•
â”‚   â”œâ”€â”€ domain/             # é¢†åŸŸé€»è¾‘æµ‹è¯•
â”‚   â”œâ”€â”€ services/           # ä¸šåŠ¡æœåŠ¡æµ‹è¯•
â”‚   â””â”€â”€ utils/              # å·¥å…·ç±»æµ‹è¯•
â”œâ”€â”€ integration/            # é›†æˆæµ‹è¯• (12%)
â”‚   â”œâ”€â”€ api/                # APIé›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ database/           # æ•°æ®åº“é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ external/           # å¤–éƒ¨æœåŠ¡é›†æˆæµ‹è¯•
â”œâ”€â”€ e2e/                    # ç«¯åˆ°ç«¯æµ‹è¯• (2%)
â”‚   â”œâ”€â”€ user_workflows/     # ç”¨æˆ·å·¥ä½œæµæµ‹è¯•
â”‚   â””â”€â”€ api_workflows/      # APIå·¥ä½œæµæµ‹è¯•
â”œâ”€â”€ performance/            # æ€§èƒ½æµ‹è¯• (1%)
â”‚   â”œâ”€â”€ benchmarks/         # åŸºå‡†æµ‹è¯•
â”‚   â””â”€â”€ load/               # è´Ÿè½½æµ‹è¯•
â”œâ”€â”€ fixtures/               # æµ‹è¯•æ•°æ®å¤¹å…·
â”œâ”€â”€ conftest.py            # pytesté…ç½®
â””â”€â”€ requirements-test.txt   # æµ‹è¯•ä¾èµ–
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…æµ‹è¯•ä¾èµ–
make install

# 2. ç¯å¢ƒæ£€æŸ¥
make env-check

# 3. æ™ºèƒ½ä¿®å¤ï¼ˆè§£å†³ç¯å¢ƒé—®é¢˜ï¼‰
python3 scripts/smart_quality_fixer.py

# 4. éªŒè¯æµ‹è¯•ç¯å¢ƒ
pytest tests/unit/utils/test_date_utils.py::test_format_date_iso -v
```

### å¸¸ç”¨æµ‹è¯•å‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•
make test.unit

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
pytest tests/unit/utils/ -v

# è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶
pytest tests/unit/core/test_di.py -v

# è¿è¡Œå•ä¸ªæµ‹è¯•æ–¹æ³•
pytest tests/unit/api/test_health.py::test_health_check_basic -v

# æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š
make coverage

# è¿è¡Œæ€§èƒ½æµ‹è¯•
pytest tests/performance/ -v

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/ -v
```

## ğŸ“Š æµ‹è¯•æ ‡è®°ç³»ç»Ÿ

é¡¹ç›®ä½¿ç”¨47ä¸ªæ ‡å‡†åŒ–æµ‹è¯•æ ‡è®°ï¼Œæ”¯æŒç²¾ç¡®çš„æµ‹è¯•é€‰æ‹©ï¼š

### æ ¸å¿ƒæ ‡è®°

```bash
# æŒ‰æµ‹è¯•ç±»å‹
pytest -m "unit"              # å•å…ƒæµ‹è¯• (85%)
pytest -m "integration"       # é›†æˆæµ‹è¯• (12%)
pytest -m "e2e"               # ç«¯åˆ°ç«¯æµ‹è¯• (2%)
pytest -m "performance"       # æ€§èƒ½æµ‹è¯• (1%)

# æŒ‰ä¼˜å…ˆçº§
pytest -m "critical"          # å…³é”®åŠŸèƒ½æµ‹è¯•
pytest -m "high"              # é«˜ä¼˜å…ˆçº§æµ‹è¯•
pytest -m "medium"            # ä¸­ç­‰ä¼˜å…ˆçº§æµ‹è¯•
pytest -m "low"               # ä½ä¼˜å…ˆçº§æµ‹è¯•

# æŒ‰åŠŸèƒ½åŸŸ
pytest -m "api and critical"  # APIå…³é”®åŠŸèƒ½æµ‹è¯•
pytest -m "domain or services" # ä¸šåŠ¡é€»è¾‘æµ‹è¯•
pytest -m "database"           # æ•°æ®åº“ç›¸å…³æµ‹è¯•
pytest -m "cache"              # ç¼“å­˜ç›¸å…³æµ‹è¯•
pytest -m "auth"               # è®¤è¯ç›¸å…³æµ‹è¯•
pytest -m "utils"              # å·¥å…·æ¨¡å—æµ‹è¯•
pytest -m "core"               # æ ¸å¿ƒæ¨¡å—æµ‹è¯•
```

### Smart Testsç»„åˆ

```bash
# æ ¸å¿ƒç¨³å®šæµ‹è¯• - æ‰§è¡Œæ—¶é—´<2åˆ†é’Ÿï¼Œé€šè¿‡ç‡>90%
pytest tests/unit/utils tests/unit/cache tests/unit/core -v --maxfail=20
```

## ğŸ¯ å•å…ƒæµ‹è¯•æœ€ä½³å®è·µ

### æµ‹è¯•å‘½åè§„èŒƒ

```python
class TestClassName:
    def test_method_scenario_expected_result(self):
        """æµ‹è¯•æ–¹æ³•_åœºæ™¯_æœŸæœ›ç»“æœ"""
        pass

# ç¤ºä¾‹
class TestPredictionService:
    def test_create_prediction_valid_data_success(self):
        """æµ‹è¯•åˆ›å»ºé¢„æµ‹_æœ‰æ•ˆæ•°æ®_æˆåŠŸ"""
        pass

    def test_create_prediction_invalid_data_raises_validation_error(self):
        """æµ‹è¯•åˆ›å»ºé¢„æµ‹_æ— æ•ˆæ•°æ®_æŠ›å‡ºéªŒè¯é”™è¯¯"""
        pass
```

### æµ‹è¯•ç»“æ„ (AAAæ¨¡å¼)

```python
def test_user_service_create_user_success():
    # Arrange (å‡†å¤‡)
    user_data = {
        "email": "test@example.com",
        "username": "testuser",
        "password": "SecurePass123!"
    }
    user_service = UserService()

    # Act (æ‰§è¡Œ)
    result = user_service.create_user(user_data)

    # Assert (æ–­è¨€)
    assert result["email"] == user_data["email"]
    assert result["username"] == user_data["username"]
    assert "id" in result
    assert "password" not in result  # å¯†ç ä¸åº”è¿”å›
```

### Mockå’ŒFixtureä½¿ç”¨

```python
import pytest
from unittest.mock import Mock, patch

@pytest.fixture
def mock_database():
    """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥"""
    return Mock()

@pytest.fixture
def user_service(mock_database):
    """åˆ›å»ºç”¨æˆ·æœåŠ¡å®ä¾‹"""
    return UserService(database=mock_database)

def test_get_user_by_id_found(user_service, mock_database):
    # è®¾ç½®mockè¿”å›å€¼
    mock_database.get_user.return_value = {
        "id": 1,
        "email": "test@example.com",
        "username": "testuser"
    }

    # æ‰§è¡Œæµ‹è¯•
    result = user_service.get_user_by_id(1)

    # éªŒè¯ç»“æœå’Œmockè°ƒç”¨
    assert result["id"] == 1
    mock_database.get_user.assert_called_once_with(1)

# ä½¿ç”¨patchè£…é¥°å™¨
@patch('src.services.external.weather_api.get_weather')
def test_prediction_service_with_weather(mock_weather_api):
    mock_weather_api.return_value = {"temperature": 25, "humidity": 60}

    service = PredictionService()
    result = service.create_prediction_with_weather(match_data)

    assert "weather" in result
    mock_weather_api.assert_called_once()
```

### å¼‚æ­¥æµ‹è¯•

```python
import pytest
import asyncio
from unittest.mock import AsyncMock

@pytest.mark.asyncio
async def test_async_service_process_data():
    # å‡†å¤‡
    async_service = AsyncService()
    test_data = {"value": 42}

    # æ‰§è¡Œ
    result = await async_service.process_data(test_data)

    # æ–­è¨€
    assert result["processed"] is True
    assert result["original_value"] == 42

@pytest.mark.asyncio
async def test_async_service_with_mock():
    # å‡†å¤‡
    mock_async_client = AsyncMock()
    mock_async_client.fetch.return_value = {"status": "success"}

    service = AsyncService(client=mock_async_client)

    # æ‰§è¡Œ
    result = await service.fetch_external_data()

    # æ–­è¨€
    assert result["status"] == "success"
    mock_async_client.fetch.assert_called_once()
```

## ğŸ”— é›†æˆæµ‹è¯•æœ€ä½³å®è·µ

### æ•°æ®åº“é›†æˆæµ‹è¯•

```python
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.database.base import Base
from src.services.prediction import PredictionService

@pytest.fixture(scope="function")
def test_db():
    """åˆ›å»ºæµ‹è¯•æ•°æ®åº“"""
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    SessionLocal = sessionmaker(bind=engine)
    session = SessionLocal()
    yield session
    session.close()

@pytest.mark.integration
def test_prediction_service_crud_operations(test_db):
    """æµ‹è¯•é¢„æµ‹æœåŠ¡çš„CRUDæ“ä½œ"""
    service = PredictionService(db_session=test_db)

    # åˆ›å»º
    prediction_data = {
        "match_id": 1,
        "predicted_result": "home_win",
        "confidence": 0.75
    }
    created = service.create_prediction(prediction_data)
    assert created.id is not None

    # è¯»å–
    retrieved = service.get_prediction(created.id)
    assert retrieved.predicted_result == "home_win"

    # æ›´æ–°
    updated = service.update_prediction(created.id, {"confidence": 0.80})
    assert updated.confidence == 0.80

    # åˆ é™¤
    service.delete_prediction(created.id)
    with pytest.raises(Exception):
        service.get_prediction(created.id)
```

### APIé›†æˆæµ‹è¯•

```python
import pytest
from fastapi.testclient import TestClient
from src.main import app

@pytest.fixture
def client():
    """åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯"""
    return TestClient(app)

@pytest.mark.integration
def test_prediction_api_full_workflow(client):
    """æµ‹è¯•é¢„æµ‹APIçš„å®Œæ•´å·¥ä½œæµ"""
    # åˆ›å»ºé¢„æµ‹
    prediction_data = {
        "match_id": 123,
        "predicted_result": "draw",
        "confidence": 0.65
    }
    response = client.post("/api/v1/predictions", json=prediction_data)
    assert response.status_code == 201
    created_prediction = response.json()

    # è·å–é¢„æµ‹
    response = client.get(f"/api/v1/predictions/{created_prediction['id']}")
    assert response.status_code == 200
    retrieved = response.json()
    assert retrieved["predicted_result"] == "draw"

    # æ›´æ–°é¢„æµ‹
    update_data = {"confidence": 0.70}
    response = client.patch(f"/api/v1/predictions/{created_prediction['id']}", json=update_data)
    assert response.status_code == 200
    updated = response.json()
    assert updated["confidence"] == 0.70

    # åˆ é™¤é¢„æµ‹
    response = client.delete(f"/api/v1/predictions/{created_prediction['id']}")
    assert response.status_code == 204

    # éªŒè¯åˆ é™¤
    response = client.get(f"/api/v1/predictions/{created_prediction['id']}")
    assert response.status_code == 404
```

## ğŸš€ ç«¯åˆ°ç«¯æµ‹è¯•æœ€ä½³å®è·µ

### ç”¨æˆ·å·¥ä½œæµæµ‹è¯•

```python
import pytest
from playwright.sync_api import Page, expect

@pytest.mark.e2e
def test_user_prediction_workflow(page: Page):
    """æµ‹è¯•ç”¨æˆ·å®Œæ•´é¢„æµ‹å·¥ä½œæµ"""
    # 1. ç”¨æˆ·ç™»å½•
    page.goto("/login")
    page.fill("[data-testid=email]", "user@example.com")
    page.fill("[data-testid=password]", "password123")
    page.click("[data-testid=login-button]")

    # 2. å¯¼èˆªåˆ°é¢„æµ‹é¡µé¢
    page.click("[data-testid=predictions-nav]")
    expect(page).to_have_url("/predictions")

    # 3. åˆ›å»ºé¢„æµ‹
    page.click("[data-testid=new-prediction-button]")
    page.select_option("[data-testid=match-select]", "123")
    page.select_option("[data-testid=result-select]", "home_win")
    page.fill("[data-testid=confidence-input]", "75")
    page.click("[data-testid=save-prediction-button]")

    # 4. éªŒè¯é¢„æµ‹å·²åˆ›å»º
    expect(page.locator("[data-testid=prediction-success]")).to_be_visible()
    expect(page.locator("[data-testid=prediction-list]")).to_contain_text("home_win")
```

### APIå·¥ä½œæµæµ‹è¯•

```python
import pytest
import requests

@pytest.mark.e2e
def test_complete_prediction_api_workflow():
    """æµ‹è¯•å®Œæ•´çš„é¢„æµ‹APIå·¥ä½œæµ"""
    base_url = "http://localhost:8000"

    # 1. ç”¨æˆ·è®¤è¯
    auth_response = requests.post(f"{base_url}/auth/login", json={
        "email": "test@example.com",
        "password": "password123"
    })
    token = auth_response.json()["access_token"]
    headers = {"Authorization": f"Bearer {token}"}

    # 2. è·å–å¯ç”¨æ¯”èµ›
    matches_response = requests.get(f"{base_url}/api/v1/matches", headers=headers)
    matches = matches_response.json()
    assert len(matches) > 0

    # 3. åˆ›å»ºé¢„æµ‹
    prediction_data = {
        "match_id": matches[0]["id"],
        "predicted_result": "home_win",
        "confidence": 0.75
    }
    prediction_response = requests.post(
        f"{base_url}/api/v1/predictions",
        json=prediction_data,
        headers=headers
    )
    assert prediction_response.status_code == 201
    prediction = prediction_response.json()

    # 4. è·å–ç”¨æˆ·æ‰€æœ‰é¢„æµ‹
    user_predictions = requests.get(f"{base_url}/api/v1/predictions/my", headers=headers)
    predictions = user_predictions.json()
    assert any(p["id"] == prediction["id"] for p in predictions)
```

## âš¡ æ€§èƒ½æµ‹è¯•æœ€ä½³å®è·µ

### åŸºå‡†æµ‹è¯•

```python
import pytest
from src.services.prediction import PredictionService

@pytest.mark.performance
def test_prediction_service_performance_benchmark():
    """æµ‹è¯•é¢„æµ‹æœåŠ¡æ€§èƒ½åŸºå‡†"""
    service = PredictionService()
    test_data = {
        "match_id": 123,
        "predicted_result": "home_win",
        "confidence": 0.75
    }

    # ä½¿ç”¨pytest-benchmark
    result = service.create_prediction(test_data)

    assert result["id"] is not None

    # æµ‹è¯•å“åº”æ—¶é—´
    start_time = time.time()
    for i in range(100):
        service.create_prediction({
            **test_data,
            "match_id": test_data["match_id"] + i
        })
    end_time = time.time()

    # 100æ¬¡æ“ä½œåº”åœ¨1ç§’å†…å®Œæˆ
    assert (end_time - start_time) < 1.0
```

### è´Ÿè½½æµ‹è¯•

```python
import pytest
import asyncio
import aiohttp

@pytest.mark.performance
async def test_api_concurrent_requests():
    """æµ‹è¯•APIå¹¶å‘è¯·æ±‚æ€§èƒ½"""
    base_url = "http://localhost:8000"

    async def make_request(session, url):
        async with session.get(url) as response:
            return await response.json()

    async with aiohttp.ClientSession() as session:
        # å¹¶å‘æ‰§è¡Œ50ä¸ªè¯·æ±‚
        tasks = [
            make_request(session, f"{base_url}/health")
            for _ in range(50)
        ]
        results = await asyncio.gather(*tasks)

        # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
        assert len(results) == 50
        for result in results:
            assert result["status"] == "healthy"
```

## ğŸ“ˆ è¦†ç›–ç‡ç®¡ç†

### è¦†ç›–ç‡é…ç½®

pytest.ini é…ç½®ï¼š

```ini
[tool:pytest]
addopts =
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-fail-under=30
    --cov-config=pyproject.toml
```

pyproject.toml é…ç½®ï¼š

```toml
[tool.coverage.run]
source = ["src"]
omit = [
    "*/tests/*",
    "*/migrations/*",
    "*/__pycache__/*",
    "*/venv/*",
    "*/env/*"
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError"
]
```

### è¦†ç›–ç‡å‘½ä»¤

```bash
# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
make coverage

# æŸ¥çœ‹HTMLæŠ¥å‘Š
open htmlcov/index.html

# æ£€æŸ¥ç‰¹å®šæ¨¡å—è¦†ç›–ç‡
pytest tests/unit/utils/ --cov=src.utils --cov-report=term-missing

# è®¾ç½®æœ€ä½è¦†ç›–ç‡è¦æ±‚
pytest --cov=src --cov-fail-under=30
```

## ğŸ› ï¸ æµ‹è¯•å·¥å…·å’Œé…ç½®

### pytesté…ç½® (conftest.py)

```python
import pytest
import asyncio
from unittest.mock import AsyncMock

@pytest.fixture(scope="session")
def event_loop():
    """åˆ›å»ºäº‹ä»¶å¾ªç¯ç”¨äºå¼‚æ­¥æµ‹è¯•"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def mock_redis():
    """æ¨¡æ‹ŸRedisè¿æ¥"""
    redis_mock = AsyncMock()
    redis_mock.get.return_value = None
    redis_mock.set.return_value = True
    redis_mock.delete.return_value = 1
    return redis_mock

@pytest.fixture
def mock_database_session():
    """æ¨¡æ‹Ÿæ•°æ®åº“ä¼šè¯"""
    session_mock = AsyncMock()
    session_mock.add.return_value = None
    session_mock.commit.return_value = None
    session_mock.refresh.return_value = None
    return session_mock
```

### å¸¸ç”¨æµ‹è¯•å·¥å…·

```bash
# æµ‹è¯•æ•°æ®ç”Ÿæˆ
pip install factory_boy faker

# HTTPæµ‹è¯•
pip install httpx

# å¼‚æ­¥æµ‹è¯•
pip install pytest-asyncio

# æ€§èƒ½æµ‹è¯•
pip install pytest-benchmark

# Mockå·¥å…·
pip install responses pytest-mock

# æµ‹è¯•è¦†ç›–ç‡
pip install pytest-cov
```

## ğŸ” æµ‹è¯•è°ƒè¯•

### è°ƒè¯•å¤±è´¥çš„æµ‹è¯•

```bash
# è¯¦ç»†è¾“å‡º
pytest tests/unit/core/test_di.py::TestDI::test_container_resolve -v -s

# è¿›å…¥è°ƒè¯•å™¨
pytest tests/unit/core/test_di.py::TestDI::test_container_resolve --pdb

# åªè¿è¡Œå¤±è´¥çš„æµ‹è¯•
pytest --lf

# åœåœ¨ç¬¬ä¸€ä¸ªå¤±è´¥å¤„
pytest -x

# æ˜¾ç¤ºæœ¬åœ°å˜é‡
pytest tests/unit/core/test_di.py -v --tb=short
```

### æµ‹è¯•æ€§èƒ½åˆ†æ

```bash
# æœ€æ…¢çš„10ä¸ªæµ‹è¯•
pytest --durations=10

# æ€§èƒ½åˆ†æ
pytest --profile-svg
```

## ğŸ“‹ æµ‹è¯•æ£€æŸ¥æ¸…å•

### å•å…ƒæµ‹è¯•æ£€æŸ¥æ¸…å•

- [ ] æµ‹è¯•å‘½åéµå¾ª `test_method_scenario_expected_result` æ ¼å¼
- [ ] ä½¿ç”¨AAAæ¨¡å¼ï¼ˆArrange-Act-Assertï¼‰
- [ ] æ¯ä¸ªæµ‹è¯•åªéªŒè¯ä¸€ä¸ªè¡Œä¸º
- [ ] ä½¿ç”¨æè¿°æ€§çš„æ–­è¨€æ¶ˆæ¯
- [ ] Mockå¤–éƒ¨ä¾èµ–
- [ ] æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸æƒ…å†µ
- [ ] æµ‹è¯•è¦†ç›–ç‡æ»¡è¶³è¦æ±‚

### é›†æˆæµ‹è¯•æ£€æŸ¥æ¸…å•

- [ ] ä½¿ç”¨çœŸå®çš„æ•°æ®åº“è¿æ¥ï¼ˆæµ‹è¯•æ•°æ®åº“ï¼‰
- [ ] æµ‹è¯•ç»„ä»¶é—´çš„äº¤äº’
- [ ] æ¸…ç†æµ‹è¯•æ•°æ®
- [ ] æµ‹è¯•äº‹åŠ¡å›æ»š
- [ ] éªŒè¯æ•°æ®ä¸€è‡´æ€§

### APIæµ‹è¯•æ£€æŸ¥æ¸…å•

- [ ] æµ‹è¯•æ‰€æœ‰HTTPçŠ¶æ€ç 
- [ ] éªŒè¯è¾“å…¥æ•°æ®éªŒè¯
- [ ] æµ‹è¯•è®¤è¯å’Œæˆæƒ
- [ ] æµ‹è¯•é”™è¯¯å¤„ç†
- [ ] éªŒè¯å“åº”æ•°æ®æ ¼å¼

## ğŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: æµ‹è¯•æ•°æ®åº“è¿æ¥å¤±è´¥

```python
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨æµ‹è¯•æ•°æ®åº“é…ç½®
@pytest.fixture
def test_db():
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    yield engine
    Base.metadata.drop_all(engine)
```

### é—®é¢˜2: å¼‚æ­¥æµ‹è¯•ä¸æ‰§è¡Œ

```python
# è§£å†³æ–¹æ¡ˆï¼šæ·»åŠ pytestæ ‡è®°
@pytest.mark.asyncio
async def test_async_function():
    result = await async_function()
    assert result is not None
```

### é—®é¢˜3: Mockä¸ç”Ÿæ•ˆ

```python
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨æ­£ç¡®çš„patchè·¯å¾„
@patch('src.services.external.api_client.APIClient')
def test_service_with_mock(mock_api_client):
    # ä½¿ç”¨æœåŠ¡ç›¸å¯¹äºæµ‹è¯•æ–‡ä»¶çš„è·¯å¾„
    pass
```

## ğŸ“š å‚è€ƒèµ„æº

- [pytestå®˜æ–¹æ–‡æ¡£](https://docs.pytest.org/)
- [pytest-asyncioæ–‡æ¡£](https://pytest-asyncio.readthedocs.io/)
- [pytest-mockæ–‡æ¡£](https://pytest-mock.readthedocs.io/)
- [æµ‹è¯•è¦†ç›–ç‡æ–‡æ¡£](https://coverage.readthedocs.io/)

---

*æ–‡æ¡£ç‰ˆæœ¬: v1.0 | æœ€åæ›´æ–°: 2025-11-08 | ç»´æŠ¤è€…: Claude Code*