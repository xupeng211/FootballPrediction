# æŠ€æœ¯å†³ç­–è®°å½• (Architecture Decision Records)

## ğŸ“‹ ADR-001: é‡‡ç”¨å¼‚æ­¥æ¶æ„ (Async Architecture)

**çŠ¶æ€**: å·²æ¥å—
**æ—¥æœŸ**: 2024-01-15
**å†³ç­–è€…**: æ¶æ„å›¢é˜Ÿ

### ä¸Šä¸‹æ–‡
è¶³çƒé¢„æµ‹ç³»ç»Ÿéœ€è¦å¤„ç†å¤§é‡çš„å¹¶å‘è¯·æ±‚ï¼ŒåŒ…æ‹¬å®æ—¶æ•°æ®æ›´æ–°ã€é¢„æµ‹è®¡ç®—å’Œç”¨æˆ·äº¤äº’ã€‚ä¼ ç»Ÿçš„åŒæ­¥æ¶æ„åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹æ€§èƒ½ç“¶é¢ˆæ˜æ˜¾ã€‚

### å†³ç­–
é‡‡ç”¨Python asyncioå’Œasync/awaitè¯­æ³•ï¼Œæ„å»ºå…¨å¼‚æ­¥çš„Webåº”ç”¨æ¶æ„ã€‚

### ç†ç”±
1. **é«˜å¹¶å‘æ”¯æŒ**: å•çº¿ç¨‹äº‹ä»¶å¾ªç¯å¯ä»¥å¤„ç†æ•°åƒä¸ªå¹¶å‘è¿æ¥
2. **èµ„æºæ•ˆç‡**: ç›¸æ¯”çº¿ç¨‹æ± ï¼Œå¼‚æ­¥I/Oå ç”¨æ›´å°‘çš„ç³»ç»Ÿèµ„æº
3. **ç”Ÿæ€æˆç†Ÿ**: FastAPIã€SQLAlchemy 2.0ç­‰ä¸»æµæ¡†æ¶éƒ½æ”¯æŒå¼‚æ­¥
4. **æœªæ¥å…¼å®¹**: å¼‚æ­¥æ¶æ„æ›´é€‚é…ç°ä»£äº‘åŸç”Ÿç¯å¢ƒ

### åæœ
- âœ… **æ€§èƒ½æå‡**: å“åº”æ—¶é—´æ˜¾è‘—æ”¹å–„ï¼Œååé‡å¤§å¹…æå‡
- âœ… **èµ„æºèŠ‚çº¦**: æœåŠ¡å™¨èµ„æºä½¿ç”¨æ•ˆç‡æé«˜
- âš ï¸ **å­¦ä¹ æ›²çº¿**: å¼€å‘å›¢é˜Ÿéœ€è¦é€‚åº”å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼
- âš ï¸ **è°ƒè¯•å¤æ‚æ€§**: å¼‚æ­¥ä»£ç çš„è°ƒè¯•å’Œæµ‹è¯•ç›¸å¯¹å¤æ‚

### å®æ–½ç»†èŠ‚
```python
# å¼‚æ­¥WebæœåŠ¡ç¤ºä¾‹
@app.post("/predictions")
async def create_prediction(request: PredictionRequest):
    # å¼‚æ­¥æ•°æ®åº“æ“ä½œ
    async with get_async_session() as session:
        prediction = await prediction_service.create_async(session, request)

    # å¼‚æ­¥ç¼“å­˜æ›´æ–°
    await cache.set_async(f"prediction:{prediction.id}", prediction)

    # å¼‚æ­¥äº‹ä»¶å‘å¸ƒ
    await event_bus.publish_async(PredictionCreatedEvent(prediction))

    return prediction
```

---

## ğŸ“‹ ADR-002: é€‰æ‹©CQRSæ¶æ„æ¨¡å¼ (CQRS Pattern)

**çŠ¶æ€**: å·²æ¥å—
**æ—¥æœŸ**: 2024-01-20
**å†³ç­–è€…**: æ¶æ„å›¢é˜Ÿ

### ä¸Šä¸‹æ–‡
ç³»ç»Ÿéœ€è¦åŒæ—¶æ”¯æŒå¤æ‚çš„ä¸šåŠ¡å†™æ“ä½œå’Œé«˜æ€§èƒ½çš„è¯»æ“ä½œã€‚ä¼ ç»Ÿçš„CRUDæ¨¡å¼éš¾ä»¥ä¼˜åŒ–è¯»å†™æ€§èƒ½ï¼Œä¸”ä¸šåŠ¡é€»è¾‘å’Œæ•°æ®æŸ¥è¯¢é€»è¾‘æ··åˆåœ¨ä¸€èµ·ã€‚

### å†³ç­–
å®æ–½å‘½ä»¤æŸ¥è¯¢è´£ä»»åˆ†ç¦»ï¼ˆCQRSï¼‰æ¨¡å¼ï¼Œå°†è¯»æ“ä½œå’Œå†™æ“ä½œåˆ†ç¦»å¤„ç†ã€‚

### ç†ç”±
1. **æ€§èƒ½ä¼˜åŒ–**: è¯»æ“ä½œå’Œå†™æ“ä½œå¯ä»¥ç‹¬ç«‹ä¼˜åŒ–å’Œæ‰©å±•
2. **ä¸šåŠ¡æ¸…æ™°**: å‘½ä»¤å¤„ç†ä¸šåŠ¡é€»è¾‘ï¼ŒæŸ¥è¯¢ä¸“æ³¨æ•°æ®è·å–
3. **æ‰©å±•æ€§**: å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ•°æ®å­˜å‚¨æŠ€æœ¯å¤„ç†è¯»å†™
4. **äº‹ä»¶æº¯æº**: ä¸ºå®ç°äº‹ä»¶æº¯æºæ¶æ„å¥ å®šåŸºç¡€

### åæœ
- âœ… **æŸ¥è¯¢æ€§èƒ½**: ä¸“é—¨ä¼˜åŒ–çš„æŸ¥è¯¢å¤„ç†ï¼Œå“åº”æ—¶é—´æ›´å¿«
- âœ… **ä¸šåŠ¡ä¸€è‡´æ€§**: å‘½ä»¤å¤„ç†ä¿è¯ä¸šåŠ¡è§„åˆ™å’Œæ•°æ®ä¸€è‡´æ€§
- âœ… **å›¢é˜Ÿåä½œ**: è¯»å†™çš„å¼€å‘å¯ä»¥å¹¶è¡Œè¿›è¡Œ
- âš ï¸ **å¤æ‚åº¦å¢åŠ **: ç³»ç»Ÿæ¶æ„æ›´åŠ å¤æ‚ï¼Œéœ€è¦æ›´å¤šçš„ä»£ç 
- âš ï¸ **æ•°æ®åŒæ­¥**: è¯»å†™æ¨¡å‹çš„æ•°æ®åŒæ­¥éœ€è¦é¢å¤–å¤„ç†

### å®æ–½ç»†èŠ‚
```python
# å‘½ä»¤å¤„ç†å™¨
class CreatePredictionCommandHandler:
    async def handle(self, command: CreatePredictionCommand) -> Prediction:
        # ä¸šåŠ¡è§„åˆ™éªŒè¯
        if not self.validate_business_rules(command):
            raise BusinessException("ä¸šåŠ¡è§„åˆ™éªŒè¯å¤±è´¥")

        # åˆ›å»ºé¢†åŸŸå¯¹è±¡
        prediction = Prediction.create(command.data)

        # æŒä¹…åŒ–
        await self.repository.save_async(prediction)

        # å‘å¸ƒäº‹ä»¶
        await self.event_bus.publish_async(PredictionCreatedEvent(prediction))

        return prediction

# æŸ¥è¯¢å¤„ç†å™¨
class GetPredictionQueryHandler:
    async def handle(self, query: GetPredictionQuery) -> Prediction:
        # ä»ç¼“å­˜è·å–
        cached = await self.cache.get_async(f"prediction:{query.id}")
        if cached:
            return cached

        # ä»æ•°æ®åº“æŸ¥è¯¢
        prediction = await self.read_repository.find_by_id_async(query.id)

        # ç¼“å­˜ç»“æœ
        await self.cache.set_async(f"prediction:{query.id}", prediction, ttl=300)

        return prediction
```

---

## ğŸ“‹ ADR-003: ä½¿ç”¨Redisä½œä¸ºåˆ†å¸ƒå¼ç¼“å­˜ (Redis Distributed Cache)

**çŠ¶æ€**: å·²æ¥å—
**æ—¥æœŸ**: 2024-02-01
**å†³ç­–è€…**: æ¶æ„å›¢é˜Ÿ

### ä¸Šä¸‹æ–‡
ç³»ç»Ÿéœ€è¦é¢‘ç¹è®¿é—®é¢„æµ‹ç»“æœã€æ¯”èµ›æ•°æ®å’Œç”¨æˆ·ä¿¡æ¯ã€‚æ¯æ¬¡è¯·æ±‚éƒ½è®¿é—®æ•°æ®åº“ä¼šå¯¼è‡´æ€§èƒ½ç“¶é¢ˆï¼Œä¸”æ•°æ®åº“æˆä¸ºç³»ç»Ÿçš„å•ç‚¹æ•…éšœã€‚

### å†³ç­–
é‡‡ç”¨Redisä½œä¸ºåˆ†å¸ƒå¼ç¼“å­˜å±‚ï¼Œå®ç°å¤šçº§ç¼“å­˜ç­–ç•¥ã€‚

### ç†ç”±
1. **é«˜æ€§èƒ½**: Rediså†…å­˜æ•°æ®åº“æä¾›æ¯«ç§’çº§å“åº”æ—¶é—´
2. **æ•°æ®ç»“æ„ä¸°å¯Œ**: æ”¯æŒå­—ç¬¦ä¸²ã€å“ˆå¸Œã€åˆ—è¡¨ã€é›†åˆç­‰å¤šç§æ•°æ®ç»“æ„
3. **æŒä¹…åŒ–**: æ”¯æŒRDBå’ŒAOFä¸¤ç§æŒä¹…åŒ–æ–¹å¼
4. **é›†ç¾¤æ”¯æŒ**: Redis Clusteræä¾›é«˜å¯ç”¨å’Œæ°´å¹³æ‰©å±•
5. **ç”Ÿæ€æˆç†Ÿ**: Pythonæœ‰æˆç†Ÿçš„Rediså®¢æˆ·ç«¯åº“

### åæœ
- âœ… **æ€§èƒ½æå‡**: ç¼“å­˜å‘½ä¸­æ—¶å“åº”æ—¶é—´ä»æ¯«ç§’çº§é™ä½åˆ°å¾®ç§’çº§
- âœ… **å¯ç”¨æ€§**: ç¼“å­˜å±‚é™ä½äº†æ•°æ®åº“å‹åŠ›ï¼Œæé«˜ç³»ç»Ÿæ•´ä½“å¯ç”¨æ€§
- âœ… **æ‰©å±•æ€§**: Redisé›†ç¾¤æ”¯æŒæ°´å¹³æ‰©å±•
- âš ï¸ **æ•°æ®ä¸€è‡´æ€§**: éœ€è¦å¤„ç†ç¼“å­˜ä¸æ•°æ®åº“çš„æ•°æ®ä¸€è‡´æ€§é—®é¢˜
- âš ï¸ **è¿ç»´å¤æ‚**: Redisé›†ç¾¤çš„è¿ç»´å’Œç›‘æ§éœ€è¦é¢å¤–å·¥ä½œ

### å®æ–½ç»†èŠ‚
```python
# ç¼“å­˜ç®¡ç†å™¨
class CacheManager:
    def __init__(self, redis_pool):
        self.redis = redis_pool
        self.default_ttl = 3600  # 1å°æ—¶

    async def get_async(self, key: str) -> Optional[Any]:
        try:
            data = await self.redis.get(key)
            if data:
                return json.loads(data)
            return None
        except Exception as e:
            logger.error(f"ç¼“å­˜è·å–å¤±è´¥: {e}")
            return None

    async def set_async(self, key: str, value: Any, ttl: Optional[int] = None):
        try:
            ttl = ttl or self.default_ttl
            data = json.dumps(value, default=str)
            await self.redis.setex(key, ttl, data)
        except Exception as e:
            logger.error(f"ç¼“å­˜è®¾ç½®å¤±è´¥: {e}")

    # ç¼“å­˜å¤±æ•ˆç­–ç•¥
    async def invalidate_pattern(self, pattern: str):
        keys = await self.redis.keys(pattern)
        if keys:
            await self.redis.delete(*keys)

# ç¼“å­˜è£…é¥°å™¨
@cache_result(ttl=1800)  # 30åˆ†é’Ÿ
async def get_prediction_stats(match_id: int) -> Dict:
    # å¤æ‚çš„ç»Ÿè®¡è®¡ç®—
    stats = await calculate_complex_stats(match_id)
    return stats
```

---

## ğŸ“‹ ADR-004: å®ç°é¢†åŸŸé©±åŠ¨è®¾è®¡ (Domain-Driven Design)

**çŠ¶æ€**: å·²æ¥å—
**æ—¥æœŸ**: 2024-02-15
**å†³ç­–è€…**: æ¶æ„å›¢é˜Ÿ

### ä¸Šä¸‹æ–‡
è¶³çƒé¢„æµ‹ç³»ç»Ÿçš„ä¸šåŠ¡é€»è¾‘å¤æ‚ï¼Œæ¶‰åŠå¤šä¸ªä¸šåŠ¡æ¦‚å¿µå’Œè§„åˆ™ã€‚ä¼ ç»Ÿçš„ä¸‰å±‚æ¶æ„ä¸­ï¼Œä¸šåŠ¡é€»è¾‘åˆ†æ•£åœ¨æœåŠ¡å±‚å’Œæ•°æ®è®¿é—®å±‚ï¼Œéš¾ä»¥ç»´æŠ¤å’Œæ‰©å±•ã€‚

### å†³ç­–
é‡‡ç”¨é¢†åŸŸé©±åŠ¨è®¾è®¡ï¼ˆDDDï¼‰ï¼Œå»ºç«‹æ¸…æ™°çš„é¢†åŸŸæ¨¡å‹å’Œä¸šåŠ¡è¾¹ç•Œã€‚

### ç†ç”±
1. **ä¸šåŠ¡ä¸­å¿ƒ**: ä»¥ä¸šåŠ¡é¢†åŸŸä¸ºä¸­å¿ƒï¼ŒæŠ€æœ¯ä¸ºä¸šåŠ¡æœåŠ¡
2. **çŸ¥è¯†å…±äº«**: ç»Ÿä¸€çš„é¢†åŸŸè¯­è¨€ä¾¿äºå›¢é˜Ÿæ²Ÿé€š
3. **å¤æ‚åº¦ç®¡ç†**: é€šè¿‡èšåˆæ ¹å’Œé¢†åŸŸæœåŠ¡ç®¡ç†ä¸šåŠ¡å¤æ‚åº¦
4. **å¯æµ‹è¯•æ€§**: é¢†åŸŸé€»è¾‘ç‹¬ç«‹äºåŸºç¡€è®¾æ–½ï¼Œæ˜“äºå•å…ƒæµ‹è¯•

### åæœ
- âœ… **ä¸šåŠ¡æ¸…æ™°**: é¢†åŸŸæ¨¡å‹æ¸…æ™°è¡¨è¾¾ä¸šåŠ¡æ¦‚å¿µå’Œè§„åˆ™
- âœ… **å¯ç»´æŠ¤æ€§**: ä¸šåŠ¡é€»è¾‘é›†ä¸­ï¼Œæ˜“äºç†è§£å’Œä¿®æ”¹
- âœ… **å›¢é˜Ÿåä½œ**: ç»Ÿä¸€çš„è¯­è¨€å’Œæ¨¡å‹ä¿ƒè¿›å›¢é˜Ÿåä½œ
- âš ï¸ **å­¦ä¹ æˆæœ¬**: DDDæ¦‚å¿µå’Œæ¨¡å¼éœ€è¦å›¢é˜Ÿå­¦ä¹ 
- âš ï¸ **è¿‡åº¦è®¾è®¡**: ç®€å•ä¸šåŠ¡å¯èƒ½å­˜åœ¨è¿‡åº¦è®¾è®¡é£é™©

### å®æ–½ç»†èŠ‚
```python
# é¢†åŸŸæ¨¡å‹ - æ¯”èµ›èšåˆæ ¹
class Match(AggregateRoot):
    def __init__(self, id: int, home_team: Team, away_team: Team, match_time: datetime):
        super().__init__(id)
        self.home_team = home_team
        self.away_team = away_team
        self.match_time = match_time
        self.status = MatchStatus.SCHEDULED
        self.score = MatchScore(0, 0)
        self.prediction_deadline = match_time - timedelta(hours=1)

    def update_score(self, home_score: int, away_score: int) -> None:
        """æ›´æ–°æ¯”åˆ†"""
        if self.status != MatchStatus.IN_PROGRESS:
            raise DomainException("æ¯”èµ›æœªè¿›è¡Œä¸­ï¼Œæ— æ³•æ›´æ–°æ¯”åˆ†")

        old_score = self.score
        self.score = MatchScore(home_score, away_score)

        # å‘å¸ƒé¢†åŸŸäº‹ä»¶
        self.add_domain_event(MatchScoreUpdatedEvent(
            match_id=self.id,
            old_score=old_score,
            new_score=self.score
        ))

    def can_predict(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥é¢„æµ‹"""
        return datetime.now() < self.prediction_deadline

# é¢†åŸŸæœåŠ¡
class PredictionService:
    def __init__(self, match_repository: MatchRepository):
        self.match_repository = match_repository

    async def create_prediction(self, user_id: int, match_id: int, prediction: PredictionData) -> Prediction:
        # è·å–æ¯”èµ›èšåˆ
        match = await self.match_repository.find_by_id(match_id)

        # ä¸šåŠ¡è§„åˆ™éªŒè¯
        if not match.can_predict():
            raise DomainException("å·²è¿‡é¢„æµ‹æˆªæ­¢æ—¶é—´")

        if await self.has_user_predicted(user_id, match_id):
            raise DomainException("ç”¨æˆ·å·²å¯¹æ­¤æ¯”èµ›è¿›è¡Œé¢„æµ‹")

        # åˆ›å»ºé¢„æµ‹èšåˆ
        prediction = Prediction.create(user_id, match_id, prediction)

        return prediction

# ä»“å‚¨æ¥å£
class MatchRepository(ABC):
    @abstractmethod
    async def find_by_id(self, match_id: int) -> Match:
        pass

    @abstractmethod
    async def save(self, match: Match) -> None:
        pass
```

---

## ğŸ“‹ ADR-005: ä½¿ç”¨PostgreSQLä½œä¸ºä¸»æ•°æ®åº“ (PostgreSQL Database)

**çŠ¶æ€**: å·²æ¥å—
**æ—¥æœŸ**: 2024-03-01
**å†³ç­–è€…**: æ¶æ„å›¢é˜Ÿ

### ä¸Šä¸‹æ–‡
ç³»ç»Ÿéœ€è¦ä¸€ä¸ªå¯é çš„å…³ç³»å‹æ•°æ®åº“æ¥å­˜å‚¨ä¸šåŠ¡æ•°æ®ï¼ŒåŒ…æ‹¬ç”¨æˆ·ä¿¡æ¯ã€æ¯”èµ›æ•°æ®ã€é¢„æµ‹ç»“æœç­‰ã€‚éœ€è¦åœ¨æ€§èƒ½ã€åŠŸèƒ½ã€å¯é æ€§ç­‰æ–¹é¢è¿›è¡Œæƒè¡¡ã€‚

### å†³ç­–
é€‰æ‹©PostgreSQLä½œä¸ºä¸»æ•°æ®åº“ï¼Œé…åˆä½¿ç”¨SQLAlchemy 2.0 ORMã€‚

### ç†ç”±
1. **ACIDç‰¹æ€§**: å®Œæ•´çš„äº‹åŠ¡æ”¯æŒï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§
2. **JSONæ”¯æŒ**: åŸç”Ÿæ”¯æŒJSONæ•°æ®ç±»å‹ï¼Œé€‚åˆå­˜å‚¨å¤æ‚ä¸šåŠ¡æ•°æ®
3. **æ€§èƒ½ä¼˜ç§€**: åœ¨å¤æ‚æŸ¥è¯¢å’Œå¤§æ•°æ®é‡åœºæ™¯ä¸‹æ€§èƒ½ä¼˜å¼‚
4. **æ‰©å±•æ€§**: æ”¯æŒå¤šç§æ‰©å±•ï¼Œå¦‚PostGISã€pg_stat_statementsç­‰
5. **å¼€æºç”Ÿæ€**: æ´»è·ƒçš„å¼€æºç¤¾åŒºå’Œä¸°å¯Œçš„å·¥å…·æ”¯æŒ

### åæœ
- âœ… **æ•°æ®ä¸€è‡´æ€§**: ACIDäº‹åŠ¡ä¿è¯æ•°æ®å®Œæ•´æ€§
- âœ… **æŸ¥è¯¢èƒ½åŠ›**: å¼ºå¤§çš„SQLæŸ¥è¯¢å’Œåˆ†æèƒ½åŠ›
- âœ… **æ‰©å±•æ€§**: ä¸°å¯Œçš„æ‰©å±•å’Œæ’ä»¶ç”Ÿæ€
- âœ… **å·¥å…·æ”¯æŒ**: æˆç†Ÿçš„å¼€å‘å’Œç®¡ç†å·¥å…·
- âš ï¸ **è¿ç»´å¤æ‚**: ç›¸æ¯”NoSQLæ•°æ®åº“ï¼Œè¿ç»´ç›¸å¯¹å¤æ‚
- âš ï¸ **æˆæœ¬**: åœ¨äº‘ç¯å¢ƒä¸­æˆæœ¬ç›¸å¯¹è¾ƒé«˜

### å®æ–½ç»†èŠ‚
```python
# æ•°æ®åº“æ¨¡å‹
class Base(DeclarativeBase):
    """æ•°æ®åº“æ¨¡å‹åŸºç±»"""
    pass

class Match(Base):
    __tablename__ = "matches"

    id = mapped_column(Integer, primary_key=True)
    home_team_id = mapped_column(Integer, ForeignKey("teams.id"), nullable=False)
    away_team_id = mapped_column(Integer, ForeignKey("teams.id"), nullable=False)
    league_id = mapped_column(Integer, ForeignKey("leagues.id"), nullable=False)
    match_time = mapped_column(DateTime, nullable=False)
    status = mapped_column(Enum(MatchStatus), nullable=False, default=MatchStatus.SCHEDULED)

    # JSONå­—æ®µå­˜å‚¨å¤æ‚æ•°æ®
    metadata = mapped_column(JSON, default=dict)
    statistics = mapped_column(JSON, default=dict)

    # å…³ç³»å®šä¹‰
    home_team = relationship("Team", foreign_keys=[home_team_id])
    away_team = relationship("Team", foreign_keys=[away_team_id])
    league = relationship("League")
    predictions = relationship("Prediction", back_populates="match")

    # ç´¢å¼•å®šä¹‰
    __table_args__ = (
        Index("idx_match_time_status", "match_time", "status"),
        Index("idx_team_match", "home_team_id", "away_team_id"),
        Index("idx_league_matches", "league_id", "match_time"),
    )

# å¼‚æ­¥æ•°æ®åº“ä¼šè¯
async def get_async_session() -> AsyncSession:
    """è·å–å¼‚æ­¥æ•°æ®åº“ä¼šè¯"""
    async with async_session_maker() as session:
        try:
            yield session
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()

# ä»“å‚¨å®ç°
class SqlAlchemyMatchRepository(MatchRepository):
    def __init__(self, session: AsyncSession):
        self.session = session

    async def find_by_id(self, match_id: int) -> Match:
        result = await self.session.execute(
            select(Match).where(Match.id == match_id).options(
                selectinload(Match.home_team),
                selectinload(Match.away_team),
                selectinload(Match.league)
            )
        )
        match = result.scalar_one_or_none()
        if not match:
            raise NotFoundException(f"æ¯”èµ› {match_id} ä¸å­˜åœ¨")
        return match

    async def save(self, match: Match) -> None:
        self.session.add(match)
        await self.session.flush()
        await self.session.refresh(match)
```

---

## ğŸ“‹ ADR-006: é‡‡ç”¨äº‹ä»¶é©±åŠ¨æ¶æ„ (Event-Driven Architecture)

**çŠ¶æ€**: å·²æ¥å—
**æ—¥æœŸ**: 2024-03-15
**å†³ç­–è€…**: æ¶æ„å›¢é˜Ÿ

### ä¸Šä¸‹æ–‡
ç³»ç»Ÿä¸­æœ‰å¤šä¸ªä¸šåŠ¡åœºæ™¯éœ€è¦å¼‚æ­¥å¤„ç†ï¼Œå¦‚é¢„æµ‹ç»“æœçš„è®¡ç®—ã€ç”¨æˆ·é€šçŸ¥çš„å‘é€ã€ç»Ÿè®¡æ•°æ®çš„æ›´æ–°ç­‰ã€‚åŒæ­¥å¤„ç†ä¼šå¯¼è‡´å“åº”æ—¶é—´å˜é•¿ï¼Œä¸”ä¸åŒæœåŠ¡ä¹‹é—´çš„è€¦åˆåº¦é«˜ã€‚

### å†³ç­–
å®ç°äº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œé€šè¿‡é¢†åŸŸäº‹ä»¶å®ç°ç³»ç»Ÿçš„æ¾è€¦åˆå’Œå¼‚æ­¥å¤„ç†ã€‚

### ç†ç”±
1. **è§£è€¦åˆ**: å‘å¸ƒè€…å’Œè®¢é˜…è€…ä¹‹é—´æ¾è€¦åˆ
2. **å¼‚æ­¥å¤„ç†**: æé«˜ç³»ç»Ÿå“åº”æ—¶é—´å’Œååé‡
3. **å¯æ‰©å±•æ€§**: æ–°çš„äº‹ä»¶å¤„ç†å™¨å¯ä»¥è½»æ¾æ·»åŠ 
4. **æœ€ç»ˆä¸€è‡´æ€§**: é€‚åˆåˆ†å¸ƒå¼ç³»ç»Ÿçš„ä¸€è‡´æ€§è¦æ±‚

### åæœ
- âœ… **ç³»ç»Ÿè§£è€¦**: å„æ¨¡å—ä¹‹é—´é€šè¿‡äº‹ä»¶é€šä¿¡ï¼Œé™ä½è€¦åˆåº¦
- âœ… **æ€§èƒ½æå‡**: ä¸»æµç¨‹å¼‚æ­¥å¤„ç†ï¼Œå“åº”æ—¶é—´æ›´å¿«
- âœ… **å¯æ‰©å±•æ€§**: æ–°åŠŸèƒ½å¯ä»¥é€šè¿‡æ·»åŠ äº‹ä»¶å¤„ç†å™¨å®ç°
- âš ï¸ **å¤æ‚æ€§**: äº‹ä»¶æµè¿½è¸ªå’Œè°ƒè¯•ç›¸å¯¹å¤æ‚
- âš ï¸ **ä¸€è‡´æ€§**: æœ€ç»ˆä¸€è‡´æ€§éœ€è¦é¢å¤–çš„å¤„ç†æœºåˆ¶

### å®æ–½ç»†èŠ‚
```python
# é¢†åŸŸäº‹ä»¶åŸºç±»
class DomainEvent:
    def __init__(self, aggregate_id: str, occurred_at: datetime = None):
        self.aggregate_id = aggregate_id
        self.occurred_at = occurred_at or datetime.utcnow()
        self.event_id = str(uuid.uuid4())

    def to_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "aggregate_id": self.aggregate_id,
            "occurred_at": self.occurred_at.isoformat(),
            "event_type": self.__class__.__name__,
            "data": self.__dict__
        }

# å…·ä½“äº‹ä»¶
class PredictionCreatedEvent(DomainEvent):
    def __init__(self, prediction_id: int, user_id: int, match_id: int, prediction_data: Dict):
        super().__init__(f"prediction_{prediction_id}")
        self.prediction_id = prediction_id
        self.user_id = user_id
        self.match_id = match_id
        self.prediction_data = prediction_data

class MatchScoreUpdatedEvent(DomainEvent):
    def __init__(self, match_id: int, old_score: MatchScore, new_score: MatchScore):
        super().__init__(f"match_{match_id}")
        self.match_id = match_id
        self.old_score = old_score
        self.new_score = new_score

# äº‹ä»¶æ€»çº¿
class EventBus:
    def __init__(self):
        self.handlers: Dict[str, List[Callable]] = {}

    def subscribe(self, event_type: str, handler: Callable):
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        self.handlers[event_type].append(handler)

    async def publish(self, event: DomainEvent):
        event_type = event.__class__.__name__
        if event_type in self.handlers:
            tasks = []
            for handler in self.handlers[event_type]:
                tasks.append(self._handle_event(handler, event))
            await asyncio.gather(*tasks, return_exceptions=True)

    async def _handle_event(self, handler: Callable, event: DomainEvent):
        try:
            if asyncio.iscoroutinefunction(handler):
                await handler(event)
            else:
                handler(event)
        except Exception as e:
            logger.error(f"äº‹ä»¶å¤„ç†å¤±è´¥: {e}", exc_info=True)

# äº‹ä»¶å¤„ç†å™¨
class PredictionStatisticsHandler:
    async def handle(self, event: PredictionCreatedEvent):
        """å¤„ç†é¢„æµ‹åˆ›å»ºäº‹ä»¶ï¼Œæ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        # å¼‚æ­¥æ›´æ–°ç”¨æˆ·é¢„æµ‹ç»Ÿè®¡
        await update_user_prediction_stats(event.user_id)

        # å¼‚æ­¥æ›´æ–°æ¯”èµ›é¢„æµ‹ç»Ÿè®¡
        await update_match_prediction_stats(event.match_id)

        # å¼‚æ­¥å‘é€é€šçŸ¥
        await send_prediction_notification(event.user_id, event.prediction_id)

class PredictionAccuracyHandler:
    async def handle(self, event: MatchScoreUpdatedEvent):
        """å¤„ç†æ¯”åˆ†æ›´æ–°äº‹ä»¶ï¼Œè®¡ç®—é¢„æµ‹å‡†ç¡®ç‡"""
        # è·å–è¯¥æ¯”èµ›çš„æ‰€æœ‰é¢„æµ‹
        predictions = await get_predictions_by_match(event.match_id)

        # è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡
        for prediction in predictions:
            accuracy = calculate_prediction_accuracy(prediction, event.new_score)
            await update_prediction_accuracy(prediction.id, accuracy)

            # å¦‚æœå‡†ç¡®ç‡æœ‰æ˜¾è‘—å˜åŒ–ï¼Œå‘é€é€šçŸ¥
            if accuracy.is_significant_change():
                await send_accuracy_notification(prediction.user_id, accuracy)

# é¢†åŸŸæœåŠ¡ä¸­ä½¿ç”¨äº‹ä»¶
class PredictionService:
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus

    async def create_prediction(self, data: PredictionData) -> Prediction:
        # ä¸šåŠ¡é€»è¾‘å¤„ç†
        prediction = Prediction.create(data)

        # ä¿å­˜åˆ°æ•°æ®åº“
        await self.repository.save(prediction)

        # å‘å¸ƒé¢†åŸŸäº‹ä»¶
        event = PredictionCreatedEvent(
            prediction_id=prediction.id,
            user_id=prediction.user_id,
            match_id=prediction.match_id,
            prediction_data=data.dict()
        )
        await self.event_bus.publish(event)

        return prediction
```

---

## ğŸ“‹ æ€»ç»“

è¿™äº›æŠ€æœ¯å†³ç­–å…±åŒæ„å»ºäº†è¶³çƒé¢„æµ‹ç³»ç»Ÿçš„æŠ€æœ¯æ¶æ„åŸºç¡€ï¼š

1. **å¼‚æ­¥æ¶æ„**æä¾›äº†é«˜æ€§èƒ½çš„å¤„ç†èƒ½åŠ›
2. **CQRSæ¨¡å¼**ä¼˜åŒ–äº†è¯»å†™æ€§èƒ½å’Œä¸šåŠ¡é€»è¾‘åˆ†ç¦»
3. **Redisç¼“å­˜**æ˜¾è‘—æå‡äº†ç³»ç»Ÿå“åº”é€Ÿåº¦
4. **DDDè®¾è®¡**ç¡®ä¿äº†ä¸šåŠ¡é€»è¾‘çš„æ¸…æ™°å’Œå¯ç»´æŠ¤æ€§
5. **PostgreSQL**æä¾›äº†å¯é çš„æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢èƒ½åŠ›
6. **äº‹ä»¶é©±åŠ¨**å®ç°äº†ç³»ç»Ÿçš„è§£è€¦å’Œå¼‚æ­¥å¤„ç†

æ¯ä¸ªå†³ç­–éƒ½æœ‰å…¶æƒè¡¡å’Œåæœï¼Œä½†æ•´ä½“ä¸Šä¸ºç³»ç»Ÿæä¾›äº†è‰¯å¥½çš„æŠ€æœ¯åŸºç¡€ï¼Œæ”¯æŒç³»ç»Ÿçš„é•¿æœŸå‘å±•å’Œæ¼”è¿›ã€‚