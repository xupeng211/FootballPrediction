# è¶³çƒæ¯”èµ›ç»“æœé¢„æµ‹ç³»ç»Ÿ - ç³»ç»Ÿæ¶æ„æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](#1-ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ)
2. [æ¨¡å—è®¾è®¡è¯´æ˜](#2-æ¨¡å—è®¾è®¡è¯´æ˜)
3. [æ•°æ®åº“è®¾è®¡è‰æ¡ˆ](#3-æ•°æ®åº“è®¾è®¡è‰æ¡ˆ)
4. [å¼€å‘é˜¶æ®µè§„åˆ’](#4-å¼€å‘é˜¶æ®µè§„åˆ’)
5. [éƒ¨ç½²ä¸è¿ç»´æ¶æ„](#5-éƒ¨ç½²ä¸è¿ç»´æ¶æ„)
6. [æœªæ¥æ‰©å±•å»ºè®®](#6-æœªæ¥æ‰©å±•å»ºè®®)

---

## 1. ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### 1.1 æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "æ•°æ®æºå±‚"
        A1[API-Football]
        A2[OddsPortal API]
        A3[å®˜æ–¹èµ›äº‹æ•°æ®]
        A4[ç¬¬ä¸‰æ–¹ä½“è‚²æ•°æ®]
    end

    subgraph "æ•°æ®é‡‡é›†å±‚"
        B1[Scrapyçˆ¬è™«å¼•æ“]
        B2[APIæ•°æ®é‡‡é›†å™¨]
        B3[å®æ—¶æ•°æ®åŒæ­¥]
        B4[æ•°æ®é‡‡é›†è°ƒåº¦å™¨]
    end

    subgraph "æ•°æ®å¤„ç†å±‚"
        C1[æ•°æ®æ¸…æ´—æ¨¡å—]
        C2[æ•°æ®éªŒè¯æ¨¡å—]
        C3[ç‰¹å¾å·¥ç¨‹å¼•æ“]
        C4[æ•°æ®å­˜å‚¨ç®¡ç†]
    end

    subgraph "å­˜å‚¨å±‚"
        D1[(MySQL/PostgreSQL<br/>ä¸»æ•°æ®åº“)]
        D2[(Redis<br/>ç¼“å­˜å±‚)]
        D3[(æ–‡ä»¶å­˜å‚¨<br/>æ¨¡å‹&æ—¥å¿—)]
    end

    subgraph "æœºå™¨å­¦ä¹ å±‚"
        E1[XGBoostæ¨¡å‹]
        E2[LightGBMæ¨¡å‹]
        E3[æ¨¡å‹è®­ç»ƒå¼•æ“]
        E4[æ¨¡å‹è¯„ä¼°ç³»ç»Ÿ]
        E5[é¢„æµ‹æœåŠ¡å¼•æ“]
    end

    subgraph "æœåŠ¡å±‚"
        F1[FastAPIæœåŠ¡]
        F2[RESTful APIæ¥å£]
        F3[è®¤è¯æˆæƒæ¨¡å—]
        F4[ç›‘æ§å‘Šè­¦ç³»ç»Ÿ]
    end

    subgraph "å‰ç«¯å±•ç¤ºå±‚"
        G1[Vue.js/Reactå‰ç«¯]
        G2[EChartså¯è§†åŒ–]
        G3[å“åº”å¼UIç»„ä»¶]
        G4[å®æ—¶æ•°æ®å±•ç¤º]
    end

    subgraph "éƒ¨ç½²å±‚"
        H1[Dockerå®¹å™¨]
        H2[Kubernetesç¼–æ’]
        H3[è´Ÿè½½å‡è¡¡å™¨]
        H4[CI/CDæµæ°´çº¿]
    end

    A1 & A2 & A3 & A4 --> B1 & B2 & B3
    B1 & B2 & B3 --> B4
    B4 --> C1 & C2
    C1 & C2 --> C3
    C3 --> C4
    C4 --> D1 & D2 & D3
    D1 --> E1 & E2 & E3
    E3 --> E4
    E1 & E2 --> E5
    E5 --> F1
    F1 --> F2 & F3
    F2 --> G1
    G1 --> G2 & G3 & G4
    F1 --> H1
    H1 --> H2
    H2 --> H3
    H4 --> H1
```

### 1.2 æ•°æ®æµè¯´æ˜

ç³»ç»Ÿé‡‡ç”¨ç»å…¸çš„æ•°æ®æµæ°´çº¿æ¶æ„ï¼Œæ•°æ®ä»é‡‡é›†åˆ°é¢„æµ‹å±•ç¤ºçš„å®Œæ•´é“¾è·¯å¦‚ä¸‹ï¼š

#### è¾“å…¥é˜¶æ®µ

- **å¤šæºæ•°æ®é‡‡é›†**ï¼šé€šè¿‡APIå’Œçˆ¬è™«ä»å¤šä¸ªæ•°æ®æºï¼ˆAPI-Footballã€OddsPortalç­‰ï¼‰é‡‡é›†æ¯”èµ›æ•°æ®ã€çƒé˜Ÿä¿¡æ¯ã€å†å²æˆ˜ç»©ã€å®æ—¶èµ”ç‡ç­‰
- **æ•°æ®æ ‡å‡†åŒ–**ï¼šå°†ä¸åŒæ ¼å¼çš„æ•°æ®ç»Ÿä¸€è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼

#### å¤„ç†é˜¶æ®µ

- **æ•°æ®æ¸…æ´—**ï¼šå»é‡ã€è¡¥ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
- **ç‰¹å¾å·¥ç¨‹**ï¼šæå–çƒé˜Ÿå®åŠ›æŒ‡æ ‡ã€ä¸»å®¢åœºä¼˜åŠ¿ã€å†å²äº¤é”‹è®°å½•ã€ä¼¤ç—…æƒ…å†µç­‰ç‰¹å¾
- **æ•°æ®å­˜å‚¨**ï¼šç»“æ„åŒ–æ•°æ®å­˜å…¥å…³ç³»æ•°æ®åº“ï¼Œç¼“å­˜çƒ­ç‚¹æ•°æ®åˆ°Redis

#### å»ºæ¨¡é˜¶æ®µ

- **æ¨¡å‹è®­ç»ƒ**ï¼šä½¿ç”¨XGBoost/LightGBMå¯¹å†å²æ•°æ®è¿›è¡Œè®­ç»ƒ
- **æ¨¡å‹è¯„ä¼°**ï¼šé€šè¿‡äº¤å‰éªŒè¯ã€å›æµ‹ç­‰æ–¹å¼è¯„ä¼°æ¨¡å‹æ€§èƒ½
- **é¢„æµ‹ç”Ÿæˆ**ï¼šå¯¹å³å°†è¿›è¡Œçš„æ¯”èµ›ç”Ÿæˆé¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦

#### è¾“å‡ºé˜¶æ®µ

- **APIæœåŠ¡**ï¼šé€šè¿‡FastAPIæä¾›RESTfulæ¥å£
- **å‰ç«¯å±•ç¤º**ï¼šä½¿ç”¨Vue.js/Reactæ„å»ºç”¨æˆ·ç•Œé¢ï¼Œé€šè¿‡EChartså±•ç¤ºé¢„æµ‹ç»“æœå’Œç»Ÿè®¡åˆ†æ
- **å®æ—¶æ›´æ–°**ï¼šæ”¯æŒå®æ—¶æ•°æ®æ›´æ–°å’Œé¢„æµ‹ç»“æœåˆ·æ–°

---

## 2. æ¨¡å—è®¾è®¡è¯´æ˜

### 2.1 æ•°æ®é‡‡é›†æ¨¡å—

#### èŒè´£

- ä»å¤šä¸ªæ•°æ®æºé‡‡é›†è¶³çƒæ¯”èµ›ç›¸å…³æ•°æ®
- å®ç°å¢é‡é‡‡é›†å’Œå…¨é‡åŒæ­¥æœºåˆ¶
- å¤„ç†APIé™æµå’Œåçˆ¬è™«ç­–ç•¥
- ä¿è¯æ•°æ®é‡‡é›†çš„ç¨³å®šæ€§å’Œå®æ—¶æ€§

#### è¾“å…¥/è¾“å‡º

- **è¾“å…¥**ï¼šAPIç«¯ç‚¹é…ç½®ã€çˆ¬è™«ç›®æ ‡ç½‘ç«™ã€é‡‡é›†ä»»åŠ¡è°ƒåº¦é…ç½®
- **è¾“å‡º**ï¼šæ ‡å‡†åŒ–çš„æ¯”èµ›æ•°æ®ã€çƒé˜Ÿæ•°æ®ã€èµ”ç‡æ•°æ®ã€çƒå‘˜æ•°æ®

#### æ ¸å¿ƒç»„ä»¶

```
src/data_collection/
â”œâ”€â”€ collectors/
â”‚   â”œâ”€â”€ api_collector.py      # APIæ•°æ®é‡‡é›†å™¨
â”‚   â”œâ”€â”€ web_scraper.py        # ç½‘é¡µçˆ¬è™«
â”‚   â””â”€â”€ odds_collector.py     # èµ”ç‡æ•°æ®é‡‡é›†
â”œâ”€â”€ schedulers/
â”‚   â”œâ”€â”€ task_scheduler.py     # ä»»åŠ¡è°ƒåº¦å™¨
â”‚   â””â”€â”€ incremental_sync.py   # å¢é‡åŒæ­¥
â””â”€â”€ utils/
    â”œâ”€â”€ rate_limiter.py       # è®¿é—®é¢‘ç‡æ§åˆ¶
    â””â”€â”€ proxy_manager.py      # ä»£ç†IPç®¡ç†
```

#### ä¾èµ–å…³ç³»

- ä¾èµ–ï¼šå¤–éƒ¨æ•°æ®APIã€ä»£ç†æœåŠ¡ã€ä»»åŠ¡è°ƒåº¦æ¡†æ¶
- è¢«ä¾èµ–ï¼šæ•°æ®å­˜å‚¨æ¨¡å—ã€æ•°æ®æ¸…æ´—æ¨¡å—

#### æ‰©å±•æ–¹å‘

- æ”¯æŒæ›´å¤šæ•°æ®æºæ¥å…¥
- å®ç°åˆ†å¸ƒå¼é‡‡é›†æ¶æ„
- å¢åŠ å®æ—¶æµæ•°æ®é‡‡é›†èƒ½åŠ›

### 2.2 æ•°æ®å­˜å‚¨ä¸æ¸…æ´—æ¨¡å—

#### èŒè´£

- æ•°æ®è´¨é‡æ£€æŸ¥å’Œæ¸…æ´—å¤„ç†
- å»ºç«‹ç»Ÿä¸€çš„æ•°æ®å­˜å‚¨è§„èŒƒ
- å®ç°æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶
- æä¾›æ•°æ®è®¿é—®æ¥å£

#### è¾“å…¥/è¾“å‡º

- **è¾“å…¥**ï¼šåŸå§‹é‡‡é›†æ•°æ®ã€æ•°æ®è´¨é‡è§„åˆ™ã€æ¸…æ´—é…ç½®å‚æ•°
- **è¾“å‡º**ï¼šæ¸…æ´—åçš„ç»“æ„åŒ–æ•°æ®ã€æ•°æ®è´¨é‡æŠ¥å‘Šã€å¼‚å¸¸æ•°æ®è®°å½•

#### æ ¸å¿ƒç»„ä»¶

```
src/data_processing/
â”œâ”€â”€ cleaners/
â”‚   â”œâ”€â”€ data_validator.py     # æ•°æ®éªŒè¯å™¨
â”‚   â”œâ”€â”€ duplicate_remover.py  # å»é‡å¤„ç†
â”‚   â””â”€â”€ missing_handler.py    # ç¼ºå¤±å€¼å¤„ç†
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ database_manager.py   # æ•°æ®åº“ç®¡ç†
â”‚   â”œâ”€â”€ cache_manager.py      # ç¼“å­˜ç®¡ç†
â”‚   â””â”€â”€ backup_manager.py     # å¤‡ä»½ç®¡ç†
â””â”€â”€ transformers/
    â”œâ”€â”€ data_normalizer.py    # æ•°æ®æ ‡å‡†åŒ–
    â””â”€â”€ schema_mapper.py      # æ¨¡å¼æ˜ å°„
```

#### ä¾èµ–å…³ç³»

- ä¾èµ–ï¼šæ•°æ®é‡‡é›†æ¨¡å—ã€æ•°æ®åº“ç³»ç»Ÿã€ç¼“å­˜ç³»ç»Ÿ
- è¢«ä¾èµ–ï¼šç‰¹å¾å·¥ç¨‹æ¨¡å—ã€æ¨¡å‹è®­ç»ƒæ¨¡å—

#### æ‰©å±•æ–¹å‘

- å®ç°æµå¼æ•°æ®å¤„ç†
- å¢åŠ æ•°æ®è¡€ç¼˜è·Ÿè¸ªåŠŸèƒ½
- æ”¯æŒå¤šç§æ•°æ®æ ¼å¼è½¬æ¢

### 2.3 ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒæ¨¡å—

#### èŒè´£

- è®¾è®¡å’Œæå–é¢„æµ‹ç›¸å…³çš„ç‰¹å¾
- è®­ç»ƒå’Œä¼˜åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹
- å®ç°æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’ŒA/Bæµ‹è¯•
- æä¾›æ¨¡å‹æ€§èƒ½ç›‘æ§

#### è¾“å…¥/è¾“å‡º

- **è¾“å…¥**ï¼šæ¸…æ´—åçš„æ¯”èµ›æ•°æ®ã€çƒé˜Ÿæ•°æ®ã€å†å²ç»Ÿè®¡æ•°æ®
- **è¾“å‡º**ï¼šè®­ç»ƒå¥½çš„é¢„æµ‹æ¨¡å‹ã€ç‰¹å¾é‡è¦æ€§åˆ†æã€æ¨¡å‹è¯„ä¼°æŠ¥å‘Š

#### æ ¸å¿ƒç»„ä»¶

```
src/ml/
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ team_features.py      # çƒé˜Ÿç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ match_features.py     # æ¯”èµ›ç‰¹å¾å·¥ç¨‹
â”‚   â””â”€â”€ historical_features.py # å†å²æ•°æ®ç‰¹å¾
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ xgboost_model.py      # XGBoostæ¨¡å‹
â”‚   â”œâ”€â”€ lightgbm_model.py     # LightGBMæ¨¡å‹
â”‚   â””â”€â”€ ensemble_model.py     # é›†æˆæ¨¡å‹
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ model_trainer.py      # æ¨¡å‹è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ hyperparameter_tuner.py # è¶…å‚æ•°è°ƒä¼˜
â”‚   â””â”€â”€ cross_validator.py    # äº¤å‰éªŒè¯
â””â”€â”€ evaluation/
    â”œâ”€â”€ model_evaluator.py    # æ¨¡å‹è¯„ä¼°
    â””â”€â”€ performance_monitor.py # æ€§èƒ½ç›‘æ§
```

#### ä¾èµ–å…³ç³»

- ä¾èµ–ï¼šæ•°æ®å¤„ç†æ¨¡å—ã€æœºå™¨å­¦ä¹ åº“ï¼ˆXGBoostã€LightGBMï¼‰
- è¢«ä¾èµ–ï¼šé¢„æµ‹æœåŠ¡æ¨¡å—

#### æ‰©å±•æ–¹å‘

- å¼•å…¥æ·±åº¦å­¦ä¹ æ¨¡å‹
- å®ç°åœ¨çº¿å­¦ä¹ èƒ½åŠ›
- å¢åŠ ç‰¹å¾è‡ªåŠ¨å‘ç°åŠŸèƒ½

### 2.4 é¢„æµ‹æœåŠ¡æ¨¡å—

#### èŒè´£

- åŸºäºè®­ç»ƒæ¨¡å‹æä¾›é¢„æµ‹æœåŠ¡
- å®ç°å®æ—¶é¢„æµ‹APIæ¥å£
- ç®¡ç†é¢„æµ‹ç»“æœç¼“å­˜å’Œå†å²è®°å½•
- æä¾›é¢„æµ‹ç½®ä¿¡åº¦å’Œè§£é‡Šæ€§ä¿¡æ¯

#### è¾“å…¥/è¾“å‡º

- **è¾“å…¥**ï¼šé¢„æµ‹è¯·æ±‚ã€æ¯”èµ›ä¿¡æ¯ã€å®æ—¶æ•°æ®æ›´æ–°
- **è¾“å‡º**ï¼šé¢„æµ‹ç»“æœã€ç½®ä¿¡åº¦è¯„åˆ†ã€é¢„æµ‹è§£é‡Šä¿¡æ¯

#### æ ¸å¿ƒç»„ä»¶

```
src/prediction/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ prediction_service.py  # é¢„æµ‹æœåŠ¡æ ¸å¿ƒ
â”‚   â”œâ”€â”€ model_loader.py       # æ¨¡å‹åŠ è½½å™¨
â”‚   â””â”€â”€ result_formatter.py   # ç»“æœæ ¼å¼åŒ–
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ prediction_api.py     # é¢„æµ‹APIæ¥å£
â”‚   â”œâ”€â”€ batch_predictor.py    # æ‰¹é‡é¢„æµ‹
â”‚   â””â”€â”€ real_time_predictor.py # å®æ—¶é¢„æµ‹
â””â”€â”€ utils/
    â”œâ”€â”€ confidence_calculator.py # ç½®ä¿¡åº¦è®¡ç®—
    â””â”€â”€ explanation_generator.py # é¢„æµ‹è§£é‡Š
```

#### ä¾èµ–å…³ç³»

- ä¾èµ–ï¼šæœºå™¨å­¦ä¹ æ¨¡å—ã€ç¼“å­˜ç³»ç»Ÿã€æ•°æ®åº“ç³»ç»Ÿ
- è¢«ä¾èµ–ï¼šAPIæœåŠ¡å±‚ã€å‰ç«¯å±•ç¤ºæ¨¡å—

#### æ‰©å±•æ–¹å‘

- æ”¯æŒå¤šæ¨¡å‹èåˆé¢„æµ‹
- å®ç°é¢„æµ‹ç»“æœçš„å®æ—¶æ ¡å‡†
- å¢åŠ ç”¨æˆ·ä¸ªæ€§åŒ–é¢„æµ‹åŠŸèƒ½

### 2.5 å‰ç«¯å±•ç¤ºæ¨¡å—

#### èŒè´£

- æä¾›ç”¨æˆ·å‹å¥½çš„Webç•Œé¢
- å±•ç¤ºé¢„æµ‹ç»“æœå’Œæ•°æ®å¯è§†åŒ–
- å®ç°å“åº”å¼è®¾è®¡æ”¯æŒå¤šè®¾å¤‡è®¿é—®
- æä¾›å®æ—¶æ•°æ®æ›´æ–°å’Œäº¤äº’åŠŸèƒ½

#### è¾“å…¥/è¾“å‡º

- **è¾“å…¥**ï¼šAPIæ•°æ®ã€ç”¨æˆ·äº¤äº’äº‹ä»¶ã€å®æ—¶æ•°æ®æ¨é€
- **è¾“å‡º**ï¼šå¯è§†åŒ–å›¾è¡¨ã€ç”¨æˆ·ç•Œé¢ã€äº¤äº’åé¦ˆ

#### æ ¸å¿ƒç»„ä»¶

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ PredictionCard.vue    # é¢„æµ‹ç»“æœå¡ç‰‡
â”‚   â”‚   â”œâ”€â”€ MatchList.vue         # æ¯”èµ›åˆ—è¡¨
â”‚   â”‚   â””â”€â”€ StatisticsChart.vue   # ç»Ÿè®¡å›¾è¡¨
â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”œâ”€â”€ Dashboard.vue         # ä»ªè¡¨æ¿
â”‚   â”‚   â”œâ”€â”€ MatchDetail.vue       # æ¯”èµ›è¯¦æƒ…
â”‚   â”‚   â””â”€â”€ Analytics.vue         # æ•°æ®åˆ†æ
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.js                # APIæœåŠ¡
â”‚   â”‚   â””â”€â”€ websocket.js          # WebSocketè¿æ¥
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ chart-config.js       # å›¾è¡¨é…ç½®
â”‚       â””â”€â”€ data-formatter.js     # æ•°æ®æ ¼å¼åŒ–
```

#### ä¾èµ–å…³ç³»

- ä¾èµ–ï¼šVue.js/Reactæ¡†æ¶ã€ECharts/Plotlyã€APIæœåŠ¡
- è¢«ä¾èµ–ï¼šæœ€ç»ˆç”¨æˆ·

#### æ‰©å±•æ–¹å‘

- æ”¯æŒç§»åŠ¨ç«¯APPå¼€å‘
- å®ç°ä¸ªæ€§åŒ–ç”¨æˆ·ç•Œé¢
- å¢åŠ ç¤¾äº¤åˆ†äº«åŠŸèƒ½

### 2.6 å®¹å™¨åŒ–ä¸éƒ¨ç½²æ¨¡å—

#### èŒè´£

- å®ç°åº”ç”¨çš„å®¹å™¨åŒ–éƒ¨ç½²
- ç®¡ç†æœåŠ¡ç¼–æ’å’Œè´Ÿè½½å‡è¡¡
- æä¾›CI/CDæµæ°´çº¿æ”¯æŒ
- ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡

#### è¾“å…¥/è¾“å‡º

- **è¾“å…¥**ï¼šåº”ç”¨ä»£ç ã€éƒ¨ç½²é…ç½®ã€ç¯å¢ƒå˜é‡
- **è¾“å‡º**ï¼šè¿è¡Œä¸­çš„æœåŠ¡å®ä¾‹ã€ç›‘æ§æ•°æ®ã€éƒ¨ç½²æ—¥å¿—

#### æ ¸å¿ƒç»„ä»¶

```
deployment/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api        # APIæœåŠ¡é•œåƒ
â”‚   â”œâ”€â”€ Dockerfile.worker     # åå°ä»»åŠ¡é•œåƒ
â”‚   â””â”€â”€ Dockerfile.frontend   # å‰ç«¯åº”ç”¨é•œåƒ
â”œâ”€â”€ kubernetes/
â”‚   â”œâ”€â”€ api-deployment.yaml   # APIæœåŠ¡éƒ¨ç½²
â”‚   â”œâ”€â”€ database-config.yaml  # æ•°æ®åº“é…ç½®
â”‚   â””â”€â”€ ingress.yaml          # è´Ÿè½½å‡è¡¡é…ç½®
â”œâ”€â”€ ci-cd/
â”‚   â”œâ”€â”€ github-actions.yml    # CI/CDæµæ°´çº¿
â”‚   â””â”€â”€ deployment-script.sh  # éƒ¨ç½²è„šæœ¬
â””â”€â”€ monitoring/
    â”œâ”€â”€ prometheus-config.yml  # ç›‘æ§é…ç½®
    â””â”€â”€ grafana-dashboard.json # ä»ªè¡¨æ¿é…ç½®
```

#### ä¾èµ–å…³ç³»

- ä¾èµ–ï¼šDockerã€Kubernetesã€CI/CDå¹³å°
- è¢«ä¾èµ–ï¼šæ‰€æœ‰å…¶ä»–æ¨¡å—ï¼ˆæä¾›è¿è¡Œç¯å¢ƒï¼‰

#### æ‰©å±•æ–¹å‘

- å®ç°å¤šäº‘éƒ¨ç½²æ”¯æŒ
- å¢åŠ è‡ªåŠ¨æ‰©ç¼©å®¹åŠŸèƒ½
- æä¾›è“ç»¿éƒ¨ç½²èƒ½åŠ›

---

## 3. æ•°æ®åº“è®¾è®¡è‰æ¡ˆ

### 3.1 æ ¸å¿ƒè¡¨ç»“æ„

#### 3.1.1 çƒé˜Ÿè¡¨ (teams)

```sql
CREATE TABLE teams (
    team_id INT PRIMARY KEY AUTO_INCREMENT,
    team_name VARCHAR(100) NOT NULL,
    team_code VARCHAR(10) UNIQUE,
    country VARCHAR(50),
    league_id INT,
    founded_year INT,
    stadium VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX idx_league (league_id),
    INDEX idx_country (country)
);
```

#### 3.1.2 æ¯”èµ›è¡¨ (matches)

```sql
CREATE TABLE matches (
    match_id INT PRIMARY KEY AUTO_INCREMENT,
    home_team_id INT NOT NULL,
    away_team_id INT NOT NULL,
    league_id INT NOT NULL,
    season VARCHAR(20),
    match_date DATETIME NOT NULL,
    match_status ENUM('scheduled', 'live', 'finished', 'cancelled') DEFAULT 'scheduled',
    home_score INT,
    away_score INT,
    home_goals_ht INT, -- åŠåœºæ¯”åˆ†
    away_goals_ht INT,
    attendance INT,
    referee VARCHAR(100),
    venue VARCHAR(100),
    weather_condition VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    FOREIGN KEY (home_team_id) REFERENCES teams(team_id),
    FOREIGN KEY (away_team_id) REFERENCES teams(team_id),
    INDEX idx_date (match_date),
    INDEX idx_teams (home_team_id, away_team_id),
    INDEX idx_league_season (league_id, season),
    INDEX idx_status (match_status)
);
```

#### 3.1.3 èµ”ç‡è¡¨ (odds)

```sql
CREATE TABLE odds (
    odds_id INT PRIMARY KEY AUTO_INCREMENT,
    match_id INT NOT NULL,
    bookmaker VARCHAR(50) NOT NULL,
    market_type ENUM('1x2', 'over_under', 'asian_handicap', 'both_teams_score') NOT NULL,
    home_odds DECIMAL(8,4),
    draw_odds DECIMAL(8,4),
    away_odds DECIMAL(8,4),
    over_odds DECIMAL(8,4),
    under_odds DECIMAL(8,4),
    line_value DECIMAL(4,2), -- ç›˜å£å€¼
    collected_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (match_id) REFERENCES matches(match_id),
    INDEX idx_match_bookmaker (match_id, bookmaker),
    INDEX idx_collected_at (collected_at),
    INDEX idx_market_type (market_type)
);
```

#### 3.1.4 ç‰¹å¾è¡¨ (features)

```sql
CREATE TABLE features (
    feature_id INT PRIMARY KEY AUTO_INCREMENT,
    match_id INT NOT NULL,
    team_id INT NOT NULL,
    team_type ENUM('home', 'away') NOT NULL,

    -- åŸºç¡€ç»Ÿè®¡ç‰¹å¾
    recent_5_wins INT DEFAULT 0,
    recent_5_draws INT DEFAULT 0,
    recent_5_losses INT DEFAULT 0,
    recent_5_goals_for INT DEFAULT 0,
    recent_5_goals_against INT DEFAULT 0,

    -- ä¸»å®¢åœºç‰¹å¾
    home_wins INT DEFAULT 0,
    home_draws INT DEFAULT 0,
    home_losses INT DEFAULT 0,
    away_wins INT DEFAULT 0,
    away_draws INT DEFAULT 0,
    away_losses INT DEFAULT 0,

    -- å¯¹æˆ˜å†å²ç‰¹å¾
    h2h_wins INT DEFAULT 0,
    h2h_draws INT DEFAULT 0,
    h2h_losses INT DEFAULT 0,
    h2h_goals_for INT DEFAULT 0,
    h2h_goals_against INT DEFAULT 0,

    -- è”èµ›æ’åç‰¹å¾
    league_position INT,
    points INT,
    goal_difference INT,

    -- å…¶ä»–ç‰¹å¾
    days_since_last_match INT,
    is_derby BOOLEAN DEFAULT FALSE,
    avg_possession DECIMAL(5,2),
    avg_shots_per_game DECIMAL(5,2),

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (match_id) REFERENCES matches(match_id),
    FOREIGN KEY (team_id) REFERENCES teams(team_id),
    INDEX idx_match (match_id),
    INDEX idx_team (team_id)
);
```

#### 3.1.5 é¢„æµ‹è¡¨ (predictions)

```sql
CREATE TABLE predictions (
    prediction_id INT PRIMARY KEY AUTO_INCREMENT,
    match_id INT NOT NULL,
    model_name VARCHAR(50) NOT NULL,
    model_version VARCHAR(20) NOT NULL,

    -- é¢„æµ‹ç»“æœ
    predicted_result ENUM('home_win', 'draw', 'away_win') NOT NULL,
    home_win_probability DECIMAL(5,4) NOT NULL,
    draw_probability DECIMAL(5,4) NOT NULL,
    away_win_probability DECIMAL(5,4) NOT NULL,

    -- æ¯”åˆ†é¢„æµ‹
    predicted_home_score DECIMAL(3,2),
    predicted_away_score DECIMAL(3,2),

    -- å…¶ä»–é¢„æµ‹
    over_2_5_probability DECIMAL(5,4),
    both_teams_score_probability DECIMAL(5,4),

    -- ç½®ä¿¡åº¦å’Œç‰¹å¾é‡è¦æ€§
    confidence_score DECIMAL(5,4),
    feature_importance JSON, -- å­˜å‚¨ç‰¹å¾é‡è¦æ€§æ•°æ®

    predicted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (match_id) REFERENCES matches(match_id),
    INDEX idx_match_model (match_id, model_name),
    INDEX idx_predicted_at (predicted_at)
);
```

#### 3.1.6 è”èµ›è¡¨ (leagues)

```sql
CREATE TABLE leagues (
    league_id INT PRIMARY KEY AUTO_INCREMENT,
    league_name VARCHAR(100) NOT NULL,
    league_code VARCHAR(20) UNIQUE,
    country VARCHAR(50),
    level INT, -- è”èµ›çº§åˆ«
    season_start_month INT,
    season_end_month INT,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_country (country),
    INDEX idx_active (is_active)
);
```

### 3.2 æ•°æ®ä¸€è‡´æ€§çº¦æŸ

#### 3.2.1 æ•°æ®å®Œæ•´æ€§çº¦æŸ

- æ‰€æœ‰æ¯”èµ›å¿…é¡»æœ‰æœ‰æ•ˆçš„ä¸»å®¢åœºçƒé˜Ÿ
- å·²å®Œæˆçš„æ¯”èµ›å¿…é¡»æœ‰æ¯”åˆ†
- é¢„æµ‹å¿…é¡»åŸºäºæœªå®Œæˆçš„æ¯”èµ›
- èµ”ç‡æ•°æ®å¿…é¡»åœ¨æ¯”èµ›å¼€å§‹å‰æ”¶é›†

#### 3.2.2 ä¸šåŠ¡é€»è¾‘çº¦æŸ

```sql
-- ç¡®ä¿æ¯”èµ›æ—¥æœŸä¸åœ¨è¿‡å»ï¼ˆå¯¹äºæ–°å»ºæ¯”èµ›ï¼‰
ALTER TABLE matches ADD CONSTRAINT check_future_date
CHECK (match_date > DATE_SUB(CURRENT_TIMESTAMP, INTERVAL 1 DAY));

-- ç¡®ä¿æ¦‚ç‡ä¹‹å’Œç­‰äº1
ALTER TABLE predictions ADD CONSTRAINT check_probability_sum
CHECK (ABS((home_win_probability + draw_probability + away_win_probability) - 1.0) < 0.001);

-- ç¡®ä¿èµ”ç‡ä¸ºæ­£æ•°
ALTER TABLE odds ADD CONSTRAINT check_positive_odds
CHECK (home_odds > 0 AND draw_odds > 0 AND away_odds > 0);
```

### 3.3 ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

#### 3.3.1 æŸ¥è¯¢ä¼˜åŒ–ç´¢å¼•

```sql
-- æœ€è¿‘æ¯”èµ›æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_recent_matches ON matches(match_date DESC, league_id);

-- çƒé˜Ÿå†å²æˆ˜ç»©æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_team_matches ON matches(home_team_id, away_team_id, match_date);

-- é¢„æµ‹ç»“æœæŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_predictions_lookup ON predictions(match_id, model_name, predicted_at DESC);

-- ç‰¹å¾å·¥ç¨‹æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_features_team_date ON matches(home_team_id, match_date);
CREATE INDEX idx_features_away_date ON matches(away_team_id, match_date);
```

### 3.4 æ•°æ®åˆ†åŒºç­–ç•¥

#### 3.4.1 æŒ‰æ—¶é—´åˆ†åŒº

```sql
-- æ¯”èµ›è¡¨æŒ‰å¹´ä»½åˆ†åŒº
ALTER TABLE matches PARTITION BY RANGE (YEAR(match_date)) (
    PARTITION p2020 VALUES LESS THAN (2021),
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- é¢„æµ‹è¡¨æŒ‰æœˆåˆ†åŒº
ALTER TABLE predictions PARTITION BY RANGE (YEAR(predicted_at) * 100 + MONTH(predicted_at)) (
    PARTITION p202401 VALUES LESS THAN (202402),
    PARTITION p202402 VALUES LESS THAN (202403),
    -- ... æ›´å¤šåˆ†åŒº
    PARTITION p_current VALUES LESS THAN MAXVALUE
);
```

### 3.5 æ‰©å±•æ€§è€ƒè™‘

#### 3.5.1 è¯»å†™åˆ†ç¦»

- ä¸»åº“å¤„ç†å†™æ“ä½œå’Œå®æ—¶æŸ¥è¯¢
- ä»åº“å¤„ç†å†å²æ•°æ®åˆ†æå’ŒæŠ¥è¡¨æŸ¥è¯¢
- é¢„æµ‹æœåŠ¡ä¼˜å…ˆä½¿ç”¨ä»åº“å‡å°‘ä¸»åº“å‹åŠ›

#### 3.5.2 ç¼“å­˜ç­–ç•¥

- Redisç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢æ•°æ®ï¼ˆè¿‘æœŸæ¯”èµ›ã€å®æ—¶é¢„æµ‹ç»“æœï¼‰
- ç¼“å­˜çƒé˜ŸåŸºç¡€ä¿¡æ¯å’Œè”èµ›ä¿¡æ¯
- ç¼“å­˜é¢„æµ‹æ¨¡å‹è¾“å‡ºç»“æœï¼ˆ1å°æ—¶æœ‰æ•ˆæœŸï¼‰

#### 3.5.3 å½’æ¡£ç­–ç•¥

- å†å²æ¯”èµ›æ•°æ®ï¼ˆ3å¹´ä»¥ä¸Šï¼‰å½’æ¡£åˆ°å•ç‹¬çš„å½’æ¡£åº“
- å†å²é¢„æµ‹æ•°æ®ä¿ç•™ç”¨äºæ¨¡å‹æ•ˆæœå›æµ‹
- èµ”ç‡å†å²æ•°æ®å®šæœŸæ¸…ç†ï¼Œä¿ç•™ä»£è¡¨æ€§æ ·æœ¬

---

## 4. å¼€å‘é˜¶æ®µè§„åˆ’

### 4.1 é˜¶æ®µä¸€ï¼šç¯å¢ƒæ­å»º + æ•°æ®é‡‡é›† + æ•°æ®å­˜å‚¨æ¸…æ´—

#### æ—¶é—´è§„åˆ’ï¼š4-6å‘¨

#### ä¸»è¦ä»»åŠ¡

1. **å¼€å‘ç¯å¢ƒæ­å»º**ï¼ˆ1å‘¨ï¼‰
   - æ­å»ºPythonå¼€å‘ç¯å¢ƒå’Œä¾èµ–ç®¡ç†
   - é…ç½®æ•°æ®åº“ï¼ˆMySQL/PostgreSQLï¼‰å’ŒRedis
   - å»ºç«‹Gitç‰ˆæœ¬æ§åˆ¶å’Œä»£ç è§„èŒƒ
   - é…ç½®æ—¥å¿—ç³»ç»Ÿå’Œç›‘æ§åŸºç¡€è®¾æ–½

2. **æ•°æ®é‡‡é›†ç³»ç»Ÿå¼€å‘**ï¼ˆ2-3å‘¨ï¼‰
   - å®ç°APIæ•°æ®é‡‡é›†å™¨ï¼ˆAPI-Footballç­‰ï¼‰
   - å¼€å‘Webçˆ¬è™«ç³»ç»Ÿï¼ˆå¤„ç†åçˆ¬æœºåˆ¶ï¼‰
   - å»ºç«‹æ•°æ®é‡‡é›†ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ
   - å®ç°å¢é‡æ•°æ®åŒæ­¥æœºåˆ¶
   - å»ºç«‹æ•°æ®é‡‡é›†ç›‘æ§å’Œå‘Šè­¦

3. **æ•°æ®å­˜å‚¨å’Œæ¸…æ´—ç³»ç»Ÿ**ï¼ˆ1-2å‘¨ï¼‰
   - å®ç°æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºå’Œè¿ç§»
   - å¼€å‘æ•°æ®æ¸…æ´—å’ŒéªŒè¯æ¨¡å—
   - å»ºç«‹æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿ
   - å®ç°æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶

#### äº¤ä»˜ç‰©

- å®Œæ•´çš„æ•°æ®é‡‡é›†ç³»ç»Ÿï¼Œèƒ½å¤Ÿç¨³å®šè·å–ä¸»è¦è”èµ›æ•°æ®
- æ•°æ®åº“schemaå’Œæ•°æ®æ¸…æ´—æµæ°´çº¿
- æ•°æ®è´¨é‡æŠ¥å‘Šå’Œç›‘æ§ä»ªè¡¨æ¿
- æŠ€æœ¯æ–‡æ¡£å’Œæ“ä½œæ‰‹å†Œ

#### é‡Œç¨‹ç¢‘æ£€æŸ¥

- èƒ½å¤Ÿé‡‡é›†è‡³å°‘3ä¸ªä¸»è¦è”èµ›çš„å†å²æ•°æ®ï¼ˆæœ€è¿‘2ä¸ªèµ›å­£ï¼‰
- æ•°æ®è´¨é‡è¾¾æ ‡ï¼ˆå®Œæ•´æ€§>95%ï¼Œå‡†ç¡®æ€§>98%ï¼‰
- ç³»ç»Ÿç¨³å®šè¿è¡Œ72å°æ—¶æ— ä¸­æ–­

#### æµ‹è¯•é‡ç‚¹

- æ•°æ®é‡‡é›†çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§æµ‹è¯•
- æ•°æ®æ¸…æ´—é€»è¾‘çš„æ­£ç¡®æ€§éªŒè¯
- å¼‚å¸¸æƒ…å†µå¤„ç†ï¼ˆç½‘ç»œä¸­æ–­ã€APIé™æµç­‰ï¼‰

### 4.2 é˜¶æ®µäºŒï¼šç‰¹å¾å·¥ç¨‹ + æ¨¡å‹è®­ç»ƒ

#### æ—¶é—´è§„åˆ’ï¼š6-8å‘¨

#### ä¸»è¦ä»»åŠ¡

1. **ç‰¹å¾å·¥ç¨‹å¼€å‘**ï¼ˆ3-4å‘¨ï¼‰
   - è®¾è®¡å’Œå®ç°åŸºç¡€ç»Ÿè®¡ç‰¹å¾ï¼ˆèƒœè´Ÿè®°å½•ã€è¿›çƒæ•°ç­‰ï¼‰
   - å¼€å‘é«˜çº§ç‰¹å¾ï¼ˆä¸»å®¢åœºä¼˜åŠ¿ã€å¯¹æˆ˜å†å²ã€çƒé˜Ÿå®åŠ›ç­‰ï¼‰
   - å®ç°æ—¶åºç‰¹å¾ï¼ˆæœ€è¿‘çŠ¶æ€ã€è¶‹åŠ¿åˆ†æï¼‰
   - å»ºç«‹ç‰¹å¾å­˜å‚¨å’Œç®¡ç†ç³»ç»Ÿ
   - ç‰¹å¾æœ‰æ•ˆæ€§åˆ†æå’Œç­›é€‰

2. **æ¨¡å‹è®­ç»ƒç³»ç»Ÿ**ï¼ˆ2-3å‘¨ï¼‰
   - å®ç°XGBoostå’ŒLightGBMæ¨¡å‹è®­ç»ƒæµæ°´çº¿
   - å¼€å‘è¶…å‚æ•°è°ƒä¼˜ç³»ç»Ÿ
   - å»ºç«‹äº¤å‰éªŒè¯å’Œæ¨¡å‹è¯„ä¼°ä½“ç³»
   - å®ç°æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œå¯¹æ¯”ç³»ç»Ÿ
   - å¼€å‘æ¨¡å‹è§£é‡Šæ€§åˆ†æå·¥å…·

3. **æ¨¡å‹ä¼˜åŒ–å’Œé›†æˆ**ï¼ˆ1å‘¨ï¼‰
   - æ¨¡å‹æ€§èƒ½ä¼˜åŒ–å’Œè°ƒå‚
   - å®ç°å¤šæ¨¡å‹é›†æˆç­–ç•¥
   - å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

#### äº¤ä»˜ç‰©

- å®Œæ•´çš„ç‰¹å¾å·¥ç¨‹ç³»ç»Ÿï¼ŒåŒ…å«100+ä¸ªé¢„æµ‹ç‰¹å¾
- è®­ç»ƒå¥½çš„é¢„æµ‹æ¨¡å‹ï¼Œé¢„æµ‹å‡†ç¡®ç‡>55%
- æ¨¡å‹è¯„ä¼°æŠ¥å‘Šå’Œæ€§èƒ½åŸºå‡†
- ç‰¹å¾é‡è¦æ€§åˆ†æå’Œæ¨¡å‹è§£é‡Šæ–‡æ¡£

#### é‡Œç¨‹ç¢‘æ£€æŸ¥

- ç‰¹å¾å·¥ç¨‹ç³»ç»Ÿèƒ½å¤Ÿä¸ºæ‰€æœ‰æ¯”èµ›ç”Ÿæˆå®Œæ•´ç‰¹å¾å‘é‡
- æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°é¢„æœŸæ€§èƒ½æŒ‡æ ‡
- èƒ½å¤Ÿä¸ºæœªæ¥æ¯”èµ›ç”Ÿæˆå¯ä¿¡çš„é¢„æµ‹ç»“æœ

#### æµ‹è¯•é‡ç‚¹

- ç‰¹å¾è®¡ç®—çš„æ­£ç¡®æ€§å’Œä¸€è‡´æ€§
- æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§
- ä¸åŒè”èµ›å’Œæ—¶é—´æ®µçš„æ³›åŒ–èƒ½åŠ›æµ‹è¯•

### 4.3 é˜¶æ®µä¸‰ï¼šé¢„æµ‹æœåŠ¡API + å‰ç«¯å±•ç¤º

#### æ—¶é—´è§„åˆ’ï¼š6-8å‘¨

#### ä¸»è¦ä»»åŠ¡

1. **é¢„æµ‹æœåŠ¡å¼€å‘**ï¼ˆ3-4å‘¨ï¼‰
   - ä½¿ç”¨FastAPIæ„å»ºRESTful APIæœåŠ¡
   - å®ç°å®æ—¶é¢„æµ‹å’Œæ‰¹é‡é¢„æµ‹æ¥å£
   - å¼€å‘é¢„æµ‹ç»“æœç¼“å­˜å’Œå­˜å‚¨ç³»ç»Ÿ
   - å»ºç«‹APIè®¤è¯å’Œé™æµæœºåˆ¶
   - å®ç°é¢„æµ‹ç½®ä¿¡åº¦è®¡ç®—å’Œç»“æœè§£é‡Š

2. **å‰ç«¯åº”ç”¨å¼€å‘**ï¼ˆ2-3å‘¨ï¼‰
   - ä½¿ç”¨Vue.js/Reactå¼€å‘å“åº”å¼Webç•Œé¢
   - å®ç°æ¯”èµ›åˆ—è¡¨ã€é¢„æµ‹ç»“æœå±•ç¤ºç»„ä»¶
   - å¼€å‘æ•°æ®å¯è§†åŒ–å›¾è¡¨ï¼ˆEChartsï¼‰
   - å»ºç«‹å®æ—¶æ•°æ®æ›´æ–°æœºåˆ¶ï¼ˆWebSocketï¼‰
   - å®ç°ç§»åŠ¨ç«¯é€‚é…

3. **ç³»ç»Ÿé›†æˆå’Œæµ‹è¯•**ï¼ˆ1å‘¨ï¼‰
   - å‰åç«¯é›†æˆå’Œè”è°ƒ
   - æ€§èƒ½ä¼˜åŒ–å’Œç”¨æˆ·ä½“éªŒæ”¹è¿›
   - å…¨é“¾è·¯åŠŸèƒ½æµ‹è¯•

#### äº¤ä»˜ç‰©

- å®Œæ•´çš„é¢„æµ‹APIæœåŠ¡ï¼Œæ”¯æŒå¤šç§é¢„æµ‹ç±»å‹
- ç”¨æˆ·å‹å¥½çš„Webå‰ç«¯åº”ç”¨
- APIæ–‡æ¡£å’Œç”¨æˆ·ä½¿ç”¨æŒ‡å—
- ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æŠ¥å‘Š

#### é‡Œç¨‹ç¢‘æ£€æŸ¥

- APIæœåŠ¡èƒ½å¤Ÿç¨³å®šæä¾›é¢„æµ‹ç»“æœï¼Œå“åº”æ—¶é—´<500ms
- å‰ç«¯åº”ç”¨åŠŸèƒ½å®Œæ•´ï¼Œç”¨æˆ·ä½“éªŒè‰¯å¥½
- ç³»ç»Ÿèƒ½å¤ŸåŒæ—¶æ”¯æŒ100ä¸ªå¹¶å‘ç”¨æˆ·

#### æµ‹è¯•é‡ç‚¹

- APIæ¥å£çš„åŠŸèƒ½æ€§å’Œæ€§èƒ½æµ‹è¯•
- å‰ç«¯ç•Œé¢çš„å…¼å®¹æ€§å’Œæ˜“ç”¨æ€§æµ‹è¯•
- ç³»ç»Ÿè´Ÿè½½å’Œå‹åŠ›æµ‹è¯•

### 4.4 é˜¶æ®µå››ï¼šå®¹å™¨åŒ–éƒ¨ç½² + CI/CDæµç¨‹

#### æ—¶é—´è§„åˆ’ï¼š4-6å‘¨

#### ä¸»è¦ä»»åŠ¡

1. **å®¹å™¨åŒ–æ”¹é€ **ï¼ˆ2-3å‘¨ï¼‰
   - ç¼–å†™Dockerfileæ„å»ºåº”ç”¨é•œåƒ
   - é…ç½®Docker Composeæœ¬åœ°éƒ¨ç½²
   - å®ç°é…ç½®ç®¡ç†å’Œç¯å¢ƒå˜é‡æ³¨å…¥
   - å»ºç«‹é•œåƒç‰ˆæœ¬ç®¡ç†å’Œä»“åº“

2. **äº‘ç«¯éƒ¨ç½²**ï¼ˆ1-2å‘¨ï¼‰
   - é€‰æ‹©å’Œé…ç½®äº‘æœåŠ¡æä¾›å•†ï¼ˆä¼˜å…ˆé¦™æ¸¯èŠ‚ç‚¹ï¼‰
   - å®ç°Kubernetesé›†ç¾¤éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰
   - é…ç½®è´Ÿè½½å‡è¡¡å’ŒåŸŸåè§£æ
   - å»ºç«‹ç”Ÿäº§ç¯å¢ƒç›‘æ§å’Œå‘Šè­¦

3. **CI/CDæµç¨‹å»ºè®¾**ï¼ˆ1å‘¨ï¼‰
   - é…ç½®GitHub Actionsè‡ªåŠ¨åŒ–æµæ°´çº¿
   - å®ç°è‡ªåŠ¨åŒ–æµ‹è¯•å’Œä»£ç è´¨é‡æ£€æŸ¥
   - å»ºç«‹è‡ªåŠ¨éƒ¨ç½²å’Œå›æ»šæœºåˆ¶
   - å»ºç«‹å‘å¸ƒæµç¨‹å’Œç‰ˆæœ¬ç®¡ç†

#### äº¤ä»˜ç‰©

- å®Œæ•´çš„DockeråŒ–åº”ç”¨ï¼Œæ”¯æŒä¸€é”®éƒ¨ç½²
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆå’Œè¿ç»´æ–‡æ¡£
- CI/CDè‡ªåŠ¨åŒ–æµæ°´çº¿
- ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

#### é‡Œç¨‹ç¢‘æ£€æŸ¥

- åº”ç”¨èƒ½å¤Ÿåœ¨äº‘ç«¯ç¨³å®šè¿è¡Œï¼Œå¯ç”¨æ€§>99%
- CI/CDæµæ°´çº¿è¿è¡Œæ­£å¸¸ï¼Œéƒ¨ç½²æ—¶é—´<10åˆ†é’Ÿ
- ç›‘æ§ç³»ç»Ÿèƒ½å¤ŸåŠæ—¶å‘ç°å’ŒæŠ¥å‘Šé—®é¢˜

#### æµ‹è¯•é‡ç‚¹

- å®¹å™¨åŒ–åº”ç”¨çš„ç¨³å®šæ€§å’Œæ€§èƒ½æµ‹è¯•
- éƒ¨ç½²æµç¨‹çš„å¯é æ€§éªŒè¯
- ç”Ÿäº§ç¯å¢ƒçš„å‹åŠ›å’Œç¾å¤‡æµ‹è¯•

### 4.5 æ•´ä½“é¡¹ç›®æ—¶é—´çº¿

```mermaid
gantt
    title è¶³çƒé¢„æµ‹ç³»ç»Ÿå¼€å‘æ—¶é—´çº¿
    dateFormat  YYYY-MM-DD
    section é˜¶æ®µä¸€
    ç¯å¢ƒæ­å»º           :done, env, 2024-01-01, 1w
    æ•°æ®é‡‡é›†å¼€å‘       :done, collect, after env, 3w
    æ•°æ®æ¸…æ´—ç³»ç»Ÿ       :done, clean, after collect, 2w
    section é˜¶æ®µäºŒ
    ç‰¹å¾å·¥ç¨‹å¼€å‘       :active, feature, after clean, 4w
    æ¨¡å‹è®­ç»ƒç³»ç»Ÿ       :model, after feature, 3w
    æ¨¡å‹ä¼˜åŒ–é›†æˆ       :optimize, after model, 1w
    section é˜¶æ®µä¸‰
    é¢„æµ‹æœåŠ¡å¼€å‘       :api, after optimize, 4w
    å‰ç«¯åº”ç”¨å¼€å‘       :frontend, after api, 3w
    ç³»ç»Ÿé›†æˆæµ‹è¯•       :integration, after frontend, 1w
    section é˜¶æ®µå››
    å®¹å™¨åŒ–æ”¹é€          :docker, after integration, 3w
    äº‘ç«¯éƒ¨ç½²           :deploy, after docker, 2w
    CI/CDæµç¨‹         :cicd, after deploy, 1w
```

### 4.6 é£é™©æ§åˆ¶å’Œåº”å¯¹ç­–ç•¥

#### ä¸»è¦é£é™©ç‚¹

1. **æ•°æ®é‡‡é›†é£é™©**
   - é£é™©ï¼šAPIé™æµã€åçˆ¬è™«ã€æ•°æ®æºå˜æ›´
   - åº”å¯¹ï¼šå¤šæ•°æ®æºå¤‡ä»½ã€ä»£ç†IPæ± ã€æ¸è¿›å¼é‡‡é›†ç­–ç•¥

2. **æ¨¡å‹æ€§èƒ½é£é™©**
   - é£é™©ï¼šé¢„æµ‹å‡†ç¡®ç‡ä¸è¾¾æ ‡ã€è¿‡æ‹Ÿåˆé—®é¢˜
   - åº”å¯¹ï¼šå¤šæ¨¡å‹å¯¹æ¯”ã€äº¤å‰éªŒè¯ã€å®šæœŸé‡è®­ç»ƒ

3. **æŠ€æœ¯å®ç°é£é™©**
   - é£é™©ï¼šæŠ€æœ¯é€‰å‹ä¸å½“ã€æ€§èƒ½ç“¶é¢ˆã€æ‰©å±•æ€§é—®é¢˜
   - åº”å¯¹ï¼šåŸå‹éªŒè¯ã€å‹åŠ›æµ‹è¯•ã€æ¶æ„è¯„å®¡

4. **éƒ¨ç½²è¿ç»´é£é™©**
   - é£é™©ï¼šæœåŠ¡ä¸ç¨³å®šã€å®‰å…¨æ¼æ´ã€è¿ç»´æˆæœ¬
   - åº”å¯¹ï¼šç°åº¦éƒ¨ç½²ã€å®‰å…¨å®¡è®¡ã€æˆæœ¬ç›‘æ§

#### è´¨é‡ä¿è¯æªæ–½

- æ¯ä¸ªé˜¶æ®µè®¾ç½®è´¨é‡å…³å£ï¼Œä¸è¾¾æ ‡ä¸è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
- å»ºç«‹ä»£ç è¯„å®¡å’Œè‡ªåŠ¨åŒ–æµ‹è¯•æœºåˆ¶
- å®šæœŸè¿›è¡Œæ¶æ„è¯„å®¡å’Œæ€§èƒ½åˆ†æ
- å»ºç«‹å®Œå–„çš„æ–‡æ¡£å’ŒçŸ¥è¯†ç®¡ç†ä½“ç³»

---

## 5. éƒ¨ç½²ä¸è¿ç»´æ¶æ„

### 5.1 æ•´ä½“éƒ¨ç½²æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ç”¨æˆ·å±‚"
        U1[Webç”¨æˆ·]
        U2[ç§»åŠ¨ç”¨æˆ·]
        U3[APIç”¨æˆ·]
    end

    subgraph "CDN & è´Ÿè½½å‡è¡¡å±‚"
        CDN[CloudFlare CDN]
        ALB[Application Load Balancer]
    end

    subgraph "å®¹å™¨ç¼–æ’å±‚"
        K8S[Kubernetesé›†ç¾¤]
        subgraph "åº”ç”¨æœåŠ¡Pod"
            API1[FastAPIå®ä¾‹1]
            API2[FastAPIå®ä¾‹2]
            API3[FastAPIå®ä¾‹3]
        end
        subgraph "å‰ç«¯æœåŠ¡Pod"
            WEB1[Nginx + Vue.js]
            WEB2[Nginx + Vue.js]
        end
        subgraph "æ•°æ®æœåŠ¡Pod"
            WORKER1[æ•°æ®é‡‡é›†Worker]
            WORKER2[æ¨¡å‹è®­ç»ƒWorker]
            SCHEDULER[ä»»åŠ¡è°ƒåº¦å™¨]
        end
    end

    subgraph "æ•°æ®å±‚"
        subgraph "æ•°æ®åº“é›†ç¾¤"
            DB_MASTER[(MySQLä¸»åº“)]
            DB_SLAVE1[(MySQLä»åº“1)]
            DB_SLAVE2[(MySQLä»åº“2)]
        end
        subgraph "ç¼“å­˜å±‚"
            REDIS_M[(Redisä¸»)]
            REDIS_S[(Redisä»)]
        end
        subgraph "å­˜å‚¨å±‚"
            S3[å¯¹è±¡å­˜å‚¨<br/>æ¨¡å‹æ–‡ä»¶&æ—¥å¿—]
        end
    end

    subgraph "ç›‘æ§å±‚"
        PROMETHEUS[Prometheus]
        GRAFANA[Grafana]
        ALERTMANAGER[AlertManager]
        ELK[ELK Stack]
    end

    U1 & U2 & U3 --> CDN
    CDN --> ALB
    ALB --> K8S
    K8S --> API1 & API2 & API3
    K8S --> WEB1 & WEB2
    K8S --> WORKER1 & WORKER2 & SCHEDULER

    API1 & API2 & API3 --> DB_SLAVE1 & DB_SLAVE2
    API1 & API2 & API3 --> REDIS_M
    WORKER1 & WORKER2 --> DB_MASTER
    SCHEDULER --> REDIS_M

    DB_MASTER --> DB_SLAVE1 & DB_SLAVE2
    REDIS_M --> REDIS_S

    K8S --> S3
    K8S --> PROMETHEUS
    PROMETHEUS --> GRAFANA
    PROMETHEUS --> ALERTMANAGER
    K8S --> ELK
```

### 5.2 Dockeré•œåƒè®¾è®¡

#### 5.2.1 APIæœåŠ¡å®¹å™¨

```dockerfile
# Dockerfile.api
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY src/ ./src/
COPY config/ ./config/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV API_HOST=0.0.0.0
ENV API_PORT=8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 5.2.2 æ•°æ®é‡‡é›†å®¹å™¨

```dockerfile
# Dockerfile.worker
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…Chromeå’ŒChrome Driverï¼ˆç”¨äºSeleniumï¼‰
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    unzip \
    curl \
    && wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…ChromeDriver
RUN CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE` \
    && wget -O /tmp/chromedriver.zip http://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip \
    && unzip /tmp/chromedriver.zip chromedriver -d /usr/local/bin/ \
    && rm /tmp/chromedriver.zip

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY src/ ./src/
COPY config/ ./config/

ENV PYTHONPATH=/app

CMD ["python", "src/workers/data_collector.py"]
```

#### 5.2.3 å‰ç«¯åº”ç”¨å®¹å™¨

```dockerfile
# Dockerfile.frontend
# æ„å»ºé˜¶æ®µ
FROM node:18-alpine AS builder

WORKDIR /app

COPY frontend/package*.json ./
RUN npm ci --only=production

COPY frontend/ .
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM nginx:alpine

# å¤åˆ¶æ„å»ºæ–‡ä»¶
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶Nginxé…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s \
    CMD curl -f http://localhost:80/ || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### 5.3 Kuberneteséƒ¨ç½²é…ç½®

#### 5.3.1 APIæœåŠ¡éƒ¨ç½²

```yaml
# k8s/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: football-prediction-api
  labels:
    app: football-prediction-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: football-prediction-api
  template:
    metadata:
      labels:
        app: football-prediction-api
    spec:
      containers:
      - name: api
        image: football-prediction/api:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        - name: REDIS_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: redis-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: football-prediction-api-service
spec:
  selector:
    app: football-prediction-api
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: ClusterIP
```

#### 5.3.2 æ•°æ®åº“é…ç½®

```yaml
# k8s/database-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
data:
  my.cnf: |
    [mysqld]
    innodb_buffer_pool_size = 2G
    innodb_log_file_size = 256M
    max_connections = 500
    query_cache_size = 128M
    slow_query_log = 1
    long_query_time = 2

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-master
spec:
  serviceName: mysql-master
  replicas: 1
  selector:
    matchLabels:
      app: mysql-master
  template:
    metadata:
      labels:
        app: mysql-master
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: root-password
        - name: MYSQL_DATABASE
          value: football_prediction
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
        - name: mysql-config
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: mysql-config
        configMap:
          name: mysql-config
  volumeClaimTemplates:
  - metadata:
      name: mysql-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
```

#### 5.3.3 è´Ÿè½½å‡è¡¡é…ç½®

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: football-prediction-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  tls:
  - hosts:
    - api.football-prediction.com
    - football-prediction.com
    secretName: football-prediction-tls
  rules:
  - host: football-prediction.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: football-prediction-frontend-service
            port:
              number: 80
  - host: api.football-prediction.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: football-prediction-api-service
            port:
              number: 80
```

### 5.4 äº‘ç«¯ä¸æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

#### 5.4.1 æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ

**ä¼˜åŠ¿ï¼š**

- å®Œå…¨å¯æ§çš„ç¯å¢ƒå’Œæ•°æ®
- æ— éœ€æ‹…å¿ƒäº‘æœåŠ¡å•†é™åˆ¶å’Œè´¹ç”¨
- é€‚åˆå¼€å‘æµ‹è¯•å’Œå°è§„æ¨¡ä½¿ç”¨

**åŠ£åŠ¿ï¼š**

- éœ€è¦è‡ªå·±ç»´æŠ¤ç¡¬ä»¶å’Œç½‘ç»œ
- æ‰©å±•æ€§æœ‰é™
- éœ€è¦æ›´å¤šè¿ç»´å·¥ä½œ

**é€‚ç”¨åœºæ™¯ï¼š**

- å¼€å‘æµ‹è¯•ç¯å¢ƒ
- é¢„ç®—æœ‰é™çš„ä¸ªäººé¡¹ç›®
- å¯¹æ•°æ®å®‰å…¨è¦æ±‚æé«˜çš„åœºæ™¯

**éƒ¨ç½²é…ç½®ï¼š**

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=mysql://user:pass@mysql:3306/football
      - REDIS_URL=redis://redis:6379
    depends_on:
      - mysql
      - redis
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "80:80"
    depends_on:
      - api
    restart: unless-stopped

  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=football
    volumes:
      - mysql_data:/var/lib/mysql
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped

  data_collector:
    build:
      context: .
      dockerfile: Dockerfile.worker
    environment:
      - DATABASE_URL=mysql://user:pass@mysql:3306/football
    depends_on:
      - mysql
      - redis
    restart: unless-stopped

volumes:
  mysql_data:
  redis_data:
```

#### 5.4.2 äº‘ç«¯éƒ¨ç½²æ–¹æ¡ˆ

**ä¼˜åŠ¿ï¼š**

- é«˜å¯ç”¨æ€§å’Œè‡ªåŠ¨æ‰©å±•
- ä¸“ä¸šçš„è¿ç»´å’Œå®‰å…¨ä¿éšœ
- å…¨çƒCDNåŠ é€Ÿ
- ä¸°å¯Œçš„äº‘æœåŠ¡ç”Ÿæ€

**åŠ£åŠ¿ï¼š**

- æŒç»­çš„è¿è¥æˆæœ¬
- å¯èƒ½çš„å‚å•†é”å®š
- æ•°æ®ä¼ è¾“å’Œå­˜å‚¨é™åˆ¶

**é€‚ç”¨åœºæ™¯ï¼š**

- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- éœ€è¦é«˜å¯ç”¨æ€§çš„åº”ç”¨
- å…¨çƒç”¨æˆ·è®¿é—®çš„æœåŠ¡

**æ¨èäº‘æœåŠ¡å•†é€‰æ‹©ï¼ˆä¼˜å…ˆé¦™æ¸¯èŠ‚ç‚¹ï¼‰ï¼š**

1. **é˜¿é‡Œäº‘ï¼ˆé¦™æ¸¯ï¼‰**
   - ä¼˜åŠ¿ï¼šå¯¹å¤§é™†è®¿é—®å‹å¥½ï¼ŒæœåŠ¡ç¨³å®š
   - é€‚åˆï¼šå›½å†…å¤–åŒé‡è¦†ç›–
   - æˆæœ¬ï¼šä¸­ç­‰

2. **è…¾è®¯äº‘ï¼ˆé¦™æ¸¯ï¼‰**
   - ä¼˜åŠ¿ï¼šç½‘ç»œå»¶è¿Ÿä½ï¼Œä»·æ ¼åˆç†
   - é€‚åˆï¼šå›½å†…ç”¨æˆ·ä¸ºä¸»çš„åº”ç”¨
   - æˆæœ¬ï¼šè¾ƒä½

3. **AWSï¼ˆäºšå¤ª-é¦™æ¸¯ï¼‰**
   - ä¼˜åŠ¿ï¼šå…¨çƒåŒ–æœåŠ¡ï¼Œç”Ÿæ€ä¸°å¯Œ
   - é€‚åˆï¼šéœ€è¦å…¨çƒéƒ¨ç½²çš„åº”ç”¨
   - æˆæœ¬ï¼šè¾ƒé«˜

4. **Google Cloudï¼ˆé¦™æ¸¯ï¼‰**
   - ä¼˜åŠ¿ï¼šAI/MLæœåŠ¡å¼ºå¤§
   - é€‚åˆï¼šæœºå™¨å­¦ä¹ é‡åº¦åº”ç”¨
   - æˆæœ¬ï¼šä¸­ç­‰

### 5.5 Kubernetesæ‰©å±•é…ç½®

#### 5.5.1 è‡ªåŠ¨ä¼¸ç¼©é…ç½®

```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: football-prediction-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: football-prediction-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Pods
        value: 2
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60
```

#### 5.5.2 èµ„æºé…é¢ç®¡ç†

```yaml
# k8s/resource-quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: football-prediction-quota
spec:
  hard:
    requests.cpu: "4"
    requests.memory: 8Gi
    limits.cpu: "8"
    limits.memory: 16Gi
    count/pods: 20
    count/services: 10
    count/secrets: 5
    count/configmaps: 10

---
apiVersion: v1
kind: LimitRange
metadata:
  name: football-prediction-limits
spec:
  limits:
  - default:
      cpu: 500m
      memory: 1Gi
    defaultRequest:
      cpu: 100m
      memory: 256Mi
    type: Container
```

### 5.6 ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

#### 5.6.1 Prometheusç›‘æ§é…ç½®

```yaml
# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      - "/etc/prometheus/rules/*.yml"

    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    scrape_configs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

    - job_name: 'football-prediction-api'
      static_configs:
      - targets: ['football-prediction-api-service:80']
      metrics_path: /metrics
      scrape_interval: 10s
```

#### 5.6.2 å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# monitoring/alert-rules.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
data:
  football-prediction.yml: |
    groups:
    - name: football-prediction
      rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} for {{ $labels.instance }}"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"

      - alert: DatabaseConnectionFailure
        expr: mysql_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database connection failure"
          description: "MySQL database is down"

      - alert: PredictionServiceDown
        expr: up{job="football-prediction-api"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Prediction service is down"
          description: "Football prediction API is not responding"
```

#### 5.6.3 Grafanaä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "è¶³çƒé¢„æµ‹ç³»ç»Ÿç›‘æ§",
    "panels": [
      {
        "title": "APIè¯·æ±‚QPS",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´åˆ†å¸ƒ",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "æ•°æ®åº“è¿æ¥æ± çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "mysql_global_status_threads_connected",
            "legendFormat": "Active Connections"
          }
        ]
      },
      {
        "title": "é¢„æµ‹å‡†ç¡®ç‡è¶‹åŠ¿",
        "type": "graph",
        "targets": [
          {
            "expr": "prediction_accuracy_rate",
            "legendFormat": "Accuracy Rate"
          }
        ]
      }
    ]
  }
}
```

### 5.7 å®‰å…¨é…ç½®

#### 5.7.1 ç½‘ç»œå®‰å…¨ç­–ç•¥

```yaml
# k8s/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: football-prediction-network-policy
spec:
  podSelector:
    matchLabels:
      app: football-prediction-api
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: nginx-ingress
    ports:
    - protocol: TCP
      port: 8000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: mysql-master
    ports:
    - protocol: TCP
      port: 3306
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
```

#### 5.7.2 å¯†é’¥ç®¡ç†

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
stringData:
  url: mysql://username:password@mysql-master:3306/football_prediction
  username: app_user
  password: secure_password_here

---
apiVersion: v1
kind: Secret
metadata:
  name: api-secret
type: Opaque
stringData:
  jwt-secret: your_jwt_secret_key_here
  api-key: your_api_key_here
```

---

## 6. æœªæ¥æ‰©å±•å»ºè®®

### 6.1 æ¨¡å‹è‡ªåŠ¨æ›´æ–°æœºåˆ¶

#### 6.1.1 è‡ªåŠ¨é‡è®­ç»ƒæµæ°´çº¿

**è®¾è®¡ç›®æ ‡ï¼š**

- å®ç°æ¨¡å‹æ€§èƒ½çš„æŒç»­ç›‘æ§å’Œè‡ªåŠ¨ä¼˜åŒ–
- åŸºäºæ–°æ•°æ®å’Œåé¦ˆå»ºç«‹è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿ
- ç¡®ä¿é¢„æµ‹è´¨é‡éšæ—¶é—´æ¨ç§»ä¸æ–­æå‡

**æ ¸å¿ƒç»„ä»¶æ¶æ„ï¼š**

```mermaid
graph TD
    A[æ•°æ®å˜åŒ–ç›‘æµ‹] --> B{æ˜¯å¦éœ€è¦é‡è®­ç»ƒ}
    B -->|æ˜¯| C[è‡ªåŠ¨æ•°æ®å‡†å¤‡]
    B -->|å¦| D[ç»§ç»­ç›‘æ§]
    C --> E[ç‰¹å¾å·¥ç¨‹æ›´æ–°]
    E --> F[æ¨¡å‹è®­ç»ƒ]
    F --> G[æ¨¡å‹éªŒè¯]
    G --> H{æ€§èƒ½æ˜¯å¦æå‡}
    H -->|æ˜¯| I[æ¨¡å‹éƒ¨ç½²]
    H -->|å¦| J[å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬]
    I --> K[A/Bæµ‹è¯•]
    K --> L[æ€§èƒ½ç›‘æ§]
    L --> A
    J --> A
```

**å®ç°æ–¹æ¡ˆï¼š**

1. **æ•°æ®è´¨é‡ç›‘æ§**

```python
# src/ml/monitoring/data_monitor.py
class DataQualityMonitor:
    def __init__(self):
        self.thresholds = {
            'completeness': 0.95,
            'accuracy': 0.98,
            'consistency': 0.99,
            'freshness': 24 * 3600  # 24å°æ—¶
        }

    def check_retrain_conditions(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ"""
        conditions = {
            'data_volume': self._check_new_data_volume(),
            'performance_degradation': self._check_model_performance(),
            'concept_drift': self._detect_concept_drift(),
            'scheduled': self._check_schedule()
        }
        return any(conditions.values()), conditions

    def _detect_concept_drift(self):
        """æ£€æµ‹æ¦‚å¿µæ¼‚ç§»"""
        recent_accuracy = self._calculate_recent_accuracy(days=7)
        historical_accuracy = self._calculate_historical_accuracy(days=30)
        return (historical_accuracy - recent_accuracy) > 0.05
```

2. **è‡ªåŠ¨è®­ç»ƒè°ƒåº¦å™¨**

```python
# src/ml/training/auto_trainer.py
class AutoTrainer:
    def __init__(self):
        self.model_registry = ModelRegistry()
        self.training_pipeline = TrainingPipeline()

    async def execute_retrain_pipeline(self):
        """æ‰§è¡Œè‡ªåŠ¨é‡è®­ç»ƒæµæ°´çº¿"""
        try:
            # 1. æ•°æ®å‡†å¤‡
            training_data = await self._prepare_training_data()

            # 2. ç‰¹å¾å·¥ç¨‹
            features = await self._update_features(training_data)

            # 3. æ¨¡å‹è®­ç»ƒ
            new_model = await self._train_model(features)

            # 4. æ¨¡å‹éªŒè¯
            validation_results = await self._validate_model(new_model)

            # 5. æ€§èƒ½æ¯”è¾ƒ
            if self._is_model_better(validation_results):
                await self._deploy_model(new_model)
                await self._start_ab_test(new_model)
            else:
                logger.warning("æ–°æ¨¡å‹æ€§èƒ½ä¸å¦‚ç°æœ‰æ¨¡å‹ï¼Œè·³è¿‡éƒ¨ç½²")

        except Exception as e:
            logger.error(f"è‡ªåŠ¨é‡è®­ç»ƒå¤±è´¥: {e}")
            await self._notify_failure(e)
```

3. **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**

```python
# src/ml/registry/model_registry.py
class ModelRegistry:
    def __init__(self):
        self.storage_backend = S3Backend()
        self.metadata_store = PostgreSQLStore()

    def register_model(self, model, metadata):
        """æ³¨å†Œæ–°æ¨¡å‹ç‰ˆæœ¬"""
        version = self._generate_version()
        model_path = f"models/football_prediction/v{version}"

        # ä¿å­˜æ¨¡å‹æ–‡ä»¶
        self.storage_backend.save(model, model_path)

        # ä¿å­˜å…ƒæ•°æ®
        self.metadata_store.save({
            'version': version,
            'created_at': datetime.now(),
            'metrics': metadata['metrics'],
            'features': metadata['features'],
            'training_data_hash': metadata['data_hash']
        })

        return version

    def rollback_model(self, target_version):
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        model = self.storage_backend.load(f"models/football_prediction/v{target_version}")
        self._deploy_model(model)
        logger.info(f"å·²å›æ»šåˆ°æ¨¡å‹ç‰ˆæœ¬ {target_version}")
```

#### 6.1.2 A/Bæµ‹è¯•æ¡†æ¶

**å®ç°å¤šç‰ˆæœ¬æ¨¡å‹å¹¶è¡Œæµ‹è¯•ï¼š**

```python
# src/prediction/ab_testing/experiment.py
class ABTestManager:
    def __init__(self):
        self.experiments = {}
        self.traffic_splitter = TrafficSplitter()

    def create_experiment(self, name, control_model, treatment_model, traffic_split=0.1):
        """åˆ›å»ºA/Bæµ‹è¯•å®éªŒ"""
        experiment = {
            'name': name,
            'control_model': control_model,
            'treatment_model': treatment_model,
            'traffic_split': traffic_split,
            'start_time': datetime.now(),
            'metrics': defaultdict(list)
        }
        self.experiments[name] = experiment
        return experiment

    async def route_prediction_request(self, request):
        """æ ¹æ®A/Bæµ‹è¯•ç­–ç•¥è·¯ç”±é¢„æµ‹è¯·æ±‚"""
        active_experiment = self._get_active_experiment()

        if active_experiment and self._should_use_treatment(request):
            model = active_experiment['treatment_model']
            variant = 'treatment'
        else:
            model = active_experiment['control_model'] if active_experiment else self.default_model
            variant = 'control'

        # æ‰§è¡Œé¢„æµ‹
        prediction = await model.predict(request)

        # è®°å½•å®éªŒæ•°æ®
        if active_experiment:
            await self._log_experiment_data(active_experiment['name'], variant, request, prediction)

        return prediction
```

### 6.2 å®æ—¶èµ”ç‡å’Œçƒé˜ŸåŠ¨æ€å¢é‡é‡‡é›†

#### 6.2.1 å®æ—¶æ•°æ®æµå¤„ç†æ¶æ„

**æŠ€æœ¯é€‰å‹ï¼š**

- Apache Kafkaä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—
- Apache Flink/Spark Streamingè¿›è¡Œæµå¤„ç†
- WebSocketè¿æ¥è·å–å®æ—¶èµ”ç‡å˜åŒ–

**æ¶æ„è®¾è®¡ï¼š**

```mermaid
graph LR
    subgraph "æ•°æ®æº"
        A1[åšå½©ç½‘ç«™WebSocket]
        A2[ä½“è‚²æ•°æ®API]
        A3[ç¤¾äº¤åª’ä½“ç›‘æ§]
        A4[æ–°é—»çˆ¬è™«]
    end

    subgraph "æ¶ˆæ¯é˜Ÿåˆ—"
        B[Apache Kafka]
    end

    subgraph "æµå¤„ç†"
        C1[Flink - èµ”ç‡å¤„ç†]
        C2[Flink - æ–°é—»åˆ†æ]
        C3[Flink - ç¤¾åª’æƒ…æ„Ÿ]
    end

    subgraph "å®æ—¶å­˜å‚¨"
        D1[(Redis Stream)]
        D2[(InfluxDB)]
    end

    subgraph "é¢„æµ‹æœåŠ¡"
        E[å®æ—¶é¢„æµ‹å¼•æ“]
    end

    A1 & A2 & A3 & A4 --> B
    B --> C1 & C2 & C3
    C1 & C2 & C3 --> D1 & D2
    D1 & D2 --> E
```

**å®ç°æ–¹æ¡ˆï¼š**

1. **å®æ—¶èµ”ç‡é‡‡é›†å™¨**

```python
# src/real_time/collectors/odds_stream.py
class RealTimeOddsCollector:
    def __init__(self):
        self.kafka_producer = KafkaProducer()
        self.websocket_connections = {}

    async def start_odds_stream(self, bookmakers):
        """å¯åŠ¨å®æ—¶èµ”ç‡æµé‡‡é›†"""
        for bookmaker in bookmakers:
            connection = await self._create_websocket_connection(bookmaker)
            self.websocket_connections[bookmaker] = connection
            asyncio.create_task(self._handle_odds_stream(bookmaker, connection))

    async def _handle_odds_stream(self, bookmaker, connection):
        """å¤„ç†èµ”ç‡æµæ•°æ®"""
        async for message in connection:
            odds_data = self._parse_odds_message(message, bookmaker)

            # å‘é€åˆ°Kafka
            await self.kafka_producer.send('odds_stream', {
                'bookmaker': bookmaker,
                'timestamp': datetime.now().isoformat(),
                'data': odds_data
            })

            # æ£€æµ‹æ˜¾è‘—å˜åŒ–
            if self._detect_significant_change(odds_data):
                await self._trigger_prediction_update(odds_data)
```

2. **æµå¤„ç†å¼•æ“**

```python
# src/real_time/processors/odds_processor.py
class OddsStreamProcessor:
    def __init__(self):
        self.flink_env = StreamExecutionEnvironment.get_execution_environment()

    def create_processing_pipeline(self):
        """åˆ›å»ºèµ”ç‡æµå¤„ç†ç®¡é“"""
        # ä»Kafkaè¯»å–èµ”ç‡æµ
        odds_stream = self.flink_env.add_source(
            FlinkKafkaConsumer('odds_stream', SimpleStringSchema(), kafka_props)
        )

        # æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–
        cleaned_stream = odds_stream.map(self._clean_odds_data)

        # è®¡ç®—ç§»åŠ¨å¹³å‡å’Œè¶‹åŠ¿
        windowed_stream = cleaned_stream.key_by('match_id').time_window(Time.minutes(5))
        trend_stream = windowed_stream.apply(OddsTrendCalculator())

        # æ£€æµ‹å¼‚å¸¸æ³¢åŠ¨
        anomaly_stream = trend_stream.filter(AnomalyDetector())

        # è¾“å‡ºåˆ°å­˜å‚¨ç³»ç»Ÿ
        trend_stream.add_sink(RedisSink('odds_trends'))
        anomaly_stream.add_sink(AlertingSink('odds_anomalies'))

        return self.flink_env.execute("OddsProcessingJob")
```

#### 6.2.2 çƒé˜ŸåŠ¨æ€ä¿¡æ¯é‡‡é›†

**ä¿¡æ¯æºæ•´åˆï¼š**

- å®˜æ–¹çƒé˜Ÿç½‘ç«™å’Œç¤¾äº¤åª’ä½“
- ä½“è‚²æ–°é—»ç½‘ç«™
- çƒå‘˜ä¼¤ç—…æŠ¥å‘Š
- è½¬ä¼šå¸‚åœºä¿¡æ¯

**å®ç°æ–¹æ¡ˆï¼š**

```python
# src/real_time/collectors/team_news.py
class TeamNewsCollector:
    def __init__(self):
        self.news_sources = NewsSourceRegistry()
        self.nlp_processor = NLPProcessor()
        self.kafka_producer = KafkaProducer()

    async def collect_team_news(self, teams):
        """é‡‡é›†çƒé˜ŸåŠ¨æ€æ–°é—»"""
        for team in teams:
            news_items = await self._fetch_team_news(team)

            for news in news_items:
                # NLPåˆ†ææ–°é—»å†…å®¹
                analysis = await self.nlp_processor.analyze_news(news)

                # æå–å…³é”®ä¿¡æ¯
                extracted_info = self._extract_key_info(analysis)

                if extracted_info['importance'] > 0.7:  # é«˜é‡è¦æ€§æ–°é—»
                    await self._send_to_processing(team, extracted_info)

    def _extract_key_info(self, analysis):
        """æå–å…³é”®ä¿¡æ¯"""
        return {
            'player_injuries': analysis.get('injuries', []),
            'lineup_changes': analysis.get('lineup_changes', []),
            'coaching_changes': analysis.get('coaching_news', []),
            'sentiment_score': analysis.get('sentiment', 0),
            'importance': analysis.get('importance_score', 0)
        }
```

### 6.3 é«˜å¹¶å‘æ¶æ„ä¼˜åŒ–

#### 6.3.1 ç¼“å­˜ç­–ç•¥å‡çº§

**å¤šå±‚ç¼“å­˜æ¶æ„ï¼š**

```mermaid
graph TD
    A[ç”¨æˆ·è¯·æ±‚] --> B[CDNç¼“å­˜]
    B --> C{ç¼“å­˜å‘½ä¸­?}
    C -->|æ˜¯| D[è¿”å›ç»“æœ]
    C -->|å¦| E[åº”ç”¨å±‚ç¼“å­˜ - Redis]
    E --> F{ç¼“å­˜å‘½ä¸­?}
    F -->|æ˜¯| G[è¿”å›ç»“æœ]
    F -->|å¦| H[æ•°æ®åº“ç¼“å­˜ - Redis]
    H --> I{ç¼“å­˜å‘½ä¸­?}
    I -->|æ˜¯| J[è¿”å›ç»“æœ]
    I -->|å¦| K[æ•°æ®åº“æŸ¥è¯¢]
    K --> L[æ›´æ–°æ‰€æœ‰ç¼“å­˜å±‚]
    L --> M[è¿”å›ç»“æœ]
```

**ç¼“å­˜å®ç°ç­–ç•¥ï¼š**

```python
# src/cache/multi_level_cache.py
class MultiLevelCache:
    def __init__(self):
        self.l1_cache = LocalLRUCache(maxsize=1000)  # æœ¬åœ°ç¼“å­˜
        self.l2_cache = RedisCache(host='redis-cluster')  # åˆ†å¸ƒå¼ç¼“å­˜
        self.l3_cache = DatabaseQueryCache()  # æŸ¥è¯¢ç»“æœç¼“å­˜

    async def get_prediction(self, match_id):
        """å¤šçº§ç¼“å­˜è·å–é¢„æµ‹ç»“æœ"""
        # L1 ç¼“å­˜ - æœ¬åœ°å†…å­˜
        result = self.l1_cache.get(f"prediction:{match_id}")
        if result:
            return result

        # L2 ç¼“å­˜ - Redis
        result = await self.l2_cache.get(f"prediction:{match_id}")
        if result:
            self.l1_cache.set(f"prediction:{match_id}", result, ttl=300)
            return result

        # L3 ç¼“å­˜ - æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜
        result = await self.l3_cache.get_or_compute(
            f"prediction:{match_id}",
            lambda: self._compute_prediction(match_id)
        )

        # æ›´æ–°ä¸Šå±‚ç¼“å­˜
        await self.l2_cache.set(f"prediction:{match_id}", result, ttl=1800)
        self.l1_cache.set(f"prediction:{match_id}", result, ttl=300)

        return result

    async def invalidate_prediction(self, match_id):
        """é¢„æµ‹ç»“æœå¤±æ•ˆå¤„ç†"""
        keys = [f"prediction:{match_id}", f"features:{match_id}"]

        # åˆ é™¤æ‰€æœ‰å±‚çº§çš„ç¼“å­˜
        for key in keys:
            self.l1_cache.delete(key)
            await self.l2_cache.delete(key)
            await self.l3_cache.delete(key)
```

#### 6.3.2 æ¶ˆæ¯é˜Ÿåˆ—æ¶æ„

**å¼‚æ­¥å¤„ç†ç³»ç»Ÿï¼š**

```python
# src/messaging/task_queue.py
class TaskQueueManager:
    def __init__(self):
        self.celery_app = Celery('football_prediction')
        self.kafka_producer = KafkaProducer()

    @celery_app.task(bind=True, max_retries=3)
    def process_prediction_request(self, match_data):
        """å¼‚æ­¥å¤„ç†é¢„æµ‹è¯·æ±‚"""
        try:
            # ç‰¹å¾è®¡ç®—
            features = self._calculate_features(match_data)

            # æ¨¡å‹é¢„æµ‹
            prediction = self._run_prediction(features)

            # ç¼“å­˜ç»“æœ
            self._cache_prediction_result(match_data['match_id'], prediction)

            # å‘é€ç»“æœé€šçŸ¥
            self._notify_prediction_ready(match_data['match_id'], prediction)

        except Exception as exc:
            if self.request.retries < self.max_retries:
                raise self.retry(countdown=60 * (self.request.retries + 1))
            else:
                self._handle_prediction_failure(match_data, str(exc))
```

#### 6.3.3 æ•°æ®åº“è¯»å†™åˆ†ç¦»å’Œåˆ†ç‰‡

**æ•°æ®åº“é›†ç¾¤æ¶æ„ï¼š**

```python
# src/database/cluster_manager.py
class DatabaseClusterManager:
    def __init__(self):
        self.write_db = self._create_master_connection()
        self.read_dbs = self._create_read_replicas()
        self.shard_router = ShardRouter()

    def get_read_connection(self, query_type='general'):
        """è·å–è¯»è¿æ¥"""
        if query_type == 'analytics':
            return self.read_dbs['analytics_replica']
        elif query_type == 'realtime':
            return self.read_dbs['realtime_replica']
        else:
            return random.choice(list(self.read_dbs.values()))

    def get_write_connection(self, table_name, shard_key=None):
        """è·å–å†™è¿æ¥"""
        if shard_key:
            shard = self.shard_router.route(table_name, shard_key)
            return self.write_db[f'shard_{shard}']
        return self.write_db['master']

    async def execute_read_query(self, query, params=None):
        """æ‰§è¡Œè¯»æŸ¥è¯¢"""
        connection = self.get_read_connection()
        return await connection.fetch(query, params)

    async def execute_write_query(self, query, params=None, table_name=None, shard_key=None):
        """æ‰§è¡Œå†™æŸ¥è¯¢"""
        connection = self.get_write_connection(table_name, shard_key)
        return await connection.execute(query, params)
```

### 6.4 ç”¨æˆ·ç”»åƒå’Œä¸ªæ€§åŒ–æ¨è

#### 6.4.1 ç”¨æˆ·è¡Œä¸ºåˆ†æç³»ç»Ÿ

**ç”¨æˆ·ç”»åƒå»ºæ¨¡ï¼š**

```python
# src/personalization/user_profiling.py
class UserProfiler:
    def __init__(self):
        self.behavior_tracker = BehaviorTracker()
        self.preference_engine = PreferenceEngine()
        self.ml_model = UserClusteringModel()

    def build_user_profile(self, user_id):
        """æ„å»ºç”¨æˆ·ç”»åƒ"""
        # æ”¶é›†ç”¨æˆ·è¡Œä¸ºæ•°æ®
        behaviors = self.behavior_tracker.get_user_behaviors(user_id)

        # åˆ†æç”¨æˆ·åå¥½
        preferences = self._analyze_preferences(behaviors)

        # ç”¨æˆ·èšç±»
        cluster = self.ml_model.predict_cluster(preferences)

        profile = {
            'user_id': user_id,
            'favorite_teams': preferences.get('teams', []),
            'favorite_leagues': preferences.get('leagues', []),
            'prediction_accuracy_interest': preferences.get('accuracy_focus', 0.5),
            'risk_tolerance': preferences.get('risk_tolerance', 'medium'),
            'interaction_frequency': behaviors['frequency'],
            'cluster': cluster,
            'created_at': datetime.now()
        }

        return profile

    def _analyze_preferences(self, behaviors):
        """åˆ†æç”¨æˆ·åå¥½"""
        team_interactions = defaultdict(int)
        league_interactions = defaultdict(int)

        for behavior in behaviors:
            if behavior['type'] == 'view_prediction':
                match_info = behavior['match_info']
                team_interactions[match_info['home_team']] += 1
                team_interactions[match_info['away_team']] += 1
                league_interactions[match_info['league']] += 1

        return {
            'teams': sorted(team_interactions.keys(),
                          key=team_interactions.get, reverse=True)[:5],
            'leagues': sorted(league_interactions.keys(),
                            key=league_interactions.get, reverse=True)[:3],
            'accuracy_focus': self._calculate_accuracy_focus(behaviors),
            'risk_tolerance': self._calculate_risk_tolerance(behaviors)
        }
```

#### 6.4.2 ä¸ªæ€§åŒ–æ¨èå¼•æ“

**æ¨èç®—æ³•å®ç°ï¼š**

```python
# src/personalization/recommendation_engine.py
class PersonalizedRecommendationEngine:
    def __init__(self):
        self.collaborative_filter = CollaborativeFiltering()
        self.content_filter = ContentBasedFiltering()
        self.hybrid_model = HybridRecommendationModel()

    async def get_personalized_matches(self, user_id, limit=10):
        """è·å–ä¸ªæ€§åŒ–æ¯”èµ›æ¨è"""
        user_profile = await self._get_user_profile(user_id)

        # åŸºäºå†…å®¹çš„è¿‡æ»¤
        content_recommendations = await self.content_filter.recommend(
            user_profile, limit=limit*2
        )

        # ååŒè¿‡æ»¤
        collaborative_recommendations = await self.collaborative_filter.recommend(
            user_id, limit=limit*2
        )

        # æ··åˆæ¨è
        final_recommendations = self.hybrid_model.combine_recommendations(
            content_recommendations,
            collaborative_recommendations,
            user_profile,
            limit=limit
        )

        return final_recommendations

    async def get_personalized_insights(self, user_id, match_id):
        """è·å–ä¸ªæ€§åŒ–é¢„æµ‹è§è§£"""
        user_profile = await self._get_user_profile(user_id)
        base_prediction = await self._get_base_prediction(match_id)

        # æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´å±•ç¤ºå†…å®¹
        insights = {
            'prediction': base_prediction,
            'confidence_explanation': self._generate_confidence_explanation(
                base_prediction, user_profile
            ),
            'key_factors': self._personalize_key_factors(
                base_prediction['factors'], user_profile
            ),
            'similar_matches': await self._find_similar_matches(
                match_id, user_profile
            )
        }

        return insights
```

#### 6.4.3 æ¨èç³»ç»Ÿè¯„ä¼°æ¡†æ¶

**A/Bæµ‹è¯•å’Œæ•ˆæœè¯„ä¼°ï¼š**

```python
# src/personalization/evaluation.py
class RecommendationEvaluator:
    def __init__(self):
        self.metrics_calculator = MetricsCalculator()
        self.ab_tester = ABTester()

    async def evaluate_recommendation_quality(self, recommendations, user_interactions):
        """è¯„ä¼°æ¨èè´¨é‡"""
        metrics = {
            'precision': self._calculate_precision(recommendations, user_interactions),
            'recall': self._calculate_recall(recommendations, user_interactions),
            'f1_score': self._calculate_f1_score(recommendations, user_interactions),
            'diversity': self._calculate_diversity(recommendations),
            'novelty': self._calculate_novelty(recommendations, user_interactions),
            'coverage': self._calculate_coverage(recommendations)
        }

        return metrics

    async def run_recommendation_ab_test(self, control_algorithm, treatment_algorithm):
        """è¿è¡Œæ¨èç®—æ³•A/Bæµ‹è¯•"""
        test_users = await self._select_test_users()

        # åˆ†é…ç”¨æˆ·åˆ°å¯¹ç…§ç»„å’Œå®éªŒç»„
        control_group, treatment_group = self._split_users(test_users)

        # è¿è¡Œæµ‹è¯•
        control_results = await self._run_recommendation_test(
            control_group, control_algorithm
        )
        treatment_results = await self._run_recommendation_test(
            treatment_group, treatment_algorithm
        )

        # ç»Ÿè®¡åˆ†æ
        significance_test = self._perform_significance_test(
            control_results, treatment_results
        )

        return {
            'control_metrics': control_results['metrics'],
            'treatment_metrics': treatment_results['metrics'],
            'statistical_significance': significance_test,
            'recommendation': self._make_algorithm_recommendation(significance_test)
        }
```

### 6.5 ç³»ç»Ÿæ‰©å±•æ€»ç»“

#### 6.5.1 æ‰©å±•ä¼˜å…ˆçº§æ’åº

**ç¬¬ä¸€ä¼˜å…ˆçº§ï¼ˆ6ä¸ªæœˆå†…ï¼‰ï¼š**

1. æ¨¡å‹è‡ªåŠ¨æ›´æ–°æœºåˆ¶ - ä¿è¯é¢„æµ‹è´¨é‡æŒç»­ä¼˜åŒ–
2. å®æ—¶èµ”ç‡é‡‡é›† - æä¾›æ›´åŠæ—¶çš„å¸‚åœºä¿¡æ¯
3. å¤šå±‚ç¼“å­˜æ¶æ„ - æ”¯æ’‘é«˜å¹¶å‘è®¿é—®éœ€æ±‚

**ç¬¬äºŒä¼˜å…ˆçº§ï¼ˆ12ä¸ªæœˆå†…ï¼‰ï¼š**

1. ç”¨æˆ·ç”»åƒç³»ç»Ÿ - æå‡ç”¨æˆ·ä½“éªŒå’Œç²˜æ€§
2. æ¶ˆæ¯é˜Ÿåˆ—ä¼˜åŒ– - æé«˜ç³»ç»Ÿå“åº”æ€§å’Œå¯é æ€§
3. æ•°æ®åº“é›†ç¾¤åŒ– - æ”¯æ’‘æ›´å¤§è§„æ¨¡æ•°æ®å¤„ç†

**ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼ˆ18ä¸ªæœˆå†…ï¼‰ï¼š**

1. ä¸ªæ€§åŒ–æ¨èå¼•æ“ - å¢å¼ºäº§å“ç«äº‰åŠ›
2. é«˜çº§åˆ†æåŠŸèƒ½ - æä¾›æ›´æ·±å…¥çš„æ•°æ®è§è§£
3. å¤šè¯­è¨€å’Œå¤šåœ°åŒºæ”¯æŒ - æ‰©å¤§ç”¨æˆ·è¦†ç›–é¢

#### 6.5.2 æŠ€æœ¯å€ºåŠ¡ç®¡ç†

**ä»£ç é‡æ„è®¡åˆ’ï¼š**

- å»ºç«‹ä»£ç è´¨é‡ç›‘æ§å’Œè‡ªåŠ¨é‡æ„å·¥å…·
- å®šæœŸè¿›è¡Œæ¶æ„è¯„å®¡å’ŒæŠ€æœ¯å€ºåŠ¡æ¸…ç†
- å®æ–½å¾®æœåŠ¡æ‹†åˆ†ï¼Œæé«˜ç³»ç»Ÿæ¨¡å—åŒ–ç¨‹åº¦

**æ€§èƒ½ä¼˜åŒ–è·¯çº¿å›¾ï¼š**

- å»ºç«‹æ€§èƒ½åŸºå‡†æµ‹è¯•å’ŒæŒç»­ç›‘æ§
- å®æ–½æ¸è¿›å¼æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- å®šæœŸè¿›è¡Œå®¹é‡è§„åˆ’å’Œæ‰©å®¹é¢„æ¡ˆ

**å®‰å…¨åŠ å›ºæªæ–½ï¼š**

- å®æ–½é›¶ä¿¡ä»»å®‰å…¨æ¶æ„
- å»ºç«‹å®‰å…¨æ¼æ´æ‰«æå’Œä¿®å¤æµç¨‹
- åŠ å¼ºæ•°æ®åŠ å¯†å’Œéšç§ä¿æŠ¤æªæ–½

---

## ğŸ“„ æ–‡æ¡£ç‰ˆæœ¬ä¿¡æ¯

- **æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0
- **åˆ›å»ºæ—¥æœŸ**ï¼š2024å¹´1æœˆ
- **æœ€åæ›´æ–°**ï¼š2024å¹´1æœˆ
- **è´Ÿè´£äºº**ï¼šç³»ç»Ÿæ¶æ„å›¢é˜Ÿ
- **å®¡æ ¸çŠ¶æ€**ï¼šå·²å®¡æ ¸é€šè¿‡

## ğŸ“ è”ç³»ä¿¡æ¯

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿï¼š

- **é‚®ç®±**ï¼š<dev-team@football-prediction.com>
- **æŠ€æœ¯æ–‡æ¡£**ï¼š<https://docs.football-prediction.com>
- **é¡¹ç›®ä»“åº“**ï¼š<https://github.com/your-org/football-prediction-system>

---

**æœ¬æ–‡æ¡£ä¸ºè¶³çƒæ¯”èµ›ç»“æœé¢„æµ‹ç³»ç»Ÿçš„æ­£å¼æŠ€æœ¯æ¶æ„è®¾è®¡æ–‡æ¡£ï¼Œæ‰€æœ‰å¼€å‘æ´»åŠ¨åº”ä¸¥æ ¼æŒ‰ç…§æœ¬æ–‡æ¡£æ‰§è¡Œã€‚**
