# v2.0 æŠ€æœ¯å€ºåŠ¡æ¸…å• (Technical Debt Backlog)

**ç‰ˆæœ¬**: v2.0.0-async
**åˆ›å»ºæ—¶é—´**: 2025-12-06
**çŠ¶æ€**: ğŸ”„ æ´»è·ƒ
**ä¼˜å…ˆçº§**: P0-P2 åˆ†çº§ç®¡ç†

---

## ğŸ“Š å€ºåŠ¡æ¦‚è§ˆ

| ä¼˜å…ˆçº§ | æ•°é‡ | çŠ¶æ€ | é¢„è®¡å·¥ä½œé‡ |
|--------|------|------|------------|
| **P0 (ç´§æ€¥)** | 1 | ğŸ”´ å¾…å¤„ç† | 2-4 å°æ—¶ |
| **P1 (é‡è¦)** | 2 | ğŸŸ¡ å¾…å¤„ç† | 1-2 å¤© |
| **P2 (ä¼˜åŒ–)** | 3 | ğŸŸ¢ å¾…å¤„ç† | 3-5 å¤© |
| **æ€»è®¡** | **6** | - | **4-7 å¤©** |

---

## ğŸ”´ P0 - ç´§æ€¥ä¿®å¤ (Critical Issues)

### 1. API å“åº”æ ¼å¼ä¿®å¤
**æ¥æº**: P1-7 æ•°æ®é“¾è·¯å‹æµ‹å‘ç°
**ä¼˜å…ˆçº§**: ğŸ”´ P0 - ä¸¥é‡
**å½±å“èŒƒå›´**: æ ¸å¿ƒä¸šåŠ¡åŠŸèƒ½
**é¢„è®¡å·¥ä½œé‡**: 2-4 å°æ—¶

#### é—®é¢˜æè¿°
```
APIç«¯ç‚¹çŠ¶æ€:
- GET /api/v1/predictions [LIST]: 100% å¤±è´¥ç‡
- GET /api/v1/predictions/match/{id}: 100% å¤±è´¥ç‡
- GET /api/v1/metrics: 100% å¤±è´¥ç‡

é”™è¯¯ç±»å‹: "Invalid response format"
æ ¹æœ¬åŸå› : APIè¿”å›æ•°æ®ç»“æ„ä¸æµ‹è¯•è„šæœ¬æœŸæœ›ä¸åŒ¹é…
```

#### æŠ€æœ¯ç»†èŠ‚
```python
# å½“å‰æœŸæœ›æ ¼å¼ (æµ‹è¯•è„šæœ¬)
if isinstance(data, list):
    response.success()
elif isinstance(data, dict) and "match_id" in data and "prediction" in data:
    response.success()

# å®é™…APIå¯èƒ½è¿”å›æ ¼å¼éœ€è¦éªŒè¯
```

#### è§£å†³æ–¹æ¡ˆ
1. **ç»Ÿä¸€APIå“åº”æ ¼å¼**:
   ```python
   # æ ‡å‡†å“åº”æ ¼å¼
   {
     "success": true,
     "data": [...],  # æˆ– {}
     "message": "Success",
     "timestamp": "2025-12-06T19:02:00Z",
     "request_id": "uuid"
   }
   ```

2. **ä¿®å¤ç«¯ç‚¹**:
   - `/api/v1/predictions` - ç¡®ä¿è¿”å›æ•°ç»„æ ¼å¼
   - `/api/v1/predictions/match/{id}` - ç¡®ä¿è¿”å›å¯¹è±¡æ ¼å¼
   - `/api/v1/metrics` - ç¡®ä¿è¿”å›æ ‡å‡†æŒ‡æ ‡æ ¼å¼

3. **æµ‹è¯•è„šæœ¬é€‚é…**:
   - æ›´æ–°å“åº”éªŒè¯é€»è¾‘
   - å¢åŠ é”™è¯¯å¤„ç†å®¹é”™æ€§

#### éªŒæ”¶æ ‡å‡†
- [ ] æ‰€æœ‰é¢„æµ‹APIç«¯ç‚¹è¿”å›æ ¼å¼ä¸€è‡´
- [ ] é”™è¯¯ç‡ < 1% (P1-7ç›®æ ‡)
- [ ] å“åº”æ—¶é—´ä¿æŒ < 200ms (P95)
- [ ] é€šè¿‡Locustå‹æµ‹éªŒè¯

---

## ğŸŸ¡ P1 - é‡è¦ä¼˜åŒ– (Important Optimizations)

### 2. RateLimiter æ€§èƒ½ä¼˜åŒ–
**æ¥æº**: P1-7 é‡‡é›†å™¨å‹æµ‹å‘ç°
**ä¼˜å…ˆçº§**: ğŸŸ¡ P1 - é‡è¦
**å½±å“èŒƒå›´**: æ•°æ®é‡‡é›†æ€§èƒ½
**é¢„è®¡å·¥ä½œé‡**: 1-2 å¤©

#### é—®é¢˜æè¿°
```
RateLimiteræµ‹è¯•ç»“æœ:
- ç†è®ºé™åˆ¶: 10 QPS (test_domain)
- å®é™…è¡¨ç°: æœªæœ‰æ•ˆé™æµ
- é«˜å¹¶å‘å½±å“: 50å¹¶å‘æ—¶å“åº”æ—¶é—´581ms â†’ 2176ms

ç“¶é¢ˆåˆ†æ: RateLimiteråœ¨é«˜å¹¶å‘ä¸‹æˆä¸ºCPUç“¶é¢ˆ
```

#### æ€§èƒ½åŸºå‡†æ•°æ®
| å¹¶å‘çº§åˆ« | RPS | å¹³å‡å“åº”æ—¶é—´ | P95å“åº”æ—¶é—´ | é™æµæ•ˆæœ |
|----------|-----|-------------|-------------|----------|
| 10 | 139.76 | 71ms | 105ms | âŒ æœªç”Ÿæ•ˆ |
| 25 | 53.06 | 95ms | 141ms | âŒ æœªç”Ÿæ•ˆ |
| 50 | 16.28 | 581ms | 1432ms | âŒ æœªç”Ÿæ•ˆ |
| 100 | 12.39 | 2176ms | 4935ms | âŒ æœªç”Ÿæ•ˆ |

#### ä¼˜åŒ–æ–¹æ¡ˆ

##### æ–¹æ¡ˆA: Redis Luaè„šæœ¬ä¼˜åŒ– (æ¨è)
```python
# ä½¿ç”¨RedisåŸå­æ“ä½œå®ç°é™æµ
LUA_RATE_LIMIT_SCRIPT = """
local key = KEYS[1]
local capacity = tonumber(ARGV[1])
local tokens = tonumber(ARGV[2])
local interval = tonumber(ARGV[3])
local request = tonumber(ARGV[4])

local bucket = redis.call('hmget', key, 'tokens', 'last_refill')
local current_tokens = tonumber(bucket[1]) or capacity
local last_refill = tonumber(bucket[2]) or 0

local now = request
local elapsed = now - last_refill
if elapsed > 0 then
    current_tokens = math.min(capacity, current_tokens + elapsed * tokens / interval)
end

if current_tokens >= 1 then
    current_tokens = current_tokens - 1
    redis.call('hmset', key, 'tokens', current_tokens, 'last_refill', now)
    redis.call('expire', key, interval * 2)
    return 1
else
    redis.call('hmset', key, 'tokens', current_tokens, 'last_refill', now)
    redis.call('expire', key, interval * 2)
    return 0
end
"""
```

##### æ–¹æ¡ˆB: Cæ‰©å±•ä¼˜åŒ–
```python
# ä½¿ç”¨Cythonæˆ–Cæ‰©å±•ä¼˜åŒ–Token Bucketç®—æ³•
# é¢„æœŸæ€§èƒ½æå‡: 5-10å€
```

##### æ–¹æ¡ˆC: å¼‚æ­¥ä¼˜åŒ–æ”¹è¿›
```python
# ä¼˜åŒ–å½“å‰Pythonå®ç°
import asyncio
from asyncio import Semaphore

class AsyncRateLimiter:
    def __init__(self, config):
        self.semaphores = {
            domain: Semaphore(rate)
            for domain, rate in config.items()
        }

    async def acquire(self, domain="default"):
        async with self.semaphores[domain]:
            await asyncio.sleep(1.0 / config[domain].rate)
```

#### å®æ–½è®¡åˆ’
1. **Phase 1**: Redis Luaè„šæœ¬å®ç° (1å¤©)
2. **Phase 2**: æ€§èƒ½æµ‹è¯•éªŒè¯ (0.5å¤©)
3. **Phase 3**: å›é€€æ–¹æ¡ˆå‡†å¤‡ (0.5å¤©)

#### éªŒæ”¶æ ‡å‡†
- [ ] é™æµå™¨åœ¨50å¹¶å‘ä¸‹æœ‰æ•ˆå·¥ä½œ
- [ ] é«˜å¹¶å‘å“åº”æ—¶é—´ < 500ms (P95)
- [ ] é™æµç²¾åº¦è¯¯å·® < 5%
- [ ] é€šè¿‡å‹æµ‹éªŒè¯æ•ˆæœ

### 3. FBref é‡‡é›†å™¨è¿ç§»
**æ¥æº**: P1-1 é—ç•™ä»»åŠ¡
**ä¼˜å…ˆçº§**: ğŸŸ¡ P1 - é‡è¦
**å½±å“èŒƒå›´**: æ•°æ®æºå®Œæ•´æ€§
**é¢„è®¡å·¥ä½œé‡**: 1-2 å¤©

#### é—®é¢˜æè¿°
```
é—ç•™çŠ¶æ€:
- FBrefé€‚é…å™¨æœªè¿ç§»åˆ°æ–°å¼‚æ­¥æ¶æ„
- ä½¿ç”¨åŒæ­¥HTTPè¯·æ±‚ï¼Œä¸ç¬¦åˆv2.0å¼‚æ­¥æ¨¡å¼
- ç¼ºå°‘RateLimiteré›†æˆ
- ç¼ºå°‘é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
```

#### æŠ€æœ¯å€ºåŠ¡åˆ†æ
```python
# å½“å‰é—®é¢˜ä»£ç ç¤ºä¾‹
def fetch_fbref_data(self, url):
    # åŒæ­¥è¯·æ±‚ - ä¸ç¬¦åˆå¼‚æ­¥æ¶æ„
    response = requests.get(url, timeout=30)
    return response.json()

# éœ€è¦è¿ç§»åˆ°å¼‚æ­¥æ¨¡å¼
async def fetch_fbref_data(self, url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url, timeout=30) as response:
            return await response.json()
```

#### è¿ç§»æ–¹æ¡ˆ

##### 1. æ¶æ„å¯¹é½
```python
# é€‚é…æ–°çš„æ•°æ®æºå·¥å‚æ¨¡å¼
from src.adapters.factory import DataSourceFactory

class FBrefAdapter(BaseAdapter):
    def __init__(self, rate_limiter: RateLimiter, proxy_pool: ProxyPool):
        self.rate_limiter = rate_limiter
        self.proxy_pool = proxy_pool

    async def fetch_match_data(self, match_id: str):
        domain = "fbref.com"
        async with self.rate_limiter.acquire(domain):
            return await self._make_request(f"/matches/{match_id}")
```

##### 2. é›†æˆç°æœ‰åŸºç¡€è®¾æ–½
- RateLimiteré›†æˆ
- ProxyPoolæ”¯æŒ
- TokenManagerè®¤è¯
- é”™è¯¯å¤„ç†å’Œé‡è¯•

##### 3. æµ‹è¯•è¦†ç›–
- å•å…ƒæµ‹è¯•
- é›†æˆæµ‹è¯•
- å‹æµ‹éªŒè¯

#### å®æ–½è®¡åˆ’
1. **é‡æ„æ ¸å¿ƒé€»è¾‘** (0.5å¤©)
2. **é›†æˆæ–°æ¶æ„ç»„ä»¶** (0.5å¤©)
3. **æµ‹è¯•å’ŒéªŒè¯** (0.5å¤©)
4. **æ–‡æ¡£æ›´æ–°** (0.5å¤©)

#### éªŒæ”¶æ ‡å‡†
- [ ] å®Œå…¨å¼‚æ­¥åŒ–å®ç°
- [ ] é›†æˆRateLimiterå’ŒProxyPool
- [ ] é€šè¿‡æ‰€æœ‰å•å…ƒæµ‹è¯•
- [ ] æ•°æ®é‡‡é›†æˆåŠŸç‡ > 95%

---

## ğŸŸ¢ P2 - æ€§èƒ½ä¼˜åŒ– (Performance Optimizations)

### 4. é«˜å¹¶å‘æ€§èƒ½ä¼˜åŒ–
**æ¥æº**: P1-7 å‹æµ‹æ•°æ®åˆ†æ
**ä¼˜å…ˆçº§**: ğŸŸ¢ P2 - ä¼˜åŒ–
**å½±å“èŒƒå›´**: ç³»ç»Ÿæ•´ä½“æ€§èƒ½
**é¢„è®¡å·¥ä½œé‡**: 1-2 å¤©

#### æ€§èƒ½ç“¶é¢ˆåˆ†æ
```
é«˜å¹¶å‘æ€§èƒ½è¡°å‡:
- 25å¹¶å‘ â†’ 50å¹¶å‘: RPSä»53.06é™è‡³16.28 (-69%)
- 50å¹¶å‘ â†’ 100å¹¶å‘: å“åº”æ—¶é—´ä»581mså¢è‡³2176ms (+275%)

æ ¹æœ¬åŸå› : èµ„æºç«äº‰å’Œå¼‚æ­¥å¤„ç†æ•ˆç‡
```

#### ä¼˜åŒ–ç­–ç•¥

##### 1. å¼‚æ­¥å¹¶å‘æ§åˆ¶
```python
import asyncio
from asyncio import Semaphore, BoundedSemaphore

class ConcurrencyManager:
    def __init__(self, max_concurrent=50):
        self.semaphore = BoundedSemaphore(max_concurrent)
        self.active_tasks = set()

    async def execute_with_limit(self, coro):
        async with self.semaphore:
            task = asyncio.create_task(coro)
            self.active_tasks.add(task)
            task.add_done_callback(self.active_tasks.discard)
            return await task
```

##### 2. è¿æ¥æ± ä¼˜åŒ–
```python
# Redisè¿æ¥æ± ä¼˜åŒ–
REDIS_POOL_CONFIG = {
    "max_connections": 100,
    "retry_on_timeout": True,
    "socket_timeout": 5,
    "socket_connect_timeout": 2,
    "health_check_interval": 30
}

# HTTPè¿æ¥æ± ä¼˜åŒ–
HTTP_POOL_CONFIG = {
    "limit": 100,
    "limit_per_host": 50,
    "timeout": aiohttp.ClientTimeout(total=30)
}
```

##### 3. å†…å­˜å’ŒCPUä¼˜åŒ–
```python
# ä½¿ç”¨å†…å­˜è§†å›¾å‡å°‘æ‹·è´
def process_large_data(data: bytes):
    view = memoryview(data)
    # å¤„ç†é€»è¾‘...

# ä½¿ç”¨ç”Ÿæˆå™¨å‡å°‘å†…å­˜å ç”¨
async def stream_processing(items):
    for item in items:
        yield await process_item(item)
```

#### éªŒæ”¶æ ‡å‡†
- [ ] 100å¹¶å‘ä¸‹å“åº”æ—¶é—´ < 1000ms (P95)
- [ ] ç³»ç»Ÿååé‡æå‡ 50%+
- [ ] å†…å­˜ä½¿ç”¨ç¨³å®šï¼Œæ— æ³„æ¼
- [ ] CPUä½¿ç”¨ç‡ < 80%

### 5. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
**æ¥æº**: P1-6 ç¼“å­˜ç³»ç»Ÿä½¿ç”¨åˆ†æ
**ä¼˜å…ˆçº§**: ğŸŸ¢ P2 - ä¼˜åŒ–
**å½±å“èŒƒå›´**: ç¼“å­˜æ•ˆç‡å’Œæˆæœ¬
**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### å½“å‰ç¼“å­˜è¡¨ç°
```
P1-6ç¼“å­˜æ•ˆæœ:
- ç‰¹å¾æœåŠ¡: 52.17ms â†’ 0.27ms (99.5% åŠ é€Ÿ)
- é¢„æµ‹æœåŠ¡: 81.10ms â†’ 0.36ms (99.6% åŠ é€Ÿ)
- å‘½ä¸­ç‡: æ¥è¿‘100%

ä¼˜åŒ–ç©ºé—´:
- TTLç­–ç•¥ä¼˜åŒ–
- ç¼“å­˜é¢„çƒ­
- æ™ºèƒ½å¤±æ•ˆ
```

#### ä¼˜åŒ–æ–¹æ¡ˆ

##### 1. æ™ºèƒ½TTLç­–ç•¥
```python
class SmartTTLManager:
    def __init__(self):
        self.access_patterns = {}

    def calculate_ttl(self, key: str, data_type: str) -> int:
        """åŸºäºè®¿é—®æ¨¡å¼åŠ¨æ€è®¡ç®—TTL"""
        pattern = self.access_patterns.get(key, {})
        frequency = pattern.get("frequency", 0)
        last_access = pattern.get("last_access", 0)

        if frequency > 10:  # é«˜é¢‘è®¿é—®
            return 3600  # 1å°æ—¶
        elif frequency > 5:  # ä¸­é¢‘è®¿é—®
            return 1800  # 30åˆ†é’Ÿ
        else:  # ä½é¢‘è®¿é—®
            return 300   # 5åˆ†é’Ÿ
```

##### 2. ç¼“å­˜é¢„çƒ­ç³»ç»Ÿ
```python
class CacheWarmer:
    async def warm_hot_data(self):
        """é¢„çƒ­çƒ­ç‚¹æ•°æ®"""
        hot_matches = await self.get_hot_matches()
        for match_id in hot_matches:
            await self.preload_match_data(match_id)

    async def warm_features(self):
        """é¢„çƒ­ç‰¹å¾æ•°æ®"""
        active_features = await self.get_active_features()
        for feature_id in active_features:
            await self.preload_feature_data(feature_id)
```

##### 3. åˆ†å±‚ç¼“å­˜ç­–ç•¥
```python
# L1: å†…å­˜ç¼“å­˜ (æœ€å¿«)
# L2: Redisç¼“å­˜ (å¿«)
# L3: æ•°æ®åº“ (æ…¢)

class TieredCache:
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache = RedisCache()  # Redisç¼“å­˜
        self.l3_storage = Database()  # æ•°æ®åº“

    async def get(self, key: str):
        # L1 -> L2 -> L3 æŸ¥æ‰¾
        if key in self.l1_cache:
            return self.l1_cache[key]

        data = await self.l2_cache.get(key)
        if data:
            self.l1_cache[key] = data
            return data

        data = await self.l3_storage.get(key)
        if data:
            await self.l2_cache.set(key, data)
            self.l1_cache[key] = data
        return data
```

#### éªŒæ”¶æ ‡å‡†
- [ ] ç¼“å­˜å‘½ä¸­ç‡ä¿æŒ > 95%
- [ ] å†…å­˜ä½¿ç”¨ä¼˜åŒ– 20%+
- [ ] ç¼“å­˜é¢„çƒ­è¦†ç›–ç‡ > 80%
- [ ] æ™ºèƒ½TTLå‡å°‘æ— æ•ˆç¼“å­˜

### 6. ç›‘æ§å’Œå‘Šè­¦å¢å¼º
**æ¥æº**: P1-7 å‹æµ‹ç›‘æ§éœ€æ±‚
**ä¼˜å…ˆçº§**: ğŸŸ¢ P2 - ä¼˜åŒ–
**å½±å“èŒƒå›´**: è¿ç»´å’Œå¯è§‚æµ‹æ€§
**é¢„è®¡å·¥ä½œé‡**: 1 å¤©

#### å½“å‰ç›‘æ§ç¼ºå£
```
ç›‘æ§ç°çŠ¶:
- åŸºç¡€å¥åº·æ£€æŸ¥ âœ…
- PrometheusæŒ‡æ ‡ âš ï¸ éƒ¨åˆ†è¦†ç›–
- é”™è¯¯è¿½è¸ª âŒ ç¼ºå¤±
- æ€§èƒ½å‘Šè­¦ âŒ ç¼ºå¤±
- ä¸šåŠ¡ç›‘æ§ âŒ ç¼ºå¤±
```

#### ç›‘æ§å¢å¼ºæ–¹æ¡ˆ

##### 1. æ ¸å¿ƒæŒ‡æ ‡ç›‘æ§
```python
from prometheus_client import Counter, Histogram, Gauge

# ä¸šåŠ¡æŒ‡æ ‡
REQUEST_COUNT = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'API request duration')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Active connections')

# ç¼“å­˜æŒ‡æ ‡
CACHE_HIT_RATE = Gauge('cache_hit_rate', 'Cache hit rate', ['cache_type'])
CACHE_SIZE = Gauge('cache_size_bytes', 'Cache size in bytes')

# æ•°æ®é‡‡é›†æŒ‡æ ‡
COLLECTION_SUCCESS = Counter('data_collection_success_total', 'Successful data collections', ['source'])
COLLECTION_ERRORS = Counter('data_collection_errors_total', 'Data collection errors', ['source', 'error_type'])
```

##### 2. å‘Šè­¦è§„åˆ™
```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
- name: football_prediction_alerts
  rules:
  - alert: HighErrorRate
    expr: rate(api_requests_total{status!~"2.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate detected"

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m])) > 0.2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "95th percentile response time too high"
```

##### 3. æ—¥å¿—ç»“æ„åŒ–
```python
import structlog

logger = structlog.get_logger()

# ç»“æ„åŒ–æ—¥å¿—
async def process_request(request):
    logger.info(
        "Processing request",
        request_id=request.id,
        method=request.method,
        path=request.path,
        user_id=request.user_id
    )

    try:
        result = await business_logic(request)
        logger.info(
            "Request completed",
            request_id=request.id,
            duration_ms=processing_time,
            result_count=len(result)
        )
        return result
    except Exception as e:
        logger.error(
            "Request failed",
            request_id=request.id,
            error=str(e),
            error_type=type(e).__name__
        )
        raise
```

##### 4. å¥åº·æ£€æŸ¥å¢å¼º
```python
async def comprehensive_health_check():
    """å…¨é¢å¥åº·æ£€æŸ¥"""
    checks = {
        "database": await check_database_health(),
        "redis": await check_redis_health(),
        "cache": await check_cache_performance(),
        "external_apis": await check_external_apis(),
        "system_resources": await check_system_resources()
    }

    overall_status = "healthy" if all(
        check["status"] == "healthy" for check in checks.values()
    ) else "unhealthy"

    return {
        "status": overall_status,
        "timestamp": datetime.utcnow().isoformat(),
        "checks": checks
    }
```

#### å®æ–½è®¡åˆ’
1. **æŒ‡æ ‡æ”¶é›†** (0.5å¤©)
2. **å‘Šè­¦é…ç½®** (0.25å¤©)
3. **æ—¥å¿—ç»“æ„åŒ–** (0.25å¤©)

#### éªŒæ”¶æ ‡å‡†
- [ ] æ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡ 100% è¦†ç›–
- [ ] å‘Šè­¦è§„åˆ™ç”Ÿæ•ˆï¼Œè¯¯æŠ¥ç‡ < 5%
- [ ] æ—¥å¿—ç»“æ„åŒ–å®Œæˆï¼Œæ”¯æŒæŸ¥è¯¢åˆ†æ
- [ ] å¥åº·æ£€æŸ¥è¦†ç›–æ‰€æœ‰å…³é”®ç»„ä»¶

---

## ğŸ“‹ å€ºåŠ¡ç®¡ç†ç­–ç•¥

### ä¼˜å…ˆçº§å¤„ç†åŸåˆ™

#### ğŸ”´ P0 - ç«‹å³å¤„ç† (24å°æ—¶å†…)
- **APIå“åº”æ ¼å¼ä¿®å¤**: å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œé˜»å¡æ€§é—®é¢˜
- **å¤„ç†æ–¹å¼**: åœæ­¢æ–°åŠŸèƒ½å¼€å‘ï¼Œå…¨åŠ›ä¿®å¤
- **èµ„æºåˆ†é…**: 100% å¼€å‘èµ„æº

#### ğŸŸ¡ P1 - æœ¬å‘¨å¤„ç† (3-5å¤©å†…)
- **RateLimiterä¼˜åŒ–**: æ€§èƒ½ç“¶é¢ˆï¼Œå½±å“æ‰©å±•æ€§
- **FBrefè¿ç§»**: æŠ€æœ¯å€ºåŠ¡ï¼Œå½±å“æ¶æ„ä¸€è‡´æ€§
- **å¤„ç†æ–¹å¼**: æ­£å¸¸è¿­ä»£ï¼Œä¼˜å…ˆå¤„ç†
- **èµ„æºåˆ†é…**: 60% å¼€å‘èµ„æº

#### ğŸŸ¢ P2 - ä¸‹ä¸ªè¿­ä»£ (1-2å‘¨å†…)
- **æ€§èƒ½ä¼˜åŒ–**: æŒç»­æ”¹è¿›ï¼Œä¸å½±å“å½“å‰åŠŸèƒ½
- **ç›‘æ§å¢å¼º**: è¿ç»´æ”¹è¿›ï¼Œæå‡å¯è§‚æµ‹æ€§
- **å¤„ç†æ–¹å¼**: æŠ€æœ¯å€ºåŠ¡æ—¶é—´ï¼Œé€æ­¥å¤„ç†
- **èµ„æºåˆ†é…**: 40% å¼€å‘èµ„æº

### å€ºåŠ¡é¢„é˜²æªæ–½

#### ä»£ç è´¨é‡æ§åˆ¶
```bash
# é¢„æäº¤æ£€æŸ¥
make prepush  # åŒ…å«: lint, test, security, type-check

# CI/CDé›†æˆ
make ci       # å®Œæ•´è´¨é‡æ£€æŸ¥
```

#### æ¶æ„è¯„å®¡æµç¨‹
1. **è®¾è®¡è¯„å®¡**: æ–°åŠŸèƒ½æ¶æ„è®¾è®¡å¿…é¡»è¯„å®¡
2. **ä»£ç è¯„å®¡**: æ‰€æœ‰ä»£ç å˜æ›´éœ€è¦è¯„å®¡
3. **æ€§èƒ½è¯„å®¡**: æ€§èƒ½æ•æ„Ÿä»£ç éœ€è¦ä¸“é¡¹è¯„å®¡

#### æµ‹è¯•è¦†ç›–è¦æ±‚
- **å•å…ƒæµ‹è¯•**: è¦†ç›–ç‡ > 80%
- **é›†æˆæµ‹è¯•**: å…³é”®æµç¨‹ 100% è¦†ç›–
- **æ€§èƒ½æµ‹è¯•**: æ‰€æœ‰APIç«¯ç‚¹åŸºå‡†æµ‹è¯•

---

## ğŸ“Š å€ºåŠ¡å½±å“åˆ†æ

### å½“å‰æŠ€æœ¯å€ºåŠ¡å½±å“

#### å¼€å‘æ•ˆç‡å½±å“
- **Bugä¿®å¤æ—¶é—´**: å¹³å‡å¢åŠ  30%
- **æ–°åŠŸèƒ½å¼€å‘**: å¹³å‡å¢åŠ  20% å·¥ä½œé‡
- **ä»£ç ç»´æŠ¤**: è®¤çŸ¥æˆæœ¬å¢åŠ  40%

#### ç³»ç»Ÿæ€§èƒ½å½±å“
- **å“åº”æ—¶é—´**: P1-7å‘ç°47.4%é”™è¯¯ç‡
- **å¹¶å‘èƒ½åŠ›**: é«˜å¹¶å‘ä¸‹æ€§èƒ½è¡°å‡69%
- **èµ„æºåˆ©ç”¨ç‡**: CPU/å†…å­˜ä½¿ç”¨æ•ˆç‡ä½

#### è¿ç»´æˆæœ¬å½±å“
- **æ•…éšœæ’æŸ¥**: ç¼ºä¹ç›‘æ§ï¼Œæ’æŸ¥æ—¶é—´å¢åŠ 
- **å®¹é‡è§„åˆ’**: ç¼ºä¹åŸºå‡†æ•°æ®ï¼Œè§„åˆ’å›°éš¾
- **å‘Šè­¦å“åº”**: ç¼ºä¹å‘Šè­¦ï¼Œè¢«åŠ¨å“åº”

### å€ºåŠ¡æ¸…ç†æ”¶ç›Šé¢„æœŸ

#### çŸ­æœŸæ”¶ç›Š (1-2å‘¨)
- **APIå¯é æ€§**: ä»47.4%é”™è¯¯ç‡é™è‡³<1%
- **å¼€å‘æ•ˆç‡**: å‡å°‘20%è¿”å·¥æ—¶é—´
- **ç³»ç»Ÿç¨³å®šæ€§**: æ¶ˆé™¤é˜»å¡æ€§é—®é¢˜

#### ä¸­æœŸæ”¶ç›Š (1-2æœˆ)
- **æ€§èƒ½æå‡**: é«˜å¹¶å‘æ€§èƒ½æå‡50%+
- **è¿ç»´æ•ˆç‡**: ç›‘æ§å‘Šè­¦å‡å°‘80%è¢«åŠ¨å“åº”
- **æ‰©å±•æ€§**: æ”¯æŒæ›´é«˜å¹¶å‘è´Ÿè½½

#### é•¿æœŸæ”¶ç›Š (3-6æœˆ)
- **æŠ€æœ¯å€ºåŠ¡å‡å°‘**: å»ºç«‹è‰¯å¥½çš„æŠ€æœ¯å€ºåŠ¡ç®¡ç†æµç¨‹
- **å›¢é˜Ÿæ•ˆèƒ½**: å¼€å‘æ•ˆç‡æå‡30%+
- **ç³»ç»Ÿå¯é æ€§**: 99.9%+å¯ç”¨æ€§ä¿éšœ

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: ç´§æ€¥ä¿®å¤ (Week 1)
```
Day 1-2: APIå“åº”æ ¼å¼ä¿®å¤
â”œâ”€â”€ ä¿®å¤é¢„æµ‹APIç«¯ç‚¹
â”œâ”€â”€ ç»Ÿä¸€å“åº”æ ¼å¼
â”œâ”€â”€ æ›´æ–°æµ‹è¯•è„šæœ¬
â””â”€â”€ å‹æµ‹éªŒè¯

Day 3-5: RateLimiterä¼˜åŒ–
â”œâ”€â”€ Redis Luaè„šæœ¬å®ç°
â”œâ”€â”€ æ€§èƒ½æµ‹è¯•éªŒè¯
â””â”€â”€ æ–‡æ¡£æ›´æ–°
```

### Phase 2: æ¶æ„å®Œå–„ (Week 2)
```
Day 6-7: FBrefè¿ç§»
â”œâ”€â”€ å¼‚æ­¥æ¶æ„é€‚é…
â”œâ”€â”€ é›†æˆç°æœ‰ç»„ä»¶
â””â”€â”€ æµ‹è¯•éªŒè¯

Day 8-10: é«˜å¹¶å‘ä¼˜åŒ–
â”œâ”€â”€ å¹¶å‘æ§åˆ¶ä¼˜åŒ–
â”œâ”€â”€ è¿æ¥æ± è°ƒä¼˜
â””â”€â”€ å†…å­˜ç®¡ç†ä¼˜åŒ–
```

### Phase 3: è¿ç»´å¢å¼º (Week 3)
```
Day 11-12: ç›‘æ§å‘Šè­¦
â”œâ”€â”€ æŒ‡æ ‡æ”¶é›†
â”œâ”€â”€ å‘Šè­¦é…ç½®
â””â”€â”€ æ—¥å¿—ç»“æ„åŒ–

Day 13-15: ç¼“å­˜ä¼˜åŒ–
â”œâ”€â”€ æ™ºèƒ½TTLç­–ç•¥
â”œâ”€â”€ ç¼“å­˜é¢„çƒ­
â””â”€â”€ åˆ†å±‚ç¼“å­˜
```

---

## ğŸ“ è´£ä»»åˆ†é…

### æ ¸å¿ƒå¼€å‘å›¢é˜Ÿ
- **æ¶æ„å¸ˆ**: RateLimiterä¼˜åŒ–ã€é«˜å¹¶å‘ä¼˜åŒ–
- **åç«¯å¼€å‘**: APIä¿®å¤ã€FBrefè¿ç§»
- **è¿ç»´å·¥ç¨‹å¸ˆ**: ç›‘æ§å‘Šè­¦ã€ç¼“å­˜ä¼˜åŒ–
- **æµ‹è¯•å·¥ç¨‹å¸ˆ**: å‹æµ‹éªŒè¯ã€å›å½’æµ‹è¯•

### åä½œæµç¨‹
1. **æ¯æ—¥ç«™ä¼š**: è¿›åº¦åŒæ­¥ã€é˜»å¡é—®é¢˜è¯†åˆ«
2. **ä»£ç è¯„å®¡**: æ‰€æœ‰ä»£ç å˜æ›´å¿…é¡»è¯„å®¡
3. **å‘¨åº¦å›é¡¾**: å€ºåŠ¡æ¸…ç†è¿›åº¦è¯„ä¼°
4. **é‡Œç¨‹ç¢‘éªŒè¯**: æ¯ä¸ªPhaseç»“æŸæ—¶çš„è´¨é‡æ£€æŸ¥

---

**ğŸ“‹ æŠ€æœ¯å€ºåŠ¡æ¸…å•å»ºç«‹å®Œæˆï¼**

**å½“å‰çŠ¶æ€**: 6ä¸ªå€ºåŠ¡é¡¹ç›®ï¼Œé¢„è®¡4-7å¤©å®Œæˆ
**é‡ç‚¹å…³æ³¨**: APIå“åº”æ ¼å¼ä¿®å¤(P0) -> RateLimiterä¼˜åŒ–(P1) -> FBrefè¿ç§»(P1)
**ç›®æ ‡**: åœ¨ä¸‹ä¸ªå‘å¸ƒå‘¨æœŸå‰æ¸…ç†æ‰€æœ‰P0-P1å€ºåŠ¡

**æŠ€æœ¯å€ºåŠ¡æ˜¯æŠ€æœ¯è¿›æ­¥çš„å‚¬åŒ–å‰‚ï¼Œæœ‰åºç®¡ç†æ‰èƒ½æŒç»­åˆ›æ–°ï¼** ğŸš€