from typing import List
from typing import Optional
from datetime import datetime
"""
Phase 4A Week 3 - ç»¼åˆæœåŠ¡é›†æˆæµ‹è¯•å¥—ä»¶

Comprehensive Service Integration Test Suite

è¿™ä¸ªæµ‹è¯•æ–‡ä»¶æä¾›ç«¯åˆ°ç«¯çš„æœåŠ¡é›†æˆæµ‹è¯•,åŒ…æ‹¬ï¼š
- ç”¨æˆ·æœåŠ¡åˆ°é¢„æµ‹æœåŠ¡çš„å®Œæ•´æµç¨‹
- æ•°æ®å¤„ç†ç®¡é“çš„ç«¯åˆ°ç«¯æµ‹è¯•
- ç¼“å­˜æœåŠ¡ä¸æ•°æ®åº“æœåŠ¡çš„é›†æˆ
- å¤–éƒ¨APIé›†æˆæµ‹è¯•
- å®Œæ•´ä¸šåŠ¡æµç¨‹éªŒè¯

æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡:>=95%
"""

import asyncio
import time
import uuid
from dataclasses import dataclass
from enum import Enum

import pytest

# å¯¼å…¥æµ‹è¯•å·¥å…·
try:
    from httpx import AsyncClient
except ImportError:
    AsyncClient = Mock

# å¯¼å…¥Phase 4A Mockå·¥å‚
try:
    from tests.unit.mocks.mock_factory_phase4a import Phase4AMockFactory
except ImportError:
    # ç®€åŒ–çš„Mockå·¥å‚
    class Phase4AMockFactory:
        @staticmethod
        def create_mock_user_service():
            return Mock()

        @staticmethod
        def create_mock_cache_service():
            return Mock()

        @staticmethod
        def create_mock_database_service():
            return Mock()

        @staticmethod
        def create_mock_prediction_service():
            return Mock()


class IntegrationTestScenario(Enum):
    """é›†æˆæµ‹è¯•åœºæ™¯æšä¸¾"""

    USER_PREDICTION_FLOW = "user_prediction_flow"
    DATA_PROCESSING_PIPELINE = "data_processing_pipeline"
    CACHE_DATABASE_SYNC = "cache_database_sync"
    EXTERNAL_API_INTEGRATION = "external_api_integration"
    PERFORMANCE_MONITORING = "performance_monitoring"


@dataclass
class TestMetrics:
    """æµ‹è¯•æŒ‡æ ‡"""

    start_time: datetime
    end_time: Optional[datetime] = None
    response_times: List[float] = None
    error_count: int = 0
    success_count: int = 0

    def __post_init__(self):
        if self.response_times is None:
            self.response_times = []

    @property
    def duration(self) -> float:
        if self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return (datetime.now() - self.start_time).total_seconds()

    @property
    def avg_response_time(self) -> float:
        return sum(self.response_times) / len(self.response_times) if self.response_times else 0

    @property
    def success_rate(self) -> float:
        total = self.success_count + self.error_count
        return self.success_count / total if total > 0 else 0


class TestServiceIntegration:
    """æœåŠ¡é›†æˆæµ‹è¯•"""

    @pytest.fixture
    def mock_services(self):
        """MockæœåŠ¡é›†åˆ"""
        return {
            "user_service": Phase4AMockFactory.create_mock_user_service(),
            "cache_service": Phase4AMockFactory.create_mock_cache_service(),
            "database_service": Phase4AMockFactory.create_mock_database_service(),
            "prediction_service": Phase4AMockFactory.create_mock_prediction_service(),
        }

    @pytest.fixture
    def api_client(self):
        """APIå®¢æˆ·ç«¯"""
        return AsyncClient(base_url="http://localhost:8000")

    @pytest.fixture
    def test_metrics(self):
        """æµ‹è¯•æŒ‡æ ‡æ”¶é›†å™¨"""
        return TestMetrics(start_time=datetime.now())

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_user_registration_to_prediction_flow(self, api_client, test_metrics):
        """æµ‹è¯•ç”¨æˆ·æ³¨å†Œåˆ°é¢„æµ‹çš„å®Œæ•´æµç¨‹"""
        scenario = IntegrationTestScenario.USER_PREDICTION_FLOW

        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: {scenario.value}")

        # 1. ç”¨æˆ·æ³¨å†Œ
        start_time = time.time()
        user_data = {
            "username": f"test_user_{int(time.time())}",
            "email": f"test_{int(time.time())}@example.com",
            "password": "SecurePass123!",
            "first_name": "Test",
            "last_name": "User",
        }

        with patch("httpx.AsyncClient.post") as mock_post:
            mock_post.return_value.status_code = 201
            mock_post.return_value.json.return_value = {
                "id": str(uuid.uuid4()),
                "username": user_data["username"],
                "email": user_data["email"],
            }

            response = await api_client.post("/api/v1/auth/register", json=user_data)
            assert response.status_code == 201

            registration_time = time.time() - start_time
            test_metrics.response_times.append(registration_time)
            test_metrics.success_count += 1

        print(f"âœ… ç”¨æˆ·æ³¨å†Œå®Œæˆ ({registration_time:.3f}s)")

        # 2. ç”¨æˆ·ç™»å½•
        start_time = time.time()
        login_data = {
            "username": user_data["username"],
            "password": user_data["password"],
        }

        with patch("httpx.AsyncClient.post") as mock_post:
            mock_post.return_value.status_code = 200
            mock_post.return_value.json.return_value = {
                "access_token": "mock_token",
                "refresh_token": "mock_refresh",
                "expires_in": 3600,
            }

            response = await api_client.post("/api/v1/auth/login", json=login_data)
            assert response.status_code == 200
            assert "access_token" in response.json()

            login_time = time.time() - start_time
            test_metrics.response_times.append(login_time)
            test_metrics.success_count += 1

        print(f"âœ… ç”¨æˆ·ç™»å½•å®Œæˆ ({login_time:.3f}s)")

        # 3. è·å–æ¯”èµ›æ•°æ®
        start_time = time.time()
        token = "mock_token"
        headers = {"Authorization": f"Bearer {token}"}

        with patch("httpx.AsyncClient.get") as mock_get:
            mock_get.return_value.status_code = 200
            mock_get.return_value.json.return_value = {
                "matches": [
                    {
                        "id": 1,
                        "home_team": "Manchester United",
                        "away_team": "Liverpool",
                        "date": "2025-10-26T15:00:00Z",
                        "odds": {"home_win": 2.1, "draw": 3.4, "away_win": 3.2},
                    }
                ]
            }

            response = await api_client.get("/api/v1/matches/upcoming", headers=headers)
            assert response.status_code == 200
            matches = response.json()["matches"]
            assert len(matches) > 0

            matches_time = time.time() - start_time
            test_metrics.response_times.append(matches_time)
            test_metrics.success_count += 1

        print(f"âœ… è·å–æ¯”èµ›æ•°æ®å®Œæˆ ({matches_time:.3f}s)")

        # 4. åˆ›å»ºé¢„æµ‹
        start_time = time.time()
        prediction_data = {"match_id": 1, "prediction": "home_win", "confidence": 0.75}

        with patch("httpx.AsyncClient.post") as mock_post:
            mock_post.return_value.status_code = 201
            mock_post.return_value.json.return_value = {
                "id": str(uuid.uuid4()),
                "match_id": prediction_data["match_id"],
                "prediction": prediction_data["prediction"],
                "confidence": prediction_data["confidence"],
                "created_at": datetime.now().isoformat(),
            }

            response = await api_client.post(
                "/api/v1/predictions", json=prediction_data, headers=headers
            )
            assert response.status_code == 201

            prediction_time = time.time() - start_time
            test_metrics.response_times.append(prediction_time)
            test_metrics.success_count += 1

        print(f"âœ… åˆ›å»ºé¢„æµ‹å®Œæˆ ({prediction_time:.3f}s)")

        # æµ‹è¯•æŒ‡æ ‡éªŒè¯
        test_metrics.end_time = datetime.now()
        total_time = test_metrics.duration
        avg_response = test_metrics.avg_response_time
        success_rate = test_metrics.success_rate

        print("ğŸ“Š æµç¨‹æµ‹è¯•å®Œæˆ:")
        print(f"   æ€»è€—æ—¶: {total_time:.3f}s")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response:.3f}s")
        print(f"   æˆåŠŸç‡: {success_rate:.1%}")

        # æ€§èƒ½æ–­è¨€
        assert total_time < 5.0, f"æµç¨‹æ€»æ—¶é—´è¿‡é•¿: {total_time:.3f}s"
        assert avg_response < 1.0, f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response:.3f}s"
        assert success_rate == 1.0, f"æˆåŠŸç‡ä¸è¾¾æ ‡: {success_rate:.1%}"

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_data_processing_pipeline_integration(self, mock_services, test_metrics):
        """æµ‹è¯•æ•°æ®å¤„ç†ç®¡é“é›†æˆ"""
        scenario = IntegrationTestScenario.DATA_PROCESSING_PIPELINE
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: {scenario.value}")

        # æ¨¡æ‹Ÿæ•°æ®æµå…¥ -> å¤„ç† -> å­˜å‚¨çš„å®Œæ•´ç®¡é“

        # 1. æ•°æ®æ”¶é›†
        start_time = time.time()
        with patch.object(mock_services["database_service"], "execute_query") as mock_query:
            mock_query.return_value = {
                "success": True,
                "rows": [
                    {"id": 1, "team": "Man United", "goals": 2},
                    {"id": 2, "team": "Liverpool", "goals": 1},
                ],
            }

            result = await mock_services["database_service"].execute_query("SELECT * FROM matches")
            assert result["success"] is True
            assert len(result["rows"]) == 2

            collection_time = time.time() - start_time
            test_metrics.response_times.append(collection_time)
            test_metrics.success_count += 1

        print(f"âœ… æ•°æ®æ”¶é›†å®Œæˆ ({collection_time:.3f}s)")

        # 2. æ•°æ®å¤„ç†
        start_time = time.time()
        processed_data = []

        for row in result["rows"]:
            processed_row = {
                "id": row["id"],
                "team": row["team"],
                "goals": row["goals"],
                "performance_score": row["goals"] * 10,
                "processed_at": datetime.now(),
            }
            processed_data.append(processed_row)

        processing_time = time.time() - start_time
        test_metrics.response_times.append(processing_time)
        test_metrics.success_count += 1

        print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ ({processing_time:.3f}s)")

        # 3. æ•°æ®å­˜å‚¨
        start_time = time.time()
        with patch.object(mock_services["database_service"], "execute_query") as mock_insert:
            mock_insert.return_value = {
                "success": True,
                "rows_affected": len(processed_data),
            }

            insert_result = await mock_services["database_service"].execute_query(
                "INSERT INTO processed_data VALUES (...)", processed_data
            )
            assert insert_result["success"] is True
            assert insert_result["rows_affected"] == len(processed_data)

            storage_time = time.time() - start_time
            test_metrics.response_times.append(storage_time)
            test_metrics.success_count += 1

        print(f"âœ… æ•°æ®å­˜å‚¨å®Œæˆ ({storage_time:.3f}s)")

        # 4. ç¼“å­˜æ›´æ–°
        start_time = time.time()
        with patch.object(mock_services["cache_service"], "set") as mock_cache:
            mock_cache.return_value = True

            cache_result = await mock_services["cache_service"].set(
                f"processed_match_data_{int(time.time())}", processed_data
            )
            assert cache_result is True

            cache_time = time.time() - start_time
            test_metrics.response_times.append(cache_time)
            test_metrics.success_count += 1

        print(f"âœ… ç¼“å­˜æ›´æ–°å®Œæˆ ({cache_time:.3f}s)")

        # æµ‹è¯•æŒ‡æ ‡éªŒè¯
        test_metrics.end_time = datetime.now()
        assert test_metrics.success_rate == 1.0
        assert test_metrics.avg_response_time < 0.5

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_cache_database_consistency(self, mock_services, test_metrics):
        """æµ‹è¯•ç¼“å­˜ä¸æ•°æ®åº“ä¸€è‡´æ€§"""
        scenario = IntegrationTestScenario.CACHE_DATABASE_SYNC
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: {scenario.value}")

        test_key = f"consistency_test_{int(time.time())}"
        test_data = {
            "id": 123,
            "value": "test_data",
            "timestamp": datetime.now().isoformat(),
        }

        # 1. å†™å…¥æ•°æ®åº“
        with patch.object(mock_services["database_service"], "execute_query") as mock_db:
            mock_db.return_value = {"success": True, "rows_affected": 1}

            db_result = await mock_services["database_service"].execute_query(
                "INSERT INTO test_table VALUES (:id, :value, :timestamp)", test_data
            )
            assert db_result["success"] is True

        # 2. å†™å…¥ç¼“å­˜
        with patch.object(mock_services["cache_service"], "set") as mock_cache:
            mock_cache.return_value = True

            cache_result = await mock_services["cache_service"].set(test_key, test_data)
            assert cache_result is True

        # 3. éªŒè¯ç¼“å­˜æ•°æ®
        with patch.object(mock_services["cache_service"], "get") as mock_get:
            mock_get.return_value = test_data

            cached_data = await mock_services["cache_service"].get(test_key)
            assert cached_data == test_data

        # 4. éªŒè¯æ•°æ®åº“æ•°æ®
        with patch.object(mock_services["database_service"], "execute_query") as mock_select:
            mock_select.return_value = {"success": True, "rows": [test_data]}

            db_data = await mock_services["database_service"].execute_query(
                "SELECT * FROM test_table WHERE id = :id", {"id": 123}
            )
            assert db_data["success"] is True
            assert db_data["rows"][0] == test_data

        # 5. éªŒè¯ä¸€è‡´æ€§
        assert cached_data == db_data["rows"][0], "ç¼“å­˜å’Œæ•°æ®åº“æ•°æ®ä¸ä¸€è‡´"

        test_metrics.success_count += 5  # 5ä¸ªæ“ä½œéƒ½æˆåŠŸ
        print("âœ… ç¼“å­˜ä¸æ•°æ®åº“ä¸€è‡´æ€§éªŒè¯é€šè¿‡")

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_external_api_integration(self, api_client, test_metrics):
        """æµ‹è¯•å¤–éƒ¨APIé›†æˆ"""
        scenario = IntegrationTestScenario.EXTERNAL_API_INTEGRATION
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: {scenario.value}")

        # æ¨¡æ‹Ÿå¤–éƒ¨ä½“è‚²æ•°æ®APIé›†æˆ
        external_api_url = "https://api.football-data.org/v1/matches"

        # 1. å¤–éƒ¨APIè°ƒç”¨
        start_time = time.time()
        mock_response = {
            "status": "success",
            "data": [
                {
                    "id": 1001,
                    "home_team": "Chelsea",
                    "away_team": "Arsenal",
                    "date": "2025-10-26T20:00:00Z",
                    "league": "Premier League",
                }
            ],
        }

        with patch("httpx.AsyncClient.get") as mock_external_get:
            mock_external_get.return_value.status_code = 200
            mock_external_get.return_value.json.return_value = mock_response

            response = await api_client.get(
                f"/api/v1/external/football-data?url={external_api_url}"
            )
            assert response.status_code == 200

            api_time = time.time() - start_time
            test_metrics.response_times.append(api_time)
            test_metrics.success_count += 1

        print(f"âœ… å¤–éƒ¨APIè°ƒç”¨å®Œæˆ ({api_time:.3f}s)")

        # 2. æ•°æ®è½¬æ¢å’Œå­˜å‚¨
        start_time = time.time()
        converted_data = []

        for item in mock_response["data"]:
            converted_item = {
                "external_id": item["id"],
                "home_team": item["home_team"],
                "away_team": item["away_team"],
                "match_date": item["date"],
                "league": item["league"],
                "source": "external_api",
                "imported_at": datetime.now(),
            }
            converted_data.append(converted_item)

        conversion_time = time.time() - start_time
        test_metrics.response_times.append(conversion_time)
        test_metrics.success_count += 1

        print(f"âœ… æ•°æ®è½¬æ¢å®Œæˆ ({conversion_time:.3f}s)")

        # 3. æœ¬åœ°å­˜å‚¨
        start_time = time.time()
        with patch("httpx.AsyncClient.post") as mock_post:
            mock_post.return_value.status_code = 201
            mock_post.return_value.json.return_value = {
                "success": True,
                "imported_count": len(converted_data),
            }

            response = await api_client.post("/api/v1/matches/import", json=converted_data)
            assert response.status_code == 201
            assert response.json()["imported_count"] == len(converted_data)

            import_time = time.time() - start_time
            test_metrics.response_times.append(import_time)
            test_metrics.success_count += 1

        print(f"âœ… æœ¬åœ°å­˜å‚¨å®Œæˆ ({import_time:.3f}s)")

        # éªŒè¯å¯¼å…¥çš„æ•°æ®
        with patch("httpx.AsyncClient.get") as mock_get:
            mock_get.return_value.status_code = 200
            mock_get.return_value.json.return_value = {
                "matches": converted_data,
                "total": len(converted_data),
            }

            response = await api_client.get("/api/v1/matches?source=external_api")
            assert response.status_code == 200
            imported_matches = response.json()["matches"]
            assert len(imported_matches) == len(converted_data)

        test_metrics.success_count += 1
        print("âœ… æ•°æ®å¯¼å…¥éªŒè¯å®Œæˆ")

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_performance_monitoring_integration(self, mock_services, test_metrics):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§é›†æˆ"""
        scenario = IntegrationTestScenario.PERFORMANCE_MONITORING
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: {scenario.value}")

        performance_data = []

        # æ¨¡æ‹Ÿé«˜å¹¶å‘è¯·æ±‚
        async def simulate_request():
            start = time.time()

            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            await asyncio.sleep(0.01)

            end = time.time()
            duration = end - start
            performance_data.append(duration)
            return {"status": "success", "duration": duration}

        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        num_requests = 10
        tasks = [simulate_request() for _ in range(num_requests)]
        results = await asyncio.gather(*tasks)

        # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
        assert len(results) == num_requests
        assert all(r["status"] == "success" for r in results)

        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        avg_response_time = sum(performance_data) / len(performance_data)
        max_response_time = max(performance_data)
        min_response_time = min(performance_data)

        print("ğŸ“Š æ€§èƒ½ç›‘æ§ç»“æœ:")
        print(f"   è¯·æ±‚æ•°é‡: {num_requests}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        print(f"   æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.3f}s")
        print(f"   æœ€å°å“åº”æ—¶é—´: {min_response_time:.3f}s")

        # æ€§èƒ½æ–­è¨€
        assert avg_response_time < 0.05, f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.3f}s"
        assert max_response_time < 0.1, f"æœ€å¤§å“åº”æ—¶é—´è¿‡é•¿: {max_response_time:.3f}s"

        test_metrics.success_count = num_requests
        test_metrics.response_times.extend(performance_data)
        test_metrics.end_time = datetime.now()

        print("âœ… æ€§èƒ½ç›‘æ§é›†æˆæµ‹è¯•é€šè¿‡")

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_error_handling_and_recovery(self, api_client, test_metrics):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤"""
        print("ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: é”™è¯¯å¤„ç†å’Œæ¢å¤")

        # 1. ç½‘ç»œé”™è¯¯å¤„ç†
        with patch("httpx.AsyncClient.get") as mock_get:
            mock_get.side_effect = Exception("Network error")

            try:
                await api_client.get("/api/v1/matches")
                assert False, "åº”è¯¥æŠ›å‡ºç½‘ç»œå¼‚å¸¸"
            except Exception:
                test_metrics.error_count += 1
                print("âœ… ç½‘ç»œé”™è¯¯å¤„ç†æ­£ç¡®")

        # 2. æœåŠ¡é™çº§å¤„ç†
        with patch("httpx.AsyncClient.get") as mock_get:
            # æ¨¡æ‹Ÿä¸»æœåŠ¡ä¸å¯ç”¨
            mock_get.return_value.status_code = 503

            response = await api_client.get("/api/v1/matches")
            assert response.status_code == 503

            # éªŒè¯é™çº§æœåŠ¡å“åº”
            with patch("httpx.AsyncClient.get") as mock_fallback:
                mock_fallback.return_value.status_code = 200
                mock_fallback.return_value.json.return_value = {
                    "matches": [],
                    "message": "æœåŠ¡é™çº§,ä½¿ç”¨ç¼“å­˜æ•°æ®",
                }

                response = await api_client.get("/api/v1/matches/fallback")
                assert response.status_code == 200
                assert "æœåŠ¡é™çº§" in response.json()["message"]

                test_metrics.success_count += 1
                print("âœ… æœåŠ¡é™çº§å¤„ç†æ­£ç¡®")

        # 3. é‡è¯•æœºåˆ¶
        retry_count = 0
        max_retries = 3

        async def simulate_flaky_service():
            nonlocal retry_count
            retry_count += 1
            if retry_count < max_retries:
                raise Exception("ä¸´æ—¶æœåŠ¡ä¸å¯ç”¨")
            return {"status": "success", "retry_count": retry_count}

        try:
            result = await simulate_flaky_service()
            assert result["status"] == "success"
            assert result["retry_count"] == max_retries

            test_metrics.success_count += 1
            print(f"âœ… é‡è¯•æœºåˆ¶æ­£ç¡®,é‡è¯•äº†{retry_count}æ¬¡")

        except Exception as e:
            test_metrics.error_count += 1
            print(f"âŒ é‡è¯•æœºåˆ¶å¤±è´¥: {e}")

        print("âœ… é”™è¯¯å¤„ç†å’Œæ¢å¤æµ‹è¯•å®Œæˆ")

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_service_dependency_graph(self, mock_services, test_metrics):
        """æµ‹è¯•æœåŠ¡ä¾èµ–å…³ç³»å›¾"""
        print("ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: æœåŠ¡ä¾èµ–å…³ç³»å›¾")

        # æ¨¡æ‹ŸæœåŠ¡ä¾èµ–å…³ç³»:
        # ç”¨æˆ·æœåŠ¡ -> ç¼“å­˜æœåŠ¡ -> æ•°æ®åº“æœåŠ¡
        # é¢„æµ‹æœåŠ¡ -> ç”¨æˆ·æœåŠ¡ -> æ•°æ®åº“æœåŠ¡

        service_calls = []

        async def mock_user_call():
            service_calls.append("user_service")
            return {"user_id": "123", "username": "test_user"}

        async def mock_cache_call(key):
            service_calls.append("cache_service")
            return {"key": key, "value": "cached_data"}

        async def mock_db_call(query):
            service_calls.append("database_service")
            return {"success": True, "data": [{"id": 1, "name": "test"}]}

        async def mock_prediction_call(user_id, prediction_data):
            # é¢„æµ‹æœåŠ¡éœ€è¦è°ƒç”¨ç”¨æˆ·æœåŠ¡å’Œæ•°æ®åº“æœåŠ¡
            user_info = await mock_user_call()
            db_data = await mock_db_call(f"SELECT * FROM predictions WHERE user_id = {user_id}")
            return {"prediction_id": "456", "user": user_info, "data": db_data}

        # æ¨¡æ‹Ÿå®Œæ•´çš„è°ƒç”¨é“¾
        result = await mock_prediction_call("123", {"match_id": 1, "prediction": "home_win"})

        # éªŒè¯è°ƒç”¨é¡ºåºå’Œå®Œæ•´æ€§
        expected_calls = ["user_service", "database_service", "user_service"]
        assert len(service_calls) == len(expected_calls)
        assert all(call in service_calls for call in expected_calls)

        # éªŒè¯ç»“æœ
        assert result["prediction_id"] == "456"
        assert result["user"]["user_id"] == "123"
        assert result["data"]["success"] is True

        test_metrics.success_count = len(expected_calls)
        print("âœ… æœåŠ¡ä¾èµ–å…³ç³»å›¾æµ‹è¯•å®Œæˆ")
        print(f"   è°ƒç”¨æœåŠ¡: {', '.join(service_calls)}")

    @pytest.mark.e2e
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_data_consistency_across_services(self, mock_services, test_metrics):
        """æµ‹è¯•è·¨æœåŠ¡æ•°æ®ä¸€è‡´æ€§"""
        print("ğŸ§ª å¼€å§‹æµ‹è¯•åœºæ™¯: è·¨æœåŠ¡æ•°æ®ä¸€è‡´æ€§")

        test_user_id = "user_123"
        test_prediction_data = {
            "user_id": test_user_id,
            "match_id": 1,
            "prediction": "home_win",
            "confidence": 0.75,
        }

        # 1. åœ¨æ•°æ®åº“ä¸­åˆ›å»ºé¢„æµ‹
        with patch.object(mock_services["database_service"], "execute_query") as mock_db:
            mock_db.return_value = {"success": True, "id": "pred_456"}

            db_result = await mock_services["database_service"].execute_query(
                "INSERT INTO predictions VALUES (:user_id, :match_id, :prediction, :confidence)",
                test_prediction_data,
            )
            assert db_result["success"] is True

        # 2. åœ¨ç¼“å­˜ä¸­å­˜å‚¨ç›¸åŒæ•°æ®
        with patch.object(mock_services["cache_service"], "set") as mock_cache:
            mock_cache.return_value = True

            cache_result = await mock_services["cache_service"].set(
                f"prediction_{test_prediction_data['match_id']}_{test_user_id}",
                test_prediction_data,
            )
            assert cache_result is True

        # 3. ä»ç¼“å­˜è¯»å–æ•°æ®
        with patch.object(mock_services["cache_service"], "get") as mock_get:
            mock_get.return_value = test_prediction_data

            cached_data = await mock_services["cache_service"].get(
                f"prediction_{test_prediction_data['match_id']}_{test_user_id}"
            )
            assert cached_data == test_prediction_data

        # 4. ä»æ•°æ®åº“è¯»å–æ•°æ®
        with patch.object(mock_services["database_service"], "execute_query") as mock_select:
            mock_select.return_value = {"success": True, "rows": [test_prediction_data]}

            db_result = await mock_services["database_service"].execute_query(
                "SELECT * FROM predictions WHERE user_id = :user_id AND match_id = :match_id",
                {"user_id": test_user_id, "match_id": test_prediction_data["match_id"]},
            )
            assert db_result["success"] is True
            assert db_result["rows"][0] == test_prediction_data

        # 5. éªŒè¯æ•°æ®ä¸€è‡´æ€§
        assert cached_data == db_result["rows"][0], "ç¼“å­˜å’Œæ•°æ®åº“æ•°æ®ä¸ä¸€è‡´"

        test_metrics.success_count = 5  # 5ä¸ªæ“ä½œéƒ½æˆåŠŸ
        print("âœ… è·¨æœåŠ¡æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
