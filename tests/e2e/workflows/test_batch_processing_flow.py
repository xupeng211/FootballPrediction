"""
æ‰¹é‡æ•°æ®å¤„ç†æµç¨‹ E2E æµ‹è¯•
æµ‹è¯•æ‰¹é‡å¯¼å…¥é¢„æµ‹,æ•°æ®å¯¼å‡ºç­‰æ‰¹é‡å¤„ç†åŠŸèƒ½
"""

import asyncio
import csv
import io
import json
from datetime import datetime, timedelta, timezone

import pytest
from httpx import AsyncClient


@pytest.mark.e2e
@pytest.mark.regression
class TestBatchProcessingFlow:
    """æ‰¹é‡æ•°æ®å¤„ç†æµç¨‹ E2E æµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_batch_prediction_import(
        self,
        api_client: AsyncClient,
        test_data_loader,
        analyst_headers,
        performance_metrics,
    ):
        """æµ‹è¯•æ‰¹é‡å¯¼å…¥é¢„æµ‹"""
        # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
        _teams = await test_data_loader.create_teams()
        _matches = await test_data_loader.create_matches()

        # åˆ›å»ºæ‰¹é‡é¢„æµ‹æ•°æ® (CSVæ ¼å¼)
        batch_predictions = []
        for i, match in enumerate(matches[:10]):  # 10åœºæ¯”èµ›
            for j in range(3):  # æ¯åœºæ¯”èµ›3ä¸ªä¸åŒçš„é¢„æµ‹
                pred = {
                    "match_id": match["id"],
                    "prediction": ["HOME_WIN", "DRAW", "AWAY_WIN"][j],
                    "confidence": round(0.5 + (i * 0.05) + (j * 0.1), 2),
                    "notes": f"Batch prediction {i}-{j}",
                }
                batch_predictions.append(pred)

        # åˆ›å»ºCSVæ–‡ä»¶
        csv_file = io.StringIO()
        fieldnames = ["match_id", "prediction", "confidence", "notes"]
        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(batch_predictions)
        csv_content = csv_file.getvalue()

        print(f"âœ… å‡†å¤‡äº† {len(batch_predictions)} ä¸ªæ‰¹é‡é¢„æµ‹")

        # 2. ä¸Šä¼ æ‰¹é‡é¢„æµ‹æ–‡ä»¶
        performance_metrics.start_timer("batch_upload")

        files = {"file": ("batch_predictions.csv", csv_content, "text/csv")}

        response = await api_client.post(
            "/api/v1/batch/predictions/upload", files=files, headers=analyst_headers
        )

        upload_duration = performance_metrics.end_timer("batch_upload")
        print(f"âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ ({upload_duration:.2f}s)")

        assert response.status_code == 202, f"æ‰¹é‡ä¸Šä¼ å¤±è´¥: {response.text}"
        batch_info = response.json()
        assert "batch_id" in batch_info
        assert "status" in batch_info
        batch_id = batch_info["batch_id"]

        print(f"âœ… æ‰¹é‡ä»»åŠ¡å·²åˆ›å»º: {batch_id}")

        # 3. ç›‘æ§æ‰¹é‡å¤„ç†è¿›åº¦
        performance_metrics.start_timer("batch_processing")

        max_wait = 60  # æœ€å¤šç­‰å¾…60ç§’
        wait_interval = 2
        elapsed = 0

        while elapsed < max_wait:
            await asyncio.sleep(wait_interval)
            elapsed += wait_interval

            response = await api_client.get(
                f"/api/v1/batch/predictions/{batch_id}/status", headers=analyst_headers
            )

            if response.status_code == 200:
                status = response.json()
                print(
                    f"ğŸ“Š å¤„ç†è¿›åº¦: {status.get('processed', 0)}/{status.get('total', 0)} "
                    f"({status.get('status', 'unknown')})"
                )

                if status.get("status") == "COMPLETED":
                    break
                elif status.get("status") == "FAILED":
                    assert False, f"æ‰¹é‡å¤„ç†å¤±è´¥: {status.get('error', 'Unknown error')}"

        processing_duration = performance_metrics.end_timer("batch_processing")
        print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ ({processing_duration:.2f}s)")

        # 4. è·å–æ‰¹é‡å¤„ç†ç»“æœ
        response = await api_client.get(
            f"/api/v1/batch/predictions/{batch_id}/results", headers=analyst_headers
        )

        assert response.status_code == 200
        results = response.json()
        assert "summary" in results
        assert "details" in results

        summary = results["summary"]
        print("âœ… å¤„ç†ç»“æœæ‘˜è¦:")
        print(f"   - æ€»æ•°: {summary.get('total', 0)}")
        print(f"   - æˆåŠŸ: {summary.get('successful', 0)}")
        print(f"   - å¤±è´¥: {summary.get('failed', 0)}")
        print(
            f"   - æˆåŠŸç‡: {(summary.get('successful', 0) / max(summary.get('total', 1), 1) * 100):.1f}%"
        )

        # éªŒè¯æˆåŠŸå¤„ç†çš„é¢„æµ‹
        assert summary.get("successful", 0) > 0
        assert summary.get("failed", 0) < summary.get("total", 0) * 0.1  # å¤±è´¥ç‡åº”ä½äº10%

        # 5. éªŒè¯é¢„æµ‹å·²å¯¼å…¥
        response = await api_client.get(
            "/api/v1/predictions",
            params={"batch_id": batch_id},
            headers=analyst_headers,
        )

        if response.status_code == 200:
            imported_predictions = response.json()
            assert len(imported_predictions.get("data", [])) >= summary.get("successful", 0)
            print(f"âœ… æˆåŠŸå¯¼å…¥äº† {len(imported_predictions.get('data', []))} ä¸ªé¢„æµ‹")

        # æ€§èƒ½æ–­è¨€
        assert upload_duration < 10.0, "ä¸Šä¼ è€—æ—¶è¿‡é•¿"
        assert processing_duration < 120.0, "å¤„ç†è€—æ—¶è¿‡é•¿"

    @pytest.mark.asyncio
    async def test_batch_data_export(
        self, api_client: AsyncClient, test_data_loader, analyst_headers
    ):
        """æµ‹è¯•æ‰¹é‡æ•°æ®å¯¼å‡º"""
        # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
        _teams = await test_data_loader.create_teams()
        _matches = await test_data_loader.create_matches()

        # åˆ›å»ºä¸€äº›é¢„æµ‹æ•°æ®
        user_token = (
            await api_client.post(
                "/api/v1/auth/login",
                _data={"username": "e2e_user", "password": "E2ETestPass123!"},
            )
        ).json()["access_token"]
        user_headers = {"Authorization": f"Bearer {user_token}"}

        for i, match in enumerate(matches[:5]):
            pred_data = {
                "match_id": match["id"],
                "prediction": "HOME_WIN" if i % 2 == 0 else "AWAY_WIN",
                "confidence": 0.7 + (i * 0.05),
            }
            await api_client.post("/api/v1/predictions", json=pred_data, headers=user_headers)

        # 2. åˆ›å»ºå¯¼å‡ºä»»åŠ¡
        export_request = {
            "data_type": "predictions",
            "format": "csv",
            "filters": {
                "date_from": (datetime.now(timezone.utc) - timedelta(days=1)).isoformat(),
                "date_to": (datetime.now(timezone.utc) + timedelta(days=1)).isoformat(),
            },
            "fields": [
                "id",
                "match_id",
                "prediction",
                "confidence",
                "status",
                "created_at",
            ],
        }

        response = await api_client.post(
            "/api/v1/batch/export", json=export_request, headers=analyst_headers
        )

        assert response.status_code == 202, f"åˆ›å»ºå¯¼å‡ºä»»åŠ¡å¤±è´¥: {response.text}"
        export_info = response.json()
        assert "export_id" in export_info
        export_id = export_info["export_id"]
        print(f"âœ… å¯¼å‡ºä»»åŠ¡å·²åˆ›å»º: {export_id}")

        # 3. ç›‘æ§å¯¼å‡ºè¿›åº¦
        max_wait = 30
        wait_interval = 1
        elapsed = 0

        while elapsed < max_wait:
            await asyncio.sleep(wait_interval)
            elapsed += wait_interval

            response = await api_client.get(
                f"/api/v1/batch/export/{export_id}/status", headers=analyst_headers
            )

            if response.status_code == 200:
                status = response.json()
                if status.get("status") == "COMPLETED":
                    break
                elif status.get("status") == "FAILED":
                    assert False, f"å¯¼å‡ºå¤±è´¥: {status.get('error')}"

        # 4. ä¸‹è½½å¯¼å‡ºæ–‡ä»¶
        response = await api_client.get(
            f"/api/v1/batch/export/{export_id}/download", headers=analyst_headers
        )

        assert response.status_code == 200
        assert "text/csv" in response.headers.get("content-type", "")

        # éªŒè¯CSVå†…å®¹
        csv_content = response.text
        lines = csv_content.strip().split("\n")
        assert len(lines) > 1  # è‡³å°‘æœ‰æ ‡é¢˜è¡Œå’Œä¸€è¡Œæ•°æ®

        print(f"âœ… å¯¼å‡ºæ–‡ä»¶ä¸‹è½½æˆåŠŸ ({len(lines)} è¡Œ)")

    @pytest.mark.asyncio
    async def test_bulk_user_import(
        self, api_client: AsyncClient, admin_headers, performance_metrics
    ):
        """æµ‹è¯•æ‰¹é‡ç”¨æˆ·å¯¼å…¥"""
        # 1. åˆ›å»ºæ‰¹é‡ç”¨æˆ·æ•°æ®
        users_data = []
        for i in range(50):
            _user = {
                "username": f"bulk_user_{i:03d}",
                "email": f"bulkuser{i:03d}@example.com",
                "password": "BulkUser123!",
                "first_name": f"User{i}",
                "last_name": f"Test{i}",
                "role": "user" if i % 10 != 0 else "analyst",
            }
            users_data.append(user)

        # åˆ›å»ºJSONæ ¼å¼æ•°æ®
        json_content = json.dumps(
            {
                "users": users_data,
                "options": {
                    "send_welcome_email": False,
                    "require_password_change": False,
                },
            }
        )

        print(f"âœ… å‡†å¤‡å¯¼å…¥ {len(users_data)} ä¸ªç”¨æˆ·")

        # 2. ä¸Šä¼ æ‰¹é‡ç”¨æˆ·æ–‡ä»¶
        performance_metrics.start_timer("bulk_import")

        files = {"file": ("bulk_users.json", json_content, "application/json")}

        response = await api_client.post(
            "/api/v1/batch/users/import", files=files, headers=admin_headers
        )

        import_duration = performance_metrics.end_timer("bulk_import")
        print(f"âœ… ç”¨æˆ·æ‰¹é‡å¯¼å…¥å¼€å§‹ ({import_duration:.2f}s)")

        assert response.status_code == 202
        import_info = response.json()
        import_id = import_info["import_id"]

        # 3. ç›‘æ§å¯¼å…¥è¿›åº¦
        processed = 0
        total = len(users_data)
        wait_time = 0

        while processed < total and wait_time < 60:
            await asyncio.sleep(2)
            wait_time += 2

            response = await api_client.get(
                f"/api/v1/batch/users/{import_id}/status", headers=admin_headers
            )

            if response.status_code == 200:
                status = response.json()
                processed = status.get("processed", 0)
                print(f"ğŸ“Š å¯¼å…¥è¿›åº¦: {processed}/{total} ({processed / total * 100:.1f}%)")

                if status.get("status") == "COMPLETED":
                    break

        # 4. è·å–å¯¼å…¥ç»“æœ
        response = await api_client.get(
            f"/api/v1/batch/users/{import_id}/results", headers=admin_headers
        )

        assert response.status_code == 200
        results = response.json()
        summary = results.get("summary", {})

        print("âœ… ç”¨æˆ·å¯¼å…¥å®Œæˆ:")
        print(f"   - æˆåŠŸ: {summary.get('successful', 0)}")
        print(f"   - å¤±è´¥: {summary.get('failed', 0)}")
        print(f"   - è·³è¿‡: {summary.get('skipped', 0)}")

        # éªŒè¯å¯¼å…¥ç»“æœ
        assert summary.get("successful", 0) >= total * 0.95  # è‡³å°‘95%æˆåŠŸ

    @pytest.mark.asyncio
    async def test_scheduled_batch_job(
        self, api_client: AsyncClient, test_data_loader, analyst_headers
    ):
        """æµ‹è¯•å®šæ—¶æ‰¹é‡ä»»åŠ¡ï¼ˆå¦‚æ¯æ—¥ç»Ÿè®¡æŠ¥å‘Šï¼‰"""
        # 1. åˆ›å»ºå®šæ—¶ä»»åŠ¡
        job_config = {
            "name": "daily_statistics_report",
            "type": "report_generation",
            "schedule": "0 2 * * *",  # æ¯å¤©å‡Œæ™¨2ç‚¹
            "parameters": {
                "report_type": "daily",
                "recipients": ["admin@example.com", "analyst@example.com"],
                "format": "pdf",
                "include_charts": True,
            },
        }

        response = await api_client.post(
            "/api/v1/batch/schedule", json=job_config, headers=analyst_headers
        )

        if response.status_code == 201:
            job = response.json()
            job_id = job["id"]
            print(f"âœ… å®šæ—¶ä»»åŠ¡å·²åˆ›å»º: {job_id}")

            # 2. è·å–ä»»åŠ¡åˆ—è¡¨
            response = await api_client.get("/api/v1/batch/schedule", headers=analyst_headers)

            if response.status_code == 200:
                jobs = response.json()
                assert any(j["id"] == job_id for j in jobs)
                print(f"âœ… æ‰¾åˆ° {len(jobs)} ä¸ªå®šæ—¶ä»»åŠ¡")

            # 3. æ‰‹åŠ¨è§¦å‘ä»»åŠ¡æ‰§è¡Œ
            response = await api_client.post(
                f"/api/v1/batch/schedule/{job_id}/trigger", headers=analyst_headers
            )

            if response.status_code == 202:
                execution = response.json()
                execution_id = execution["execution_id"]
                print(f"âœ… ä»»åŠ¡æ‰§è¡Œå·²è§¦å‘: {execution_id}")

                # 4. ç›‘æ§æ‰§è¡ŒçŠ¶æ€
                for _ in range(30):  # æœ€å¤šç­‰å¾…30ç§’
                    await asyncio.sleep(1)

                    response = await api_client.get(
                        f"/api/v1/batch/execution/{execution_id}",
                        headers=analyst_headers,
                    )

                    if response.status_code == 200:
                        exec_status = response.json()
                        if exec_status.get("status") == "COMPLETED":
                            print("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
                            break
                        elif exec_status.get("status") == "FAILED":
                            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {exec_status.get('error')}")
                            break

    @pytest.mark.asyncio
    async def test_bulk_notification_sending(
        self, api_client: AsyncClient, test_data_loader, admin_headers
    ):
        """æµ‹è¯•æ‰¹é‡å‘é€é€šçŸ¥"""
        # 1. åˆ›å»ºå¤šä¸ªç”¨æˆ·ï¼ˆæ¨¡æ‹Ÿéœ€è¦é€šçŸ¥çš„ç”¨æˆ·ï¼‰
        users = []
        for i in range(10):
            user_data = {
                "username": f"notify_user_{i}",
                "email": f"notifyuser{i}@example.com",
                "password": "NotifyPass123!",
                "notifications_enabled": True,
            }

            response = await api_client.post("/api/v1/auth/register", json=user_data)
            if response.status_code == 201:
                users.append(user_data)

        assert len(users) >= 5, "è‡³å°‘éœ€è¦5ä¸ªç”¨æˆ·è¿›è¡Œé€šçŸ¥æµ‹è¯•"

        # 2. åˆ›å»ºæ‰¹é‡é€šçŸ¥
        notification_data = {
            "title": "ç³»ç»Ÿç»´æŠ¤é€šçŸ¥",
            "message": "ç³»ç»Ÿå°†äºä»Šæ™šè¿›è¡Œä¾‹è¡Œç»´æŠ¤,é¢„è®¡è€—æ—¶2å°æ—¶",
            "type": "system",
            "priority": "normal",
            "channels": ["email", "in_app"],
            "send_immediately": True,
        }

        # æ·»åŠ ç›®æ ‡ç”¨æˆ·
        notification_data["recipients"] = [u["username"] for u in users[:5]]

        response = await api_client.post(
            "/api/v1/batch/notifications/send",
            json=notification_data,
            headers=admin_headers,
        )

        if response.status_code == 202:
            batch_info = response.json()
            batch_id = batch_info["batch_id"]
            print(f"âœ… æ‰¹é‡é€šçŸ¥ä»»åŠ¡å·²åˆ›å»º: {batch_id}")

            # 3. ç›‘æ§å‘é€çŠ¶æ€
            max_wait = 30
            elapsed = 0

            while elapsed < max_wait:
                await asyncio.sleep(2)
                elapsed += 2

                response = await api_client.get(
                    f"/api/v1/batch/notifications/{batch_id}/status",
                    headers=admin_headers,
                )

                if response.status_code == 200:
                    status = response.json()
                    if status.get("status") == "COMPLETED":
                        break

            # 4. è·å–å‘é€ç»“æœ
            response = await api_client.get(
                f"/api/v1/batch/notifications/{batch_id}/results", headers=admin_headers
            )

            if response.status_code == 200:
                results = response.json()
                summary = results.get("summary", {})
                print("âœ… é€šçŸ¥å‘é€ç»“æœ:")
                print(f"   - æ€»æ•°: {summary.get('total', 0)}")
                print(f"   - æˆåŠŸ: {summary.get('sent', 0)}")
                print(f"   - å¤±è´¥: {summary.get('failed', 0)}")

                assert summary.get("sent", 0) > 0
