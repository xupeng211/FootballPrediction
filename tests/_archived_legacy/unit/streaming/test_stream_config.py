import os

from dataclasses import is_dataclass
from src.streaming.stream_config import KafkaConfig, TopicConfig, StreamConfig
from unittest.mock import patch
import pytest

"""
æµå¼å¤„ç†é…ç½®ç®¡ç†æµ‹è¯•å¥—ä»¶

è¦†ç›–src/streaming/stream_config.pyçš„æ‰€æœ‰åŠŸèƒ½ï¼š
- KafkaConfig æ•°æ®ç±»
- TopicConfig æ•°æ®ç±»
- StreamConfig é…ç½®ç®¡ç†å™¨

ç›®æ ‡ï¼šå®ç°100%è¦†ç›–ç‡
"""

class TestKafkaConfig:
    """KafkaConfigæµ‹è¯•ç±»"""
    def test_kafka_config_creation_default(self):
        """æµ‹è¯•ä½¿ç”¨é»˜è®¤å€¼åˆ›å»ºKafkaConfig"""
        config = KafkaConfig()
        # éªŒè¯è¿æ¥é…ç½®
        assert config.bootstrap_servers =="localhost9092[" assert config.security_protocol =="]PLAINTEXT["""""
        # éªŒè¯ç”Ÿäº§è€…é…ç½®
        assert config.producer_client_id =="]football-prediction-producer[" assert config.producer_acks =="]all[" assert config.producer_retries ==3[""""
        assert config.producer_retry_backoff_ms ==1000
        assert config.producer_linger_ms ==5
        assert config.producer_batch_size ==16384
        # éªŒè¯æ¶ˆè´¹è€…é…ç½®
        assert config.consumer_group_id =="]]football-prediction-consumers[" assert config.consumer_client_id =="]football-prediction-consumer[" assert config.consumer_auto_offset_reset =="]latest[" assert config.consumer_enable_auto_commit is True[""""
        assert config.consumer_auto_commit_interval_ms ==5000
        assert config.consumer_max_poll_records ==500
        # éªŒè¯åºåˆ—åŒ–é…ç½®
        assert config.key_serializer =="]]string[" assert config.value_serializer =="]json[" def test_kafka_config_creation_custom("
    """"
        "]""æµ‹è¯•ä½¿ç”¨è‡ªå®šä¹‰å€¼åˆ›å»ºKafkaConfig"""
        config = KafkaConfig(
            bootstrap_servers = "kafka-server9092[",": security_protocol="]SASL_SSL[",": producer_client_id="]custom-producer[",": producer_acks="]1[",": producer_retries=5,": consumer_group_id="]custom-group[",": consumer_client_id="]custom-consumer[",": consumer_auto_offset_reset="]earliest[",": consumer_enable_auto_commit=False,": key_serializer="]avro[",": value_serializer="]avro[")": assert config.bootstrap_servers =="]kafka-server9092[" assert config.security_protocol =="]SASL_SSL[" assert config.producer_client_id =="]custom-producer[" assert config.producer_acks =="]1[" assert config.producer_retries ==5[""""
        assert config.consumer_group_id =="]]custom-group[" assert config.consumer_client_id =="]custom-consumer[" assert config.consumer_auto_offset_reset =="]earliest[" assert config.consumer_enable_auto_commit is False[""""
        assert config.key_serializer =="]]avro[" assert config.value_serializer =="]avro[" def test_kafka_config_dataclass_properties("
    """"
        "]""æµ‹è¯•KafkaConfigçš„dataclasså±æ€§"""
        # éªŒè¯æ˜¯dataclass
        assert is_dataclass(KafkaConfig)
        # éªŒè¯å­—æ®µ
        config = KafkaConfig()
        assert hasattr(config, "bootstrap_servers[")" assert hasattr(config, "]security_protocol[")" assert hasattr(config, "]producer_client_id[")" assert hasattr(config, "]consumer_group_id[")" assert hasattr(config, "]key_serializer[")" assert hasattr(config, "]value_serializer[")" def test_kafka_config_boundary_values(self):"""
        "]""æµ‹è¯•KafkaConfigè¾¹ç•Œå€¼"""
        # æµ‹è¯•è¾¹ç•Œæ•°å€¼
        config = KafkaConfig(
            producer_retries=0,  # æœ€å°é‡è¯•æ¬¡æ•°
            producer_retry_backoff_ms=0,  # æœ€å°é€€é¿æ—¶é—´
            producer_linger_ms=0,  # æœ€å°å»¶è¿Ÿ
            producer_batch_size=1,  # æœ€å°æ‰¹é‡å¤§å°
            consumer_max_poll_records=1,  # æœ€å°è½®è¯¢è®°å½•æ•°
            consumer_auto_commit_interval_ms=1,  # æœ€å°æäº¤é—´éš”
        )
        assert config.producer_retries ==0
        assert config.producer_retry_backoff_ms ==0
        assert config.producer_linger_ms ==0
        assert config.producer_batch_size ==1
        assert config.consumer_max_poll_records ==1
        assert config.consumer_auto_commit_interval_ms ==1
    def test_kafka_config_large_values(self):
        """æµ‹è¯•KafkaConfigå¤§æ•°å€¼"""
        config = KafkaConfig(
            producer_retries=999999,
            producer_retry_backoff_ms=999999999,
            producer_linger_ms=999999999,
            producer_batch_size=999999999,
            consumer_max_poll_records=999999999,
            consumer_auto_commit_interval_ms=999999999)
        assert config.producer_retries ==999999
        assert config.producer_retry_backoff_ms ==999999999
        assert config.producer_linger_ms ==999999999
        assert config.producer_batch_size ==999999999
class TestTopicConfig:
    """TopicConfigæµ‹è¯•ç±»"""
    def test_topic_config_creation_default(self):
        """æµ‹è¯•ä½¿ç”¨é»˜è®¤å€¼åˆ›å»ºTopicConfig"""
        config = TopicConfig(name="test-topic[")": assert config.name =="]test-topic[" assert config.partitions ==3[""""
        assert config.replication_factor ==1
        assert config.cleanup_policy =="]]delete[" assert config.retention_ms ==604800000  # 7å¤©[""""
        assert config.segment_ms ==86400000  # 1å¤©
    def test_topic_config_creation_custom(self):
        "]]""æµ‹è¯•ä½¿ç”¨è‡ªå®šä¹‰å€¼åˆ›å»ºTopicConfig"""
        config = TopicConfig(
            name="custom-topic[",": partitions=10,": replication_factor=3,": cleanup_policy="]compact[",": retention_ms=3600000,  # 1å°æ—¶[": segment_ms=1800000,  # 30åˆ†é’Ÿ[""
        )
        assert config.name =="]]]custom-topic[" assert config.partitions ==10[""""
        assert config.replication_factor ==3
        assert config.cleanup_policy =="]]compact[" assert config.retention_ms ==3600000[""""
        assert config.segment_ms ==1800000
    def test_topic_config_dataclass_properties(self):
        "]]""æµ‹è¯•TopicConfigçš„dataclasså±æ€§"""
        # éªŒè¯æ˜¯dataclass
        assert is_dataclass(TopicConfig)
        # éªŒè¯å­—æ®µ
        config = TopicConfig(name="test[")": assert hasattr(config, "]name[")" assert hasattr(config, "]partitions[")" assert hasattr(config, "]replication_factor[")" assert hasattr(config, "]cleanup_policy[")" assert hasattr(config, "]retention_ms[")" assert hasattr(config, "]segment_ms[")" def test_topic_config_boundary_values(self):"""
        "]""æµ‹è¯•TopicConfigè¾¹ç•Œå€¼"""
        # æµ‹è¯•æœ€å°æœ‰æ•ˆå€¼
        config = TopicConfig(
            name="test[",": partitions=1,  # æœ€å°åˆ†åŒºæ•°[": replication_factor=1,  # æœ€å°å‰¯æœ¬å› å­[": retention_ms=1,  # æœ€å°ä¿ç•™æ—¶é—´"
            segment_ms=1,  # æœ€å°æ®µå¤§å°
        )
        assert config.partitions ==1
        assert config.replication_factor ==1
        assert config.retention_ms ==1
        assert config.segment_ms ==1
    def test_topic_config_retention_time_values(self):
        "]]]""æµ‹è¯•ä¸åŒä¿ç•™æ—¶é—´é…ç½®"""
        test_cases = [
            ("1 hour[", 3600000),""""
            ("]6 hours[", 21600000),""""
            ("]12 hours[", 43200000),""""
            ("]1 day[", 86400000),""""
            ("]7 days[", 604800000),""""
            ("]30 days[", 2592000000)]": for name, retention_ms in test_cases = config TopicConfig(name=f["]test-{name)"], retention_ms=retention_ms)": assert config.retention_ms ==retention_ms[" def test_topic_config_cleanup_policies(self):""
        "]""æµ‹è¯•ä¸åŒçš„æ¸…ç†ç­–ç•¥"""
        policies = ["delete[", "]compact[", "]compact,delete["]": for policy in policies = config TopicConfig(name=f["]test-{policy)"], cleanup_policy=policy)": assert config.cleanup_policy ==policy[" class TestStreamConfig:""
    "]""StreamConfigæµ‹è¯•ç±»"""
    @pytest.fixture
    def mock_env_vars(self):
        """æ¨¡æ‹Ÿç¯å¢ƒå˜é‡"""
        env_vars = {
            "KAFKA_BOOTSTRAP_SERVERS[: "kafka-prod:9092[","]"""
            "]KAFKA_SECURITY_PROTOCOL[": ["]SASL_SSL[",""""
            "]KAFKA_PRODUCER_CLIENT_ID[: "prod-producer[","]"""
            "]KAFKA_PRODUCER_ACKS[: "1[","]"""
            "]KAFKA_PRODUCER_RETRIES[: "5[","]"""
            "]KAFKA_CONSUMER_GROUP_ID[: "prod-consumers[","]"""
            "]KAFKA_CONSUMER_CLIENT_ID[: "prod-consumer[","]"""
            "]KAFKA_CONSUMER_AUTO_OFFSET_RESET[": ["]earliest["}": return env_vars[": def test_stream_config_init_default(self):""
        "]]""æµ‹è¯•StreamConfigé»˜è®¤åˆå§‹åŒ–"""
        with patch.dict(os.environ, {), clear = True)
            config = StreamConfig()
            # éªŒè¯Kafkaé…ç½®åŠ è½½
            assert config.kafka_config.bootstrap_servers =="localhost9092[" assert config.kafka_config.security_protocol =="]PLAINTEXT[" assert (""""
                config.kafka_config.producer_client_id =="]football-prediction-producer["""""
            )
            assert (
                config.kafka_config.consumer_group_id =="]football-prediction-consumers["""""
            )
            # éªŒè¯Topicsåˆå§‹åŒ–
            assert len(config.topics) ==4
            assert "]matches-stream[" in config.topics[""""
            assert "]]odds-stream[" in config.topics[""""
            assert "]]scores-stream[" in config.topics[""""
            assert "]]processed-data-stream[" in config.topics[""""
    def test_stream_config_init_with_env_vars(self, mock_env_vars):
        "]]""æµ‹è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡åˆå§‹åŒ–StreamConfig"""
        with patch.dict(os.environ, mock_env_vars):
            config = StreamConfig()
            # éªŒè¯ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ
            assert config.kafka_config.bootstrap_servers =="kafka-prod9092[" assert config.kafka_config.security_protocol =="]SASL_SSL[" assert config.kafka_config.producer_client_id =="]prod-producer[" assert config.kafka_config.producer_acks =="]1[" assert config.kafka_config.producer_retries ==5[""""
            assert config.kafka_config.consumer_group_id =="]]prod-consumers[" assert config.kafka_config.consumer_client_id =="]prod-consumer[" assert config.kafka_config.consumer_auto_offset_reset =="]earliest[" def test_load_kafka_config_with_env_vars("
    """"
        "]""æµ‹è¯•_load_kafka_configæ–¹æ³•"""
        with patch.dict(os.environ, mock_env_vars):
            config = StreamConfig()
            kafka_config = config._load_kafka_config()
            assert isinstance(kafka_config, KafkaConfig)
            assert kafka_config.bootstrap_servers =="kafka-prod9092[" assert kafka_config.security_protocol =="]SASL_SSL[" assert kafka_config.producer_retries ==5[""""
    def test_init_topics_default(self):
        "]]""æµ‹è¯•_init_topicsæ–¹æ³•é»˜è®¤é…ç½®"""
        with patch.dict(os.environ, {), clear = True)
            config = StreamConfig()
            topics = config._init_topics()
            assert len(topics) ==4
            # éªŒè¯matches-streamé…ç½®
            matches_topic = topics["matches-stream["]"]": assert matches_topic.name =="matches-stream[" assert matches_topic.partitions ==3[""""
            assert matches_topic.retention_ms ==86400000  # 1å¤©
            # éªŒè¯odds-streamé…ç½®
            odds_topic = topics["]]odds-stream["]: assert odds_topic.name =="]odds-stream[" assert odds_topic.partitions ==6  # èµ”ç‡æ•°æ®é‡å¤§ï¼Œæ›´å¤šåˆ†åŒº[""""
            assert odds_topic.retention_ms ==43200000  # 12å°æ—¶
            # éªŒè¯scores-streamé…ç½®
            scores_topic = topics["]]scores-stream["]: assert scores_topic.name =="]scores-stream[" assert scores_topic.partitions ==3[""""
            assert scores_topic.retention_ms ==21600000  # 6å°æ—¶
            # éªŒè¯processed-data-streamé…ç½®
            processed_topic = topics["]]processed-data-stream["]: assert processed_topic.name =="]processed-data-stream[" assert processed_topic.partitions ==3[""""
            assert processed_topic.retention_ms ==604800000  # 7å¤©
    def test_get_producer_config(self):
        "]]""æµ‹è¯•get_producer_configæ–¹æ³•"""
        config = StreamConfig()
        producer_config = config.get_producer_config()
        expected_keys = [
            "bootstrap.servers[",""""
            "]security.protocol[",""""
            "]client.id[",""""
            "]acks[",""""
            "]retries[",""""
            "]retry.backoff.ms[",""""
            "]linger.ms[",""""
            "]batch.size[",""""
            "]compression.type[",""""
            "]max.in.flight.requests.per.connection["]": for key in expected_keys:": assert key in producer_config[""
        # éªŒè¯é…ç½®å€¼è½¬æ¢
        assert (
            producer_config["]]bootstrap.servers["]""""
            ==config.kafka_config.bootstrap_servers
        )
        assert (
            producer_config["]security.protocol["]""""
            ==config.kafka_config.security_protocol
        )
        assert producer_config["]client.id["] ==config.kafka_config.producer_client_id[" assert producer_config["]]acks["] ==config.kafka_config.producer_acks[" assert producer_config["]]compression.type["] =="]gzip[" assert producer_config["]max.in.flight.requests.per.connection["] ==1[" def test_get_consumer_config_default(self):"""
        "]]""æµ‹è¯•get_consumer_configæ–¹æ³•é»˜è®¤å€¼"""
        config = StreamConfig()
        consumer_config = config.get_consumer_config()
        expected_keys = [
            "bootstrap.servers[",""""
            "]security.protocol[",""""
            "]client.id[",""""
            "]group.id[",""""
            "]auto.offset.reset[",""""
            "]enable.auto.commit[",""""
            "]auto.commit.interval.ms[",""""
            "]max.poll.interval.ms[",""""
            "]session.timeout.ms[",""""
            "]heartbeat.interval.ms["]": for key in expected_keys:": assert key in consumer_config[""
        # éªŒè¯é…ç½®å€¼
        assert consumer_config["]]group.id["] ==config.kafka_config.consumer_group_id[" assert ("""
            consumer_config["]]auto.offset.reset["]""""
            ==config.kafka_config.consumer_auto_offset_reset
        )
        assert (
            consumer_config["]enable.auto.commit["]""""
            ==config.kafka_config.consumer_enable_auto_commit
        )
        assert consumer_config["]max.poll.interval.ms["] ==300000[" def test_get_consumer_config_custom_group(self):"""
        "]]""æµ‹è¯•get_consumer_configæ–¹æ³•è‡ªå®šä¹‰group"""
        config = StreamConfig()
        custom_group = "custom-test-group[": consumer_config = config.get_consumer_config(consumer_group_id=custom_group)": assert consumer_config["]group.id["] ==custom_group[" def test_get_topic_config_existing(self):"""
        "]]""æµ‹è¯•get_topic_configæ–¹æ³• - å­˜åœ¨çš„topic"""
        config = StreamConfig()
        topic_config = config.get_topic_config("matches-stream[")": assert topic_config is not None[" assert topic_config.name =="]]matches-stream[" assert topic_config.partitions ==3[""""
    def test_get_topic_config_non_existing(self):
        "]]""æµ‹è¯•get_topic_configæ–¹æ³• - ä¸å­˜åœ¨çš„topic"""
        config = StreamConfig()
        topic_config = config.get_topic_config("non-existing-topic[")": assert topic_config is None[" def test_get_all_topics(self):""
        "]]""æµ‹è¯•get_all_topicsæ–¹æ³•"""
        config = StreamConfig()
        all_topics = config.get_all_topics()
        assert isinstance(all_topics, list)
        assert len(all_topics) ==4
        assert "matches-stream[" in all_topics[""""
        assert "]]odds-stream[" in all_topics[""""
        assert "]]scores-stream[" in all_topics[""""
        assert "]]processed-data-stream[" in all_topics[""""
    def test_is_valid_topic_true(self):
        "]]""æµ‹è¯•is_valid_topicæ–¹æ³• - æœ‰æ•ˆtopic"""
        config = StreamConfig()
        assert config.is_valid_topic("matches-stream[") is True[" assert config.is_valid_topic("]]odds-stream[") is True[" assert config.is_valid_topic("]]scores-stream[") is True[" assert config.is_valid_topic("]]processed-data-stream[") is True[" def test_is_valid_topic_false(self):"""
        "]]""æµ‹è¯•is_valid_topicæ–¹æ³• - æ— æ•ˆtopic"""
        config = StreamConfig()
        assert config.is_valid_topic("invalid-topic[") is False[" assert config.is_valid_topic( ) is False["""
        assert config.is_valid_topic(None) is False
        assert config.is_valid_topic("]]]matches-stream-extra[") is False[" def test_topics_direct_modification(self):"""
        "]]""éªŒè¯topicså­—å…¸å¯ä»¥ç›´æ¥ä¿®æ”¹ï¼ˆå®é™…è¡Œä¸ºæµ‹è¯•ï¼‰"""
        config = StreamConfig()
        config.get_all_topics()
        # ç›´æ¥ä¿®æ”¹topicså­—å…¸ï¼ˆè¿™æ˜¯å…è®¸çš„ï¼‰
        config.topics["new-topic["] = TopicConfig(name="]new-topic[")""""
        # éªŒè¯é…ç½®ç¡®å®è¢«ä¿®æ”¹äº†
        assert len(config.get_all_topics()) ==5
        assert "]new-topic[" in config.get_all_topics()""""
        assert config.get_topic_config("]new-topic[") is not None[" class TestStreamConfigIntegration:"""
    "]]""StreamConfigé›†æˆæµ‹è¯•"""
    def test_config_consistency(self):
        """æµ‹è¯•é…ç½®ä¸€è‡´æ€§"""
        config = StreamConfig()
        # éªŒè¯ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…é…ç½®ä½¿ç”¨ç›¸åŒçš„æœåŠ¡å™¨
        producer_config = config.get_producer_config()
        consumer_config = config.get_consumer_config()
        assert (
            producer_config["bootstrap.servers["] ==consumer_config["]bootstrap.servers["]"]"""
        )
        assert (
            producer_config["security.protocol["] ==consumer_config["]security.protocol["]"]"""
        )
    def test_environment_variable_priority(self):
        """æµ‹è¯•ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§"""
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env_vars = {"KAFKA_BOOTSTRAP_SERVERS[: "env-kafka9092["}"]": with patch.dict(os.environ, env_vars):": config = StreamConfig()"
            # éªŒè¯ç¯å¢ƒå˜é‡è¦†ç›–é»˜è®¤å€¼
            assert config.kafka_config.bootstrap_servers =="]env-kafka9092[" def test_topic_config_completeness("
    """"
        "]""æµ‹è¯•Topicé…ç½®å®Œæ•´æ€§"""
        config = StreamConfig()
        for topic_name in config.get_all_topics():
            topic_config = config.get_topic_config(topic_name)
            # éªŒè¯å¿…è¦å­—æ®µ
            assert topic_config.name is not None
            assert topic_config.partitions > 0
            assert topic_config.replication_factor > 0
            assert topic_config.cleanup_policy in [
                "delete[",""""
                "]compact[",""""
                "]compact,delete["]": assert topic_config.retention_ms > 0[" assert topic_config.segment_ms > 0[""
    def test_config_serialization_compatibility(self):
        "]]]""æµ‹è¯•é…ç½®åºåˆ—åŒ–å…¼å®¹æ€§"""
        config = StreamConfig()
        # æµ‹è¯•KafkaConfigåºåˆ—åŒ–
        kafka_dict = {
            "bootstrap_servers[": config.kafka_config.bootstrap_servers,""""
            "]security_protocol[": config.kafka_config.security_protocol,""""
            "]producer_client_id[": config.kafka_config.producer_client_id}": assert isinstance(kafka_dict, dict)"""
        # æµ‹è¯•TopicConfigåºåˆ—åŒ–
        for topic_name in config.get_all_topics():
            topic_config = config.get_topic_config(topic_name)
            topic_dict = {
                "]name[": topic_config.name,""""
                "]partitions[": topic_config.partitions,""""
                "]replication_factor[": topic_config.replication_factor}": assert isinstance(topic_dict, dict)" class TestStreamConfigEdgeCases:""
    "]""StreamConfigè¾¹ç•Œæƒ…å†µæµ‹è¯•"""
    def test_empty_environment_variables(self):
        """æµ‹è¯•ç©ºç¯å¢ƒå˜é‡"""
        with patch.dict(os.environ, {), clear = True)
            config = StreamConfig()
            # åº”è¯¥ä½¿ç”¨é»˜è®¤å€¼
            assert config.kafka_config.bootstrap_servers =="localhost9092[" assert (""""
                config.kafka_config.consumer_group_id =="]football-prediction-consumers["""""
            )
    def test_invalid_environment_variable_types(self):
        "]""æµ‹è¯•æ— æ•ˆç¯å¢ƒå˜é‡ç±»å‹"""
        # è®¾ç½®æ— æ•ˆçš„æ•°å€¼ç±»å‹ç¯å¢ƒå˜é‡
        env_vars = {
            "KAFKA_PRODUCER_RETRIES[": ["]invalid_number[",  # åº”è¯¥æ˜¯æ•°å­—[""""
        }
        with patch.dict(os.environ, env_vars):
            # åº”è¯¥æŠ›å‡ºValueError
            with pytest.raises(ValueError):
                StreamConfig()
    def test_special_characters_in_config(self):
        "]]""æµ‹è¯•é…ç½®ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        StreamConfig()
        # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦åœ¨å­—ç¬¦ä¸²å­—æ®µä¸­
        special_chars_config = KafkaConfig(
            bootstrap_servers = "kafka:9092,another-kafka9093[",": security_protocol="]SASL_SSL[",": producer_client_id="]producer@test#123[")": assert "]," in special_chars_config.bootstrap_servers[""""
        assert "]#" in special_chars_config.producer_client_id[""""
    def test_unicode_config_values(self):
        "]""æµ‹è¯•Unicodeé…ç½®å€¼"""
        StreamConfig()
        # æµ‹è¯•Unicodeæ”¯æŒ
        unicode_config = TopicConfig(
            name="æµ‹è¯•ä¸»é¢˜-ä¸­æ–‡-ğŸš€",": partitions=5)": assert "æµ‹è¯•ä¸»é¢˜[" in unicode_config.name[""""
        assert "]]ğŸš€" in unicode_config.name[""""
    def test_large_configuration_values(self):
        "]""æµ‹è¯•å¤§é…ç½®å€¼"""
        StreamConfig()
        # æµ‹è¯•å¤§æ•°å€¼é…ç½®
        large_config = TopicConfig(
            name="large-topic[",": partitions=1000,  # å¤§åˆ†åŒºæ•°[": retention_ms=999999999999,  # å¤§ä¿ç•™æ—¶é—´[""
        )
        assert large_config.partitions ==1000
        assert large_config.retention_ms ==999999999999
if __name__ =="]]]__main__[": pytest.main(""""
        ["]__file__[",""""
            "]-v[",""""
            "]--cov=src.streaming.stream_config[",""""
            "]--cov-report=term-missing["]"]"""
    )