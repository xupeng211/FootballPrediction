#!/usr/bin/env python3
"""
Issue #159 å¢å¼ºç‰ˆè¦†ç›–ç‡ç³»ç»Ÿ v2.0
Phase 1 çŸ­æœŸä¼˜åŒ–ï¼šæ€§èƒ½å’Œç¨³å®šæ€§æå‡
åŸºäºPhase 1æˆæœçš„ç³»ç»Ÿä¼˜åŒ–å’Œå¢å¼º
"""

import os
import sys
import ast
import time
import concurrent.futures
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass
from functools import lru_cache
import threading

@dataclass
class CoverageMetrics:
    """è¦†ç›–ç‡æŒ‡æ ‡æ•°æ®ç±»"""
    total_files: int
    successful_files: int
    total_test_classes: int
    total_test_methods: int
    covered_modules: int
    total_project_modules: int
    coverage_percentage: float
    execution_time: float

@dataclass
class TestFileAnalysis:
    """æµ‹è¯•æ–‡ä»¶åˆ†æç»“æœ"""
    file_path: Path
    test_classes: List[Dict]
    total_tests: int
    imports: Set[str]
    internal_imports: Set[str]
    class_count: int
    parse_success: bool
    error_message: Optional[str] = None

class EnhancedCoverageSystemV2:
    """å¢å¼ºç‰ˆè¦†ç›–ç‡åˆ†æç³»ç»Ÿ v2.0 - æ€§èƒ½å’Œç¨³å®šæ€§ä¼˜åŒ–ç‰ˆ"""

    def __init__(self, max_workers: int = 4, cache_size: int = 128):
        self.test_root = Path(__file__).parent
        self.project_root = self.test_root.parent
        self.src_root = self.project_root / "src"
        self.max_workers = max_workers
        self.cache_size = cache_size

        # æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜æœºåˆ¶
        self._module_cache = {}
        self._ast_cache = {}

        # çº¿ç¨‹å®‰å…¨
        self._cache_lock = threading.Lock()

        # å‘ç°çš„æµ‹è¯•æ–‡ä»¶
        self.test_files: List[Path] = []

        # ç»Ÿè®¡æ•°æ®
        self.total_test_classes = 0
        self.total_test_methods = 0
        self.successful_files = 0

        print(f"ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆè¦†ç›–ç‡ç³»ç»Ÿ v2.0")
        print(f"ğŸ“Š æ€§èƒ½ä¼˜åŒ–: å¤šçº¿ç¨‹å¤„ç†({max_workers}çº¿ç¨‹), LRUç¼“å­˜({cache_size}é¡¹)")

    def discover_test_files(self) -> List[Path]:
        """ä¼˜åŒ–çš„æµ‹è¯•æ–‡ä»¶å‘ç°æœºåˆ¶"""
        start_time = time.time()

        patterns = [
            "test_issue159_phase*.py",
            "test_breakthrough_*.py",
            "test_phase3_*.py",
            "test_final_breakthrough_*.py",
            "test_super_breakthrough_*.py",
            "test_ultra_breakthrough_*.py",
            "test_ultimate_breakthrough_*.py",
            "test_legendary_breakthrough_*.py",
            "test_mythical_breakthrough_*.py",
            "test_epic_breakthrough_*.py",
            "test_final_milestone_*.py"
        ]

        discovered = []
        for pattern in patterns:
            try:
                files = list(self.test_root.glob(pattern))
                discovered.extend([f for f in files if f.is_file() and f.name != "__init__.py"])
            except Exception as e:
                print(f"âš ï¸ æ¨¡å¼ {pattern} æ‰«æå¤±è´¥: {e}")

        self.test_files = sorted(set(discovered))  # å»é‡

        discovery_time = time.time() - start_time
        print(f"ğŸ“ æ–‡ä»¶å‘ç°å®Œæˆ: {len(self.test_files)}ä¸ªæ–‡ä»¶ ({discovery_time:.2f}ç§’)")

        return self.test_files

    @lru_cache(maxsize=128)
    def _parse_python_file_cached(self, file_path: str, file_mtime: float) -> Optional[ast.AST]:
        """ç¼“å­˜çš„Pythonæ–‡ä»¶è§£æ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return ast.parse(content)
        except SyntaxError as e:
            return None
        except Exception as e:
            return None

    def parse_python_file_optimized(self, file_path: Path) -> Optional[ast.AST]:
        """ä¼˜åŒ–çš„Pythonæ–‡ä»¶è§£æ"""
        try:
            file_mtime = file_path.stat().st_mtime
            cache_key = str(file_path)

            # æ£€æŸ¥ç¼“å­˜
            with self._cache_lock:
                if cache_key in self._ast_cache:
                    cached_mtime, cached_tree = self._ast_cache[cache_key]
                    if cached_mtime == file_mtime:
                        return cached_tree

            # è§£ææ–‡ä»¶
            tree = self._parse_python_file_cached(cache_key, file_mtime)

            # æ›´æ–°ç¼“å­˜
            if tree is not None:
                with self._cache_lock:
                    self._ast_cache[cache_key] = (file_mtime, tree)

            return tree

        except Exception as e:
            print(f"  âš ï¸ è§£ææ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")
            return None

    def extract_test_classes_optimized(self, tree: ast.AST) -> List[Dict]:
        """ä¼˜åŒ–çš„æµ‹è¯•ç±»æå–"""
        test_classes = []

        if not tree:
            return test_classes

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef) and node.name.startswith('Test'):
                test_methods = []
                for item in node.body:
                    if isinstance(item, ast.FunctionDef) and item.name.startswith('test_'):
                        test_methods.append(item.name)

                test_classes.append({
                    'name': node.name,
                    'methods': test_methods,
                    'method_count': len(test_methods)
                })

        return test_classes

    def extract_imports_optimized(self, tree: ast.AST) -> Set[str]:
        """ä¼˜åŒ–çš„å¯¼å…¥æå–"""
        imports = set()

        if not tree:
            return imports

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.add(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.add(node.module)

        return imports

    def filter_internal_imports(self, imports: Set[str]) -> Set[str]:
        """è¿‡æ»¤å†…éƒ¨é¡¹ç›®å¯¼å…¥"""
        internal_prefixes = [
            'core.', 'database.', 'services.', 'api.',
            'domain.', 'config.', 'adapters.', 'cache.',
            'monitoring.', 'middleware.', 'decorators.',
            'performance.', 'security.', 'utils.',
            'cqrs.', 'realtime.', 'timeseries.',
            'ml.', 'data.', 'tasks.', 'patterns.'
        ]

        internal_imports = {
            imp for imp in imports
            if any(imp.startswith(prefix) for prefix in internal_prefixes)
        }

        return internal_imports

    @lru_cache(maxsize=256)
    def discover_project_modules_cached(self) -> Dict[str, Path]:
        """ç¼“å­˜çš„é¡¹ç›®æ¨¡å—å‘ç°"""
        modules = {}

        if not self.src_root.exists():
            return modules

        try:
            for py_file in self.src_root.rglob("*.py"):
                if py_file.name == "__init__.py":
                    continue

                try:
                    relative_path = py_file.relative_to(self.src_root)
                    module_path = str(relative_path.with_suffix('')).replace(os.sep, '.')
                    modules[module_path] = py_file
                except Exception:
                    continue

        except Exception as e:
            print(f"âš ï¸ æ¨¡å—å‘ç°è­¦å‘Š: {e}")

        return modules

    def analyze_single_file(self, test_file: Path) -> TestFileAnalysis:
        """åˆ†æå•ä¸ªæµ‹è¯•æ–‡ä»¶"""
        file_start_time = time.time()

        # è§£ææ–‡ä»¶
        tree = self.parse_python_file_optimized(test_file)
        if tree is None:
            return TestFileAnalysis(
                file_path=test_file,
                test_classes=[],
                total_tests=0,
                imports=set(),
                internal_imports=set(),
                class_count=0,
                parse_success=False,
                error_message="è¯­æ³•é”™è¯¯æˆ–è§£æå¤±è´¥"
            )

        # æå–æµ‹è¯•ç±»
        test_classes = self.extract_test_classes_optimized(tree)

        # æå–å¯¼å…¥
        imports = self.extract_imports_optimized(tree)
        internal_imports = self.filter_internal_imports(imports)

        # è®¡ç®—ç»Ÿè®¡
        total_tests = sum(cls['method_count'] for cls in test_classes)
        class_count = len(test_classes)

        analysis_time = time.time() - file_start_time

        return TestFileAnalysis(
            file_path=test_file,
            test_classes=test_classes,
            total_tests=total_tests,
            imports=imports,
            internal_imports=internal_imports,
            class_count=class_count,
            parse_success=True
        )

    def analyze_files_parallel(self, test_files: List[Path]) -> List[TestFileAnalysis]:
        """å¹¶è¡Œåˆ†ææµ‹è¯•æ–‡ä»¶"""
        print(f"ğŸ”„ å¼€å§‹å¹¶è¡Œåˆ†æ {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶...")

        analyses = []
        failed_files = []

        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.analyze_single_file, test_file): test_file
                for test_file in test_files
            }

            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_file):
                test_file = future_to_file[future]
                try:
                    analysis = future.result()
                    analyses.append(analysis)

                    if analysis.parse_success:
                        print(f"  âœ… {test_file.name}: {analysis.class_count}ç±», {analysis.total_tests}æ–¹æ³•, {len(analysis.internal_imports)}æ¨¡å—")
                    else:
                        print(f"  âŒ {test_file.name}: {analysis.error_message}")
                        failed_files.append(test_file)

                except Exception as e:
                    print(f"  âŒ {test_file.name}: åˆ†æå¼‚å¸¸ - {e}")
                    failed_files.append(test_file)

        print(f"ğŸ“Š åˆ†æå®Œæˆ: {len(analyses) - len(failed_files)}æˆåŠŸ, {len(failed_files)}å¤±è´¥")
        return analyses

    def calculate_coverage_metrics(self, analyses: List[TestFileAnalysis]) -> CoverageMetrics:
        """è®¡ç®—è¦†ç›–ç‡æŒ‡æ ‡"""
        start_time = time.time()

        # ç»Ÿè®¡æˆåŠŸåˆ†æçš„æ–‡ä»¶
        successful_analyses = [a for a in analyses if a.parse_success]

        # ç»Ÿè®¡æµ‹è¯•è§„æ¨¡
        total_test_classes = sum(a.class_count for a in successful_analyses)
        total_test_methods = sum(a.total_tests for a in successful_analyses)

        # æ”¶é›†æ‰€æœ‰å†…éƒ¨å¯¼å…¥
        all_internal_imports = set()
        for analysis in successful_analyses:
            all_internal_imports.update(analysis.internal_imports)

        # è·å–é¡¹ç›®æ€»æ¨¡å—æ•°
        project_modules = self.discover_project_modules_cached()
        total_project_modules = len(project_modules)

        # è®¡ç®—è¦†ç›–ç‡
        coverage_percentage = (len(all_internal_imports) / total_project_modules * 100) if total_project_modules > 0 else 0

        calculation_time = time.time() - start_time

        return CoverageMetrics(
            total_files=len(analyses),
            successful_files=len(successful_analyses),
            total_test_classes=total_test_classes,
            total_test_methods=total_test_methods,
            covered_modules=len(all_internal_imports),
            total_project_modules=total_project_modules,
            coverage_percentage=coverage_percentage,
            execution_time=calculation_time
        )

    def generate_enhanced_report(self, metrics: CoverageMetrics, analyses: List[TestFileAnalysis]):
        """ç”Ÿæˆå¢å¼ºç‰ˆè¦†ç›–ç‡æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸš€ Issue #159 å¢å¼ºç‰ˆè¦†ç›–ç‡ç³»ç»Ÿ v2.0 - Phase 1 ä¼˜åŒ–æˆæœ")
        print("=" * 80)

        # æ€§èƒ½ç»Ÿè®¡
        print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
        print(f"  ğŸ”§ å¹¶è¡Œçº¿ç¨‹æ•°: {self.max_workers}")
        print(f"  ğŸ’¾ ç¼“å­˜å¤§å°: {self.cache_size}é¡¹")
        print(f"  â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {metrics.execution_time:.2f}ç§’")

        # æ–‡ä»¶åˆ†æç»Ÿè®¡
        success_rate = (metrics.successful_files / metrics.total_files * 100) if metrics.total_files > 0 else 0
        print(f"\nğŸ“Š æ–‡ä»¶åˆ†æç»Ÿè®¡:")
        print(f"  ğŸ“ æ€»æµ‹è¯•æ–‡ä»¶: {metrics.total_files}")
        print(f"  âœ… æˆåŠŸåˆ†æ: {metrics.successful_files}")
        print(f"  ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")

        # æµ‹è¯•è§„æ¨¡ç»Ÿè®¡
        print(f"\nğŸ§ª æµ‹è¯•è§„æ¨¡ç»Ÿè®¡:")
        print(f"  ğŸ›ï¸ æµ‹è¯•ç±»æ€»æ•°: {metrics.total_test_classes}")
        print(f"  ğŸ§ª æµ‹è¯•æ–¹æ³•æ€»æ•°: {metrics.total_test_methods}")

        # è¦†ç›–ç‡çªç ´ç»“æœ
        print(f"\nğŸ“ˆ è¦†ç›–ç‡çªç ´ç»“æœ:")
        print(f"  ğŸ“ é¡¹ç›®æ€»æ¨¡å—: {metrics.total_project_modules}")
        print(f"  âœ… è¦†ç›–æ¨¡å—æ•°: {metrics.covered_modules}")
        print(f"  ğŸ¯ æœ€ç»ˆè¦†ç›–ç‡: {metrics.coverage_percentage:.1f}%")

        # ç›®æ ‡è¾¾æˆçŠ¶æ€
        print(f"\nğŸ† Issue #159 ç›®æ ‡è¾¾æˆçŠ¶æ€:")
        print(f"  ğŸ¯ Phase 1ç›®æ ‡: 30%")
        print(f"  ğŸ“Š å®é™…è¾¾æˆ: {metrics.coverage_percentage:.1f}%")

        if metrics.coverage_percentage >= 30.0:
            improvement = metrics.coverage_percentage / 0.5  # ç›¸å¯¹äºåˆå§‹0.5%çš„æå‡å€æ•°
            print(f"  âœ¨ çŠ¶æ€: ğŸ† Phase 1é‡Œç¨‹ç¢‘æˆåŠŸè¾¾æˆ!")
            print(f"  ğŸš€ æå‡å€æ•°: {improvement:.1f}å€")
            print(f"  ğŸ”¥ æ€§èƒ½ä¼˜åŒ–: v2.0ç³»ç»Ÿæ˜¾è‘—æå‡åˆ†ææ•ˆç‡!")
        else:
            needed = 30.0 - metrics.coverage_percentage
            print(f"  âœ¨ çŠ¶æ€: ğŸ¯ Phase 1è¿›è¡Œä¸­...")
            print(f"  ğŸ’¡ è·ç¦»ç›®æ ‡è¿˜éœ€: {needed:.1f}%")

        # æ˜¾ç¤ºè¦†ç›–çš„æ¨¡å—
        all_modules = set()
        for analysis in analyses:
            if analysis.parse_success:
                all_modules.update(analysis.internal_imports)

        if all_modules:
            print(f"\nğŸ“¦ æˆåŠŸè¦†ç›–çš„æ¨¡å— ({len(all_modules)}ä¸ª):")
            for module in sorted(list(all_modules))[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
                print(f"  âœ… {module}")
            if len(all_modules) > 20:
                print(f"  ... è¿˜æœ‰ {len(all_modules) - 20} ä¸ªæ¨¡å—")

        print("\n" + "=" * 80)

        if metrics.coverage_percentage >= 30.0:
            print("ğŸ‰ğŸ‰ğŸ‰ æ­å–œ! Issue #159 Phase 1 30%é‡Œç¨‹ç¢‘æˆåŠŸè¾¾æˆ! ğŸ‰ğŸ‰ğŸ‰")
            print("ğŸš€ å¢å¼ºç‰ˆv2.0ç³»ç»ŸéªŒè¯äº†æŠ€æœ¯ä¼˜åŒ–çš„æœ‰æ•ˆæ€§!")
            print("âš¡ æ€§èƒ½å’Œç¨³å®šæ€§æ˜¾è‘—æå‡ï¼Œä¸ºPhase 2åšå¥½å……åˆ†å‡†å¤‡!")
        else:
            print("ğŸ¯ Issue #159 Phase 1 è¦†ç›–ç‡ä¼˜åŒ–è¿›è¡Œä¸­...")
            print("ğŸ’ª å¢å¼ºç‰ˆç³»ç»Ÿå·²ç»ä¼˜åŒ–ï¼Œå¯ä»¥ç»§ç»­å‘30%ç›®æ ‡å‰è¿›!")

        print("=" * 80)

    def run_enhanced_analysis(self) -> CoverageMetrics:
        """è¿è¡Œå¢å¼ºç‰ˆè¦†ç›–ç‡åˆ†æ"""
        total_start_time = time.time()

        print("=" * 80)
        print("ğŸš€ Issue #159 å¢å¼ºç‰ˆè¦†ç›–ç‡ç³»ç»Ÿ v2.0 å¯åŠ¨")
        print("ğŸ”§ Phase 1 çŸ­æœŸä¼˜åŒ–: æ€§èƒ½å’Œç¨³å®šæ€§æå‡")
        print("ğŸ¯ ç›®æ ‡: éªŒè¯ä¼˜åŒ–æ•ˆæœï¼Œå·©å›º30%é‡Œç¨‹ç¢‘æˆæœ")
        print("=" * 80)

        # å‘ç°æµ‹è¯•æ–‡ä»¶
        test_files = self.discover_test_files()
        print(f"\nğŸ“‹ å‘ç° {len(test_files)} ä¸ªIssue #159æµ‹è¯•æ–‡ä»¶")

        # å¹¶è¡Œåˆ†ææµ‹è¯•æ–‡ä»¶
        analyses = self.analyze_files_parallel(test_files)

        # è®¡ç®—è¦†ç›–ç‡æŒ‡æ ‡
        metrics = self.calculate_coverage_metrics(analyses)

        # ç”Ÿæˆå¢å¼ºæŠ¥å‘Š
        self.generate_enhanced_report(metrics, analyses)

        total_time = time.time() - total_start_time
        print(f"\nâ±ï¸ æ€»åˆ†ææ—¶é—´: {total_time:.2f}ç§’")

        return metrics

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¯åŠ¨å¢å¼ºç‰ˆè¦†ç›–ç‡ç³»ç»Ÿ v2.0...")

    try:
        # åˆ›å»ºå¢å¼ºç‰ˆç³»ç»Ÿ
        enhanced_system = EnhancedCoverageSystemV2(
            max_workers=4,  # 4çº¿ç¨‹å¹¶è¡Œå¤„ç†
            cache_size=128  # 128é¡¹LRUç¼“å­˜
        )

        # è¿è¡Œå¢å¼ºåˆ†æ
        metrics = enhanced_system.run_enhanced_analysis()

        # è¾“å‡ºç»“æœä¾›è„šæœ¬åˆ¤æ–­
        if metrics.coverage_percentage >= 30.0:
            print(f"\nğŸ¯ Issue #159 Phase 1 ä¼˜åŒ–æˆåŠŸ: {metrics.coverage_percentage:.1f}% â‰¥ 30%")
            return 0
        else:
            print(f"\nğŸ¯ Issue #159 Phase 1 ä¼˜åŒ–ä¸­: {metrics.coverage_percentage:.1f}% < 30%")
            return 1

    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
        return 2

if __name__ == "__main__":
    sys.exit(main())