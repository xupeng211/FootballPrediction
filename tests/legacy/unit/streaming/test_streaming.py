from datetime import datetime, timezone
import json

from decimal import Decimal
from src.data.collectors.streaming_collector import StreamingDataCollector
from src.streaming import (
from src.streaming.stream_processor import StreamProcessorManager
from unittest.mock import AsyncMock, Mock, patch
import pytest

"""
æµå¼æ•°æ®å¤„ç†æµ‹è¯•

æµ‹è¯•Kafka Producerå’ŒConsumerçš„ç”Ÿäº§/æ¶ˆè´¹æµç¨‹ï¼ŒéªŒè¯Kafkaé›†æˆçš„æ­£ç¡®æ€§ã€‚

âœ… æµ‹è¯•ç¯å¢ƒMockç­–ç•¥è¯´æ˜ï¼š
=====================================

æœ¬æµ‹è¯•æ–‡ä»¶ä½¿ç”¨Mock/Fakeå¯¹è±¡æ›¿ä»£çœŸå®Kafkaï¼Œå®ç°ä»¥ä¸‹ç›®æ ‡ï¼š
1. ğŸ”„ æµ‹è¯•ç‹¬ç«‹æ€§ï¼šä¸ä¾èµ–å¤–éƒ¨KafkaæœåŠ¡ï¼Œæµ‹è¯•å¯ä»¥åœ¨ä»»ä½•ç¯å¢ƒè¿è¡Œ
2. âš¡ å¿«é€Ÿæ‰§è¡Œï¼šé¿å…ç½‘ç»œå»¶è¿Ÿå’ŒKafkaé›†ç¾¤å¯åŠ¨æ—¶é—´
3. ğŸ›¡ï¸ é”™è¯¯æ§åˆ¶ï¼šå¯ä»¥æ¨¡æ‹Ÿå„ç§é”™è¯¯åœºæ™¯è¿›è¡Œæµ‹è¯•
4. ğŸ“Š ç»“æœéªŒè¯ï¼šç›´æ¥éªŒè¯æ¶ˆæ¯å†…å®¹å’Œè°ƒç”¨é€»è¾‘

ğŸ“š Mockå®ç°è¯¦è§£ï¼š
=====================================

1. FakeKafkaProducer ç±»ï¼š
   - æ¨¡æ‹Ÿconfluent_kafka.Producerçš„æ¥å£
   - å°†æ¶ˆæ¯å­˜å‚¨åœ¨å†…å­˜åˆ—è¡¨ä¸­ï¼Œæ–¹ä¾¿æµ‹è¯•éªŒè¯
   - æ”¯æŒproduce()ã€poll()ã€flush()ç­‰æ ¸å¿ƒæ–¹æ³•
   - æä¾›delivery_callbackå›è°ƒæœºåˆ¶

2. FakeKafkaConsumer ç±»ï¼š
   - æ¨¡æ‹Ÿconfluent_kafka.Consumerçš„æ¥å£
   - ä»é¢„è®¾çš„æ¶ˆæ¯åˆ—è¡¨ä¸­["æ¶ˆè´¹["]æ¶ˆæ¯["]"]""
   - æ”¯æŒsubscribe()ã€poll()ã€commit()ç­‰æ ¸å¿ƒæ–¹æ³•
   - å¯ä»¥æ¨¡æ‹Ÿå„ç§æ¶ˆè´¹åœºæ™¯å’Œé”™è¯¯æƒ…å†µ

3. MockMessage ç±»ï¼š
   - æ¨¡æ‹ŸKafkaæ¶ˆæ¯å¯¹è±¡
   - æä¾›value()ã€error()ã€topic()ç­‰æ–¹æ³•
   - æ”¯æŒæ­£å¸¸æ¶ˆæ¯å’Œé”™è¯¯æ¶ˆæ¯çš„æ¨¡æ‹Ÿ

ğŸ”§ åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„æ›¿æ¢æ–¹æ³•ï¼š
=====================================

è¦å°†æµ‹è¯•Mockæ›¿æ¢ä¸ºçœŸå®Kafkaï¼Œéœ€è¦ï¼š

1. ç¯å¢ƒé…ç½®ï¼š
   export KAFKA_BOOTSTRAP_SERVERS = "localhost9092[": export KAFKA_GROUP_ID="]football-data-consumers[": 2. ä¾èµ–å®‰è£…ï¼š": pip install confluent-kafka["""

3. ä»£ç ä¿®æ”¹ï¼ˆåœ¨éæµ‹è¯•ç¯å¢ƒï¼‰ï¼š
   - ç§»é™¤patchè£…é¥°å™¨
   - ä½¿ç”¨çœŸå®çš„StreamConfigé…ç½®
   - è¿æ¥åˆ°å®é™…çš„Kafkaé›†ç¾¤

4. Dockeréƒ¨ç½²ç¤ºä¾‹ï¼š
   # docker-compose.yml
   kafka:
    image: confluentinc/cp-kafka
    environment:
    KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

âš ï¸ é”™è¯¯å¤„ç†ç­–ç•¥ï¼š
=====================================

æœ¬æµ‹è¯•éªŒè¯äº†ä»¥ä¸‹é”™è¯¯å¤„ç†åœºæ™¯ï¼š
1. æ¶ˆæ¯å‘é€å¤±è´¥æ—¶è¿”å›Falseè€ŒéæŠ›å‡ºå¼‚å¸¸
2. æ¶ˆæ¯ååºåˆ—åŒ–å¤±è´¥æ—¶çš„å®‰å…¨é™çº§
3. æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶çš„é”™è¯¯è®°å½•
4. æ‰¹é‡æ“ä½œä¸­éƒ¨åˆ†å¤±è´¥çš„ç»Ÿè®¡å’Œå¤„ç†

è¿™ç¡®ä¿äº†åœ¨çœŸå®ç¯å¢ƒä¸­å³ä½¿é‡åˆ°ç½‘ç»œé—®é¢˜ã€Kafkaæ•…éšœç­‰æƒ…å†µï¼Œ
ç³»ç»Ÿä¹Ÿèƒ½ä¼˜é›…åœ°å¤„ç†é”™è¯¯ï¼Œä¸ä¼šå¯¼è‡´æ•´ä¸ªåº”ç”¨å´©æºƒã€‚
"]]"""

    FootballKafkaConsumer,
    FootballKafkaProducer,
    StreamConfig,
    StreamProcessor)
from src.streaming.stream_processor import StreamProcessorManager
# ğŸ“¦ ä¸ºæµ‹è¯•ç¯å¢ƒåˆ›å»ºçš„ Fake/Mock Kafka å®¢æˆ·ç«¯
# ========================================================
# è¿™äº›ç±»æ¨¡æ‹Ÿäº†çœŸå® Kafka å®¢æˆ·ç«¯çš„è¡Œä¸ºï¼Œä½†åœ¨æµ‹è¯•æœŸé—´ä¸ä¼šä¸çœŸå®çš„ Kafka broker é€šä¿¡ã€‚
# è¿™ä½¿å¾—æµ‹è¯•èƒ½å¤Ÿç‹¬ç«‹äºå¤–éƒ¨æœåŠ¡è¿è¡Œï¼Œä»è€Œæ›´å¿«ã€æ›´å¯é ã€‚
class FakeKafkaProducer:
    """
    ğŸ­ æ¨¡æ‹Ÿ Kafka Producer
    å®Œå…¨æ›¿ä»£ confluent_kafka.Producerï¼Œæä¾›ç›¸åŒçš„æ¥å£ä½†ä¸è¿›è¡Œå®é™…ç½‘ç»œé€šä¿¡ã€‚
    æ‰€æœ‰["å‘é€["]çš„æ¶ˆæ¯éƒ½å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œæ–¹ä¾¿æµ‹è¯•éªŒè¯ã€‚"]"""
    âœ… ä¸»è¦åŠŸèƒ½ï¼š
    - å­˜å‚¨æ‰€æœ‰produceè°ƒç”¨çš„æ¶ˆæ¯
    - æ¨¡æ‹Ÿdelivery_callbackå›è°ƒæœºåˆ¶
    - æä¾›poll()å’Œflush()æ–¹æ³•çš„ç©ºå®ç°
    - ğŸ›¡ï¸ å¢å¼ºé”™è¯¯å¤„ç†ï¼šæ”¯æŒæ¨¡æ‹Ÿå‘é€å¤±è´¥åœºæ™¯
    - ä¸æŠ›å‡ºç½‘ç»œç›¸å…³å¼‚å¸¸ï¼Œç¡®ä¿æµ‹è¯•ç¨³å®š
    ğŸ”§ ä¸ºä»€ä¹ˆä½¿ç”¨Fakeæ›¿ä»£çœŸå®Kafkaï¼š
    =================================
    1. æµ‹è¯•ç‹¬ç«‹æ€§ï¼šä¸ä¾èµ–å¤–éƒ¨KafkaæœåŠ¡ï¼Œå¯åœ¨ä»»ä½•ç¯å¢ƒè¿è¡Œ
    2. å¿«é€Ÿæ‰§è¡Œï¼šé¿å…ç½‘ç»œå»¶è¿Ÿå’ŒKafkaé›†ç¾¤å¯åŠ¨æ—¶é—´
    3. é”™è¯¯æ§åˆ¶ï¼šå¯ç²¾ç¡®æ§åˆ¶å„ç§é”™è¯¯åœºæ™¯çš„æ¨¡æ‹Ÿ
    4. ç»“æœéªŒè¯ï¼šç›´æ¥è®¿é—®å†…å­˜ä¸­çš„æ¶ˆæ¯ï¼Œä¾¿äºæ–­è¨€éªŒè¯
    5. CI/CDå‹å¥½ï¼šGitHub Actionsç­‰CIç¯å¢ƒæ— éœ€é…ç½®Kafka
    """
    def __init__(self, configs):
        """
        åˆå§‹åŒ–å‡Kafkaç”Ÿäº§è€…
        Args:
        configs: Kafkaé…ç½®å­—å…¸ï¼ˆåœ¨æµ‹è¯•ä¸­è¢«å¿½ç•¥ï¼‰
        """
        self.configs = configs
        self.messages = []  # å­˜å‚¨æ‰€æœ‰["å‘é€["]çš„æ¶ˆæ¯["]"]": self.simulate_failure = False  # ğŸ›¡ï¸ ç”¨äºæ¨¡æ‹Ÿå‘é€å¤±è´¥çš„å¼€å…³"
        self.failure_count = 0  # ğŸ›¡ï¸ è®°å½•å¤±è´¥æ¬¡æ•°
    def produce(self, topic, key, value, callback):
        """
        æ¨¡æ‹Ÿç”Ÿäº§æ¶ˆæ¯åˆ°Kafka topic
        Args:
        topic: ç›®æ ‡topicåç§°
        key: æ¶ˆæ¯key
        value: æ¶ˆæ¯å†…å®¹
        callback: å‘é€å®Œæˆåçš„å›è°ƒå‡½æ•°
        ğŸ’¡ æµ‹è¯•è¡Œä¸ºï¼š
        - å°†æ¶ˆæ¯å­˜å‚¨åˆ°self.messagesåˆ—è¡¨
        - ğŸ›¡ï¸ æ”¯æŒæ¨¡æ‹Ÿå‘é€å¤±è´¥åœºæ™¯
        - ç«‹å³è°ƒç”¨callbackæ¨¡æ‹Ÿå‘é€ç»“æœ
        - ä¸è¿›è¡Œä»»ä½•ç½‘ç»œæ“ä½œ
        ğŸ”§ é”™è¯¯å¤„ç†é€»è¾‘ï¼š
        - å½“simulate_failure=Trueæ—¶ï¼Œæ¨¡æ‹Ÿå‘é€å¤±è´¥
        - å¤±è´¥æ—¶callbackæ¥æ”¶åˆ°é”™è¯¯å¯¹è±¡è€ŒéNone
        - è¿™ç¡®ä¿äº†ä»£ç åœ¨çœŸå®ç¯å¢ƒä¸­çš„é”™è¯¯å¤„ç†è·¯å¾„å¾—åˆ°æµ‹è¯•
        """
        # ğŸ›¡ï¸ æ¨¡æ‹Ÿå‘é€å¤±è´¥åœºæ™¯
        if self.simulate_failure:
            self.failure_count += 1
            if callback:
            # æ¨¡æ‹Ÿå‘é€å¤±è´¥ï¼Œä¼ é€’é”™è¯¯å¯¹è±¡
            error = Exception(f["æ¨¡æ‹ŸKafkaå‘é€å¤±è´¥ #{self.failure_count)"])": callback(error, None)  # err=errorè¡¨ç¤ºå¤±è´¥["""
            # æŠ›å‡ºå¼‚å¸¸è®©producerçš„try-catchæ•è·åˆ°å¤±è´¥
            raise Exception(f["]æ¨¡æ‹ŸKafkaå‘é€å¤±è´¥ #{self.failure_count)"])": return["""
        # æ­£å¸¸å‘é€é€»è¾‘
        self.messages.append({"]topic[": topic, "]key[": key, "]value[": value))": if callback:"""
            # æ¨¡æ‹ŸçœŸå®å›è°ƒï¼Œä¼ é€’ä¸€ä¸ªæ¶ˆæ¯å¯¹è±¡è¡¨ç¤ºå‘é€æˆåŠŸ
            mock_msg = MockMessage(value=value, topic=topic)
            callback(None, mock_msg)  # err=Noneè¡¨ç¤ºæˆåŠŸ
    def poll(self, timeout):
        "]"""
        æ¨¡æ‹Ÿè½®è¯¢ï¼ˆå¤„ç†å›è°ƒå’Œè·å–å‘é€çŠ¶æ€ï¼‰
        Args:
        timeout: è½®è¯¢è¶…æ—¶æ—¶é—´ï¼ˆåœ¨æµ‹è¯•ä¸­è¢«å¿½ç•¥ï¼‰
        ğŸ’¡ æµ‹è¯•è¡Œä¸ºï¼šç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•å¤„ç†
        """
    def flush(self, timeout):
        """
        æ¨¡æ‹Ÿåˆ·æ–°æ‰€æœ‰å¾…å‘é€æ¶ˆæ¯
        Args:
        timeout: åˆ·æ–°è¶…æ—¶æ—¶é—´ï¼ˆåœ¨æµ‹è¯•ä¸­è¢«å¿½ç•¥ï¼‰
        Returns:
        int: å‰©ä½™æœªå‘é€æ¶ˆæ¯æ•°é‡
        ğŸ›¡ï¸ å¢å¼ºé”™è¯¯å¤„ç†ï¼š
        - å½“æ¨¡æ‹Ÿå¤±è´¥æ—¶ï¼Œè¿”å›å¤±è´¥æ•°é‡
        - ç¡®ä¿è°ƒç”¨è€…èƒ½æ£€æµ‹åˆ°å‘é€å¤±è´¥çš„æ¶ˆæ¯
        """
        if self.simulate_failure:
        return self.failure_count
        return 0
    def set_failure_mode(self, enable: bool):
        """
        ğŸ›¡ï¸ è®¾ç½®å¤±è´¥æ¨¡æ‹Ÿæ¨¡å¼
        Args:
        enable: æ˜¯å¦å¯ç”¨å¤±è´¥æ¨¡æ‹Ÿ
        ğŸ’¡ æµ‹è¯•ç”¨æ³•ï¼š
        - ç”¨äºæµ‹è¯•Kafkaå‘é€å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†é€»è¾‘
        - ç¡®ä¿åº”ç”¨åœ¨ç½‘ç»œé—®é¢˜æ—¶èƒ½ä¼˜é›…é™çº§
        """
        self.simulate_failure = enable
        if not enable:
        self.failure_count = 0
class FakeKafkaConsumer:
    """
    ğŸ­ æ¨¡æ‹Ÿ Kafka Consumer
    å®Œå…¨æ›¿ä»£ confluent_kafka.Consumerï¼Œæä¾›ç›¸åŒçš„æ¥å£ä½†ä¸è¿›è¡Œå®é™…ç½‘ç»œé€šä¿¡ã€‚
    ä»é¢„è®¾çš„æ¶ˆæ¯åˆ—è¡¨ä¸­["æ¶ˆè´¹["]æ¶ˆæ¯ï¼Œæ¨¡æ‹ŸçœŸå®çš„æ¶ˆè´¹è¡Œä¸ºã€‚"]"""
    âœ… ä¸»è¦åŠŸèƒ½ï¼š
    - ä»å†…å­˜æ¶ˆæ¯åˆ—è¡¨ä¸­æŒ‰åº["æ¶ˆè´¹["]æ¶ˆæ¯["]"]""
    - æ”¯æŒsubscribe()ã€poll()ã€commit()ç­‰æ ¸å¿ƒæ–¹æ³•
    - ğŸ›¡ï¸ å¯ä»¥é¢„è®¾æ¶ˆæ¯æ¥æ¨¡æ‹Ÿå„ç§æ¶ˆè´¹åœºæ™¯ï¼ˆåŒ…æ‹¬é”™è¯¯åœºæ™¯ï¼‰
    - æ”¯æŒé”™è¯¯æ¶ˆæ¯çš„æ¨¡æ‹Ÿæµ‹è¯•
    ğŸ”§ ä¸ºä»€ä¹ˆä½¿ç”¨Fakeæ›¿ä»£çœŸå®Kafkaï¼š
    =================================
    1. æ¶ˆè´¹æ§åˆ¶ï¼šå¯ç²¾ç¡®æ§åˆ¶æ¶ˆè´¹çš„æ¶ˆæ¯é¡ºåºå’Œå†…å®¹
    2. é”™è¯¯æ¨¡æ‹Ÿï¼šèƒ½æ¨¡æ‹Ÿå„ç§æ¶ˆè´¹å¼‚å¸¸å’Œç½‘ç»œé—®é¢˜
    3. æµ‹è¯•ç¨³å®šï¼šä¸å—å¤–éƒ¨Kafkaé›†ç¾¤çŠ¶æ€å½±å“
    4. æ€§èƒ½ä¼˜åŒ–ï¼šå†…å­˜æ“ä½œæ¯”ç½‘ç»œæ¶ˆè´¹å¿«æ•°ç™¾å€
    5. åœºæ™¯è¦†ç›–ï¼šèƒ½æµ‹è¯•ç½•è§çš„edge caseå’Œé”™è¯¯æƒ…å†µ
    """
    def __init__(self, configs):
        """
        åˆå§‹åŒ–å‡Kafkaæ¶ˆè´¹è€…
        Args:
        configs: Kafkaé…ç½®å­—å…¸ï¼ˆåœ¨æµ‹è¯•ä¸­è¢«å¿½ç•¥ï¼‰
        """
        self.configs = configs
        self.messages = []  # é¢„è®¾çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæµ‹è¯•æ—¶æ‰‹åŠ¨å¡«å……
        self.position = 0  # å½“å‰æ¶ˆè´¹ä½ç½®
        self.simulate_errors = False  # ğŸ›¡ï¸ ç”¨äºæ¨¡æ‹Ÿæ¶ˆè´¹é”™è¯¯çš„å¼€å…³
    def subscribe(self, topics):
        """
        æ¨¡æ‹Ÿè®¢é˜…Kafkaä¸»é¢˜
        Args:
        topics: è¦è®¢é˜…çš„ä¸»é¢˜åˆ—è¡¨
        ğŸ’¡ æµ‹è¯•è¡Œä¸ºï¼š
        - ä¸è¿›è¡Œå®é™…è®¢é˜…æ“ä½œ
        - å¯ä»¥åœ¨æµ‹è¯•ä¸­éªŒè¯æ˜¯å¦è°ƒç”¨äº†æ­¤æ–¹æ³•
        """
    def poll(self, timeout):
        """
        æ¨¡æ‹Ÿè½®è¯¢æ¶ˆæ¯
        Args:
        timeout: è½®è¯¢è¶…æ—¶æ—¶é—´ï¼ˆåœ¨æµ‹è¯•ä¸­è¢«å¿½ç•¥ï¼‰
        Returns:
        MockMessageæˆ–None: ä¸‹ä¸€æ¡æ¶ˆæ¯ï¼Œå¦‚æœæ²¡æœ‰æ¶ˆæ¯åˆ™è¿”å›None
        ğŸ’¡ æµ‹è¯•è¡Œä¸ºï¼š
        - ä»self.messagesåˆ—è¡¨ä¸­æŒ‰åºè¿”å›æ¶ˆæ¯
        - ğŸ›¡ï¸ æ”¯æŒæ¨¡æ‹Ÿå„ç§pollé”™è¯¯åœºæ™¯
        - è‡ªåŠ¨æ›´æ–°æ¶ˆè´¹ä½ç½®
        - å½“æ‰€æœ‰æ¶ˆæ¯æ¶ˆè´¹å®Œæ¯•åè¿”å›None
        ğŸ”§ é”™è¯¯å¤„ç†é€»è¾‘ï¼š
        - å¯ä»¥æ¨¡æ‹Ÿç½‘ç»œè¶…æ—¶ã€è¿æ¥å¤±è´¥ç­‰åœºæ™¯
        - ç¡®ä¿æ¶ˆè´¹è€…ä»£ç çš„é”™è¯¯å¤„ç†è·¯å¾„å¾—åˆ°å……åˆ†æµ‹è¯•
        """
        # ğŸ›¡ï¸ æ¨¡æ‹Ÿæ¶ˆè´¹é”™è¯¯åœºæ™¯
        if self.simulate_errors and self.position % 3 ==1:  # æ¯3æ¡æ¶ˆæ¯ä¸­æœ‰1æ¡é”™è¯¯
        error_mock = Mock()
        error_mock.code.return_value = 1  # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
            return MockMessage(error=error_mock)
        if self.position < len(self.messages):
            msg = self.messages[self.position]
            self.position += 1
            return msg
        return None
    def set_error_mode(self, enable: bool):
        """
        ğŸ›¡ï¸ è®¾ç½®é”™è¯¯æ¨¡æ‹Ÿæ¨¡å¼
        Args:
        enable: æ˜¯å¦å¯ç”¨é”™è¯¯æ¨¡æ‹Ÿ
        ğŸ’¡ æµ‹è¯•ç”¨æ³•ï¼š
        - ç”¨äºæµ‹è¯•Kafkaæ¶ˆè´¹é”™è¯¯æ—¶çš„å¤„ç†é€»è¾‘
        - ç¡®ä¿åº”ç”¨åœ¨æ¶ˆè´¹å¼‚å¸¸æ—¶èƒ½æ­£ç¡®é‡è¯•æˆ–è·³è¿‡
        """
        self.simulate_errors = enable
    def commit(self, msg):
        """
        æ¨¡æ‹Ÿæäº¤æ¶ˆæ¯åç§»é‡
        Args:
        msg: è¦æäº¤çš„æ¶ˆæ¯å¯¹è±¡
        ğŸ’¡ æµ‹è¯•è¡Œä¸ºï¼š
        - ä¸è¿›è¡Œå®é™…åç§»é‡æäº¤
        - å¯ä»¥åœ¨æµ‹è¯•ä¸­éªŒè¯æ˜¯å¦è°ƒç”¨äº†æ­¤æ–¹æ³•
        """
    def close(self):
        """
        æ¨¡æ‹Ÿå…³é—­æ¶ˆè´¹è€…è¿æ¥
        ğŸ’¡ æµ‹è¯•è¡Œä¸ºï¼šä¸è¿›è¡Œä»»ä½•æ“ä½œ
        """
class MockMessage:
    """
    ğŸ­ æ¨¡æ‹Ÿ Kafka æ¶ˆæ¯å¯¹è±¡
    å®Œå…¨æ›¿ä»£confluent_kafkaæ¶ˆæ¯å¯¹è±¡ï¼Œæä¾›ç›¸åŒçš„æ¥å£æ–¹æ³•ã€‚
    å¯ä»¥æ¨¡æ‹Ÿæ­£å¸¸æ¶ˆæ¯å’Œé”™è¯¯æ¶ˆæ¯ï¼Œæ»¡è¶³å„ç§æµ‹è¯•åœºæ™¯éœ€æ±‚ã€‚
    âœ… ä¸»è¦åŠŸèƒ½ï¼š
    - å­˜å‚¨æ¶ˆæ¯å†…å®¹ã€é”™è¯¯ä¿¡æ¯ã€å…ƒæ•°æ®
    - æä¾›value()ã€error()ã€topic()ç­‰æ ‡å‡†æ–¹æ³•
    - æ”¯æŒæ­£å¸¸æ¶ˆæ¯å’Œé”™è¯¯æ¶ˆæ¯çš„æ¨¡æ‹Ÿ
    - å¯è‡ªå®šä¹‰partitionå’Œoffsetä¿¡æ¯
    - ğŸ›¡ï¸ æ”¯æŒå¤æ‚é”™è¯¯åœºæ™¯æ¨¡æ‹Ÿï¼ˆç½‘ç»œæ–­å¼€ã€åºåˆ—åŒ–å¤±è´¥ç­‰ï¼‰
    ğŸ”§ ä¸ºä»€ä¹ˆéœ€è¦Mockæ¶ˆæ¯å¯¹è±¡ï¼š
    ===============================
    1. æ¥å£å…¼å®¹ï¼šä¸confluent_kafka.Messageå®Œå…¨ä¸€è‡´çš„API
    2. é”™è¯¯æ¨¡æ‹Ÿï¼šå¯ç²¾ç¡®æ§åˆ¶é”™è¯¯ç±»å‹å’Œé”™è¯¯ç 
    3. æ•°æ®æ§åˆ¶ï¼šå¯æ¨¡æ‹Ÿä»»æ„çš„æ¶ˆæ¯å†…å®¹å’Œå…ƒæ•°æ®
    4. æ€§èƒ½ä¼˜åŒ–ï¼šå†…å­˜æ“ä½œæ¯”ç½‘ç»œååºåˆ—åŒ–å¿«å¾—å¤š
    5. ç¡®å®šæ€§ï¼šæµ‹è¯•ç»“æœä¸å—å¤–éƒ¨æ•°æ®æºå½±å“
    """
    def __init__(
        self, value=None, error=None, topic="test-topic[", partition=0, offset=0[""""
        ):
        "]]"""
        åˆå§‹åŒ–æ¨¡æ‹Ÿæ¶ˆæ¯å¯¹è±¡
        Args:
        value: æ¶ˆæ¯å†…å®¹ï¼ˆbytesæˆ–Noneï¼‰
        error: é”™è¯¯å¯¹è±¡ï¼ˆç”¨äºæ¨¡æ‹Ÿæ¶ˆè´¹é”™è¯¯ï¼‰
        topic: æ¶ˆæ¯æ‰€å±çš„topicåç§°
        partition: æ¶ˆæ¯æ‰€å±çš„åˆ†åŒºå·
            offset: æ¶ˆæ¯åœ¨åˆ†åŒºä¸­çš„åç§»é‡
        """
        self._value = value
        self._error = error
        self._topic = topic
        self._partition = partition
        self._offset = offset
    def value(self):
        """
        è·å–æ¶ˆæ¯å†…å®¹
        Returns:
        bytesæˆ–None: æ¶ˆæ¯çš„åŸå§‹å­—èŠ‚å†…å®¹
        ğŸ’¡ æµ‹è¯•ç”¨æ³•ï¼š
        - æ­£å¸¸æ¶ˆæ¯ï¼šè¿”å›æ¶ˆæ¯å†…å®¹å­—èŠ‚
        - é”™è¯¯æ¶ˆæ¯ï¼šé€šå¸¸è¿”å›None
        """
        return self._value
    def error(self):
        """
        è·å–æ¶ˆæ¯é”™è¯¯ä¿¡æ¯
        Returns:
        é”™è¯¯å¯¹è±¡æˆ–None: å¦‚æœæ¶ˆæ¯æœ‰é”™è¯¯åˆ™è¿”å›é”™è¯¯å¯¹è±¡ï¼Œå¦åˆ™è¿”å›None
        ğŸ’¡ æµ‹è¯•ç”¨æ³•ï¼š
        - æ­£å¸¸æ¶ˆæ¯ï¼šè¿”å›None
        - é”™è¯¯æ¶ˆæ¯ï¼šè¿”å›Mocké”™è¯¯å¯¹è±¡
        """
        return self._error
    def topic(self):
        """
        è·å–æ¶ˆæ¯æ‰€å±çš„topic
        Returns:
        str: topicåç§°
        """
        return self._topic
    def partition(self):
        """
        è·å–æ¶ˆæ¯æ‰€å±çš„åˆ†åŒºå·
        Returns:
        int: åˆ†åŒºå·
        ğŸ’¡ æµ‹è¯•ä¼˜åŠ¿ï¼š
        - å¯æ¨¡æ‹Ÿä¸åŒåˆ†åŒºçš„æ¶ˆæ¯åˆ†å‘æƒ…å†µ
        - ç”¨äºæµ‹è¯•åˆ†åŒºè´Ÿè½½å‡è¡¡ç­–ç•¥
        """
        return self._partition
    def offset(self):
        """
        è·å–æ¶ˆæ¯åœ¨åˆ†åŒºä¸­çš„åç§»é‡
        Returns:
        int: åç§»é‡
        ğŸ’¡ æµ‹è¯•ä¼˜åŠ¿ï¼š
        - å¯æ¨¡æ‹Ÿæ¶ˆè´¹è¿›åº¦å’Œåç§»é‡ç®¡ç†
        - ç”¨äºæµ‹è¯•æ¶ˆè´¹è€…çš„commité€»è¾‘
        """
        return self._offset
        @classmethod
    def create_error_message(
        cls, error_code: "int[", error_description = str : """"
        ) -> "]MockMessage[":""""
        "]"""
        ğŸ›¡ï¸ åˆ›å»ºé”™è¯¯æ¶ˆæ¯çš„å·¥å‚æ–¹æ³•
        Args:
        error_code: é”™è¯¯ç  (1=ç½‘ç»œé”™è¯¯, 2=åºåˆ—åŒ–é”™è¯¯, ç­‰)
        error_description: é”™è¯¯æè¿°
        Returns:
        MockMessage: åŒ…å«é”™è¯¯ä¿¡æ¯çš„æ¶ˆæ¯å¯¹è±¡
        ğŸ’¡ æµ‹è¯•ç”¨æ³•ï¼š
        - å¯æ¨¡æ‹Ÿå„ç§å…·ä½“çš„Kafkaé”™è¯¯åœºæ™¯
        - ç”¨äºéªŒè¯é”™è¯¯å¤„ç†é€»è¾‘çš„å®Œæ•´æ€§
        """
        error_mock = Mock()
        error_mock.code.return_value = error_code
        error_mock.str.return_value = error_description or f["Kafka error {error_code}"]": return cls(error=error_mock, value=None)"""
        @classmethod
    def create_normal_message(
        cls, data: "dict[", topic = str "]test-topic[", partition = int 0, offset int = 0[""""
        ) -> "]]MockMessage"""
        ğŸ’¡ åˆ›å»ºæ­£å¸¸æ¶ˆæ¯çš„å·¥å‚æ–¹æ³•
        Args:
        data: è¦åºåˆ—åŒ–çš„æ•°æ®
        topic: topicåç§°
        partition: åˆ†åŒºå·
        offset: åç§»é‡
        Returns:
            MockMessage: åŒ…å«æ•°æ®çš„æ­£å¸¸æ¶ˆæ¯å¯¹è±¡
        ğŸ’¡ æµ‹è¯•ç”¨æ³•ï¼š
        - å¿«é€Ÿåˆ›å»ºæ ‡å‡†æ ¼å¼çš„æµ‹è¯•æ¶ˆæ¯
        - è‡ªåŠ¨å¤„ç†JSONåºåˆ—åŒ–ï¼Œå‡å°‘æµ‹è¯•ä»£ç é‡å¤
        """
        serialized_data = json.dumps(data).encode("utf-8[")": return cls(": value=serialized_data, topic=topic, partition=partition, offset=offset[""
        )
class TestStreamConfig:
    "]]""æµ‹è¯•æµé…ç½®"""
    def test_stream_config_initialization(self):
        """æµ‹è¯•é…ç½®åˆå§‹åŒ–"""
        config = StreamConfig()
        assert config.kafka_config is not None
        assert config.kafka_config.bootstrap_servers is not None
        assert config.topics is not None
        assert "matches-stream[" in config.topics[""""
        assert "]]odds-stream[" in config.topics[""""
        assert "]]scores-stream[" in config.topics[""""
    def test_producer_config(self):
        "]]""æµ‹è¯•ç”Ÿäº§è€…é…ç½®"""
        config = StreamConfig()
        producer_config = config.get_producer_config()
        assert "bootstrap.servers[" in producer_config[""""
        assert "]]client.id[" in producer_config[""""
        assert "]]acks[" in producer_config[""""
    def test_consumer_config(self):
        "]]""æµ‹è¯•æ¶ˆè´¹è€…é…ç½®"""
        config = StreamConfig()
        consumer_config = config.get_consumer_config()
        assert "bootstrap.servers[" in consumer_config[""""
        assert "]]group.id[" in consumer_config[""""
        assert "]]auto.offset.reset[" in consumer_config[""""
class TestFootballKafkaProducer:
    "]]""æµ‹è¯•Kafkaç”Ÿäº§è€…"""
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.config = StreamConfig()
        # ä½¿ç”¨ FakeKafkaProducer æ›¿ä»£çœŸå®çš„ Producer
        self.patcher = patch(
        "src.streaming.kafka_producer.Producer[", new=FakeKafkaProducer[""""
        )
        self.mock_producer_class = self.patcher.start()
    def teardown_method(self):
        "]]""æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        self.patcher.stop()
    def test_producer_initialization(self):
        """æµ‹è¯•ç”Ÿäº§è€…åˆå§‹åŒ–"""
        producer = FootballKafkaProducer(self.config)
        producer._create_producer()  # æ‰‹åŠ¨è§¦å‘åˆ›å»º
        assert producer.config ==self.config
        assert isinstance(producer.producer, FakeKafkaProducer)
        @pytest.mark.asyncio
    async def test_send_match_data(self):
        """æµ‹è¯•å‘é€æ¯”èµ›æ•°æ®"""
        producer = FootballKafkaProducer(self.config)
        match_data = {
        "match_id[": 12345,""""
        "]home_team[: "Team A[","]"""
        "]away_team[: "Team B[","]"""
        "]match_time[": datetime.now(timezone.utc)": result = await producer.send_match_data(match_data)": assert result is True[" assert len(producer.producer.messages) ==1"
        sent_message = json.loads(producer.producer.messages[0]"]]value[")": assert sent_message["]data["]"]match_id[" ==12345[""""
        @pytest.mark.asyncio
    async def test_send_odds_data(self):
        "]]""æµ‹è¯•å‘é€èµ”ç‡æ•°æ®"""
        producer = FootballKafkaProducer(self.config)
        odds_data = {
        "match_id[": 12345,""""
        "]bookmaker[: "Test Bookmaker[","]"""
        "]home_odds[": 2.5,""""
        "]draw_odds[": 3.2,""""
            "]away_odds[": 1.8}": result = await producer.send_odds_data(odds_data)": assert result is True[" assert len(producer.producer.messages) ==1"
        sent_message = json.loads(producer.producer.messages[0]"]]value[")": assert sent_message["]data["]"]bookmaker[" =="]Test Bookmaker["""""
        @pytest.mark.asyncio
    async def test_send_scores_data(self):
        "]""æµ‹è¯•å‘é€æ¯”åˆ†æ•°æ®"""
        producer = FootballKafkaProducer(self.config)
        scores_data = {
        "match_id[": 12345,""""
        "]home_score[": 2,""""
        "]away_score[": 1,""""
        "]minute[": 90,""""
            "]status[": ["]finished["}": result = await producer.send_scores_data(scores_data)": assert result is True[" assert len(producer.producer.messages) ==1"
        sent_message = json.loads(producer.producer.messages[0]"]]value[")": assert sent_message["]data["]"]home_score[" ==2[""""
        @pytest.mark.asyncio
    async def test_producer_error_handling(self):
        "]]""æµ‹è¯•ç”Ÿäº§è€…é”™è¯¯å¤„ç†"""
        producer = FootballKafkaProducer(self.config)
        producer._create_producer()  # ç¡®ä¿ producer å®ä¾‹å·²åˆ›å»º
        # æ¨¡æ‹Ÿå‘é€å¤±è´¥
        with patch.object(:
            producer.producer, "produce[", side_effect=Exception("]Kafka Error[")""""
        ):
            result = await producer.send_match_data({"]match_id[": 12345))": assert result is False["""
        @pytest.mark.asyncio
    async def test_batch_send(self):
        "]]""æµ‹è¯•æ‰¹é‡å‘é€"""
        producer = FootballKafkaProducer(self.config)
        batch_data = [{"match_id[": i} for i in range(3)]": results = await producer.send_batch(batch_data, "]match[")": assert results["]success["] ==3[" assert results["]]failed["] ==0[" assert len(producer.producer.messages) ==3["""
        @pytest.mark.asyncio
    async def test_producer_failure_handling(self):
        "]]]"""
        ğŸ›¡ï¸ æµ‹è¯•ç”Ÿäº§è€…å¤±è´¥å¤„ç† - æ–°å¢çš„é”™è¯¯å¤„ç†æµ‹è¯•
        ç›®æ ‡ï¼šéªŒè¯åœ¨æ¨¡æ‹Ÿçš„Kafkaå‘é€å¤±è´¥åœºæ™¯ä¸‹ï¼Œ
        ç³»ç»Ÿèƒ½å¦è¿”å›å®‰å…¨çš„ç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ã€‚
        è¿™ç¡®ä¿äº†åœ¨çœŸå®ç¯å¢ƒä¸­é‡åˆ°ç½‘ç»œé—®é¢˜æˆ–Kafkaé›†ç¾¤æ•…éšœæ—¶ï¼Œ
        åº”ç”¨ç¨‹åºä¸ä¼šå´©æºƒï¼Œè€Œæ˜¯ä¼˜é›…åœ°å¤„ç†é”™è¯¯ã€‚
        """
        producer = FootballKafkaProducer(self.config)
        producer._create_producer()  # åˆå§‹åŒ–producer
        # ğŸ›¡ï¸ å¯ç”¨å¤±è´¥æ¨¡æ‹Ÿæ¨¡å¼
        producer.producer.set_failure_mode(True)
        # æµ‹è¯•å•æ¡æ¶ˆæ¯å‘é€å¤±è´¥
        match_data = {"match_id[": 12345, "]home_team[": "]Team A[", "]away_team[": "]Team B["}": result = await producer.send_match_data(match_data)"""
        # éªŒè¯å¤±è´¥å¤„ç†ï¼šåº”è¿”å›Falseè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        assert result is False
        assert len(producer.producer.messages) ==0  # æ²¡æœ‰æ¶ˆæ¯è¢«å­˜å‚¨
        assert producer.producer.failure_count ==1  # è®°å½•äº†å¤±è´¥æ¬¡æ•°
        # æµ‹è¯•æ‰¹é‡å‘é€å¤±è´¥
        batch_data = [{"]match_id[": i} for i in range(3)]": batch_results = await producer.send_batch(batch_data, "]match[")""""
        # éªŒè¯æ‰¹é‡å¤±è´¥å¤„ç†
        assert batch_results["]success["] ==0[" assert batch_results["]]failed["] ==3[" assert producer.producer.failure_count ==4  # 1 + 3 = 4æ¬¡å¤±è´¥["""
        # æµ‹è¯•flushåœ¨å¤±è´¥æ¨¡å¼ä¸‹çš„è¡Œä¸º
        remaining = producer.producer.flush(10.0)
        assert remaining ==4  # è¿”å›å¤±è´¥æ•°é‡
        # æ¢å¤æ­£å¸¸æ¨¡å¼å¹¶éªŒè¯
        producer.producer.set_failure_mode(False)
        result = await producer.send_match_data({"]]]match_id[": 99999))": assert result is True[" assert len(producer.producer.messages) ==1  # ç°åœ¨æœ‰äº†æˆåŠŸçš„æ¶ˆæ¯[""
class TestFootballKafkaConsumer:
    "]]]""æµ‹è¯•Kafkaæ¶ˆè´¹è€…"""
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.config = StreamConfig()
        self.patcher = patch(
        "src.streaming.kafka_consumer.Consumer[", new=FakeKafkaConsumer[""""
        )
        self.mock_consumer_class = self.patcher.start()
    def teardown_method(self):
        "]]""æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        self.patcher.stop()
    def test_consumer_initialization(self):
        """æµ‹è¯•æ¶ˆè´¹è€…åˆå§‹åŒ–"""
        consumer = FootballKafkaConsumer(self.config)
        consumer._create_consumer()  # æ‰‹åŠ¨è§¦å‘
        assert consumer.config ==self.config
        assert isinstance(consumer.consumer, FakeKafkaConsumer)
        @pytest.mark.asyncio
        @patch("src.streaming.kafka_consumer.DatabaseManager[")": async def test_process_match_message(self, mock_db_manager_class):"""
        "]""æµ‹è¯•å¤„ç†æ¯”èµ›æ¶ˆæ¯"""
        # ğŸ”§ ä¿®å¤AsyncMockåç¨‹è­¦å‘Š - ç¡®ä¿session.addå’Œsession.commitæ­£ç¡®æ¨¡æ‹Ÿ
        mock_session = AsyncMock()
        # å°†addè®¾ä¸ºæ™®é€šMockï¼Œå› ä¸ºåœ¨çœŸå®ä»£ç ä¸­å®ƒä¸æ˜¯åç¨‹
        mock_session.add = Mock()
        # commitåœ¨çœŸå®ä»£ç ä¸­æ˜¯åç¨‹ï¼Œæ‰€ä»¥ä¿æŒAsyncMock
        mock_session.commit = AsyncMock()
        mock_db_manager = Mock()
        mock_context_manager = AsyncMock()
        mock_context_manager.__aenter__.return_value = mock_session
        mock_context_manager.__aexit__.return_value = None
        mock_db_manager.get_async_session.return_value = mock_context_manager
        mock_db_manager_class.return_value = mock_db_manager
        consumer = FootballKafkaConsumer(self.config)
        message_data = {
        "data[": {""""
        "]match_id[": 12345,""""
        "]home_team[: "Team A[","]"""
        "]away_team[: "Team B[","]"""
            "]match_time[": datetime.now(timezone.utc)": result = await consumer._process_match_message(message_data)": assert result is True[" mock_session.add.assert_called_once()"
        mock_session.commit.assert_called_once()
        @pytest.mark.asyncio
        @patch("]]src.streaming.kafka_consumer.DatabaseManager[")": async def test_process_odds_message(self, mock_db_manager_class):"""
        "]""æµ‹è¯•å¤„ç†èµ”ç‡æ¶ˆæ¯"""
        # ğŸ”§ ä¿®å¤AsyncMockåç¨‹è­¦å‘Š - ç¡®ä¿session.addå’Œsession.commitæ­£ç¡®æ¨¡æ‹Ÿ
        mock_session = AsyncMock()
        # å°†addè®¾ä¸ºæ™®é€šMockï¼Œå› ä¸ºåœ¨çœŸå®ä»£ç ä¸­å®ƒä¸æ˜¯åç¨‹
        mock_session.add = Mock()
        # commitåœ¨çœŸå®ä»£ç ä¸­æ˜¯åç¨‹ï¼Œæ‰€ä»¥ä¿æŒAsyncMock
        mock_session.commit = AsyncMock()
        mock_db_manager = Mock()
        mock_context_manager = AsyncMock()
        mock_context_manager.__aenter__.return_value = mock_session
        mock_context_manager.__aexit__.return_value = None
        mock_db_manager.get_async_session.return_value = mock_context_manager
        mock_db_manager_class.return_value = mock_db_manager
        consumer = FootballKafkaConsumer(self.config)
        message_data = {
        "data[": {""""
        "]match_id[": 12345,""""
        "]bookmaker[: "Test Bookmaker[","]"""
        "]home_odds[": 2.5,""""
            "]draw_odds[": 3.2}""""
        }
        result = await consumer._process_odds_message(message_data)
        assert result is True
        mock_session.add.assert_called_once()
        mock_session.commit.assert_called_once()
        @pytest.mark.asyncio
        @patch("]src.streaming.kafka_consumer.DatabaseManager[")": async def test_process_scores_message(self, mock_db_manager_class):"""
        "]""æµ‹è¯•å¤„ç†æ¯”åˆ†æ¶ˆæ¯"""
        # ğŸ”§ ä¿®å¤AsyncMockåç¨‹è­¦å‘Š - ç¡®ä¿session.addå’Œsession.commitæ­£ç¡®æ¨¡æ‹Ÿ
        mock_session = AsyncMock()
        # å°†addè®¾ä¸ºæ™®é€šMockï¼Œå› ä¸ºåœ¨çœŸå®ä»£ç ä¸­å®ƒä¸æ˜¯åç¨‹
        mock_session.add = Mock()
        # commitåœ¨çœŸå®ä»£ç ä¸­æ˜¯åç¨‹ï¼Œæ‰€ä»¥ä¿æŒAsyncMock
        mock_session.commit = AsyncMock()
        mock_db_manager = Mock()
        mock_context_manager = AsyncMock()
        mock_context_manager.__aenter__.return_value = mock_session
        mock_context_manager.__aexit__.return_value = None
        mock_db_manager.get_async_session.return_value = mock_context_manager
        mock_db_manager_class.return_value = mock_db_manager
        consumer = FootballKafkaConsumer(self.config)
        message_data = {
        "data[": {""""
        "]match_id[": 12345,""""
        "]home_score[": 2,""""
        "]away_score[": 1,""""
            "]minute[": 90}""""
        }
        result = await consumer._process_scores_message(message_data)
        assert result is True
        mock_session.add.assert_called_once()
        mock_session.commit.assert_called_once()
        @pytest.mark.asyncio
    async def test_consume_batch(self):
        "]""æµ‹è¯•æ‰¹é‡æ¶ˆè´¹"""
        consumer = FootballKafkaConsumer(self.config)
        consumer._create_consumer()  # æ‰‹åŠ¨è§¦å‘
        # å‡†å¤‡æ¨¡æ‹Ÿæ¶ˆæ¯
        messages = [
        MockMessage(value=json.dumps(
        {"data_type[: "match"", "data["]: 1})""""
        ).encode()
            ),
            MockMessage(value=json.dumps(
                {"]data_type[: "odds"", "data["]: 2})""""
                ).encode()
            )]
        consumer.consumer.messages = messages
        with patch.object(:
            consumer, "]_process_message[", new_callable=AsyncMock[""""
        ) as mock_process:
            mock_process.return_value = True
            results = await consumer.consume_batch(batch_size=2, timeout=1.0)
        assert results["]]processed["] ==2[" assert mock_process.call_count ==2["""
        @pytest.mark.asyncio
    async def test_consumer_error_handling(self):
        "]]]""æµ‹è¯•æ¶ˆè´¹è€…é”™è¯¯å¤„ç†"""
        consumer = FootballKafkaConsumer(self.config)
        consumer._create_consumer()
        # æ¨¡æ‹ŸåŒ…å«é”™è¯¯çš„æ¶ˆæ¯
        error_mock = Mock()
        error_mock.code.return_value = 1  # é EOF é”™è¯¯
        consumer.consumer.messages = [MockMessage(error=error_mock)]
        results = await consumer.consume_batch(batch_size=1, timeout=1.0)
        assert results["failed["] ==1["]"]" assert results["processed["] ==0["]"]""
        @pytest.mark.asyncio
    async def test_consumer_error_simulation(self):
        """
        ğŸ›¡ï¸ æµ‹è¯•æ¶ˆè´¹è€…é”™è¯¯æ¨¡æ‹Ÿ - æ–°å¢çš„é”™è¯¯å¤„ç†æµ‹è¯•
        ç›®æ ‡ï¼šéªŒè¯åœ¨æ¨¡æ‹Ÿçš„Kafkaæ¶ˆè´¹é”™è¯¯åœºæ™¯ä¸‹ï¼Œ
        ç³»ç»Ÿèƒ½å¦æ­£ç¡®è¯†åˆ«å’Œå¤„ç†å„ç§æ¶ˆè´¹å¼‚å¸¸ã€‚
        è¿™ç¡®ä¿äº†åœ¨çœŸå®ç¯å¢ƒä¸­é‡åˆ°ç½‘ç»œé—®é¢˜æˆ–è¿æ¥å¤±è´¥æ—¶ï¼Œ
        æ¶ˆè´¹è€…èƒ½åç•¥å–æ¶ˆè´¹æˆ–è¿›è¡Œé€‚å½“çš„é‡è¯•ã€‚
        """
        consumer = FootballKafkaConsumer(self.config)
        consumer._create_consumer()
        # æ·»åŠ æ­£å¸¸æ¶ˆæ¯å’Œé”™è¯¯æ¶ˆæ¯æ··åˆ
        normal_message = MockMessage(value = json.dumps({"data_type[: "match"", "data["]: 1})).encode()""""
        )
        consumer.consumer.messages = ["]normal_message[",  # ç¬¬1æ¡ï¼šæ­£å¸¸[": None,  # ç¬¬2æ¡ï¼šä¼šè§¦å‘é”™è¯¯æ¨¡æ‹Ÿ[": normal_message,  # ç¬¬3æ¡ï¼šæ­£å¸¸[""
        ]
        # ğŸ›¡ï¸ å¯ç”¨é”™è¯¯æ¨¡æ‹Ÿæ¨¡å¼
        consumer.consumer.set_error_mode(True)
        # éªŒè¯é”™è¯¯å¤„ç†
        with patch.object(:
            consumer, "]]]]_process_message[", new_callable=AsyncMock[""""
        ) as mock_process:
            mock_process.return_value = True
            results = await consumer.consume_batch(batch_size=5, timeout=2.0)
            # åº”è¯¥æœ‰éƒ¨åˆ†æˆåŠŸå’Œéƒ¨åˆ†å¤±è´¥
        assert results["]]processed["] >= 1  # è‡³å°‘å¤„ç†äº†ä¸€æ¡æ­£å¸¸æ¶ˆæ¯[" assert results["]]failed["] >= 1  # è‡³å°‘æœ‰ä¸€æ¡é”™è¯¯[""""
        # æ¢å¤æ­£å¸¸æ¨¡å¼
        consumer.consumer.set_error_mode(False)
class TestStreamProcessor:
    "]]""æµ‹è¯•æµå¤„ç†å™¨"""
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.config = StreamConfig()
    def test_stream_processor_initialization(self):
        """æµ‹è¯•æµå¤„ç†å™¨åˆå§‹åŒ–"""
        processor = StreamProcessor(self.config)
        assert processor.config ==self.config
        assert processor.producer is None  # åˆå§‹åŒ–æ—¶ä¸ºNoneï¼Œæƒ°æ€§åˆ›å»º
        assert processor.consumer is None  # åˆå§‹åŒ–æ—¶ä¸ºNoneï¼Œæƒ°æ€§åˆ›å»º
        @pytest.mark.asyncio
    async def test_send_data(self):
        """æµ‹è¯•å‘é€æ•°æ®"""
        with patch(:
            "src.streaming.stream_processor.FootballKafkaProducer["""""
        ) as mock_producer_class = mock_producer AsyncMock()
            mock_producer.send_match_data.return_value = True
            mock_producer_class.return_value = mock_producer
            processor = StreamProcessor(self.config)
            result = await processor.send_data({"]match_id[": 12345), "]match[")": assert result is True[" mock_producer.send_match_data.assert_called_once_with({"]]match_id[": 12345))": def test_consume_data(self):"""
        "]""æµ‹è¯•æ¶ˆè´¹æ•°æ®"""
        with patch(:
            "src.streaming.stream_processor.FootballKafkaConsumer["""""
        ) as mock_consumer_class = mock_consumer Mock()
            mock_consumer.consume_batch = AsyncMock(return_value = {"]processed[": 1, "]failed[": 0)""""
            )
            mock_consumer.subscribe_all_topics = Mock()
            mock_consumer_class.return_value = mock_consumer
            processor = StreamProcessor(self.config)
            results = processor.consume_data(timeout=1.0, max_messages=10)
        assert results["]processed["] ==1[" mock_consumer.subscribe_all_topics.assert_called_once()"""
        @pytest.mark.asyncio
    async def test_health_check(self):
        "]]""æµ‹è¯•å¥åº·æ£€æŸ¥"""
        processor = StreamProcessor(self.config)
        # æµ‹è¯•æœªåˆå§‹åŒ–çŠ¶æ€
        health_status = await processor.health_check()
        assert health_status["producer_status["] =="]not_initialized[" assert health_status["]consumer_status["] =="]not_initialized[" assert health_status["]kafka_connection["] is False[""""
        # æµ‹è¯•å·²åˆå§‹åŒ–çŠ¶æ€
        with patch(:
            "]]src.streaming.stream_processor.FootballKafkaProducer["""""
        ) as mock_producer_class = mock_producer Mock()
            mock_producer.producer = Mock()  # æ¨¡æ‹Ÿå·²åˆå§‹åŒ–çš„ producer
            mock_producer_class.return_value = mock_producer
            processor._initialize_producer()  # æ‰‹åŠ¨åˆå§‹åŒ–
            health_status = await processor.health_check()
        assert health_status["]producer_status["] =="]healthy[" assert health_status["]consumer_status["] =="]not_initialized[" class TestStreamProcessorManager:""""
    "]""æµ‹è¯•æµå¤„ç†å™¨ç®¡ç†å™¨"""
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.config = StreamConfig()
        @patch("src.streaming.stream_processor.StreamProcessor[")": def test_manager_initialization(self, mock_processor_class):"""
        "]""æµ‹è¯•ç®¡ç†å™¨åˆå§‹åŒ–"""
        manager = StreamProcessorManager(self.config, num_processors=3)
        assert len(manager.processors) ==3
        assert mock_processor_class.call_count ==3
        @patch("src.streaming.stream_processor.StreamProcessor[")": def test_start_all_processors(self, mock_processor_class):"""
        "]""æµ‹è¯•å¯åŠ¨æ‰€æœ‰å¤„ç†å™¨"""
        # ä¸ºæ¯ä¸ªå¤„ç†å™¨åˆ›å»ºç‹¬ç«‹çš„Mockå®ä¾‹
        mock_processors = []
        for i in range(2):
        mock_processor = Mock()
        mock_processor.start = Mock(return_value=True)
        mock_processors.append(mock_processor)
        mock_processor_class.side_effect = mock_processors
        manager = StreamProcessorManager(self.config, num_processors=2)
        result = manager.start_all()
        assert result is True
        # éªŒè¯æ¯ä¸ªå¤„ç†å™¨çš„ start æ–¹æ³•éƒ½è¢«è°ƒç”¨äº†ä¸€æ¬¡
        for mock_processor in mock_processors:
        mock_processor.start.assert_called_once()
        @patch("src.streaming.stream_processor.StreamProcessor[")": def test_stop_all_processors(self, mock_processor_class):"""
        "]""æµ‹è¯•åœæ­¢æ‰€æœ‰å¤„ç†å™¨"""
        # ä¸ºæ¯ä¸ªå¤„ç†å™¨åˆ›å»ºç‹¬ç«‹çš„Mockå®ä¾‹
        mock_processors = []
        for i in range(2):
        mock_processor = Mock()
        mock_processor.stop_processing = Mock()
        mock_processors.append(mock_processor)
        mock_processor_class.side_effect = mock_processors
        manager = StreamProcessorManager(self.config, num_processors=2)
        result = manager.stop_all()
        assert result is True
        # éªŒè¯æ¯ä¸ªå¤„ç†å™¨çš„ stop_processing æ–¹æ³•éƒ½è¢«è°ƒç”¨äº†ä¸€æ¬¡
        for mock_processor in mock_processors:
        mock_processor.stop_processing.assert_called_once()
class TestStreamingDataCollector:
    """æµ‹è¯•æµå¼æ•°æ®æ”¶é›†å™¨"""
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.config = StreamConfig()
        @patch("src.data.collectors.streaming_collector.FootballKafkaProducer[")""""
        @patch("]src.data.collectors.streaming_collector.DataCollector.__init__[")": def test_streaming_collector_initialization(": self, mock_base_init, mock_producer_class[""
        ):
        "]]""æµ‹è¯•æµå¼æ”¶é›†å™¨åˆå§‹åŒ–"""
        mock_base_init.return_value = None
        collector = StreamingDataCollector()
        assert collector.kafka_producer is not None
        mock_producer_class.assert_called_once()
        @pytest.mark.asyncio
    async def test_collect_fixtures_with_streaming(self):
        """æµ‹è¯•å¸¦æµå¼å¤„ç†çš„èµ›ç¨‹æ”¶é›†"""
        with patch(:
            "src.data.collectors.streaming_collector.FootballKafkaProducer["""""
        ) as mock_producer_class, patch(
            "]src.data.collectors.streaming_collector.DataCollector.__init__[",": return_value=None), patch.object(": StreamingDataCollector, "]collect_fixtures[", new_callable=AsyncMock[""""
        ) as mock_base_collect:
            # è®¾ç½® mock è¿”å›å€¼
            from src.data.collectors.base_collector import CollectionResult
            mock_result = CollectionResult(data_source="]]test_source[",": collection_type="]fixtures[",": records_collected=1,": success_count=1,": error_count=0,"
                status="]success[",": collected_data = [{"]fixture[": {"]id[": 1})])": mock_base_collect.return_value = mock_result[": mock_producer = AsyncMock()": mock_producer.send_match_data.return_value = True"
            mock_producer.close = Mock()  # closeä¸æ˜¯åç¨‹æ–¹æ³•
            mock_producer_class.return_value = mock_producer
            collector = StreamingDataCollector()
            collector.kafka_producer = mock_producer
            collector.enable_streaming = True
            results = await collector.collect_fixtures_with_streaming(
                league_id=39, season=2024
            )
        assert results.status =="]]success[" assert len(results.collected_data) ==1[""""
        mock_base_collect.assert_called_once_with(league_id=39, season=2024)
        @pytest.mark.asyncio
    async def test_collect_odds_with_streaming(self):
        "]]""æµ‹è¯•å¸¦æµå¼å¤„ç†çš„èµ”ç‡æ”¶é›†"""
        with patch(:
            "src.data.collectors.streaming_collector.FootballKafkaProducer["""""
        ) as mock_producer_class, patch(
            "]src.data.collectors.streaming_collector.DataCollector.__init__[",": return_value=None), patch.object(": StreamingDataCollector, "]collect_odds[", new_callable=AsyncMock[""""
        ) as mock_base_collect:
            # è®¾ç½® mock è¿”å›å€¼
            from src.data.collectors.base_collector import CollectionResult
            mock_result = CollectionResult(data_source="]]test_source[",": collection_type="]odds[",": records_collected=1,": success_count=1,": error_count=0,"
                status="]success[",": collected_data = [{"]bookmakers[": [{"]name[": "]test[", "]bets[" []}])])": mock_base_collect.return_value = mock_result[": mock_producer = AsyncMock()": mock_producer.send_odds_data.return_value = True"
            mock_producer.close = Mock()  # closeä¸æ˜¯åç¨‹æ–¹æ³•
            mock_producer_class.return_value = mock_producer
            collector = StreamingDataCollector()
            collector.kafka_producer = mock_producer
            collector.enable_streaming = True
            results = await collector.collect_odds_with_streaming(fixture_id=12345)
        assert results.status =="]]success[" assert len(results.collected_data) ==1[""""
        mock_base_collect.assert_called_once_with(fixture_id=12345)
        @pytest.mark.asyncio
    async def test_collect_live_scores_with_streaming(self):
        "]]""æµ‹è¯•å¸¦æµå¼å¤„ç†çš„å®æ—¶æ¯”åˆ†æ”¶é›†"""
        with patch(:
            "src.data.collectors.streaming_collector.FootballKafkaProducer["""""
        ) as mock_producer_class, patch(
            "]src.data.collectors.streaming_collector.DataCollector.__init__[",": return_value=None), patch.object(": StreamingDataCollector, "]collect_live_scores[", new_callable=AsyncMock[""""
        ) as mock_base_collect:
            # è®¾ç½® mock è¿”å›å€¼
            from src.data.collectors.base_collector import CollectionResult
            mock_result = CollectionResult(data_source="]]test_source[",": collection_type="]live_scores[",": records_collected=1,": success_count=1,": error_count=0,"
                status="]success[",": collected_data=["""
                {"]fixture[": {"]id[": 1}, "]goals[": {"]home[": 2, "]away[": 1})""""
                ])
            mock_base_collect.return_value = mock_result
            mock_producer = AsyncMock()
            mock_producer.send_scores_data.return_value = True
            mock_producer.close = Mock()  # closeä¸æ˜¯åç¨‹æ–¹æ³•
            mock_producer_class.return_value = mock_producer
            collector = StreamingDataCollector()
            collector.kafka_producer = mock_producer
            collector.enable_streaming = True
            results = await collector.collect_live_scores_with_streaming()
        assert results.status =="]success[" assert len(results.collected_data) ==1[""""
        mock_base_collect.assert_called_once_with()
class TestKafkaIntegration:
    "]]""æµ‹è¯•Kafkaé›†æˆåœºæ™¯"""
    @pytest.mark.asyncio
    @patch("src.streaming.kafka_consumer.DatabaseManager[")": async def test_end_to_end_flow(self, mock_db_manager_class):"""
        "]""æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹"""
        config = StreamConfig()
        with patch(:
        "src.streaming.kafka_producer.Producer[", new=FakeKafkaProducer[""""
        ), patch("]]src.streaming.kafka_consumer.Consumer[", new = FakeKafkaConsumer)""""
            # 1. ç”Ÿäº§è€…å‘é€æ¶ˆæ¯
            producer = FootballKafkaProducer(config)
            test_data = {"]match_id[": 12345, "]home_team[": "]Team A["}": result = await producer.send_match_data(test_data)": assert result is True[" assert len(producer.producer.messages) ==1"
        # 2. æ¶ˆè´¹è€…æ¥æ”¶å¹¶å¤„ç†æ¶ˆæ¯
        consumer = FootballKafkaConsumer(config)
        consumer._create_consumer()
        # ä» FakeProducer è·å–æ¶ˆæ¯å¹¶æ”¾å…¥ FakeConsumer
        sent_message = producer.producer.messages[0]
        consumer.consumer.messages = [MockMessage(value=sent_message["]]value["].encode())]""""
        # ğŸ”§ Mock æ•°æ®åº“ - ä¿®å¤AsyncMockåç¨‹è­¦å‘Š
        mock_session = AsyncMock()
        # å°†addè®¾ä¸ºæ™®é€šMockï¼Œå› ä¸ºåœ¨çœŸå®ä»£ç ä¸­å®ƒä¸æ˜¯åç¨‹
        mock_session.add = Mock()
        # commitåœ¨çœŸå®ä»£ç ä¸­æ˜¯åç¨‹ï¼Œæ‰€ä»¥ä¿æŒAsyncMock
        mock_session.commit = AsyncMock()
        mock_db_manager = Mock()
        mock_context_manager = AsyncMock()
        mock_context_manager.__aenter__.return_value = mock_session
        mock_context_manager.__aexit__.return_value = None
        mock_db_manager.get_async_session.return_value = mock_context_manager
        mock_db_manager_class.return_value = mock_db_manager
        # é‡æ–°è®¾ç½®consumerçš„æ•°æ®åº“ç®¡ç†å™¨
        consumer.db_manager = mock_db_manager
        # éªŒè¯æ¶ˆæ¯å†…å®¹æ ¼å¼æ­£ç¡®
        message_content = json.loads(sent_message["]value["])": assert "]data_type[" in message_content[""""
        assert "]]data[" in message_content[""""
        # æ‰‹åŠ¨æ·»åŠ ç¼ºå¤±çš„å­—æ®µåˆ°æ¶ˆæ¯ä¸­
        if "]]data_type[": not in message_content:": message_content["]data_type["] = "]match[": message_content["]source["] = "]test_source[": updated_message = json.dumps(message_content)": consumer.consumer.messages = [MockMessage(value=updated_message.encode())]"""
        # æ¶ˆè´¹å¹¶éªŒè¯
        results = await consumer.consume_batch(batch_size=1)
        assert results["]processed["] ==1[""""
        # éªŒè¯sessionçš„è°ƒç”¨
        mock_session.add.assert_called_once()
        mock_session.commit.assert_called_once()
    def test_data_serialization(self):
        "]]""æµ‹è¯•æ•°æ®åºåˆ—åŒ–"""
        config = StreamConfig()
        with patch("src.streaming.kafka_producer.Producer[", new = FakeKafkaProducer)": producer = FootballKafkaProducer(config)": test_data = {""
            "]match_id[": 12345,""""
            "]match_time[": datetime.now(timezone.utc)": serialized = producer._serialize_data(test_data)": assert isinstance(serialized, str)" deserialized = json.loads(serialized)"
        assert "]match_id[" in deserialized[""""
        @pytest.mark.asyncio
    async def test_async_processing(self):
        "]]""æµ‹è¯•å¼‚æ­¥å¤„ç†"""
        config = StreamConfig()
        with patch("src.streaming.kafka_producer.Producer[", new = FakeKafkaProducer)": producer = FootballKafkaProducer(config)": batch_data = [{"]match_id[": i} for i in range(5)]": results = await producer.send_batch(batch_data, "]match[")": assert results["]success["] ==5[" if __name__ =="]]__main__[": pytest.main(["]__file__[", "]-v["])"]": from src.data.collectors.base_collector import CollectionResult": from src.data.collectors.base_collector import CollectionResult"
            from src.data.collectors.base_collector import CollectionResult