#!/usr/bin/env python3
"""
P3.1.2 è¿æ¥æ± ç¨³å®šæ€§æµ‹è¯•
æµ‹è¯•æ•°æ®åº“è¿æ¥æ± åœ¨å¹¶å‘åœºæ™¯ä¸‹çš„è¡¨ç°
"""

import pytest
import asyncio
import time
import statistics
from typing import List, Dict, Any
from datetime import datetime
import asyncpg
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

import pytest_asyncio

# æ³¨é‡Šæ‰ä¸å­˜åœ¨çš„å¯¼å…¥ï¼Œæ”¹ç”¨åŸºæœ¬æµ‹è¯•é…ç½®
# from tests.integration.conftest import (
#     integration_connection_pool,
#     integration_db_engine,
#     integration_db_session,
#     integration_redis_client
# )


class TestConnectionPoolStability:
    """è¿æ¥æ± ç¨³å®šæ€§æµ‹è¯•å¥—ä»¶"""

    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.database
    @pytest.mark.connection_pool
    async def test_connection_pool_basic_functionality(
        self, integration_connection_pool
    ):
        """æµ‹è¯•è¿æ¥æ± åŸºæœ¬åŠŸèƒ½"""
        print("\nğŸŠ æµ‹è¯•è¿æ¥æ± åŸºæœ¬åŠŸèƒ½...")

        # éªŒè¯è¿æ¥æ± çŠ¶æ€
        pool_info = {
            "min_size": integration_connection_pool._minsize,
            "max_size": integration_connection_pool._maxsize,
            "current_size": len(integration_connection_pool._queue._queue),
            "available_connections": integration_connection_pool._queue.qsize(),
        }

        print(f"ğŸ“Š è¿æ¥æ± é…ç½®: min={pool_info['min_size']}, max={pool_info['max_size']}")
        print(f"ğŸ“Š å½“å‰çŠ¶æ€: size={pool_info['current_size']}, available={pool_info['available_connections']}")

        # åŸºæœ¬è¿æ¥æµ‹è¯•
        async with integration_connection_pool.acquire() as conn:
            result = await conn.fetchval("SELECT 1 as test")
            assert result == 1, "åŸºæœ¬è¿æ¥æµ‹è¯•å¤±è´¥"

        print("âœ… è¿æ¥æ± åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")

    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.database
    @pytest.mark.connection_pool
    async def test_concurrent_connections_10(
        self, integration_connection_pool
    ):
        """æµ‹è¯•10ä¸ªå¹¶å‘è¿æ¥ - æ ¸å¿ƒç¨³å®šæ€§æµ‹è¯•"""
        print("\nğŸš€ æµ‹è¯•10ä¸ªå¹¶å‘è¿æ¥...")

        concurrent_tasks = 10
        connection_results = []
        connection_times = []

        async def worker_task(worker_id: int) -> Dict[str, Any]:
            """å·¥ä½œçº¿ç¨‹ä»»åŠ¡"""
            start_time = time.time()

            try:
                # è·å–è¿æ¥å¹¶æ‰§è¡ŒæŸ¥è¯¢
                async with integration_connection_pool.acquire() as conn:
                    # æ¨¡æ‹Ÿå®é™…ä¸šåŠ¡æŸ¥è¯¢
                    result = await conn.fetchval(
                        "SELECT $1 as worker_id, version() as pg_version",
                        worker_id
                    )

                    # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´
                    await asyncio.sleep(0.1)

                    # æ‰§è¡Œä¸€ä¸ªç®€å•çš„å†™å…¥æ“ä½œ
                    await conn.execute(
                        """
                        INSERT INTO integration_test.test_logs (test_name, status, details)
                        VALUES ($1, $2, $3)
                        """,
                        f"concurrent_test_worker_{worker_id}",
                        "PASSED",
                        f"Worker {worker_id} completed successfully"
                    )

                end_time = time.time()
                execution_time = end_time - start_time

                return {
                    "worker_id": worker_id,
                    "success": True,
                    "execution_time": execution_time,
                    "result": result
                }

            except Exception as e:
                end_time = time.time()
                execution_time = end_time - start_time

                return {
                    "worker_id": worker_id,
                    "success": False,
                    "execution_time": execution_time,
                    "error": str(e)
                }

        # å¯åŠ¨å¹¶å‘ä»»åŠ¡
        print(f"ğŸ”„ å¯åŠ¨ {concurrent_tasks} ä¸ªå¹¶å‘è¿æ¥ä»»åŠ¡...")
        start_time = time.time()

        tasks = [worker_task(i) for i in range(concurrent_tasks)]
        connection_results = await asyncio.gather(*tasks, return_exceptions=True)

        end_time = time.time()
        total_time = end_time - start_time

        # åˆ†æç»“æœ
        successful_tasks = [r for r in connection_results if isinstance(r, dict) and r.get('success')]
        failed_tasks = [r for r in connection_results if isinstance(r, dict) and not r.get('success')]
        exceptions = [r for r in connection_results if isinstance(r, Exception)]

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        execution_times = [r['execution_time'] for r in successful_tasks]

        if execution_times:
            avg_time = statistics.mean(execution_times)
            max_time = max(execution_times)
            min_time = min(execution_times)
            median_time = statistics.median(execution_times)
        else:
            avg_time = max_time = min_time = median_time = 0

        print(f"\nğŸ“Š å¹¶å‘è¿æ¥æµ‹è¯•ç»“æœ:")
        print(f"   æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’")
        print(f"   æˆåŠŸä»»åŠ¡: {len(successful_tasks)}/{concurrent_tasks}")
        print(f"   å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}")
        print(f"   å¼‚å¸¸æ•°é‡: {len(exceptions)}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}ç§’")
        print(f"   æœ€å¤§å“åº”æ—¶é—´: {max_time:.3f}ç§’")
        print(f"   æœ€å°å“åº”æ—¶é—´: {min_time:.3f}ç§’")
        print(f"   ä¸­ä½æ•°å“åº”æ—¶é—´: {median_time:.3f}ç§’")

        # éªŒè¯æµ‹è¯•ç»“æœ
        assert len(successful_tasks) >= concurrent_tasks * 0.9, \
            f"æˆåŠŸç‡è¿‡ä½: {len(successful_tasks)}/{concurrent_tasks}"

        assert len(exceptions) == 0, f"å­˜åœ¨æœªå¤„ç†çš„å¼‚å¸¸: {exceptions}"

        if failed_tasks:
            print(f"âš ï¸ å¤±è´¥ä»»åŠ¡è¯¦æƒ…:")
            for task in failed_tasks:
                print(f"   Worker {task['worker_id']}: {task.get('error', 'Unknown error')}")

        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        async with integration_connection_pool.acquire() as conn:
            count = await conn.fetchval(
                "SELECT COUNT(*) FROM integration_test.test_logs WHERE test_name LIKE 'concurrent_test_worker_%'"
            )
            print(f"ğŸ“‹ æ•°æ®åº“è®°å½•æ•°: {count}")

            # åº”è¯¥è‡³å°‘æœ‰90%çš„è®°å½•æˆåŠŸå†™å…¥
            assert count >= concurrent_tasks * 0.9, \
                f"æ•°æ®å†™å…¥ä¸å®Œæ•´: {count}/{concurrent_tasks}"

        print("âœ… 10ä¸ªå¹¶å‘è¿æ¥ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")

    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.database
    @pytest.mark.connection_pool
    async def test_connection_pool_recovery(
        self, integration_connection_pool
    ):
        """æµ‹è¯•è¿æ¥æ± æ•…éšœæ¢å¤èƒ½åŠ›"""
        print("\nğŸ”§ æµ‹è¯•è¿æ¥æ± æ•…éšœæ¢å¤èƒ½åŠ›...")

        # æ­£å¸¸è¿æ¥æµ‹è¯•
        async with integration_connection_pool.acquire() as conn:
            result = await conn.fetchval("SELECT 'normal' as status")
            assert result == "normal", "æ­£å¸¸è¿æ¥æµ‹è¯•å¤±è´¥"

        print("âœ… æ­£å¸¸è¿æ¥å·¥ä½œæ­£å¸¸")

        # æ¨¡æ‹Ÿè¿æ¥å‹åŠ›æµ‹è¯•
        pressure_tasks = []

        async def pressure_worker(worker_id: int) -> bool:
            """å‹åŠ›æµ‹è¯•å·¥ä½œçº¿ç¨‹"""
            try:
                for i in range(5):  # æ¯ä¸ªworkeræ‰§è¡Œ5æ¬¡æ“ä½œ
                    async with integration_connection_pool.acquire() as conn:
                        await conn.fetchval(f"SELECT {worker_id * 100 + i} as test")
                        await asyncio.sleep(0.01)  # çŸ­æš‚ç­‰å¾…
                return True
            except Exception as e:
                print(f"âŒ Pressure worker {worker_id} failed: {e}")
                return False

        # å¯åŠ¨å‹åŠ›æµ‹è¯•
        print("ğŸ”„ å¯åŠ¨è¿æ¥å‹åŠ›æµ‹è¯•...")
        pressure_tasks = [pressure_worker(i) for i in range(20)]
        pressure_results = await asyncio.gather(*pressure_tasks, return_exceptions=True)

        successful_pressure = sum(1 for r in pressure_results if r is True)
        print(f"ğŸ“Š å‹åŠ›æµ‹è¯•ç»“æœ: {successful_pressure}/20 æˆåŠŸ")

        # éªŒè¯è¿æ¥æ± æ¢å¤èƒ½åŠ›
        async with integration_connection_pool.acquire() as conn:
            result = await conn.fetchval("SELECT 'recovered' as status")
            assert result == "recovered", "è¿æ¥æ± æ¢å¤æµ‹è¯•å¤±è´¥"

        print("âœ… è¿æ¥æ± æ•…éšœæ¢å¤èƒ½åŠ›æµ‹è¯•é€šè¿‡")

    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.database
    @pytest.mark.connection_pool
    async def test_connection_pool_timeout_behavior(
        self, integration_connection_pool
    ):
        """æµ‹è¯•è¿æ¥æ± è¶…æ—¶è¡Œä¸º"""
        print("\nâ±ï¸ æµ‹è¯•è¿æ¥æ± è¶…æ—¶è¡Œä¸º...")

        # åˆ›å»ºä¸´æ—¶è¿æ¥æ± ç”¨äºè¶…æ—¶æµ‹è¯•
        temp_pool = await asyncpg.create_pool(
            host="postgres-integration",
            port=5432,
            database="football_prediction_integration",
            user="integration_user",
            password="integration_password",
            min_size=1,
            max_size=2,  # é™åˆ¶è¿æ¥æ•°
            timeout=2,   # çŸ­è¶…æ—¶æ—¶é—´
            command_timeout=3
        )

        try:
            # å¿«é€Ÿè·å–è¿æ¥æµ‹è¯•
            async with temp_pool.acquire() as conn:
                result = await conn.fetchval("SELECT 'fast' as test")
                assert result == "fast", "å¿«é€Ÿè¿æ¥æµ‹è¯•å¤±è´¥"

            print("âœ… å¿«é€Ÿè¿æ¥è·å–æ­£å¸¸")

            # å¹¶å‘è¶…æ—¶æµ‹è¯•ï¼ˆåº”è¯¥è§¦å‘è¿æ¥æ± é™åˆ¶ï¼‰
            timeout_results = []

            async def timeout_task(task_id: int) -> str:
                """è¶…æ—¶æµ‹è¯•ä»»åŠ¡"""
                try:
                    async with temp_pool.acquire() as conn:
                        # æ¨¡æ‹Ÿè¾ƒé•¿æ“ä½œ
                        await asyncio.sleep(0.5)
                        await conn.fetchval(f"SELECT {task_id} as timeout_test")
                        return "success"
                except asyncio.TimeoutError:
                    return "timeout"
                except Exception as e:
                    return f"error: {e}"

            # å¯åŠ¨å¤šä¸ªå¹¶å‘ä»»åŠ¡ï¼ˆè¶…è¿‡è¿æ¥æ± å¤§å°ï¼‰
            timeout_tasks = [timeout_task(i) for i in range(5)]
            timeout_results = await asyncio.gather(*timeout_tasks, return_exceptions=True)

            success_count = sum(1 for r in timeout_results if r == "success")
            timeout_count = sum(1 for r in timeout_results if r == "timeout")

            print(f"ğŸ“Š è¶…æ—¶æµ‹è¯•ç»“æœ: {success_count} æˆåŠŸ, {timeout_count} è¶…æ—¶")

            # åº”è¯¥æœ‰ä¸€äº›æˆåŠŸï¼Œä¸€äº›è¶…æ—¶
            assert success_count > 0, "æ²¡æœ‰æˆåŠŸçš„è¿æ¥"
            assert timeout_count > 0, "æ²¡æœ‰è§¦å‘é¢„æœŸçš„è¶…æ—¶"

            print("âœ… è¿æ¥æ± è¶…æ—¶è¡Œä¸ºæµ‹è¯•é€šè¿‡")

        finally:
            await temp_pool.close()

    @pytest.mark.asyncio
    @pytest.mark.integration
    @pytest.mark.database
    @pytest.mark.connection_pool
    async def test_connection_pool_memory_usage(
        self, integration_connection_pool
    ):
        """æµ‹è¯•è¿æ¥æ± å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ’¾ æµ‹è¯•è¿æ¥æ± å†…å­˜ä½¿ç”¨...")

        import psutil
        import os

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        print(f"ğŸ“Š åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.2f} MB")

        # æ‰§è¡Œå¤§é‡æ•°æ®åº“æ“ä½œ
        operations = 100
        for i in range(operations):
            async with integration_connection_pool.acquire() as conn:
                await conn.fetchval(f"SELECT {i} as iteration")
                await conn.execute(
                    """
                    INSERT INTO integration_test.test_logs (test_name, status, details)
                    VALUES ($1, $2, $3)
                    """,
                    f"memory_test_{i}",
                    "PASSED",
                    f"Memory test iteration {i}"
                )

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory

        print(f"ğŸ“Š æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_memory:.2f} MB")
        print(f"ğŸ“Š å†…å­˜å¢é•¿: {memory_increase:.2f} MB ({operations} æ¬¡æ“ä½œ)")
        print(f"ğŸ“Š å¹³å‡æ¯æ¬¡æ“ä½œå†…å­˜å¢é•¿: {memory_increase/operations:.3f} MB")

        # éªŒè¯å†…å­˜ä½¿ç”¨åœ¨åˆç†èŒƒå›´å†…ï¼ˆæ¯æ¬¡æ“ä½œä¸åº”è¶…è¿‡0.5MBï¼‰
        avg_memory_per_operation = memory_increase / operations
        assert avg_memory_per_operation < 0.5, \
            f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {avg_memory_per_operation:.3f} MB/operation"

        print("âœ… è¿æ¥æ± å†…å­˜ä½¿ç”¨æµ‹è¯•é€šè¿‡")