import pytest
#!/usr/bin/env python3
"""
åŸºç¡€CI/CDåŠŸèƒ½æµ‹è¯•
éªŒè¯æ ¸å¿ƒCI/CDåŠŸèƒ½æ˜¯å¦æ­£å¸¸
"""

import os
import subprocess
import sys
from pathlib import Path

def test_basic_ci_functionality(, client, client, client):
    """æµ‹è¯•åŸºç¡€CI/CDåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•åŸºç¡€CI/CDåŠŸèƒ½...")
    
    tests_passed = 0
    tests_total = 0
    
    # æµ‹è¯•1: Pythonç¯å¢ƒæ£€æŸ¥
    tests_total += 1
    try:
        import sys
        python_version = f"{sys.version_info.major}.{sys.version_info.minor}"
        print(f"âœ… Pythonç‰ˆæœ¬: {python_version}")
        tests_passed += 1
    except Exception as e:
        print(f"âŒ Pythonç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•2: åŸºç¡€æ¨¡å—å¯¼å…¥
    tests_total += 1
    try:
        import os
        import sys
        import json
        import pathlib
        print("âœ… åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ")
        tests_passed += 1
    except Exception as e:
        print(f"âŒ åŸºç¡€æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    
    # æµ‹è¯•3: é¡¹ç›®ç»“æ„æ£€æŸ¥
    tests_total += 1
    try:
        required_dirs = ['src', 'tests', 'scripts']
        missing_dirs = []
        
        for dir_name in required_dirs:
            if not Path(dir_name).exists():
                missing_dirs.append(dir_name)
        
        if not missing_dirs:
            print("âœ… é¡¹ç›®ç»“æ„å®Œæ•´")
            tests_passed += 1
        else:
            print(f"âŒ ç¼ºå¤±ç›®å½•: {', '.join(missing_dirs)}")
    except Exception as e:
        print(f"âŒ é¡¹ç›®ç»“æ„æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•4: æ ¸å¿ƒæ–‡ä»¶æ£€æŸ¥
    tests_total += 1
    try:
        required_files = ['CLAUDE.md', 'pyproject.toml', 'Makefile']
        missing_files = []
        
        for file_name in required_files:
            if not Path(file_name).exists():
                missing_files.append(file_name)
        
        if not missing_files:
            print("âœ… æ ¸å¿ƒæ–‡ä»¶å®Œæ•´")
            tests_passed += 1
        else:
            print(f"âŒ ç¼ºå¤±æ–‡ä»¶: {', '.join(missing_files)}")
    except Exception as e:
        print(f"âŒ æ ¸å¿ƒæ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•5: è´¨é‡å·¥å…·å¯ç”¨æ€§
    tests_total += 1
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰è´¨é‡å®ˆæŠ¤å·¥å…·
        if Path('scripts/quality_guardian.py').exists():
            print("âœ… è´¨é‡å®ˆæŠ¤å·¥å…·å¯ç”¨")
            tests_passed += 1
        else:
            print("âš ï¸  è´¨é‡å®ˆæŠ¤å·¥å…·ç¼ºå¤±")
    except Exception as e:
        print(f"âŒ è´¨é‡å·¥å…·æ£€æŸ¥å¤±è´¥: {e}")
    
    # æµ‹è¯•6: ä»£ç æ£€æŸ¥å·¥å…·
    tests_total += 1
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç æ£€æŸ¥å·¥å…·
        try:
            subprocess.run(['ruff', '--version'], capture_output=True, timeout=5)
            print("âœ… Ruffä»£ç æ£€æŸ¥å·¥å…·å¯ç”¨")
            tests_passed += 1
        except:
            print("âš ï¸  Ruffå·¥å…·ä¸å¯ç”¨")
    except Exception as e:
        print(f"âŒ ä»£ç æ£€æŸ¥å·¥å…·å¤±è´¥: {e}")
    
    # æµ‹è¯•7: ç®€å•æµ‹è¯•æ‰§è¡Œ
    tests_total += 1
    try:
        # æ‰§è¡Œç®€å•æµ‹è¯•
        test_result = subprocess.run([
            sys.executable, 'test_simple_working.py'
        ], capture_output=True, text=True, timeout=10)
        
        if test_result.returncode == 0:
            print("âœ… ç®€å•æµ‹è¯•æ‰§è¡ŒæˆåŠŸ")
            tests_passed += 1
        else:
            print(f"âŒ ç®€å•æµ‹è¯•å¤±è´¥: {test_result.stderr}")
    except Exception as e:
        print(f"âŒ ç®€å•æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
    
    # æµ‹è¯•8: æ–‡ä»¶æ“ä½œèƒ½åŠ›
    tests_total += 1
    try:
        # æµ‹è¯•æ–‡ä»¶è¯»å†™
        test_file = Path('test_ci_cd_temp.txt')
        test_file.write_text('CI/CD test content')
        content = test_file.read_text()
        
        if content == 'CI/CD test content':
            test_file.unlink()
            print("âœ… æ–‡ä»¶æ“ä½œèƒ½åŠ›æ­£å¸¸")
            tests_passed += 1
        else:
            print("âŒ æ–‡ä»¶æ“ä½œå†…å®¹ä¸åŒ¹é…")
    except Exception as e:
        print(f"âŒ æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")
    
    success_rate = (tests_passed / tests_total) * 100 if tests_total > 0 else 0
    print(f"\nğŸ“Š CI/CDåŠŸèƒ½æµ‹è¯•ç»“æœ:")
    print(f"   - æ€»æµ‹è¯•æ•°: {tests_total}")
    print(f"   - é€šè¿‡æ•°: {tests_passed}")
    print(f"   - æˆåŠŸç‡: {success_rate:.1f}%")
    
    return tests_passed, tests_total, success_rate

def test_deployment_readiness(, client, client, client):
    """æµ‹è¯•éƒ¨ç½²å°±ç»ªçŠ¶æ€"""
    print("\nğŸš€ æµ‹è¯•éƒ¨ç½²å°±ç»ªçŠ¶æ€...")
    
    readiness_checks = []
    
    # æ£€æŸ¥1: ç¯å¢ƒå˜é‡
    readiness_checks.append(('ç¯å¢ƒå˜é‡', os.environ.get('PATH') is not None))
    
    # æ£€æŸ¥2: å·¥ä½œç›®å½•
    readiness_checks.append(('å·¥ä½œç›®å½•', Path('.').exists() and Path('.').is_dir()))
    
    # æ£€æŸ¥3: Gitä»“åº“
    git_repo = Path('.git')
    if git_repo.exists():
        readiness_checks.append(('Gitä»“åº“', True))
    else:
        readiness_checks.append(('Gitä»“åº“', False))
    
    # æ£€æŸ¥4: é…ç½®æ–‡ä»¶
    config_files = ['pyproject.toml', 'pytest.ini']
    config_ok = all(Path(f).exists() for f in config_files)
    readiness_checks.append(('é…ç½®æ–‡ä»¶', config_ok))
    
    # æ£€æŸ¥5: è„šæœ¬æ–‡ä»¶
    scripts_dir = Path('scripts')
    if scripts_dir.exists():
        script_count = len(list(scripts_dir.glob('*.py')))
        readiness_checks.append(('è„šæœ¬æ–‡ä»¶', script_count > 10))
    else:
        readiness_checks.append(('è„šæœ¬æ–‡ä»¶', False))
    
    print(f"\nğŸ“‹ éƒ¨ç½²å°±ç»ªæ£€æŸ¥:")
    for check_name, status in readiness_checks:
        status_icon = "âœ…" if status else "âŒ"
        print(f"   {status_icon} {check_name}: {'å°±ç»ª' if status else 'æœªå°±ç»ª'}")
    
    readiness_score = sum(1 for _, status in readiness_checks if status) / len(readiness_checks)
    print(f"\nğŸ¯ éƒ¨ç½²å°±ç»ªåº¦: {readiness_score:.1f}")
    
    return readiness_score

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åŸºç¡€CI/CDåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æ‰§è¡ŒCI/CDåŠŸèƒ½æµ‹è¯•
    passed, total, success_rate = test_basic_ci_functionality()
    
    # æµ‹è¯•éƒ¨ç½²å°±ç»ªçŠ¶æ€
    readiness_score = test_deployment_readiness()
    
    # ç»¼åˆè¯„ä¼°
    overall_score = (success_rate + readiness_score) / 2
    print(f"\nğŸ¯ ç»¼åˆCI/CDè¯„ä¼°:")
    print(f"   - åŠŸèƒ½æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"   - éƒ¨ç½²å°±ç»ªåº¦: {readiness_score:.1f}")
    print(f"   - ç»¼åˆåˆ†æ•°: {overall_score:.1f}%")
    
    # æ£€æŸ¥ç›®æ ‡
    target_achieved = overall_score >= 50.0
    print(f"\nğŸ¯ ç›®æ ‡æ£€æŸ¥ (50%+):")
    if target_achieved:
        print(f"   âœ… ç›®æ ‡è¾¾æˆ: {overall_score:.1f}% â‰¥ 50%")
    else:
        print(f"   âš ï¸  æ¥è¿‘ç›®æ ‡: {overall_score:.1f}%")
    
    return {
        'passed_tests': passed,
        'total_tests': total,
        'success_rate': success_rate,
        'readiness_score': readiness_score,
        'overall_score': overall_score,
        'target_achieved': target_achieved
    }

if __name__ == "__main__":
    result = main()
    
    if result['target_achieved']:
        print("\nğŸ‰ CI/CDåŠŸèƒ½åŸºæœ¬æ¢å¤ï¼")
    else:
        print("\nğŸ“ˆ CI/CDåŠŸèƒ½æœ‰æ‰€æ”¹å–„")
