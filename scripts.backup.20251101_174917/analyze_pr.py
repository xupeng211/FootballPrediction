#!/usr/bin/env python3
"""
PR Analysis Script
Pull Requeståˆ†æå’Œå®¡æŸ¥è„šæœ¬
"""

import json
import os
import re
import subprocess
import sys
from typing import Dict, List, Any, Optional

class PRAnalyzer:
    def __init__(self, pr_number: int, repo: str, token: str):
        self.pr_number = pr_number
        self.repo = repo
        self.token = token
        self.base_url = "https://api.github.com"

    def get_pr_details(self) -> Dict[str, Any]:
        """è·å–PRè¯¦æƒ…"""
        import requests

        headers = {
            "Authorization": f"token {self.token}",
            "Accept": "application/vnd.github.v3+json"
        }

        url = f"{self.base_url}/repos/{self.repo}/pulls/{self.pr_number}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()

        return response.json()

    def get_pr_files(self) -> List[Dict[str, Any]]:
        """è·å–PRæ–‡ä»¶åˆ—è¡¨"""
        import requests

        headers = {
            "Authorization": f"token {self.token}",
            "Accept": "application/vnd.github.v3+json"
        }

        url = f"{self.base_url}/repos/{self.repo}/pulls/{self.pr_number}/files"
        response = requests.get(url, headers=headers)
        response.raise_for_status()

        return response.json()

    def analyze_code_complexity(self, files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        complexity_score = 0
        risk_level = "Low"
        suggestions = []

        file_types = {}
        total_lines_added = 0
        total_lines_deleted = 0

        for file in files:
            filename = file['filename']
            additions = file.get('additions', 0)
            deletions = file.get('deletions', 0)
            changes = file.get('changes', 0)

            # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
            ext = os.path.splitext(filename)[1].lower()
            file_types[ext] = file_types.get(ext, 0) + 1

            total_lines_added += additions
            total_lines_deleted += deletions

            # åˆ†æå•ä¸ªæ–‡ä»¶çš„å¤æ‚åº¦
            if ext in ['.py']:
                # Pythonæ–‡ä»¶ç‰¹æ®Šå¤„ç†
                if additions > 100:
                    complexity_score += 2
                    suggestions.append(f"Large Python file changed: {filename} ({additions} lines added)")
                elif additions > 50:
                    complexity_score += 1

                # æ£€æŸ¥æ˜¯å¦æ¶‰åŠå¤æ‚é€»è¾‘
                if filename.endswith('.py'):
                    try:
                        # å°è¯•åˆ†æPythonæ–‡ä»¶çš„å¤æ‚æ€§æŒ‡æ ‡
                        self._analyze_python_file(filename, complexity_score, suggestions)
                        pass

            # æ£€æŸ¥é…ç½®æ–‡ä»¶å˜æ›´
            if ext in ['.yml', '.yaml', '.json']:
                if changes > 50:
                    complexity_score += 1
                    suggestions.append(f"Large configuration change: {filename}")

            # æ£€æŸ¥æ–‡æ¡£å˜æ›´
            if ext in ['.md', '.rst']:
                if additions > 200:
                    suggestions.append(f"Large documentation update: {filename}")

        # è®¡ç®—é£é™©çº§åˆ«
        if total_lines_added > 500:
            risk_level = "High"
        elif total_lines_added > 200:
            risk_level = "Medium"

        # ç‰¹æ®Šæ–‡ä»¶ç±»å‹é£é™©
        high_risk_files = ['.sql', 'migrations/', 'requirements.txt', 'Dockerfile']
        for file in files:
            if any(risk_file in file['filename'] for risk_file in high_risk_files):
                if risk_level == "Low":
                    risk_level = "Medium"
                complexity_score += 1

        return {
            "score": min(10, complexity_score),
            "risk": risk_level,
            "suggestions": suggestions,
            "file_types": file_types,
            "lines_added": total_lines_added,
            "lines_deleted": total_lines_deleted
        }

    def _analyze_python_file(self, filename: str, current_score: int, suggestions: List[str]):
        """åˆ†æPythonæ–‡ä»¶çš„å¤æ‚åº¦"""
        try:
            # å°è¯•åˆ†ææ–‡ä»¶å†…å®¹
            with open(filename, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ£€æŸ¥å¤æ‚çš„ä»£ç æ¨¡å¼
            patterns = {
                r'class\s+\w+.*\n.*def\s+__init__': "Complex class definition",
                r'def\s+\w+.*\(.*\*.*\).*:': "Function with variable arguments",
                r'@.*\n.*def\s+\w+': "Decorated function",
                r'async\s+def\s+\w+': "Async function",
                r'try:\s*\n.*except.*:\s*\n.*finally:': "Complex exception handling",
                r'for.*in.*:\s*\n.*for.*in.*:': "Nested loops",
                r'if.*:\s*\n.*if.*:\s*\n.*if.*:': "Deeply nested conditions"
            }

            for pattern, description in patterns.items():
                matches = len(re.findall(pattern, content))
                if matches > 0:
                    suggestions.append(f"{description} in {filename} ({matches} occurrences)")

            # æ£€æŸ¥ä»£ç é•¿åº¦
            lines = content.split('\n')
            if len(lines) > 200:
                suggestions.append(f"Very long file: {filename} ({len(lines)} lines)")

        except Exception as e:
            print(f"Warning: Could not analyze {filename}: {e}")

    def check_for_common_issues(self, files: List[Dict[str, Any]]) -> List[str]:
        """æ£€æŸ¥å¸¸è§é—®é¢˜"""
        issues = []

        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ–‡ä»¶
        has_tests = any('test_' in f['filename'] or '/tests/' in f['filename'] for f in files)
        if not has_tests:
            issues.append("No test files included in this PR")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£æ›´æ–°
        has_docs = any(f['filename'].endswith('.md') for f in files)
        if not has_docs:
            issues.append("Consider updating documentation for new features")

        # æ£€æŸ¥æ˜¯å¦æœ‰é…ç½®æ–‡ä»¶å˜æ›´
        has_config = any(f['filename'].endswith(('.yml', '.yaml', '.ini', '.toml')) for f in files)
        if has_config:
            issues.append("Configuration files changed - please verify changes")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®åº“è¿ç§»
        has_migrations = any('migration' in f['filename'].lower() for f in files)
        if has_migrations:
            issues.append("Database migrations included - ensure backward compatibility")

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–æ›´æ–°
        has_deps = any(f['filename'] in ['requirements.txt', 'pyproject.toml', 'Pipfile'] for f in files)
        if has_deps:
            issues.append("Dependencies updated - please test compatibility")

        return issues

    def generate_review_summary(self, pr_details: Dict[str, Any], files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆå®¡æŸ¥æ‘˜è¦"""
        complexity = self.analyze_code_complexity(files)
        issues = self.check_for_common_issues(files)

        return {
            "pr_number": self.pr_number,
            "title": pr_details.get('title', ''),
            "author": pr_details.get('user', {}).get('login', ''),
            "description": pr_details.get('body', '')[:200] + '...' if len(pr_details.get('body', '')) > 200 else pr_details.get('body', ''),
            "files_count": len(files),
            "additions": pr_details.get('additions', 0),
            "deletions": pr_details.get('deletions', 0),
            "changed_files": pr_details.get('changed_files', 0),
            "complexity": complexity,
            "issues": issues,
            "mergeable": pr_details.get('mergeable', False),
            "draft": pr_details.get('draft', False)
        }

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='Analyze Pull Request')
    parser.add_argument('--pr-number', type=int, required=True, help='PR number')
    parser.add_argument('--repo', type=str, required=True, help='Repository name')
    parser.add_argument('--token', type=str, required=True, help='GitHub token')

    args = parser.parse_args()

    try:
        analyzer = PRAnalyzer(args.pr_number, args.repo, args.token)

        print(f"ğŸ” Analyzing PR #{args.pr_number} in {args.repo}...")

        # è·å–PRè¯¦æƒ…
        pr_details = analyzer.get_pr_details()
        print(f"ğŸ“‹ Title: {pr_details.get('title', '')}")
        print(f"ğŸ‘¤ Author: {pr_details.get('user', {}).get('login', '')}")
        print(f"ğŸ“Š Changed files: {pr_details.get('changed_files', 0)}")

        # è·å–æ–‡ä»¶åˆ—è¡¨
        files = analyzer.get_pr_files()
        print(f"ğŸ“ Files analyzed: {len(files)}")

        # ç”Ÿæˆå®¡æŸ¥æ‘˜è¦
        summary = analyzer.generate_review_summary(pr_details, files)

        # ä¿å­˜åˆ†æç»“æœ
        with open('pr_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2)

        print("âœ… Analysis completed. Results saved to pr_analysis.json")

        # è¾“å‡ºå…³é”®ä¿¡æ¯
        print(f"\nğŸ“Š Complexity Score: {summary['complexity']['score']}/10")
        print(f"âš ï¸  Risk Level: {summary['complexity']['risk']}")
        print(f"ğŸ“ Issues Found: {len(summary['issues'])}")

        if summary['issues']:
            print("\nğŸ” Issues to address:")
            for issue in summary['issues']:
                print(f"  â€¢ {issue}")

        if summary['complexity']['suggestions']:
            print("\nğŸ’¡ Suggestions:")
            for suggestion in summary['complexity']['suggestions'][:5]:
                print(f"  â€¢ {suggestion}")

    except Exception as e:
        print(f"âŒ Error analyzing PR: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()