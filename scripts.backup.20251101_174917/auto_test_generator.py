#!/usr/bin/env python3
"""
ğŸ¤– Auto Test Generator
è‡ªåŠ¨åŒ–æµ‹è¯•ç”Ÿæˆå™¨ - Phase Gæ ¸å¿ƒç»„ä»¶

åŸºäºæ™ºèƒ½åˆ†æçš„æµ‹è¯•ç¼ºå£ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ä»£ç 
æ”¯æŒè¾¹ç•Œæ¡ä»¶ã€å¼‚å¸¸å¤„ç†ã€æ€§èƒ½æµ‹è¯•ç­‰å¤šç§æµ‹è¯•ç±»å‹
"""

import ast
import json
import os
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from jinja2 import Template

@dataclass
class TestGenerationConfig:
    """æµ‹è¯•ç”Ÿæˆé…ç½®"""
    output_dir: str = "tests/generated"
    template_dir: str = "scripts/templates"
    include_performance_tests: bool = True
    include_boundary_tests: bool = True
    include_exception_tests: bool = True
    max_test_cases_per_function: int = 10

class AutoTestGenerator:
    """è‡ªåŠ¨åŒ–æµ‹è¯•ç”Ÿæˆå™¨"""

    def __init__(self, config: Optional[TestGenerationConfig] = None):
        self.config = config or TestGenerationConfig()
        self.output_dir = Path(self.config.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_tests_from_analysis(self, analysis_report: Dict) -> Dict:
        """åŸºäºåˆ†ææŠ¥å‘Šç”Ÿæˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–æµ‹è¯•ç”Ÿæˆ...")

        generation_results = {
            'generated_files': [],
            'generated_test_cases': 0,
            'generation_errors': [],
            'by_module': {}
        }

        # æŒ‰æ¨¡å—ç»„ç»‡æµ‹è¯•ç”Ÿæˆ
        gaps_by_module = analysis_report.get('gaps_by_module', {})

        for module_name, gaps in gaps_by_module.items():
            if not gaps:
                continue

            print(f"ğŸ“ ä¸ºæ¨¡å— {module_name} ç”Ÿæˆæµ‹è¯•...")

            module_result = self._generate_module_tests(module_name, gaps)
            generation_results['by_module'][module_name] = module_result
            generation_results['generated_files'].extend(module_result['files'])
            generation_results['generated_test_cases'] += module_result['test_cases']

        # ç”Ÿæˆæµ‹è¯•ç´¢å¼•æ–‡ä»¶
        self._generate_test_index(generation_results)

        print("âœ… æµ‹è¯•ç”Ÿæˆå®Œæˆ:")
        print(f"   ç”Ÿæˆæ–‡ä»¶: {len(generation_results['generated_files'])}")
        print(f"   ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {generation_results['generated_test_cases']}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")

        return generation_results

    def _generate_module_tests(self, module_name: str, gaps: List[Dict]) -> Dict:
        """ä¸ºå•ä¸ªæ¨¡å—ç”Ÿæˆæµ‹è¯•"""
        module_result = {
            'files': [],
            'test_cases': 0,
            'errors': []
        }

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        gaps.sort(key=lambda x: (x.get('priority', 1), x.get('complexity', 1)), reverse=True)

        # ç”Ÿæˆæµ‹è¯•æ–‡ä»¶å†…å®¹
        test_content = self._generate_test_file_content(module_name, gaps)

        # ç¡®å®šæ–‡ä»¶å
        safe_module_name = module_name.replace('/', '_').replace('\\', '_')
        test_file_name = f"test_{safe_module_name}_generated.py"
        test_file_path = self.output_dir / test_file_name

        try:
            # å†™å…¥æµ‹è¯•æ–‡ä»¶
            with open(test_file_path, 'w', encoding='utf-8') as f:
                f.write(test_content)

            module_result['files'].append(str(test_file_path))
            module_result['test_cases'] = len([gap for gap in gaps])

            print(f"   âœ… ç”Ÿæˆ {test_file_name} ({len(gaps)} ä¸ªæµ‹è¯•)")

        except Exception as e:
            error_msg = f"ç”Ÿæˆæµ‹è¯•æ–‡ä»¶å¤±è´¥ {test_file_name}: {e}"
            module_result['errors'].append(error_msg)
            print(f"   âŒ {error_msg}")

        return module_result

    def _generate_test_file_content(self, module_name: str, gaps: List[Dict]) -> str:
        """ç”Ÿæˆæµ‹è¯•æ–‡ä»¶å†…å®¹"""

        # æ–‡ä»¶å¤´éƒ¨
        header = self._generate_file_header(module_name)

        # å¯¼å…¥è¯­å¥
        imports = self._generate_imports(gaps)

        # æµ‹è¯•ç±»å®šä¹‰
        test_classes = self._generate_test_classes(gaps)

        # ç»„åˆå®Œæ•´å†…å®¹
        content = f"{header}\n\n{imports}\n\n{test_classes}"

        return content

    def _generate_file_header(self, module_name: str) -> str:
        """ç”Ÿæˆæ–‡ä»¶å¤´éƒ¨æ³¨é‡Š"""
        return f'''"""
ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶
æ¨¡å—: {module_name}
ç”Ÿæˆæ—¶é—´: {self._get_current_time()}
ç”Ÿæˆå™¨: AutoTest Generator (Phase G)

âš ï¸  è¿™æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶ï¼Œè¯·æ ¹æ®éœ€è¦è°ƒæ•´å’Œå®Œå–„
"""

import pytest
import asyncio
from unittest.mock import Mock, patch, MagicMock
from typing import Dict, List, Any, Optional
import tempfile
import os'''

    def _generate_imports(self, gaps: List[Dict]) -> str:
        """ç”Ÿæˆå¯¼å…¥è¯­å¥"""
        imports = []

        # æ”¶é›†æ‰€æœ‰éœ€è¦å¯¼å…¥çš„æ¨¡å—
        modules_to_import = set()
        for gap in gaps:
            file_path = gap.get('file_path', '')
            if file_path and file_path.startswith('src/'):
                # è½¬æ¢æ–‡ä»¶è·¯å¾„ä¸ºPythonæ¨¡å—è·¯å¾„
                module_path = file_path.replace('.py', '').replace('/', '.')
                modules_to_import.add(module_path)

        # ç”Ÿæˆå¯¼å…¥è¯­å¥
        if modules_to_import:
            imports.extend(["try:" for _ in modules_to_import])
            for module in sorted(modules_to_import):
                imports.append(f"    from {module} import *")
            imports.extend(["except ImportError:" for _ in modules_to_import])
            imports.extend(["    pass" for _ in modules_to_import])

        return '\n'.join(imports)

    def _generate_test_classes(self, gaps: List[Dict]) -> str:
        """ç”Ÿæˆæµ‹è¯•ç±»"""
        test_classes = []

        # æŒ‰åŠŸèƒ½åŸŸåˆ†ç»„
        gaps_by_domain = self._group_gaps_by_domain(gaps)

        for domain, domain_gaps in gaps_by_domain.items():
            class_name = f"Test{domain.title().replace('_', '')}Generated"
            test_class = self._generate_test_class(class_name, domain_gaps)
            test_classes.append(test_class)

        return '\n\n'.join(test_classes)

    def _group_gaps_by_domain(self, gaps: List[Dict]) -> Dict[str, List[Dict]]:
        """æŒ‰åŠŸèƒ½åŸŸåˆ†ç»„æµ‹è¯•ç¼ºå£"""
        domains = {}

        for gap in gaps:
            function_name = gap.get('function_name', '')

            # æ ¹æ®å‡½æ•°åç¡®å®šåŠŸèƒ½åŸŸ
            if any(keyword in function_name.lower() for keyword in ['predict', 'forecast', 'estimate']):
                domain = 'prediction'
            elif any(keyword in function_name.lower() for keyword in ['parse', 'load', 'save', 'export', 'import']):
                domain = 'data_processing'
            elif any(keyword in function_name.lower() for keyword in ['validate', 'check', 'verify', 'ensure']):
                domain = 'validation'
            elif any(keyword in function_name.lower() for keyword in ['calculate', 'compute', 'process']):
                domain = 'calculation'
            elif any(keyword in function_name.lower() for keyword in ['get', 'fetch', 'retrieve', 'find']):
                domain = 'retrieval'
            else:
                domain = 'general'

            if domain not in domains:
                domains[domain] = []
            domains[domain].append(gap)

        return domains

    def _generate_test_class(self, class_name: str, gaps: List[Dict]) -> str:
        """ç”Ÿæˆå•ä¸ªæµ‹è¯•ç±»"""
        class_header = f"""@pytest.mark.generated
@pytest.mark.unit
class {class_name}:
    \"\"\"
    ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•ç±»

    åŠŸèƒ½åŸŸ: {gaps[0].get('file_path', 'unknown') if gaps else 'unknown'}
    æµ‹è¯•æ•°é‡: {len(gaps)}
    \"\"\"
"""

        methods = []
        for gap in gaps:
            function_name = gap.get('function_name', 'unknown_function')
            test_methods = self._generate_test_methods(function_name, gap)
            methods.extend(test_methods)

        return f"{class_header}\n\n" + "\n\n".join(methods)

    def _generate_test_methods(self, function_name: str, gap: Dict) -> List[str]:
        """ä¸ºå•ä¸ªå‡½æ•°ç”Ÿæˆæµ‹è¯•æ–¹æ³•"""
        methods = []
        suggested_tests = gap.get('suggested_tests', [])

        for i, test_suggestion in enumerate(suggested_tests):
            test_type = test_suggestion.get('type', 'basic')
            test_cases = test_suggestion.get('test_cases', [])

            if test_type == 'basic_functionality':
                methods.append(self._generate_basic_test_method(function_name, test_cases, i))
            elif test_type == 'boundary_conditions':
                methods.append(self._generate_boundary_test_method(function_name, test_cases, i))
            elif test_type == 'exception_handling':
                methods.append(self._generate_exception_test_method(function_name, test_cases, i))
            elif test_type == 'performance':
                methods.append(self._generate_performance_test_method(function_name, test_cases, i))

        return methods

    def _generate_basic_test_method(self, function_name: str, test_cases: List[Dict], index: int) -> str:
        """ç”ŸæˆåŸºç¡€åŠŸèƒ½æµ‹è¯•æ–¹æ³•"""
        method_name = f"test_{function_name}_basic_functionality_{index}"

        method_template = f'''    def {method_name}(self):
        """ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„åŸºç¡€åŠŸèƒ½æµ‹è¯•

        æµ‹è¯•ç›®æ ‡: {function_name}
        æµ‹è¯•ç±»å‹: åŸºç¡€åŠŸèƒ½éªŒè¯
        """
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_inputs = self._prepare_test_inputs_for_{function_name}()
        expected_output = self._get_expected_output_for_{function_name}()

        try:
            # æ‰§è¡Œæµ‹è¯•
            result = {function_name}(**test_inputs)

            # åŸºæœ¬æ–­è¨€
            assert result is not None, f"{{function_name}} ä¸åº”è¿”å› None"
            print(f"âœ… {{function_name}} åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡: {{result}}")

        except ImportError:
            pytest.skip(f"{{function_name}} æ¨¡å—ä¸å¯ç”¨")
        except Exception as e:
            pytest.fail(f"{{function_name}} åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {{e}}")

    def _prepare_test_inputs_for_{function_name}(self) -> Dict[str, Any]:
        """ä¸º {function_name} å‡†å¤‡æµ‹è¯•è¾“å…¥æ•°æ®"""
        return {{
            # TODO: æ ¹æ®å®é™…å‡½æ•°ç­¾åè°ƒæ•´æµ‹è¯•æ•°æ®
            'param1': 'test_value_1',
            'param2': 'test_value_2',
            'param3': True,
        }}

    def _get_expected_output_for_{function_name}(self) -> Any:
        """è·å– {function_name} çš„æœŸæœ›è¾“å‡º"""
        # TODO: æ ¹æ®å®é™…å‡½æ•°é€»è¾‘è°ƒæ•´æœŸæœ›å€¼
        return "expected_result"'''

        return method_template

    def _generate_boundary_test_method(self, function_name: str, test_cases: List[Dict], index: int) -> str:
        """ç”Ÿæˆè¾¹ç•Œæ¡ä»¶æµ‹è¯•æ–¹æ³•"""
        method_name = f"test_{function_name}_boundary_conditions_{index}"

        method_template = f'''    def {method_name}(self):
        """ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„è¾¹ç•Œæ¡ä»¶æµ‹è¯•

        æµ‹è¯•ç›®æ ‡: {function_name}
        æµ‹è¯•ç±»å‹: è¾¹ç•Œæ¡ä»¶éªŒè¯
        """
        boundary_test_cases = [
            # ç©ºå€¼æµ‹è¯•
            {{'input': None, 'expected': 'appropriate_handling'}},
            # æå°å€¼æµ‹è¯•
            {{'input': 0, 'expected': 'appropriate_handling'}},
            # æå¤§å€¼æµ‹è¯•
            {{'input': 999999, 'expected': 'appropriate_handling'}},
            # ç©ºå­—ç¬¦ä¸²æµ‹è¯•
            {{'input': '', 'expected': 'appropriate_handling'}},
            # è´Ÿå€¼æµ‹è¯•
            {{'input': -1, 'expected': 'appropriate_handling'}},
        ]

        for i, test_case in enumerate(boundary_test_cases):
            with pytest.subTest(test_case=i, input=test_case['input']):
                try:
                    result = {function_name}(test_case['input'])

                    # æ ¹æ®æœŸæœ›ç»“æœè¿›è¡Œæ–­è¨€
                    if test_case['expected'] == 'appropriate_handling':
                        assert result is not None, "è¾¹ç•Œæ¡ä»¶å¤„ç†ä¸å½“: è¾“å…¥ {{test_case['input']}}"

                    print("âœ… è¾¹ç•Œæ¡ä»¶æµ‹è¯•é€šè¿‡: è¾“å…¥ {{test_case['input']}} -> ç»“æœ {{result}}")

                except Exception as e:
                    if test_case['expected'] == 'appropriate_exception':
                        print("âœ… æœŸæœ›çš„å¼‚å¸¸: {{e}}")
                    else:
                        pytest.fail("è¾¹ç•Œæ¡ä»¶æµ‹è¯•å¤±è´¥: è¾“å…¥ {{test_case['input']}}, å¼‚å¸¸ {{e}}")'''

        return method_template

    def _generate_exception_test_method(self, function_name: str, test_cases: List[Dict], index: int) -> str:
        """ç”Ÿæˆå¼‚å¸¸å¤„ç†æµ‹è¯•æ–¹æ³•"""
        method_name = f"test_{function_name}_exception_handling_{index}"

        method_template = f'''    def {method_name}(self):
        """ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„å¼‚å¸¸å¤„ç†æµ‹è¯•

        æµ‹è¯•ç›®æ ‡: {function_name}
        æµ‹è¯•ç±»å‹: å¼‚å¸¸å¤„ç†éªŒè¯
        """
        exception_test_cases = [
            # æ— æ•ˆç±»å‹è¾“å…¥
            {{'input': {{'type': 'invalid_type', 'value': [{{}}]}}, 'expected_exception': (TypeError, ValueError)}},
            # ç¼ºå°‘å¿…éœ€å‚æ•°
            {{'input': {{}}, 'expected_exception': (TypeError, ValueError)}},
            # æ ¼å¼é”™è¯¯è¾“å…¥
            {{'input': 'invalid_format_string', 'expected_exception': ValueError}},
            # æƒé™ä¸è¶³
            {{'input': {{'user_id': None, 'action': 'admin_only'}}, 'expected_exception': PermissionError}},
        ]

        for i, test_case in enumerate(exception_test_cases):
            with pytest.subTest(test_case=i, description=test_case.get('description', 'exception test')):
                expected_exceptions = test_case['expected_exception']

                # æ£€æŸ¥æ˜¯å¦æŠ›å‡ºæœŸæœ›çš„å¼‚å¸¸
                with pytest.raises(expected_exceptions):
                    try:
                        {function_name}(test_case['input'])
                    except ImportError:
                        pytest.skip(f"{{function_name}} æ¨¡å—ä¸å¯ç”¨")

                print(f"âœ… å¼‚å¸¸å¤„ç†æµ‹è¯•é€šè¿‡: {{test_case.get('description', 'exception test')}}")'''

        return method_template

    def _generate_performance_test_method(self, function_name: str, test_cases: List[Dict], index: int) -> str:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æ–¹æ³•"""
        method_name = f"test_{function_name}_performance_{index}"

        method_template = f'''    def {method_name}(self):
        """ğŸ¤– è‡ªåŠ¨ç”Ÿæˆçš„æ€§èƒ½æµ‹è¯•

        æµ‹è¯•ç›®æ ‡: {function_name}
        æµ‹è¯•ç±»å‹: æ€§èƒ½åŸºå‡†éªŒè¯
        """
        import time
        import psutil
        import os

        # å‡†å¤‡æ€§èƒ½æµ‹è¯•æ•°æ®
        performance_inputs = self._prepare_performance_inputs_for_{function_name}()

        try:
            # æ‰§è¡Œæ—¶é—´æµ‹è¯•
            start_time = time.time()
            result = {function_name}(**performance_inputs)
            execution_time = time.time() - start_time

            # æ€§èƒ½æ–­è¨€
            assert execution_time < 1.0, f"æ‰§è¡Œæ—¶é—´è¿‡é•¿: {{execution_time:.3f}}ç§’"

            # å†…å­˜ä½¿ç”¨æµ‹è¯•
            process = psutil.Process(os.getpid())
            memory_usage = process.memory_info().rss / 1024 / 1024  # MB

            # åŸºæœ¬ç»“æœéªŒè¯
            assert result is not None, "æ€§èƒ½æµ‹è¯•ä¸­å‡½æ•°è¿”å›äº†None"

            print(f"âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡:")
            print(f"   æ‰§è¡Œæ—¶é—´: {{execution_time:.3f}}ç§’")
            print(f"   å†…å­˜ä½¿ç”¨: {{memory_usage:.2f}}MB")
            print(f"   æµ‹è¯•ç»“æœ: {{result}}")

        except ImportError:
            pytest.skip(f"{{function_name}} æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        except Exception as e:
            pytest.fail(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {{e}}")

    def _prepare_performance_inputs_for_{function_name}(self) -> Dict[str, Any]:
        """ä¸º {function_name} å‡†å¤‡æ€§èƒ½æµ‹è¯•æ•°æ®"""
        return {{
            # ä½¿ç”¨ç›¸å¯¹è¾ƒå¤§çš„æ•°æ®é›†è¿›è¡Œæ€§èƒ½æµ‹è¯•
            'large_dataset': list(range(1000)),
            'complex_config': {{
                'option1': True,
                'option2': False,
                'nested': {{
                    'level1': {{'level2': [1, 2, 3, 4, 5]}}
                }}
            }}
        }}'''

        return method_template

    def _generate_test_index(self, generation_results: Dict):
        """ç”Ÿæˆæµ‹è¯•ç´¢å¼•æ–‡ä»¶"""
        index_content = f'''"""
ğŸ¤– è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç´¢å¼•
ç”Ÿæˆæ—¶é—´: {self._get_current_time()}

æœ¬æ–‡ä»¶åŒ…å«æ‰€æœ‰è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶çš„ç´¢å¼•ä¿¡æ¯
"""

AUTO_GENERATED_TESTS_INDEX = {{
    "generation_summary": {{
        "total_files": {len(generation_results['generated_files'])},
        "total_test_cases": {generation_results['generated_test_cases']},
        "generation_time": "{self._get_current_time()}"
    }},
    "generated_files": {generation_results['generated_files']},
    "by_module": {{
'''

        # æ·»åŠ æ¨¡å—ä¿¡æ¯
        for module_name, module_result in generation_results['by_module'].items():
            index_content += f'''
        "{module_name}": {{
            "files": {module_result['files']},
            "test_cases": {module_result['test_cases']},
            "errors": {module_result['errors']}
        }},'''

        index_content += '''
    }
}

# ä½¿ç”¨ç¤ºä¾‹:
# from test_index import AUTO_GENERATED_TESTS_INDEX
# print(f"ç”Ÿæˆäº† {AUTO_GENERATED_TESTS_INDEX['generation_summary']['total_files']} ä¸ªæµ‹è¯•æ–‡ä»¶")
'''

        index_file_path = self.output_dir / "__init__.py"
        with open(index_file_path, 'w', encoding='utf-8') as f:
            f.write(index_content)

        print(f"ğŸ“‹ ç”Ÿæˆæµ‹è¯•ç´¢å¼•: {index_file_path}")

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•ç”Ÿæˆ"""
    print("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–æµ‹è¯•ç”Ÿæˆå™¨...")

    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ææŠ¥å‘Š
    analysis_report_file = "test_gap_analysis_report.json"
    if not os.path.exists(analysis_report_file):
        print(f"âŒ æœªæ‰¾åˆ°åˆ†ææŠ¥å‘Šæ–‡ä»¶: {analysis_report_file}")
        print("è¯·å…ˆè¿è¡Œæ™ºèƒ½æµ‹è¯•ç¼ºå£åˆ†æå™¨ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        return

    # è¯»å–åˆ†ææŠ¥å‘Š
    try:
        with open(analysis_report_file, 'r', encoding='utf-8') as f:
            analysis_report = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        return

    # åˆ›å»ºç”Ÿæˆå™¨é…ç½®
    config = TestGenerationConfig(
        output_dir="tests/generated",
        include_performance_tests=True,
        include_boundary_tests=True,
        include_exception_tests=True
    )

    # æ‰§è¡Œæµ‹è¯•ç”Ÿæˆ
    generator = AutoTestGenerator(config)
    results = generator.generate_tests_from_analysis(analysis_report)

    # ä¿å­˜ç”Ÿæˆç»“æœ
    results_file = "test_generation_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print("\nğŸ“Š ç”Ÿæˆç»“æœ:")
    print(f"   æ€»æ–‡ä»¶æ•°: {len(results['generated_files'])}")
    print(f"   æ€»æµ‹è¯•ç”¨ä¾‹: {results['generated_test_cases']}")
    print(f"   é”™è¯¯æ•°é‡: {len(results.get('generation_errors', []))}")
    print(f"   è¯¦ç»†ç»“æœ: {results_file}")

    return results

if __name__ == "__main__":
    main()