#!/usr/bin/env python3
"""
é€šç”¨é•¿æ–‡ä»¶é‡æ„å·¥å…·
å¯ä»¥å¤„ç†ä»»æ„é•¿æ–‡ä»¶çš„æ™ºèƒ½æ‹†åˆ†
"""

import os
import re
import ast


def analyze_any_file(filepath):
    """åˆ†æä»»æ„æ–‡ä»¶çš„ç»“æ„"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()

        # å°è¯•è§£æAST
        try:
            tree = ast.parse(content)
            functions = []
            classes = []

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append(
                        {
                            "name": node.name,
                            "lineno": node.lineno,
                            "type": "function",
                            "decorators": [
                                d.id if isinstance(d, ast.Name) else str(d)
                                for d in node.decorator_list
                            ],
                        }
                    )
                elif isinstance(node, ast.ClassDef):
                    classes.append(
                        {
                            "name": node.name,
                            "lineno": node.lineno,
                            "type": "class",
                            "methods": [
                                n.name for n in node.body if isinstance(n, ast.FunctionDef)
                            ],
                        }
                    )

            return {
                "functions": functions,
                "classes": classes,
                "total_lines": len(content.split("\n")),
                "content": content,
                "ast_parsed": True,
            }
        except SyntaxError:
            # å¦‚æœæ— æ³•è§£æASTï¼Œä½¿ç”¨è¡Œåˆ†æ
            return analyze_by_lines(content)
    except Exception as e:
        print(f"åˆ†ææ–‡ä»¶ {filepath} å¤±è´¥: {e}")
        return None


def analyze_by_lines(content):
    """æŒ‰è¡Œåˆ†ææ–‡ä»¶å†…å®¹"""
    lines = content.split("\n")
    functions = []
    classes = []

    for i, line in enumerate(lines):
        line_num = i + 1
        line.strip()

        # è¯†åˆ«å‡½æ•°å®šä¹‰
        if re.match(r"^\s*def\s+\w+", line):
            func_name = re.search(r"def\s+(\w+)", line)
            if func_name:
                functions.append(
                    {
                        "name": func_name.group(1),
                        "lineno": line_num,
                        "type": "function",
                        "decorators": [],
                    }
                )

        # è¯†åˆ«ç±»å®šä¹‰
        elif re.match(r"^\s*class\s+\w+", line):
            class_name = re.search(r"class\s+(\w+)", line)
            if class_name:
                classes.append(
                    {
                        "name": class_name.group(1),
                        "lineno": line_num,
                        "type": "class",
                        "methods": [],
                    }
                )

    return {
        "functions": functions,
        "classes": classes,
        "total_lines": len(lines),
        "content": content,
        "ast_parsed": False,
    }


def split_long_file(filepath, max_lines_per_file=250):
    """æ‹†åˆ†é•¿æ–‡ä»¶"""
    print(f"ğŸ”§ åˆ†ææ–‡ä»¶: {filepath}")

    analysis = analyze_any_file(filepath)
    if not analysis:
        print("âŒ æ–‡ä»¶åˆ†æå¤±è´¥")
        return False

    print("ğŸ“Š åˆ†æç»“æœ:")
    print(f"   æ€»è¡Œæ•°: {analysis['total_lines']}")
    print(f"   å‡½æ•°æ•°: {len(analysis['functions'])}")
    print(f"   ç±»æ•°: {len(analysis['classes'])}")
    print(f"   ASTè§£æ: {'æˆåŠŸ' if analysis['ast_parsed'] else 'å¤±è´¥ (ä½¿ç”¨è¡Œåˆ†æ)'}")

    if analysis["total_lines"] <= max_lines_per_file:
        print(f"âœ… æ–‡ä»¶é•¿åº¦ ({analysis['total_lines']} è¡Œ) åœ¨é™åˆ¶èŒƒå›´å†…ï¼Œæ— éœ€æ‹†åˆ†")
        return True

    # ç”Ÿæˆæ‹†åˆ†ç­–ç•¥
    all_items = analysis["functions"] + analysis["classes"]
    all_items.sort(key=lambda x: x["lineno"])

    # æŒ‰åŠŸèƒ½åˆ†ç»„æ‹†åˆ†
    groups = []
    current_group = []
    current_lines = 0

    for item in all_items:
        # ä¼°ç®—è¿™ä¸ªé¡¹ç›®çš„å¤§æ¦‚è¡Œæ•°
        item_lines = 50  # é»˜è®¤ä¼°ç®—
        if current_lines + item_lines > max_lines_per_file and current_group:
            groups.append(current_group)
            current_group = [item]
            current_lines = item_lines
        else:
            current_group.append(item)
            current_lines += item_lines

    if current_group:
        groups.append(current_group)

    # è¯»å–åŸæ–‡ä»¶å†…å®¹
    with open(filepath, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # åˆ›å»ºæ‹†åˆ†æ–‡ä»¶
    base_name = os.path.splitext(os.path.basename(filepath))[0]
    output_dir = os.path.dirname(filepath)
    created_files = []

    for i, group in enumerate(groups):
        if group:
            # åˆ›å»ºæ–°æ–‡ä»¶å
            if len(groups) == 1:
                filename = f"{base_name}_refactored.py"
            else:
                filename = f"{base_name}_part_{i+1}.py"

            filepath_new = os.path.join(output_dir, filename)

            # æå–ç›¸å…³ä»£ç 
            relevant_lines = []

            # æ·»åŠ æ–‡ä»¶å¤´
            relevant_lines.append('"""\n')
            relevant_lines.append(f"{base_name} - ç¬¬{i+1}éƒ¨åˆ†\n")
            relevant_lines.append(f"ä»åŸæ–‡ä»¶ {os.path.basename(filepath)} æ‹†åˆ†\n")
            relevant_lines.append(f'åˆ›å»ºæ—¶é—´: {__import__("datetime").datetime.now()}\n')
            relevant_lines.append(f"åŒ…å«é¡¹ç›®: {len(group)} ä¸ª (å‡½æ•°/ç±»)\n")
            relevant_lines.append('"""\n\n')

            # æ·»åŠ åŸºç¡€å¯¼å…¥
            relevant_lines.append("import pytest\n")
            relevant_lines.append("from unittest.mock import Mock, patch\n")
            relevant_lines.append("import sys\n")
            relevant_lines.append("import os\n\n")

            # æå–æ¯ä¸ªé¡¹ç›®çš„ä»£ç 
            for item in group:
                start_line = item["lineno"] - 1
                if start_line < len(lines):
                    # æ‰¾åˆ°è¿™ä¸ªé¡¹ç›®çš„ç»“æŸä½ç½®
                    end_line = len(lines)
                    for next_item in all_items:
                        if next_item["lineno"] > item["lineno"]:
                            end_line = next_item["lineno"] - 1
                            break

                    # æå–ä»£ç ï¼Œç¡®ä¿ç¼©è¿›æ­£ç¡®
                    for j in range(start_line, min(end_line, len(lines))):
                        line_content = lines[j]
                        if j == start_line:
                            # ç¡®ä¿ç¬¬ä¸€è¡Œæ²¡æœ‰å¤šä½™ç¼©è¿›
                            if line_content.strip().startswith(("def ", "class ", "@")):
                                relevant_lines.append(line_content.lstrip() + "\n")
                            else:
                                relevant_lines.append(line_content)
                        else:
                            relevant_lines.append(line_content)

                    relevant_lines.append("\n")

            # å†™å…¥æ–‡ä»¶
            os.makedirs(os.path.dirname(filepath_new), exist_ok=True)
            with open(filepath_new, "w", encoding="utf-8") as f:
                f.writelines(relevant_lines)

            created_files.append(filepath_new)
            print(f"âœ… åˆ›å»ºæ–‡ä»¶: {filename} ({len(relevant_lines)} è¡Œ)")

    # å¤‡ä»½åŸæ–‡ä»¶
    backup_file = filepath + ".backup"
    if not os.path.exists(backup_file):
        os.rename(filepath, backup_file)
        print(f"ğŸ“¦ åŸæ–‡ä»¶å¤‡ä»½è‡³: {backup_file}")

    print("\nğŸ“Š æ‹†åˆ†æ€»ç»“:")
    print(f"   åŸæ–‡ä»¶: {filepath} ({analysis['total_lines']} è¡Œ)")
    print(f"   æ‹†åˆ†æ–‡ä»¶æ•°: {len(created_files)}")
    print("   åˆ›å»ºæ–‡ä»¶:")
    for f in created_files:
        lines_count = len(open(f, "r", encoding="utf-8").readlines())
        print(f"     - {os.path.basename(f)} ({lines_count} è¡Œ)")

    return True


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    import sys

    if len(sys.argv) > 1:
        target_file = sys.argv[1]
        if not os.path.exists(target_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {target_file}")
            return
    else:
        # é»˜è®¤å¤„ç†æ—¥æœŸæ—¶é—´å·¥å…·æµ‹è¯•æ–‡ä»¶
        target_file = "tests/unit/utils/test_date_time_utils.py"
        if not os.path.exists(target_file):
            print(f"âŒ é»˜è®¤æ–‡ä»¶ä¸å­˜åœ¨: {target_file}")
            print("ç”¨æ³•: python3 universal_refactor.py [æ–‡ä»¶è·¯å¾„]")
            return

    print("ğŸš€ å¼€å§‹é€šç”¨é‡æ„...")
    print(f"ç›®æ ‡æ–‡ä»¶: {target_file}")

    if split_long_file(target_file):
        print("âœ… æ–‡ä»¶é‡æ„å®Œæˆ")

        # éªŒè¯æ‹†åˆ†åçš„æ–‡ä»¶
        print("\nğŸ” éªŒè¯æ‹†åˆ†ç»“æœ...")
        base_name = os.path.splitext(os.path.basename(target_file))[0]
        output_dir = os.path.dirname(target_file)

        # æŸ¥æ‰¾æ‹†åˆ†æ–‡ä»¶
        import glob

        pattern = os.path.join(output_dir, f"{base_name}_part_*.py")
        split_files = glob.glob(pattern)

        if not split_files:
            pattern = os.path.join(output_dir, f"{base_name}_refactored.py")
            split_files = glob.glob(pattern)

        syntax_errors = 0
        for split_file in split_files:
            try:
                with open(split_file, "r", encoding="utf-8") as f:
                    content = f.read()
                ast.parse(content)
                print(f"  âœ… {os.path.basename(split_file)}: è¯­æ³•æ­£ç¡®")
            except SyntaxError as e:
                print(f"  âŒ {os.path.basename(split_file)}: ç¬¬{e.lineno}è¡Œè¯­æ³•é”™è¯¯")
                syntax_errors += 1

        if syntax_errors == 0:
            print("ğŸ‰ æ‰€æœ‰æ‹†åˆ†æ–‡ä»¶è¯­æ³•æ­£ç¡®ï¼")
        else:
            print(f"âš ï¸ æœ‰ {syntax_errors} ä¸ªæ–‡ä»¶å­˜åœ¨è¯­æ³•é”™è¯¯")
    else:
        print("âŒ æ–‡ä»¶é‡æ„å¤±è´¥")


if __name__ == "__main__":
    main()
