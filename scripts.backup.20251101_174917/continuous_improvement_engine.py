#!/usr/bin/env python3
"""
æŒç»­æ”¹è¿›å¼•æ“
Continuous Improvement Engine

åŸºäºè´¨é‡å®ˆæŠ¤ç³»ç»Ÿï¼Œè‡ªåŠ¨æ‰§è¡ŒæŒç»­æ”¹è¿›æµç¨‹
"""

import os
import sys
import json
import subprocess
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging

# å¯¼å…¥è´¨é‡å®ˆæŠ¤ç³»ç»Ÿ
try:
    from quality_guardian import QualityGuardian
    from smart_quality_fixer import SmartQualityFixer
    from quality_standards_optimizer import QualityStandardsOptimizer
except ImportError as e:
    print(f"å¯¼å…¥è´¨é‡æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class ContinuousImprovementEngine:
    """æŒç»­æ”¹è¿›å¼•æ“"""

    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(__file__).parent.parent
        self.improvement_log = self.project_root / "improvement-log.json"
        self.goals_file = self.project_root / "quality-goals.json"

        # åˆå§‹åŒ–ç»„ä»¶
        self.guardian = QualityGuardian(self.project_root)
        self.fixer = SmartQualityFixer(self.project_root)
        self.optimizer = QualityStandardsOptimizer(self.project_root)

        # æ”¹è¿›å†å²
        self.improvement_history = self._load_improvement_history()

        # å½“å‰ç›®æ ‡
        self.current_goals = self._load_quality_goals()

    def _load_improvement_history(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ”¹è¿›å†å²"""
        if self.improvement_log.exists():
            try:
                with open(self.improvement_log, "r") as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½æ”¹è¿›å†å²å¤±è´¥: {e}")
        return []

    def _load_quality_goals(self) -> Dict[str, Any]:
        """åŠ è½½è´¨é‡ç›®æ ‡"""
        if self.goals_file.exists():
            try:
                with open(self.goals_file, "r") as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½è´¨é‡ç›®æ ‡å¤±è´¥: {e}")

        # é»˜è®¤ç›®æ ‡
        return {
            "overall_score": 8.0,
            "coverage": 25.0,
            "code_quality": 8.0,
            "security": 9.0,
            "timeline": "3_months",
            "created_at": datetime.now().isoformat(),
        }

    def run_continuous_improvement_cycle(self) -> Dict[str, Any]:
        """è¿è¡ŒæŒç»­æ”¹è¿›å‘¨æœŸ"""
        print("ğŸš€ å¯åŠ¨æŒç»­æ”¹è¿›å¼•æ“")
        print("=" * 60)

        cycle_start = datetime.now()

        # 1. è´¨é‡çŠ¶æ€è¯„ä¼°
        print("\n1ï¸âƒ£ è¯„ä¼°å½“å‰è´¨é‡çŠ¶æ€...")
        quality_status = self.guardian.run_full_quality_check()

        # 2. ç›®æ ‡å·®è·åˆ†æ
        print("\n2ï¸âƒ£ åˆ†æç›®æ ‡å·®è·...")
        gap_analysis = self._analyze_goal_gaps(quality_status)

        # 3. åˆ¶å®šæ”¹è¿›è®¡åˆ’
        print("\n3ï¸âƒ£ åˆ¶å®šæ”¹è¿›è®¡åˆ’...")
        improvement_plan = self._create_improvement_plan(gap_analysis)

        # 4. æ‰§è¡Œæ”¹è¿›æªæ–½
        print("\n4ï¸âƒ£ æ‰§è¡Œæ”¹è¿›æªæ–½...")
        improvement_results = self._execute_improvements(improvement_plan)

        # 5. éªŒè¯æ”¹è¿›æ•ˆæœ
        print("\n5ï¸âƒ£ éªŒè¯æ”¹è¿›æ•ˆæœ...")
        verification_results = self._verify_improvements()

        # 6. è®°å½•æ”¹è¿›å‘¨æœŸ
        cycle_data = {
            "timestamp": cycle_start.isoformat(),
            "duration_seconds": (datetime.now() - cycle_start).total_seconds(),
            "quality_status_before": quality_status,
            "gap_analysis": gap_analysis,
            "improvement_plan": improvement_plan,
            "improvement_results": improvement_results,
            "verification_results": verification_results,
            "success": verification_results.get("overall_improvement", False),
        }

        self._log_improvement_cycle(cycle_data)

        # 7. ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š
        self._generate_improvement_report(cycle_data)

        print("\nâœ… æŒç»­æ”¹è¿›å‘¨æœŸå®Œæˆï¼")
        print(f"â±ï¸ ç”¨æ—¶: {cycle_data['duration_seconds']:.1f}ç§’")
        print(f"ğŸ“Š æ”¹è¿›æˆåŠŸ: {'æ˜¯' if cycle_data['success'] else 'å¦'}")

        return cycle_data

    def _analyze_goal_gaps(self, quality_status: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æç›®æ ‡å·®è·"""
        gaps = {}

        # ç»¼åˆåˆ†æ•°å·®è·
        current_score = quality_status.get("overall_score", 0)
        target_score = self.current_goals.get("overall_score", 8.0)
        gaps["overall_score"] = {
            "current": current_score,
            "target": target_score,
            "gap": max(0, target_score - current_score),
            "priority": "HIGH" if current_score < 6 else "MEDIUM",
        }

        # è¦†ç›–ç‡å·®è·
        current_coverage = quality_status.get("coverage", 0)
        target_coverage = self.current_goals.get("coverage", 25.0)
        gaps["coverage"] = {
            "current": current_coverage,
            "target": target_coverage,
            "gap": max(0, target_coverage - current_coverage),
            "priority": "HIGH" if current_coverage < 15 else "MEDIUM",
        }

        # ä»£ç è´¨é‡å·®è·
        current_quality = quality_status.get("code_quality", 0)
        target_quality = self.current_goals.get("code_quality", 8.0)
        gaps["code_quality"] = {
            "current": current_quality,
            "target": target_quality,
            "gap": max(0, target_quality - current_quality),
            "priority": "MEDIUM",
        }

        # å®‰å…¨æ€§å·®è·
        current_security = quality_status.get("security", 0)
        target_security = self.current_goals.get("security", 9.0)
        gaps["security"] = {
            "current": current_security,
            "target": target_security,
            "gap": max(0, target_security - current_security),
            "priority": "LOW",
        }

        return gaps

    def _create_improvement_plan(self, gap_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ›å»ºæ”¹è¿›è®¡åˆ’"""
        plan = []

        # æŒ‰ä¼˜å…ˆçº§æ’åºå·®è·
        prioritized_gaps = sorted(
            gap_analysis.items(),
            key=lambda x: {"HIGH": 0, "MEDIUM": 1, "LOW": 2}.get(x[1]["priority"], 3),
        )

        for metric, gap_data in prioritized_gaps:
            if gap_data["gap"] > 0:
                improvement_actions = self._get_improvement_actions(metric, gap_data)
                plan.extend(improvement_actions)

        return plan

    def _get_improvement_actions(
        self, metric: str, gap_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """è·å–æ”¹è¿›æªæ–½"""
        actions = []

        if metric == "coverage":
            if gap_data["current"] < 15:
                actions.append(
                    {
                        "type": "test_generation",
                        "priority": "HIGH",
                        "description": "ä¸ºæ ¸å¿ƒæ¨¡å—ç”ŸæˆåŸºç¡€æµ‹è¯•",
                        "target_modules": ["src/api", "src/core"],
                        "expected_improvement": 3.0,
                    }
                )
            if gap_data["gap"] > 5:
                actions.append(
                    {
                        "type": "coverage_analysis",
                        "priority": "MEDIUM",
                        "description": "åˆ†ææœªè¦†ç›–ä»£ç å¹¶é’ˆå¯¹æ€§æ·»åŠ æµ‹è¯•",
                        "expected_improvement": 2.0,
                    }
                )

        elif metric == "overall_score" and gap_data["current"] < 6:
            actions.append(
                {
                    "type": "comprehensive_fix",
                    "priority": "HIGH",
                    "description": "è¿è¡Œç»¼åˆè´¨é‡ä¿®å¤",
                    "expected_improvement": 1.0,
                }
            )

        elif metric == "code_quality" and gap_data["gap"] > 1:
            actions.append(
                {
                    "type": "code_quality_improvement",
                    "priority": "MEDIUM",
                    "description": "æ”¹è¿›ä»£ç è´¨é‡æŒ‡æ ‡",
                    "expected_improvement": 0.5,
                }
            )

        return actions

    def _execute_improvements(self, improvement_plan: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰§è¡Œæ”¹è¿›æªæ–½"""
        results = {"actions_executed": 0, "improvements_made": [], "failures": []}

        for action in improvement_plan:
            print(f"  ğŸ”„ æ‰§è¡Œ: {action['description']}")

            try:
                if action["type"] == "test_generation":
                    result = self._generate_tests_for_modules(action.get("target_modules", []))
                elif action["type"] == "coverage_analysis":
                    result = self._analyze_and_improve_coverage()
                elif action["type"] == "comprehensive_fix":
                    result = self._run_comprehensive_fix()
                elif action["type"] == "code_quality_improvement":
                    result = self._improve_code_quality()
                else:
                    result = {"success": False, "message": f"æœªçŸ¥æ”¹è¿›ç±»å‹: {action['type']}"}

                if result.get("success", False):
                    results["improvements_made"].append(
                        {"action": action["description"], "result": result}
                    )
                    results["actions_executed"] += 1
                    print("    âœ… æˆåŠŸ")
                else:
                    results["failures"].append(
                        {
                            "action": action["description"],
                            "error": result.get("message", "æœªçŸ¥é”™è¯¯"),
                        }
                    )
                    print(f"    âŒ å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

            except Exception as e:
                results["failures"].append({"action": action["description"], "error": str(e)})
                print(f"    âŒ å¼‚å¸¸: {e}")

        return results

    def _generate_tests_for_modules(self, modules: List[str]) -> Dict[str, Any]:
        """ä¸ºæŒ‡å®šæ¨¡å—ç”Ÿæˆæµ‹è¯•"""
        try:
            # ç®€åŒ–çš„æµ‹è¯•ç”Ÿæˆé€»è¾‘
            generated_tests = 0
            for module in modules:
                module_path = Path(module)
                if module_path.exists():
                    # æŸ¥æ‰¾æœªæµ‹è¯•çš„Pythonæ–‡ä»¶
                    for py_file in module_path.rglob("*.py"):
                        if not py_file.name.startswith("__"):
                            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
                            test_file = (
                                self.project_root / "tests" / "unit" / f"test_{py_file.stem}.py"
                            )
                            if not test_file.exists():
                                # ç”ŸæˆåŸºç¡€æµ‹è¯•æ–‡ä»¶
                                self._create_basic_test_file(test_file, py_file)
                                generated_tests += 1

            return {
                "success": True,
                "generated_tests": generated_tests,
                "message": f"ç”Ÿæˆäº† {generated_tests} ä¸ªåŸºç¡€æµ‹è¯•æ–‡ä»¶",
            }

        except Exception as e:
            return {"success": False, "message": f"æµ‹è¯•ç”Ÿæˆå¤±è´¥: {e}"}

    def _create_basic_test_file(self, test_file: Path, source_file: Path):
        """åˆ›å»ºåŸºç¡€æµ‹è¯•æ–‡ä»¶"""
        try:
            test_file.parent.mkdir(parents=True, exist_ok=True)

            with open(test_file, "w") as f:
                f.write(
                    f'''#!/usr/bin/env python3
"""
Auto-generated basic tests for {source_file.name}
TODO: Expand these tests with actual functionality
"""

import pytest
from unittest.mock import Mock, patch

# TODO: Import the module to test
# from {source_file.stem.replace('/', '.')} import *


class Test{source_file.stem.title().replace('_', '')}:
    """Basic test class for {source_file.name}"""

    def test_module_imports(self):
        """Test that the module can be imported"""
        # TODO: Implement actual import test
        pass

    def test_basic_functionality(self):
        """Test basic functionality"""
        # TODO: Implement actual functionality tests
        pass

    def test_error_handling(self):
        """Test error handling"""
        # TODO: Implement error handling tests
        pass
'''
                )
        except Exception as e:
            logger.warning(f"åˆ›å»ºæµ‹è¯•æ–‡ä»¶å¤±è´¥ {test_file}: {e}")

    def _analyze_and_improve_coverage(self) -> Dict[str, Any]:
        """åˆ†æå¹¶æ”¹è¿›è¦†ç›–ç‡"""
        try:
            # è¿è¡Œè¦†ç›–ç‡åˆ†æ
            subprocess.run(
                [
                    sys.executable,
                    "-m",
                    "pytest",
                    "tests/unit/api/test_health.py",
                    "--cov=src/",
                    "--cov-report=json",
                    "--cov-report=html",
                    "--tb=short",
                    "-q",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )

            return {
                "success": True,
                "message": "è¦†ç›–ç‡åˆ†æå®Œæˆï¼Œç”Ÿæˆäº†HTMLæŠ¥å‘Š",
                "coverage_report_generated": True,
            }

        except Exception as e:
            return {"success": False, "message": f"è¦†ç›–ç‡åˆ†æå¤±è´¥: {e}"}

    def _run_comprehensive_fix(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆä¿®å¤"""
        try:
            fix_results = self.fixer.run_comprehensive_fix()
            total_fixes = fix_results.get("total_fixes", 0)

            return {
                "success": True,
                "fixes_applied": total_fixes,
                "message": f"åº”ç”¨äº† {total_fixes} ä¸ªè‡ªåŠ¨ä¿®å¤",
            }

        except Exception as e:
            return {"success": False, "message": f"ç»¼åˆä¿®å¤å¤±è´¥: {e}"}

    def _improve_code_quality(self) -> Dict[str, Any]:
        """æ”¹è¿›ä»£ç è´¨é‡"""
        try:
            # è¿è¡ŒRuffä¿®å¤
            result = subprocess.run(
                ["ruff", "check", "src/", "--fix"], capture_output=True, text=True, timeout=60
            )

            return {
                "success": result.returncode == 0,
                "message": "Ruffä»£ç è´¨é‡ä¿®å¤å®Œæˆ" if result.returncode == 0 else "Ruffä¿®å¤å‘ç°é—®é¢˜",
            }

        except Exception as e:
            return {"success": False, "message": f"ä»£ç è´¨é‡æ”¹è¿›å¤±è´¥: {e}"}

    def _verify_improvements(self) -> Dict[str, Any]:
        """éªŒè¯æ”¹è¿›æ•ˆæœ"""
        print("  ğŸ” éªŒè¯æ”¹è¿›æ•ˆæœ...")

        # é‡æ–°è¿è¡Œè´¨é‡æ£€æŸ¥
        new_quality_status = self.guardian.run_full_quality_check()

        # åŠ è½½ä¹‹å‰çš„è´¨é‡çŠ¶æ€
        previous_status = (
            self.improvement_history[-1]["quality_status_before"]
            if self.improvement_history
            else {}
        )

        # è®¡ç®—æ”¹è¿›æƒ…å†µ
        improvements = {}
        overall_improvement = False

        # æ¯”è¾ƒå„é¡¹æŒ‡æ ‡
        metrics = ["overall_score", "coverage", "code_quality", "security"]
        for metric in metrics:
            old_value = previous_status.get(metric, 0)
            new_value = new_quality_status.get(metric, 0)

            improvement = new_value - old_value
            improvements[metric] = {
                "old": old_value,
                "new": new_value,
                "improvement": improvement,
                "percentage_change": (
                    (improvement / max(old_value, 0.1)) * 100 if old_value > 0 else 0
                ),
            }

            if improvement > 0:
                overall_improvement = True

        return {
            "overall_improvement": overall_improvement,
            "new_quality_status": new_quality_status,
            "improvements": improvements,
            "summary": self._generate_improvement_summary(improvements),
        }

    def _generate_improvement_summary(self, improvements: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ”¹è¿›æ‘˜è¦"""
        summary_parts = []

        for metric, data in improvements.items():
            if data["improvement"] > 0:
                if metric == "coverage":
                    summary_parts.append(f"è¦†ç›–ç‡æå‡ {data['improvement']:.1f}%")
                elif metric == "overall_score":
                    summary_parts.append(f"ç»¼åˆåˆ†æ•°æå‡ {data['improvement']:.1f} åˆ†")
                else:
                    summary_parts.append(f"{metric} æå‡ {data['improvement']:.1f}")

        if summary_parts:
            return f"æ”¹è¿›æˆæœ: {', '.join(summary_parts)}"
        else:
            return "è´¨é‡æŒ‡æ ‡ä¿æŒç¨³å®š"

    def _log_improvement_cycle(self, cycle_data: Dict[str, Any]):
        """è®°å½•æ”¹è¿›å‘¨æœŸ"""
        self.improvement_history.append(cycle_data)

        # ä¿å­˜æ”¹è¿›å†å²ï¼ˆä¿ç•™æœ€è¿‘50ä¸ªå‘¨æœŸï¼‰
        recent_history = self.improvement_history[-50:]

        try:
            with open(self.improvement_log, "w") as f:
                json.dump(recent_history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜æ”¹è¿›å†å²å¤±è´¥: {e}")

    def _generate_improvement_report(self, cycle_data: Dict[str, Any]):
        """ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š"""
        report_file = (
            self.project_root / f"improvement-report-{datetime.now().strftime('%Y%m%d-%H%M%S')}.md"
        )

        verification = cycle_data.get("verification_results", {})
        improvements = verification.get("improvements", {})

        report_content = f"""# ğŸš€ æŒç»­æ”¹è¿›æŠ¥å‘Š

**æ”¹è¿›å‘¨æœŸ**: {cycle_data['timestamp']}
**æŒç»­æ—¶é—´**: {cycle_data['duration_seconds']:.1f} ç§’
**æ”¹è¿›æˆåŠŸ**: {'âœ… æ˜¯' if cycle_data['success'] else 'âŒ å¦'}

## ğŸ“Š è´¨é‡æŒ‡æ ‡å˜åŒ–

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | å˜åŒ– | å˜åŒ–ç‡ |
|------|--------|--------|------|--------|
"""

        metrics = ["overall_score", "coverage", "code_quality", "security"]
        metric_names = {
            "overall_score": "ç»¼åˆåˆ†æ•°",
            "coverage": "æµ‹è¯•è¦†ç›–ç‡",
            "code_quality": "ä»£ç è´¨é‡",
            "security": "å®‰å…¨æ€§",
        }

        for metric in metrics:
            if metric in improvements:
                data = improvements[metric]
                change_symbol = (
                    "ğŸ“ˆ" if data["improvement"] > 0 else "ğŸ“‰" if data["improvement"] < 0 else "â¡ï¸"
                )
                report_content += f"| {metric_names[metric]} | {data['old']:.1f} | {data['new']:.1f} | {change_symbol} {data['improvement']:+.1f} | {data['percentage_change']:+.1f}% |\n"

        report_content += """

## ğŸ¯ æ‰§è¡Œçš„æ”¹è¿›æªæ–½

"""

        improvement_results = cycle_data.get("improvement_results", {})
        for improvement in improvement_results.get("improvements_made", []):
            report_content += f"âœ… {improvement['action']}\n"

        if improvement_results.get("failures"):
            report_content += "\n## âš ï¸ å¤±è´¥çš„æªæ–½\n\n"
            for failure in improvement_results["failures"]:
                report_content += f"âŒ {failure['action']}: {failure['error']}\n"

        report_content += f"""

## ğŸ“‹ æ”¹è¿›æ‘˜è¦

{verification.get('summary', 'æ— æ”¹è¿›')}

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®

"""

        # åŸºäºå½“å‰çŠ¶æ€ç”Ÿæˆå»ºè®®
        new_status = verification.get("new_quality_status", {})
        if new_status.get("coverage", 0) < 20:
            report_content += "- ğŸ¯ ç»§ç»­æå‡æµ‹è¯•è¦†ç›–ç‡\n"
        if new_status.get("overall_score", 0) < 7:
            report_content += "- ğŸ”§ è¿›ä¸€æ­¥ä¼˜åŒ–ä»£ç è´¨é‡\n"
        if new_status.get("code_quality", 0) < 9:
            report_content += "- ğŸ“š åŠ å¼ºä»£ç è§„èŒƒåŸ¹è®­\n"

        report_content += (
            """
## ğŸ“ˆ è¶‹åŠ¿åˆ†æ

æŒç»­è¿è¡Œæ”¹è¿›å¼•æ“ä»¥è§‚å¯Ÿé•¿æœŸè¶‹åŠ¿ã€‚

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: """
            + datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            + "*"
        )

        try:
            with open(report_file, "w", encoding="utf-8") as f:
                f.write(report_content)
            logger.info(f"æ”¹è¿›æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ”¹è¿›æŠ¥å‘Šå¤±è´¥: {e}")

    def start_automated_improvement(self, interval_minutes: int = 60):
        """å¯åŠ¨è‡ªåŠ¨åŒ–æ”¹è¿›ï¼ˆå®šæ—¶è¿è¡Œï¼‰"""
        print(f"ğŸ¤– å¯åŠ¨è‡ªåŠ¨åŒ–æ”¹è¿›å¼•æ“ï¼Œæ¯ {interval_minutes} åˆ†é’Ÿè¿è¡Œä¸€æ¬¡")
        print("æŒ‰ Ctrl+C åœæ­¢")

        try:
            while True:
                cycle_start = datetime.now()
                print(f"\n{'='*60}")
                print(f"ğŸš€ è‡ªåŠ¨æ”¹è¿›å‘¨æœŸ - {cycle_start.strftime('%Y-%m-%d %H:%M:%S')}")
                print("=" * 60)

                # è¿è¡Œæ”¹è¿›å‘¨æœŸ
                self.run_continuous_improvement_cycle()

                # è®¡ç®—ä¸‹æ¬¡è¿è¡Œæ—¶é—´
                cycle_duration = (datetime.now() - cycle_start).total_seconds()
                wait_time = interval_minutes * 60 - cycle_duration

                if wait_time > 0:
                    print(f"\nâ° ä¸‹æ¬¡æ”¹è¿›å‘¨æœŸ: {interval_minutes} åˆ†é’Ÿå")
                    print(f"â±ï¸ ç­‰å¾…æ—¶é—´: {wait_time:.0f} ç§’")
                    time.sleep(wait_time)
                else:
                    print("\nâš ï¸ å‘¨æœŸè€—æ—¶è¿‡é•¿ï¼Œç«‹å³å¼€å§‹ä¸‹ä¸ªå‘¨æœŸ")

        except KeyboardInterrupt:
            print("\nğŸ›‘ è‡ªåŠ¨åŒ–æ”¹è¿›å¼•æ“å·²åœæ­¢")
        except Exception as e:
            logger.error(f"è‡ªåŠ¨åŒ–æ”¹è¿›å¼•æ“å¼‚å¸¸: {e}")

    def print_improvement_history(self, limit: int = 5):
        """æ‰“å°æ”¹è¿›å†å²"""
        print(f"\nğŸ“ˆ æœ€è¿‘ {limit} ä¸ªæ”¹è¿›å‘¨æœŸ:")
        print("=" * 60)

        recent_cycles = self.improvement_history[-limit:]

        for i, cycle in enumerate(recent_cycles, 1):
            timestamp = cycle.get("timestamp", "Unknown")
            success = cycle.get("success", False)
            duration = cycle.get("duration_seconds", 0)

            verification = cycle.get("verification_results", {})
            improvements = verification.get("improvements", {})

            print(f"\n{i}. å‘¨æœŸæ—¶é—´: {timestamp}")
            print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
            print(f"   è€—æ—¶: {duration:.1f}ç§’")

            if improvements:
                summary_improvements = []
                for metric, data in improvements.items():
                    if data["improvement"] > 0:
                        summary_improvements.append(f"{metric}+{data['improvement']:.1f}")

                if summary_improvements:
                    print(f"   æ”¹è¿›: {', '.join(summary_improvements)}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æŒç»­æ”¹è¿›å¼•æ“")
    parser.add_argument("--project-root", type=Path, help="é¡¹ç›®æ ¹ç›®å½•")
    parser.add_argument("--automated", action="store_true", help="å¯åŠ¨è‡ªåŠ¨åŒ–æ”¹è¿›")
    parser.add_argument("--interval", type=int, default=60, help="è‡ªåŠ¨åŒ–æ”¹è¿›é—´éš”(åˆ†é’Ÿ)")
    parser.add_argument("--history", action="store_true", help="æ˜¾ç¤ºæ”¹è¿›å†å²")
    parser.add_argument("--history-limit", type=int, default=5, help="å†å²è®°å½•æ˜¾ç¤ºæ•°é‡")

    args = parser.parse_args()

    engine = ContinuousImprovementEngine(args.project_root)

    if args.history:
        engine.print_improvement_history(args.history_limit)
    elif args.automated:
        engine.start_automated_improvement(args.interval)
    else:
        # è¿è¡Œå•æ¬¡æ”¹è¿›å‘¨æœŸ
        engine.run_continuous_improvement_cycle()


if __name__ == "__main__":
    main()
