#!/usr/bin/env python3
"""
ğŸ“Š CI/CDæ€§èƒ½ç›‘æ§å™¨
ç›‘æ§å’Œåˆ†æCI/CDå·¥ä½œæµçš„æ€§èƒ½æŒ‡æ ‡

ç‰ˆæœ¬: v1.0 | åˆ›å»ºæ—¶é—´: 2025-10-26 | ä½œè€…: Claude AI Assistant
"""

import os
import sys
import json
import time
import subprocess
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""

    job_name: str
    start_time: float
    end_time: float
    duration: float
    status: str
    cache_hits: int = 0
    cache_misses: int = 0
    test_count: int = 0
    test_passed: int = 0
    test_failed: int = 0
    coverage_percent: float = 0.0


class CIPerformanceMonitor:
    """CI/CDæ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.metrics: List[PerformanceMetrics] = []
        self.start_time = time.time()
        self.root_dir = Path(__file__).parent.parent

    def start_job_timer(self, job_name: str) -> None:
        """å¼€å§‹è®¡æ—¶ä½œä¸š"""
        metric = PerformanceMetrics(
            job_name=job_name, start_time=time.time(), end_time=0.0, duration=0.0, status="running"
        )
        self.metrics.append(metric)
        print(f"â±ï¸  å¼€å§‹è®¡æ—¶: {job_name}")

    def end_job_timer(self, job_name: str, status: str = "completed") -> None:
        """ç»“æŸè®¡æ—¶ä½œä¸š"""
        for metric in self.metrics:
            if metric.job_name == job_name and metric.status == "running":
                metric.end_time = time.time()
                metric.duration = metric.end_time - metric.start_time
                metric.status = status
                print(f"â¹ï¸  ç»“æŸè®¡æ—¶: {job_name} (è€—æ—¶: {metric.duration:.2f}s)")
                break

    def run_performance_test(self, test_type: str = "quick") -> Dict:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print(f"ğŸš€ è¿è¡Œ{test_type}æ€§èƒ½æµ‹è¯•...")

        results = {}

        # æµ‹è¯•1: ä¾èµ–å®‰è£…æ€§èƒ½
        print("ğŸ“¦ æµ‹è¯•ä¾èµ–å®‰è£…æ€§èƒ½...")
        start_time = time.time()
        try:
            subprocess.run(
                ["pip", "install", "--quiet", "-r", "requirements/requirements.lock"],
                check=True,
                capture_output=True,
            )
            install_time = time.time() - start_time
            results["install_time"] = install_time
            print(f"âœ… ä¾èµ–å®‰è£…è€—æ—¶: {install_time:.2f}s")
        except subprocess.CalledProcessError as e:
            print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            results["install_time"] = -1

        # æµ‹è¯•2: è¯­æ³•æ£€æŸ¥æ€§èƒ½
        print("ğŸ”§ æµ‹è¯•è¯­æ³•æ£€æŸ¥æ€§èƒ½...")
        start_time = time.time()
        try:
            result = subprocess.run(
                ["python", "-m", "py_compile", "src/**/*.py"],
                check=True,
                capture_output=True,
                shell=True,
            )
            syntax_time = time.time() - start_time
            results["syntax_time"] = syntax_time
            print(f"âœ… è¯­æ³•æ£€æŸ¥è€—æ—¶: {syntax_time:.2f}s")
        except subprocess.CalledProcessError:
            syntax_time = time.time() - start_time
            results["syntax_time"] = syntax_time
            print(f"âš ï¸ è¯­æ³•æ£€æŸ¥å‘ç°é—®é¢˜ (è€—æ—¶: {syntax_time:.2f}s)")

        # æµ‹è¯•3: Lintæ£€æŸ¥æ€§èƒ½
        print("ğŸ” æµ‹è¯•Lintæ£€æŸ¥æ€§èƒ½...")
        start_time = time.time()
        try:
            result = subprocess.run(
                ["ruff", "check", "src/", "--output-format=json"],
                check=True,
                capture_output=True,
                text=True,
            )
            lint_time = time.time() - start_time
            lint_issues = len(result.stdout.strip()) if result.stdout.strip() else 0
            results["lint_time"] = lint_time
            results["lint_issues"] = lint_issues
            print(
                f"âœ… Lintæ£€æŸ¥è€—æ—¶: {lint_time:.2f}s (é—®é¢˜: {len(json.loads(result.stdout) if result.stdout.strip() else '[]')})"
            )
        except subprocess.CalledProcessError:
            lint_time = time.time() - start_time
            results["lint_time"] = lint_time
            results["lint_issues"] = -1
            print(f"âš ï¸ Lintæ£€æŸ¥å‘ç°é—®é¢˜ (è€—æ—¶: {lint_time:.2f}s)")

        # æµ‹è¯•4: æµ‹è¯•æ‰§è¡Œæ€§èƒ½
        if test_type == "full":
            print("ğŸ§ª æµ‹è¯•æµ‹è¯•æ‰§è¡Œæ€§èƒ½...")
            start_time = time.time()
            try:
                result = subprocess.run(
                    ["pytest", "tests/unit/", "--tb=no", "-q"],
                    check=True,
                    capture_output=True,
                    text=True,
                )
                test_time = time.time() - start_time
                # è§£æpytestè¾“å‡º
                lines = result.stdout.strip().split("\n")
                test_summary = lines[-1] if lines else ""
                results["test_time"] = test_time
                results["test_summary"] = test_summary
                print(f"âœ… æµ‹è¯•æ‰§è¡Œè€—æ—¶: {test_time:.2f}s")
            except subprocess.CalledProcessError:
                test_time = time.time() - start_time
                results["test_time"] = test_time
                results["test_summary"] = "æµ‹è¯•å¤±è´¥"
                print(f"âš ï¸ æµ‹è¯•æ‰§è¡Œå¤±è´¥ (è€—æ—¶: {test_time:.2f}s)")

        return results

    def generate_performance_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        total_time = time.time() - self.start_time
        completed_metrics = [m for m in self.metrics if m.status != "running"]

        report = f"""## ğŸ“Š CI/CDæ€§èƒ½æŠ¥å‘Š

### ğŸ“ˆ æ€»ä½“æ€§èƒ½
- **æ€»æ‰§è¡Œæ—¶é—´**: {total_time:.2f}s
- **å·²å®Œæˆä½œä¸š**: {len(completed_metrics)}/{len(self.metrics)}
- **å¹³å‡ä½œä¸šæ—¶é—´**: {sum(m.duration for m in completed_metrics)/len(completed_metrics):.2f}s

### ğŸƒâ€â™‚ï¸ ä½œä¸šæ€§èƒ½è¯¦æƒ…
"""

        for metric in completed_metrics:
            status_emoji = "âœ…" if metric.status == "completed" else "âŒ"
            report += f"""
#### {status_emoji} {metric.job_name}
- **æ‰§è¡Œæ—¶é—´**: {metric.duration:.2f}s
- **çŠ¶æ€**: {metric.status}
"""

        if completed_metrics:
            slowest = max(completed_metrics, key=lambda m: m.duration)
            fastest = min(completed_metrics, key=lambda m: m.duration)
            report += f"""
### ğŸ† æ€§èƒ½ç»Ÿè®¡
- **æœ€æ…¢ä½œä¸š**: {slowest.job_name} ({slowest.duration:.2f}s)
- **æœ€å¿«ä½œä¸š**: {fastest.job_name} ({fastest.duration:.2f}s)
- **æ€§èƒ½å·®å¼‚**: {slowest.duration - fastest.duration:.2f}s
"""

        return report

    def save_report(self, filename: str = "ci_performance_report.md") -> None:
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        report = self.generate_performance_report()
        report_path = Path(filename)

        with open(report_path, "w", encoding="utf-8") as f:
            f.write("# CI/CDæ€§èƒ½ç›‘æ§æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("**ç›‘æ§å™¨ç‰ˆæœ¬**: v1.0\n\n")
            f.write(report)

        print(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="CI/CDæ€§èƒ½ç›‘æ§å™¨")
    parser.add_argument("--test", choices=["quick", "full"], default="quick", help="æ€§èƒ½æµ‹è¯•ç±»å‹")
    parser.add_argument("--job", help="ç›‘æ§ç‰¹å®šä½œä¸šåç§°")
    parser.add_argument("--start", help="å¼€å§‹è®¡æ—¶ä½œä¸š")
    parser.add_argument("--end", help="ç»“æŸè®¡æ—¶ä½œä¸š")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š")
    parser.add_argument("--output", default="ci_performance_report.md", help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶")

    args = parser.parse_args()

    monitor = CIPerformanceMonitor()

    if args.start:
        monitor.start_job_timer(args.start)
    elif args.end:
        monitor.end_job_timer(args.end)
    elif args.test:
        results = monitor.run_performance_test(args.test)
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
        for key, value in results.items():
            print(f"  {key}: {value}")
    elif args.report:
        monitor.save_report(args.output)
    else:
        # é»˜è®¤è¿è¡Œå¿«é€Ÿæ€§èƒ½æµ‹è¯•
        results = monitor.run_performance_test("quick")
        monitor.save_report()


if __name__ == "__main__":
    main()
