#!/usr/bin/env python3
"""
F405æ˜Ÿå·å¯¼å…¥ä¼˜åŒ–å·¥å…·
F405 Star Import Fixer

ä¸“é—¨ç”¨äºä¿®å¤F405æ˜Ÿå·å¯¼å…¥é”™è¯¯ï¼Œé€šè¿‡ä»¥ä¸‹ç­–ç•¥ï¼š
1. åˆ†ææ˜Ÿå·å¯¼å…¥çš„å®é™…ä½¿ç”¨æƒ…å†µ
2. æ›¿æ¢ä¸ºæ˜ç¡®çš„å¯¼å…¥è¯­å¥
3. ç§»é™¤æœªä½¿ç”¨çš„æ˜Ÿå·å¯¼å…¥
"""

import ast
import json
import logging
import re
import subprocess
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class F405StarImportFixer:
    """F405æ˜Ÿå·å¯¼å…¥ä¿®å¤å™¨"""

    def __init__(self):
        self.fixes_applied = 0
        self.files_processed = 0
        self.files_fixed = 0

        # å¸¸è§çš„æ˜Ÿå·å¯¼å…¥æ¨¡å—
        self.common_star_imports = {
            'django.db.models',
            'sqlalchemy.orm',
            'pandas',
            'numpy',
            'matplotlib.pyplot',
            'seaborn',
            'sklearn',
            'tensorflow',
            'torch',
            'pytest',
            'src.*'
        }

    def get_f405_errors(self) -> List[Dict]:
        """è·å–æ‰€æœ‰F405é”™è¯¯"""
        logger.info("æ­£åœ¨è·å–F405é”™è¯¯åˆ—è¡¨...")
        errors = []

        try:
            result = subprocess.run(
                ['make', 'lint'],
                capture_output=True,
                text=True,
                timeout=60
            )

            for line in result.stdout.split('\n'):
                if 'F405' in line and 'may be undefined' in line:
                    parts = line.split(':')
                    if len(parts) >= 4:
                        file_path = parts[0]
                        line_num = int(parts[1])
                        col_num = int(parts[2])
                        error_msg = parts[3].strip()

                        # æå–æ¨¡å—åå’Œå¯¼å…¥å
                        module_match = re.search(r"from (\S+) \* may be undefined", error_msg)
                        if module_match:
                            module_name = module_match.group(1)
                            errors.append({
                                'file': file_path,
                                'line': line_num,
                                'column': col_num,
                                'message': error_msg,
                                'module_name': module_name,
                                'full_line': line
                            })
        except Exception as e:
            logger.error(f"è·å–F405é”™è¯¯å¤±è´¥: {e}")

        logger.info(f"å‘ç° {len(errors)} ä¸ªF405é”™è¯¯")
        return errors

    def analyze_star_imports(self, file_path: str) -> Dict:
        """åˆ†ææ–‡ä»¶çš„æ˜Ÿå·å¯¼å…¥ä½¿ç”¨æƒ…å†µ"""
        path = Path(file_path)
        if not path.exists():
            return {}

        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ä½¿ç”¨ASTåˆ†æå¯¼å…¥ä½¿ç”¨æƒ…å†µ
            try:
                tree = ast.parse(content)
                analyzer = StarImportAnalyzer()
                analyzer.visit(tree)
                return analyzer.star_imports_usage
            except SyntaxError:
                logger.warning(f"æ–‡ä»¶ {file_path} å­˜åœ¨è¯­æ³•é”™è¯¯ï¼Œè·³è¿‡ASTåˆ†æ")
                return {}

        except Exception as e:
            logger.error(f"åˆ†ææ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            return {}

    def fix_star_imports(self, file_path: str, usage_info: Dict) -> bool:
        """ä¿®å¤æ˜Ÿå·å¯¼å…¥"""
        path = Path(file_path)
        if not path.exists():
            return False

        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.split('\n')
            modified = False

            # å¤„ç†æ¯ä¸ªæ˜Ÿå·å¯¼å…¥
            for module, used_names in usage_info.items():
                # æ‰¾åˆ°æ˜Ÿå·å¯¼å…¥è¯­å¥
                for i, line in enumerate(lines):
                    if f'from {module} import *' in line:
                        if used_names:
                            # æ›¿æ¢ä¸ºæ˜ç¡®å¯¼å…¥
                            if len(used_names) <= 5:  # å°‘é‡å¯¼å…¥æ”¾åœ¨ä¸€è¡Œ
                                new_import = f"from {module} import {', '.join(sorted(used_names))}"
                            else:  # å¤šä¸ªå¯¼å…¥åˆ†è¡Œ
                                new_import = f"from {module} import ("
                                for name in sorted(used_names):
                                    new_import += f"\n    {name},"
                                new_import += "\n)"
                            lines[i] = new_import
                        else:
                            # å¦‚æœæ²¡æœ‰ä½¿ç”¨ä»»ä½•å¯¼å…¥ï¼Œæ³¨é‡Šæ‰æˆ–åˆ é™¤
                            lines[i] = f"# from {module} import *  # Removed: unused"
                        modified = True
                        break

            # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå†™å›æ–‡ä»¶
            if modified:
                content = '\n'.join(lines)
                with open(path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"ä¿®å¤æ˜Ÿå·å¯¼å…¥: {file_path}")
                return True

        except Exception as e:
            logger.error(f"ä¿®å¤æ–‡ä»¶ {file_path} å¤±è´¥: {e}")

        return False

    def run_batch_fix(self) -> Dict:
        """è¿è¡Œæ‰¹é‡ä¿®å¤"""
        logger.info("ğŸ”§ å¼€å§‹F405æ˜Ÿå·å¯¼å…¥æ‰¹é‡ä¿®å¤...")

        errors = self.get_f405_errors()
        if not errors:
            logger.info("æ²¡æœ‰å‘ç°F405é”™è¯¯")
            return {
                'success': True,
                'errors_fixed': 0,
                'files_processed': 0,
                'message': 'æ²¡æœ‰F405é”™è¯¯éœ€è¦ä¿®å¤'
            }

        # è·å–éœ€è¦ä¿®å¤çš„æ–‡ä»¶åˆ—è¡¨
        files_to_fix = set(error['file'] for error in errors)

        # ä¿®å¤æ¯ä¸ªæ–‡ä»¶
        files_fixed = 0
        total_errors_fixed = 0

        for file_path in files_to_fix:
            # åˆ†ææ˜Ÿå·å¯¼å…¥ä½¿ç”¨æƒ…å†µ
            usage_info = self.analyze_star_imports(file_path)

            if usage_info:
                if self.fix_star_imports(file_path, usage_info):
                    files_fixed += 1
                    # ä¼°ç®—ä¿®å¤çš„é”™è¯¯æ•°
                    file_errors = [e for e in errors if e['file'] == file_path]
                    total_errors_fixed += len(file_errors)

            self.files_processed += 1

        result = {
            'success': True,
            'errors_fixed': total_errors_fixed,
            'files_processed': self.files_processed,
            'files_fixed': files_fixed,
            'message': f'ä¿®å¤äº† {files_fixed} ä¸ªæ–‡ä»¶ä¸­çš„ {total_errors_fixed} ä¸ªF405é”™è¯¯'
        }

        logger.info(f"F405æ‰¹é‡ä¿®å¤å®Œæˆ: {result}")
        return result

    def generate_report(self) -> Dict:
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        return {
            'fixer_name': 'F405 Star Import Fixer',
            'timestamp': '2025-10-30T01:55:00.000000',
            'fixes_applied': self.fixes_applied,
            'files_processed': self.files_processed,
            'success_rate': f"{(self.fixes_applied / max(self.files_processed, 1)) * 100:.1f}%"
        }


class StarImportAnalyzer(ast.NodeVisitor):
    """æ˜Ÿå·å¯¼å…¥ä½¿ç”¨åˆ†æå™¨"""

    def __init__(self):
        self.star_imports_usage = {}
        self.current_star_imports = []

    def visit_ImportFrom(self, node):
        """è®¿é—®å¯¼å…¥è¯­å¥"""
        if node.names and isinstance(node.names[0], ast.alias) and node.names[0].name == '*':
            # è®°å½•æ˜Ÿå·å¯¼å…¥
            module = node.module or ''
            self.current_star_imports.append(module)
        self.generic_visit(node)

    def visit_Name(self, node):
        """è®¿é—®åç§°èŠ‚ç‚¹"""
        if isinstance(node.ctx, ast.Load):
            # æ£€æŸ¥æ˜¯å¦æ¥è‡ªæ˜Ÿå·å¯¼å…¥
            for module in self.current_star_imports:
                if module not in self.star_imports_usage:
                    self.star_imports_usage[module] = set()
                self.star_imports_usage[module].add(node.id)
        self.generic_visit(node)

    def visit_Attribute(self, node):
        """è®¿é—®å±æ€§èŠ‚ç‚¹"""
        # å¤„ç†å±æ€§è®¿é—®ï¼Œå¦‚ module.name
        if isinstance(node.value, ast.Name):
            name_parts = [node.value.id]
            current = node
            while isinstance(current, ast.Attribute):
                name_parts.append(current.attr)
                current = current.value

            # æ£€æŸ¥æ˜¯å¦æ¥è‡ªæ˜Ÿå·å¯¼å…¥
            '.'.join(reversed(name_parts))
            for module in self.current_star_imports:
                if module not in self.star_imports_usage:
                    self.star_imports_usage[module] = set()
                # æ·»åŠ åŸºåç§°
                if name_parts:
                    self.star_imports_usage[module].add(name_parts[0])

        self.generic_visit(node)


def main():
    """ä¸»å‡½æ•°"""
    fixer = F405StarImportFixer()

    print("ğŸ”§ F405 æ˜Ÿå·å¯¼å…¥æ‰¹é‡ä¿®å¤å·¥å…·")
    print("=" * 50)

    # è¿è¡Œæ‰¹é‡ä¿®å¤
    result = fixer.run_batch_fix()

    # ç”ŸæˆæŠ¥å‘Š
    report = fixer.generate_report()

    print("\nğŸ“Š ä¿®å¤æ‘˜è¦:")
    print(f"   ä¿®å¤é”™è¯¯æ•°: {result['errors_fixed']}")
    print(f"   å¤„ç†æ–‡ä»¶æ•°: {result['files_processed']}")
    print(f"   ä¿®å¤æ–‡ä»¶æ•°: {result['files_fixed']}")
    print(f"   æˆåŠŸç‡: {report['success_rate']}")
    print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±è´¥'}")

    # ä¿å­˜æŠ¥å‘Š
    report_file = Path('f405_fix_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            'result': result,
            'report': report
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    return result


if __name__ == '__main__':
    main()