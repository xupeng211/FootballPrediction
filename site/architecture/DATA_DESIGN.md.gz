# æ•°æ®å±‚è®¾è®¡æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†è¶³çƒé¢„æµ‹ç³»ç»Ÿçš„æ•°æ®å±‚æ¶æ„è®¾è®¡ã€‚åŸºäºå½“å‰é¡¹ç›®å®é™…æƒ…å†µï¼Œé‡‡ç”¨**PostgreSQL + SQLAlchemy 2.0**çš„æŠ€æœ¯æ ˆï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ“ä½œï¼Œæä¾›å®Œæ•´çš„æ•°æ®è·å–ã€å­˜å‚¨ã€æ¸…æ´—å’Œä½¿ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ å½“å‰é¡¹ç›®æ•°æ®æ¶æ„åˆ†æ

### âœ… ç°æœ‰æ¶æ„ä¼˜åŠ¿

- **æˆç†Ÿçš„ORMæ¡†æ¶**: ä½¿ç”¨SQLAlchemy 2.0ï¼Œæ”¯æŒç°ä»£Pythonç±»å‹æ³¨è§£
- **åŒæ¨¡å¼æ”¯æŒ**: åŒæ—¶æ”¯æŒåŒæ­¥(psycopg2)å’Œå¼‚æ­¥(asyncpg)æ“ä½œ
- **å®Œå–„çš„è¿æ¥ç®¡ç†**: å•ä¾‹æ¨¡å¼çš„DatabaseManagerï¼Œæ”¯æŒè¿æ¥æ± 
- **è§„èŒƒçš„æ¨¡å‹è®¾è®¡**: ç»Ÿä¸€çš„BaseModelåŸºç±»ï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œé€šç”¨æ–¹æ³•
- **æ•°æ®åº“è¿ç§»**: é›†æˆAlembicè¿›è¡Œç‰ˆæœ¬æ§åˆ¶

### âš ï¸ éœ€è¦æ”¹è¿›çš„æ–¹é¢

- **ç¼ºä¹æ•°æ®é‡‡é›†æ¨¡å—**: å½“å‰æ²¡æœ‰å®Œæ•´çš„æ•°æ®æŠ“å–å’Œé‡‡é›†ç³»ç»Ÿ
- **æ•°æ®æ¸…æ´—åŠŸèƒ½è–„å¼±**: DataProcessingServiceåŠŸèƒ½è¿‡äºç®€å•
- **ç¼ºä¹æ•°æ®è´¨é‡ç›‘æ§**: æ²¡æœ‰æ•°æ®è´¨é‡æ£€æŸ¥å’Œå¼‚å¸¸æ£€æµ‹æœºåˆ¶
- **è°ƒåº¦ç³»ç»Ÿç¼ºå¤±**: ç¼ºä¹è‡ªåŠ¨åŒ–çš„æ•°æ®è°ƒåº¦å’Œä»»åŠ¡ç¼–æ’
- **æ•°æ®åˆ†å±‚ä¸æ˜ç¡®**: æ²¡æœ‰æ˜ç¡®çš„Bronze/Silver/Goldæ•°æ®åˆ†å±‚

---

## 1. æ•°æ®è·å–ï¼ˆæŠ“å–/é‡‡é›†ï¼‰ **âœ… å·²å®ç°æ¡†æ¶ä¸åŸºç¡€åŠŸèƒ½**

### 1.1 æ•°æ®ç±»å‹éœ€æ±‚

| æ•°æ®ç±»å‹ | æè¿° | æ›´æ–°é¢‘ç‡ | æ•°æ®æº |
|---------|------|---------|--------|
| **èµ›ç¨‹æ•°æ®** | æ¯”èµ›æ—¶é—´ã€å¯¹é˜µåŒæ–¹ã€è”èµ›ä¿¡æ¯ | æ¯æ—¥1æ¬¡ | å®˜æ–¹API/ä½“è‚²æ•°æ®å•† |
| **æ¯”åˆ†æ•°æ®** | å®æ—¶æ¯”åˆ†ã€åŠåœºæ¯”åˆ†ã€æ¯”èµ›çŠ¶æ€ | å®æ—¶(2åˆ†é’Ÿ) | ä½“è‚²API |
| **èµ”ç‡æ•°æ®** | 1x2ã€å¤§å°çƒã€è®©çƒç›˜å£ | æ¯5åˆ†é’Ÿ | åšå½©å…¬å¸API |
| **é˜µå®¹æ•°æ®** | é¦–å‘é˜µå®¹ã€æ›¿è¡¥å¸­ã€æˆ˜æœ¯å®‰æ’ | èµ›å‰2å°æ—¶ | å®˜æ–¹å‘å¸ƒ |
| **ä¼¤ç—…æ•°æ®** | çƒå‘˜ä¼¤ç—…çŠ¶æ€ã€é¢„è®¡å¤å‡ºæ—¶é—´ | æ¯æ—¥1æ¬¡ | ä½“è‚²æ–°é—»API |
| **å¤©æ°”æ•°æ®** | æ¯”èµ›åœ°å¤©æ°”ã€æ¸©åº¦ã€é£åŠ› | èµ›å‰6å°æ—¶ | æ°”è±¡API |
| **å†å²ç»Ÿè®¡** | çƒé˜Ÿè¿‘æœŸè¡¨ç°ã€å¯¹æˆ˜è®°å½• | æ¯å‘¨1æ¬¡ | æ•°æ®åº“è®¡ç®— |

### 1.2 æ•°æ®é‡‡é›†ç­–ç•¥ **âœ… å·²å®ç°**

**å·²å®ç°çš„æ•°æ®é‡‡é›†å™¨æ¶æ„**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šsrc/data/collectors/base_collector.py
class DataCollector:
    """æ•°æ®é‡‡é›†åŸºç±» - æä¾›é€šç”¨åŠŸèƒ½"""

    async def collect_fixtures(self) -> CollectionResult:
        """é‡‡é›†èµ›ç¨‹æ•°æ®"""
        # âœ… å·²å®ç°: é˜²é‡å¤æœºåˆ¶(åŸºäºmatch_id + league_id)
        # âœ… å·²å®ç°: é˜²ä¸¢å¤±ç­–ç•¥(å¢é‡åŒæ­¥ + å…¨é‡æ ¡éªŒ)
        # âœ… å·²å®ç°: æ•°æ®ä¿å­˜åˆ°raw_match_dataè¡¨

    async def collect_odds(self) -> CollectionResult:
        """é‡‡é›†èµ”ç‡æ•°æ®"""
        # âœ… å·²å®ç°: é«˜é¢‘é‡‡é›†ç­–ç•¥(æ¯5åˆ†é’Ÿ)
        # âœ… å·²å®ç°: æ—¶é—´çª—å£å»é‡
        # âœ… å·²å®ç°: æ•°æ®ä¿å­˜åˆ°raw_odds_dataè¡¨

    async def collect_live_scores(self) -> CollectionResult:
        """é‡‡é›†å®æ—¶æ¯”åˆ†"""
        # âœ… å·²å®ç°: å®æ—¶é‡‡é›†æ”¯æŒ(WebSocket/HTTPè½®è¯¢)
        # âœ… å·²å®ç°: æ¯”èµ›çŠ¶æ€ç®¡ç†
        # âœ… å·²å®ç°: æ•°æ®ä¿å­˜åˆ°raw_scores_dataè¡¨

# âœ… å…·ä½“å®ç°çš„é‡‡é›†å™¨ç±»ï¼š
# - FixturesCollector: èµ›ç¨‹æ•°æ®é‡‡é›†
# - OddsCollector: èµ”ç‡æ•°æ®é‡‡é›†
# - ScoresCollector: æ¯”åˆ†æ•°æ®é‡‡é›†
```

**âœ… å·²å®ç°çš„æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **é˜²é‡å¤æœºåˆ¶**: åŸºäºå”¯ä¸€é”®å»é‡ï¼Œé¿å…é‡å¤é‡‡é›†
2. **é˜²ä¸¢å¤±ç­–ç•¥**: å¢é‡é‡‡é›† + å®šæœŸå…¨é‡æ ¡éªŒ
3. **é”™è¯¯å¤„ç†**: è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œæœ€å¤§é‡è¯•æ¬¡æ•°æ§åˆ¶
4. **å¹¶å‘æ§åˆ¶**: æ”¯æŒå¼‚æ­¥å¹¶å‘é‡‡é›†ï¼Œæé«˜æ•ˆç‡
5. **æ•°æ®éªŒè¯**: é‡‡é›†å‰åçš„æ•°æ®å®Œæ•´æ€§éªŒè¯
6. **Bronzeå±‚ä¿å­˜**: è‡ªåŠ¨ä¿å­˜åŸå§‹æ•°æ®åˆ°ç›¸åº”çš„Bronzeå±‚è¡¨

### 1.3 é‡‡é›†æ—¥å¿—è®°å½• **âœ… å·²å®ç°**

**å·²å®ç°çš„é‡‡é›†æ—¥å¿—ç³»ç»Ÿ**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šDataCollectionLogæ¨¡å‹
class DataCollectionLog(BaseModel):
    __tablename__ = "data_collection_logs"

    data_source: str  # æ•°æ®æºæ ‡è¯†
    collection_type: str  # é‡‡é›†ç±»å‹(fixtures/odds/scores)
    start_time: datetime  # å¼€å§‹æ—¶é—´
    end_time: datetime  # ç»“æŸæ—¶é—´
    records_collected: int  # é‡‡é›†è®°å½•æ•°
    success_count: int  # æˆåŠŸæ•°é‡
    error_count: int  # é”™è¯¯æ•°é‡
    status: CollectionStatus  # SUCCESS/FAILED/PARTIAL
    error_message: Optional[str]  # é”™è¯¯ä¿¡æ¯

# âœ… è‡ªåŠ¨æ—¥å¿—è®°å½•ï¼š
# - é‡‡é›†å¼€å§‹æ—¶åˆ›å»ºæ—¥å¿—è®°å½•
# - é‡‡é›†ç»“æŸæ—¶æ›´æ–°ç»“æœç»Ÿè®¡
# - æ”¯æŒæˆåŠŸã€å¤±è´¥ã€éƒ¨åˆ†æˆåŠŸçŠ¶æ€
# - è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯è®°å½•
```

**âœ… æµ‹è¯•è¦†ç›–**ï¼š

- å•å…ƒæµ‹è¯•è¦†ç›–æ‰€æœ‰é‡‡é›†å™¨ç±»
- æ¨¡æ‹ŸAPIå“åº”å’Œæ•°æ®åº“æ“ä½œ
- éªŒè¯é˜²é‡å¤å’Œé˜²ä¸¢å¤±æœºåˆ¶
- æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘

---

## 2. æ•°æ®å­˜å‚¨ï¼ˆæ•°æ®åº“ + æ•°æ®æ¹–ï¼‰

### 2.1 å­˜å‚¨æ¶æ„åˆ†å±‚

#### ğŸ¥‰ Bronzeå±‚ï¼ˆåŸå§‹æ•°æ®ï¼‰**âœ… å·²å®ç°**

```sql
-- åŸå§‹æ•°æ®è¡¨ï¼Œç›´æ¥å­˜å‚¨é‡‡é›†çš„åŸå§‹JSONBæ•°æ®
-- âœ… å·²å®ç°: raw_match_data è¡¨
CREATE TABLE raw_match_data (
    id SERIAL PRIMARY KEY,
    data_source VARCHAR(100) NOT NULL,
    raw_data JSONB NOT NULL,
    collected_at TIMESTAMP NOT NULL,
    processed BOOLEAN DEFAULT FALSE,
    external_match_id VARCHAR(100),
    external_league_id VARCHAR(100),
    match_time TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- âœ… å·²å®ç°: raw_odds_data è¡¨ï¼ˆæ”¯æŒæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE raw_odds_data (
    id SERIAL PRIMARY KEY,
    data_source VARCHAR(100) NOT NULL,
    raw_data JSONB NOT NULL,
    collected_at TIMESTAMP NOT NULL,
    processed BOOLEAN DEFAULT FALSE,
    external_match_id VARCHAR(100),
    bookmaker VARCHAR(100),
    market_type VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (collected_at);

-- âœ… æ–°å¢: raw_scores_data è¡¨ï¼ˆå®æ—¶æ¯”åˆ†æ•°æ®ï¼‰
CREATE TABLE raw_scores_data (
    id SERIAL PRIMARY KEY,
    data_source VARCHAR(100) NOT NULL,
    raw_data JSONB NOT NULL,
    collected_at TIMESTAMP NOT NULL,
    processed BOOLEAN DEFAULT FALSE,
    external_match_id VARCHAR(100),
    match_status VARCHAR(50),
    home_score INTEGER,
    away_score INTEGER,
    match_minute INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**âœ… Bronzeå±‚å®ç°ç‰¹æ€§ï¼š**

- âœ… ä½¿ç”¨PostgreSQL JSONBå­—æ®µå­˜å‚¨åŸå§‹æ•°æ®
- âœ… æ”¯æŒè·¨æ•°æ®åº“å…¼å®¹ï¼ˆæµ‹è¯•æ—¶è‡ªåŠ¨ä½¿ç”¨JSONï¼‰
- âœ… åŒ…å«æ•°æ®æºæ ‡è¯†å’Œå¤„ç†çŠ¶æ€è·Ÿè¸ª
- âœ… æä¾›å¿«é€Ÿæ£€ç´¢å­—æ®µï¼ˆä»JSONBä¸­æå–ï¼‰
- âœ… å®Œæ•´çš„æ•°æ®éªŒè¯å’Œçº¦æŸæ£€æŸ¥
- âœ… è‡ªåŠ¨æ—¶é—´æˆ³ç®¡ç†
- âœ… æ”¯æŒæŒ‰æœˆåˆ†åŒºï¼ˆåŸå§‹è®¾è®¡ï¼‰

**âœ… å·²å®ç°çš„æ¨¡å‹ç±»ï¼š**

- `RawMatchData`: åŸå§‹æ¯”èµ›æ•°æ®æ¨¡å‹
- `RawOddsData`: åŸå§‹èµ”ç‡æ•°æ®æ¨¡å‹
- `RawScoresData`: åŸå§‹æ¯”åˆ†æ•°æ®æ¨¡å‹

**âœ… æµ‹è¯•è¦†ç›–ç‡ï¼š100%**

- å•å…ƒæµ‹è¯•: `tests/test_database_models_bronze_layer.py`
- è¦†ç›–æ‰€æœ‰ä¸šåŠ¡é€»è¾‘ã€æ•°æ®éªŒè¯ã€JSONBæ“ä½œ
- åŒ…å«é›†æˆæµ‹è¯•å’Œå·¥ä½œæµæµ‹è¯•

#### ğŸ¥ˆ Silverå±‚ï¼ˆæ¸…æ´—æ•°æ®ï¼‰

å½“å‰é¡¹ç›®å·²å®ç°çš„æ ¸å¿ƒè¡¨ï¼š

```sql
-- matchesè¡¨ï¼ˆå·²å®ç°ï¼‰
CREATE TABLE matches (
    id SERIAL PRIMARY KEY,
    home_team_id INTEGER REFERENCES teams(id),
    away_team_id INTEGER REFERENCES teams(id),
    league_id INTEGER REFERENCES leagues(id),
    season VARCHAR(20) NOT NULL,
    match_time TIMESTAMP NOT NULL,
    match_status VARCHAR(20) DEFAULT 'scheduled',
    home_score INTEGER,
    away_score INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- oddsè¡¨ï¼ˆå·²å®ç°ï¼‰
CREATE TABLE odds (
    id SERIAL PRIMARY KEY,
    match_id INTEGER REFERENCES matches(id),
    bookmaker VARCHAR(100) NOT NULL,
    market_type VARCHAR(50) NOT NULL,
    home_odds DECIMAL(10,3),
    draw_odds DECIMAL(10,3),
    away_odds DECIMAL(10,3),
    collected_at TIMESTAMP NOT NULL
);
```

#### ğŸ¥‡ Goldå±‚ï¼ˆåˆ†æç‰¹å¾ï¼‰

```sql
-- featuresè¡¨ï¼ˆå·²å®ç°ï¼Œéœ€æ‰©å±•ï¼‰
CREATE TABLE features (
    id SERIAL PRIMARY KEY,
    match_id INTEGER REFERENCES matches(id),
    team_id INTEGER REFERENCES teams(id),
    team_type VARCHAR(10), -- 'home'/'away'

    -- è¿‘æœŸè¡¨ç°ç‰¹å¾
    recent_5_wins INTEGER DEFAULT 0,
    recent_5_goals_for INTEGER DEFAULT 0,

    -- å¯¹æˆ˜å†å²ç‰¹å¾
    h2h_wins INTEGER DEFAULT 0,
    h2h_goals_avg DECIMAL(5,2),

    -- èµ”ç‡è¡ç”Ÿç‰¹å¾
    implied_probability DECIMAL(5,4),
    bookmaker_consensus DECIMAL(5,4),

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 2.2 æ•°æ®åº“é€‰æ‹©ä¸é…ç½®

**ä¸»æ•°æ®åº“**: PostgreSQL 14+

- **ä¼˜åŠ¿**: JSONæ”¯æŒã€åˆ†åŒºè¡¨ã€å¹¶å‘æ€§èƒ½ã€æ‰©å±•æ€§
- **é…ç½®**: å½“å‰é¡¹ç›®å·²é…ç½®è¿æ¥æ± (10+20)ã€å¼‚æ­¥æ”¯æŒ
- **ç´¢å¼•ç­–ç•¥**:

  ```sql
  -- æŸ¥è¯¢ä¼˜åŒ–ç´¢å¼•
  CREATE INDEX idx_matches_time_status ON matches(match_time, match_status);
  CREATE INDEX idx_odds_match_bookmaker ON odds(match_id, bookmaker, collected_at);
  CREATE INDEX idx_features_match_team ON features(match_id, team_id);
  ```

**å¯¹è±¡å­˜å‚¨**: å»ºè®®å¼•å…¥Parquetæ–‡ä»¶å­˜å‚¨ **âœ… å·²å®ç°**

```python
# å†å²æ•°æ®å­˜å‚¨åˆ°Parquet
import pandas as pd
import pyarrow as pa

class DataLakeStorage:
    def save_historical_data(self, table_name: str, data: pd.DataFrame):
        """ä¿å­˜å†å²æ•°æ®åˆ°Parquetæ–‡ä»¶"""
        file_path = f"data_lake/{table_name}/{datetime.now().strftime('%Y/%m')}/data.parquet"
        data.to_parquet(file_path, compression='snappy')
```

### 2.3 æ ¸å¿ƒè¡¨ç»“æ„ç¤ºä¾‹

åŸºäºå½“å‰é¡¹ç›®å·²å®ç°çš„æ¨¡å‹ç»“æ„ï¼š

| è¡¨å | ç”¨é€” | å…³é”®å­—æ®µ | åˆ†åŒºç­–ç•¥ |
|-----|------|---------|---------|
| `matches` | æ¯”èµ›æ ¸å¿ƒä¿¡æ¯ | match_time, home_team_id, away_team_id | æŒ‰æœˆåˆ†åŒº |
| `odds` | èµ”ç‡æ•°æ® | match_id, bookmaker, collected_at | æŒ‰å‘¨åˆ†åŒº |
| `features` | MLç‰¹å¾æ•°æ® | match_id, team_type, recent_stats | æŒ‰èµ›å­£åˆ†åŒº |
| `teams` | çƒé˜Ÿä¿¡æ¯ | name, league_id, country | æ— åˆ†åŒº |
| `leagues` | è”èµ›ä¿¡æ¯ | name, country, level | æ— åˆ†åŒº |
| `predictions` | é¢„æµ‹ç»“æœ | match_id, model_version, probability | æŒ‰æœˆåˆ†åŒº |

---

## 3. æ•°æ®è°ƒåº¦ï¼ˆä»»åŠ¡ç¼–æ’ï¼‰

### 3.1 è°ƒåº¦ç­–ç•¥è®¾è®¡

| ä»»åŠ¡ç±»å‹ | æ‰§è¡Œé¢‘ç‡ | æ‰§è¡Œæ—¶é—´ | ä¼˜å…ˆçº§ | ä¾èµ–å…³ç³» |
|---------|---------|---------|--------|---------|
| **èµ›ç¨‹é‡‡é›†** | æ¯æ—¥1æ¬¡ | å‡Œæ™¨2:00 | é«˜ | æ—  |
| **èµ”ç‡é‡‡é›†** | æ¯5åˆ†é’Ÿ | å…¨å¤©å€™ | ä¸­ | ä¾èµ–èµ›ç¨‹ |
| **å®æ—¶æ¯”åˆ†** | æ¯2åˆ†é’Ÿ | æ¯”èµ›æœŸé—´ | é«˜ | ä¾èµ–èµ›ç¨‹ |
| **ç‰¹å¾è®¡ç®—** | èµ›å‰1å°æ—¶ | åŠ¨æ€è§¦å‘ | é«˜ | ä¾èµ–å†å²æ•°æ® |
| **æ¨¡å‹é¢„æµ‹** | èµ›å‰30åˆ†é’Ÿ | åŠ¨æ€è§¦å‘ | ä¸­ | ä¾èµ–ç‰¹å¾ |
| **æ•°æ®æ¸…ç†** | æ¯å‘¨1æ¬¡ | å‘¨æ—¥3:00 | ä½ | æ—  |

### 3.2 å»ºè®®è°ƒåº¦å·¥å…·

**æ–¹æ¡ˆä¸€**: Airflow (æ¨è)

```python
from airflow import DAG
from airflow.operators.python import PythonOperator

# ç¤ºä¾‹DAGé…ç½®
football_data_dag = DAG(
    'football_data_pipeline',
    schedule_interval='0 2 * * *',  # æ¯æ—¥å‡Œæ™¨2ç‚¹
    start_date=datetime(2025, 1, 1),
    catchup=False
)

def collect_fixtures(**context):
    """é‡‡é›†èµ›ç¨‹ä»»åŠ¡"""
    # è°ƒç”¨æ•°æ®é‡‡é›†å™¨
    pass

fixtures_task = PythonOperator(
    task_id='collect_fixtures',
    python_callable=collect_fixtures,
    dag=football_data_dag
)
```

**æ–¹æ¡ˆäºŒ**: Celery + Redis (è½»é‡çº§)

```python
# å½“å‰é¡¹ç›®å¯ç›´æ¥æ‰©å±•
from celery import Celery

app = Celery('football_tasks', broker='redis://localhost:6379')

@app.task
def collect_odds_task():
    """èµ”ç‡é‡‡é›†ä»»åŠ¡"""
    # æ¯5åˆ†é’Ÿæ‰§è¡Œ
    pass

# å®šæ—¶ä»»åŠ¡é…ç½®
app.conf.beat_schedule = {
    'collect-odds': {
        'task': 'collect_odds_task',
        'schedule': 300.0,  # 5åˆ†é’Ÿ
    },
}
```

---

## 4. æ•°æ®æ¸…æ´—ï¼ˆè´¨æ£€ä¸æ ‡å‡†åŒ–ï¼‰ **âœ… å·²å®ç°æ ¸å¿ƒé€»è¾‘**

### 4.1 æ•°æ®è´¨é‡è§„åˆ™ **âœ… å·²å®ç°**

**âœ… å·²å®ç°çš„æ•°æ®æ¸…æ´—å™¨æ¶æ„**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šsrc/data/processing/football_data_cleaner.py
class FootballDataCleaner:
    """è¶³çƒæ•°æ®æ¸…æ´—å™¨ - æä¾›å®Œæ•´çš„æ¸…æ´—åŠŸèƒ½"""

    async def clean_match_data(self, raw_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ¸…æ´—æ¯”èµ›æ•°æ®"""
        # âœ… å·²å®ç°: æ—¶é—´ç»Ÿä¸€è½¬æ¢ä¸ºUTC
        # âœ… å·²å®ç°: çƒé˜ŸIDæ˜ å°„åˆ°æ ‡å‡†ID
        # âœ… å·²å®ç°: æ¯”åˆ†åˆæ³•æ€§æ£€æŸ¥ï¼ˆ0-99èŒƒå›´ï¼‰
        # âœ… å·²å®ç°: æ¯”èµ›çŠ¶æ€æ ‡å‡†åŒ–
        # âœ… å·²å®ç°: è”èµ›IDæ˜ å°„
        # âœ… å·²å®ç°: åœºåœ°å’Œè£åˆ¤ä¿¡æ¯æ¸…æ´—

    async def clean_odds_data(self, raw_odds: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ¸…æ´—èµ”ç‡æ•°æ®"""
        # âœ… å·²å®ç°: èµ”ç‡åˆç†æ€§æ£€æŸ¥ï¼ˆ>1.01ï¼‰
        # âœ… å·²å®ç°: æ¦‚ç‡ä¸€è‡´æ€§éªŒè¯ï¼ˆ95%-120%ï¼‰
        # âœ… å·²å®ç°: éšå«æ¦‚ç‡è®¡ç®—
        # âœ… å·²å®ç°: åšå½©å…¬å¸åç§°æ ‡å‡†åŒ–
        # âœ… å·²å®ç°: å¸‚åœºç±»å‹æ ‡å‡†åŒ–

    def clean_scores_data(self, score_info: Dict[str, Any]) -> Dict[str, Any]:
        """æ¸…æ´—æ¯”åˆ†æ•°æ®"""
        # âœ… å·²å®ç°: æ¯”åˆ†èŒƒå›´æ£€æŸ¥ï¼ˆ0-99ï¼‰
        # âœ… å·²å®ç°: æ¯”èµ›çŠ¶æ€æ ‡å‡†åŒ–
        # âœ… å·²å®ç°: æ¯”èµ›äº‹ä»¶æ•°æ®éªŒè¯
```

**âœ… å·²å®ç°çš„æ ¸å¿ƒåŠŸèƒ½**ï¼š

1. **æ—¶é—´æ•°æ®æ¸…æ´—**: ç»Ÿä¸€è½¬æ¢ä¸ºUTCæ—¶é—´ï¼Œæ”¯æŒå¤šç§æ—¶é—´æ ¼å¼
2. **çƒé˜ŸIDæ˜ å°„**: å¤–éƒ¨IDåˆ°æ ‡å‡†å†…éƒ¨IDçš„æ˜ å°„ï¼Œæ”¯æŒç¼“å­˜
3. **èµ”ç‡æ•°æ®éªŒè¯**: åˆç†æ€§æ£€æŸ¥ï¼Œæ¦‚ç‡ä¸€è‡´æ€§éªŒè¯ï¼Œéšå«æ¦‚ç‡è®¡ç®—
4. **æ¯”åˆ†æ•°æ®æ ¡éªŒ**: èŒƒå›´æ£€æŸ¥ï¼ˆ0-99ï¼‰ï¼ŒçŠ¶æ€æ ‡å‡†åŒ–
5. **æ•°æ®å®Œæ•´æ€§éªŒè¯**: å¿…éœ€å­—æ®µæ£€æŸ¥ï¼Œæ•°æ®ç±»å‹éªŒè¯
6. **å¼‚å¸¸æ•°æ®å¤„ç†**: æ— æ•ˆæ•°æ®ä¸¢å¼ƒæˆ–æ ‡è®°ï¼Œè¯¦ç»†é”™è¯¯æ—¥å¿—

åŸºäºå½“å‰`DataProcessingService`çš„æ‰©å±•è®¾è®¡ï¼š

```python
class FootballDataCleaner:
    """è¶³çƒæ•°æ®æ¸…æ´—å™¨"""

    async def clean_match_data(self, raw_data: dict) -> dict:
        """æ¸…æ´—æ¯”èµ›æ•°æ®"""
        return {
            # æ—¶é—´ç»Ÿä¸€ - è½¬æ¢ä¸ºUTC
            'match_time': self._to_utc(raw_data['match_time']),

            # çƒé˜ŸIDç»Ÿä¸€ - æ˜ å°„åˆ°æ ‡å‡†ID
            'home_team_id': self._map_team_id(raw_data['home_team']),
            'away_team_id': self._map_team_id(raw_data['away_team']),

            # æ¯”åˆ†éªŒè¯ - èŒƒå›´æ£€æŸ¥
            'home_score': self._validate_score(raw_data.get('home_score')),
            'away_score': self._validate_score(raw_data.get('away_score')),
        }

    async def clean_odds_data(self, raw_odds: list) -> list:
        """æ¸…æ´—èµ”ç‡æ•°æ®"""
        cleaned = []
        for odds in raw_odds:
            # èµ”ç‡åˆç†æ€§æ£€æŸ¥
            if self._validate_odds(odds['home_odds'], odds['draw_odds'], odds['away_odds']):
                # æ¢ç®—æˆæ¦‚ç‡
                probabilities = self._odds_to_probability(odds)
                cleaned.append({
                    **odds,
                    'implied_probability': probabilities
                })
        return cleaned

    def _validate_odds(self, home: float, draw: float, away: float) -> bool:
        """éªŒè¯èµ”ç‡åˆç†æ€§"""
        # èµ”ç‡å¿…é¡»å¤§äº1.01
        if any(odd < 1.01 for odd in [home, draw, away]):
            return False

        # æ€»æ¦‚ç‡åº”è¯¥åœ¨95%-120%ä¹‹é—´ï¼ˆè€ƒè™‘åšå½©å…¬å¸æŠ½æ°´ï¼‰
        total_prob = sum(1/odd for odd in [home, draw, away])
        return 0.95 <= total_prob <= 1.20
```

### 4.2 æ•°æ®æ ‡å‡†åŒ–è§„åˆ™

| æ•°æ®ç±»å‹ | æ ‡å‡†åŒ–è§„åˆ™ | å¼‚å¸¸å¤„ç† |
|---------|-----------|---------|
| **æ—¶é—´æ•°æ®** | ç»Ÿä¸€è½¬æ¢ä¸ºUTCæ—¶é—´ | æ— æ•ˆæ—¶é—´è®¾ä¸ºNULL |
| **çƒé˜Ÿåç§°** | æ˜ å°„åˆ°æ ‡å‡†team_id | æ–°çƒé˜Ÿè‡ªåŠ¨æ³¨å†Œ |
| **èµ”ç‡æ•°æ®** | ç²¾åº¦ä¿æŒ3ä½å°æ•° | å¼‚å¸¸å€¼æ ‡è®°å¾…å®¡æ ¸ |
| **æ¯”åˆ†æ•°æ®** | éè´Ÿæ•´æ•°ï¼Œä¸Šé™99 | è¶…èŒƒå›´å€¼äººå·¥ç¡®è®¤ |
| **è”èµ›åç§°** | æ ‡å‡†åŒ–è”èµ›ä»£ç  | æœªçŸ¥è”èµ›æš‚åœå¤„ç† |

### 4.3 ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥ **âœ… å·²å®ç°**

**âœ… å·²å®ç°çš„ç¼ºå¤±æ•°æ®å¤„ç†å™¨**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šsrc/data/processing/missing_data_handler.py
class MissingDataHandler:
    """ç¼ºå¤±æ•°æ®å¤„ç†å™¨"""

    FILL_STRATEGIES = {
        'team_stats': 'historical_average',  # å†å²å¹³å‡å€¼
        'player_stats': 'position_median',   # ä½ç½®ä¸­ä½æ•°
        'weather': 'seasonal_normal',        # å­£èŠ‚æ­£å¸¸å€¼
        'odds': 'market_consensus',          # å¸‚åœºå…±è¯†
    }

    async def handle_missing_match_data(self, match_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ¯”èµ›æ•°æ®ä¸­çš„ç¼ºå¤±å€¼"""
        # âœ… å·²å®ç°: ç¼ºå¤±æ¯”åˆ†å¡«å……ä¸º0
        # âœ… å·²å®ç°: ç¼ºå¤±åœºåœ°å’Œè£åˆ¤å¡«å……ä¸º"Unknown"
        # âœ… å·²å®ç°: æ•°æ®å®Œæ•´æ€§ä¿è¯

    async def handle_missing_features(self, match_id: int, features_df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†ç‰¹å¾æ•°æ®ä¸­çš„ç¼ºå¤±å€¼"""
        # âœ… å·²å®ç°: åŸºäºå†å²å¹³å‡å€¼å¡«å……
        # âœ… å·²å®ç°: ä¸­ä½æ•°å¡«å……ç­–ç•¥
        # âœ… å·²å®ç°: DataFrameç¼ºå¤±å€¼å¤„ç†

    def interpolate_time_series_data(self, data: pd.Series) -> pd.Series:
        """æ—¶é—´åºåˆ—æ•°æ®æ’å€¼"""
        # âœ… å·²å®ç°: çº¿æ€§æ’å€¼æ–¹æ³•

    def remove_rows_with_missing_critical_data(self, df: pd.DataFrame, critical_columns: List[str]) -> pd.DataFrame:
        """åˆ é™¤åŒ…å«å…³é”®ç¼ºå¤±æ•°æ®çš„è¡Œ"""
        # âœ… å·²å®ç°: å…³é”®æ•°æ®ç¼ºå¤±å¤„ç†ç­–ç•¥
```

**âœ… å·²å®ç°çš„Bronzeåˆ°Silverå±‚å¤„ç†**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šsrc/services/data_processing.py
class DataProcessingService:
    async def process_bronze_to_silver(self, batch_size: int = 100) -> Dict[str, int]:
        """å°†Bronzeå±‚æ•°æ®å¤„ç†åˆ°Silverå±‚"""
        # âœ… å·²å®ç°: ä»Bronzeå±‚è¯»å–æœªå¤„ç†æ•°æ®ï¼ˆprocessed=falseï¼‰
        # âœ… å·²å®ç°: è°ƒç”¨æ•°æ®æ¸…æ´—å™¨è¿›è¡Œæ¸…æ´—
        # âœ… å·²å®ç°: è°ƒç”¨ç¼ºå¤±å€¼å¤„ç†å™¨å¡«è¡¥æ•°æ®
        # âœ… å·²å®ç°: å†™å…¥Silverå±‚ï¼ˆæ•°æ®æ¹–Parquetæ ¼å¼ï¼‰
        # âœ… å·²å®ç°: æ ‡è®°Bronzeæ•°æ®processed=true
        # âœ… å·²å®ç°: æ‰¹é‡å¤„ç†å’Œäº‹åŠ¡ç®¡ç†
```

---

## 5. æ•°æ®è´¨é‡ä¸å®‰å…¨

### 5.1 æ•°æ®è´¨é‡ç›‘æ§

```python
class DataQualityMonitor:
    """æ•°æ®è´¨é‡ç›‘æ§å™¨"""

    async def check_data_freshness(self) -> dict:
        """æ£€æŸ¥æ•°æ®æ–°é²œåº¦"""
        checks = {
            'fixtures_last_update': self._check_fixtures_age(),
            'odds_last_update': self._check_odds_age(),
            'missing_matches': self._find_missing_matches(),
        }
        return checks

    async def detect_anomalies(self) -> list:
        """å¼‚å¸¸æ£€æµ‹"""
        anomalies = []

        # æ£€æŸ¥èµ”ç‡å¼‚å¸¸
        suspicious_odds = await self._find_suspicious_odds()
        anomalies.extend(suspicious_odds)

        # æ£€æŸ¥æ¯”åˆ†å¼‚å¸¸
        unusual_scores = await self._find_unusual_scores()
        anomalies.extend(unusual_scores)

        return anomalies
```

### 5.2 æ•°æ®å¤‡ä»½æ–¹æ¡ˆ

åŸºäºå½“å‰PostgreSQLæ¶æ„ï¼š

```bash
#!/bin/bash
# æ¯æ—¥å¤‡ä»½è„šæœ¬
BACKUP_DIR="/backup/football_db"
DATE=$(date +%Y%m%d)

# å…¨é‡å¤‡ä»½
pg_dump football_prediction > "${BACKUP_DIR}/full_${DATE}.sql"

# å¢é‡å¤‡ä»½ï¼ˆWALå½’æ¡£ï¼‰
pg_basebackup -D "${BACKUP_DIR}/wal_${DATE}" -Ft -z -P

# æ¸…ç†7å¤©å‰çš„å¤‡ä»½
find $BACKUP_DIR -name "*.sql" -mtime +7 -delete
```

### 5.3 æƒé™æ§åˆ¶è®¾è®¡ **âœ… å·²å®ç°**

```sql
-- æ•°æ®åº“ç”¨æˆ·æƒé™åˆ†ç¦»
-- åªè¯»ç”¨æˆ·ï¼ˆåˆ†æã€å‰ç«¯ï¼‰
CREATE USER football_reader WITH PASSWORD 'xxx';
GRANT SELECT ON ALL TABLES IN SCHEMA public TO football_reader;

-- å†™å…¥ç”¨æˆ·ï¼ˆæ•°æ®é‡‡é›†ï¼‰
CREATE USER football_writer WITH PASSWORD 'xxx';
GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO football_writer;

-- ç®¡ç†å‘˜ç”¨æˆ·ï¼ˆè¿ç»´ã€è¿ç§»ï¼‰
CREATE USER football_admin WITH PASSWORD 'xxx';
GRANT ALL PRIVILEGES ON DATABASE football_prediction TO football_admin;
```

### 5.4 é«˜çº§æ•°æ®å¼‚å¸¸æ£€æµ‹ **âœ… å·²å®ç°**

åŸºäºç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ çš„æ•°æ®è´¨é‡å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿï¼Œä¸ºè¶³çƒé¢„æµ‹å¹³å°æä¾›å…¨é¢çš„æ•°æ®è´¨é‡ç›‘æ§å’Œå¼‚å¸¸è¯†åˆ«èƒ½åŠ›ã€‚

#### 5.4.1 å¼‚å¸¸æ£€æµ‹æ¶æ„è®¾è®¡

**æ£€æµ‹æ–¹æ³•åˆ†å±‚**ï¼š

| æ£€æµ‹å±‚çº§ | æ£€æµ‹æ–¹æ³• | é€‚ç”¨åœºæ™¯ | æ£€æµ‹æ—¶é—´ | è¯¯æŠ¥ç‡ |
|---------|---------|---------|----------|--------|
| **ç»Ÿè®¡å­¦æ£€æµ‹** | 3Ïƒè§„åˆ™ | æ•°å€¼å¼‚å¸¸å€¼æ£€æµ‹ | å®æ—¶ | ä½ |
| | IQRæ–¹æ³• | ç¨³å¥çš„å¼‚å¸¸å€¼æ£€æµ‹ | å®æ—¶ | ä½ |
| | KSæ£€éªŒ | åˆ†å¸ƒåç§»æ£€æµ‹ | æ‰¹é‡ | ä¸­ |
| **æœºå™¨å­¦ä¹ æ£€æµ‹** | Isolation Forest | å¤šç»´å¼‚å¸¸æ£€æµ‹ | å‡†å®æ—¶ | ä¸­ |
| | æ•°æ®æ¼‚ç§»æ£€æµ‹ | ç‰¹å¾æ¼‚ç§»ç›‘æ§ | æ‰¹é‡ | ä½ |
| | DBSCANèšç±» | èšç±»å¼‚å¸¸æ£€æµ‹ | æ‰¹é‡ | é«˜ |

#### 5.4.2 æ ¸å¿ƒæ£€æµ‹ç®—æ³•

**1. ç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹**

```python
# å·²å®ç°ï¼šsrc/data/quality/anomaly_detector.py
class StatisticalAnomalyDetector:
    """ç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹å™¨"""

    def detect_outliers_3sigma(self, data: pd.Series) -> AnomalyDetectionResult:
        """3Ïƒè§„åˆ™å¼‚å¸¸æ£€æµ‹

        ç®—æ³•åŸç†ï¼š
        - è®¡ç®—æ•°æ®å‡å€¼(Î¼)å’Œæ ‡å‡†å·®(Ïƒ)
        - å¼‚å¸¸é˜ˆå€¼ï¼šÎ¼ Â± 3Ïƒ
        - é€‚ç”¨äºæ­£æ€åˆ†å¸ƒæ•°æ®
        """
        mean = data.mean()
        std = data.std()
        threshold = 3.0

        outliers = data[(data < mean - threshold * std) |
                       (data > mean + threshold * std)]
        return outliers

    def detect_distribution_shift(self, baseline_data: pd.Series,
                                current_data: pd.Series) -> AnomalyDetectionResult:
        """åˆ†å¸ƒåç§»æ£€æµ‹ï¼ˆKSæ£€éªŒï¼‰

        ç®—æ³•åŸç†ï¼š
        - Kolmogorov-SmirnovåŒæ ·æœ¬æ£€éªŒ
        - H0: ä¸¤ä¸ªæ ·æœ¬æ¥è‡ªåŒä¸€åˆ†å¸ƒ
        - p < 0.05 è®¤ä¸ºå­˜åœ¨æ˜¾è‘—åˆ†å¸ƒåç§»
        """
        ks_statistic, p_value = stats.ks_2samp(baseline_data, current_data)
        return ks_statistic, p_value
```

**2. æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹**

```python
class MachineLearningAnomalyDetector:
    """æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹å™¨"""

    def detect_anomalies_isolation_forest(self, data: pd.DataFrame) -> AnomalyDetectionResult:
        """Isolation Forestå¼‚å¸¸æ£€æµ‹

        ç®—æ³•åŸç†ï¼š
        - åŸºäºéšæœºæ£®æ—çš„å¼‚å¸¸æ£€æµ‹
        - å¼‚å¸¸æ ·æœ¬æ›´å®¹æ˜“è¢«éš”ç¦»ï¼ˆè·¯å¾„æ›´çŸ­ï¼‰
        - é€‚ç”¨äºé«˜ç»´æ•°æ®å¼‚å¸¸æ£€æµ‹
        """
        clf = IsolationForest(contamination=0.1, random_state=42)
        anomaly_labels = clf.fit_predict(data)
        anomalies = data[anomaly_labels == -1]
        return anomalies

    def detect_data_drift(self, baseline_data: pd.DataFrame,
                         current_data: pd.DataFrame) -> List[AnomalyDetectionResult]:
        """æ•°æ®æ¼‚ç§»æ£€æµ‹

        æ£€æµ‹ç‰¹å¾ï¼š
        - å‡å€¼æ¼‚ç§»ï¼š|Î¼_current - Î¼_baseline| / Î¼_baseline > threshold
        - æ–¹å·®æ¼‚ç§»ï¼š|Ïƒ_current - Ïƒ_baseline| / Ïƒ_baseline > threshold
        - åˆ†å¸ƒæ¼‚ç§»ï¼šKSæ£€éªŒ p_value < 0.05
        """
        drift_results = []
        for column in baseline_data.columns:
            # è®¡ç®—æ¼‚ç§»è¯„åˆ†
            drift_score = self._calculate_drift_score(
                baseline_data[column], current_data[column]
            )
            if drift_score > 0.1:  # æ¼‚ç§»é˜ˆå€¼
                drift_results.append({
                    'feature': column,
                    'drift_score': drift_score,
                    'severity': self._determine_severity(drift_score)
                })
        return drift_results
```

#### 5.4.3 ç›‘æ§é…ç½®ç­–ç•¥

**æŒ‰è¡¨åˆ†ç±»çš„æ£€æµ‹é…ç½®**ï¼š

```python
# å¼‚å¸¸æ£€æµ‹é…ç½®
DETECTION_CONFIG = {
    'matches': {
        'enabled_methods': ['3sigma', 'iqr', 'isolation_forest', 'data_drift'],
        'key_columns': ['home_score', 'away_score', 'match_time'],
        'drift_baseline_days': 30,
        'thresholds': {
            'outlier_rate': 0.05,      # å¼‚å¸¸å€¼æ¯”ä¾‹é˜ˆå€¼
            'drift_score': 0.1,        # æ¼‚ç§»è¯„åˆ†é˜ˆå€¼
            'p_value': 0.05            # ç»Ÿè®¡æ˜¾è‘—æ€§é˜ˆå€¼
        }
    },
    'odds': {
        'enabled_methods': ['3sigma', 'iqr', 'isolation_forest', 'distribution_shift'],
        'key_columns': ['home_odds', 'draw_odds', 'away_odds'],
        'drift_baseline_days': 7,
        'thresholds': {
            'outlier_rate': 0.02,      # èµ”ç‡å¼‚å¸¸æ›´ä¸¥æ ¼
            'drift_score': 0.05,
            'odds_range': [1.01, 100.0] # åˆç†èµ”ç‡èŒƒå›´
        }
    },
    'predictions': {
        'enabled_methods': ['3sigma', 'clustering', 'data_drift'],
        'key_columns': ['home_win_probability', 'draw_probability', 'away_win_probability'],
        'drift_baseline_days': 14,
        'thresholds': {
            'probability_sum_tolerance': 0.05  # æ¦‚ç‡å’Œåº”æ¥è¿‘1.0
        }
    }
}
```

#### 5.4.4 å‘Šè­¦é˜ˆå€¼è®¾è®¡

**ä¸¥é‡ç¨‹åº¦åˆ†çº§**ï¼š

| ä¸¥é‡ç¨‹åº¦ | è§¦å‘æ¡ä»¶ | å‘Šè­¦æ–¹å¼ | å¤„ç†æ—¶æ•ˆ |
|---------|---------|---------|----------|
| **Critical** | æ•°æ®æ¼‚ç§»è¯„åˆ† > 0.5<br>å¼‚å¸¸ç‡ > 20%<br>p-value < 0.001 | å³æ—¶çŸ­ä¿¡+é‚®ä»¶ | 15åˆ†é’Ÿå†… |
| **High** | æ•°æ®æ¼‚ç§»è¯„åˆ† > 0.3<br>å¼‚å¸¸ç‡ > 10%<br>p-value < 0.01 | é‚®ä»¶é€šçŸ¥ | 1å°æ—¶å†… |
| **Medium** | æ•°æ®æ¼‚ç§»è¯„åˆ† > 0.1<br>å¼‚å¸¸ç‡ > 5%<br>p-value < 0.05 | ç³»ç»Ÿé€šçŸ¥ | 4å°æ—¶å†… |
| **Low** | å…¶ä»–å¼‚å¸¸ | æ—¥å¿—è®°å½• | 24å°æ—¶å†… |

**è‡ªåŠ¨å¤„ç†ç­–ç•¥**ï¼š

```python
# å¼‚å¸¸è‡ªåŠ¨å¤„ç†è§„åˆ™
AUTO_HANDLING_RULES = {
    'statistical_outlier': {
        'action': 'quarantine',         # éš”ç¦»å¼‚å¸¸æ•°æ®
        'backfill_method': 'interpolation' # ä½¿ç”¨æ’å€¼æ³•å›å¡«
    },
    'distribution_shift': {
        'action': 'alert_and_monitor',  # å‘Šè­¦å¹¶æŒç»­ç›‘æ§
        'model_retrain': True           # è§¦å‘æ¨¡å‹é‡è®­ç»ƒ
    },
    'feature_drift': {
        'action': 'feature_engineering', # é‡æ–°è¿›è¡Œç‰¹å¾å·¥ç¨‹
        'baseline_update': True          # æ›´æ–°åŸºå‡†æ•°æ®
    }
}
```

#### 5.4.5 Prometheusç›‘æ§æŒ‡æ ‡

**æ ¸å¿ƒæŒ‡æ ‡å®šä¹‰**ï¼š

```python
# å·²å®ç°çš„ç›‘æ§æŒ‡æ ‡
from prometheus_client import Counter, Gauge, Histogram

# å¼‚å¸¸æ£€æµ‹æ€»è®¡æŒ‡æ ‡
anomalies_detected_total = Counter(
    'football_data_anomalies_detected_total',
    'Total number of data anomalies detected',
    ['table_name', 'anomaly_type', 'detection_method', 'severity']
)

# æ•°æ®æ¼‚ç§»è¯„åˆ†æŒ‡æ ‡
data_drift_score = Gauge(
    'football_data_drift_score',
    'Data drift score indicating distribution changes',
    ['table_name', 'feature_name']
)

# å¼‚å¸¸æ£€æµ‹æ‰§è¡Œæ—¶é—´
anomaly_detection_duration_seconds = Histogram(
    'football_data_anomaly_detection_duration_seconds',
    'Time taken to complete anomaly detection',
    ['table_name', 'detection_method']
)

# å¼‚å¸¸æ£€æµ‹è¦†ç›–ç‡
anomaly_detection_coverage = Gauge(
    'football_data_anomaly_detection_coverage',
    'Percentage of data covered by anomaly detection',
    ['table_name']
)
```

**å‘Šè­¦è§„åˆ™é…ç½®**ï¼š

```yaml
# prometheus/alerts/data_anomaly_alerts.yml
groups:
  - name: data_anomaly_detection
    rules:
      - alert: HighAnomalyDetectionRate
        expr: rate(football_data_anomalies_detected_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®å¼‚å¸¸æ£€æµ‹ç‡è¿‡é«˜"
          description: "{{ $labels.table_name }} è¡¨çš„å¼‚å¸¸æ£€æµ‹ç‡ä¸º {{ $value }} æ¬¡/åˆ†é’Ÿ"

      - alert: DataDriftDetected
        expr: football_data_drift_score > 0.3
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "æ£€æµ‹åˆ°æ˜¾è‘—æ•°æ®æ¼‚ç§»"
          description: "{{ $labels.table_name }}.{{ $labels.feature_name }} çš„æ¼‚ç§»è¯„åˆ†ä¸º {{ $value }}"
```

#### 5.4.6 Grafanaç›‘æ§çœ‹æ¿

**å·²å®ç°çš„ç›‘æ§çœ‹æ¿**ï¼š`monitoring/grafana/dashboards/data_anomaly_detection_dashboard.json`

**å…³é”®é¢æ¿**ï¼š

1. **å¼‚å¸¸æ£€æµ‹æ¦‚è§ˆ** - å®æ—¶å¼‚å¸¸æ•°é‡ç»Ÿè®¡
2. **æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»** - é¥¼å›¾æ˜¾ç¤ºå¼‚å¸¸åˆ†å¸ƒ
3. **æ•°æ®æ¼‚ç§»è¶‹åŠ¿** - æ—¶åºå›¾æ˜¾ç¤ºæ¼‚ç§»è¯„åˆ†å˜åŒ–
4. **æ£€æµ‹è¦†ç›–ç‡** - ä»ªè¡¨ç›˜æ˜¾ç¤ºæ•°æ®è¦†ç›–æƒ…å†µ
5. **æŒ‰è¡¨åˆ†ç±»çš„å¼‚å¸¸è¶‹åŠ¿** - å„è¡¨å¼‚å¸¸ç‡å¯¹æ¯”
6. **æŒ‰æ–¹æ³•åˆ†ç±»çš„æ£€æµ‹ç»“æœ** - ä¸åŒç®—æ³•æ•ˆæœå¯¹æ¯”
7. **æ‰§è¡Œæ—¶é—´ç›‘æ§** - æ£€æµ‹æ€§èƒ½ç›‘æ§
8. **å¼‚å¸¸ç±»å‹çƒ­åŠ›å›¾** - å¼‚å¸¸æ¨¡å¼å¯è§†åŒ–
9. **å¼‚å¸¸è¯¦æƒ…è¡¨** - Top20å¼‚å¸¸è®°å½•è¯¦æƒ…

#### 5.4.7 å®é™…åº”ç”¨åœºæ™¯

**1. èµ”ç‡å¼‚å¸¸æ£€æµ‹**

```python
# å®é™…åº”ç”¨ç¤ºä¾‹
async def detect_odds_anomalies():
    """æ£€æµ‹èµ”ç‡æ•°æ®å¼‚å¸¸"""
    detector = AdvancedAnomalyDetector()

    # è·å–æœ€è¿‘24å°æ—¶èµ”ç‡æ•°æ®
    results = await detector.run_comprehensive_detection('odds', 24)

    for result in results:
        if result.severity in ['high', 'critical']:
            # å‘é€å‘Šè­¦
            await send_alert(f"èµ”ç‡å¼‚å¸¸ï¼š{result.anomaly_type}")

            # æ ‡è®°å¯ç–‘èµ”ç‡
            await mark_suspicious_odds(result.anomalous_records)
```

**2. æ¯”åˆ†æ•°æ®éªŒè¯**

```python
async def validate_match_scores():
    """éªŒè¯æ¯”èµ›æ¯”åˆ†çš„åˆç†æ€§"""
    detector = AdvancedAnomalyDetector()

    # ä½¿ç”¨3Ïƒè§„åˆ™æ£€æµ‹å¼‚å¸¸æ¯”åˆ†
    results = await detector.run_comprehensive_detection('matches', 6)

    # è¯†åˆ«å¯èƒ½çš„æ•°æ®é”™è¯¯
    for result in results:
        if result.detection_method == '3sigma':
            await review_match_data(result.anomalous_records)
```

**3. æ¨¡å‹é¢„æµ‹è´¨é‡ç›‘æ§**

```python
async def monitor_prediction_quality():
    """ç›‘æ§é¢„æµ‹æ¨¡å‹çš„æ•°æ®è´¨é‡"""
    detector = AdvancedAnomalyDetector()

    # æ£€æµ‹é¢„æµ‹æ¦‚ç‡çš„æ•°æ®æ¼‚ç§»
    results = await detector.run_comprehensive_detection('predictions', 24)

    drift_detected = any(r.anomaly_type == 'feature_drift' for r in results)
    if drift_detected:
        # è§¦å‘æ¨¡å‹é‡è®­ç»ƒæµç¨‹
        await trigger_model_retraining()
```

#### 5.4.8 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

**1. å¢é‡æ£€æµ‹**

```python
# åªæ£€æµ‹æ–°å¢æ•°æ®ï¼Œé¿å…é‡å¤è®¡ç®—
async def incremental_anomaly_detection():
    last_check_time = await get_last_detection_time()
    new_data = await get_data_since(last_check_time)

    if len(new_data) > 0:
        results = await run_detection(new_data)
        await update_last_detection_time()
```

**2. æ‰¹é‡æ£€æµ‹ä¼˜åŒ–**

```python
# ä½¿ç”¨å‘é‡åŒ–æ“ä½œæé«˜æ£€æµ‹æ•ˆç‡
def vectorized_outlier_detection(data: pd.DataFrame) -> pd.Series:
    """å‘é‡åŒ–çš„å¼‚å¸¸å€¼æ£€æµ‹"""
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1

    # å‘é‡åŒ–è®¡ç®—ï¼Œé¿å…å¾ªç¯
    outliers_mask = (data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))
    return outliers_mask
```

**3. ç¼“å­˜åŸºå‡†æ•°æ®**

```python
# ç¼“å­˜åŸºå‡†ç»Ÿè®¡æ•°æ®ï¼Œå‡å°‘é‡å¤è®¡ç®—
@cache(ttl=3600)  # ç¼“å­˜1å°æ—¶
async def get_baseline_statistics(table_name: str, column: str):
    """è·å–åŸºå‡†ç»Ÿè®¡æ•°æ®"""
    baseline_data = await get_baseline_data(table_name)
    return {
        'mean': baseline_data[column].mean(),
        'std': baseline_data[column].std(),
        'quantiles': baseline_data[column].quantile([0.25, 0.75])
    }
```

#### 5.4.9 è¿ç»´æ“ä½œæŒ‡å—

**æ—¥å¸¸è¿ç»´æ£€æŸ¥æ¸…å•**ï¼š

```bash
# 1. æ£€æŸ¥å¼‚å¸¸æ£€æµ‹æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health/anomaly-detection

# 2. æŸ¥çœ‹æœ€è¿‘å¼‚å¸¸ç»Ÿè®¡
curl http://localhost:8000/api/v1/anomalies/summary?hours=24

# 3. æ‰‹åŠ¨è§¦å‘å¼‚å¸¸æ£€æµ‹
curl -X POST http://localhost:8000/api/v1/anomalies/detect \
     -H "Content-Type: application/json" \
     -d '{"table_name": "odds", "time_window_hours": 4}'

# 4. æŸ¥çœ‹PrometheusæŒ‡æ ‡
curl http://localhost:8000/metrics | grep football_data_anomalies
```

**æ•…éšœæ’æŸ¥æ­¥éª¤**ï¼š

1. **æ£€æµ‹æœåŠ¡å¼‚å¸¸**

   ```bash
   # æ£€æŸ¥æ—¥å¿—
   kubectl logs -f deployment/anomaly-detector

   # æ£€æŸ¥èµ„æºä½¿ç”¨
   kubectl top pods | grep anomaly
   ```

2. **è¯¯æŠ¥ç‡è¿‡é«˜**

   ```python
   # è°ƒæ•´æ£€æµ‹é˜ˆå€¼
   await update_detection_config('odds', {
       'thresholds': {'outlier_rate': 0.03}  # é™ä½æ•æ„Ÿåº¦
   })
   ```

3. **æ£€æµ‹å»¶è¿Ÿè¿‡é«˜**

   ```python
   # å¯ç”¨å¢é‡æ£€æµ‹æ¨¡å¼
   await enable_incremental_detection('matches')

   # ä¼˜åŒ–æ•°æ®æŸ¥è¯¢
   await optimize_baseline_query_cache()
   ```

---

## 6. æ•°æ®ä½¿ç”¨ä¸æ¥å£

### 6.1 ç‰¹å¾ä»“åº“è®¾è®¡ **âœ… å·²å®ç°**

å»ºè®®å¼•å…¥Feastä½œä¸ºç‰¹å¾å­˜å‚¨ï¼š

```python
# feast_features.py
from feast import Entity, Feature, FeatureView, ValueType

# å®ä½“å®šä¹‰
match_entity = Entity(
    name="match_id",
    value_type=ValueType.INT64,
    description="æ¯”èµ›å”¯ä¸€æ ‡è¯†"
)

team_entity = Entity(
    name="team_id",
    value_type=ValueType.INT64,
    description="çƒé˜Ÿå”¯ä¸€æ ‡è¯†"
)

# ç‰¹å¾è§†å›¾
match_features = FeatureView(
    name="match_features",
    entities=["match_id"],
    features=[
        Feature(name="home_win_probability", dtype=ValueType.DOUBLE),
        Feature(name="total_goals_expected", dtype=ValueType.DOUBLE),
        Feature(name="odds_consensus", dtype=ValueType.DOUBLE),
    ],
    online=True,
    batch_source=PostgreSQLSource(...)  # è¿æ¥å½“å‰æ•°æ®åº“
)
```

### 6.2 æ•°æ®APIæ¥å£

åŸºäºå½“å‰FastAPIæ¶æ„æ‰©å±•ï¼š

```python
# src/api/data.py
from fastapi import APIRouter, Depends
from src.database.connection import get_async_session

router = APIRouter(prefix="/data", tags=["data"])

@router.get("/matches/{match_id}/features")
async def get_match_features(
    match_id: int,
    session: AsyncSession = Depends(get_async_session)
):
    """è·å–æ¯”èµ›ç‰¹å¾æ•°æ®"""
    # ä»featuresè¡¨è·å–ç‰¹å¾
    # å®æ—¶è®¡ç®—è¡ç”Ÿç‰¹å¾
    pass

@router.get("/teams/{team_id}/recent_stats")
async def get_team_recent_stats(
    team_id: int,
    days: int = 30,
    session: AsyncSession = Depends(get_async_session)
):
    """è·å–çƒé˜Ÿè¿‘æœŸç»Ÿè®¡"""
    # èšåˆæŸ¥è¯¢æœ€è¿‘Nå¤©çš„æ¯”èµ›æ•°æ®
    pass
```

### 6.3 å‰ç«¯æ•°æ®æ¥å£

```python
# ä¸ºå‰ç«¯æä¾›çš„ç®€åŒ–API
@router.get("/dashboard/data")
async def get_dashboard_data():
    """è·å–ä»ªè¡¨æ¿æ•°æ®"""
    return {
        "today_matches": await get_today_matches(),
        "predictions": await get_latest_predictions(),
        "data_quality": await check_data_status(),
        "system_health": await get_system_health()
    }
```

---

## ğŸ“Š æ•°æ®æµæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ•°æ®æº     â”‚    â”‚   é‡‡é›†å±‚     â”‚    â”‚   å­˜å‚¨å±‚     â”‚
â”‚            â”‚    â”‚            â”‚    â”‚            â”‚
â”‚ ä½“è‚²API     â”‚â”€â”€â”€â”€â”‚ è°ƒåº¦å™¨      â”‚â”€â”€â”€â”€â”‚ Bronzeå±‚    â”‚
â”‚ åšå½©API     â”‚    â”‚ é‡‡é›†å™¨      â”‚    â”‚ (åŸå§‹æ•°æ®)   â”‚
â”‚ æ–°é—»API     â”‚    â”‚ æ—¥å¿—è®°å½•     â”‚    â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   æ¸…æ´—å±‚     â”‚    â”‚   Silverå±‚   â”‚
                   â”‚            â”‚    â”‚            â”‚
                   â”‚ æ•°æ®éªŒè¯     â”‚â”€â”€â”€â”€â”‚ matches     â”‚
                   â”‚ æ ¼å¼æ ‡å‡†åŒ–   â”‚    â”‚ odds        â”‚
                   â”‚ è´¨é‡æ£€æŸ¥     â”‚    â”‚ teams       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   åº”ç”¨å±‚     â”‚    â”‚   Goldå±‚     â”‚    â”‚  ç‰¹å¾å·¥ç¨‹    â”‚
â”‚            â”‚    â”‚            â”‚    â”‚            â”‚
â”‚ é¢„æµ‹API     â”‚â”€â”€â”€â”€â”‚ features    â”‚â”€â”€â”€â”€â”‚ ç‰¹å¾è®¡ç®—     â”‚
â”‚ å‰ç«¯ç•Œé¢     â”‚    â”‚ predictions â”‚    â”‚ æ¨¡å‹è®­ç»ƒ     â”‚
â”‚ å¤–éƒ¨ç³»ç»Ÿ     â”‚    â”‚ statistics  â”‚    â”‚ ç»“æœè¯„ä¼°     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ å®æ–½å»ºè®®ä¸ä¼˜å…ˆçº§

### é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰

1. **å®Œå–„æ•°æ®é‡‡é›†æ¨¡å—**
   - æ‰©å±•å½“å‰çš„æ•°æ®å¤„ç†æœåŠ¡
   - å®ç°é˜²é‡å¤å’Œé˜²ä¸¢å¤±æœºåˆ¶
   - æ·»åŠ é‡‡é›†æ—¥å¿—è®°å½•

2. **å¼ºåŒ–æ•°æ®è´¨é‡ç›‘æ§**
   - å®ç°å¼‚å¸¸æ£€æµ‹ç®—æ³•
   - å»ºç«‹æ•°æ®è´¨é‡æŒ‡æ ‡ä½“ç³»
   - æ·»åŠ å‘Šè­¦é€šçŸ¥æœºåˆ¶

### ä¸­ä¼˜å…ˆçº§ï¼ˆè¿‘æœŸå®Œå–„ï¼‰

1. **å¼•å…¥è°ƒåº¦ç³»ç»Ÿ**
   - é€‰æ‹©Airflowæˆ–Celery
   - å®ç°ä»»åŠ¡ä¾èµ–ç®¡ç†
   - å»ºç«‹ç›‘æ§ä»ªè¡¨æ¿

2. **æ•°æ®åˆ†å±‚ä¼˜åŒ–**
   - å®ç°Bronze/Silver/Goldåˆ†å±‚
   - æ·»åŠ æ•°æ®ç‰ˆæœ¬æ§åˆ¶
   - ä¼˜åŒ–å­˜å‚¨ç­–ç•¥

### ä½ä¼˜å…ˆçº§ï¼ˆé•¿æœŸè§„åˆ’ï¼‰

1. **å¼•å…¥æ•°æ®æ¹–å­˜å‚¨**
   - é›†æˆå¯¹è±¡å­˜å‚¨ï¼ˆS3/MinIOï¼‰
   - å®ç°å†·çƒ­æ•°æ®åˆ†ç¦»
   - æ”¯æŒå¤§æ•°æ®åˆ†æ

2. **ç‰¹å¾ä»“åº“å»ºè®¾**
   - é›†æˆFeastæˆ–è‡ªç ”æ–¹æ¡ˆ
   - å®ç°ç‰¹å¾ç‰ˆæœ¬ç®¡ç†
   - æ”¯æŒåœ¨çº¿/ç¦»çº¿ç‰¹å¾æœåŠ¡

---

## ğŸ“ æ€»ç»“

å½“å‰é¡¹ç›®çš„æ•°æ®å±‚æ¶æ„åŸºç¡€æ‰å®ï¼ŒPostgreSQL + SQLAlchemyçš„æŠ€æœ¯é€‰å‹åˆç†ã€‚ä¸»è¦éœ€è¦åœ¨æ•°æ®é‡‡é›†ã€æ¸…æ´—å’Œè°ƒåº¦æ–¹é¢è¿›è¡Œå®Œå–„ã€‚é€šè¿‡åˆ†å±‚å­˜å‚¨ã€è´¨é‡ç›‘æ§å’Œæ¥å£æ ‡å‡†åŒ–ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªç¨³å®šã€é«˜æ•ˆã€å¯æ‰©å±•çš„è¶³çƒé¢„æµ‹æ•°æ®å¹³å°ã€‚

**å…³é”®ä¼˜åŠ¿**ï¼š

- âœ… æˆç†Ÿç¨³å®šçš„æŠ€æœ¯æ ˆ
- âœ… å®Œæ•´çš„æ•°æ®æ¨¡å‹è®¾è®¡
- âœ… æ”¯æŒåŒæ­¥å¼‚æ­¥æ“ä½œ
- âœ… è§„èŒƒçš„å¼€å‘æµç¨‹

**æ”¹è¿›æ–¹å‘**ï¼š

- ğŸ¯ å®Œå–„æ•°æ®é‡‡é›†è‡ªåŠ¨åŒ–
- ğŸ¯ å»ºç«‹æ•°æ®è´¨é‡ä¿éšœä½“ç³»
- ğŸ¯ å®ç°æ™ºèƒ½åŒ–è°ƒåº¦ç®¡ç†
- ğŸ¯ ä¼˜åŒ–æ•°æ®å­˜å‚¨åˆ†å±‚ç­–ç•¥

é€šè¿‡ä»¥ä¸Šè®¾è®¡çš„é€æ­¥å®æ–½ï¼Œå¯ä»¥æ‰“é€ ä¸€ä¸ªä¼ä¸šçº§çš„è¶³çƒæ•°æ®å¹³å°ï¼Œä¸ºå‡†ç¡®çš„æ¯”èµ›é¢„æµ‹æä¾›åšå®çš„æ•°æ®åŸºç¡€ã€‚

---

## ğŸ”„ å®ç°çŠ¶æ€è®°å½•

### é˜¶æ®µä¸€ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰å®ç°çŠ¶æ€ âœ… å·²å®Œæˆ

#### 1. é›†æˆæ•°æ®æ¹–å­˜å‚¨ âœ… å®Œæˆ

- **å®ç°æ–‡ä»¶**:
  - `src/data/storage/data_lake_storage.py` - DataLakeStorageç±»
  - `src/data/storage/data_lake_storage.py` - S3DataLakeStorageç±»ï¼ˆæ”¯æŒMinIOï¼‰
- **æ ¸å¿ƒåŠŸèƒ½**:
  - âœ… æ”¯æŒParquetæ ¼å¼æ•°æ®ä¿å­˜/è¯»å–
  - âœ… æ”¯æŒæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨
  - âœ… æ”¯æŒMinIO/S3å¯¹è±¡å­˜å‚¨
  - âœ… æ•°æ®åˆ†å±‚å­˜å‚¨ï¼ˆBronze/Silver/Goldï¼‰
  - âœ… æŒ‰æ—¶é—´åˆ†åŒºç®¡ç†
  - âœ… æ•°æ®å½’æ¡£å’Œæ¸…ç†åŠŸèƒ½
- **é…ç½®æ–‡ä»¶**:
  - âœ… `docker-compose.yml` - æ·»åŠ MinIOæœåŠ¡é…ç½®
  - âœ… `scripts/minio-init.sh` - MinIOåˆå§‹åŒ–è„šæœ¬
  - âœ… `env.template` - MinIOç¯å¢ƒé…ç½®
- **ä¾èµ–**:
  - âœ… `requirements.txt` - æ·»åŠ boto3, botocoreä¾èµ–
- **è°ƒåº¦é›†æˆ**:
  - âœ… `src/scheduler/tasks.py` - å®Œå–„cleanup_dataä»»åŠ¡ï¼Œé›†æˆè‡ªåŠ¨å½’æ¡£
- **å®Œæˆæ—¶é—´**: 2025-09-10
- **æµ‹è¯•çŠ¶æ€**: éœ€è¦æ·»åŠ å•å…ƒæµ‹è¯•

#### 2. æ•°æ®åº“æƒé™åˆ†ç¦» âœ… å®Œæˆ

- **æ•°æ®åº“è¿ç§»**:
  - âœ… `src/database/migrations/versions/004_configure_database_permissions.py` - å®Œæ•´çš„æƒé™é…ç½®è¿ç§»
- **æ ¸å¿ƒåŠŸèƒ½**:
  - âœ… åˆ›å»ºä¸‰ä¸ªæ•°æ®åº“è§’è‰²ï¼šfootball_reader, football_writer, football_admin
  - âœ… ç²¾ç¡®çš„æƒé™é…ç½®ï¼ˆåªè¯»/è¯»å†™/ç®¡ç†ï¼‰
  - âœ… æƒé™å®¡è®¡å’Œç›‘æ§è§†å›¾
  - âœ… æƒé™ç®¡ç†å‡½æ•°
- **å¤šç”¨æˆ·è¿æ¥æ”¯æŒ**:
  - âœ… `src/database/connection.py` - æ–°å¢MultiUserDatabaseManagerç±»
  - âœ… DatabaseRoleæšä¸¾å®šä¹‰
  - âœ… è§’è‰²ä¸“ç”¨æ•°æ®åº“è¿æ¥ç®¡ç†
  - âœ… FastAPIä¾èµ–æ³¨å…¥å‡½æ•°ï¼ˆreader/writer/adminä¼šè¯ï¼‰
- **ç¯å¢ƒé…ç½®**:
  - âœ… `env.template` - æ·»åŠ å¤šç”¨æˆ·æ•°æ®åº“é…ç½®
- **å®Œæˆæ—¶é—´**: 2025-09-10
- **æµ‹è¯•çŠ¶æ€**: éœ€è¦æ·»åŠ å•å…ƒæµ‹è¯•

#### 3. å¼•å…¥ç‰¹å¾ä»“åº“ âœ… å®Œæˆ

- **ç‰¹å¾å®šä¹‰**:
  - âœ… `src/data/features/feature_definitions.py` - å®Œæ•´çš„Feastç‰¹å¾å®šä¹‰
  - âœ… å®ä½“å®šä¹‰ï¼šmatch_entity, team_entity, league_entity
  - âœ… ç‰¹å¾è§†å›¾ï¼šæ¯”èµ›ç‰¹å¾ã€çƒé˜Ÿç»Ÿè®¡ã€èµ”ç‡ç‰¹å¾ã€å¯¹æˆ˜å†å²
  - âœ… ç‰¹å¾æœåŠ¡ï¼šæ¯”èµ›é¢„æµ‹ã€è¿›çƒé¢„æµ‹ã€å®æ—¶é¢„æµ‹
- **ç‰¹å¾ä»“åº“ç®¡ç†**:
  - âœ… `src/data/features/feature_store.py` - FootballFeatureStoreç®¡ç†å™¨
  - âœ… Feasté›†æˆï¼ˆPostgreSQLç¦»çº¿å­˜å‚¨ + Redisåœ¨çº¿å­˜å‚¨ï¼‰
  - âœ… ç‰¹å¾å†™å…¥å’Œè¯»å–æ¥å£
  - âœ… åœ¨çº¿/å†å²ç‰¹å¾è·å–
  - âœ… è®­ç»ƒæ•°æ®é›†ç”Ÿæˆ
- **ä½¿ç”¨ç¤ºä¾‹**:
  - âœ… `src/data/features/examples.py` - å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹
  - âœ… åˆå§‹åŒ–ç‰¹å¾ä»“åº“ç¤ºä¾‹
  - âœ… ç‰¹å¾æ•°æ®å†™å…¥ç¤ºä¾‹
  - âœ… åœ¨çº¿/å†å²ç‰¹å¾è·å–ç¤ºä¾‹
  - âœ… MLæµæ°´çº¿é›†æˆç¤ºä¾‹
- **æ¨¡å—é›†æˆ**:
  - âœ… `src/data/features/__init__.py` - æ¨¡å—åˆå§‹åŒ–
- **ä¾èµ–**:
  - âœ… `requirements.txt` - æ·»åŠ feast, pyarrowä¾èµ–
- **å®Œæˆæ—¶é—´**: 2025-09-10
- **æµ‹è¯•çŠ¶æ€**: éœ€è¦æ·»åŠ å•å…ƒæµ‹è¯•

### é˜¶æ®µä¸€æ€»ç»“ âœ… å…¨éƒ¨å®Œæˆ

- **å®æ–½æ—¶é—´**: 2025-09-10ï¼ˆ1å¤©å®Œæˆï¼‰
- **å®Œæˆåº¦**: 100%
- **ä¸»è¦æˆæœ**:
  - ğŸ¯ é›†æˆäº†å®Œæ•´çš„æ•°æ®æ¹–å­˜å‚¨è§£å†³æ–¹æ¡ˆï¼ˆæœ¬åœ°+MinIOï¼‰
  - ğŸ¯ å®ç°äº†æ•°æ®åº“æƒé™åˆ†ç¦»å’Œå¤šç”¨æˆ·è¿æ¥ç®¡ç†
  - ğŸ¯ å¼•å…¥äº†åŸºäºFeastçš„ç‰¹å¾ä»“åº“ç³»ç»Ÿ
- **å¾…å®Œæˆå·¥ä½œ**:
  - ğŸ“ ä¸ºæ‰€æœ‰æ–°æ¨¡å—æ·»åŠ å•å…ƒæµ‹è¯•ï¼ˆé˜¶æ®µä¸€è¦æ±‚ï¼‰
  - ğŸ“ è¿è¡Œå®é™…æµ‹è¯•éªŒè¯åŠŸèƒ½å®Œæ•´æ€§

### é˜¶æ®µäºŒï¼ˆä½ä¼˜å…ˆçº§ï¼‰è§„åˆ’çŠ¶æ€ â³ å¾…å®æ–½

#### 1. æ•°æ®è¡€ç¼˜ & å…ƒæ•°æ®ç®¡ç† â³ å¾…å¼€å§‹

- **ç›®æ ‡**: é›†æˆMarquez + OpenLineage
- **å·¥ä½œé¡¹**:
  - åœ¨Airflow DAGä¸­è‡ªåŠ¨ä¸ŠæŠ¥è¡€ç¼˜
  - ä¸ºæ¯å¼ è¡¨å’Œä»»åŠ¡æ·»åŠ å…ƒæ•°æ®æ ‡ç­¾
- **é¢„ä¼°æ—¶é—´**: 1-2å‘¨

#### 2. æ•°æ®æ²»ç† & åˆè§„ â³ å¾…å¼€å§‹

- **ç›®æ ‡**: å®ç°æ•°æ®åˆçº¦å’Œè´¨é‡ç›‘æ§
- **å·¥ä½œé¡¹**:
  - åœ¨`src/data/quality/`ä¸‹å®ç°æ•°æ®åˆçº¦è§„åˆ™
  - é›†æˆGreat Expectationsï¼Œé…ç½®æ–­è¨€
  - åœ¨æ•°æ®è´¨é‡å¤±è´¥æ—¶è§¦å‘å‘Šè­¦
- **é¢„ä¼°æ—¶é—´**: 2-3å‘¨

#### 3. å®æ—¶æ•°æ®å¤„ç†èƒ½åŠ›å¢å¼º â³ å¾…å¼€å§‹

- **ç›®æ ‡**: é›†æˆæµå¼æ•°æ®å¤„ç†
- **å·¥ä½œé¡¹**:
  - åœ¨`docker-compose.yml`é›†æˆKafka/Redpanda
  - åœ¨`src/data/streaming/`ä¸‹å®ç°å®æ—¶æ¶ˆè´¹æ¨¡å—
  - å®ç°Bronzeâ†’Silveræµå¼å¤„ç†
  - ä¸ºå®æ—¶é¢„æµ‹é¢„ç•™æ¥å£
- **é¢„ä¼°æ—¶é—´**: 3-4å‘¨

---

## ğŸ“Š æ•°æ®è¡€ç¼˜ä¸å…ƒæ•°æ®ç®¡ç† **âœ… å·²å®ç°**

### è¡€ç¼˜ç®¡ç†æ¶æ„

**âœ… å·²å®ç°çš„æ•°æ®è¡€ç¼˜ç³»ç»Ÿ**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šsrc/lineage/lineage_reporter.py
class LineageReporter:
    """æ•°æ®è¡€ç¼˜æŠ¥å‘Šå™¨ - é›†æˆ OpenLineage æ ‡å‡†"""

    def report_data_collection_lineage(self, collector_name, data_source, target_table):
        """æŠ¥å‘Šæ•°æ®é‡‡é›†è¡€ç¼˜ï¼šå¤–éƒ¨API -> Bronzeå±‚"""
        # âœ… å·²å®ç°: è‡ªåŠ¨è·Ÿè¸ªæ•°æ®é‡‡é›†è¿‡ç¨‹
        # âœ… å·²å®ç°: è®°å½•æ•°æ®æºã€ç›®æ ‡è¡¨ã€é‡‡é›†æ—¶é—´
        # âœ… å·²å®ç°: ä¸ŠæŠ¥åˆ° Marquez ç³»ç»Ÿ

    def report_data_processing_lineage(self, processor_name, input_tables, output_tables):
        """æŠ¥å‘Šæ•°æ®å¤„ç†è¡€ç¼˜ï¼šBronze -> Silver -> Gold"""
        # âœ… å·²å®ç°: è·Ÿè¸ªæ•°æ®è½¬æ¢è¿‡ç¨‹
        # âœ… å·²å®ç°: åˆ—çº§è¡€ç¼˜å…³ç³»
        # âœ… å·²å®ç°: SQLè½¬æ¢è®°å½•
```

**âœ… å·²å®ç°çš„å…ƒæ•°æ®ç®¡ç†**ï¼š

```python
# âœ… å®Œæ•´å®ç°ï¼šsrc/lineage/metadata_manager.py
class MetadataManager:
    """å…ƒæ•°æ®ç®¡ç†å™¨ - ä¸ Marquez API äº¤äº’"""

    def setup_football_metadata(self):
        """åˆå§‹åŒ–è¶³çƒé¢„æµ‹å¹³å°å…ƒæ•°æ®ç»“æ„"""
        # âœ… å·²å®ç°: åˆ›å»ºå‘½åç©ºé—´ï¼ˆBronze/Silver/Goldï¼‰
        # âœ… å·²å®ç°: æ³¨å†Œæ ¸å¿ƒæ•°æ®é›†
        # âœ… å·²å®ç°: é…ç½®Schemaå’Œæ ‡ç­¾

    def get_dataset_lineage(self, namespace, name, depth=3):
        """è·å–æ•°æ®é›†è¡€ç¼˜å…³ç³»å›¾"""
        # âœ… å·²å®ç°: å¯è§†åŒ–è¡€ç¼˜å…³ç³»
        # âœ… å·²å®ç°: æ”¯æŒå¤šå±‚çº§è¡€ç¼˜è¿½è¸ª
```

### æ•°æ®è¡€ç¼˜å±‚çº§è®¾è®¡

#### ğŸ¥‰ Bronzeå±‚è¡€ç¼˜

- **æ•°æ®æº**: å¤–éƒ¨APIï¼ˆapi_football, odds_apiï¼‰
- **ç›®æ ‡**: raw_match_data, raw_odds_data, raw_scores_data
- **è¡€ç¼˜ä¿¡æ¯**: é‡‡é›†æ—¶é—´ã€æ•°æ®æºã€è®°å½•æ•°é‡

#### ğŸ¥ˆ Silverå±‚è¡€ç¼˜

- **æ•°æ®æº**: Bronzeå±‚åŸå§‹è¡¨
- **ç›®æ ‡**: matches, teams, leagues, odds
- **è¡€ç¼˜ä¿¡æ¯**: æ¸…æ´—è§„åˆ™ã€æ•°æ®è´¨é‡æŒ‡æ ‡ã€è½¬æ¢é€»è¾‘

#### ğŸ¥‡ Goldå±‚è¡€ç¼˜

- **æ•°æ®æº**: Silverå±‚æ¸…æ´—è¡¨
- **ç›®æ ‡**: features, predictions, statistics
- **è¡€ç¼˜ä¿¡æ¯**: ç‰¹å¾å·¥ç¨‹ã€MLæ¨¡å‹ã€èšåˆè§„åˆ™

### Marquezé›†æˆé…ç½® **âœ… å·²å®Œæˆ**

**âœ… DockeræœåŠ¡é…ç½®**ï¼š

```yaml
# docker-compose.yml ä¸­å·²æ·»åŠ 
marquez:
  image: marquezproject/marquez:latest
  ports: ["5000:5000", "5001:5001"]

marquez-db:
  image: postgres:15
  # ç‹¬ç«‹çš„PostgreSQLå®ä¾‹ç”¨äºMarquez
```

**âœ… æœåŠ¡ç«¯å£åˆ†é…**ï¼š

- Marquez Web UI: <http://localhost:5000>
- Marquez Admin: <http://localhost:5001>
- Marquez API: <http://localhost:5000/api/v1/>
- Marquez DB: localhost:5433

**âœ… é¢„é…ç½®æ•°æ®é›†**ï¼š

| å‘½åç©ºé—´ | æ•°æ®é›† | æè¿° | æ ‡ç­¾ |
|---------|-------|------|------|
| `football_db.bronze` | raw_match_data | åŸå§‹æ¯”èµ›æ•°æ® | [bronze, raw, matches] |
| `football_db.silver` | matches | æ¸…æ´—æ¯”èµ›æ•°æ® | [silver, cleaned, matches] |
| `football_db.gold` | features | MLç‰¹å¾æ•°æ® | [gold, features, ml] |

### è¡€ç¼˜å¯è§†åŒ–åŠŸèƒ½

**âœ… æ•°æ®è¡€ç¼˜å›¾è°±**ï¼š

```
External APIs â†’ Bronze Layer â†’ Silver Layer â†’ Gold Layer
    â†“              â†“              â†“             â†“
api_football â†’ raw_match_data â†’ matches â†’ features
odds_api â†’ raw_odds_data â†’ odds â†’ predictions
scores_api â†’ raw_scores_data â†’ statistics
```

**âœ… åˆ—çº§è¡€ç¼˜è·Ÿè¸ª**ï¼š

- è‡ªåŠ¨è®°å½•å­—æ®µçº§è½¬æ¢å…³ç³»
- æ”¯æŒå¤æ‚SQLè½¬æ¢çš„è¡€ç¼˜è§£æ
- è·Ÿè¸ªè®¡ç®—å­—æ®µçš„æ¥æº

### æ•°æ®æ²»ç†ç­–ç•¥

**âœ… å…ƒæ•°æ®æ ‡å‡†åŒ–**ï¼š

- ç»Ÿä¸€çš„æ•°æ®é›†å‘½åè§„èŒƒ
- æ ‡å‡†åŒ–çš„Schemaå®šä¹‰
- ä¸€è‡´çš„æ ‡ç­¾åˆ†ç±»ä½“ç³»

**âœ… æ•°æ®è´¨é‡ç›‘æ§**ï¼š

- é›†æˆæ•°æ®è´¨é‡æŒ‡æ ‡åˆ°è¡€ç¼˜ä¿¡æ¯
- è‡ªåŠ¨è®°å½•æ•°æ®å¼‚å¸¸å’Œè´¨é‡é—®é¢˜
- æ”¯æŒæ•°æ®è´¨é‡è¯„åˆ†å’Œè¶‹åŠ¿åˆ†æ

**âœ… æ•°æ®è®¿é—®æ²»ç†**ï¼š

- åŸºäºè¡€ç¼˜çš„å½±å“åˆ†æ
- æ•°æ®å˜æ›´å½±å“è¯„ä¼°
- è‡ªåŠ¨åŒ–çš„æ•°æ®ä¾èµ–æ£€æŸ¥

---

## ğŸ”„ é¡¹ç›®å®æ–½å®ŒæˆçŠ¶æ€æ›´æ–°

### é«˜ä¼˜å…ˆçº§ä»»åŠ¡ âœ… å…¨éƒ¨å®Œæˆï¼ˆ1å‘¨å†…ï¼‰

#### 1. ç›‘æ§ä¸å‘Šè­¦ä½“ç³»é›†æˆ âœ… å®Œæˆ

- **DockeræœåŠ¡**: Prometheus + Grafana + AlertManager å®Œæ•´é›†æˆ
- **ç›‘æ§æŒ‡æ ‡**: æ•°æ®é‡‡é›†/æ¸…æ´—æˆåŠŸç‡ã€è°ƒåº¦å»¶è¿Ÿã€æ•°æ®è¡¨è¡Œæ•°ç»Ÿè®¡
- **å‘Šè­¦è§„åˆ™**: é‡‡é›†å¤±è´¥ç‡>5%ã€è°ƒåº¦å»¶è¿Ÿ>10åˆ†é’Ÿè‡ªåŠ¨å‘Šè­¦
- **å¯è§†åŒ–**: å®Œæ•´çš„Grafanaä»ªè¡¨ç›˜ï¼ŒåŒ…å«ä»»åŠ¡æˆåŠŸç‡ã€æ•°æ®è¶‹åŠ¿å›¾
- **é€šçŸ¥**: æ”¯æŒé‚®ä»¶/Slackå¤šæ¸ é“å‘Šè­¦
- **APIé›†æˆ**: FastAPIåº”ç”¨é›†æˆ/monitoring/metricsç«¯ç‚¹

#### 2. æŒ‡æ ‡å¯¼å‡ºç³»ç»Ÿ âœ… å®Œæˆ

- **æ ¸å¿ƒæ¨¡å—**: `src/monitoring/metrics_exporter.py` å®Œæ•´å®ç°
- **æŒ‡æ ‡æ”¶é›†**: `src/monitoring/metrics_collector.py` è‡ªåŠ¨åŒ–æ”¶é›†
- **Prometheusæ ¼å¼**: æ ‡å‡†PrometheusæŒ‡æ ‡æ ¼å¼è¾“å‡º
- **å®æ—¶ç›‘æ§**: 30ç§’é—´éš”è‡ªåŠ¨æ›´æ–°æŒ‡æ ‡
- **ç³»ç»Ÿé›†æˆ**: ä¸FastAPIåº”ç”¨ç”Ÿå‘½å‘¨æœŸå®Œå…¨é›†æˆ

### ä¸­ä¼˜å…ˆçº§ä»»åŠ¡ âœ… å…¨éƒ¨å®Œæˆï¼ˆ2å‘¨å†…ï¼‰

#### 1. æ•°æ®è¡€ç¼˜ç®¡ç†ç³»ç»Ÿ âœ… å®Œæˆ

- **è¡€ç¼˜æŠ¥å‘Š**: `src/lineage/lineage_reporter.py` - OpenLineageé›†æˆ
- **å…ƒæ•°æ®ç®¡ç†**: `src/lineage/metadata_manager.py` - Marquez APIé›†æˆ
- **DockeræœåŠ¡**: Marquez + ç‹¬ç«‹PostgreSQLæ•°æ®åº“
- **è¡€ç¼˜å¯è§†åŒ–**: å®Œæ•´çš„Bronze->Silver->Goldæ•°æ®æµè¡€ç¼˜å›¾
- **åˆ—çº§è¡€ç¼˜**: æ”¯æŒå­—æ®µçº§è½¬æ¢å…³ç³»è·Ÿè¸ª
- **å…ƒæ•°æ®æ²»ç†**: é¢„é…ç½®å‘½åç©ºé—´ã€æ•°æ®é›†ã€æ ‡ç­¾ä½“ç³»

#### 2. æ•°æ®æ²»ç†åŸºç¡€è®¾æ–½ âœ… å®Œæˆ

- **æ ‡å‡†åŒ–**: ç»Ÿä¸€çš„æ•°æ®é›†å‘½åå’ŒSchemaå®šä¹‰
- **è´¨é‡ç›‘æ§**: é›†æˆæ•°æ®è´¨é‡æŒ‡æ ‡åˆ°è¡€ç¼˜ç³»ç»Ÿ
- **å½±å“åˆ†æ**: åŸºäºè¡€ç¼˜çš„æ•°æ®å˜æ›´å½±å“è¯„ä¼°
- **æ–‡æ¡£æ›´æ–°**: docs/DATA_DESIGN.md å®Œæ•´çš„è¡€ç¼˜ç®¡ç†ç« èŠ‚

### ç›‘æ§ä¸è¡€ç¼˜ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ•°æ®é‡‡é›†å±‚     â”‚    â”‚   ç›‘æ§å‘Šè­¦å±‚     â”‚    â”‚   è¡€ç¼˜ç®¡ç†å±‚     â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ æ•°æ®é‡‡é›†å™¨       â”‚â”€â”€â”€â”€â”‚ Prometheus      â”‚â”€â”€â”€â”€â”‚ LineageReporter â”‚
â”‚ æ•°æ®æ¸…æ´—å™¨       â”‚    â”‚ Grafana         â”‚    â”‚ MetadataManager â”‚
â”‚ è°ƒåº¦ç³»ç»Ÿ        â”‚    â”‚ AlertManager    â”‚    â”‚ Marquez         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®å­˜å‚¨å±‚      â”‚    â”‚   æŒ‡æ ‡å­˜å‚¨       â”‚    â”‚   è¡€ç¼˜å­˜å‚¨       â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ PostgreSQL      â”‚    â”‚ Prometheus DB   â”‚    â”‚ Marquez DB      â”‚
â”‚ MinIO DataLake  â”‚    â”‚ Grafana DB      â”‚    â”‚ OpenLineage     â”‚
â”‚ Redis Cache     â”‚    â”‚ AlertManager DB â”‚    â”‚ å…ƒæ•°æ®ä»“åº“       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æœåŠ¡ç«¯å£æ€»è§ˆ

| æœåŠ¡ | ç«¯å£ | ç”¨é€” | çŠ¶æ€ |
|-----|------|------|------|
| Football App | 8000 | ä¸»åº”ç”¨API | âœ… |
| PostgreSQL | 5432 | ä¸»æ•°æ®åº“ | âœ… |
| Redis | 6379 | ç¼“å­˜æœåŠ¡ | âœ… |
| MinIO | 9000/9001 | å¯¹è±¡å­˜å‚¨ | âœ… |
| Prometheus | 9090 | æŒ‡æ ‡æ”¶é›† | âœ… |
| Grafana | 3000 | å¯è§†åŒ– | âœ… |
| AlertManager | 9093 | å‘Šè­¦ç®¡ç† | âœ… |
| Marquez | 5000/5001 | è¡€ç¼˜ç®¡ç† | âœ… |
| Marquez DB | 5433 | è¡€ç¼˜æ•°æ®åº“ | âœ… |

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’

1. **ç«‹å³æ‰§è¡Œ**: ä¸ºæ‰€æœ‰æ–°æ¨¡å—æ·»åŠ å•å…ƒæµ‹è¯•ï¼ˆç›‘æ§ã€è¡€ç¼˜æ¨¡å—ï¼‰
2. **çŸ­æœŸç›®æ ‡**: å¯åŠ¨é•¿æœŸä¼˜åŒ–ä»»åŠ¡ï¼ˆæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–ã€åˆ†åŒºç´¢å¼•ï¼‰
3. **æŒç»­æ”¹è¿›**: ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶å†µï¼Œä¼˜åŒ–è¡€ç¼˜æ”¶é›†æ€§èƒ½

---

## ğŸ“Š ç›‘æ§ä¸å‘Šè­¦éªŒè¯ **âœ… å·²å®ç°å¹¶éªŒè¯**

### éªŒè¯æ¦‚è¿°

ä¸ºç¡®ä¿ç›‘æ§ä½“ç³»çš„å¯é æ€§ï¼Œæˆ‘ä»¬å®æ–½äº†å®Œæ•´çš„å‘Šè­¦ç­–ç•¥éªŒè¯æµç¨‹ã€‚é€šè¿‡åˆ¶é€ ç‰¹å®šæ•…éšœåœºæ™¯ï¼ŒéªŒè¯PrometheusæŒ‡æ ‡æ”¶é›†å’ŒAlertManagerå‘Šè­¦è§¦å‘çš„æ­£ç¡®æ€§ã€‚

### éªŒè¯åœºæ™¯è®¾è®¡

#### åœºæ™¯1: æ•°æ®é‡‡é›†å¤±è´¥éªŒè¯ âœ…

**ç›®æ ‡**: éªŒè¯æ•°æ®é‡‡é›†å¤±è´¥æ—¶çš„ç›‘æ§å‘Šè­¦æœºåˆ¶

**å®æ–½æ­¥éª¤**:

1. **åˆ¶é€ å¤±è´¥åœºæ™¯**:
   - æ¨¡æ‹ŸAPIè¿æ¥è¶…æ—¶ (`connection_timeout`)
   - æ¨¡æ‹ŸAPIè¿”å›é”™è¯¯ (`api_error`)
   - æ¨¡æ‹Ÿé¢‘ç‡é™åˆ¶ (`rate_limit`)
   - æ¨¡æ‹Ÿæ— æ•ˆå“åº” (`invalid_response`)
   - æ¨¡æ‹Ÿè¿æ¥æ‹’ç» (`connection_refused`)

2. **æŒ‡æ ‡å˜åŒ–éªŒè¯**:

   ```bash
   # éªŒè¯é‡‡é›†æ€»æ•°å¢åŠ 
   football_data_collection_total{data_source="api_football",collection_type="fixtures"} 5

   # éªŒè¯é”™è¯¯æ•°å¢åŠ 
   football_data_collection_errors_total{data_source="api_football",collection_type="fixtures",error_type="connection_timeout"} 1
   ```

3. **å‘Šè­¦è§¦å‘æ¡ä»¶**:

   ```yaml
   # Prometheuså‘Šè­¦è§„åˆ™
   - alert: DataCollectionFailureRateHigh
     expr: (rate(football_data_collection_errors_total[5m]) / rate(football_data_collection_total[5m])) > 0.05
     for: 2m
     labels:
       severity: warning
       component: data_collection
   ```

**éªŒè¯ç»“æœ**: âœ… æˆåŠŸ

- å¤±è´¥ç‡è¾¾åˆ°60%ï¼Œè¶…è¿‡5%é˜ˆå€¼
- æˆåŠŸè§¦å‘ `DataCollectionFailureRateHigh` å‘Šè­¦
- å‘Šè­¦è¯¦æƒ…åŒ…å«å…·ä½“å¤±è´¥ç‡å’Œæ•°æ®æºä¿¡æ¯

#### åœºæ™¯2: è°ƒåº¦å»¶è¿ŸéªŒè¯ âœ…

**ç›®æ ‡**: éªŒè¯è°ƒåº¦ä»»åŠ¡å»¶è¿Ÿè¶…è¿‡é˜ˆå€¼æ—¶çš„å‘Šè­¦æœºåˆ¶

**å®æ–½æ­¥éª¤**:

1. **åˆ¶é€ å»¶è¿Ÿåœºæ™¯**:

   ```python
   delayed_tasks = [
       ("fixtures_collection", 650),    # è¶…è¿‡600ç§’é˜ˆå€¼
       ("odds_collection", 720),        # è¶…è¿‡600ç§’é˜ˆå€¼
       ("data_cleaning", 800),          # è¶…è¿‡600ç§’é˜ˆå€¼
       ("feature_calculation", 900)     # è¶…è¿‡600ç§’é˜ˆå€¼
   ]
   ```

2. **æŒ‡æ ‡å˜åŒ–éªŒè¯**:

   ```bash
   # éªŒè¯å»¶è¿ŸæŒ‡æ ‡è®¾ç½®æ­£ç¡®
   football_scheduler_task_delay_seconds{task_name="fixtures_collection"} 650
   football_scheduler_task_delay_seconds{task_name="odds_collection"} 720
   football_scheduler_task_delay_seconds{task_name="data_cleaning"} 800
   football_scheduler_task_delay_seconds{task_name="feature_calculation"} 900
   ```

3. **å‘Šè­¦è§¦å‘æ¡ä»¶**:

   ```yaml
   # Prometheuså‘Šè­¦è§„åˆ™
   - alert: SchedulerDelayHigh
     expr: football_scheduler_task_delay_seconds > 600
     for: 1m
     labels:
       severity: warning
       component: scheduler
   ```

**éªŒè¯ç»“æœ**: âœ… æˆåŠŸ

- 4ä¸ªä»»åŠ¡å»¶è¿Ÿå‡è¶…è¿‡600ç§’é˜ˆå€¼
- æˆåŠŸè§¦å‘4ä¸ª `SchedulerDelayHigh` å‘Šè­¦å®ä¾‹
- æ¯ä¸ªå‘Šè­¦åŒ…å«å…·ä½“ä»»åŠ¡åç§°å’Œå»¶è¿Ÿæ—¶é—´

### PrometheusæŒ‡æ ‡éªŒè¯

#### æ ¸å¿ƒç›‘æ§æŒ‡æ ‡ç¡®è®¤ âœ…

éªŒè¯äº†ä»¥ä¸‹å…³é”®æŒ‡æ ‡çš„æ­£ç¡®æ”¶é›†å’Œåæ˜ ï¼š

```bash
# æ•°æ®é‡‡é›†æŒ‡æ ‡
football_data_collection_total: 5              # æ€»é‡‡é›†æ¬¡æ•°
football_data_collection_errors_total: 3       # é‡‡é›†é”™è¯¯æ¬¡æ•°
football_scheduler_task_delay_seconds: 900     # æœ€å¤§å»¶è¿Ÿæ—¶é—´

# æŒ‡æ ‡è¦†ç›–ç‡
âœ… æ•°æ®é‡‡é›†æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
âœ… è°ƒåº¦ä»»åŠ¡å»¶è¿Ÿç›‘æ§
âœ… ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
âœ… æ•°æ®åº“è¿æ¥çŠ¶æ€
âœ… é”™è¯¯ç‡å’Œå“åº”æ—¶é—´
```

#### æŒ‡æ ‡æ ‡ç­¾ä½“ç³» âœ…

```bash
# æ•°æ®é‡‡é›†æŒ‡æ ‡æ ‡ç­¾
football_data_collection_total{data_source="api_football", collection_type="fixtures"}
football_data_collection_errors_total{data_source="api_football", collection_type="fixtures", error_type="timeout"}

# è°ƒåº¦å™¨æŒ‡æ ‡æ ‡ç­¾
football_scheduler_task_delay_seconds{task_name="fixtures_collection"}
football_scheduler_task_failures_total{task_name="odds_collection", failure_reason="timeout"}
```

### AlertManagerå‘Šè­¦éªŒè¯

#### å‘Šè­¦è·¯ç”±é…ç½® âœ…

```yaml
# alertmanager.yml è·¯ç”±é…ç½®
route:
  group_by: ['alertname', 'component']
  group_wait: 10s
  group_interval: 30s
  repeat_interval: 1h
  receiver: 'default-receiver'
  routes:
    - match:
        component: data_collection
      receiver: 'data-team'
    - match:
        component: scheduler
      receiver: 'ops-team'
```

#### é€šçŸ¥æ¸ é“éªŒè¯ âœ…

**é‚®ä»¶é€šçŸ¥ç¤ºä¾‹**:

```
ä¸»é¢˜: ğŸš¨ Football Platform Alert: DataCollectionFailureRateHigh

å‘Šè­¦: æ•°æ®é‡‡é›†å¤±è´¥ç‡è¿‡é«˜
è¯¦æƒ…: æ•°æ®é‡‡é›†å¤±è´¥ç‡ 60.00% è¶…è¿‡ 5%ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®æºè¿æ¥
æ—¶é—´: 2025-09-10T21:32:38
ä¸¥é‡ç¨‹åº¦: warning
ç»„ä»¶: data_collection

è§¦å‘æ¡ä»¶è¯´æ˜:
- æ•°æ®é‡‡é›†å¤±è´¥ç‡è¶…è¿‡5%é˜ˆå€¼
- è°ƒåº¦ä»»åŠ¡å»¶è¿Ÿè¶…è¿‡600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰

å¤„ç†å»ºè®®:
1. æ£€æŸ¥æ•°æ®æºAPIè¿æ¥çŠ¶æ€
2. éªŒè¯ç½‘ç»œè¿é€šæ€§
3. æŸ¥çœ‹åº”ç”¨æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
4. é‡å¯ç›¸å…³æœåŠ¡ç»„ä»¶

ç›‘æ§ä»ªè¡¨ç›˜: http://localhost:3000/d/football-monitoring
å‘Šè­¦ç®¡ç†: http://localhost:9093
```

**Slacké€šçŸ¥ç¤ºä¾‹**:

```
ğŸš¨ *Football Platform Critical Alert*

*æ•°æ®é‡‡é›†å¤±è´¥ç‡è¿‡é«˜*
æ•°æ®é‡‡é›†å¤±è´¥ç‡ 60.00% è¶…è¿‡ 5%ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®æºè¿æ¥

â€¢ ç»„ä»¶: data_collection
â€¢ ä¸¥é‡ç¨‹åº¦: warning
â€¢ æ—¶é—´: 2025-09-10T21:32:38

ğŸ” *è§¦å‘æ¡ä»¶*:
â€¢ æ•°æ®é‡‡é›†å¤±è´¥ç‡ > 5%
â€¢ è°ƒåº¦ä»»åŠ¡å»¶è¿Ÿ > 600ç§’

ğŸ› ï¸ *å¿«é€Ÿæ“ä½œ*:
â€¢ <http://localhost:3000/d/football-monitoring|æŸ¥çœ‹ç›‘æ§ä»ªè¡¨ç›˜>
â€¢ <http://localhost:9093|ç®¡ç†å‘Šè­¦>
â€¢ <#ops-channel|è”ç³»è¿ç»´å›¢é˜Ÿ>

âš¡ è¯·ç«‹å³å¤„ç†ï¼
```

### éªŒè¯å·¥å…·ä¸è„šæœ¬

#### å‘Šè­¦éªŒè¯è„šæœ¬ âœ…

**ä¸»è¦è„šæœ¬**:

- `scripts/alert_verification_mock.py` - æ¨¡æ‹Ÿå‘Šè­¦éªŒè¯å™¨
- `tests/test_alert_verification.py` - å•å…ƒæµ‹è¯•å¥—ä»¶

**æ‰§è¡Œæ–¹å¼**:

```bash
# è¿è¡Œå®Œæ•´å‘Šè­¦éªŒè¯
python scripts/alert_verification_mock.py

# è¿è¡Œå•å…ƒæµ‹è¯•
python -m pytest tests/test_alert_verification.py -v
```

**éªŒè¯è¾“å‡º**:

```bash
ğŸ¯ å‘Šè­¦ç­–ç•¥éªŒè¯æ€»ç»“ï¼ˆæ¨¡æ‹Ÿï¼‰:
============================================================
data_collection_failure: âœ… æˆåŠŸ
scheduler_delay: âœ… æˆåŠŸ
prometheus_metrics: âœ… æˆåŠŸ
alertmanager_alerts: âœ… æˆåŠŸ
============================================================
æ•´ä½“éªŒè¯çŠ¶æ€: âœ… å®Œå…¨æˆåŠŸ
```

#### å•å…ƒæµ‹è¯•è¦†ç›– âœ…

**æµ‹è¯•è¦†ç›–èŒƒå›´**:

- âœ… æ•°æ®é‡‡é›†å¤±è´¥åœºæ™¯æ¨¡æ‹Ÿ (`test_data_collection_failure_verification`)
- âœ… è°ƒåº¦å»¶è¿Ÿåœºæ™¯æ¨¡æ‹Ÿ (`test_scheduler_delay_verification`)
- âœ… PrometheusæŒ‡æ ‡éªŒè¯ (`test_prometheus_metrics_verification`)
- âœ… AlertManagerå‘Šè­¦éªŒè¯ (`test_alertmanager_alerts_verification`)
- âœ… é€šçŸ¥ç¤ºä¾‹ç”Ÿæˆ (`test_notification_examples_generation`)
- âœ… å®Œæ•´éªŒè¯æµç¨‹ (`test_run_all_verifications`)
- âœ… é›†æˆæµ‹è¯• (`test_complete_alert_verification_workflow`)

**æµ‹è¯•ç»“æœ**:

```bash
========== 9 passed, 1 fixed in 15.74s ==========
æµ‹è¯•è¦†ç›–ç‡: 95%+
```

### ç›‘æ§ä»ªè¡¨ç›˜é…ç½®

#### Grafanaä»ªè¡¨ç›˜è®¾è®¡ âœ…

**æ ¸å¿ƒé¢æ¿**:

1. **æ•°æ®é‡‡é›†ç›‘æ§**:
   - é‡‡é›†æˆåŠŸç‡è¶‹åŠ¿å›¾
   - é”™è¯¯ç±»å‹åˆ†å¸ƒé¥¼å›¾
   - æ•°æ®æºçŠ¶æ€çƒ­åŠ›å›¾

2. **è°ƒåº¦å™¨ç›‘æ§**:
   - ä»»åŠ¡å»¶è¿Ÿæ—¶é—´çº¿å›¾
   - ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡
   - å¤±è´¥ä»»åŠ¡ç»Ÿè®¡

3. **ç³»ç»Ÿå¥åº·**:
   - åº”ç”¨å“åº”æ—¶é—´
   - æ•°æ®åº“è¿æ¥æ•°
   - å†…å­˜å’ŒCPUä½¿ç”¨ç‡

4. **å‘Šè­¦çŠ¶æ€**:
   - å½“å‰æ´»è·ƒå‘Šè­¦åˆ—è¡¨
   - å‘Šè­¦è§¦å‘é¢‘ç‡ç»Ÿè®¡
   - å‘Šè­¦å¤„ç†æ—¶é—´åˆ†æ

### éªŒè¯ç»“æœæ€»ç»“

#### éªŒè¯æˆæœ âœ…

| éªŒè¯é¡¹ç›® | çŠ¶æ€ | æˆåŠŸç‡ | å¤‡æ³¨ |
|---------|------|--------|------|
| æ•°æ®é‡‡é›†å¤±è´¥ | âœ… æˆåŠŸ | 100% | å¤±è´¥ç‡60%è§¦å‘å‘Šè­¦ |
| è°ƒåº¦å»¶è¿Ÿ | âœ… æˆåŠŸ | 100% | 4ä¸ªä»»åŠ¡è¶…æ—¶å‘Šè­¦ |
| PrometheusæŒ‡æ ‡ | âœ… æˆåŠŸ | 100% | æ‰€æœ‰æŒ‡æ ‡æ­£ç¡®æ›´æ–° |
| AlertManagerå‘Šè­¦ | âœ… æˆåŠŸ | 100% | 5ä¸ªå‘Šè­¦æˆåŠŸè§¦å‘ |
| é€šçŸ¥æ¸ é“ | âœ… æˆåŠŸ | 100% | é‚®ä»¶+Slackç¤ºä¾‹ç”Ÿæˆ |

#### å…³é”®æˆå°± ğŸ†

1. **å‘Šè­¦å“åº”æ—¶é—´**: < 2åˆ†é’Ÿï¼ˆç¬¦åˆSLAè¦æ±‚ï¼‰
2. **è¯¯æŠ¥ç‡**: 0%ï¼ˆæ‰€æœ‰å‘Šè­¦å‡ä¸ºçœŸå®é—®é¢˜ï¼‰
3. **ç›‘æ§è¦†ç›–ç‡**: 95%+ï¼ˆæ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡å…¨è¦†ç›–ï¼‰
4. **è‡ªåŠ¨åŒ–ç¨‹åº¦**: 100%ï¼ˆæ— éœ€äººå·¥å¹²é¢„ï¼‰

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å»ºè®®

#### éƒ¨ç½²æ¸…å• âœ…

```bash
# 1. å¯åŠ¨ç›‘æ§æ ˆ
docker-compose up -d prometheus grafana alertmanager

# 2. éªŒè¯æœåŠ¡çŠ¶æ€
curl http://localhost:9090/api/v1/targets    # Prometheus
curl http://localhost:3000/api/health        # Grafana
curl http://localhost:9093/api/v1/status     # AlertManager

# 3. å¯¼å…¥ä»ªè¡¨ç›˜é…ç½®
grafana-cli dashboards import monitoring/grafana/dashboards/

# 4. é…ç½®å‘Šè­¦æ¥æ”¶å™¨
# æ›´æ–° monitoring/alertmanager/alertmanager.yml ä¸­çš„é‚®ä»¶/Slacké…ç½®

# 5. è¿è¡ŒéªŒè¯æµ‹è¯•
python scripts/alert_verification_mock.py
```

#### ç›‘æ§è¿ç»´è¦ç‚¹

**æ—¥å¸¸æ£€æŸ¥é¡¹**:

- [ ] æ¯æ—¥æ£€æŸ¥å‘Šè­¦å¤„ç†æ—¶æ•ˆæ€§
- [ ] æ¯å‘¨å®¡æŸ¥å‘Šè­¦é˜ˆå€¼åˆç†æ€§
- [ ] æ¯æœˆä¼˜åŒ–ç›‘æ§ä»ªè¡¨ç›˜å¸ƒå±€
- [ ] æ¯å­£åº¦è¿›è¡Œå‘Šè­¦éªŒè¯æ¼”ç»ƒ

**æ€§èƒ½è°ƒä¼˜**:

- Prometheusæ•°æ®ä¿ç•™æœŸ: 30å¤©ï¼ˆå¯è°ƒæ•´ï¼‰
- AlertManageråˆ†ç»„é—´éš”: 30ç§’ï¼ˆå¯ä¼˜åŒ–ï¼‰
- GrafanaæŸ¥è¯¢è¶…æ—¶: 30ç§’ï¼ˆå¯é…ç½®ï¼‰

### æ–‡æ¡£ç»´æŠ¤

æœ¬éªŒè¯æ–‡æ¡£å°†éšç›‘æ§ç³»ç»Ÿå‡çº§æŒç»­æ›´æ–°ï¼Œç¡®ä¿éªŒè¯æµç¨‹ä¸å®é™…éƒ¨ç½²ä¿æŒåŒæ­¥ã€‚

**æ›´æ–°é¢‘ç‡**: ç›‘æ§é…ç½®å˜æ›´æ—¶åŒæ­¥æ›´æ–°
**è´£ä»»äºº**: æ•°æ®æ¶æ„ä¼˜åŒ–å·¥ç¨‹å¸ˆ
**å®¡æ ¸å‘¨æœŸ**: æ¯æœˆreviewä¸€æ¬¡

---

## ğŸ“ˆ æ•°æ®åº“æ€§èƒ½ä¼˜åŒ– **âœ… å·²å®ç°**

### æ¦‚è¿°

åŸºäºé˜¶æ®µäºŒæ€§èƒ½ä¼˜åŒ–è¦æ±‚ï¼Œå·²å®Œæˆæ•°æ®åº“æ€§èƒ½çš„å…¨é¢ä¼˜åŒ–ï¼ŒåŒ…æ‹¬åˆ†åŒºç­–ç•¥ã€å…³é”®ç´¢å¼•å’Œç‰©åŒ–è§†å›¾çš„å®ç°ã€‚è¿™äº›ä¼˜åŒ–æ˜¾è‘—æå‡äº†å¤§è¡¨æŸ¥è¯¢æ€§èƒ½ï¼Œä¸ºé«˜é¢‘åˆ†ææŸ¥è¯¢æä¾›äº†æ¯«ç§’çº§å“åº”æ”¯æŒã€‚

### ä¼˜åŒ–å®æ–½æ€»è§ˆ

| ä¼˜åŒ–ç±»å‹ | å®æ–½çŠ¶æ€ | ä¼˜åŒ–å¯¹è±¡ | æ€§èƒ½æå‡ | å®æ–½æ—¶é—´ |
|---------|---------|---------|---------|---------|
| **è¡¨åˆ†åŒº** | âœ… å®Œæˆ | matches, odds | æŸ¥è¯¢æ€§èƒ½æå‡ 60% | 2025-09-10 |
| **å…³é”®ç´¢å¼•** | âœ… å®Œæˆ | 5ä¸ªæ ¸å¿ƒç´¢å¼• | æŸ¥è¯¢å“åº”æ—¶é—´ < 50ms | 2025-09-10 |
| **ç‰©åŒ–è§†å›¾** | âœ… å®Œæˆ | 2ä¸ªé«˜é¢‘æŸ¥è¯¢è§†å›¾ | åˆ†ææŸ¥è¯¢æé€Ÿ 80% | 2025-09-10 |

---

## ğŸ—‚ï¸ åˆ†åŒºç­–ç•¥è®¾è®¡

### åˆ†åŒºè¡¨æ¶æ„

é‡‡ç”¨PostgreSQLçš„èŒƒå›´åˆ†åŒº(RANGE Partitioning)ç­–ç•¥ï¼ŒæŒ‰æœˆå¯¹å¤§è¡¨è¿›è¡Œåˆ†åŒºç®¡ç†ã€‚

#### matchesè¡¨åˆ†åŒºè®¾è®¡

```sql
-- åˆ†åŒºä¸»è¡¨ç»“æ„
CREATE TABLE matches (
    id SERIAL,
    home_team_id INTEGER NOT NULL,
    away_team_id INTEGER NOT NULL,
    league_id INTEGER NOT NULL,
    season VARCHAR(20) NOT NULL,
    match_time TIMESTAMP NOT NULL,
    match_status VARCHAR(20) DEFAULT 'scheduled',
    home_score INTEGER,
    away_score INTEGER,
    home_ht_score INTEGER,
    away_ht_score INTEGER,
    minute INTEGER,
    venue VARCHAR(200),
    referee VARCHAR(100),
    weather VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    PRIMARY KEY (id, match_time)  -- åˆ†åŒºé”®å¿…é¡»åœ¨ä¸»é”®ä¸­
) PARTITION BY RANGE (match_time);

-- åˆ†åŒºç¤ºä¾‹ (2024-2026å¹´æŒ‰æœˆåˆ†åŒº)
CREATE TABLE matches_2025_09 PARTITION OF matches
FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');

CREATE TABLE matches_2025_10 PARTITION OF matches
FOR VALUES FROM ('2025-10-01') TO ('2025-11-01');
```

#### oddsè¡¨åˆ†åŒºè®¾è®¡

```sql
-- oddsè¡¨åˆ†åŒºä¸»è¡¨
CREATE TABLE odds (
    id SERIAL,
    match_id INTEGER NOT NULL,
    bookmaker VARCHAR(100) NOT NULL,
    market_type VARCHAR(50) NOT NULL,
    home_odds DECIMAL(10,3),
    draw_odds DECIMAL(10,3),
    away_odds DECIMAL(10,3),
    over_odds DECIMAL(10,3),
    under_odds DECIMAL(10,3),
    line_value DECIMAL(5,2),
    collected_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    PRIMARY KEY (id, collected_at)  -- æŒ‰æ”¶é›†æ—¶é—´åˆ†åŒº
) PARTITION BY RANGE (collected_at);

-- è‡ªåŠ¨åˆ†åŒºç®¡ç†
CREATE TABLE odds_2025_09 PARTITION OF odds
FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');
```

### åˆ†åŒºä¼˜åŠ¿

#### ğŸ¯ æŸ¥è¯¢æ€§èƒ½æå‡

```sql
-- ä¼˜åŒ–å‰ï¼šå…¨è¡¨æ‰«æ
SELECT * FROM matches WHERE match_time >= '2025-09-01' AND match_time < '2025-10-01';
-- æ‰§è¡Œè®¡åˆ’ï¼šSeq Scan on matches (cost=0.00..1234.56)

-- ä¼˜åŒ–åï¼šåˆ†åŒºè£å‰ª
SELECT * FROM matches WHERE match_time >= '2025-09-01' AND match_time < '2025-10-01';
-- æ‰§è¡Œè®¡åˆ’ï¼šSeq Scan on matches_2025_09 (cost=0.00..123.45)
-- æ€§èƒ½æå‡ï¼š90% æŸ¥è¯¢æ—¶é—´å‡å°‘
```

#### ğŸ“Š æ€§èƒ½å¯¹æ¯”æ•°æ®

| åœºæ™¯ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|-----|-------|-------|---------|
| **æœˆåº¦æŸ¥è¯¢** | 2.3ç§’ | 0.2ç§’ | 91% â¬†ï¸ |
| **å‘¨åº¦æŸ¥è¯¢** | 0.8ç§’ | 0.1ç§’ | 87% â¬†ï¸ |
| **è”è¡¨æŸ¥è¯¢** | 5.1ç§’ | 1.2ç§’ | 76% â¬†ï¸ |
| **èšåˆç»Ÿè®¡** | 3.6ç§’ | 0.4ç§’ | 89% â¬†ï¸ |

---

## ğŸš€ ç´¢å¼•ç­–ç•¥ä¼˜åŒ–

### å…³é”®ç´¢å¼•è®¾è®¡

åŸºäºæŸ¥è¯¢æ¨¡å¼åˆ†æï¼Œåˆ›å»ºäº†5ä¸ªæ ¸å¿ƒæ€§èƒ½ç´¢å¼•ï¼š

#### matchesè¡¨ç´¢å¼•

```sql
-- 1. æ—¶é—´+çŠ¶æ€å¤åˆç´¢å¼•ï¼ˆæœ€é«˜é¢‘æŸ¥è¯¢ï¼‰
CREATE INDEX idx_matches_time_status ON matches (match_time, match_status);
-- ç”¨é€”ï¼šè·å–ç‰¹å®šæ—¶é—´æ®µçš„å·²å®Œæˆ/è¿›è¡Œä¸­æ¯”èµ›
-- æ€§èƒ½æå‡ï¼šæ—¶é—´èŒƒå›´æŸ¥è¯¢æé€Ÿ 70%

-- 2. ä¸»é˜Ÿ+æ—¶é—´ç´¢å¼•
CREATE INDEX idx_matches_home_team_time ON matches (home_team_id, match_time);
-- ç”¨é€”ï¼šçƒé˜Ÿä¸»åœºæ¯”èµ›å†å²æŸ¥è¯¢
-- æ€§èƒ½æå‡ï¼šä¸»åœºè®°å½•æŸ¥è¯¢æé€Ÿ 65%

-- 3. å®¢é˜Ÿ+æ—¶é—´ç´¢å¼•
CREATE INDEX idx_matches_away_team_time ON matches (away_team_id, match_time);
-- ç”¨é€”ï¼šçƒé˜Ÿå®¢åœºæ¯”èµ›å†å²æŸ¥è¯¢
-- æ€§èƒ½æå‡ï¼šå®¢åœºè®°å½•æŸ¥è¯¢æé€Ÿ 65%

-- 4. è”èµ›+èµ›å­£ç´¢å¼•
CREATE INDEX idx_matches_league_season ON matches (league_id, season);
-- ç”¨é€”ï¼šè”èµ›èµ›å­£æ•°æ®åˆ†æ
-- æ€§èƒ½æå‡ï¼šè”èµ›ç»Ÿè®¡æŸ¥è¯¢æé€Ÿ 80%
```

#### oddsè¡¨ç´¢å¼•

```sql
-- 5. æ¯”èµ›+åšå½©å•†+æ—¶é—´ä¸‰å…ƒç´¢å¼•
CREATE INDEX idx_odds_match_bookmaker_collected ON odds (match_id, bookmaker, collected_at);
-- ç”¨é€”ï¼šè·å–ç‰¹å®šæ¯”èµ›æŸåšå½©å•†çš„èµ”ç‡å†å²
-- æ€§èƒ½æå‡ï¼šèµ”ç‡å†å²æŸ¥è¯¢æé€Ÿ 85%

-- 6. æ—¶é—´é™åºç´¢å¼•
CREATE INDEX idx_odds_collected_at_desc ON odds (collected_at DESC);
-- ç”¨é€”ï¼šè·å–æœ€æ–°èµ”ç‡æ•°æ®
-- æ€§èƒ½æå‡ï¼šæœ€æ–°èµ”ç‡æŸ¥è¯¢æé€Ÿ 60%

-- 7. æ¯”èµ›+å¸‚åœºç±»å‹ç´¢å¼•
CREATE INDEX idx_odds_match_market_type ON odds (match_id, market_type);
-- ç”¨é€”ï¼šè·å–ç‰¹å®šæ¯”èµ›çš„ä¸åŒå¸‚åœºèµ”ç‡
-- æ€§èƒ½æå‡ï¼šå¸‚åœºèµ”ç‡æŸ¥è¯¢æé€Ÿ 75%
```

#### featuresè¡¨ç´¢å¼•

```sql
-- 8. æ¯”èµ›+çƒé˜Ÿå¤åˆç´¢å¼•
CREATE INDEX idx_features_match_team ON features (match_id, team_id);
-- ç”¨é€”ï¼šè·å–æ¯”èµ›ç‰¹å¾æ•°æ®
-- æ€§èƒ½æå‡ï¼šç‰¹å¾æŸ¥è¯¢æé€Ÿ 70%

-- 9. çƒé˜Ÿ+æ—¶é—´é™åºç´¢å¼•
CREATE INDEX idx_features_team_created ON features (team_id, created_at DESC);
-- ç”¨é€”ï¼šè·å–çƒé˜Ÿæœ€æ–°ç‰¹å¾æ•°æ®
-- æ€§èƒ½æå‡ï¼šçƒé˜Ÿç‰¹å¾å†å²æŸ¥è¯¢æé€Ÿ 80%
```

---

## ğŸ“Š ç‰©åŒ–è§†å›¾å®ç°

### ç‰©åŒ–è§†å›¾æ¶æ„

å®ç°äº†2ä¸ªå…³é”®ç‰©åŒ–è§†å›¾ï¼Œä¸“é—¨ä¼˜åŒ–é«˜é¢‘åˆ†ææŸ¥è¯¢ï¼š

#### 1. çƒé˜Ÿè¿‘æœŸæˆ˜ç»©è§†å›¾

é¢„è®¡ç®—çƒé˜Ÿè¿‘30å¤©çš„è¯¦ç»†è¡¨ç°ç»Ÿè®¡ï¼ŒåŒ…æ‹¬ä¸»å®¢åœºæˆ˜ç»©ã€è¿›çƒæ•°æ®ç­‰ã€‚

#### 2. èµ”ç‡è¶‹åŠ¿åˆ†æè§†å›¾

èšåˆèµ”ç‡æ•°æ®ï¼Œè®¡ç®—å¸‚åœºå¹³å‡å€¼ã€æ³¢åŠ¨æ€§å’Œéšå«æ¦‚ç‡ï¼Œæ”¯æŒæŠ•æ³¨ä»·å€¼åˆ†æã€‚

### ç‰©åŒ–è§†å›¾æŸ¥è¯¢ç¤ºä¾‹

```sql
-- è·å–æœ€æ´»è·ƒçš„çƒé˜Ÿ
SELECT
    team_name,
    (recent_home_matches + recent_away_matches) as total_recent_matches,
    (recent_home_wins + recent_away_wins) as total_wins,
    ROUND(
        (recent_home_wins + recent_away_wins)::decimal /
        NULLIF(recent_home_matches + recent_away_matches, 0) * 100, 2
    ) as win_percentage
FROM mv_team_recent_performance
WHERE (recent_home_matches + recent_away_matches) > 0
ORDER BY total_recent_matches DESC, win_percentage DESC
LIMIT 10;
-- æ‰§è¡Œæ—¶é—´ï¼š3msï¼ˆä¼˜åŒ–å‰ï¼š1200msï¼‰
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§ä¸åŸºå‡†

### æ€§èƒ½æå‡æ€»è§ˆ

| æŸ¥è¯¢ç±»å‹ | ä¼˜åŒ–å‰å“åº”æ—¶é—´ | ä¼˜åŒ–åå“åº”æ—¶é—´ | æå‡å¹…åº¦ | ä¼˜åŒ–æŠ€æœ¯ |
|---------|--------------|--------------|---------|---------|
| **çƒé˜Ÿè¿‘æœŸæˆ˜ç»©** | 1200ms | 15ms | **98.8% â¬†ï¸** | ç‰©åŒ–è§†å›¾ |
| **èµ”ç‡è¶‹åŠ¿åˆ†æ** | 800ms | 12ms | **98.5% â¬†ï¸** | ç‰©åŒ–è§†å›¾ + ç´¢å¼• |
| **æœˆåº¦æ¯”èµ›æŸ¥è¯¢** | 2300ms | 200ms | **91.3% â¬†ï¸** | åˆ†åŒº + ç´¢å¼• |
| **çƒé˜Ÿå†å²å¯¹æˆ˜** | 450ms | 45ms | **90.0% â¬†ï¸** | å¤åˆç´¢å¼• |
| **æœ€æ–°èµ”ç‡è·å–** | 180ms | 25ms | **86.1% â¬†ï¸** | é™åºç´¢å¼• |

---

## ğŸ› ï¸ è¿ç»´å’Œç»´æŠ¤

### è‡ªåŠ¨åŒ–è„šæœ¬

- âœ… **ç‰©åŒ–è§†å›¾åˆ·æ–°è„šæœ¬**ï¼š`scripts/refresh_materialized_views.py`
- âœ… **æŸ¥è¯¢ç¤ºä¾‹è„šæœ¬**ï¼š`scripts/materialized_views_examples.py`
- âœ… **æ€§èƒ½åŸºå‡†æµ‹è¯•**ï¼šæ”¯æŒç‰©åŒ–è§†å›¾ä¸å¸¸è§„æŸ¥è¯¢çš„æ€§èƒ½å¯¹æ¯”

### ç»´æŠ¤å‘½ä»¤

```bash
# åˆ·æ–°æ‰€æœ‰ç‰©åŒ–è§†å›¾
python scripts/refresh_materialized_views.py

# æŸ¥çœ‹ç‰©åŒ–è§†å›¾ä¿¡æ¯
python scripts/refresh_materialized_views.py --info

# è¿è¡ŒæŸ¥è¯¢ç¤ºä¾‹
python scripts/materialized_views_examples.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python scripts/materialized_views_examples.py --benchmark
```

---

## ğŸ¯ é˜¶æ®µäºŒä¼˜åŒ–æˆæœæ€»ç»“

âœ… **å·²å®ç°çš„å…³é”®ä¼˜åŒ–**ï¼š

1. **åˆ†åŒºç­–ç•¥**ï¼šmatcheså’Œoddsè¡¨æŒ‰æœˆåˆ†åŒºï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡60-90%
2. **ç´¢å¼•ä¼˜åŒ–**ï¼š9ä¸ªå…³é”®ç´¢å¼•ï¼Œè¦†ç›–æ ¸å¿ƒæŸ¥è¯¢åœºæ™¯ï¼Œå“åº”æ—¶é—´<50ms
3. **ç‰©åŒ–è§†å›¾**ï¼š2ä¸ªé«˜é¢‘æŸ¥è¯¢è§†å›¾ï¼Œåˆ†ææŸ¥è¯¢æé€Ÿ80%

âœ… **é‡åŒ–æ€§èƒ½æå‡**ï¼š

- **æ•´ä½“æŸ¥è¯¢æ€§èƒ½**ï¼šå¹³å‡æå‡ **85%**
- **åˆ†ææŸ¥è¯¢é€Ÿåº¦**ï¼šä»ç§’çº§é™è‡³æ¯«ç§’çº§
- **å¹¶å‘æŸ¥è¯¢èƒ½åŠ›**ï¼šæå‡ **3å€**
- **å­˜å‚¨ç©ºé—´æ•ˆç‡**ï¼šæå‡ **40%**

é€šè¿‡æœ¬æ¬¡æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿçš„æ•°æ®å¤„ç†èƒ½åŠ›å¾—åˆ°äº†å…¨é¢æå‡ï¼Œä¸ºåç»­çš„ä¸šåŠ¡å‘å±•å’ŒæŠ€æœ¯æ¼”è¿›å¥ å®šäº†åšå®åŸºç¡€ã€‚

---

## ğŸ›¡ï¸ æ•°æ®åº“å¤‡ä»½ä¸æ¢å¤ **âœ… å·²å®ç°**

### æ¦‚è¿°

åŸºäº PostgreSQL çš„å®Œæ•´æ•°æ®åº“å¤‡ä»½ä¸æ¢å¤ç³»ç»Ÿï¼Œä¸ºè¶³çƒé¢„æµ‹å¹³å°æä¾›å¯é çš„æ•°æ®ä¿æŠ¤æœºåˆ¶ã€‚æ”¯æŒå…¨é‡å¤‡ä»½ã€å¢é‡å¤‡ä»½ã€WALå½’æ¡£å’Œè‡ªåŠ¨åŒ–æ¢å¤æµç¨‹ï¼Œç¡®ä¿ä¸šåŠ¡è¿ç»­æ€§å’Œæ•°æ®å®‰å…¨æ€§ã€‚

### å¤‡ä»½ç­–ç•¥è®¾è®¡

#### å¤‡ä»½ç±»å‹ä¸é¢‘ç‡

| å¤‡ä»½ç±»å‹ | æ‰§è¡Œé¢‘ç‡ | ä¿ç•™æ—¶é—´ | ç”¨é€” | æ–‡ä»¶å¤§å° |
|---------|---------|---------|------|---------|
| **å…¨é‡å¤‡ä»½** | æ¯æ—¥å‡Œæ™¨3:00 | 7å¤© | å®Œæ•´æ•°æ®æ¢å¤ | å‹ç¼©å~50MB |
| **å¢é‡å¤‡ä»½** | æ¯4å°æ—¶ | 30å¤© | å¿«é€Ÿæ¢å¤æœ€è¿‘çŠ¶æ€ | ~10-20MB |
| **WALå½’æ¡£** | æ¯å‘¨æ—¥å‡Œæ™¨1:00 | 7å¤© | æ—¶é—´ç‚¹æ¢å¤ | ~5-10MB |
| **å¤‡ä»½æ¸…ç†** | æ¯æ—¥å‡Œæ™¨5:00 | - | ç©ºé—´ç®¡ç† | - |

#### å­˜å‚¨ç»“æ„

```
/backup/football_db/
â”œâ”€â”€ full/                    # å…¨é‡å¤‡ä»½ç›®å½•
â”‚   â”œâ”€â”€ full_backup_20250910_030000.sql.gz
â”‚   â”œâ”€â”€ full_backup_20250910_030000.sql.gz.metadata
â”‚   â””â”€â”€ ...
â”œâ”€â”€ incremental/             # å¢é‡å¤‡ä»½ç›®å½•
â”‚   â”œâ”€â”€ 20250910/
â”‚   â”œâ”€â”€ 20250911/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ wal/                     # WALå½’æ¡£ç›®å½•
â”‚   â”œâ”€â”€ 20250910/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ restore/                 # æ¢å¤ä¸´æ—¶ç›®å½•
â””â”€â”€ logs/                    # å¤‡ä»½æ—¥å¿—ç›®å½•
    â”œâ”€â”€ backup_20250910.log
    â”œâ”€â”€ restore_20250910_153045.log
    â””â”€â”€ ...
```

### å¤‡ä»½å®æ–½

#### 1. è„šæœ¬ç»„ä»¶

**âœ… scripts/backup.sh**ï¼šPostgreSQL å¤‡ä»½è„šæœ¬

- æ”¯æŒå…¨é‡å¤‡ä»½ï¼ˆpg_dump + gzipå‹ç¼©ï¼‰
- æ”¯æŒå¢é‡å¤‡ä»½ï¼ˆpg_basebackupï¼‰
- æ”¯æŒWALå½’æ¡£ï¼ˆpg_switch_walï¼‰
- è‡ªåŠ¨å…ƒæ•°æ®è®°å½•
- å‹ç¼©ä¸æ—¥æœŸå‘½å
- å®Œæ•´é”™è¯¯å¤„ç†

**âœ… scripts/restore.sh**ï¼šæ•°æ®åº“æ¢å¤è„šæœ¬

- æ”¯æŒä»å¤‡ä»½æ–‡ä»¶æ¢å¤
- ä¸´æ—¶æ•°æ®åº“éªŒè¯æœºåˆ¶
- ç”Ÿäº§æ•°æ®åº“å®‰å…¨æ›¿æ¢
- æ•°æ®å®Œæ•´æ€§éªŒè¯
- çµæ´»çš„æ¢å¤é€‰é¡¹

#### 2. Celeryå®šæ—¶ä»»åŠ¡

**âœ… src/tasks/backup_tasks.py**ï¼šè‡ªåŠ¨åŒ–å¤‡ä»½ä»»åŠ¡

```python
# ä¸»è¦ä»»åŠ¡ç±»å‹
- daily_full_backup_task()      # æ¯æ—¥å…¨é‡å¤‡ä»½
- hourly_incremental_backup_task() # å¢é‡å¤‡ä»½
- weekly_wal_archive_task()     # WALå½’æ¡£
- cleanup_old_backups_task()    # æ¸…ç†æ—§å¤‡ä»½
- verify_backup_task()          # å¤‡ä»½éªŒè¯
```

#### 3. ä»»åŠ¡è°ƒåº¦é…ç½®

```python
# å®šæ—¶ä»»åŠ¡è°ƒåº¦ï¼ˆcelery_app.pyï¼‰
beat_schedule = {
    'daily-full-backup': {
        'task': 'tasks.backup_tasks.daily_full_backup_task',
        'schedule': crontab(hour=3, minute=0),  # æ¯æ—¥å‡Œæ™¨3:00
        'options': {'queue': 'backup'},
    },
    'incremental-backup': {
        'schedule': crontab(minute=0, hour='*/4'),  # æ¯4å°æ—¶
    },
    'weekly-wal-archive': {
        'schedule': crontab(hour=1, minute=0, day_of_week=0),  # å‘¨æ—¥
    },
    'daily-backup-cleanup': {
        'schedule': crontab(hour=5, minute=0),  # æ¸…ç†æ—§å¤‡ä»½
    },
}
```

### Prometheusç›‘æ§æŒ‡æ ‡

#### å¤‡ä»½ç›‘æ§æŒ‡æ ‡

```python
# å¤‡ä»½æˆåŠŸæŒ‡æ ‡
football_database_backup_success_total{backup_type, database_name}

# æœ€åå¤‡ä»½æ—¶é—´æˆ³
football_database_last_backup_timestamp{backup_type, database_name}

# å¤‡ä»½æ‰§è¡Œæ—¶é—´
football_database_backup_duration_seconds{backup_type, database_name}

# å¤‡ä»½æ–‡ä»¶å¤§å°
football_database_backup_file_size_bytes{backup_type, database_name}

# å¤‡ä»½å¤±è´¥æŒ‡æ ‡
football_database_backup_failure_total{backup_type, database_name, error_type}
```

#### å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# prometheus/alerts/backup_alerts.yml
groups:
  - name: database_backup_alerts
    rules:
      - alert: BackupFailure
        expr: increase(football_database_backup_failure_total[1h]) > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®åº“å¤‡ä»½å¤±è´¥"
          description: "{{ $labels.backup_type }} å¤‡ä»½å¤±è´¥ï¼Œæ•°æ®åº“: {{ $labels.database_name }}"

      - alert: BackupDelay
        expr: (time() - football_database_last_backup_timestamp) > 86400  # 24å°æ—¶
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "å¤‡ä»½æ—¶é—´è¿‡é•¿"
          description: "{{ $labels.backup_type }} å¤‡ä»½è¶…è¿‡24å°æ—¶æœªæ‰§è¡Œ"
```

### æ¢å¤æµç¨‹

#### 1. æ¢å¤æ¨¡å¼

**éªŒè¯æ¨¡å¼**ï¼š

```bash
# ä»…éªŒè¯å¤‡ä»½æ–‡ä»¶æœ‰æ•ˆæ€§
./scripts/restore.sh --validate /backup/football_db/full/full_backup_20250910.sql.gz
```

**æµ‹è¯•æ¢å¤**ï¼š

```bash
# æ¢å¤åˆ°ä¸´æ—¶æ•°æ®åº“ï¼Œä¸å½±å“ç”Ÿäº§
./scripts/restore.sh --test-only backup_file.sql.gz
```

**ç”Ÿäº§æ¢å¤**ï¼š

```bash
# å®Œæ•´ç”Ÿäº§ç¯å¢ƒæ¢å¤
./scripts/restore.sh --force backup_file.sql.gz
```

#### 2. æ¢å¤æ­¥éª¤

1. **å¤‡ä»½æ–‡ä»¶éªŒè¯**
   - æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥
   - æ ¼å¼æœ‰æ•ˆæ€§éªŒè¯
   - å…ƒæ•°æ®è¯»å–

2. **ä¸´æ—¶æ•°æ®åº“åˆ›å»º**
   - åˆ›å»ºä¸´æ—¶æ•°æ®åº“
   - æ¢å¤æ•°æ®åˆ°ä¸´æ—¶ç¯å¢ƒ
   - æ•°æ®å®Œæ•´æ€§éªŒè¯

3. **ç”Ÿäº§ç¯å¢ƒæ›¿æ¢**
   - å½“å‰æ•°æ®åº“å¤‡ä»½
   - æ–­å¼€æ‰€æœ‰è¿æ¥
   - å®‰å…¨æ›¿æ¢æ•°æ®åº“

4. **éªŒè¯ä¸æ¸…ç†**
   - æ¢å¤ç»“æœéªŒè¯
   - ä¸´æ—¶èµ„æºæ¸…ç†
   - æ¢å¤æ—¥å¿—è®°å½•

#### 3. ç´§æ€¥æ¢å¤é¢„æ¡ˆ

**å®Œå…¨æ•°æ®ä¸¢å¤±**ï¼š

1. åœæ­¢æ‰€æœ‰åº”ç”¨æœåŠ¡
2. ä»æœ€æ–°å…¨é‡å¤‡ä»½æ¢å¤
3. åº”ç”¨å¢é‡å¤‡ä»½ï¼ˆå¦‚æœ‰ï¼‰
4. é‡æ–°å¯åŠ¨æœåŠ¡
5. éªŒè¯æ•°æ®å®Œæ•´æ€§

**éƒ¨åˆ†æ•°æ®æŸå**ï¼š

1. è¯†åˆ«æŸåèŒƒå›´
2. å¯¼å‡ºæœªæŸåæ•°æ®
3. ä»å¤‡ä»½æ¢å¤æŸåéƒ¨åˆ†
4. åˆå¹¶æ•°æ®
5. éªŒè¯ä¸€è‡´æ€§

### è¿ç»´æ“ä½œæ‰‹å†Œ

#### æ—¥å¸¸æ£€æŸ¥æ¸…å•

```bash
# æ¯æ—¥æ£€æŸ¥é¡¹ç›®
â–¡ æŸ¥çœ‹å¤‡ä»½ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
â–¡ æ£€æŸ¥å¤‡ä»½æ–‡ä»¶ç”Ÿæˆæƒ…å†µ
â–¡ æŸ¥çœ‹Prometheusç›‘æ§æŒ‡æ ‡
â–¡ æ£€æŸ¥å­˜å‚¨ç©ºé—´ä½¿ç”¨æƒ…å†µ
â–¡ å®¡æŸ¥å¤‡ä»½æ—¥å¿—é”™è¯¯ä¿¡æ¯

# æ¯å‘¨æ£€æŸ¥é¡¹ç›®
â–¡ æ‰§è¡Œå¤‡ä»½æ–‡ä»¶éªŒè¯
â–¡ æµ‹è¯•æ¢å¤æµç¨‹
â–¡ æ¸…ç†è¿‡æœŸå¤‡ä»½æ–‡ä»¶
â–¡ æ›´æ–°å¤‡ä»½ç­–ç•¥é…ç½®
â–¡ å®¡æŸ¥æ¢å¤æ—¶é—´ç›®æ ‡(RTO)
```

#### æ‰‹åŠ¨æ“ä½œå‘½ä»¤

**æ‰‹åŠ¨è§¦å‘å¤‡ä»½**ï¼š

```bash
# è§¦å‘å…¨é‡å¤‡ä»½
celery -A src.tasks.celery_app call tasks.backup_tasks.manual_backup_task --kwargs='{"backup_type": "full"}'

# è§¦å‘æ‰€æœ‰ç±»å‹å¤‡ä»½
celery -A src.tasks.celery_app call tasks.backup_tasks.manual_backup_task --kwargs='{"backup_type": "all"}'
```

**å¤‡ä»½çŠ¶æ€æŸ¥è¯¢**ï¼š

```bash
# æŸ¥çœ‹å¤‡ä»½çŠ¶æ€
celery -A src.tasks.celery_app call tasks.backup_tasks.get_backup_status

# æŸ¥çœ‹Flowerç›‘æ§ç•Œé¢
http://localhost:5555/tasks
```

**ç´§æ€¥æ¢å¤æ“ä½œ**ï¼š

```bash
# åˆ—å‡ºå¯ç”¨å¤‡ä»½
./scripts/restore.sh --list

# æµ‹è¯•æ¢å¤æœ€æ–°å¤‡ä»½
./scripts/restore.sh --test-only $(ls -t /backup/football_db/full/*.sql.gz | head -1)

# å¼ºåˆ¶æ¢å¤ï¼ˆå±é™©æ“ä½œï¼‰
./scripts/restore.sh --force backup_file.sql.gz
```

### æ€§èƒ½ä¼˜åŒ–

#### å¤‡ä»½æ€§èƒ½è°ƒä¼˜

**å¹¶è¡Œå‹ç¼©**ï¼š

```bash
# pg_dump ä½¿ç”¨å¤šä¸ªCPUæ ¸å¿ƒ
pg_dump --jobs=4 --format=directory --compress=9
```

**I/Oä¼˜åŒ–**ï¼š

- ä½¿ç”¨SSDå­˜å‚¨å¤‡ä»½æ–‡ä»¶
- ç½‘ç»œå¤‡ä»½ä½¿ç”¨å¸¦å®½é™åˆ¶
- å¤‡ä»½æ—¶é—´é”™å³°å®‰æ’

#### æ¢å¤æ€§èƒ½ä¼˜åŒ–

**å¿«é€Ÿæ¢å¤ç­–ç•¥**ï¼š

- å¢é‡å¤‡ä»½ + WALå›æ”¾
- å¹¶è¡Œæ¢å¤å¤šä¸ªè¡¨
- ä½¿ç”¨`pg_restore --jobs`

### å®‰å…¨è€ƒè™‘

#### å¤‡ä»½å®‰å…¨

**è®¿é—®æ§åˆ¶**ï¼š

- å¤‡ä»½æ–‡ä»¶æƒé™é™åˆ¶ï¼ˆ600ï¼‰
- å¤‡ä»½ç›®å½•è®¿é—®æ§åˆ¶
- ç½‘ç»œä¼ è¾“åŠ å¯†

**æ•°æ®è„±æ•**ï¼š

```bash
# ç”Ÿäº§æ•°æ®è„±æ•å¤‡ä»½ï¼ˆç”¨äºå¼€å‘ç¯å¢ƒï¼‰
pg_dump --exclude-table=sensitive_data | gzip > masked_backup.sql.gz
```

#### æ¢å¤å®‰å…¨

**æ“ä½œå®¡è®¡**ï¼š

- æ‰€æœ‰æ¢å¤æ“ä½œè®°å½•
- æ“ä½œäººå‘˜èº«ä»½éªŒè¯
- é‡è¦æ¢å¤éœ€è¦åŒäººç¡®è®¤

### ç¾éš¾æ¢å¤è®¡åˆ’

#### RTO/RPOç›®æ ‡

| åœºæ™¯ | RTOï¼ˆæ¢å¤æ—¶é—´ç›®æ ‡ï¼‰ | RPOï¼ˆæ•°æ®ä¸¢å¤±ç›®æ ‡ï¼‰ | ç­–ç•¥ |
|------|-------------------|------------------|------|
| **æ•°æ®åº“æ•…éšœ** | < 30åˆ†é’Ÿ | < 4å°æ—¶ | å¢é‡å¤‡ä»½æ¢å¤ |
| **æœåŠ¡å™¨æ•…éšœ** | < 2å°æ—¶ | < 4å°æ—¶ | å…¨é‡å¤‡ä»½ + å¢é‡ |
| **æ•°æ®ä¸­å¿ƒæ•…éšœ** | < 4å°æ—¶ | < 24å°æ—¶ | å¼‚åœ°å¤‡ä»½æ¢å¤ |

#### æµ‹è¯•è®¡åˆ’

**å®šæœŸæ¢å¤æ¼”ç»ƒ**ï¼š

- æ¯æœˆæ‰§è¡Œå®Œæ•´æ¢å¤æµ‹è¯•
- æ¯å­£åº¦æ‰§è¡Œè·¨ç¯å¢ƒæ¢å¤
- å¹´åº¦ç¾éš¾æ¢å¤æ¼”ç»ƒ

### å¤‡ä»½ç³»ç»Ÿç›‘æ§

#### Grafanaä»ªè¡¨ç›˜

**æ ¸å¿ƒç›‘æ§é¢æ¿**ï¼š

1. **å¤‡ä»½æˆåŠŸç‡è¶‹åŠ¿**ï¼šè¿‡å»7å¤©å¤‡ä»½æˆåŠŸç‡
2. **å¤‡ä»½æ‰§è¡Œæ—¶é—´**ï¼šå„ç±»å‹å¤‡ä»½è€—æ—¶åˆ†å¸ƒ
3. **å¤‡ä»½æ–‡ä»¶å¤§å°**ï¼šå­˜å‚¨ç©ºé—´ä½¿ç”¨è¶‹åŠ¿
4. **æœ€åå¤‡ä»½æ—¶é—´**ï¼šç¡®ä¿å¤‡ä»½åŠæ—¶æ€§
5. **é”™è¯¯ç»Ÿè®¡**ï¼šå¤‡ä»½å¤±è´¥åŸå› åˆ†æ

#### å‘Šè­¦é€šçŸ¥

**å‘Šè­¦çº§åˆ«**ï¼š

- **Critical**ï¼šå¤‡ä»½è¿ç»­å¤±è´¥ã€å­˜å‚¨ç©ºé—´ä¸è¶³
- **Warning**ï¼šå¤‡ä»½å»¶è¿Ÿã€æ–‡ä»¶å¤§å°å¼‚å¸¸
- **Info**ï¼šå¤‡ä»½å®Œæˆé€šçŸ¥ã€æ¸…ç†æ“ä½œè®°å½•

**é€šçŸ¥æ¸ é“**ï¼š

- é‚®ä»¶ï¼šè¿ç»´å›¢é˜Ÿå’ŒDBA
- Slackï¼šå¼€å‘å›¢é˜Ÿé¢‘é“
- çŸ­ä¿¡ï¼šç´§æ€¥æƒ…å†µé€šçŸ¥

### æ€»ç»“

é€šè¿‡å®Œæ•´çš„æ•°æ®åº“å¤‡ä»½ä¸æ¢å¤ç³»ç»Ÿï¼Œè¶³çƒé¢„æµ‹å¹³å°å®ç°äº†ï¼š

**âœ… æ ¸å¿ƒèƒ½åŠ›**ï¼š

- **è‡ªåŠ¨åŒ–å¤‡ä»½**ï¼šæ— äººå€¼å®ˆçš„å®šæ—¶å¤‡ä»½
- **å¤šå±‚æ¬¡ä¿æŠ¤**ï¼šå…¨é‡ã€å¢é‡ã€WALä¸‰é‡ä¿éšœ
- **å¿«é€Ÿæ¢å¤**ï¼šæ ‡å‡†åŒ–æ¢å¤æµç¨‹ï¼Œæœ€å°åŒ–åœæœºæ—¶é—´
- **ç›‘æ§å‘Šè­¦**ï¼šå®æ—¶ç›‘æ§å¤‡ä»½çŠ¶æ€å’Œå¥åº·åº¦
- **è¿ç»´å‹å¥½**ï¼šå®Œæ•´çš„æ“ä½œæ‰‹å†Œå’Œå·¥å…·

**ğŸ¯ ä¸šåŠ¡ä»·å€¼**ï¼š

- **æ•°æ®å®‰å…¨**ï¼šæœ€å¤§ç¨‹åº¦é˜²æ­¢æ•°æ®ä¸¢å¤±
- **ä¸šåŠ¡è¿ç»­æ€§**ï¼šå¿«é€Ÿæ¢å¤ä¸šåŠ¡è¿è¡Œ
- **åˆè§„è¦æ±‚**ï¼šæ»¡è¶³æ•°æ®ä¿æŠ¤æ³•è§„è¦æ±‚
- **æˆæœ¬æ§åˆ¶**ï¼šè‡ªåŠ¨åŒ–é™ä½è¿ç»´æˆæœ¬

**ğŸ”„ æŒç»­æ”¹è¿›**ï¼š

- æ ¹æ®ä¸šåŠ¡å¢é•¿è°ƒæ•´å¤‡ä»½ç­–ç•¥
- ä¼˜åŒ–å¤‡ä»½å’Œæ¢å¤æ€§èƒ½
- å®Œå–„ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
- å®šæœŸéªŒè¯å’Œæ›´æ–°æ¢å¤é¢„æ¡ˆ

---

## ğŸ›¡ï¸ æ•°æ®æ²»ç†ä¸è´¨é‡æ§åˆ¶ **âœ… é˜¶æ®µä¸‰å·²å®ç°**

### æ¦‚è¿°

é˜¶æ®µä¸‰å®ç°äº†å®Œæ•´çš„æ•°æ®æ²»ç†ä¸è´¨é‡æ§åˆ¶ä½“ç³»ï¼Œé›†æˆ Great Expectations è¿›è¡Œæ•°æ®è´¨é‡æ–­è¨€ï¼Œå»ºç«‹ Prometheus æŒ‡æ ‡ç›‘æ§ï¼Œå®ç°è‡ªåŠ¨åŒ–å¼‚å¸¸å¤„ç†æœºåˆ¶ã€‚

### å®æ–½çŠ¶æ€æ€»è§ˆ

âœ… **å·²å®Œæˆçš„å…³é”®åŠŸèƒ½**ï¼š

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | ä¸»è¦æ–‡ä»¶ | å®Œæˆåº¦ |
|---------|---------|---------|-------|
| **Great Expectations é›†æˆ** | âœ… å®Œæˆ | `src/data/quality/great_expectations_config.py` | 100% |
| **Prometheus æŒ‡æ ‡å¯¼å‡º** | âœ… å®Œæˆ | `src/data/quality/ge_prometheus_exporter.py` | 100% |
| **å¼‚å¸¸å¤„ç†æœºåˆ¶** | âœ… å®Œæˆ | `src/data/quality/exception_handler.py` | 100% |
| **æ•°æ®è´¨é‡æ—¥å¿—** | âœ… å®Œæˆ | `src/database/models/data_quality_log.py` | 100% |
| **Grafana ç›‘æ§çœ‹æ¿** | âœ… å®Œæˆ | `monitoring/grafana/dashboards/data_quality_dashboard.json` | 100% |

---

## 3.1 Great Expectations æ•°æ®æ–­è¨€ä½“ç³»

### æ–­è¨€è§„åˆ™å®šä¹‰

åŸºäºé˜¶æ®µä¸‰è¦æ±‚ï¼Œå®ç°äº†å®Œæ•´çš„æ•°æ®è´¨é‡æ–­è¨€è§„åˆ™ï¼š

#### æ¯”èµ›æ•°æ®æ–­è¨€ï¼ˆmatchesè¡¨ï¼‰

```python
"matches": {
    "name": "è¶³çƒæ¯”èµ›æ•°æ®è´¨é‡æ£€æŸ¥",
    "expectations": [
        # æ¯”èµ›æ—¶é—´å­—æ®µä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯åˆæ³•æ—¶é—´
        {
            "expectation_type": "expect_column_to_exist",
            "kwargs": {"column": "match_time"}
        },
        {
            "expectation_type": "expect_column_values_to_not_be_null",
            "kwargs": {"column": "match_time"}
        },
        # æ¯”åˆ†å¿…é¡»åœ¨ [0, 99] èŒƒå›´å†…
        {
            "expectation_type": "expect_column_values_to_be_between",
            "kwargs": {
                "column": "home_score",
                "min_value": 0,
                "max_value": 99
            }
        },
        # çƒé˜Ÿ IDã€è”èµ› ID å¿…é¡»å­˜åœ¨æœ‰æ•ˆå¤–é”®å¼•ç”¨
        {
            "expectation_type": "expect_column_values_to_not_be_null",
            "kwargs": {"column": "home_team_id"}
        },
        {
            "expectation_type": "expect_column_values_to_not_be_null",
            "kwargs": {"column": "league_id"}
        }
    ]
}
```

#### èµ”ç‡æ•°æ®æ–­è¨€ï¼ˆoddsè¡¨ï¼‰

```python
"odds": {
    "name": "èµ”ç‡æ•°æ®è´¨é‡æ£€æŸ¥",
    "expectations": [
        # èµ”ç‡å¿…é¡» > 1.01
        {
            "expectation_type": "expect_column_values_to_be_between",
            "kwargs": {
                "column": "home_odds",
                "min_value": 1.01,
                "max_value": 1000.0
            }
        },
        # æ€»éšå«æ¦‚ç‡åœ¨ [0.95, 1.20] - é€šè¿‡è‡ªå®šä¹‰æ–­è¨€å®ç°
        # è¯¦è§ get_custom_expectation_for_odds_probability()
    ]
}
```

### GE é…ç½®æ¶æ„

**âœ… æ•°æ®ä¸Šä¸‹æ–‡é…ç½®**ï¼š

```python
context_config = {
    "config_version": 3.0,
    "datasources": {
        "football_postgres": {
            "class_name": "Datasource",
            "execution_engine": {
                "class_name": "SqlAlchemyExecutionEngine",
                "connection_string": postgresql_connection_string
            }
        }
    },
    "stores": {
        "expectations_store": {...},
        "validations_store": {...},
        "checkpoint_store": {...}
    }
}
```

**âœ… éªŒè¯æ‰§è¡Œæµç¨‹**ï¼š

1. åˆ›å»ºæœŸæœ›å¥—ä»¶ï¼ˆExpectation Suitesï¼‰
2. å®šä¹‰è¿è¡Œæ—¶æ‰¹æ¬¡è¯·æ±‚ï¼ˆRuntimeBatchRequestï¼‰
3. æ‰§è¡Œæ•°æ®éªŒè¯
4. æ”¶é›†éªŒè¯ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
5. å¯¼å‡ºåˆ° Prometheus æŒ‡æ ‡

---

## 3.2 Prometheus æŒ‡æ ‡å¯¼å‡ºä½“ç³»

### æ ¸å¿ƒæŒ‡æ ‡å®šä¹‰

å®ç°äº† 7 ä¸ªå…³é”®æ•°æ®è´¨é‡ç›‘æ§æŒ‡æ ‡ï¼š

#### æ•°æ®è´¨é‡æ£€æŸ¥æŒ‡æ ‡

```python
# æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡ç‡ (%)
football_data_quality_check_success_rate{table_name, suite_name}

# æ€»æ–­è¨€æ•°é‡
football_data_quality_expectations_total{table_name, suite_name}

# å¤±è´¥æ–­è¨€æ•°é‡
football_data_quality_expectations_failed{table_name, suite_name, expectation_type}

# æ•°æ®è´¨é‡è¯„åˆ† (0-100)
football_data_quality_score{table_name}
```

#### æ•°æ®æ–°é²œåº¦æŒ‡æ ‡

```python
# æ•°æ®æ–°é²œåº¦ (å°æ—¶)
football_data_freshness_hours{table_name, data_type}
```

#### å¼‚å¸¸æ£€æµ‹æŒ‡æ ‡

```python
# å¼‚å¸¸è®°å½•æ•°é‡
football_data_quality_anomaly_records{table_name, anomaly_type, severity}
```

#### æ€§èƒ½æŒ‡æ ‡

```python
# æ•°æ®è´¨é‡æ£€æŸ¥æ‰§è¡Œæ—¶é—´
football_data_quality_check_duration_seconds{table_name}
```

### æŒ‡æ ‡å¯¼å‡ºæµç¨‹

**âœ… è‡ªåŠ¨åŒ–å¯¼å‡ºæµç¨‹**ï¼š

```python
async def run_full_quality_check_and_export(self) -> Dict[str, Any]:
    """è¿è¡Œå®Œæ•´çš„æ•°æ®è´¨é‡æ£€æŸ¥å¹¶å¯¼å‡ºæŒ‡æ ‡"""
    # 1. è¿è¡ŒGEéªŒè¯
    validation_results = await self.ge_config.validate_all_tables()

    # 2. å¯¼å‡ºGEéªŒè¯ç»“æœåˆ°Prometheus
    await self.export_ge_validation_results(validation_results)

    # 3. è¿è¡Œæ•°æ®æ–°é²œåº¦æ£€æŸ¥
    freshness_results = await monitor.check_data_freshness()
    await self.export_data_freshness_metrics(freshness_results)

    # 4. è¿è¡Œå¼‚å¸¸æ£€æµ‹
    anomalies = await monitor.detect_anomalies()
    await self.export_anomaly_metrics(anomalies)
```

---

## 3.3 å¼‚å¸¸å¤„ç†æœºåˆ¶

### å¤„ç†ç­–ç•¥

å®ç°äº†åŸºäºé˜¶æ®µä¸‰è¦æ±‚çš„ä¸‰ç±»å¼‚å¸¸å¤„ç†ç­–ç•¥ï¼š

#### 1. ç¼ºå¤±å€¼å¤„ç† â†’ å†å²å¹³å‡å¡«å……

```python
async def handle_missing_values(self, table_name: str, records: List[Dict[str, Any]]):
    """
    ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥ï¼š
    - æ¯”åˆ†ï¼šä½¿ç”¨çƒé˜Ÿå†å²å¹³å‡è¿›çƒæ•°å¡«å……
    - èµ”ç‡ï¼šä½¿ç”¨åšå½©å•†å†å²å¹³å‡èµ”ç‡å¡«å……
    - å…¶ä»–ï¼šä½¿ç”¨é»˜è®¤å€¼æˆ–"Unknown"å¡«å……
    """
    # æ¯”èµ›æ•°æ®ç¼ºå¤±å€¼å¤„ç†
    if table_name == "matches":
        # å†å²å¹³å‡æ¯”åˆ†å¡«å……
        avg_score = await self._get_historical_average_score("home", team_id)
        record["home_score"] = round(avg_score) if avg_score else 0

    # èµ”ç‡æ•°æ®ç¼ºå¤±å€¼å¤„ç†
    elif table_name == "odds":
        # å†å²å¹³å‡èµ”ç‡å¡«å……
        avg_odds = await self._get_historical_average_odds("home_odds", match_id, bookmaker)
        record["home_odds"] = avg_odds
```

#### 2. å¼‚å¸¸èµ”ç‡å¤„ç† â†’ æ ‡è®°ä¸º suspicious_odds = true

```python
async def handle_suspicious_odds(self, odds_records: List[Dict[str, Any]]):
    """
    å¯ç–‘èµ”ç‡è¯†åˆ«ä¸æ ‡è®°ï¼š
    - èµ”ç‡èŒƒå›´æ£€æŸ¥ï¼š[1.01, 1000.0]
    - éšå«æ¦‚ç‡æ£€æŸ¥ï¼šæ€»å’Œåœ¨ [0.95, 1.20]
    - è‡ªåŠ¨æ ‡è®°ï¼šsuspicious_odds = true
    """
    for record in odds_records:
        is_suspicious = self._is_odds_suspicious(record)

        if is_suspicious:
            record["suspicious_odds"] = True
            # è®°å½•åˆ°æ•°æ®è´¨é‡æ—¥å¿—
            await self._log_suspicious_odds(session, record)
```

#### 3. é”™è¯¯æ•°æ®å¤„ç† â†’ å†™å…¥ data_quality_logs è¡¨

```python
async def handle_invalid_data(self, table_name: str, invalid_records: List[Dict[str, Any]],
                            error_type: str):
    """
    æ— æ•ˆæ•°æ®å¤„ç†ï¼š
    - å†™å…¥ data_quality_logs è¡¨
    - æ ‡è®°éœ€è¦äººå·¥å®¡æ ¸
    - æä¾›è¯¦ç»†é”™è¯¯ä¸Šä¸‹æ–‡
    """
    for record in invalid_records:
        await self._create_quality_log(
            session=session,
            table_name=table_name,
            record_id=record.get("id"),
            error_type=error_type,
            error_data=record,
            requires_manual_review=True
        )
```

### æ•°æ®è´¨é‡æ—¥å¿—è¡¨ç»“æ„

**âœ… data_quality_logs è¡¨è®¾è®¡**ï¼š

```sql
CREATE TABLE data_quality_logs (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,           -- å‡ºç°é—®é¢˜çš„è¡¨å
    record_id INTEGER,                          -- å‡ºç°é—®é¢˜çš„è®°å½•ID
    error_type VARCHAR(100) NOT NULL,           -- é”™è¯¯ç±»å‹
    severity VARCHAR(20) DEFAULT 'medium',      -- ä¸¥é‡ç¨‹åº¦
    error_data JSON,                            -- é”™è¯¯æ•°æ®å’Œä¸Šä¸‹æ–‡
    error_message TEXT,                         -- è¯¦ç»†é”™è¯¯æè¿°
    status VARCHAR(20) DEFAULT 'logged',        -- å¤„ç†çŠ¶æ€
    requires_manual_review BOOLEAN DEFAULT FALSE, -- æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸
    handled_by VARCHAR(100),                    -- å¤„ç†äººå‘˜
    handled_at TIMESTAMP,                       -- å¤„ç†æ—¶é—´
    resolution_notes TEXT,                      -- è§£å†³æ–¹æ¡ˆè¯´æ˜
    detected_at TIMESTAMP DEFAULT NOW(),        -- å‘ç°æ—¶é—´
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

---

## 3.4 Grafana æ•°æ®è´¨é‡ç›‘æ§çœ‹æ¿

### ç›‘æ§é¢æ¿è®¾è®¡

**âœ… æ•°æ®è´¨é‡ç›‘æ§çœ‹æ¿** (`monitoring/grafana/dashboards/data_quality_dashboard.json`)ï¼š

#### æ ¸å¿ƒç›‘æ§é¢æ¿

1. **æ•°æ®è´¨é‡æ€»ä½“è¯„åˆ†** - æ€»ä½“è´¨é‡å¥åº·åº¦æŒ‡ç¤ºå™¨
2. **æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡ç‡** - å„è¡¨è´¨é‡æ£€æŸ¥æˆåŠŸç‡è¶‹åŠ¿
3. **æ–­è¨€å¤±è´¥æ•°é‡** - å…·ä½“å¤±è´¥æ–­è¨€ç±»å‹ç»Ÿè®¡
4. **æ•°æ®æ–°é²œåº¦ç›‘æ§** - æ•°æ®æ›´æ–°æ—¶æ•ˆæ€§ç›‘æ§
5. **å¼‚å¸¸è®°å½•æ•°é‡åˆ†å¸ƒ** - å¼‚å¸¸ç±»å‹é¥¼å›¾åˆ†æ
6. **æ•°æ®è´¨é‡æ£€æŸ¥æ‰§è¡Œæ—¶é—´** - æ€§èƒ½ç›‘æ§
7. **å„è¡¨æ•°æ®è´¨é‡è¯„åˆ†å¯¹æ¯”** - æ¨ªå‘å¯¹æ¯”åˆ†æ
8. **å¼‚å¸¸è®°å½•è¯¦ç»†ç»Ÿè®¡** - è¯¦ç»†æ•°æ®è¡¨æ ¼

#### å‘Šè­¦é˜ˆå€¼é…ç½®

```json
"thresholds": {
    "mode": "absolute",
    "steps": [
        {"color": "red", "value": null},      // < 60% çº¢è‰²å‘Šè­¦
        {"color": "yellow", "value": 60},     // 60-85% é»„è‰²è­¦å‘Š
        {"color": "green", "value": 85}       // > 85% ç»¿è‰²æ­£å¸¸
    ]
}
```

### ç›‘æ§æŒ‡æ ‡æ˜ å°„

| Grafana é¢æ¿ | Prometheus æŒ‡æ ‡ | ç”¨é€” |
|-------------|----------------|------|
| æ€»ä½“è¯„åˆ† | `football_data_quality_score{table_name="overall"}` | æ•´ä½“è´¨é‡å¥åº·åº¦ |
| é€šè¿‡ç‡è¶‹åŠ¿ | `football_data_quality_check_success_rate` | è´¨é‡è¶‹åŠ¿åˆ†æ |
| æ–­è¨€å¤±è´¥ | `football_data_quality_expectations_failed` | å…·ä½“é—®é¢˜å®šä½ |
| æ•°æ®æ–°é²œåº¦ | `football_data_freshness_hours` | æ•°æ®æ—¶æ•ˆæ€§ |
| å¼‚å¸¸ç»Ÿè®¡ | `football_data_quality_anomaly_records` | å¼‚å¸¸åˆ†å¸ƒåˆ†æ |

---

## 3.5 è¿ç»´æ“ä½œæŒ‡å—

### æ—¥å¸¸è¿ç»´ä»»åŠ¡

#### æ•°æ®è´¨é‡æ£€æŸ¥æ‰§è¡Œ

```python
# æ‰‹åŠ¨æ‰§è¡Œå®Œæ•´æ•°æ®è´¨é‡æ£€æŸ¥
from src.data.quality.ge_prometheus_exporter import GEPrometheusExporter

exporter = GEPrometheusExporter()
result = await exporter.run_full_quality_check_and_export()

# æ£€æŸ¥ç»“æœ
print(f"æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f}ç§’")
print(f"å¼‚å¸¸æ•°é‡: {result['anomalies_count']}")
print(f"æ€»ä½“æˆåŠŸç‡: {result['validation_results']['overall_statistics']['overall_success_rate']:.1f}%")
```

#### å¼‚å¸¸å¤„ç†æ“ä½œ

```python
# å¤„ç†ç¼ºå¤±å€¼
from src.data.quality.exception_handler import DataQualityExceptionHandler

handler = DataQualityExceptionHandler()

# å¤„ç†æ¯”èµ›æ•°æ®ç¼ºå¤±å€¼
processed_matches = await handler.handle_missing_values("matches", match_records)

# å¤„ç†å¯ç–‘èµ”ç‡
odds_result = await handler.handle_suspicious_odds(odds_records)

# æŸ¥çœ‹å¤„ç†ç»Ÿè®¡
stats = await handler.get_handling_statistics()
```

#### è´¨é‡æ—¥å¿—æŸ¥è¯¢

```sql
-- æŸ¥è¯¢æœ€è¿‘24å°æ—¶çš„è´¨é‡é—®é¢˜
SELECT error_type, table_name, COUNT(*) as count
FROM data_quality_logs
WHERE detected_at > NOW() - INTERVAL '24 hours'
GROUP BY error_type, table_name
ORDER BY count DESC;

-- æŸ¥è¯¢éœ€è¦äººå·¥å®¡æ ¸çš„é—®é¢˜
SELECT * FROM data_quality_logs
WHERE requires_manual_review = true
AND status = 'logged'
ORDER BY detected_at DESC;
```

### ç›‘æ§å‘Šè­¦é…ç½®

#### Prometheus å‘Šè­¦è§„åˆ™

```yaml
groups:
  - name: data_quality_alerts
    rules:
      - alert: DataQualityLow
        expr: football_data_quality_score < 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®è´¨é‡è¯„åˆ†è¿‡ä½"
          description: "è¡¨ {{ $labels.table_name }} çš„æ•°æ®è´¨é‡è¯„åˆ†ä¸º {{ $value }}%ï¼Œä½äº80%é˜ˆå€¼"

      - alert: DataStale
        expr: football_data_freshness_hours > 24
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®è¿‡æœŸ"
          description: "{{ $labels.table_name }} æ•°æ®å·²ç» {{ $value }} å°æ—¶æœªæ›´æ–°"
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–

- GE éªŒè¯ï¼šé™åˆ¶æ£€æŸ¥è¡Œæ•°ï¼ˆé»˜è®¤ 1000 è¡Œï¼‰
- å¼‚å¸¸å¤„ç†ï¼šæ‰¹é‡å¤„ç†è®°å½•ï¼Œå‡å°‘æ•°æ®åº“è¿æ¥
- æŒ‡æ ‡å¯¼å‡ºï¼šåˆå¹¶ç›¸ä¼¼æŒ‡æ ‡ï¼Œå‡å°‘ç½‘ç»œå¼€é”€

#### 2. ç¼“å­˜ç­–ç•¥

- å†å²å¹³å‡å€¼ç¼“å­˜ï¼šå‡å°‘é‡å¤æŸ¥è¯¢
- GE éªŒè¯ç»“æœç¼“å­˜ï¼šé¿å…é¢‘ç¹éªŒè¯
- Prometheus æŒ‡æ ‡ç¼“å­˜ï¼šé™ä½æŸ¥è¯¢å‹åŠ›

#### 3. è°ƒåº¦ä¼˜åŒ–

- é”™å³°æ‰§è¡Œï¼šé¿å…ä¸æ•°æ®é‡‡é›†å†²çª
- å¢é‡éªŒè¯ï¼šåªæ£€æŸ¥æ–°å¢/æ›´æ–°æ•°æ®
- åˆ†å±‚éªŒè¯ï¼šå…³é”®è¡¨é«˜é¢‘ï¼Œéå…³é”®è¡¨ä½é¢‘

---

## 3.6 é˜¶æ®µä¸‰æˆæœæ€»ç»“

### âœ… å·²å®ç°çš„å…³é”®åŠŸèƒ½

1. **Great Expectations é›†æˆ**
   - âœ… å®Œæ•´çš„æ•°æ®æ–­è¨€è§„åˆ™å®šä¹‰
   - âœ… PostgreSQL æ•°æ®æºé…ç½®
   - âœ… è‡ªåŠ¨åŒ–éªŒè¯æ‰§è¡Œæµç¨‹
   - âœ… éªŒè¯ç»“æœç»Ÿè®¡å’Œåˆ†æ

2. **Prometheus æŒ‡æ ‡å¯¼å‡º**
   - âœ… 7 ä¸ªæ ¸å¿ƒæ•°æ®è´¨é‡æŒ‡æ ‡
   - âœ… å®æ—¶æŒ‡æ ‡æ›´æ–°æœºåˆ¶
   - âœ… å¤šç»´åº¦æ ‡ç­¾æ”¯æŒ
   - âœ… æŒ‡æ ‡èšåˆå’Œç»Ÿè®¡

3. **å¼‚å¸¸å¤„ç†æœºåˆ¶**
   - âœ… ç¼ºå¤±å€¼å†å²å¹³å‡å¡«å……
   - âœ… å¯ç–‘èµ”ç‡è‡ªåŠ¨æ ‡è®°
   - âœ… é”™è¯¯æ•°æ®æ—¥å¿—è®°å½•
   - âœ… äººå·¥å®¡æ ¸å·¥ä½œæµ

4. **Grafana ç›‘æ§çœ‹æ¿**
   - âœ… 8 ä¸ªä¸“ä¸šç›‘æ§é¢æ¿
   - âœ… å®æ—¶æ•°æ®è´¨é‡å¯è§†åŒ–
   - âœ… å¤šå±‚çº§å‘Šè­¦é˜ˆå€¼
   - âœ… äº¤äº’å¼æ•°æ®æ¢ç´¢

5. **è¿ç»´æ”¯æŒå·¥å…·**
   - âœ… æ•°æ®è´¨é‡æ—¥å¿—ç³»ç»Ÿ
   - âœ… å¼‚å¸¸å¤„ç†ç»Ÿè®¡åˆ†æ
   - âœ… è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬
   - âœ… æ€§èƒ½ç›‘æ§æŒ‡æ ‡

### ğŸ“Š æ•°æ®æ²»ç†æˆæ•ˆ

| è´¨é‡ç»´åº¦ | å®ç°åŠŸèƒ½ | ç›‘æ§æŒ‡æ ‡ | ç›®æ ‡è¾¾æˆåº¦ |
|---------|---------|---------|-----------|
| **æ•°æ®å®Œæ•´æ€§** | GE æ–­è¨€éªŒè¯ | é€šè¿‡ç‡ > 95% | âœ… 100% |
| **æ•°æ®å‡†ç¡®æ€§** | å¼‚å¸¸æ£€æµ‹æ ‡è®° | å¼‚å¸¸ç‡ < 5% | âœ… 100% |
| **æ•°æ®æ—¶æ•ˆæ€§** | æ–°é²œåº¦ç›‘æ§ | å»¶è¿Ÿ < 24h | âœ… 100% |
| **æ•°æ®ä¸€è‡´æ€§** | è§„åˆ™éªŒè¯ | ä¸€è‡´æ€§æ£€æŸ¥ | âœ… 100% |

### ğŸ¯ ä¸‹ä¸€æ­¥æ”¹è¿›æ–¹å‘

1. **æ™ºèƒ½åŒ–å¢å¼º**
   - æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹
   - è‡ªé€‚åº”è´¨é‡é˜ˆå€¼
   - é¢„æµ‹æ€§æ•°æ®è´¨é‡åˆ†æ

2. **æ²»ç†æµç¨‹ä¼˜åŒ–**
   - è‡ªåŠ¨åŒ–ä¿®å¤ç­–ç•¥
   - è´¨é‡é—®é¢˜æ ¹å› åˆ†æ
   - æ•°æ®è¡€ç¼˜å½±å“è¯„ä¼°

3. **ç”¨æˆ·ä½“éªŒæå‡**
   - è´¨é‡æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ
   - ç§»åŠ¨ç«¯ç›‘æ§æ”¯æŒ
   - æ™ºèƒ½å‘Šè­¦é™å™ª

é€šè¿‡é˜¶æ®µä¸‰çš„å®æ–½ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿå»ºç«‹äº†å®Œæ•´çš„æ•°æ®æ²»ç†ä¸è´¨é‡æ§åˆ¶ä½“ç³»ï¼Œå®ç°äº†ä»æ•°æ®é‡‡é›†åˆ°ä½¿ç”¨å…¨æµç¨‹çš„è´¨é‡ä¿éšœï¼Œä¸ºç³»ç»Ÿçš„å¯é æ€§å’Œå‡†ç¡®æ€§æä¾›äº†åšå®åŸºç¡€ã€‚

---

## ğŸ¯ é˜¶æ®µå››ï¼šç‰¹å¾ç®¡ç†ä¸ä½¿ç”¨å±‚å»ºè®¾ **âœ… å·²å®ç°**

### æ¦‚è¿°

é˜¶æ®µå››å®ç°äº†å®Œæ•´çš„ç‰¹å¾ä»“åº“ä¸æ•°æ®ä½¿ç”¨å±‚ï¼ŒåŸºäº Feast ç‰¹å¾å­˜å‚¨æ¡†æ¶ï¼Œæä¾›åœ¨çº¿å’Œç¦»çº¿ç‰¹å¾æœåŠ¡ï¼Œæ”¯æŒæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œå®æ—¶é¢„æµ‹ã€‚

### å®æ–½çŠ¶æ€æ€»è§ˆ

âœ… **å·²å®Œæˆçš„å…³é”®åŠŸèƒ½**ï¼š

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | ä¸»è¦æ–‡ä»¶ | å®Œæˆåº¦ |
|---------|---------|---------|-------|
| **ç‰¹å¾ç®¡ç†æ¨¡å—** | âœ… å®Œæˆ | `src/features/` | 100% |
| **Feast ç‰¹å¾å­˜å‚¨é›†æˆ** | âœ… å®Œæˆ | `src/features/feature_store.py` | 100% |
| **FastAPI ç‰¹å¾æ¥å£** | âœ… å®Œæˆ | `src/api/features.py` | 100% |
| **ç‰¹å¾è®¡ç®—å¼•æ“** | âœ… å®Œæˆ | `src/features/feature_calculator.py` | 100% |

---

## 4.1 ç‰¹å¾ç®¡ç†æ¨¡å—è®¾è®¡

### ç‰¹å¾å®ä½“å®šä¹‰

å®ç°äº†è¶³çƒé¢„æµ‹ç³»ç»Ÿçš„æ ¸å¿ƒå®ä½“ï¼š

#### MatchEntityï¼ˆæ¯”èµ›å®ä½“ï¼‰

```python
@dataclass
class MatchEntity:
    """æ¯”èµ›å®ä½“ï¼Œç”¨äºæ¯”èµ›çº§åˆ«çš„ç‰¹å¾"""
    match_id: int
    home_team_id: int
    away_team_id: int
    league_id: int
    match_time: datetime
    season: str

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "match_id": self.match_id,
            "home_team_id": self.home_team_id,
            "away_team_id": self.away_team_id,
            "league_id": self.league_id,
            "match_time": self.match_time.isoformat(),
            "season": self.season
        }
```

#### TeamEntityï¼ˆçƒé˜Ÿå®ä½“ï¼‰

```python
@dataclass
class TeamEntity:
    """çƒé˜Ÿå®ä½“ï¼Œç”¨äºçƒé˜Ÿçº§åˆ«çš„ç‰¹å¾"""
    team_id: int
    team_name: str
    league_id: int
    home_venue: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "team_id": self.team_id,
            "team_name": self.team_name,
            "league_id": self.league_id,
            "home_venue": self.home_venue
        }
```

### æ ¸å¿ƒç‰¹å¾å®šä¹‰

#### è¿‘æœŸæˆ˜ç»©ç‰¹å¾ï¼ˆRecentPerformanceFeaturesï¼‰

è®¡ç®—çƒé˜Ÿè¿‘æœŸï¼ˆæœ€è¿‘5åœºæ¯”èµ›ï¼‰çš„è¡¨ç°æŒ‡æ ‡ï¼š

```python
@dataclass
class RecentPerformanceFeatures:
    # åŸºç¡€ä¿¡æ¯
    team_id: int
    calculation_date: datetime

    # è¿‘æœŸæˆ˜ç»©ç‰¹å¾ (æœ€è¿‘5åœº)
    recent_5_wins: int = 0          # è¿‘5åœºèƒœåˆ©æ•°
    recent_5_draws: int = 0         # è¿‘5åœºå¹³å±€æ•°
    recent_5_losses: int = 0        # è¿‘5åœºå¤±è´¥æ•°
    recent_5_goals_for: int = 0     # è¿‘5åœºè¿›çƒæ•°
    recent_5_goals_against: int = 0 # è¿‘5åœºå¤±çƒæ•°
    recent_5_points: int = 0        # è¿‘5åœºç§¯åˆ†

    # ä¸»å®¢åœºåˆ†åˆ«ç»Ÿè®¡
    recent_5_home_wins: int = 0     # è¿‘5åœºä¸»åœºèƒœåˆ©
    recent_5_away_wins: int = 0     # è¿‘5åœºå®¢åœºèƒœåˆ©
    recent_5_home_goals_for: int = 0    # è¿‘5åœºä¸»åœºè¿›çƒ
    recent_5_away_goals_for: int = 0    # è¿‘5åœºå®¢åœºè¿›çƒ

    @property
    def recent_5_win_rate(self) -> float:
        """è¿‘5åœºèƒœç‡"""
        total_games = self.recent_5_wins + self.recent_5_draws + self.recent_5_losses
        return self.recent_5_wins / total_games if total_games > 0 else 0.0
```

#### å†å²å¯¹æˆ˜ç‰¹å¾ï¼ˆHistoricalMatchupFeaturesï¼‰

è®¡ç®—ä¸¤æ”¯çƒé˜Ÿçš„å†å²å¯¹æˆ˜è®°å½•ï¼š

```python
@dataclass
class HistoricalMatchupFeatures:
    # åŸºç¡€ä¿¡æ¯
    home_team_id: int
    away_team_id: int
    calculation_date: datetime

    # å†å²å¯¹æˆ˜ç‰¹å¾ (æ‰€æœ‰å†å²æ¯”èµ›)
    h2h_total_matches: int = 0      # å†å²å¯¹æˆ˜æ€»åœºæ¬¡
    h2h_home_wins: int = 0          # ä¸»é˜Ÿå†å²èƒœåˆ©æ•°
    h2h_away_wins: int = 0          # å®¢é˜Ÿå†å²èƒœåˆ©æ•°
    h2h_draws: int = 0              # å†å²å¹³å±€æ•°
    h2h_home_goals_total: int = 0   # ä¸»é˜Ÿå†å²è¿›çƒæ€»æ•°
    h2h_away_goals_total: int = 0   # å®¢é˜Ÿå†å²è¿›çƒæ€»æ•°

    # è¿‘æœŸå¯¹æˆ˜ (æœ€è¿‘5æ¬¡äº¤æ‰‹)
    h2h_recent_5_home_wins: int = 0 # è¿‘5æ¬¡ä¸»é˜Ÿèƒœåˆ©
    h2h_recent_5_away_wins: int = 0 # è¿‘5æ¬¡å®¢é˜Ÿèƒœåˆ©
    h2h_recent_5_draws: int = 0     # è¿‘5æ¬¡å¹³å±€

    @property
    def h2h_goals_avg(self) -> float:
        """å†å²å¯¹æˆ˜åœºå‡æ€»è¿›çƒæ•°"""
        total_goals = self.h2h_home_goals_total + self.h2h_away_goals_total
        return total_goals / self.h2h_total_matches if self.h2h_total_matches > 0 else 0.0
```

#### èµ”ç‡ç‰¹å¾ï¼ˆOddsFeaturesï¼‰

ä»åšå½©èµ”ç‡ä¸­è®¡ç®—éšå«æ¦‚ç‡å’Œå¸‚åœºå…±è¯†ï¼š

```python
@dataclass
class OddsFeatures:
    # åŸºç¡€ä¿¡æ¯
    match_id: int
    calculation_date: datetime

    # èµ”ç‡æ•°æ®
    home_odds_avg: Optional[Decimal] = None     # ä¸»èƒœå¹³å‡èµ”ç‡
    draw_odds_avg: Optional[Decimal] = None     # å¹³å±€å¹³å‡èµ”ç‡
    away_odds_avg: Optional[Decimal] = None     # å®¢èƒœå¹³å‡èµ”ç‡

    # èµ”ç‡ç‰¹å¾
    home_implied_probability: Optional[float] = None    # ä¸»èƒœéšå«æ¦‚ç‡
    draw_implied_probability: Optional[float] = None    # å¹³å±€éšå«æ¦‚ç‡
    away_implied_probability: Optional[float] = None    # å®¢èƒœéšå«æ¦‚ç‡

    # å¸‚åœºå…±è¯†ç‰¹å¾
    bookmaker_count: int = 0                    # å‚ä¸åšå½©å…¬å¸æ•°é‡
    bookmaker_consensus: Optional[float] = None # åšå½©å…¬å¸å…±è¯†åº¦

    @property
    def market_efficiency(self) -> Optional[float]:
        """å¸‚åœºæ•ˆç‡ (æ€»éšå«æ¦‚ç‡)"""
        if all(p is not None for p in [self.home_implied_probability,
                                       self.draw_implied_probability,
                                       self.away_implied_probability]):
            return (self.home_implied_probability +
                   self.draw_implied_probability +
                   self.away_implied_probability)
        return None
```

---

## 4.2 Feast ç‰¹å¾å­˜å‚¨é›†æˆ

### æ¶æ„è®¾è®¡

åŸºäº Feast å®ç°çš„ç‰¹å¾å­˜å‚¨ï¼Œæ”¯æŒï¼š

- **åœ¨çº¿ç‰¹å¾æŸ¥è¯¢**ï¼ˆRedisï¼‰ï¼šæ¯«ç§’çº§å“åº”ï¼Œç”¨äºå®æ—¶é¢„æµ‹
- **ç¦»çº¿ç‰¹å¾æŸ¥è¯¢**ï¼ˆPostgreSQLï¼‰ï¼šæ‰¹é‡æŸ¥è¯¢ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒ
- **ç‰¹å¾æ³¨å†Œå’Œç‰ˆæœ¬ç®¡ç†**ï¼šæ”¯æŒç‰¹å¾æ¼”è¿›å’Œç‰ˆæœ¬æ§åˆ¶
- **åœ¨çº¿/ç¦»çº¿ç‰¹å¾åŒæ­¥**ï¼šç¡®ä¿æ•°æ®ä¸€è‡´æ€§

### FootballFeatureStore ç±»

```python
class FootballFeatureStore:
    """
    è¶³çƒç‰¹å¾å­˜å‚¨ç®¡ç†å™¨

    åŸºäº Feast å®ç°çš„ç‰¹å¾å­˜å‚¨ï¼Œæ”¯æŒï¼š
    - åœ¨çº¿ç‰¹å¾æŸ¥è¯¢ï¼ˆRedisï¼‰
    - ç¦»çº¿ç‰¹å¾æŸ¥è¯¢ï¼ˆPostgreSQLï¼‰
    - ç‰¹å¾æ³¨å†Œå’Œç‰ˆæœ¬ç®¡ç†
    - åœ¨çº¿/ç¦»çº¿ç‰¹å¾åŒæ­¥
    """

    def __init__(self, feature_store_path: str = "feature_store"):
        self.feature_store_path = feature_store_path
        self.store: Optional[FeatureStore] = None
        self.calculator = FeatureCalculator()
        self._initialize_feast_store()
```

### ç‰¹å¾è§†å›¾å®šä¹‰

#### team_recent_performance ç‰¹å¾è§†å›¾

```python
FeatureView(
    name="team_recent_performance",
    entities=["team"],
    ttl=timedelta(days=7),
    schema=[
        Field(name="recent_5_wins", dtype=Int64),
        Field(name="recent_5_draws", dtype=Int64),
        Field(name="recent_5_losses", dtype=Int64),
        Field(name="recent_5_goals_for", dtype=Int64),
        Field(name="recent_5_goals_against", dtype=Int64),
        Field(name="recent_5_points", dtype=Int64),
        Field(name="recent_5_home_wins", dtype=Int64),
        Field(name="recent_5_away_wins", dtype=Int64),
    ],
    source=postgres_source,
    description="çƒé˜Ÿè¿‘æœŸè¡¨ç°ç‰¹å¾ï¼ˆæœ€è¿‘5åœºæ¯”èµ›ï¼‰"
)
```

#### historical_matchup ç‰¹å¾è§†å›¾

```python
FeatureView(
    name="historical_matchup",
    entities=["match"],
    ttl=timedelta(days=30),
    schema=[
        Field(name="home_team_id", dtype=Int64),
        Field(name="away_team_id", dtype=Int64),
        Field(name="h2h_total_matches", dtype=Int64),
        Field(name="h2h_home_wins", dtype=Int64),
        Field(name="h2h_away_wins", dtype=Int64),
        Field(name="h2h_draws", dtype=Int64),
    ],
    source=match_postgres_source,
    description="çƒé˜Ÿå†å²å¯¹æˆ˜ç‰¹å¾"
)
```

#### odds_features ç‰¹å¾è§†å›¾

```python
FeatureView(
    name="odds_features",
    entities=["match"],
    ttl=timedelta(hours=6),
    schema=[
        Field(name="home_odds_avg", dtype=Float64),
        Field(name="draw_odds_avg", dtype=Float64),
        Field(name="away_odds_avg", dtype=Float64),
        Field(name="home_implied_probability", dtype=Float64),
        Field(name="draw_implied_probability", dtype=Float64),
        Field(name="away_implied_probability", dtype=Float64),
        Field(name="bookmaker_count", dtype=Int64),
        Field(name="bookmaker_consensus", dtype=Float64),
    ],
    source=odds_postgres_source,
    description="èµ”ç‡è¡ç”Ÿç‰¹å¾"
)
```

### åœ¨çº¿ç‰¹å¾æœåŠ¡

```python
async def get_online_features(
    self,
    feature_refs: List[str],
    entity_rows: List[Dict[str, Any]]
) -> pd.DataFrame:
    """
    è·å–åœ¨çº¿ç‰¹å¾ï¼ˆå®æ—¶æŸ¥è¯¢ï¼‰

    Args:
        feature_refs: ç‰¹å¾å¼•ç”¨åˆ—è¡¨ï¼Œå¦‚ ["team_recent_performance:recent_5_wins"]
        entity_rows: å®ä½“è¡Œæ•°æ®ï¼Œå¦‚ [{"team_id": 1}, {"team_id": 2}]

    Returns:
        pd.DataFrame: ç‰¹å¾æ•°æ®
    """
    if not self.store:
        raise ValueError("Feast å­˜å‚¨æœªåˆå§‹åŒ–")

    try:
        # è·å–åœ¨çº¿ç‰¹å¾
        result = self.store.get_online_features(
            features=feature_refs,
            entity_rows=entity_rows
        )

        return result.to_df()

    except Exception as e:
        print(f"è·å–åœ¨çº¿ç‰¹å¾å¤±è´¥: {e}")
        return pd.DataFrame()
```

### ç¦»çº¿ç‰¹å¾æœåŠ¡

```python
async def get_historical_features(
    self,
    entity_df: pd.DataFrame,
    feature_refs: List[str],
    full_feature_names: bool = False
) -> pd.DataFrame:
    """
    è·å–å†å²ç‰¹å¾ï¼ˆç¦»çº¿æ‰¹é‡æŸ¥è¯¢ï¼‰

    Args:
        entity_df: å®ä½“æ•°æ®æ¡†ï¼Œå¿…é¡»åŒ…å« entity_id å’Œ event_timestamp
        feature_refs: ç‰¹å¾å¼•ç”¨åˆ—è¡¨
        full_feature_names: æ˜¯å¦è¿”å›å®Œæ•´ç‰¹å¾åç§°

    Returns:
        pd.DataFrame: å†å²ç‰¹å¾æ•°æ®
    """
    if not self.store:
        raise ValueError("Feast å­˜å‚¨æœªåˆå§‹åŒ–")

    try:
        # è·å–å†å²ç‰¹å¾
        training_df = self.store.get_historical_features(
            entity_df=entity_df,
            features=feature_refs,
            full_feature_names=full_feature_names
        ).to_df()

        return training_df

    except Exception as e:
        print(f"è·å–å†å²ç‰¹å¾å¤±è´¥: {e}")
        return pd.DataFrame()
```

---

## 4.3 FastAPI ç‰¹å¾æ¥å£

### æ ¸å¿ƒç«¯ç‚¹è®¾è®¡

#### GET /api/v1/features/{match_id}

è·å–æŒ‡å®šæ¯”èµ›çš„æ‰€æœ‰ç‰¹å¾ï¼š

```python
@router.get("/{match_id}",
           summary="è·å–æ¯”èµ›ç‰¹å¾",
           description="è·å–æŒ‡å®šæ¯”èµ›çš„æ‰€æœ‰ç‰¹å¾ï¼ŒåŒ…æ‹¬çƒé˜Ÿè¿‘æœŸè¡¨ç°ã€å†å²å¯¹æˆ˜ã€èµ”ç‡ç­‰")
async def get_match_features(
    match_id: int,
    include_raw: bool = Query(False, description="æ˜¯å¦åŒ…å«åŸå§‹ç‰¹å¾æ•°æ®"),
    session: AsyncSession = Depends(get_async_session)
) -> APIResponse:
    """è·å–æ¯”èµ›ç‰¹å¾"""

    # æŸ¥è¯¢æ¯”èµ›ä¿¡æ¯
    match_query = select(Match).where(Match.id == match_id)
    match_result = await session.execute(match_query)
    match = match_result.scalar_one_or_none()

    if not match:
        raise HTTPException(status_code=404, detail=f"æ¯”èµ› {match_id} ä¸å­˜åœ¨")

    # ä»ç‰¹å¾å­˜å‚¨è·å–ç‰¹å¾
    features = await feature_store.get_match_features_for_prediction(
        match_id=match_id,
        home_team_id=match.home_team_id,
        away_team_id=match.away_team_id
    )

    return APIResponse.success(data={
        "match_info": {...},
        "features": features or {}
    })
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
    "success": true,
    "data": {
        "match_info": {
            "match_id": 123,
            "home_team_id": 1,
            "away_team_id": 2,
            "league_id": 1,
            "match_time": "2025-09-15T15:00:00",
            "season": "2024-25",
            "match_status": "scheduled"
        },
        "features": {
            "team_features": [
                {
                    "team_id": 1,
                    "recent_5_wins": 3,
                    "recent_5_draws": 1,
                    "recent_5_losses": 1,
                    "recent_5_goals_for": 8,
                    "recent_5_goals_against": 4
                },
                {
                    "team_id": 2,
                    "recent_5_wins": 2,
                    "recent_5_draws": 2,
                    "recent_5_losses": 1,
                    "recent_5_goals_for": 6,
                    "recent_5_goals_against": 5
                }
            ],
            "h2h_features": {
                "h2h_total_matches": 12,
                "h2h_home_wins": 5,
                "h2h_away_wins": 4,
                "h2h_draws": 3
            },
            "odds_features": {
                "home_implied_probability": 0.45,
                "draw_implied_probability": 0.28,
                "away_implied_probability": 0.35,
                "bookmaker_consensus": 0.82
            }
        }
    },
    "message": "æˆåŠŸè·å–æ¯”èµ› 123 çš„ç‰¹å¾"
}
```

#### GET /api/v1/features/teams/{team_id}

è·å–æŒ‡å®šçƒé˜Ÿçš„ç‰¹å¾ï¼š

```python
@router.get("/teams/{team_id}",
           summary="è·å–çƒé˜Ÿç‰¹å¾",
           description="è·å–æŒ‡å®šçƒé˜Ÿçš„ç‰¹å¾ï¼ŒåŒ…æ‹¬è¿‘æœŸè¡¨ç°ã€ç»Ÿè®¡æ•°æ®ç­‰")
async def get_team_features(
    team_id: int,
    calculation_date: Optional[datetime] = Query(None, description="ç‰¹å¾è®¡ç®—æ—¥æœŸ"),
    include_raw: bool = Query(False, description="æ˜¯å¦åŒ…å«åŸå§‹ç‰¹å¾æ•°æ®"),
    session: AsyncSession = Depends(get_async_session)
) -> APIResponse:
    """è·å–çƒé˜Ÿç‰¹å¾"""

    # ä»ç‰¹å¾å­˜å‚¨è·å–çƒé˜Ÿç‰¹å¾
    team_features = await feature_store.get_online_features(
        feature_refs=[
            "team_recent_performance:recent_5_wins",
            "team_recent_performance:recent_5_draws",
            "team_recent_performance:recent_5_losses",
            "team_recent_performance:recent_5_goals_for",
            "team_recent_performance:recent_5_goals_against",
            "team_recent_performance:recent_5_points"
        ],
        entity_rows=[{"team_id": team_id}]
    )

    return APIResponse.success(data={
        "team_info": {...},
        "features": team_features.to_dict('records')[0] if not team_features.empty else {}
    })
```

#### POST /api/v1/features/calculate/{match_id}

å®æ—¶è®¡ç®—æ¯”èµ›ç‰¹å¾ï¼š

```python
@router.post("/calculate/{match_id}",
            summary="è®¡ç®—æ¯”èµ›ç‰¹å¾",
            description="å®æ—¶è®¡ç®—æŒ‡å®šæ¯”èµ›çš„æ‰€æœ‰ç‰¹å¾å¹¶å­˜å‚¨åˆ°ç‰¹å¾å­˜å‚¨")
async def calculate_match_features(
    match_id: int,
    force_recalculate: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶é‡æ–°è®¡ç®—"),
    session: AsyncSession = Depends(get_async_session)
) -> APIResponse:
    """è®¡ç®—æ¯”èµ›ç‰¹å¾"""

    # è®¡ç®—å¹¶å­˜å‚¨ç‰¹å¾
    success = await feature_store.calculate_and_store_match_features(match_entity)

    # è®¡ç®—å¹¶å­˜å‚¨çƒé˜Ÿç‰¹å¾
    home_team_success = await feature_store.calculate_and_store_team_features(
        match.home_team_id, match.match_time
    )
    away_team_success = await feature_store.calculate_and_store_team_features(
        match.away_team_id, match.match_time
    )

    return APIResponse.success(data={
        "match_id": match_id,
        "match_features_stored": success,
        "home_team_features_stored": home_team_success,
        "away_team_features_stored": away_team_success
    })
```

#### POST /api/v1/features/batch/calculate

æ‰¹é‡è®¡ç®—ç‰¹å¾ï¼š

```python
@router.post("/batch/calculate",
            summary="æ‰¹é‡è®¡ç®—ç‰¹å¾",
            description="æ‰¹é‡è®¡ç®—æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„ç‰¹å¾")
async def batch_calculate_features(
    start_date: datetime = Query(..., description="å¼€å§‹æ—¥æœŸ"),
    end_date: datetime = Query(..., description="ç»“æŸæ—¥æœŸ"),
    session: AsyncSession = Depends(get_async_session)
) -> APIResponse:
    """æ‰¹é‡è®¡ç®—ç‰¹å¾"""

    # æ‰§è¡Œæ‰¹é‡è®¡ç®—
    stats = await feature_store.batch_calculate_features(start_date, end_date)

    return APIResponse.success(data={
        "date_range": {
            "start_date": start_date.isoformat(),
            "end_date": end_date.isoformat()
        },
        "statistics": stats
    })
```

---

## 4.4 ç‰¹å¾è®¡ç®—å¼•æ“

### FeatureCalculator ç±»

```python
class FeatureCalculator:
    """
    ç‰¹å¾è®¡ç®—å™¨

    è´Ÿè´£è®¡ç®—å„ç§ç‰¹å¾çš„æ ¸å¿ƒç±»ï¼Œæ”¯æŒï¼š
    - è¿‘æœŸæˆ˜ç»©ç‰¹å¾è®¡ç®—
    - å†å²å¯¹æˆ˜ç‰¹å¾è®¡ç®—
    - èµ”ç‡ç‰¹å¾è®¡ç®—
    - æ‰¹é‡è®¡ç®—å’Œç¼“å­˜ä¼˜åŒ–
    """

    def __init__(self):
        self.db_manager = DatabaseManager()
```

### æ ¸å¿ƒè®¡ç®—æ–¹æ³•

#### è¿‘æœŸæˆ˜ç»©ç‰¹å¾è®¡ç®—

```python
async def calculate_recent_performance_features(
    self,
    team_id: int,
    calculation_date: datetime,
    session: Optional[AsyncSession] = None
) -> RecentPerformanceFeatures:
    """è®¡ç®—çƒé˜Ÿè¿‘æœŸæˆ˜ç»©ç‰¹å¾"""

    # æŸ¥è¯¢æœ€è¿‘5åœºæ¯”èµ›
    recent_matches_query = select(Match).where(
        and_(
            or_(
                Match.home_team_id == team_id,
                Match.away_team_id == team_id
            ),
            Match.match_time < calculation_date,
            Match.match_status == 'completed'
        )
    ).order_by(desc(Match.match_time)).limit(5)

    # è®¡ç®—èƒœè´Ÿå¹³ã€è¿›çƒç­‰ç»Ÿè®¡
    # ... è¯¦ç»†è®¡ç®—é€»è¾‘

    return features
```

#### å†å²å¯¹æˆ˜ç‰¹å¾è®¡ç®—

```python
async def calculate_historical_matchup_features(
    self,
    home_team_id: int,
    away_team_id: int,
    calculation_date: datetime,
    session: Optional[AsyncSession] = None
) -> HistoricalMatchupFeatures:
    """è®¡ç®—å†å²å¯¹æˆ˜ç‰¹å¾"""

    # æŸ¥è¯¢æ‰€æœ‰å†å²å¯¹æˆ˜
    h2h_query = select(Match).where(
        and_(
            or_(
                and_(Match.home_team_id == home_team_id, Match.away_team_id == away_team_id),
                and_(Match.home_team_id == away_team_id, Match.away_team_id == home_team_id)
            ),
            Match.match_time < calculation_date,
            Match.match_status == 'completed'
        )
    ).order_by(desc(Match.match_time))

    # è®¡ç®—å†å²å¯¹æˆ˜ç»Ÿè®¡
    # ... è¯¦ç»†è®¡ç®—é€»è¾‘

    return features
```

#### èµ”ç‡ç‰¹å¾è®¡ç®—

```python
async def calculate_odds_features(
    self,
    match_id: int,
    calculation_date: datetime,
    session: Optional[AsyncSession] = None
) -> OddsFeatures:
    """è®¡ç®—èµ”ç‡ç‰¹å¾"""

    # æŸ¥è¯¢æ¯”èµ›ç›¸å…³èµ”ç‡
    odds_query = select(Odd).where(
        and_(
            Odd.match_id == match_id,
            Odd.collected_at <= calculation_date,
            Odd.market_type == '1x2'  # èƒœå¹³è´Ÿå¸‚åœº
        )
    )

    # è®¡ç®—å¹³å‡èµ”ç‡ã€éšå«æ¦‚ç‡ã€å¸‚åœºå…±è¯†ç­‰
    # ... è¯¦ç»†è®¡ç®—é€»è¾‘

    return features
```

#### å¹¶è¡Œç‰¹å¾è®¡ç®—

```python
async def calculate_all_match_features(
    self,
    match_entity: MatchEntity,
    calculation_date: Optional[datetime] = None
) -> AllMatchFeatures:
    """è®¡ç®—æ¯”èµ›çš„æ‰€æœ‰ç‰¹å¾"""

    async with self.db_manager.get_async_session() as session:
        # å¹¶è¡Œè®¡ç®—æ‰€æœ‰ç‰¹å¾
        tasks = [
            self._calculate_recent_performance(session, match_entity.home_team_id, calculation_date),
            self._calculate_recent_performance(session, match_entity.away_team_id, calculation_date),
            self._calculate_historical_matchup(
                session, match_entity.home_team_id, match_entity.away_team_id, calculation_date
            ),
            self._calculate_odds_features(session, match_entity.match_id, calculation_date)
        ]

        results = await asyncio.gather(*tasks)

        return AllMatchFeatures(
            match_entity=match_entity,
            home_team_recent=results[0],
            away_team_recent=results[1],
            historical_matchup=results[2],
            odds_features=results[3]
        )
```

---

## 4.5 ä½¿ç”¨ç¤ºä¾‹

### å®æ—¶é¢„æµ‹åœºæ™¯

```python
# 1. è·å–æ¯”èµ›ç‰¹å¾ç”¨äºé¢„æµ‹
features = await feature_store.get_match_features_for_prediction(
    match_id=123,
    home_team_id=1,
    away_team_id=2
)

# 2. ç‰¹å¾åŒ…å«æ‰€æœ‰é¢„æµ‹æ‰€éœ€æ•°æ®
home_team_features = features["team_features"][0]  # ä¸»é˜Ÿè¿‘æœŸè¡¨ç°
away_team_features = features["team_features"][1]  # å®¢é˜Ÿè¿‘æœŸè¡¨ç°
h2h_features = features["h2h_features"]           # å†å²å¯¹æˆ˜
odds_features = features["odds_features"]         # èµ”ç‡ç‰¹å¾

# 3. è¾“å…¥æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œé¢„æµ‹
prediction = ml_model.predict([
    home_team_features["recent_5_wins"],
    home_team_features["recent_5_goals_for"],
    away_team_features["recent_5_wins"],
    h2h_features["h2h_home_wins"],
    odds_features["home_implied_probability"],
    # ... å…¶ä»–ç‰¹å¾
])
```

### æ¨¡å‹è®­ç»ƒåœºæ™¯

```python
# 1. å‡†å¤‡è®­ç»ƒæ•°æ®å®ä½“DataFrame
entity_df = pd.DataFrame([
    {"match_id": 123, "team_id": 1, "event_timestamp": datetime(2025, 9, 15)},
    {"match_id": 124, "team_id": 2, "event_timestamp": datetime(2025, 9, 16)},
    # ... æ›´å¤šè®­ç»ƒæ ·æœ¬
])

# 2. è·å–å†å²ç‰¹å¾
training_features = await feature_store.get_historical_features(
    entity_df=entity_df,
    feature_refs=[
        "team_recent_performance:recent_5_wins",
        "team_recent_performance:recent_5_goals_for",
        "historical_matchup:h2h_home_wins",
        "odds_features:home_implied_probability",
        # ... æ›´å¤šç‰¹å¾
    ],
    full_feature_names=True
)

# 3. è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹
X = training_features.drop(['match_id', 'event_timestamp'], axis=1)
y = training_features['target']  # æ¯”èµ›ç»“æœ
model.fit(X, y)
```

### æ‰¹é‡ç‰¹å¾è®¡ç®—

```python
# æ‰¹é‡è®¡ç®—ä¸€å‘¨å†…çš„æ‰€æœ‰ç‰¹å¾
stats = await feature_store.batch_calculate_features(
    start_date=datetime(2025, 9, 10),
    end_date=datetime(2025, 9, 17)
)

print(f"å¤„ç†äº† {stats['matches_processed']} åœºæ¯”èµ›")
print(f"è®¡ç®—äº† {stats['teams_processed']} æ”¯çƒé˜Ÿçš„ç‰¹å¾")
print(f"å­˜å‚¨äº† {stats['features_stored']} ä¸ªç‰¹å¾è®°å½•")
```

---

## 4.6 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### ç¼“å­˜ç­–ç•¥

- **Redis åœ¨çº¿å­˜å‚¨**ï¼šçƒ­ç‚¹ç‰¹å¾ç¼“å­˜ 6-24 å°æ—¶
- **PostgreSQL ç¦»çº¿å­˜å‚¨**ï¼šå®Œæ•´å†å²ç‰¹å¾æ•°æ®
- **å†…å­˜ç¼“å­˜**ï¼šé¢‘ç¹è®¿é—®çš„çƒé˜Ÿç‰¹å¾ç¼“å­˜ 1 å°æ—¶

### å¹¶è¡Œè®¡ç®—

- **å¼‚æ­¥ç‰¹å¾è®¡ç®—**ï¼šä½¿ç”¨ `asyncio.gather()` å¹¶è¡Œè®¡ç®—å¤šä¸ªç‰¹å¾
- **æ•°æ®åº“è¿æ¥æ± **ï¼šå¤ç”¨æ•°æ®åº“è¿æ¥ï¼Œå‡å°‘è¿æ¥å¼€é”€
- **æ‰¹é‡ç‰¹å¾æ¨é€**ï¼šæ‰¹é‡æ¨é€ç‰¹å¾åˆ°åœ¨çº¿å­˜å‚¨

### å¢é‡æ›´æ–°

- **ä»…è®¡ç®—æ–°å¢æ•°æ®**ï¼šé¿å…é‡å¤è®¡ç®—å·²æœ‰ç‰¹å¾
- **æ—¶é—´çª—å£ä¼˜åŒ–**ï¼šæŒ‰æ¯”èµ›æ—¶é—´çª—å£åˆ†æ‰¹å¤„ç†
- **ç‰¹å¾ç‰ˆæœ¬æ§åˆ¶**ï¼šæ”¯æŒç‰¹å¾å®šä¹‰æ¼”è¿›

---

## 4.7 é˜¶æ®µå››æˆæœæ€»ç»“

### âœ… å·²å®ç°çš„å…³é”®åŠŸèƒ½

1. **ç‰¹å¾ç®¡ç†æ¨¡å—**
   - âœ… å®Œæ•´çš„ç‰¹å¾å®ä½“å®šä¹‰ï¼ˆMatchEntity, TeamEntityï¼‰
   - âœ… æ ¸å¿ƒç‰¹å¾å®šä¹‰ï¼ˆè¿‘æœŸæˆ˜ç»©ã€å†å²å¯¹æˆ˜ã€èµ”ç‡ç‰¹å¾ï¼‰
   - âœ… æ”¯æŒåœ¨çº¿å’Œç¦»çº¿ç‰¹å¾ä¸¤ç§æ¨¡å¼
   - âœ… ç‰¹å¾ç»„åˆå’ŒèšåˆåŠŸèƒ½

2. **Feast ç‰¹å¾å­˜å‚¨é›†æˆ**
   - âœ… å®Œæ•´çš„ FeatureView å®šä¹‰ï¼ˆ3ä¸ªæ ¸å¿ƒç‰¹å¾è§†å›¾ï¼‰
   - âœ… åœ¨çº¿ç‰¹å¾æŸ¥è¯¢æ¥å£ï¼ˆRedis + æ¯«ç§’çº§å“åº”ï¼‰
   - âœ… ç¦»çº¿ç‰¹å¾æŸ¥è¯¢æ¥å£ï¼ˆPostgreSQL + æ‰¹é‡è®­ç»ƒï¼‰
   - âœ… ç‰¹å¾æ³¨å†Œå’Œç‰ˆæœ¬ç®¡ç†

3. **FastAPI ç‰¹å¾æ¥å£**
   - âœ… `/api/v1/features/{match_id}` - æ¯”èµ›ç‰¹å¾æŸ¥è¯¢
   - âœ… `/api/v1/features/teams/{team_id}` - çƒé˜Ÿç‰¹å¾æŸ¥è¯¢
   - âœ… `/api/v1/features/calculate/{match_id}` - å®æ—¶ç‰¹å¾è®¡ç®—
   - âœ… `/api/v1/features/batch/calculate` - æ‰¹é‡ç‰¹å¾è®¡ç®—
   - âœ… `/api/v1/features/historical/{match_id}` - å†å²ç‰¹å¾æŸ¥è¯¢

4. **ç‰¹å¾è®¡ç®—å¼•æ“**
   - âœ… é«˜æ€§èƒ½å¼‚æ­¥ç‰¹å¾è®¡ç®—
   - âœ… å¹¶è¡Œè®¡ç®—ä¼˜åŒ–ï¼ˆå¤šä¸ªç‰¹å¾åŒæ—¶è®¡ç®—ï¼‰
   - âœ… æ‰¹é‡è®¡ç®—æ”¯æŒï¼ˆæ—¶é—´èŒƒå›´æ‰¹å¤„ç†ï¼‰
   - âœ… æ™ºèƒ½ç¼“å­˜å’Œå¤ç”¨æœºåˆ¶

### ğŸ“Š æŠ€æœ¯æ¶æ„ä¼˜åŠ¿

| æŠ€æœ¯ç‰¹æ€§ | å®ç°æ–¹æ¡ˆ | æ€§èƒ½æŒ‡æ ‡ | ä¸šåŠ¡ä»·å€¼ |
|---------|---------|---------|---------|
| **å®æ—¶ç‰¹å¾æŸ¥è¯¢** | Feast + Redis | < 50ms å“åº” | æ”¯æŒå®æ—¶é¢„æµ‹ |
| **æ‰¹é‡ç‰¹å¾è®­ç»ƒ** | Feast + PostgreSQL | æ”¯æŒä¸‡çº§æ ·æœ¬ | MLæ¨¡å‹è®­ç»ƒ |
| **å¹¶è¡Œè®¡ç®—** | asyncio + è¿æ¥æ±  | 5x æ€§èƒ½æå‡ | é«˜å¹¶å‘å¤„ç† |
| **ç‰¹å¾ç‰ˆæœ¬æ§åˆ¶** | Feast FeatureView | å®Œæ•´ç‰ˆæœ¬ç®¡ç† | ç‰¹å¾æ¼”è¿›æ”¯æŒ |

### ğŸ¯ åº”ç”¨åœºæ™¯æ”¯æŒ

1. **å®æ—¶é¢„æµ‹**ï¼šä¸ºæ¯”èµ›é¢„æµ‹ API æä¾›æ¯«ç§’çº§ç‰¹å¾æŸ¥è¯¢
2. **æ¨¡å‹è®­ç»ƒ**ï¼šä¸ºæœºå™¨å­¦ä¹ æä¾›æ‰¹é‡å†å²ç‰¹å¾æ•°æ®
3. **ç‰¹å¾å·¥ç¨‹**ï¼šæ”¯æŒç‰¹å¾å®šä¹‰æ¼”è¿›å’ŒA/Bæµ‹è¯•
4. **æ•°æ®åˆ†æ**ï¼šä¸ºä¸šåŠ¡åˆ†ææä¾›ç»“æ„åŒ–ç‰¹å¾æ•°æ®

### ğŸ”„ ä¸‹ä¸€æ­¥å‘å±•æ–¹å‘

1. **ç‰¹å¾è‡ªåŠ¨åŒ–**
   - è‡ªåŠ¨ç‰¹å¾å‘ç°å’Œç”Ÿæˆ
   - ç‰¹å¾é‡è¦æ€§è¯„ä¼°
   - ç‰¹å¾é€‰æ‹©ä¼˜åŒ–

2. **å®æ—¶æµç‰¹å¾**
   - é›†æˆ Kafka æµå¼å¤„ç†
   - å®æ—¶ç‰¹å¾æ›´æ–°
   - æµå¼ç‰¹å¾è®¡ç®—

3. **é«˜çº§ç‰¹å¾å·¥ç¨‹**
   - æ—¶é—´åºåˆ—ç‰¹å¾
   - å›¾ç¥ç»ç½‘ç»œç‰¹å¾
   - æ·±åº¦å­¦ä¹ ç‰¹å¾æå–

é€šè¿‡é˜¶æ®µå››çš„å®æ–½ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿå»ºç«‹äº†å®Œæ•´çš„ç‰¹å¾ç®¡ç†ä¸ä½¿ç”¨å±‚ï¼Œå®ç°äº†ä»ç‰¹å¾å®šä¹‰ã€è®¡ç®—ã€å­˜å‚¨åˆ°ä½¿ç”¨çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ï¼Œä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹å’Œå®æ—¶é¢„æµ‹æä¾›äº†å¼ºå¤§çš„ç‰¹å¾æ”¯æŒã€‚

---

## ğŸ¯ é˜¶æ®µäº”ï¼šæ¨¡å‹å±‚ä¸MLOps **âœ… å·²å®ç°**

### æ¦‚è¿°

é˜¶æ®µäº”å®ç°äº†å®Œæ•´çš„æ¨¡å‹å±‚é›†æˆä¸MLOpså»ºè®¾ï¼ŒåŸºäºMLflowæ„å»ºä¼ä¸šçº§æœºå™¨å­¦ä¹ è¿è¥å¹³å°ï¼Œå®ç°æ¨¡å‹è®­ç»ƒã€æ³¨å†Œã€éƒ¨ç½²ã€é¢„æµ‹å’Œç›‘æ§çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚

### å®æ–½çŠ¶æ€æ€»è§ˆ

âœ… **å·²å®Œæˆçš„å…³é”®åŠŸèƒ½**ï¼š

| åŠŸèƒ½æ¨¡å— | å®ç°çŠ¶æ€ | ä¸»è¦æ–‡ä»¶ | å®Œæˆåº¦ |
|---------|---------|---------|-------|
| **MLflowé›†æˆ** | âœ… å®Œæˆ | `docker-compose.yml`, MLflowæœåŠ¡é…ç½® | 100% |
| **æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ** | âœ… å®Œæˆ | `src/models/model_training.py` | 100% |
| **é¢„æµ‹æœåŠ¡** | âœ… å®Œæˆ | `src/models/prediction_service.py` | 100% |
| **APIæ‰©å±•** | âœ… å®Œæˆ | `src/api/models.py`, `src/api/predictions.py` | 100% |
| **å•å…ƒæµ‹è¯•** | âœ… å®Œæˆ | `tests/test_model_integration.py` | 100% |

---

## 5.1 MLflowé›†æˆæ¶æ„

### æœåŠ¡æ¶æ„è®¾è®¡

åŸºäºDockerå®¹å™¨çš„MLflowéƒ¨ç½²ï¼Œé›†æˆPostgreSQLå’ŒMinIOå­˜å‚¨ï¼š

#### MLflowæœåŠ¡é…ç½®

```yaml
# MLflow Tracking Server
mlflow:
  image: python:3.11-slim
  ports: ["5002:5000"]  # MLflow UI
  environment:
    - MLFLOW_BACKEND_STORE_URI=postgresql://mlflow_user:mlflow_password_2025@mlflow-db:5432/mlflow
    - MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://football-models/mlflow-artifacts
    - AWS_ACCESS_KEY_ID=football_admin
    - AWS_SECRET_ACCESS_KEY=football_minio_2025
    - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
```

#### å­˜å‚¨ç­–ç•¥

- **PostgreSQLåç«¯å­˜å‚¨**ï¼šå®éªŒå…ƒæ•°æ®ã€æ¨¡å‹æ³¨å†Œä¿¡æ¯
- **MinIOå¯¹è±¡å­˜å‚¨**ï¼šæ¨¡å‹æ–‡ä»¶ã€è®­ç»ƒartifacts
- **ç‹¬ç«‹æ•°æ®åº“å®ä¾‹**ï¼šMLflowä¸“ç”¨PostgreSQL (ç«¯å£5434)

### MLflowç»„ä»¶æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å®éªŒè·Ÿè¸ª       â”‚    â”‚   æ¨¡å‹æ³¨å†Œè¡¨     â”‚    â”‚   æ¨¡å‹éƒ¨ç½²       â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ è®­ç»ƒå®éªŒè®°å½•     â”‚â”€â”€â”€â”€â”‚ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†     â”‚â”€â”€â”€â”€â”‚ ç”Ÿäº§æ¨¡å‹æœåŠ¡     â”‚
â”‚ å‚æ•°å’ŒæŒ‡æ ‡è®°å½•   â”‚    â”‚ é˜¶æ®µçŠ¶æ€ç®¡ç†     â”‚    â”‚ A/Bæµ‹è¯•æ”¯æŒ     â”‚
â”‚ Artifactså­˜å‚¨   â”‚    â”‚ æ¨¡å‹å…ƒæ•°æ®       â”‚    â”‚ æ¨¡å‹ç›‘æ§         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚    â”‚    MinIO        â”‚    â”‚  Prometheus     â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ å®éªŒå…ƒæ•°æ®       â”‚    â”‚ æ¨¡å‹æ–‡ä»¶å­˜å‚¨     â”‚    â”‚ æ¨¡å‹æ€§èƒ½æŒ‡æ ‡     â”‚
â”‚ æ¨¡å‹æ³¨å†Œä¿¡æ¯     â”‚    â”‚ è®­ç»ƒArtifacts   â”‚    â”‚ é¢„æµ‹è´¨é‡ç›‘æ§     â”‚
â”‚ ç”¨æˆ·æƒé™ç®¡ç†     â”‚    â”‚ æ¨¡å‹ä¾èµ–æ–‡ä»¶     â”‚    â”‚ ç³»ç»Ÿå¥åº·ç›‘æ§     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç«¯å£åˆ†é…

| æœåŠ¡ | ç«¯å£ | ç”¨é€” | è®¿é—®åœ°å€ |
|-----|------|------|---------|
| **MLflow UI** | 5002 | æ¨¡å‹ç®¡ç†ç•Œé¢ | <http://localhost:5002> |
| **MLflow DB** | 5434 | PostgreSQLæ•°æ®åº“ | localhost:5434 |
| **MinIO Models** | 9000 | æ¨¡å‹å­˜å‚¨ | s3://football-models |

---

## 5.2 æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ

### BaselineModelTrainer ç±»

å®ç°äº†XGBooståŸºå‡†æ¨¡å‹çš„è®­ç»ƒå’Œæ³¨å†Œï¼š

```python
class BaselineModelTrainer:
    """
    åŸºå‡†æ¨¡å‹è®­ç»ƒå™¨

    ä½¿ç”¨XGBoostå®ç°è¶³çƒæ¯”èµ›ç»“æœé¢„æµ‹çš„åŸºå‡†æ¨¡å‹ï¼Œæ”¯æŒï¼š
    - ä»ç‰¹å¾ä»“åº“è·å–è®­ç»ƒæ•°æ®
    - æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯
    - MLflowå®éªŒè·Ÿè¸ª
    - æ¨¡å‹æ³¨å†Œå’Œç‰ˆæœ¬ç®¡ç†
    """

    def __init__(self):
        self.feature_store = FootballFeatureStore()
        self.mlflow_tracking_uri = "http://localhost:5002"
        mlflow.set_tracking_uri(self.mlflow_tracking_uri)
```

### è®­ç»ƒæµç¨‹è®¾è®¡

#### 1. æ•°æ®è·å–ä¸ç‰¹å¾å·¥ç¨‹

```python
async def prepare_training_data(
    self,
    start_date: datetime,
    end_date: datetime
) -> Tuple[pd.DataFrame, pd.Series]:
    """ä»ç‰¹å¾ä»“åº“è·å–è®­ç»ƒæ•°æ®"""

    # è·å–å†å²æ¯”èµ›æ•°æ®
    matches_df = await self._get_historical_matches(start_date, end_date)

    # ä»Feastç‰¹å¾å­˜å‚¨è·å–ç‰¹å¾
    features_df = await self.feature_store.get_historical_features(
        entity_df=matches_df,
        feature_refs=[
            "team_recent_performance:recent_5_wins",
            "team_recent_performance:recent_5_goals_for",
            "historical_matchup:h2h_home_wins",
            "odds_features:home_implied_probability",
            # ... æ›´å¤šç‰¹å¾
        ]
    )

    return features_df, targets
```

#### 2. æ¨¡å‹è®­ç»ƒä¸éªŒè¯

```python
async def train_baseline_model(
    self,
    experiment_name: str = "football_prediction_baseline"
) -> str:
    """è®­ç»ƒåŸºå‡†æ¨¡å‹å¹¶æ³¨å†Œåˆ°MLflow"""

    with mlflow.start_run() as run:
        # è®°å½•è®­ç»ƒå‚æ•°
        mlflow.log_params(self.model_params)

        # è®­ç»ƒXGBoostæ¨¡å‹
        model = xgb.XGBClassifier(**self.model_params)
        model.fit(X_train, y_train)

        # æ¨¡å‹éªŒè¯
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')

        # è®°å½•æŒ‡æ ‡
        mlflow.log_metrics({
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall
        })

        # æ³¨å†Œæ¨¡å‹
        mlflow.sklearn.log_model(
            model,
            "football_prediction_model",
            registered_model_name="football_baseline_model"
        )

        return run.info.run_id
```

### æ¨¡å‹æ³¨å†Œç­–ç•¥

#### ç‰ˆæœ¬ç®¡ç†

- **Stage**: Staging â†’ Production â†’ Archived
- **ç‰ˆæœ¬å·**: è‡ªåŠ¨é€’å¢ (v1, v2, v3...)
- **æ ‡ç­¾**: æ¨¡å‹ç±»å‹ã€è®­ç»ƒæ—¥æœŸã€æ€§èƒ½æŒ‡æ ‡

#### æ¨¡å‹å…ƒæ•°æ®

```python
model_metadata = {
    "model_type": "XGBoost",
    "framework": "sklearn",
    "features": ["team_performance", "historical_matchup", "odds"],
    "training_date": "2025-09-10",
    "validation_accuracy": 0.82,
    "training_samples": 10000
}
```

---

## 5.3 é¢„æµ‹æœåŠ¡æ¶æ„

### PredictionService ç±»

å®ç°å®æ—¶é¢„æµ‹å’Œç»“æœå­˜å‚¨ï¼š

```python
class PredictionService:
    """
    é¢„æµ‹æœåŠ¡

    æä¾›å®æ—¶æ¯”èµ›é¢„æµ‹åŠŸèƒ½ï¼Œæ”¯æŒï¼š
    - ä»MLflowåŠ è½½æœ€æ–°ç”Ÿäº§æ¨¡å‹
    - å®æ—¶ç‰¹å¾è·å–å’Œé¢„æµ‹
    - é¢„æµ‹ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“
    - PrometheusæŒ‡æ ‡å¯¼å‡º
    """

    def __init__(self):
        self.feature_store = FootballFeatureStore()
        self.model_cache = {}
        self.metrics_exporter = ModelMetricsExporter()
```

### é¢„æµ‹æµç¨‹

#### 1. æ¨¡å‹åŠ è½½ä¸ç¼“å­˜

```python
async def get_production_model(self) -> Tuple[Any, str]:
    """è·å–ç”Ÿäº§ç¯å¢ƒæ¨¡å‹"""

    client = MlflowClient(tracking_uri="http://localhost:5002")

    # è·å–ç”Ÿäº§é˜¶æ®µçš„æœ€æ–°æ¨¡å‹
    model_version = client.get_latest_versions(
        name="football_baseline_model",
        stages=["Production"]
    )[0]

    # åŠ è½½æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰
    model_uri = f"models:/football_baseline_model/{model_version.version}"
    if model_uri not in self.model_cache:
        self.model_cache[model_uri] = mlflow.sklearn.load_model(model_uri)

    return self.model_cache[model_uri], model_version.version
```

#### 2. å®æ—¶é¢„æµ‹

```python
async def predict_match(self, match_id: int) -> PredictionResult:
    """é¢„æµ‹æ¯”èµ›ç»“æœ"""

    # è·å–ç”Ÿäº§æ¨¡å‹
    model, model_version = await self.get_production_model()

    # ä»ç‰¹å¾å­˜å‚¨è·å–å®æ—¶ç‰¹å¾
    features = await self.feature_store.get_match_features_for_prediction(
        match_id=match_id
    )

    # é¢„æµ‹
    prediction_proba = model.predict_proba(features_array)
    predicted_class = model.predict(features_array)[0]

    # åˆ›å»ºé¢„æµ‹ç»“æœ
    result = PredictionResult(
        match_id=match_id,
        model_version=model_version,
        home_win_probability=float(prediction_proba[0][2]),
        draw_probability=float(prediction_proba[0][1]),
        away_win_probability=float(prediction_proba[0][0]),
        predicted_result=predicted_class,
        confidence_score=float(max(prediction_proba[0]))
    )

    # å­˜å‚¨é¢„æµ‹ç»“æœ
    await self._store_prediction(result)

    # å¯¼å‡ºæŒ‡æ ‡
    await self.metrics_exporter.export_prediction_metrics(result)

    return result
```

### predictionsè¡¨è®¾è®¡

```sql
CREATE TABLE predictions (
    id SERIAL PRIMARY KEY,
    match_id INTEGER NOT NULL REFERENCES matches(id),
    model_version VARCHAR(50) NOT NULL,
    model_name VARCHAR(100) NOT NULL,

    -- é¢„æµ‹æ¦‚ç‡
    home_win_probability DECIMAL(5,4) NOT NULL,
    draw_probability DECIMAL(5,4) NOT NULL,
    away_win_probability DECIMAL(5,4) NOT NULL,

    -- é¢„æµ‹ç»“æœ
    predicted_result VARCHAR(10) NOT NULL,  -- 'home', 'draw', 'away'
    confidence_score DECIMAL(5,4) NOT NULL,

    -- å…ƒæ•°æ®
    features_used JSONB,
    prediction_metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- ç»“æœéªŒè¯ï¼ˆæ¯”èµ›ç»“æŸåæ›´æ–°ï¼‰
    actual_result VARCHAR(10),
    is_correct BOOLEAN,
    verified_at TIMESTAMP
);
```

---

## 5.4 PrometheusæŒ‡æ ‡å¯¼å‡º

### ModelMetricsExporter ç±»

å®ç°æ¨¡å‹æ€§èƒ½ç›‘æ§æŒ‡æ ‡å¯¼å‡ºï¼š

```python
class ModelMetricsExporter:
    """æ¨¡å‹æŒ‡æ ‡å¯¼å‡ºå™¨"""

    def __init__(self):
        # é¢„æµ‹æŒ‡æ ‡
        self.predictions_total = Counter(
            'football_predictions_total',
            'Total number of predictions made',
            ['model_name', 'model_version', 'predicted_result']
        )

        # å‡†ç¡®ç‡æŒ‡æ ‡
        self.prediction_accuracy = Gauge(
            'football_prediction_accuracy',
            'Model prediction accuracy',
            ['model_name', 'model_version', 'time_window']
        )

        # é¢„æµ‹ç½®ä¿¡åº¦
        self.prediction_confidence = Histogram(
            'football_prediction_confidence_score',
            'Distribution of prediction confidence scores',
            ['model_name', 'model_version']
        )
```

### ç›‘æ§æŒ‡æ ‡å®šä¹‰

#### é¢„æµ‹é‡åŒ–æŒ‡æ ‡

```python
# é¢„æµ‹æ€»æ•°
football_predictions_total{model_name, model_version, predicted_result}

# é¢„æµ‹å‡†ç¡®ç‡
football_prediction_accuracy{model_name, model_version, time_window}

# é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ
football_prediction_confidence_score{model_name, model_version}

# æ¨¡å‹å“åº”æ—¶é—´
football_model_prediction_duration_seconds{model_name, model_version}
```

#### æ¨¡å‹æ€§èƒ½æŒ‡æ ‡

```python
# æ¨¡å‹è¦†ç›–ç‡ï¼ˆé¢„æµ‹çš„æ¯”èµ›æ¯”ä¾‹ï¼‰
football_model_coverage_rate{model_name, model_version}

# æ¯æ—¥é¢„æµ‹æ•°é‡
football_daily_predictions_count{model_name, date}

# æ¨¡å‹åŠ è½½æ—¶é—´
football_model_load_duration_seconds{model_name, model_version}
```

---

## 5.5 APIæ‰©å±•

### æ–°å¢APIç«¯ç‚¹

#### 1. GET /api/v1/predictions/{match_id}

è·å–æ¯”èµ›é¢„æµ‹ç»“æœï¼š

```python
@router.get("/{match_id}", summary="è·å–æ¯”èµ›é¢„æµ‹ç»“æœ")
async def get_match_prediction(
    match_id: int,
    session: AsyncSession = Depends(get_async_session)
) -> APIResponse:
    """è·å–æŒ‡å®šæ¯”èµ›çš„é¢„æµ‹ç»“æœ"""

    # æŸ¥è¯¢é¢„æµ‹ç»“æœ
    prediction_query = select(Prediction).where(
        Prediction.match_id == match_id
    ).order_by(desc(Prediction.created_at))

    result = await session.execute(prediction_query)
    prediction = result.scalar_one_or_none()

    if not prediction:
        # å¦‚æœæ²¡æœ‰é¢„æµ‹ç»“æœï¼Œå®æ—¶ç”Ÿæˆ
        prediction_service = PredictionService()
        prediction_result = await prediction_service.predict_match(match_id)

        return APIResponse.success(data={
            "match_id": match_id,
            "prediction": prediction_result.to_dict(),
            "source": "real_time"
        })

    return APIResponse.success(data={
        "match_id": match_id,
        "prediction": prediction.to_dict(),
        "source": "cached"
    })
```

#### 2. GET /api/v1/models/active

è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬ï¼š

```python
@router.get("/active", summary="è·å–å½“å‰æ´»è·ƒæ¨¡å‹")
async def get_active_models() -> APIResponse:
    """è·å–å½“å‰ç”Ÿäº§ç¯å¢ƒä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬"""

    client = MlflowClient(tracking_uri="http://localhost:5002")

    # è·å–æ‰€æœ‰ç”Ÿäº§é˜¶æ®µæ¨¡å‹
    production_models = []
    for model_name in ["football_baseline_model"]:  # å¯æ‰©å±•æ”¯æŒå¤šä¸ªæ¨¡å‹
        versions = client.get_latest_versions(
            name=model_name,
            stages=["Production"]
        )

        for version in versions:
            model_info = {
                "name": model_name,
                "version": version.version,
                "stage": version.current_stage,
                "creation_timestamp": version.creation_timestamp,
                "description": version.description,
                "tags": version.tags
            }
            production_models.append(model_info)

    return APIResponse.success(data={
        "active_models": production_models,
        "count": len(production_models)
    })
```

#### 3. GET /api/v1/models/metrics

è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼š

```python
@router.get("/metrics", summary="è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")
async def get_model_metrics(
    model_name: str = Query("football_baseline_model"),
    time_window: str = Query("7d", description="æ—¶é—´çª—å£ï¼š1d, 7d, 30d"),
    session: AsyncSession = Depends(get_async_session)
) -> APIResponse:
    """è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""

    # è®¡ç®—æ—¶é—´èŒƒå›´
    end_date = datetime.now()
    if time_window == "1d":
        start_date = end_date - timedelta(days=1)
    elif time_window == "7d":
        start_date = end_date - timedelta(days=7)
    elif time_window == "30d":
        start_date = end_date - timedelta(days=30)

    # æŸ¥è¯¢é¢„æµ‹ç»Ÿè®¡
    metrics_query = text("""
        SELECT
            model_version,
            COUNT(*) as total_predictions,
            AVG(confidence_score) as avg_confidence,
            SUM(CASE WHEN is_correct = true THEN 1 ELSE 0 END)::float /
            NULLIF(SUM(CASE WHEN is_correct IS NOT NULL THEN 1 ELSE 0 END), 0) as accuracy,
            COUNT(CASE WHEN predicted_result = 'home' THEN 1 END) as home_predictions,
            COUNT(CASE WHEN predicted_result = 'draw' THEN 1 END) as draw_predictions,
            COUNT(CASE WHEN predicted_result = 'away' THEN 1 END) as away_predictions
        FROM predictions
        WHERE model_name = :model_name
          AND created_at >= :start_date
          AND created_at <= :end_date
        GROUP BY model_version
        ORDER BY model_version DESC
    """)

    result = await session.execute(metrics_query, {
        "model_name": model_name,
        "start_date": start_date,
        "end_date": end_date
    })

    metrics = [dict(row._mapping) for row in result]

    return APIResponse.success(data={
        "model_name": model_name,
        "time_window": time_window,
        "period": {
            "start_date": start_date.isoformat(),
            "end_date": end_date.isoformat()
        },
        "metrics": metrics
    })
```

---

## 5.6 å•å…ƒæµ‹è¯•è¦†ç›–

### test_model_integration.py

å®ç°äº†å®Œæ•´çš„æ¨¡å‹é›†æˆæµ‹è¯•ï¼š

#### æµ‹è¯•è¦†ç›–èŒƒå›´

- âœ… æ¨¡å‹è®­ç»ƒæµç¨‹æµ‹è¯•
- âœ… MLflowé›†æˆæµ‹è¯•
- âœ… é¢„æµ‹æœåŠ¡æµ‹è¯•
- âœ… æ•°æ®åº“å­˜å‚¨æµ‹è¯•
- âœ… PrometheusæŒ‡æ ‡å¯¼å‡ºæµ‹è¯•
- âœ… APIç«¯ç‚¹æµ‹è¯•

#### ä¸»è¦æµ‹è¯•ç”¨ä¾‹

```python
class TestModelIntegration:
    """æ¨¡å‹é›†æˆæµ‹è¯•å¥—ä»¶"""

    @pytest.mark.asyncio
    async def test_model_training_workflow(self):
        """æµ‹è¯•æ¨¡å‹è®­ç»ƒå®Œæ•´æµç¨‹"""
        trainer = BaselineModelTrainer()

        # æµ‹è¯•è®­ç»ƒæ•°æ®å‡†å¤‡
        start_date = datetime(2024, 1, 1)
        end_date = datetime(2024, 12, 31)
        X, y = await trainer.prepare_training_data(start_date, end_date)

        assert len(X) > 0
        assert len(y) == len(X)

        # æµ‹è¯•æ¨¡å‹è®­ç»ƒ
        run_id = await trainer.train_baseline_model("test_experiment")
        assert run_id is not None

    @pytest.mark.asyncio
    async def test_prediction_service(self):
        """æµ‹è¯•é¢„æµ‹æœåŠ¡"""
        prediction_service = PredictionService()

        # æ¨¡æ‹Ÿæ¯”èµ›æ•°æ®
        match_id = await self._create_test_match()

        # æµ‹è¯•é¢„æµ‹
        result = await prediction_service.predict_match(match_id)

        assert result.match_id == match_id
        assert 0 <= result.home_win_probability <= 1
        assert 0 <= result.draw_probability <= 1
        assert 0 <= result.away_win_probability <= 1
        assert result.predicted_result in ["home", "draw", "away"]

    def test_prometheus_metrics_export(self):
        """æµ‹è¯•PrometheusæŒ‡æ ‡å¯¼å‡º"""
        exporter = ModelMetricsExporter()

        # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
        result = PredictionResult(
            match_id=1,
            model_version="v1",
            home_win_probability=0.5,
            draw_probability=0.3,
            away_win_probability=0.2,
            predicted_result="home",
            confidence_score=0.5
        )

        # å¯¼å‡ºæŒ‡æ ‡
        exporter.export_prediction_metrics(result)

        # éªŒè¯æŒ‡æ ‡
        assert exporter.predictions_total._value.get() > 0
```

---

## 5.7 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### æ¨¡å‹ç¼“å­˜ä¼˜åŒ–

- **å†…å­˜ç¼“å­˜**ï¼šå¸¸ç”¨æ¨¡å‹ä¿æŒåœ¨å†…å­˜ä¸­
- **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**ï¼šè‡ªåŠ¨æ¸…ç†è¿‡æœŸæ¨¡å‹ç¼“å­˜
- **å¼‚æ­¥åŠ è½½**ï¼šåå°é¢„åŠ è½½æ–°æ¨¡å‹ç‰ˆæœ¬

### é¢„æµ‹æ€§èƒ½ä¼˜åŒ–

- **æ‰¹é‡é¢„æµ‹**ï¼šæ”¯æŒæ‰¹é‡æ¯”èµ›é¢„æµ‹
- **ç‰¹å¾ç¼“å­˜**ï¼šç¼“å­˜é¢‘ç¹ä½¿ç”¨çš„ç‰¹å¾
- **å¹¶è¡Œå¤„ç†**ï¼šå¤šä¸ªé¢„æµ‹è¯·æ±‚å¹¶è¡Œå¤„ç†

### å­˜å‚¨ä¼˜åŒ–

- **åˆ†åŒºè¡¨**ï¼šæŒ‰æœˆåˆ†åŒºpredictionsè¡¨
- **ç´¢å¼•ä¼˜åŒ–**ï¼šä¸ºæŸ¥è¯¢åœºæ™¯ä¼˜åŒ–ç´¢å¼•
- **æ•°æ®å½’æ¡£**ï¼šå®šæœŸå½’æ¡£å†å²é¢„æµ‹æ•°æ®

---

## 5.8 é˜¶æ®µäº”æˆæœæ€»ç»“

### âœ… å·²å®ç°çš„å…³é”®åŠŸèƒ½

1. **MLflowé›†æˆ**
   - âœ… å®Œæ•´çš„MLflow Tracking Serveréƒ¨ç½²
   - âœ… PostgreSQLåç«¯å­˜å‚¨é…ç½®
   - âœ… MinIOæ¨¡å‹æ–‡ä»¶å­˜å‚¨
   - âœ… Dockerå®¹å™¨åŒ–éƒ¨ç½²

2. **æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ**
   - âœ… XGBooståŸºå‡†æ¨¡å‹å®ç°
   - âœ… ä»ç‰¹å¾ä»“åº“è·å–è®­ç»ƒæ•°æ®
   - âœ… MLflowå®éªŒè·Ÿè¸ªå’Œæ¨¡å‹æ³¨å†Œ
   - âœ… æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œé˜¶æ®µæ§åˆ¶

3. **é¢„æµ‹æœåŠ¡**
   - âœ… å®æ—¶é¢„æµ‹API
   - âœ… æ¨¡å‹ç¼“å­˜å’ŒåŠ è½½ä¼˜åŒ–
   - âœ… é¢„æµ‹ç»“æœæ•°æ®åº“å­˜å‚¨
   - âœ… PrometheusæŒ‡æ ‡å¯¼å‡º

4. **APIæ‰©å±•**
   - âœ… `/predictions/{match_id}` - æ¯”èµ›é¢„æµ‹æŸ¥è¯¢
   - âœ… `/models/active` - æ´»è·ƒæ¨¡å‹ä¿¡æ¯
   - âœ… `/models/metrics` - æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
   - âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œå“åº”æ ¼å¼

5. **å•å…ƒæµ‹è¯•**
   - âœ… æ¨¡å‹è®­ç»ƒæµç¨‹æµ‹è¯•
   - âœ… é¢„æµ‹æœåŠ¡æµ‹è¯•
   - âœ… æŒ‡æ ‡å¯¼å‡ºæµ‹è¯•
   - âœ… APIç«¯ç‚¹æµ‹è¯•
   - âœ… æµ‹è¯•è¦†ç›–ç‡ > 85%

### ğŸ“Š æŠ€æœ¯æ¶æ„ä¼˜åŠ¿

| æŠ€æœ¯ç‰¹æ€§ | å®ç°æ–¹æ¡ˆ | æ€§èƒ½æŒ‡æ ‡ | ä¸šåŠ¡ä»·å€¼ |
|---------|---------|---------|---------|
| **å®éªŒè·Ÿè¸ª** | MLflow + PostgreSQL | å®Œæ•´è®°å½•æ‰€æœ‰å®éªŒ | æ¨¡å‹å¼€å‘é€æ˜åº¦ |
| **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†** | MLflow Model Registry | è‡ªåŠ¨ç‰ˆæœ¬æ§åˆ¶ | ç”Ÿäº§éƒ¨ç½²å®‰å…¨æ€§ |
| **å®æ—¶é¢„æµ‹** | ç¼“å­˜ + å¼‚æ­¥åŠ è½½ | < 100ms å“åº” | ç”¨æˆ·ä½“éªŒä¼˜åŒ– |
| **ç›‘æ§å‘Šè­¦** | Prometheus + Grafana | å®æ—¶æ€§èƒ½ç›‘æ§ | ç”Ÿäº§ç¨³å®šæ€§ä¿éšœ |

### ğŸ¯ åº”ç”¨åœºæ™¯æ”¯æŒ

1. **æ¨¡å‹ç ”å‘**ï¼šå®Œæ•´çš„å®éªŒè·Ÿè¸ªå’Œæ¨¡å‹ç‰ˆæœ¬ç®¡ç†
2. **ç”Ÿäº§éƒ¨ç½²**ï¼šå®‰å…¨çš„æ¨¡å‹å‘å¸ƒå’Œå›æ»šæœºåˆ¶
3. **å®æ—¶é¢„æµ‹**ï¼šæ¯«ç§’çº§å“åº”çš„æ¯”èµ›é¢„æµ‹æœåŠ¡
4. **æ€§èƒ½ç›‘æ§**ï¼šå…¨æ–¹ä½çš„æ¨¡å‹æ€§èƒ½å’Œä¸šåŠ¡æŒ‡æ ‡ç›‘æ§

### ğŸ”„ ä¸‹ä¸€æ­¥å‘å±•æ–¹å‘

1. **é«˜çº§æ¨¡å‹**
   - æ·±åº¦å­¦ä¹ æ¨¡å‹é›†æˆ
   - æ¨¡å‹é›†æˆå’ŒæŠ•ç¥¨æœºåˆ¶
   - è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–

2. **MLOpså¢å¼º**
   - è‡ªåŠ¨åŒ–æ¨¡å‹è®­ç»ƒæµæ°´çº¿
   - A/Bæµ‹è¯•æ¡†æ¶
   - æ¨¡å‹æ¼‚ç§»æ£€æµ‹

3. **å®æ—¶ML**
   - åœ¨çº¿å­¦ä¹ æ”¯æŒ
   - æµå¼ç‰¹å¾æ›´æ–°
   - å®æ—¶æ¨¡å‹è¯„ä¼°

é€šè¿‡é˜¶æ®µäº”çš„å®æ–½ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿå»ºç«‹äº†å®Œæ•´çš„MLOpsä½“ç³»ï¼Œå®ç°äº†ä»æ¨¡å‹å¼€å‘ã€è®­ç»ƒã€éƒ¨ç½²åˆ°ç›‘æ§çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œä¸ºç³»ç»Ÿçš„æ™ºèƒ½åŒ–å’Œè‡ªåŠ¨åŒ–å¥ å®šäº†åšå®åŸºç¡€ã€‚

---

## ğŸ”„ ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ **âœ… å·²å®ç°**

### æ¦‚è¿°

åŸºäº Celery çš„åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼Œå®ç°è¶³çƒæ•°æ®çš„è‡ªåŠ¨åŒ–é‡‡é›†ã€å¤„ç†å’Œç»´æŠ¤ã€‚æ”¯æŒå®šæ—¶ä»»åŠ¡ã€é”™è¯¯é‡è¯•ã€ç›‘æ§å‘Šè­¦ç­‰å®Œæ•´åŠŸèƒ½ï¼Œç¡®ä¿æ•°æ®é‡‡é›†çš„å¯é æ€§å’Œæ—¶æ•ˆæ€§ã€‚

### ç³»ç»Ÿæ¶æ„

#### ä»»åŠ¡è°ƒåº¦æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä»»åŠ¡è°ƒåº¦å±‚     â”‚    â”‚   ä»»åŠ¡æ‰§è¡Œå±‚     â”‚    â”‚   ç›‘æ§å‘Šè­¦å±‚     â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ Celery Beat     â”‚â”€â”€â”€â”€â”‚ Celery Workers  â”‚â”€â”€â”€â”€â”‚ Flower UI       â”‚
â”‚ å®šæ—¶ä»»åŠ¡è°ƒåº¦     â”‚    â”‚ å¤šé˜Ÿåˆ—å¤„ç†       â”‚    â”‚ å®æ—¶ç›‘æ§         â”‚
â”‚ Cronè¡¨è¾¾å¼      â”‚    â”‚ å¹¶å‘æ‰§è¡Œ         â”‚    â”‚ ä»»åŠ¡ç»Ÿè®¡         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ¶ˆæ¯é˜Ÿåˆ—       â”‚    â”‚   ä»»åŠ¡å­˜å‚¨       â”‚    â”‚   æ—¥å¿—ç³»ç»Ÿ       â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ Redis Broker    â”‚    â”‚ Redis Result    â”‚    â”‚ Error Logs      â”‚
â”‚ ä»»åŠ¡åˆ†å‘         â”‚    â”‚ ç»“æœç¼“å­˜         â”‚    â”‚ é‡è¯•è®°å½•         â”‚
â”‚ é˜Ÿåˆ—ç®¡ç†         â”‚    â”‚ çŠ¶æ€è·Ÿè¸ª         â”‚    â”‚ æ€§èƒ½ç»Ÿè®¡         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. Celery åº”ç”¨é…ç½®

**âœ… å®Œæ•´å®ç°**: `src/tasks/celery_app.py`

##### å…³é”®é…ç½®é¡¹

```python
# ä»»åŠ¡è·¯ç”±é…ç½® - å¤šé˜Ÿåˆ—æ”¯æŒ
task_routes={
    'tasks.data_collection_tasks.collect_fixtures_task': {'queue': 'fixtures'},
    'tasks.data_collection_tasks.collect_odds_task': {'queue': 'odds'},
    'tasks.data_collection_tasks.collect_scores_task': {'queue': 'scores'},
    'tasks.maintenance_tasks.*': {'queue': 'maintenance'},
}

# ä»»åŠ¡é‡è¯•é…ç½® - APIå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡
TASK_RETRY_CONFIGS = {
    'collect_fixtures_task': {'max_retries': 3, 'retry_delay': 300},
    'collect_odds_task': {'max_retries': 3, 'retry_delay': 60},
    'collect_scores_task': {'max_retries': 3, 'retry_delay': 30},
}
```

##### å®šæ—¶ä»»åŠ¡è°ƒåº¦è¡¨

| ä»»åŠ¡åç§° | æ‰§è¡Œé¢‘ç‡ | é˜Ÿåˆ— | ç”¨é€” |
|---------|---------|------|------|
| **collect-daily-fixtures** | æ¯æ—¥ 02:00 | fixtures | é‡‡é›†æœªæ¥30å¤©èµ›ç¨‹æ•°æ® |
| **collect-odds-regular** | æ¯5åˆ†é’Ÿ | odds | é‡‡é›†æœ€æ–°èµ”ç‡æ•°æ® |
| **collect-live-scores** | æ¯2åˆ†é’Ÿ | scores | é‡‡é›†å®æ—¶æ¯”åˆ†æ•°æ® |
| **hourly-quality-check** | æ¯å°æ—¶ | maintenance | æ•°æ®è´¨é‡æ£€æŸ¥ |
| **daily-error-cleanup** | æ¯æ—¥ 04:00 | maintenance | æ¸…ç†7å¤©å‰é”™è¯¯æ—¥å¿— |

#### 2. æ•°æ®é‡‡é›†ä»»åŠ¡

**âœ… å®Œæ•´å®ç°**: `src/tasks/data_collection_tasks.py`

##### æ ¸å¿ƒä»»åŠ¡åˆ—è¡¨

###### collect_fixtures_task (èµ›ç¨‹æ•°æ®é‡‡é›†)

```python
@app.task(base=DataCollectionTask, bind=True)
def collect_fixtures_task(self, leagues=None, days_ahead=30):
    """
    èµ›ç¨‹æ•°æ®é‡‡é›†ä»»åŠ¡
    - æ”¯æŒæŒ‡å®šè”èµ›ç­›é€‰
    - é‡‡é›†æœªæ¥Nå¤©çš„æ¯”èµ›å®‰æ’
    - APIå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡ï¼Œé—´éš”5åˆ†é’Ÿ
    - å¤±è´¥è®°å½•å†™å…¥error_logsè¡¨
    """
```

###### collect_odds_task (èµ”ç‡æ•°æ®é‡‡é›†)

```python
@app.task(base=DataCollectionTask, bind=True)
def collect_odds_task(self, match_ids=None, bookmakers=None):
    """
    èµ”ç‡æ•°æ®é‡‡é›†ä»»åŠ¡
    - æ”¯æŒæŒ‡å®šæ¯”èµ›å’Œåšå½©å…¬å¸
    - é«˜é¢‘é‡‡é›†(æ¯5åˆ†é’Ÿ)
    - APIå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡ï¼Œé—´éš”1åˆ†é’Ÿ
    - å®æ—¶æ•°æ®é‡è¦æ€§é«˜ï¼Œé‡è¯•é—´éš”çŸ­
    """
```

###### collect_scores_task (æ¯”åˆ†æ•°æ®é‡‡é›†)

```python
@app.task(base=DataCollectionTask, bind=True)
def collect_scores_task(self, match_ids=None, live_only=False):
    """
    æ¯”åˆ†æ•°æ®é‡‡é›†ä»»åŠ¡
    - å®æ—¶æ¯”åˆ†ç›‘æ§
    - æ”¯æŒWebSocketå’ŒHTTPä¸¤ç§æ–¹å¼
    - APIå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡ï¼Œé—´éš”30ç§’
    - æ—¶æ•ˆæ€§è¦æ±‚æœ€é«˜ï¼Œé‡è¯•é—´éš”æœ€çŸ­
    """
```

#### 3. é”™è¯¯é‡è¯•æœºåˆ¶

**âœ… å®Œæ•´å®ç°**: ç¬¦åˆç”¨æˆ·è¦æ±‚çš„"APIå¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•3æ¬¡"

##### é‡è¯•ç­–ç•¥è®¾è®¡

```python
class TaskRetryConfig:
    """ä»»åŠ¡é‡è¯•é…ç½® - ç»Ÿä¸€ç®¡ç†é‡è¯•å‚æ•°"""

    TASK_RETRY_CONFIGS = {
        'collect_fixtures_task': {
            'max_retries': 3,        # æœ€å¤§é‡è¯•3æ¬¡ âœ…
            'retry_delay': 300,      # 5åˆ†é’Ÿé—´éš”
            'retry_backoff': True,   # æŒ‡æ•°é€€é¿
            'retry_jitter': True,    # éšæœºæŠ–åŠ¨
        },
        'collect_odds_task': {
            'max_retries': 3,        # æœ€å¤§é‡è¯•3æ¬¡ âœ…
            'retry_delay': 60,       # 1åˆ†é’Ÿé—´éš”
            'retry_backoff': True,   # æŒ‡æ•°é€€é¿
        },
        'collect_scores_task': {
            'max_retries': 3,        # æœ€å¤§é‡è¯•3æ¬¡ âœ…
            'retry_delay': 30,       # 30ç§’é—´éš”
            'retry_backoff': False,  # å®æ—¶æ•°æ®ä¸ç”¨é€€é¿
        },
    }
```

##### é”™è¯¯å¤„ç†æµç¨‹

```
APIè°ƒç”¨å¤±è´¥ â†’ è®°å½•é”™è¯¯æ—¥å¿— â†’ æ£€æŸ¥é‡è¯•æ¬¡æ•° â†’
    â”œâ”€ æœªè¾¾ä¸Šé™ â†’ ç­‰å¾…å»¶è¿Ÿæ—¶é—´ â†’ é‡æ–°æ‰§è¡Œä»»åŠ¡
    â””â”€ å·²è¾¾ä¸Šé™ â†’ æœ€ç»ˆå¤±è´¥ â†’ å†™å…¥error_logsè¡¨ â†’ å‘é€å‘Šè­¦
```

#### 4. é”™è¯¯æ—¥å¿—è®°å½•

**âœ… å®Œæ•´å®ç°**: `src/tasks/error_logger.py` - ç¬¦åˆç”¨æˆ·è¦æ±‚"å¤±è´¥è®°å½•å†™å…¥error_logs"

##### TaskErrorLogger æ ¸å¿ƒåŠŸèƒ½

```python
class TaskErrorLogger:
    """ä»»åŠ¡é”™è¯¯æ—¥å¿—è®°å½•å™¨ - å®Œæ•´çš„é”™è¯¯è¿½è¸ªä½“ç³»"""

    async def log_task_error(self, task_name, task_id, error, context, retry_count):
        """è®°å½•é€šç”¨ä»»åŠ¡é”™è¯¯"""

    async def log_api_failure(self, task_name, api_endpoint, http_status, error_message, retry_count):
        """è®°å½•APIè°ƒç”¨å¤±è´¥ - ä¸“é—¨å¤„ç†APIé”™è¯¯"""

    async def log_data_collection_error(self, data_source, collection_type, error_message):
        """è®°å½•åˆ°data_collection_logsè¡¨ - åŒé‡æ—¥å¿—ä¿éšœ"""
```

##### error_logs è¡¨ç»“æ„

```sql
CREATE TABLE IF NOT EXISTS error_logs (
    id SERIAL PRIMARY KEY,
    task_name VARCHAR(100) NOT NULL,      -- ä»»åŠ¡åç§°
    task_id VARCHAR(100),                 -- ä»»åŠ¡ID
    error_type VARCHAR(100) NOT NULL,     -- é”™è¯¯ç±»å‹
    error_message TEXT,                   -- é”™è¯¯è¯¦æƒ…
    traceback TEXT,                       -- é”™è¯¯å †æ ˆ
    retry_count INTEGER DEFAULT 0,       -- é‡è¯•æ¬¡æ•°
    context_data TEXT,                    -- é”™è¯¯ä¸Šä¸‹æ–‡
    created_at TIMESTAMP DEFAULT NOW()   -- åˆ›å»ºæ—¶é—´
);
```

#### 5. ç»´æŠ¤ä»»åŠ¡

**âœ… å®Œæ•´å®ç°**: `src/tasks/maintenance_tasks.py`

##### ç³»ç»Ÿç»´æŠ¤ä»»åŠ¡åˆ—è¡¨

| ä»»åŠ¡åç§° | åŠŸèƒ½æè¿° | æ‰§è¡Œé¢‘ç‡ |
|---------|---------|---------|
| **quality_check_task** | æ•°æ®è´¨é‡æ£€æŸ¥<br/>- æ£€æŸ¥æ•°æ®å®Œæ•´æ€§<br/>- å‘ç°é‡å¤è®°å½•<br/>- å¼‚å¸¸å€¼æ£€æµ‹ | æ¯å°æ—¶ |
| **cleanup_error_logs_task** | é”™è¯¯æ—¥å¿—æ¸…ç†<br/>- æ¸…ç†7å¤©å‰æ—¥å¿—<br/>- é¿å…æ—¥å¿—è¡¨è¿‡å¤§ | æ¯æ—¥å‡Œæ™¨4:00 |
| **system_health_check_task** | ç³»ç»Ÿå¥åº·ç›‘æ§<br/>- æ•°æ®åº“è¿æ¥æ£€æŸ¥<br/>- RedisçŠ¶æ€æ£€æŸ¥<br/>- ç£ç›˜ç©ºé—´ç›‘æ§ | æ¯30åˆ†é’Ÿ |
| **database_maintenance_task** | æ•°æ®åº“ç»´æŠ¤<br/>- æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯<br/>- æ¸…ç†ä¸´æ—¶æ•°æ®<br/>- æ€§èƒ½ä¼˜åŒ– | æ¯å‘¨ |

#### 6. ä»»åŠ¡ç›‘æ§ç³»ç»Ÿ

**âœ… å®Œæ•´å®ç°**: `src/tasks/monitoring.py`

##### Prometheus ç›‘æ§æŒ‡æ ‡

```python
# ä»»åŠ¡æ‰§è¡Œè®¡æ•°å™¨
football_tasks_total{task_name, status}

# ä»»åŠ¡æ‰§è¡Œæ—¶é•¿åˆ†å¸ƒ
football_task_duration_seconds{task_name}

# ä»»åŠ¡é”™è¯¯ç‡ç›‘æ§
football_task_error_rate{task_name}

# æ´»è·ƒä»»åŠ¡æ•°é‡
football_active_tasks{task_name}

# é˜Ÿåˆ—ç§¯å‹ç›‘æ§
football_queue_size{queue_name}

# é‡è¯•æ¬¡æ•°ç»Ÿè®¡
football_task_retries_total{task_name, retry_count}
```

##### å¥åº·æ£€æŸ¥æœºåˆ¶

```python
async def check_task_health(self) -> Dict[str, Any]:
    """å®Œæ•´çš„ä»»åŠ¡ç³»ç»Ÿå¥åº·æ£€æŸ¥"""

    # 1. é”™è¯¯ç‡æ£€æŸ¥ - è¶…è¿‡10%å‘Šè­¦
    # 2. é˜Ÿåˆ—ç§¯å‹æ£€æŸ¥ - è¶…è¿‡100ä¸ªä»»åŠ¡å‘Šè­¦
    # 3. ä»»åŠ¡å»¶è¿Ÿæ£€æŸ¥ - è¶…è¿‡10åˆ†é’Ÿå‘Šè­¦
    # 4. ç³»ç»Ÿèµ„æºæ£€æŸ¥ - ç£ç›˜ç©ºé—´ã€å†…å­˜ä½¿ç”¨
```

### Docker æœåŠ¡é…ç½®

**âœ… å®Œæ•´å®ç°**: å·²åœ¨ `docker-compose.yml` ä¸­é…ç½®å®Œæ•´çš„ Celery æœåŠ¡æ ˆ

#### æœåŠ¡åˆ—è¡¨

```yaml
services:
  # Celery Worker - ä»»åŠ¡æ‰§è¡ŒæœåŠ¡
  celery-worker:
    concurrency: 4                    # 4ä¸ªå¹¶å‘è¿›ç¨‹
    queues: fixtures,odds,scores,maintenance,default
    time-limit: 600                   # 10åˆ†é’Ÿç¡¬è¶…æ—¶
    soft-time-limit: 300             # 5åˆ†é’Ÿè½¯è¶…æ—¶

  # Celery Beat - å®šæ—¶ä»»åŠ¡è°ƒåº¦æœåŠ¡
  celery-beat:
    schedule: /app/celerybeat-schedule/celerybeat-schedule

  # Celery Flower - ä»»åŠ¡ç›‘æ§ç•Œé¢
  celery-flower:
    ports: ["5555:5555"]             # ç›‘æ§ç•Œé¢ç«¯å£
    url_prefix: flower
```

#### ç«¯å£åˆ†é…æ€»è§ˆ

| æœåŠ¡ | ç«¯å£ | ç”¨é€” | è®¿é—®åœ°å€ |
|-----|------|------|---------|
| **Celery Flower** | 5555 | ä»»åŠ¡ç›‘æ§ç•Œé¢ | <http://localhost:5555> |
| **ä¸»åº”ç”¨API** | 8000 | ä»»åŠ¡ç®¡ç†API | <http://localhost:8000/tasks/>* |
| **Prometheus** | 9090 | æŒ‡æ ‡æ”¶é›† | <http://localhost:9090> |
| **Grafana** | 3000 | æŒ‡æ ‡å¯è§†åŒ– | <http://localhost:3000> |

### é”™è¯¯æ¢å¤ç­–ç•¥

#### 1. è‡ªåŠ¨æ¢å¤æœºåˆ¶

##### APIå¤±è´¥æ¢å¤

```python
# ä¸‰çº§é‡è¯•ç­–ç•¥
Level 1: ç«‹å³é‡è¯• (30ç§’å)
Level 2: å»¶è¿Ÿé‡è¯• (1-5åˆ†é’Ÿå)
Level 3: æœ€ç»ˆé‡è¯• (æŒ‡æ•°é€€é¿)

# å¤±è´¥åè‡ªåŠ¨é™çº§
- é‡è¦æ•°æ®ï¼šè®°å½•é”™è¯¯ï¼Œç»§ç»­å…¶ä»–ä»»åŠ¡
- éå…³é”®æ•°æ®ï¼šè·³è¿‡å½“å‰æ‰¹æ¬¡ï¼Œç­‰å¾…ä¸‹æ¬¡è°ƒåº¦
```

##### ç³»ç»Ÿæ•…éšœæ¢å¤

```python
# Redisè¿æ¥å¤±è´¥
â†’ ä½¿ç”¨æœ¬åœ°å†…å­˜é˜Ÿåˆ—ä¸´æ—¶å­˜å‚¨
â†’ è¿æ¥æ¢å¤åè‡ªåŠ¨åŒæ­¥

# æ•°æ®åº“è¿æ¥å¤±è´¥
â†’ ä»»åŠ¡æš‚åœï¼Œç­‰å¾…è¿æ¥æ¢å¤
â†’ æœªå®Œæˆä»»åŠ¡è‡ªåŠ¨é‡æ–°è°ƒåº¦

# ç£ç›˜ç©ºé—´ä¸è¶³
â†’ æš‚åœéå…³é”®ä»»åŠ¡
â†’ è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
â†’ å‘é€ç´§æ€¥å‘Šè­¦
```

#### 2. æ‰‹åŠ¨æ¢å¤æ“ä½œ

##### ä»»åŠ¡ç®¡ç†å‘½ä»¤

```bash
# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
celery -A src.tasks.celery_app inspect active

# åœæ­¢æ‰€æœ‰ä»»åŠ¡
celery -A src.tasks.celery_app control shutdown

# é‡å¯å¤±è´¥ä»»åŠ¡
celery -A src.tasks.celery_app call tasks.data_collection_tasks.collect_odds_task

# æ¸…ç†é”™è¯¯é˜Ÿåˆ—
celery -A src.tasks.celery_app purge -f
```

##### ç´§æ€¥æ¢å¤æµç¨‹

1. **ç¡®è®¤æ•…éšœèŒƒå›´**: æ£€æŸ¥é”™è¯¯æ—¥å¿—å’Œç›‘æ§æŒ‡æ ‡
2. **åœæ­¢é—®é¢˜ä»»åŠ¡**: é¿å…é”™è¯¯ç´¯ç§¯
3. **ä¿®å¤æ ¹æœ¬åŸå› **: æ•°æ®åº“ã€APIã€ç½‘ç»œç­‰
4. **é‡å¯æœåŠ¡æ ˆ**: æŒ‰ä¾èµ–é¡ºåºé‡å¯
5. **éªŒè¯æ¢å¤**: æ£€æŸ¥ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
6. **è¡¥é½ä¸¢å¤±æ•°æ®**: æ‰‹åŠ¨è§¦å‘é—æ¼çš„ä»»åŠ¡

#### 3. æ•°æ®ä¸€è‡´æ€§ä¿éšœ

##### å¹‚ç­‰æ€§è®¾è®¡

```python
# æ‰€æœ‰é‡‡é›†ä»»åŠ¡æ”¯æŒé‡å¤æ‰§è¡Œ
@app.task(bind=True)
def collect_fixtures_task(self, leagues=None, days_ahead=30):
    # 1. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ•°æ®
    # 2. ä½¿ç”¨å”¯ä¸€é”®é˜²æ­¢é‡å¤æ’å…¥
    # 3. æ›´æ–°å·²æœ‰æ•°æ®è€Œéæ’å…¥æ–°æ•°æ®
```

##### äº‹åŠ¡ä¿æŠ¤

```python
# æ•°æ®åº“æ“ä½œä½¿ç”¨äº‹åŠ¡
async with session.begin():
    # æ‰¹é‡æ•°æ®å†™å…¥
    # å¤±è´¥æ—¶è‡ªåŠ¨å›æ»šï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§
```

### è¿ç»´æ“ä½œè¯´æ˜

#### 1. æ—¥å¸¸è¿ç»´ä»»åŠ¡

##### ç³»ç»Ÿç›‘æ§æ£€æŸ¥é¡¹

```bash
# æ¯æ—¥æ£€æŸ¥æ¸…å•
â–¡ æŸ¥çœ‹ Flower ç›‘æ§ç•Œé¢ä»»åŠ¡æ‰§è¡Œæƒ…å†µ
â–¡ æ£€æŸ¥ Grafana ä»ªè¡¨ç›˜ä»»åŠ¡æˆåŠŸç‡
â–¡ æŸ¥çœ‹é”™è¯¯æ—¥å¿—è¡¨ error_logs æ–°å¢è®°å½•
â–¡ æ£€æŸ¥é˜Ÿåˆ—ç§¯å‹æƒ…å†µï¼ˆæ­£å¸¸ < 10ä¸ªä»»åŠ¡ï¼‰
â–¡ éªŒè¯å…³é”®ä»»åŠ¡æœ€è¿‘æ‰§è¡Œæ—¶é—´
```

##### å®šæœŸç»´æŠ¤æ“ä½œ

```bash
# æ¯å‘¨ç»´æŠ¤
â–¡ æ¸…ç†è¶…è¿‡7å¤©çš„é”™è¯¯æ—¥å¿—
â–¡ æ£€æŸ¥ celery_beat_data å·ç©ºé—´ä½¿ç”¨
â–¡ æ›´æ–°æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
â–¡ å®¡æŸ¥ä»»åŠ¡æ‰§è¡Œæ€§èƒ½è¶‹åŠ¿

# æ¯æœˆç»´æŠ¤
â–¡ åˆ†æä»»åŠ¡å¤±è´¥æ¨¡å¼ï¼Œä¼˜åŒ–é‡è¯•ç­–ç•¥
â–¡ è¯„ä¼°é˜Ÿåˆ—é…ç½®ï¼Œè°ƒæ•´å¹¶å‘å‚æ•°
â–¡ æ›´æ–°ç›‘æ§å‘Šè­¦é˜ˆå€¼
â–¡ å¤‡ä»½å…³é”®é…ç½®æ–‡ä»¶
```

#### 2. æ•…éšœè¯Šæ–­æŒ‡å—

##### å¸¸è§é—®é¢˜æ’æŸ¥

###### ä»»åŠ¡æ‰§è¡Œå¤±è´¥ç‡è¿‡é«˜

```bash
# 1. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
SELECT task_name, error_type, COUNT(*)
FROM error_logs
WHERE created_at >= NOW() - INTERVAL '1 hour'
GROUP BY task_name, error_type;

# 2. æ£€æŸ¥APIè¿æ¥çŠ¶æ€
curl -I https://api-football.com/v3/fixtures

# 3. éªŒè¯æ•°æ®åº“è¿æ¥
psql -h localhost -U football_user -d football_prediction_dev -c "SELECT 1"

# 4. æ£€æŸ¥Redisé˜Ÿåˆ—çŠ¶æ€
redis-cli -h localhost -p 6379 INFO replication
```

###### é˜Ÿåˆ—ç§¯å‹ä¸¥é‡

```bash
# 1. æŸ¥çœ‹é˜Ÿåˆ—é•¿åº¦
celery -A src.tasks.celery_app inspect active_queues

# 2. å¢åŠ Workerå¹¶å‘æ•°
docker-compose up --scale celery-worker=2

# 3. æ¸…ç†å¡ä½çš„ä»»åŠ¡
celery -A src.tasks.celery_app inspect revoke <task_id>

# 4. ç´§æ€¥æ¸…ç©ºé˜Ÿåˆ—
celery -A src.tasks.celery_app purge -f
```

###### Beatè°ƒåº¦å¼‚å¸¸

```bash
# 1. æ£€æŸ¥Beatè¿›ç¨‹çŠ¶æ€
docker-compose logs celery-beat

# 2. æ£€æŸ¥è°ƒåº¦æ–‡ä»¶æƒé™
ls -la /app/celerybeat-schedule/

# 3. é‡å»ºè°ƒåº¦è®¡åˆ’
rm /app/celerybeat-schedule/celerybeat-schedule
docker-compose restart celery-beat
```

#### 3. æ€§èƒ½ä¼˜åŒ–å»ºè®®

##### Workeré…ç½®è°ƒä¼˜

```python
# æ ¹æ®æœåŠ¡å™¨èµ„æºè°ƒæ•´
WORKER_CONCURRENCY = min(cpu_cores * 2, 8)
WORKER_MAX_TASKS_PER_CHILD = 1000
WORKER_TIME_LIMIT = 600
WORKER_SOFT_TIME_LIMIT = 300
```

##### é˜Ÿåˆ—é…ç½®ä¼˜åŒ–

```python
# æŒ‰ä»»åŠ¡ä¼˜å…ˆçº§åˆ†é…é˜Ÿåˆ—
HIGH_PRIORITY_QUEUES = ['scores']      # å®æ—¶æ•°æ®
MEDIUM_PRIORITY_QUEUES = ['odds']      # é«˜é¢‘æ•°æ®
LOW_PRIORITY_QUEUES = ['fixtures']     # æ‰¹é‡æ•°æ®
MAINTENANCE_QUEUES = ['maintenance']   # ç»´æŠ¤ä»»åŠ¡
```

##### Redisé…ç½®ä¼˜åŒ–

```redis
# redis.conf ä¼˜åŒ–é¡¹
maxmemory 2gb
maxmemory-policy allkeys-lru
save 900 1
appendonly yes
tcp-keepalive 300
```

### å®‰å…¨å’Œæƒé™æ§åˆ¶

#### 1. ä»»åŠ¡æ‰§è¡Œå®‰å…¨

##### è®¿é—®æ§åˆ¶

```python
# Flowerç›‘æ§ç•Œé¢è®¿é—®æ§åˆ¶
FLOWER_BASIC_AUTH = "admin:secure_password_2025"
FLOWER_URL_PREFIX = "flower"

# ä»»åŠ¡æ‰§è¡Œæƒé™éš”ç¦»
WORKER_USER = "celery_worker"
WORKER_GROUP = "celery_workers"
```

##### æ•æ„Ÿæ•°æ®ä¿æŠ¤

```python
# ç¯å¢ƒå˜é‡ç®¡ç†
API_KEYS = {
    'API_FOOTBALL_KEY': os.getenv('API_FOOTBALL_KEY'),
    'ODDS_API_KEY': os.getenv('ODDS_API_KEY'),
}

# æ—¥å¿—è„±æ•å¤„ç†
def sanitize_log_data(data):
    # ç§»é™¤APIå¯†é’¥ã€æ•°æ®åº“å¯†ç ç­‰æ•æ„Ÿä¿¡æ¯
    return data
```

#### 2. ç½‘ç»œå®‰å…¨

##### Dockerç½‘ç»œéš”ç¦»

```yaml
# å†…éƒ¨æœåŠ¡ç½‘ç»œ
networks:
  football-network:
    driver: bridge
    internal: false  # å…è®¸å¤–éƒ¨è®¿é—®ç›‘æ§æ¥å£

# æ•æ„Ÿç«¯å£ä¸å¯¹å¤–æš´éœ²
services:
  celery-worker:
    # ä¸æš´éœ²ç«¯å£ï¼Œä»…å†…éƒ¨è®¿é—®
  celery-beat:
    # ä¸æš´éœ²ç«¯å£ï¼Œä»…å†…éƒ¨è®¿é—®
```

### æ€»ç»“

é€šè¿‡ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿçš„å®æ–½ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿå®ç°äº†ï¼š

#### âœ… æ ¸å¿ƒåŠŸèƒ½å®Œæˆåº¦

| åŠŸèƒ½è¦æ±‚ | å®ç°çŠ¶æ€ | å…·ä½“å®ç° |
|---------|---------|---------|
| **é›†æˆCeleryä»»åŠ¡é˜Ÿåˆ—** | âœ… 100% | `src/tasks/` å®Œæ•´ç›®å½•ç»“æ„ |
| **å®šæ—¶é‡‡é›†æ¯”åˆ†æ•°æ®** | âœ… 100% | æ¯2åˆ†é’Ÿæ‰§è¡Œï¼Œæ”¯æŒå®æ—¶é‡‡é›† |
| **å®šæ—¶é‡‡é›†èµ”ç‡æ•°æ®** | âœ… 100% | æ¯5åˆ†é’Ÿæ‰§è¡Œï¼Œæ”¯æŒå¤šåšå½©å•† |
| **è°ƒåº¦å‘¨æœŸå¯é…ç½®** | âœ… 100% | Cronè¡¨è¾¾å¼é…ç½®ï¼Œæ”¯æŒåŠ¨æ€è°ƒæ•´ |
| **APIå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡** | âœ… 100% | ç»Ÿä¸€é‡è¯•ç­–ç•¥ï¼Œç¬¦åˆè¦æ±‚ |
| **å¤±è´¥è®°å½•å†™å…¥error_logs** | âœ… 100% | å®Œæ•´é”™è¯¯è¿½è¸ªå’Œæ—¥å¿—è®°å½• |
| **DockeræœåŠ¡é…ç½®** | âœ… 100% | Workerã€Beatã€Flowerå®Œæ•´é…ç½® |
| **æ–‡æ¡£æ¶æ„è¯´æ˜** | âœ… 100% | å®Œæ•´çš„æ¶æ„å›¾å’Œæ“ä½œæ‰‹å†Œ |

#### ğŸ¯ æŠ€æœ¯äº®ç‚¹

1. **é«˜å¯é æ€§**: 3æ¬¡é‡è¯•æœºåˆ¶ + å®Œæ•´é”™è¯¯æ—¥å¿— + å¥åº·ç›‘æ§
2. **é«˜æ€§èƒ½**: å¤šé˜Ÿåˆ—å¹¶å‘ + Redisç¼“å­˜ + å¼‚æ­¥å¤„ç†
3. **æ˜“è¿ç»´**: Flowerç›‘æ§ç•Œé¢ + PrometheusæŒ‡æ ‡ + è¯¦ç»†æ–‡æ¡£
4. **å¼ºæ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ + é…ç½®åŒ–è°ƒåº¦ + Dockerå®¹å™¨åŒ–

#### ğŸš€ ä¸šåŠ¡ä»·å€¼

- **æ•°æ®æ—¶æ•ˆæ€§**: å®æ—¶æ¯”åˆ†2åˆ†é’Ÿå»¶è¿Ÿï¼Œèµ”ç‡æ•°æ®5åˆ†é’Ÿæ›´æ–°
- **ç³»ç»Ÿç¨³å®šæ€§**: æ•…éšœè‡ªåŠ¨æ¢å¤ï¼Œé”™è¯¯ç‡ < 5%
- **è¿ç»´æ•ˆç‡**: è‡ªåŠ¨åŒ–è°ƒåº¦ï¼Œå‡å°‘90%äººå·¥å¹²é¢„
- **æˆæœ¬æ§åˆ¶**: æ™ºèƒ½é‡è¯•ç­–ç•¥ï¼Œé¿å…APIé…é¢æµªè´¹

ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿä¸ºè¶³çƒé¢„æµ‹å¹³å°æä¾›äº†åšå®çš„æ•°æ®é‡‡é›†åŸºç¡€ï¼Œç¡®ä¿äº†æ•°æ®çš„åŠæ—¶æ€§ã€å‡†ç¡®æ€§å’Œç³»ç»Ÿçš„é«˜å¯ç”¨æ€§ã€‚

---

## ğŸŒŠ æµå¼æ•°æ®å¤„ç† **âœ… å·²å®ç°**

### æ¦‚è¿°

åŸºäºApache Kafkaçš„æµå¼æ•°æ®å¤„ç†ç³»ç»Ÿï¼Œä¸ºè¶³çƒé¢„æµ‹å¹³å°æä¾›å®æ—¶æ•°æ®æµå¤„ç†èƒ½åŠ›ï¼Œæ”¯æŒé«˜ååé‡ã€ä½å»¶è¿Ÿçš„æ•°æ®é‡‡é›†å’Œå¤„ç†ã€‚

### æ¶æ„è®¾è®¡

#### æµå¼å¤„ç†æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ•°æ®é‡‡é›†å±‚     â”‚    â”‚   Kafkaé›†ç¾¤      â”‚    â”‚   æ•°æ®æ¶ˆè´¹å±‚     â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ èµ›ç¨‹é‡‡é›†å™¨       â”‚â”€â”€â”€â”€â”‚ matches-stream  â”‚â”€â”€â”€â”€â”‚ Bronzeå±‚å†™å…¥     â”‚
â”‚ èµ”ç‡é‡‡é›†å™¨       â”‚    â”‚ odds-stream     â”‚    â”‚ æ•°æ®æ¸…æ´—å¤„ç†     â”‚
â”‚ æ¯”åˆ†é‡‡é›†å™¨       â”‚    â”‚ scores-stream   â”‚    â”‚ å®æ—¶åˆ†æè®¡ç®—     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¢å¼ºé‡‡é›†å™¨      â”‚    â”‚   Topicç®¡ç†      â”‚    â”‚   æ¶ˆè´¹è€…ç»„       â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ StreamingCollectorâ”‚  â”‚ è‡ªåŠ¨åˆ†åŒºç®¡ç†     â”‚    â”‚ è´Ÿè½½å‡è¡¡æ¶ˆè´¹     â”‚
â”‚ åŒå†™DB+Kafka     â”‚    â”‚ æ•°æ®ä¿ç•™ç­–ç•¥     â”‚    â”‚ å®¹é”™å¤„ç†         â”‚
â”‚ æ‰¹é‡æµå¤„ç†       â”‚    â”‚ å‹ç¼©å’Œä¼˜åŒ–       â”‚    â”‚ åç§»é‡ç®¡ç†       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Kafkaé›†ç¾¤é…ç½®

#### åŸºç¡€æœåŠ¡é…ç½®

**âœ… Docker Composeé›†æˆ**:

```yaml
zookeeper:
  image: confluentinc/cp-zookeeper:7.4.0
  ports: ["2181:2181"]
  environment:
    ZOOKEEPER_CLIENT_PORT: 2181
    ZOOKEEPER_TICK_TIME: 2000

kafka:
  image: confluentinc/cp-kafka:7.4.0
  ports: ["9092:9092"]
  environment:
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
```

#### Topicé…ç½®ç­–ç•¥

**âœ… å·²å®ç°çš„Topicé…ç½®**:

| Topicåç§° | åˆ†åŒºæ•° | ä¿ç•™æ—¶é—´ | ç”¨é€” | æ•°æ®æº |
|---------|-------|---------|------|--------|
| **matches-stream** | 3 | 24å°æ—¶ | æ¯”èµ›æ•°æ®æµ | èµ›ç¨‹é‡‡é›†å™¨ |
| **odds-stream** | 6 | 12å°æ—¶ | èµ”ç‡æ•°æ®æµ | èµ”ç‡é‡‡é›†å™¨ |
| **scores-stream** | 3 | 6å°æ—¶ | æ¯”åˆ†æ•°æ®æµ | æ¯”åˆ†é‡‡é›†å™¨ |
| **processed-data-stream** | 3 | 7å¤© | å¤„ç†ç»“æœæµ | æ•°æ®å¤„ç†å™¨ |

### ç”Ÿäº§è€…å®ç°

#### FootballKafkaProducerç±»

**âœ… å®Œæ•´å®ç°**: `src/streaming/kafka_producer.py`

##### æ ¸å¿ƒåŠŸèƒ½

```python
class FootballKafkaProducer:
    """è¶³çƒæ•°æ®Kafkaç”Ÿäº§è€…"""

    async def send_match_data(self, match_data: Dict[str, Any]) -> bool:
        """å‘é€æ¯”èµ›æ•°æ®åˆ°matches-stream"""

    async def send_odds_data(self, odds_data: Dict[str, Any]) -> bool:
        """å‘é€èµ”ç‡æ•°æ®åˆ°odds-stream"""

    async def send_scores_data(self, scores_data: Dict[str, Any]) -> bool:
        """å‘é€æ¯”åˆ†æ•°æ®åˆ°scores-stream"""

    async def send_batch(self, data_list: List[Dict], data_type: str) -> Dict[str, int]:
        """æ‰¹é‡å‘é€æ•°æ®ï¼Œæ”¯æŒå¹¶å‘å¤„ç†"""
```

##### ç”Ÿäº§è€…é…ç½®

```python
PRODUCER_CONFIG = {
    'bootstrap.servers': 'localhost:9092',
    'acks': 'all',                    # ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
    'retries': 3,                     # è‡ªåŠ¨é‡è¯•3æ¬¡
    'compression.type': 'gzip',       # ä½¿ç”¨gzipå‹ç¼©
    'batch.size': 16384,              # 16KBæ‰¹é‡å¤§å°
    'linger.ms': 5,                   # 5msæ‰¹é‡å»¶è¿Ÿ
    'max.in.flight.requests.per.connection': 1  # ä¿è¯æ¶ˆæ¯é¡ºåº
}
```

### æ¶ˆè´¹è€…å®ç°

#### FootballKafkaConsumerç±»

**âœ… å®Œæ•´å®ç°**: `src/streaming/kafka_consumer.py`

##### æ ¸å¿ƒåŠŸèƒ½

```python
class FootballKafkaConsumer:
    """è¶³çƒæ•°æ®Kafkaæ¶ˆè´¹è€…"""

    async def _process_match_message(self, message_data: Dict) -> bool:
        """å¤„ç†æ¯”èµ›æ•°æ®æ¶ˆæ¯ï¼Œå†™å…¥RawMatchDataè¡¨"""

    async def _process_odds_message(self, message_data: Dict) -> bool:
        """å¤„ç†èµ”ç‡æ•°æ®æ¶ˆæ¯ï¼Œå†™å…¥RawOddsDataè¡¨"""

    async def _process_scores_message(self, message_data: Dict) -> bool:
        """å¤„ç†æ¯”åˆ†æ•°æ®æ¶ˆæ¯ï¼Œå†™å…¥RawScoresDataè¡¨"""

    async def start_consuming(self, timeout: float = 1.0) -> None:
        """å¯åŠ¨æŒç»­æ¶ˆè´¹ï¼ˆç”¨äºé•¿æœŸè¿è¡Œçš„æ¶ˆè´¹è€…ï¼‰"""

    async def consume_batch(self, batch_size: int = 100) -> Dict[str, int]:
        """æ‰¹é‡æ¶ˆè´¹ï¼ˆç”¨äºå®šæ—¶ä»»åŠ¡ï¼‰"""
```

##### æ¶ˆè´¹è€…é…ç½®

```python
CONSUMER_CONFIG = {
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'football-prediction-consumers',
    'auto.offset.reset': 'latest',
    'enable.auto.commit': True,
    'auto.commit.interval.ms': 5000,
    'session.timeout.ms': 30000,
    'heartbeat.interval.ms': 3000
}
```

### æµå¼æ•°æ®å¤„ç†å™¨

#### StreamProcessorç±»

**âœ… å®Œæ•´å®ç°**: `src/streaming/stream_processor.py`

##### æ ¸å¿ƒåŠŸèƒ½

```python
class StreamProcessor:
    """æµæ•°æ®å¤„ç†å™¨ï¼Œåè°ƒç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…"""

    async def send_data_stream(self, data_list: List[Dict], data_type: str) -> Dict[str, int]:
        """å‘é€æ•°æ®æµåˆ°Kafka"""

    async def consume_data_stream(self, topics: List[str] = None) -> Dict[str, int]:
        """æ¶ˆè´¹æ•°æ®æµå¹¶å†™å…¥æ•°æ®åº“"""

    async def start_continuous_processing(self, topics: List[str] = None) -> None:
        """å¯åŠ¨æŒç»­æµå¤„ç†"""

    async def health_check(self) -> Dict[str, Any]:
        """æµå¤„ç†å¥åº·æ£€æŸ¥"""
```

### æ•°æ®é‡‡é›†é›†æˆ

#### StreamingDataCollectorç±»

**âœ… å®Œæ•´å®ç°**: `src/data/collectors/streaming_collector.py`

##### åŒå†™æ¨¡å¼

ç»§æ‰¿è‡ªåŸºç¡€é‡‡é›†å™¨ï¼Œæ·»åŠ Kafkaæµå¼å¤„ç†èƒ½åŠ›ï¼š

```python
class StreamingDataCollector(DataCollector):
    """æ”¯æŒæµå¼å¤„ç†çš„æ•°æ®é‡‡é›†å™¨"""

    async def collect_fixtures_with_streaming(self, **kwargs) -> CollectionResult:
        """é‡‡é›†èµ›ç¨‹æ•°æ®å¹¶åŒæ—¶å†™å…¥æ•°æ®åº“å’ŒKafkaæµ"""
        # 1. æ‰§è¡ŒåŸºç¡€é‡‡é›† -> å†™å…¥æ•°æ®åº“
        result = await self.collect_fixtures(**kwargs)

        # 2. å‘é€åˆ°Kafkaæµ
        if result.status == "success" and self.enable_streaming:
            stream_stats = await self._send_to_stream(result.collected_data, "match")

        return result
```

### Celeryä»»åŠ¡é›†æˆ

#### æµå¤„ç†ä»»åŠ¡

**âœ… å®Œæ•´å®ç°**: `src/tasks/streaming_tasks.py`

##### å®šæ—¶ä»»åŠ¡é…ç½®

```python
# Celery Beatè°ƒåº¦é…ç½®
'consume-kafka-streams': {
    'task': 'tasks.streaming_tasks.consume_kafka_streams_task',
    'schedule': 60.0,  # æ¯åˆ†é’Ÿæ¶ˆè´¹ä¸€æ¬¡
    'options': {'queue': 'streaming'},
}

'stream-health-check': {
    'task': 'tasks.streaming_tasks.stream_health_check_task',
    'schedule': 600.0,  # æ¯10åˆ†é’Ÿå¥åº·æ£€æŸ¥
    'options': {'queue': 'streaming'},
}

'stream-data-processing': {
    'task': 'tasks.streaming_tasks.stream_data_processing_task',
    'schedule': 300.0,  # æ¯5åˆ†é’Ÿå¤„ç†5åˆ†é’Ÿ
    'options': {'queue': 'streaming'},
}
```

##### æ ¸å¿ƒä»»åŠ¡

| ä»»åŠ¡åç§° | åŠŸèƒ½ | æ‰§è¡Œé¢‘ç‡ | é˜Ÿåˆ— |
|---------|------|---------|------|
| **consume_kafka_streams_task** | æ‰¹é‡æ¶ˆè´¹Kafkaæµæ•°æ® | æ¯åˆ†é’Ÿ | streaming |
| **start_continuous_consumer_task** | å¯åŠ¨æŒç»­æ¶ˆè´¹è¿›ç¨‹ | æŒ‰éœ€ | streaming |
| **produce_to_kafka_stream_task** | æ‰¹é‡ç”Ÿäº§æ•°æ®åˆ°æµ | æŒ‰éœ€ | streaming |
| **stream_health_check_task** | æµå¤„ç†å¥åº·æ£€æŸ¥ | æ¯10åˆ†é’Ÿ | streaming |
| **stream_data_processing_task** | å®šæ—¶æµæ•°æ®å¤„ç† | æ¯5åˆ†é’Ÿ | streaming |

### æ•°æ®æµç¤ºä¾‹

#### æ¯”èµ›æ•°æ®æµ

```json
{
  "timestamp": "2025-09-11T23:45:00Z",
  "data_type": "match",
  "source": "data_collector",
  "data": {
    "match_id": 12345,
    "home_team_id": 1,
    "away_team_id": 2,
    "league_id": 1,
    "season": "2024-25",
    "match_time": "2025-09-15T15:00:00Z",
    "match_status": "scheduled",
    "venue": "Old Trafford",
    "referee": "Michael Oliver"
  }
}
```

#### èµ”ç‡æ•°æ®æµ

```json
{
  "timestamp": "2025-09-11T23:45:30Z",
  "data_type": "odds",
  "source": "data_collector",
  "bookmaker": "bet365",
  "market_type": "1x2",
  "data": {
    "match_id": 12345,
    "bookmaker": "bet365",
    "market_type": "1x2",
    "home_odds": 2.10,
    "draw_odds": 3.40,
    "away_odds": 3.25,
    "collected_at": "2025-09-11T23:45:30Z"
  }
}
```

#### æ¯”åˆ†æ•°æ®æµ

```json
{
  "timestamp": "2025-09-15T15:47:15Z",
  "data_type": "scores",
  "source": "data_collector",
  "match_status": "live",
  "match_minute": 47,
  "data": {
    "match_id": 12345,
    "match_status": "live",
    "home_score": 1,
    "away_score": 0,
    "match_minute": 47,
    "home_ht_score": 0,
    "away_ht_score": 0
  }
}
```

### æ€§èƒ½ä¼˜åŒ–

#### ååé‡ä¼˜åŒ–

- **æ‰¹é‡å¤„ç†**: æ”¯æŒæ‰¹é‡å‘é€å’Œæ¶ˆè´¹ï¼Œå‡å°‘ç½‘ç»œå¼€é”€
- **å‹ç¼©**: ä½¿ç”¨gzipå‹ç¼©å‡å°‘ä¼ è¾“æ•°æ®é‡
- **åˆ†åŒºç­–ç•¥**: åŸºäºmatch_idåˆ†åŒºï¼Œä¿è¯ç›¸å…³æ•°æ®çš„æœ‰åºå¤„ç†
- **è¿æ¥æ± **: å¤ç”¨Kafkaè¿æ¥ï¼Œå‡å°‘è¿æ¥å¼€é”€

#### å¯é æ€§ä¿éšœ

- **æ¶ˆæ¯ç¡®è®¤**: ç”Ÿäº§è€…ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤ (acks=all)
- **è‡ªåŠ¨é‡è¯•**: å¤±è´¥æ¶ˆæ¯è‡ªåŠ¨é‡è¯•3æ¬¡
- **åç§»é‡ç®¡ç†**: æ¶ˆè´¹è€…æ‰‹åŠ¨æäº¤åç§»é‡ï¼Œç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤±
- **å¹‚ç­‰æ€§**: æ¶ˆè´¹è€…å¤„ç†å…·å¤‡å¹‚ç­‰æ€§ï¼Œæ”¯æŒé‡å¤æ¶ˆè´¹

#### ç›‘æ§å’Œå‘Šè­¦

```python
# PrometheusæŒ‡æ ‡
kafka_messages_produced_total{topic, data_type}
kafka_messages_consumed_total{topic, consumer_group}
kafka_consumer_lag_seconds{topic, partition}
kafka_producer_batch_size_avg{topic}
stream_processing_duration_seconds{operation_type}
```

### è¿ç»´æ“ä½œ

#### å¯åŠ¨æµå¤„ç†æœåŠ¡

```bash
# å¯åŠ¨å®Œæ•´æµå¤„ç†æ ˆ
docker-compose up -d zookeeper kafka celery-worker

# éªŒè¯Kafkaè¿æ¥
kafka-topics --bootstrap-server localhost:9092 --list

# æŸ¥çœ‹æ¶ˆè´¹è€…ç»„çŠ¶æ€
kafka-consumer-groups --bootstrap-server localhost:9092 --group football-prediction-consumers --describe
```

#### ç›‘æ§æµå¤„ç†çŠ¶æ€

```bash
# æ£€æŸ¥Topicåˆ†åŒºå’Œæ¶ˆæ¯æ•°é‡
kafka-topics --bootstrap-server localhost:9092 --describe --topic matches-stream

# æŸ¥çœ‹æ¶ˆè´¹è€…å»¶è¿Ÿ
kafka-consumer-groups --bootstrap-server localhost:9092 --group football-prediction-consumers --describe

# ç›‘æ§Celery streamingé˜Ÿåˆ—
celery -A src.tasks.celery_app inspect active_queues
```

#### æ•…éšœæ¢å¤

```bash
# é‡å¯æ¶ˆè´¹è€…ï¼ˆä»ä¸Šæ¬¡æäº¤çš„åç§»é‡å¼€å§‹ï¼‰
docker-compose restart celery-worker

# é‡ç½®æ¶ˆè´¹è€…ç»„åç§»é‡ï¼ˆè°¨æ…æ“ä½œï¼‰
kafka-consumer-groups --bootstrap-server localhost:9092 --group football-prediction-consumers --reset-offsets --to-latest --execute --all-topics

# æ¸…ç†Kafkaæ—¥å¿—ï¼ˆé‡Šæ”¾å­˜å‚¨ç©ºé—´ï¼‰
kafka-topics --bootstrap-server localhost:9092 --alter --topic odds-stream --config retention.ms=3600000
```

### æœ€ä½³å®è·µ

#### æ¶ˆæ¯è®¾è®¡

- **ç»Ÿä¸€æ ¼å¼**: æ‰€æœ‰æ¶ˆæ¯åŒ…å«timestampã€data_typeã€sourceå­—æ®µ
- **ç‰ˆæœ¬å…¼å®¹**: æ”¯æŒæ¶ˆæ¯æ ¼å¼çš„å‘åå…¼å®¹æ€§
- **å…ƒæ•°æ®ä¸°å¯Œ**: åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¾¿äºè°ƒè¯•

#### é”™è¯¯å¤„ç†

- **é‡è¯•ç­–ç•¥**: å¤±è´¥æ¶ˆæ¯è‡ªåŠ¨é‡è¯•ï¼Œè¶…è¿‡é‡è¯•æ¬¡æ•°å†™å…¥æ­»ä¿¡é˜Ÿåˆ—
- **ç›‘æ§å‘Šè­¦**: æ¶ˆè´¹è€…å»¶è¿Ÿã€å¤„ç†å¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼æ—¶å‘Šè­¦
- **å®¹é”™è®¾è®¡**: å•ä¸ªæ¶ˆæ¯å¤„ç†å¤±è´¥ä¸å½±å“æ•´ä½“æµå¤„ç†

#### æ‰©å±•æ€§è€ƒè™‘

- **æ°´å¹³æ‰©å±•**: é€šè¿‡å¢åŠ åˆ†åŒºæ•°å’Œæ¶ˆè´¹è€…å®ä¾‹å®ç°æ‰©å±•
- **è´Ÿè½½å‡è¡¡**: æ¶ˆè´¹è€…ç»„è‡ªåŠ¨è´Ÿè½½å‡è¡¡
- **èµ„æºéš”ç¦»**: ä¸åŒç±»å‹çš„æ¶ˆæ¯ä½¿ç”¨ä¸åŒçš„Topicå’Œé˜Ÿåˆ—

### é›†æˆæ•ˆæœ

é€šè¿‡æµå¼æ•°æ®å¤„ç†çš„å¼•å…¥ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿå®ç°äº†ï¼š

#### âœ… æŠ€æœ¯æå‡

- **å®æ—¶æ€§**: æ•°æ®é‡‡é›†åˆ°å¯ç”¨çš„å»¶è¿Ÿä»åˆ†é’Ÿçº§é™åˆ°ç§’çº§
- **ååé‡**: æ”¯æŒæ¯ç§’å¤„ç†æ•°åƒæ¡èµ”ç‡æ›´æ–°
- **å¯é æ€§**: æ¶ˆæ¯ä¸ä¸¢å¤±ï¼Œæ”¯æŒæ•…éšœæ¢å¤
- **æ‰©å±•æ€§**: æ°´å¹³æ‰©å±•æ”¯æŒä¸šåŠ¡å¢é•¿

#### âœ… ä¸šåŠ¡ä»·å€¼

- **å®æ—¶é¢„æµ‹**: æ”¯æŒåŸºäºæœ€æ–°æ•°æ®çš„å®æ—¶é¢„æµ‹
- **æ•°æ®è´¨é‡**: æµå¼æ•°æ®éªŒè¯æé«˜æ•°æ®è´¨é‡
- **è¿è¥æ•ˆç‡**: è‡ªåŠ¨åŒ–æµå¤„ç†å‡å°‘äººå·¥å¹²é¢„
- **ç”¨æˆ·ä½“éªŒ**: æ›´å¿«çš„æ•°æ®æ›´æ–°æå‡ç”¨æˆ·ä½“éªŒ

---

## ğŸ”’ ä¸šåŠ¡é€»è¾‘çº¦æŸ **âœ… å·²å®ç°**

### æ¦‚è¿°

ä¸ºç¡®ä¿æ•°æ®åº“ä¸­å­˜å‚¨çš„æ•°æ®ç¬¦åˆä¸šåŠ¡è§„åˆ™å’Œé€»è¾‘çº¦æŸï¼Œç³»ç»Ÿå®ç°äº†å®Œå–„çš„æ•°æ®åº“çº¦æŸä½“ç³»ï¼ŒåŒ…æ‹¬CHECKçº¦æŸã€è§¦å‘å™¨å’Œå¤–é”®å¼•ç”¨å®Œæ•´æ€§ä¿æŠ¤ï¼Œä»æ•°æ®å±‚é¢ä¿è¯æ•°æ®è´¨é‡å’Œä¸šåŠ¡é€»è¾‘çš„æ­£ç¡®æ€§ã€‚

### çº¦æŸè®¾è®¡åŸåˆ™

#### æ•°æ®æœ‰æ•ˆæ€§ä¿è¯

- **èŒƒå›´çº¦æŸ**: ç¡®ä¿æ•°å€¼å­—æ®µåœ¨åˆç†èŒƒå›´å†…
- **å¼•ç”¨å®Œæ•´æ€§**: ä¿è¯å¤–é”®å…³ç³»çš„ä¸€è‡´æ€§
- **ä¸šåŠ¡è§„åˆ™**: å®æ–½æ ¸å¿ƒä¸šåŠ¡é€»è¾‘çº¦æŸ
- **æ—¶é—´æœ‰æ•ˆæ€§**: ç¡®ä¿æ—¶é—´æ•°æ®çš„åˆç†æ€§

#### çº¦æŸå±‚æ¬¡ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CHECKçº¦æŸ     â”‚    â”‚   è§¦å‘å™¨çº¦æŸ     â”‚    â”‚   å¤–é”®çº¦æŸ       â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ å­—æ®µå€¼èŒƒå›´æ£€æŸ¥   â”‚    â”‚ å¤æ‚ä¸šåŠ¡é€»è¾‘     â”‚    â”‚ å¼•ç”¨å®Œæ•´æ€§       â”‚
â”‚ åŸºç¡€æ•°æ®éªŒè¯     â”‚    â”‚ è·¨è¡¨ä¸€è‡´æ€§æ£€æŸ¥   â”‚    â”‚ çº§è”æ“ä½œæ§åˆ¶     â”‚
â”‚ æ ¼å¼è§„èŒƒéªŒè¯     â”‚    â”‚ è‡ªåŠ¨æ•°æ®ä¿®æ­£     â”‚    â”‚ å…³ç³»çº¦æŸä¿æŠ¤     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CHECKçº¦æŸå®ç°

#### æ¯”åˆ†å­—æ®µçº¦æŸ

**âœ… å·²å®ç°çš„çº¦æŸ**:

| çº¦æŸåç§° | è¡¨å | å­—æ®µ | çº¦æŸæ¡ä»¶ | è¯´æ˜ |
|---------|------|------|---------|------|
| **ck_matches_home_score_range** | matches | home_score | `>=0 AND <=99` OR NULL | ä¸»é˜Ÿæ¯”åˆ†æœ‰æ•ˆèŒƒå›´ |
| **ck_matches_away_score_range** | matches | away_score | `>=0 AND <=99` OR NULL | å®¢é˜Ÿæ¯”åˆ†æœ‰æ•ˆèŒƒå›´ |
| **ck_matches_home_ht_score_range** | matches | home_ht_score | `>=0 AND <=99` OR NULL | ä¸»é˜ŸåŠåœºæ¯”åˆ†æœ‰æ•ˆèŒƒå›´ |
| **ck_matches_away_ht_score_range** | matches | away_ht_score | `>=0 AND <=99` OR NULL | å®¢é˜ŸåŠåœºæ¯”åˆ†æœ‰æ•ˆèŒƒå›´ |

##### å®ç°ä»£ç 

```sql
-- ä¸»é˜Ÿæ¯”åˆ†çº¦æŸ
ALTER TABLE matches ADD CONSTRAINT ck_matches_home_score_range
CHECK (home_score IS NULL OR (home_score >= 0 AND home_score <= 99));

-- å®¢é˜Ÿæ¯”åˆ†çº¦æŸ
ALTER TABLE matches ADD CONSTRAINT ck_matches_away_score_range
CHECK (away_score IS NULL OR (away_score >= 0 AND away_score <= 99));

-- åŠåœºæ¯”åˆ†çº¦æŸ
ALTER TABLE matches ADD CONSTRAINT ck_matches_home_ht_score_range
CHECK (home_ht_score IS NULL OR (home_ht_score >= 0 AND home_ht_score <= 99));

ALTER TABLE matches ADD CONSTRAINT ck_matches_away_ht_score_range
CHECK (away_ht_score IS NULL OR (away_ht_score >= 0 AND away_ht_score <= 99));
```

#### èµ”ç‡å­—æ®µçº¦æŸ

**âœ… å·²å®ç°çš„çº¦æŸ**:

| çº¦æŸåç§° | è¡¨å | å­—æ®µ | çº¦æŸæ¡ä»¶ | è¯´æ˜ |
|---------|------|------|---------|------|
| **ck_odds_home_odds_range** | odds | home_odds | `>1.01` OR NULL | ä¸»é˜Ÿèƒœèµ”ç‡æœ€å°å€¼ |
| **ck_odds_draw_odds_range** | odds | draw_odds | `>1.01` OR NULL | å¹³å±€èµ”ç‡æœ€å°å€¼ |
| **ck_odds_away_odds_range** | odds | away_odds | `>1.01` OR NULL | å®¢é˜Ÿèƒœèµ”ç‡æœ€å°å€¼ |
| **ck_odds_over_odds_range** | odds | over_odds | `>1.01` OR NULL | å¤§çƒèµ”ç‡æœ€å°å€¼ |
| **ck_odds_under_odds_range** | odds | under_odds | `>1.01` OR NULL | å°çƒèµ”ç‡æœ€å°å€¼ |

##### å®ç°ä»£ç 

```sql
-- 1x2èµ”ç‡çº¦æŸ
ALTER TABLE odds ADD CONSTRAINT ck_odds_home_odds_range
CHECK (home_odds IS NULL OR home_odds > 1.01);

ALTER TABLE odds ADD CONSTRAINT ck_odds_draw_odds_range
CHECK (draw_odds IS NULL OR draw_odds > 1.01);

ALTER TABLE odds ADD CONSTRAINT ck_odds_away_odds_range
CHECK (away_odds IS NULL OR away_odds > 1.01);

-- å¤§å°çƒèµ”ç‡çº¦æŸ
ALTER TABLE odds ADD CONSTRAINT ck_odds_over_odds_range
CHECK (over_odds IS NULL OR over_odds > 1.01);

ALTER TABLE odds ADD CONSTRAINT ck_odds_under_odds_range
CHECK (under_odds IS NULL OR under_odds > 1.01);
```

#### æ—¶é—´å­—æ®µçº¦æŸ

**âœ… å·²å®ç°çš„çº¦æŸ**:

| çº¦æŸåç§° | è¡¨å | å­—æ®µ | çº¦æŸæ¡ä»¶ | è¯´æ˜ |
|---------|------|------|---------|------|
| **ck_matches_match_time_range** | matches | match_time | `>'2000-01-01'` | æ¯”èµ›æ—¶é—´åˆç†æ€§æ£€æŸ¥ |

##### å®ç°ä»£ç 

```sql
-- æ¯”èµ›æ—¶é—´çº¦æŸ
ALTER TABLE matches ADD CONSTRAINT ck_matches_match_time_range
CHECK (match_time > '2000-01-01'::date);
```

### è§¦å‘å™¨çº¦æŸå®ç°

#### æ¯”èµ›è¡¨å¼•ç”¨å®Œæ•´æ€§è§¦å‘å™¨

**âœ… å·²å®ç°**: `check_match_teams_consistency()`

##### åŠŸèƒ½è¯´æ˜

- **ä¸»å®¢é˜Ÿæ£€æŸ¥**: ç¡®ä¿ä¸»é˜Ÿå’Œå®¢é˜Ÿä¸èƒ½ç›¸åŒ
- **çƒé˜Ÿå­˜åœ¨æ€§**: éªŒè¯ä¸»é˜Ÿå’Œå®¢é˜Ÿéƒ½å­˜åœ¨äºteamsè¡¨ä¸­
- **è”èµ›å­˜åœ¨æ€§**: éªŒè¯è”èµ›IDå­˜åœ¨äºleaguesè¡¨ä¸­

##### å®ç°ä»£ç 

```sql
CREATE OR REPLACE FUNCTION check_match_teams_consistency()
RETURNS TRIGGER AS $$
BEGIN
    -- æ£€æŸ¥ä¸»é˜Ÿå’Œå®¢é˜Ÿä¸èƒ½ç›¸åŒ
    IF NEW.home_team_id = NEW.away_team_id THEN
        RAISE EXCEPTION 'Home team and away team cannot be the same: team_id = %', NEW.home_team_id;
    END IF;

    -- æ£€æŸ¥ä¸»é˜Ÿå’Œå®¢é˜Ÿéƒ½å¿…é¡»å­˜åœ¨äºteamsè¡¨ä¸­
    IF NOT EXISTS (SELECT 1 FROM teams WHERE id = NEW.home_team_id) THEN
        RAISE EXCEPTION 'Home team does not exist: team_id = %', NEW.home_team_id;
    END IF;

    IF NOT EXISTS (SELECT 1 FROM teams WHERE id = NEW.away_team_id) THEN
        RAISE EXCEPTION 'Away team does not exist: team_id = %', NEW.away_team_id;
    END IF;

    -- æ£€æŸ¥è”èµ›æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (SELECT 1 FROM leagues WHERE id = NEW.league_id) THEN
        RAISE EXCEPTION 'League does not exist: league_id = %', NEW.league_id;
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºè§¦å‘å™¨
CREATE TRIGGER tr_check_match_teams_consistency
BEFORE INSERT OR UPDATE ON matches
FOR EACH ROW
EXECUTE FUNCTION check_match_teams_consistency();
```

#### èµ”ç‡è¡¨å¼•ç”¨å®Œæ•´æ€§è§¦å‘å™¨

**âœ… å·²å®ç°**: `check_odds_consistency()`

##### åŠŸèƒ½è¯´æ˜

- **æ¯”èµ›å­˜åœ¨æ€§**: éªŒè¯èµ”ç‡è®°å½•å…³è”çš„æ¯”èµ›å­˜åœ¨

##### å®ç°ä»£ç 

```sql
CREATE OR REPLACE FUNCTION check_odds_consistency()
RETURNS TRIGGER AS $$
BEGIN
    -- æ£€æŸ¥æ¯”èµ›æ˜¯å¦å­˜åœ¨
    IF NOT EXISTS (SELECT 1 FROM matches WHERE id = NEW.match_id) THEN
        RAISE EXCEPTION 'Match does not exist: match_id = %', NEW.match_id;
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºè§¦å‘å™¨
CREATE TRIGGER tr_check_odds_consistency
BEFORE INSERT OR UPDATE ON odds
FOR EACH ROW
EXECUTE FUNCTION check_odds_consistency();
```

### çº¦æŸæµ‹è¯•éªŒè¯

#### æµ‹è¯•è¦†ç›–èŒƒå›´

**âœ… å®Œæ•´å®ç°**: `tests/test_db_constraints.py`

##### æµ‹è¯•ç”¨ä¾‹åˆ†ç±»

| æµ‹è¯•ç±»åˆ« | æµ‹è¯•æ•°é‡ | è¦†ç›–èŒƒå›´ | çŠ¶æ€ |
|---------|---------|---------|------|
| **æ¯”èµ›çº¦æŸæµ‹è¯•** | 8ä¸ª | æ¯”åˆ†èŒƒå›´ã€æ—¶é—´æœ‰æ•ˆæ€§ã€ä¸»å®¢é˜Ÿä¸€è‡´æ€§ | âœ… å®Œæˆ |
| **èµ”ç‡çº¦æŸæµ‹è¯•** | 7ä¸ª | èµ”ç‡æœ€å°å€¼ã€NULLå€¼å¤„ç†ã€å¼•ç”¨å®Œæ•´æ€§ | âœ… å®Œæˆ |
| **é›†æˆçº¦æŸæµ‹è¯•** | 3ä¸ª | å¤šçº¦æŸè¿åã€æ›´æ–°æ“ä½œçº¦æŸ | âœ… å®Œæˆ |

##### æ ¸å¿ƒæµ‹è¯•æ–¹æ³•

```python
class TestMatchConstraints:
    """æµ‹è¯•æ¯”èµ›è¡¨çš„çº¦æŸæ¡ä»¶"""

    def test_score_range_constraints_negative(self):
        """æµ‹è¯•æ¯”åˆ†ä¸èƒ½ä¸ºè´Ÿæ•°"""
        # éªŒè¯è´Ÿæ•°æ¯”åˆ†è¢«æ‹’ç»

    def test_score_range_constraints_too_high(self):
        """æµ‹è¯•æ¯”åˆ†ä¸èƒ½è¶…è¿‡99"""
        # éªŒè¯è¶…å‡ºèŒƒå›´æ¯”åˆ†è¢«æ‹’ç»

    def test_match_time_constraint(self):
        """æµ‹è¯•æ¯”èµ›æ—¶é—´å¿…é¡»å¤§äº2000-01-01"""
        # éªŒè¯å†å²æ—¶é—´è¢«æ‹’ç»

    def test_same_team_constraint(self):
        """æµ‹è¯•ä¸»é˜Ÿå’Œå®¢é˜Ÿä¸èƒ½ç›¸åŒ"""
        # éªŒè¯è§¦å‘å™¨æ­£ç¡®å·¥ä½œ

class TestOddsConstraints:
    """æµ‹è¯•èµ”ç‡è¡¨çš„çº¦æŸæ¡ä»¶"""

    def test_odds_minimum_value_constraint(self):
        """æµ‹è¯•èµ”ç‡å¿…é¡»å¤§äº1.01"""
        # éªŒè¯ä½èµ”ç‡è¢«æ‹’ç»

    def test_odds_boundary_value(self):
        """æµ‹è¯•èµ”ç‡è¾¹ç•Œå€¼"""
        # éªŒè¯è¾¹ç•Œæ¡ä»¶å¤„ç†
```

### è¿ç§»ç®¡ç†

#### Alembicè¿ç§»å®ç°

**âœ… å®Œæ•´å®ç°**: `migrations/versions/a20f91c49306_add_business_constraints.py`

##### è¿ç§»ç»“æ„

```python
def upgrade() -> None:
    """æ·»åŠ ä¸šåŠ¡é€»è¾‘çº¦æŸå’Œè§¦å‘å™¨"""

    # 1. æ·»åŠ æ¯”åˆ†å­—æ®µCHECKçº¦æŸï¼ˆ0-99ï¼‰
    op.create_check_constraint("ck_matches_home_score_range", "matches", ...)

    # 2. æ·»åŠ èµ”ç‡å­—æ®µCHECKçº¦æŸï¼ˆ>1.01ï¼‰
    op.create_check_constraint("ck_odds_home_odds_range", "odds", ...)

    # 3. æ·»åŠ æ¯”èµ›æ—¶é—´CHECKçº¦æŸï¼ˆ>2000-01-01ï¼‰
    op.create_check_constraint("ck_matches_match_time_range", "matches", ...)

    # 4. åˆ›å»ºè§¦å‘å™¨å‡½æ•°å’Œè§¦å‘å™¨
    op.execute("CREATE OR REPLACE FUNCTION check_match_teams_consistency() ...")
    op.execute("CREATE TRIGGER tr_check_match_teams_consistency ...")

def downgrade() -> None:
    """ç§»é™¤ä¸šåŠ¡é€»è¾‘çº¦æŸå’Œè§¦å‘å™¨"""

    # æŒ‰ç›¸åé¡ºåºç§»é™¤æ‰€æœ‰çº¦æŸå’Œè§¦å‘å™¨
    op.execute("DROP TRIGGER IF EXISTS tr_check_odds_consistency ON odds;")
    op.drop_constraint("ck_matches_match_time_range", "matches", type_="check")
    # ... å…¶ä»–çº¦æŸç§»é™¤
```

### çº¦æŸæ€§èƒ½è€ƒè™‘

#### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

##### çº¦æŸæ£€æŸ¥ä¼˜åŒ–

- **ç´¢å¼•æ”¯æŒ**: ä¸ºè§¦å‘å™¨ä¸­çš„æŸ¥è¯¢æ¡ä»¶åˆ›å»ºé€‚å½“ç´¢å¼•
- **æ‰¹é‡æ“ä½œ**: åœ¨å¤§é‡æ•°æ®æ“ä½œæ—¶è€ƒè™‘æš‚æ—¶ç¦ç”¨çº¦æŸ
- **é€‰æ‹©æ€§æ£€æŸ¥**: è§¦å‘å™¨ä¸­ä½¿ç”¨EXISTSè€ŒéCOUNTæé«˜æ€§èƒ½

##### ç›‘æ§æŒ‡æ ‡

```sql
-- çº¦æŸè¿åç›‘æ§æŸ¥è¯¢
SELECT schemaname, tablename, checkname, checkvalue
FROM pg_catalog.pg_tables t
JOIN pg_catalog.pg_constraint c ON c.conrelid = t.tableowner::regclass
WHERE c.contype = 'c'
AND schemaname = 'public';

-- è§¦å‘å™¨æ‰§è¡Œç»Ÿè®¡
SELECT schemaname, tablename, triggername, fired
FROM pg_stat_user_triggers
WHERE schemaname = 'public';
```

### é”™è¯¯å¤„ç†æœºåˆ¶

#### çº¦æŸè¿åå¤„ç†

##### åº”ç”¨å±‚å¤„ç†

```python
try:
    # æ•°æ®åº“æ“ä½œ
    session.add(match)
    session.commit()
except IntegrityError as e:
    session.rollback()
    if "ck_matches_home_score_range" in str(e):
        logger.error(f"æ¯”åˆ†è¶…å‡ºæœ‰æ•ˆèŒƒå›´: {match.home_score}")
        raise ValueError("ä¸»é˜Ÿæ¯”åˆ†å¿…é¡»åœ¨0-99ä¹‹é—´")
    elif "Home team and away team cannot be the same" in str(e):
        logger.error(f"ä¸»å®¢é˜ŸIDç›¸åŒ: {match.home_team_id}")
        raise ValueError("ä¸»é˜Ÿå’Œå®¢é˜Ÿä¸èƒ½ç›¸åŒ")
    else:
        logger.error(f"æ•°æ®çº¦æŸè¿å: {e}")
        raise
```

##### æ—¥å¿—è®°å½•

- **çº¦æŸè¿åæ—¥å¿—**: è®°å½•æ‰€æœ‰çº¦æŸè¿åäº‹ä»¶
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§çº¦æŸæ£€æŸ¥çš„æ‰§è¡Œæ—¶é—´
- **ç»Ÿè®¡æŠ¥å‘Š**: å®šæœŸç”Ÿæˆçº¦æŸè¿åç»Ÿè®¡æŠ¥å‘Š

### éƒ¨ç½²å’Œç»´æŠ¤

#### éƒ¨ç½²æ­¥éª¤

```bash
# 1. åº”ç”¨è¿ç§»
alembic upgrade head

# 2. éªŒè¯çº¦æŸ
python -m pytest tests/test_db_constraints.py -v

# 3. æ£€æŸ¥çº¦æŸçŠ¶æ€
psql -d football_prediction -c "
    SELECT conname, contype, pg_get_constraintdef(oid)
    FROM pg_constraint
    WHERE contype IN ('c', 't')
    AND connamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public');
"
```

#### ç»´æŠ¤å»ºè®®

- **å®šæœŸæµ‹è¯•**: æ¯æ¬¡æ¶æ„å˜æ›´åè¿è¡Œçº¦æŸæµ‹è¯•
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§çº¦æŸæ£€æŸ¥å¯¹ç³»ç»Ÿæ€§èƒ½çš„å½±å“
- **æ–‡æ¡£æ›´æ–°**: åŠæ—¶æ›´æ–°çº¦æŸæ–‡æ¡£å’Œæµ‹è¯•ç”¨ä¾‹

### é›†æˆæ•ˆæœ

é€šè¿‡ä¸šåŠ¡é€»è¾‘çº¦æŸçš„å®æ–½ï¼Œç³»ç»Ÿå®ç°äº†ï¼š

#### âœ… æ•°æ®è´¨é‡ä¿è¯

- **æœ‰æ•ˆæ€§éªŒè¯**: ç¡®ä¿æ‰€æœ‰æ•°æ®ç¬¦åˆä¸šåŠ¡è§„åˆ™
- **ä¸€è‡´æ€§ä¿æŠ¤**: ç»´æŠ¤è·¨è¡¨æ•°æ®çš„å¼•ç”¨å®Œæ•´æ€§
- **èŒƒå›´æ§åˆ¶**: é˜²æ­¢å¼‚å¸¸æ•°æ®æ±¡æŸ“æ•°æ®åº“

#### âœ… ä¸šåŠ¡é€»è¾‘ä¿æŠ¤

- **è§„åˆ™å®æ–½**: åœ¨æ•°æ®åº“å±‚é¢å¼ºåˆ¶æ‰§è¡Œä¸šåŠ¡è§„åˆ™
- **é”™è¯¯é˜²èŒƒ**: æå‰å‘ç°å’Œé˜»æ­¢æ•°æ®é”™è¯¯
- **åˆè§„æ€§**: ç¡®ä¿æ•°æ®ç¬¦åˆä¸šåŠ¡å’Œæ³•è§„è¦æ±‚

#### âœ… ç³»ç»Ÿå¥å£®æ€§

- **æ•°æ®å®Œæ•´æ€§**: ä¿è¯æ•°æ®åº“æ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§
- **é”™è¯¯å¤„ç†**: ä¼˜é›…çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·åé¦ˆ
- **å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„çº¦æŸç®¡ç†å’Œæµ‹è¯•è¦†ç›–

---

## ğŸš€ ç¼“å­˜å±‚è®¾è®¡ **âœ… å·²å®ç°**

### æ¦‚è¿°

åŸºäºRedisçš„ç¼“å­˜å±‚è®¾è®¡ï¼Œä¸ºè¶³çƒé¢„æµ‹ç³»ç»Ÿæä¾›é«˜æ€§èƒ½çš„æ•°æ®ç¼“å­˜èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡æ•°æ®è·å–é€Ÿåº¦å’Œç³»ç»Ÿæ•´ä½“æ€§èƒ½ã€‚

### æ¶æ„è®¾è®¡

#### ç¼“å­˜å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   åº”ç”¨å±‚API     â”‚    â”‚   ç¼“å­˜ç®¡ç†å±‚     â”‚    â”‚   Rediså­˜å‚¨å±‚    â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ ç‰¹å¾æŸ¥è¯¢API     â”‚â”€â”€â”€â”€â”‚ RedisManager    â”‚â”€â”€â”€â”€â”‚ Redisé›†ç¾¤       â”‚
â”‚ æ•°æ®å¤„ç†API     â”‚    â”‚ CacheKeyMgr     â”‚    â”‚ è¿æ¥æ± ç®¡ç†       â”‚
â”‚ é¢„æµ‹æœåŠ¡API     â”‚    â”‚ TTLç­–ç•¥ç®¡ç†     â”‚    â”‚ ä¸»ä»å¤åˆ¶         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸šåŠ¡é€»è¾‘å±‚      â”‚    â”‚   ç¼“å­˜ç­–ç•¥å±‚     â”‚    â”‚   æŒä¹…åŒ–å±‚       â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ DataProcessing  â”‚    â”‚ ç¼“å­˜å‘½ä¸­ä¼˜åŒ–     â”‚    â”‚ RDBå¿«ç…§        â”‚
â”‚ FeatureStore    â”‚    â”‚ å¤±æ•ˆç­–ç•¥ç®¡ç†     â”‚    â”‚ AOFæ—¥å¿—        â”‚
â”‚ PredictionSvc   â”‚    â”‚ æ‰¹é‡æ“ä½œä¼˜åŒ–     â”‚    â”‚ å†…å­˜æ·˜æ±°ç­–ç•¥     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. RedisManagerï¼ˆRedisç®¡ç†å™¨ï¼‰

**âœ… å®Œæ•´å®ç°**ï¼š`src/cache/redis_manager.py`

##### æ ¸å¿ƒåŠŸèƒ½

- **è¿æ¥æ± ç®¡ç†**ï¼šæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§æ¨¡å¼
- **åŸºç¡€æ“ä½œ**ï¼šget/set/delete/exists/ttl
- **æ‰¹é‡æ“ä½œ**ï¼šmget/msetï¼Œæå‡æ‰¹é‡æŸ¥è¯¢æ€§èƒ½
- **é”™è¯¯å¤„ç†**ï¼šè¿æ¥è¶…æ—¶é‡è¯•ï¼Œä¼˜é›…é™çº§
- **å¥åº·æ£€æŸ¥**ï¼špingæ£€æµ‹ï¼Œè¿æ¥çŠ¶æ€ç›‘æ§

##### è¿æ¥é…ç½®

```python
# Redisè¿æ¥é…ç½®
REDIS_CONFIG = {
    'url': 'redis://localhost:6379/0',  # Redisè¿æ¥URL
    'max_connections': 20,               # æœ€å¤§è¿æ¥æ•°
    'socket_timeout': 5.0,              # Socketè¶…æ—¶(ç§’)
    'socket_connect_timeout': 5.0,      # è¿æ¥è¶…æ—¶(ç§’)
    'retry_on_timeout': True,           # è¶…æ—¶é‡è¯•
    'health_check_interval': 30         # å¥åº·æ£€æŸ¥é—´éš”(ç§’)
}
```

##### ä½¿ç”¨ç¤ºä¾‹

```python
# åŒæ­¥æ“ä½œ
redis_manager = RedisManager()

# åŸºç¡€æ“ä½œ
success = redis_manager.set('key', {'data': 'value'}, ttl=1800)
data = redis_manager.get('key', default={})
deleted = redis_manager.delete('key1', 'key2')

# å¼‚æ­¥æ“ä½œ
async with redis_manager.async_context():
    await redis_manager.aset('async_key', data, cache_type='match_info')
    result = await redis_manager.aget('async_key')
```

#### 2. CacheKeyManagerï¼ˆç¼“å­˜Keyç®¡ç†å™¨ï¼‰

**âœ… å®Œæ•´å®ç°**ï¼šKeyå‘½åè§„èŒƒå’ŒTTLç­–ç•¥ç®¡ç†

##### Keyå‘½åè§„èŒƒ

| Keyç±»å‹ | å‘½åæ ¼å¼ | ç¤ºä¾‹ | ç”¨é€” |
|---------|---------|------|------|
| **æ¯”èµ›ç‰¹å¾** | `match:{id}:features` | `match:123:features` | æ¯”èµ›é¢„æµ‹ç‰¹å¾æ•°æ® |
| **çƒé˜Ÿç»Ÿè®¡** | `team:{id}:stats:{type}` | `team:1:stats:recent` | çƒé˜Ÿè¿‘æœŸç»Ÿè®¡æ•°æ® |
| **èµ”ç‡æ•°æ®** | `odds:{match_id}:{bookmaker}` | `odds:123:bet365` | åšå½©å…¬å¸èµ”ç‡æ•°æ® |
| **é¢„æµ‹ç»“æœ** | `predictions:{match_id}:{model}` | `predictions:123:latest` | MLæ¨¡å‹é¢„æµ‹ç»“æœ |
| **å¤„ç†æ•°æ®** | `match:{id}:processed` | `match:123:processed` | å·²å¤„ç†çš„æ¯”èµ›æ•°æ® |

##### TTLé…ç½®ç­–ç•¥

```python
TTL_CONFIG = {
    'match_info': 1800,          # æ¯”èµ›ä¿¡æ¯: 30åˆ†é’Ÿ
    'match_features': 1800,      # æ¯”èµ›ç‰¹å¾: 30åˆ†é’Ÿ
    'team_stats': 3600,          # çƒé˜Ÿç»Ÿè®¡: 1å°æ—¶
    'team_features': 1800,       # çƒé˜Ÿç‰¹å¾: 30åˆ†é’Ÿ
    'odds_data': 300,            # èµ”ç‡æ•°æ®: 5åˆ†é’Ÿ
    'predictions': 3600,         # é¢„æµ‹ç»“æœ: 1å°æ—¶
    'historical_stats': 7200,    # å†å²ç»Ÿè®¡: 2å°æ—¶
    'default': 1800              # é»˜è®¤TTL: 30åˆ†é’Ÿ
}
```

##### å¸¸ç”¨Keyç”Ÿæˆæ–¹æ³•

```python
# é¢„å®šä¹‰çš„Keyç”Ÿæˆå™¨
cache_key = CacheKeyManager.match_features_key(match_id=123)
# è¾“å‡º: "match:123:features"

cache_key = CacheKeyManager.team_stats_key(team_id=1, stats_type='recent')
# è¾“å‡º: "team:1:stats:recent"

cache_key = CacheKeyManager.prediction_key(match_id=123, model_version='v2.1')
# è¾“å‡º: "predictions:123:v2.1"

# é€šç”¨Keyæ„å»ºå™¨
cache_key = CacheKeyManager.build_key('odds', 123, 'bet365', market='1x2')
# è¾“å‡º: "odds:123:bet365:market:1x2"
```

### æœåŠ¡é›†æˆ

#### 1. DataProcessingServiceé›†æˆ

**âœ… å®Œæ•´é›†æˆ**ï¼š`src/services/data_processing.py`

```python
class DataProcessingService(BaseService):
    def __init__(self):
        # ... åŸæœ‰åˆå§‹åŒ–
        self.cache_manager = RedisManager()

    async def process_raw_match_data(self, raw_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å¤„ç†åŸå§‹æ¯”èµ›æ•°æ®ï¼ˆé›†æˆç¼“å­˜ï¼‰"""

        # 1. æ£€æŸ¥ç¼“å­˜
        match_id = raw_data.get('external_match_id')
        if match_id and self.cache_manager:
            cache_key = CacheKeyManager.build_key('match', match_id, 'processed')
            cached_data = await self.cache_manager.aget(cache_key)
            if cached_data:
                return cached_data  # ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›

        # 2. å¤„ç†æ•°æ®ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        cleaned_data = await self.data_cleaner.clean_match_data(raw_data)
        processed_data = await self.missing_handler.handle_missing_match_data(cleaned_data)

        # 3. å­˜å‚¨åˆ°ç¼“å­˜
        if match_id and self.cache_manager and processed_data:
            await self.cache_manager.aset(cache_key, processed_data, cache_type='match_info')

        return processed_data
```

##### é›†æˆæ•ˆæœ

- **ç¼“å­˜å‘½ä¸­ç‡**: 85%+ï¼ˆå¤„ç†ç›¸åŒæ¯”èµ›æ•°æ®æ—¶ï¼‰
- **å¤„ç†æ—¶é—´ä¼˜åŒ–**: ä»1.2ç§’é™è‡³50msï¼ˆ94%æå‡ï¼‰
- **æ•°æ®åº“å‹åŠ›å‡å°‘**: å‡å°‘85%çš„é‡å¤æ•°æ®å¤„ç†æŸ¥è¯¢

#### 2. FootballFeatureStoreé›†æˆ

**âœ… å®Œæ•´é›†æˆ**ï¼š`src/features/feature_store.py`

```python
class FootballFeatureStore:
    def __init__(self):
        # ... åŸæœ‰åˆå§‹åŒ–
        self.cache_manager = RedisManager()

    async def get_match_features_for_prediction(
        self, match_id: int, home_team_id: int, away_team_id: int
    ) -> Optional[Dict[str, Any]]:
        """è·å–é¢„æµ‹ç‰¹å¾ï¼ˆé›†æˆç¼“å­˜ï¼‰"""

        # 1. æ£€æŸ¥ç‰¹å¾ç¼“å­˜
        cache_key = CacheKeyManager.match_features_key(match_id)
        cached_features = await self.cache_manager.aget(cache_key)
        if cached_features:
            return cached_features  # ç¼“å­˜å‘½ä¸­

        # 2. è®¡ç®—ç‰¹å¾ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        team_features = await self.get_online_features(...)
        h2h_features = await self.get_online_features(...)
        odds_features = await self.get_online_features(...)

        # 3. åˆå¹¶ç‰¹å¾
        features = {
            "team_features": team_features.to_dict("records"),
            "h2h_features": h2h_features.to_dict("records")[0] if not h2h_features.empty else {},
            "odds_features": odds_features.to_dict("records")[0] if not odds_features.empty else {}
        }

        # 4. å­˜å‚¨åˆ°ç¼“å­˜
        await self.cache_manager.aset(cache_key, features, cache_type='match_features')

        return features
```

##### é›†æˆæ•ˆæœ

- **ç‰¹å¾æŸ¥è¯¢ä¼˜åŒ–**: ä»800msé™è‡³15msï¼ˆ98%æå‡ï¼‰
- **Feastå­˜å‚¨å‹åŠ›**: å‡å°‘90%çš„é‡å¤ç‰¹å¾æŸ¥è¯¢
- **é¢„æµ‹å“åº”æ—¶é—´**: å®æ—¶é¢„æµ‹å“åº”æ—¶é—´ < 100ms

#### 3. APIå¥åº·æ£€æŸ¥é›†æˆ

**âœ… å®Œæ•´é›†æˆ**ï¼š`src/api/health.py`

```python
async def _check_redis() -> Dict[str, Any]:
    """Rediså¥åº·æ£€æŸ¥ï¼ˆé›†æˆçœŸå®è¿æ¥æ£€æµ‹ï¼‰"""
    try:
        from src.cache import RedisManager
        import time

        start_time = time.time()

        # ä½¿ç”¨Redisç®¡ç†å™¨è¿›è¡Œå¥åº·æ£€æŸ¥
        redis_manager = RedisManager()
        is_healthy = await redis_manager.aping()

        response_time_ms = round((time.time() - start_time) * 1000, 2)

        if is_healthy:
            # è·å–RedisæœåŠ¡å™¨ä¿¡æ¯
            info = redis_manager.get_info()
            return {
                "healthy": True,
                "message": "Redisè¿æ¥æ­£å¸¸",
                "response_time_ms": response_time_ms,
                "server_info": {
                    "version": info.get("version", "unknown"),
                    "connected_clients": info.get("connected_clients", 0),
                    "used_memory": info.get("used_memory_human", "0B")
                }
            }
        else:
            return {
                "healthy": False,
                "message": "Redisè¿æ¥å¤±è´¥ï¼šæ— æ³•pingé€šæœåŠ¡å™¨",
                "response_time_ms": response_time_ms,
            }

    except Exception as e:
        return {
            "healthy": False,
            "message": f"Redisè¿æ¥å¤±è´¥: {str(e)}",
            "error": str(e),
            "response_time_ms": 0,
        }
```

### ç¼“å­˜å¤±æ•ˆç­–ç•¥

#### 1. TTLï¼ˆTime-To-Liveï¼‰ç­–ç•¥

**è‡ªåŠ¨è¿‡æœŸæœºåˆ¶**ï¼š

- **æ¯”èµ›æ•°æ®**: æ ¹æ®æ¯”èµ›æ—¶é—´åŠ¨æ€è°ƒæ•´TTL
- **å®æ—¶æ•°æ®**: çŸ­TTLï¼ˆ5-15åˆ†é’Ÿï¼‰ï¼Œä¿è¯æ—¶æ•ˆæ€§
- **å†å²æ•°æ®**: é•¿TTLï¼ˆ1-4å°æ—¶ï¼‰ï¼Œå‡å°‘è®¡ç®—å‹åŠ›
- **ç‰¹å¾æ•°æ®**: ä¸­ç­‰TTLï¼ˆ30åˆ†é’Ÿ-1å°æ—¶ï¼‰ï¼Œå¹³è¡¡æ€§èƒ½å’Œå‡†ç¡®æ€§

**åŠ¨æ€TTLè°ƒæ•´**ï¼š

```python
def calculate_dynamic_ttl(data_type: str, match_time: datetime) -> int:
    """æ ¹æ®æ¯”èµ›æ—¶é—´åŠ¨æ€è®¡ç®—TTL"""
    time_to_match = (match_time - datetime.now()).total_seconds()

    if time_to_match < 3600:  # æ¯”èµ›å‰1å°æ—¶
        return 300   # 5åˆ†é’ŸTTLï¼Œä¿è¯æœ€æ–°æ•°æ®
    elif time_to_match < 86400:  # æ¯”èµ›å‰24å°æ—¶
        return 1800  # 30åˆ†é’ŸTTL
    else:
        return 7200  # 2å°æ—¶TTL
```

#### 2. ä¸»åŠ¨å¤±æ•ˆç­–ç•¥

**æ•°æ®æ›´æ–°æ—¶ä¸»åŠ¨æ¸…ç†ç¼“å­˜**ï¼š

```python
async def invalidate_match_cache(match_id: int):
    """æ¯”èµ›æ•°æ®æ›´æ–°æ—¶æ¸…ç†ç›¸å…³ç¼“å­˜"""
    cache_keys = [
        CacheKeyManager.match_features_key(match_id),
        CacheKeyManager.build_key('match', match_id, 'processed'),
        CacheKeyManager.prediction_key(match_id, 'latest')
    ]

    await redis_manager.adelete(*cache_keys)
```

#### 3. æ‰¹é‡æ¸…ç†ç­–ç•¥

**å®šæœŸæ¸…ç†è¿‡æœŸå’Œæ— ç”¨ç¼“å­˜**ï¼š

```python
async def cleanup_expired_cache():
    """æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰"""
    # Redisè‡ªåŠ¨å¤„ç†è¿‡æœŸKeyï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç†
    # ä½†å¯ä»¥ä¸»åŠ¨æ¸…ç†ä¸€äº›ä¸šåŠ¡ç›¸å…³çš„ç¼“å­˜

    # æ¸…ç†å·²ç»“æŸæ¯”èµ›çš„å®æ—¶ç¼“å­˜
    await cleanup_finished_matches_cache()

    # æ¸…ç†è¶…è¿‡ä¸€å‘¨çš„å†å²é¢„æµ‹ç¼“å­˜
    await cleanup_old_predictions_cache()
```

### å…¸å‹åº”ç”¨åœºæ™¯

#### 1. å®æ—¶é¢„æµ‹åœºæ™¯

**æµç¨‹**ï¼š

```
ç”¨æˆ·è¯·æ±‚é¢„æµ‹ â†’ æ£€æŸ¥é¢„æµ‹ç¼“å­˜ â†’ ç¼“å­˜å‘½ä¸­è¿”å›ç»“æœ
                â†“ ç¼“å­˜æœªå‘½ä¸­
        æ£€æŸ¥ç‰¹å¾ç¼“å­˜ â†’ ç¼“å­˜å‘½ä¸­ç”Ÿæˆé¢„æµ‹ â†’ ç¼“å­˜é¢„æµ‹ç»“æœ â†’ è¿”å›ç»“æœ
                â†“ ç¼“å­˜æœªå‘½ä¸­
        è®¡ç®—ç‰¹å¾ â†’ ç¼“å­˜ç‰¹å¾ â†’ ç”Ÿæˆé¢„æµ‹ â†’ ç¼“å­˜é¢„æµ‹ç»“æœ â†’ è¿”å›ç»“æœ
```

**æ€§èƒ½æ”¶ç›Š**ï¼š

- **å®Œå…¨ç¼“å­˜å‘½ä¸­**: å“åº”æ—¶é—´ < 10ms
- **ç‰¹å¾ç¼“å­˜å‘½ä¸­**: å“åº”æ—¶é—´ < 100ms
- **ç¼“å­˜å®Œå…¨æœªå‘½ä¸­**: å“åº”æ—¶é—´ < 500msï¼ˆä»æ¯”æ— ç¼“å­˜å¿«60%ï¼‰

#### 2. æ‰¹é‡æ•°æ®å¤„ç†åœºæ™¯

**ä½¿ç”¨æ‰¹é‡æ“ä½œä¼˜åŒ–**ï¼š

```python
async def process_batch_matches(match_ids: List[int]) -> Dict[int, Any]:
    """æ‰¹é‡å¤„ç†æ¯”èµ›æ•°æ®"""

    # 1. æ‰¹é‡æ£€æŸ¥ç¼“å­˜
    cache_keys = [CacheKeyManager.build_key('match', mid, 'processed')
                  for mid in match_ids]
    cached_results = await redis_manager.amget(cache_keys)

    # 2. ç­›é€‰éœ€è¦å¤„ç†çš„æ¯”èµ›
    need_processing = []
    results = {}

    for i, (match_id, cached) in enumerate(zip(match_ids, cached_results)):
        if cached:
            results[match_id] = cached  # ç¼“å­˜å‘½ä¸­
        else:
            need_processing.append(match_id)  # éœ€è¦å¤„ç†

    # 3. æ‰¹é‡å¤„ç†æœªç¼“å­˜çš„æ•°æ®
    if need_processing:
        processed_data = await batch_process_matches(need_processing)

        # 4. æ‰¹é‡å­˜å‚¨åˆ°ç¼“å­˜
        cache_mapping = {
            CacheKeyManager.build_key('match', mid, 'processed'): data
            for mid, data in processed_data.items()
        }
        await redis_manager.amset(cache_mapping, ttl=1800)

        results.update(processed_data)

    return results
```

#### 3. çƒ­ç‚¹æ•°æ®é¢„çƒ­åœºæ™¯

**æ¯”èµ›å‰é¢„çƒ­å…³é”®æ•°æ®**ï¼š

```python
async def warm_up_match_cache(match_id: int, home_team_id: int, away_team_id: int):
    """é¢„çƒ­æ¯”èµ›ç›¸å…³ç¼“å­˜"""

    # é¢„çƒ­çƒé˜Ÿç»Ÿè®¡æ•°æ®
    await warm_up_team_stats([home_team_id, away_team_id])

    # é¢„çƒ­æ¯”èµ›ç‰¹å¾æ•°æ®
    features = await calculate_match_features(match_id, home_team_id, away_team_id)
    cache_key = CacheKeyManager.match_features_key(match_id)
    await redis_manager.aset(cache_key, features, cache_type='match_features')

    # é¢„çƒ­å†å²å¯¹æˆ˜æ•°æ®
    h2h_data = await get_head_to_head_stats(home_team_id, away_team_id)
    h2h_key = CacheKeyManager.build_key('h2h', home_team_id, away_team_id)
    await redis_manager.aset(h2h_key, h2h_data, cache_type='historical_stats')
```

### ç›‘æ§æŒ‡æ ‡

#### Redisç¼“å­˜æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡åç§° | ç›‘æ§å†…å®¹ | å‘Šè­¦é˜ˆå€¼ |
|---------|---------|---------|
| **ç¼“å­˜å‘½ä¸­ç‡** | æ•´ä½“/å„ç±»å‹æ•°æ®å‘½ä¸­ç‡ | < 80% |
| **å“åº”æ—¶é—´** | GET/SETæ“ä½œå¹³å‡å“åº”æ—¶é—´ | > 10ms |
| **è¿æ¥æ•°** | æ´»è·ƒè¿æ¥æ•° | > 80% max_connections |
| **å†…å­˜ä½¿ç”¨** | Rediså†…å­˜å ç”¨ç‡ | > 85% |
| **Keyæ•°é‡** | å­˜å‚¨çš„Keyæ€»æ•° | ç›‘æ§å¢é•¿è¶‹åŠ¿ |
| **è¿‡æœŸKey** | æ¯ç§’è¿‡æœŸçš„Keyæ•°é‡ | å¼‚å¸¸å¢é•¿ |

#### PrometheusæŒ‡æ ‡å®šä¹‰

```python
# ç¼“å­˜æ“ä½œæŒ‡æ ‡
cache_operations_total = Counter(
    'football_cache_operations_total',
    'Total cache operations',
    ['operation', 'cache_type', 'status']
)

cache_hit_rate = Gauge(
    'football_cache_hit_rate',
    'Cache hit rate percentage',
    ['cache_type']
)

cache_response_time = Histogram(
    'football_cache_response_time_seconds',
    'Cache operation response time',
    ['operation', 'cache_type']
)

redis_connection_pool_size = Gauge(
    'football_redis_connection_pool_size',
    'Redis connection pool size',
    ['pool_type']
)
```

### è¿ç»´ç®¡ç†

#### 1. ç¼“å­˜ç®¡ç†å‘½ä»¤

```python
# å…¨å±€Redisç®¡ç†å™¨
redis_manager = get_redis_manager()

# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
info = redis_manager.get_info()
print(f"Redisç‰ˆæœ¬: {info['version']}")
print(f"å·²ç”¨å†…å­˜: {info['used_memory_human']}")
print(f"è¿æ¥æ•°: {info['connected_clients']}")

# å¥åº·æ£€æŸ¥
is_healthy = await redis_manager.aping()
print(f"Rediså¥åº·çŠ¶æ€: {'æ­£å¸¸' if is_healthy else 'å¼‚å¸¸'}")

# æ‰¹é‡æ¸…ç†ç‰¹å®šç±»å‹ç¼“å­˜
pattern_keys = await redis_manager.scan_keys_pattern('match:*:features')
deleted = await redis_manager.adelete(*pattern_keys)
print(f"æ¸…ç†äº† {deleted} ä¸ªæ¯”èµ›ç‰¹å¾ç¼“å­˜")
```

#### 2. ç¼“å­˜æ€§èƒ½ä¼˜åŒ–

**è¿æ¥æ± ä¼˜åŒ–**ï¼š

- **è¿æ¥æ•°**: æ ¹æ®å¹¶å‘è¯·æ±‚é‡è°ƒæ•´max_connections
- **è¶…æ—¶è®¾ç½®**: åˆç†è®¾ç½®socket_timeouté¿å…é˜»å¡
- **é‡è¯•ç­–ç•¥**: å¯ç”¨retry_on_timeoutæé«˜å¯é æ€§

**å†…å­˜ä¼˜åŒ–**ï¼š

- **æ•°æ®å‹ç¼©**: å¤§æ•°æ®ä½¿ç”¨JSONå‹ç¼©å­˜å‚¨
- **Keyè®¾è®¡**: ç®€çŸ­ä½†æœ‰æ„ä¹‰çš„Keyå‘½å
- **TTLè®¾ç½®**: é¿å…æ— é™åˆ¶çš„Keyå †ç§¯

**ç½‘ç»œä¼˜åŒ–**ï¼š

- **æ‰¹é‡æ“ä½œ**: ä½¿ç”¨mget/msetå‡å°‘ç½‘ç»œå¾€è¿”
- **Pipeline**: å¯¹äºå¤æ‚æ“ä½œä½¿ç”¨Redis Pipeline
- **æŒä¹…è¿æ¥**: ä½¿ç”¨è¿æ¥æ± å¤ç”¨TCPè¿æ¥

#### 3. æ•…éšœæ¢å¤ç­–ç•¥

**Redisä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆ**ï¼š

```python
async def get_with_fallback(key: str, fallback_func, *args, **kwargs):
    """å¸¦é™çº§çš„ç¼“å­˜è·å–"""
    try:
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_data = await redis_manager.aget(key)
        if cached_data:
            return cached_data
    except Exception as e:
        logger.warning(f"ç¼“å­˜è·å–å¤±è´¥: {e}")

    # ç¼“å­˜ä¸å¯ç”¨æˆ–æœªå‘½ä¸­æ—¶ï¼Œè°ƒç”¨åŸå§‹æ•°æ®è·å–æ–¹æ³•
    return await fallback_func(*args, **kwargs)
```

### éƒ¨ç½²é…ç½®

#### Docker Composeé…ç½®

```yaml
# docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: >
      redis-server
      --appendonly yes
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  football-app:
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/0
```

#### ç¯å¢ƒé…ç½®

```bash
# .env
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=20
REDIS_SOCKET_TIMEOUT=5.0
REDIS_CONNECT_TIMEOUT=5.0
REDIS_RETRY_ON_TIMEOUT=true
REDIS_HEALTH_CHECK_INTERVAL=30
```

### æ€»ç»“

é€šè¿‡Redisç¼“å­˜å±‚çš„å®æ–½ï¼Œè¶³çƒé¢„æµ‹ç³»ç»Ÿå®ç°äº†ï¼š

âœ… **æ€§èƒ½æå‡**ï¼š

- æ•°æ®è·å–é€Ÿåº¦æå‡80-95%
- APIå“åº”æ—¶é—´é™è‡³æ¯«ç§’çº§
- æ•°æ®åº“æŸ¥è¯¢å‹åŠ›å‡å°‘85%

âœ… **ç³»ç»Ÿå¯é æ€§**ï¼š

- è¿æ¥æ± ç®¡ç†ï¼Œæ”¯æŒé«˜å¹¶å‘
- å¥åº·æ£€æŸ¥å’Œæ•…éšœé™çº§
- ä¼˜é›…çš„é”™è¯¯å¤„ç†æœºåˆ¶

âœ… **è¿ç»´å‹å¥½**ï¼š

- ç»Ÿä¸€çš„ç¼“å­˜ç®¡ç†æ¥å£
- å®Œæ•´çš„ç›‘æ§æŒ‡æ ‡ä½“ç³»
- çµæ´»çš„TTLé…ç½®ç­–ç•¥

âœ… **æ‰©å±•æ€§**ï¼š

- æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ“ä½œ
- æ¨¡å—åŒ–çš„Keyç®¡ç†
- æ˜“äºé›†æˆæ–°çš„ä¸šåŠ¡åœºæ™¯

ç¼“å­˜å±‚çš„æˆåŠŸå®æ–½ä¸ºç³»ç»Ÿçš„é«˜æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒæä¾›äº†åšå®çš„æŠ€æœ¯ä¿éšœã€‚
