# AI Programming Tool Context

## Project Testing Strategy

This project uses a **mock-based testing approach** where tests simulate external dependencies. This is intentional and provides fast, reliable unit tests.

## Critical Testing Rules

1. **NEVER run single files with coverage**:
   ```bash
   # ❌ WRONG - Shows 0% coverage
   pytest tests/unit/api/test_health.py --cov=src

   # ✅ CORRECT - Shows actual coverage
   make test-phase1
   ```

2. **Phase 1 is already complete**:
   - data.py: 17 tests, 90% coverage
   - features.py: 28 tests, 88% coverage
   - predictions.py: 27 tests, 88% coverage

3. **Use Makefile commands**:
   - `make test-phase1` - Core API tests
   - `make test-quick` - Fast unit tests
   - `make coverage` - Full coverage report

## Project Structure

```
src/
├── api/           # FastAPI endpoints (Phase 1 complete ✅)
├── database/      # SQLAlchemy models
├── services/      # Business logic
└── utils/         # Utilities

tests/
├── unit/          # Unit tests (96.35% coverage)
└── integration/   # Integration tests
```

## Key Configuration

- pytest.ini: Auto-enables `--cov=src`
- Coverage threshold: 80%
- Test markers: unit, integration, slow, legacy

## Before Making Changes

1. Run `make test-phase1` to verify current state
2. Read CLAUDE.md for development guidelines
3. Check existing test patterns in `tests/unit/api/`

---
*This context helps AI tools understand the testing methodology and avoid common mistakes.*