# ğŸš€ Football Prediction Project Makefile
# Author: DevOps Engineer
# Description: Concise, maintainable Makefile for Python/FastAPI project

# ============================================================================
# ğŸ”§ Configuration Variables
# ============================================================================
PYTHON := python3
VENV := .venv
VENV_BIN := $(VENV)/bin
ACTIVATE := . $(VENV_BIN)/activate
COVERAGE_THRESHOLD := 60

# Colors for better UX
GREEN := \033[32m
YELLOW := \033[33m
RED := \033[31m
BLUE := \033[34m
RESET := \033[0m

# ============================================================================
# ğŸ¯ Default Target
# ============================================================================
.DEFAULT_GOAL := help

help: ## ğŸ“‹ Show available commands
	@echo "$(BLUE)ğŸš€ Football Prediction Project Commands$(RESET)"
	@echo "$(YELLOW)Environment:$(RESET)"
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## .*Environment/ {printf "  $(GREEN)%-12s$(RESET) %s\n", $$1, $$2}' $(MAKEFILE_LIST)
	@echo "$(YELLOW)Code Quality:$(RESET)"
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## .*Quality/ {printf "  $(GREEN)%-12s$(RESET) %s\n", $$1, $$2}' $(MAKEFILE_LIST)
	@echo "$(YELLOW)Testing:$(RESET)"
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## .*Test/ {printf "  $(GREEN)%-12s$(RESET) %s\n", $$1, $$2}' $(MAKEFILE_LIST)
	@echo "$(YELLOW)CI/Container:$(RESET)"
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## .*(CI|Container)/ {printf "  $(GREEN)%-12s$(RESET) %s\n", $$1, $$2}' $(MAKEFILE_LIST)
	@echo "$(YELLOW)Other:$(RESET)"
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## / && !/Environment|Quality|Test|CI|Container/ {printf "  $(GREEN)%-12s$(RESET) %s\n", $$1, $$2}' $(MAKEFILE_LIST)

# ============================================================================
# ğŸŒ Environment Management
# ============================================================================
env-check: ## Environment: Check development environment health
	@echo "$(YELLOW)Checking development environment...$(RESET)"
	@$(ACTIVATE) && \
	echo "$(BLUE)âœ“ Virtual environment: $(VENV)$(RESET)" && \
	python --version && \
	echo "$(BLUE)âœ“ Python version check passed$(RESET)" && \
	pip list | head -5 && \
	echo "$(GREEN)âœ… Environment check completed$(RESET)"
venv: ## Environment: Create and activate virtual environment
	@if [ ! -d "$(VENV)" ]; then \
		echo "$(YELLOW)Creating virtual environment...$(RESET)"; \
		$(PYTHON) -m venv $(VENV); \
		echo "$(GREEN)âœ… Virtual environment created$(RESET)"; \
	else \
		echo "$(BLUE)â„¹ï¸  Virtual environment already exists$(RESET)"; \
	fi

install: venv ## Environment: Install dependencies from requirements.txt
	@$(ACTIVATE) && \
	if pip list | grep -F "$(shell head -n1 requirements.txt | cut -d'=' -f1)" > /dev/null 2>&1; then \
		echo "$(BLUE)â„¹ï¸  Dependencies appear to be installed$(RESET)"; \
	else \
		echo "$(YELLOW)Installing dependencies...$(RESET)"; \
		pip install --upgrade pip && \
		pip install -r requirements.txt && \
		pip install -r requirements-dev.txt; \
		echo "$(GREEN)âœ… Dependencies installed$(RESET)"; \
	fi

# ============================================================================
# ğŸ¨ Code Quality
# ============================================================================
lint: ## Quality: Run flake8 and mypy checks
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running flake8...$(RESET)" && \
	flake8 src/ tests/ && \
	echo "$(YELLOW)Running mypy...$(RESET)" && \
	mypy --config-file mypy.ini src/ && \
	echo "$(GREEN)âœ… Linting passed$(RESET)"

fmt: ## Quality: Format code with black and isort
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running black...$(RESET)" && \
	black src/ tests/ && \
	echo "$(YELLOW)Running isort...$(RESET)" && \
	isort src/ tests/ && \
	echo "$(GREEN)âœ… Code formatted$(RESET)"

quality: lint fmt test ## Quality: Complete quality check (lint + format + test)
	@echo "$(GREEN)âœ… All quality checks passed$(RESET)"

check: quality ## Quality: Alias for quality command
	@echo "$(GREEN)âœ… All quality checks passed$(RESET)"

# ============================================================================
# ğŸ§ª Testing
# ============================================================================
test: ## Test: Run pytest unit tests
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running tests...$(RESET)" && \
	pytest tests/ -v --maxfail=5 --disable-warnings && \
	echo "$(GREEN)âœ… Tests passed$(RESET)"

coverage: ## Test: Run tests with coverage report (threshold: 60%)
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running coverage tests...$(RESET)" && \
	pytest tests/ --cov=src --cov-report=term-missing --cov-fail-under=$(COVERAGE_THRESHOLD) --maxfail=5 --disable-warnings && \
	echo "$(GREEN)âœ… Coverage passed (>=$(COVERAGE_THRESHOLD)%)$(RESET)"

coverage-fast: ## Test: Run fast coverage (unit tests only, 60% threshold)
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running fast coverage tests...$(RESET)" && \
	pytest tests/unit/ --cov=src --cov-report=term-missing --cov-fail-under=$(COVERAGE_THRESHOLD) --maxfail=5 --disable-warnings --timeout=30 && \
	echo "$(GREEN)âœ… Fast coverage passed (>=$(COVERAGE_THRESHOLD)%)$(RESET)"

coverage-unit: ## Test: Unit test coverage only
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running unit test coverage...$(RESET)" && \
	pytest tests/unit/ --cov=src --cov-report=html --cov-report=term --timeout=30 --maxfail=5 --disable-warnings && \
	echo "$(GREEN)âœ… Unit coverage completed$(RESET)"

test-quick: ## Test: Quick test run (unit tests with timeout)
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running quick tests...$(RESET)" && \
	pytest tests/unit/ -v --timeout=30 --maxfail=5 --disable-warnings && \
	echo "$(GREEN)âœ… Quick tests passed$(RESET)"

type-check: ## Quality: Run type checking with mypy
	@$(ACTIVATE) && \
	echo "$(YELLOW)Running mypy type checking...$(RESET)" && \
	mypy src tests && \
	echo "$(GREEN)âœ… Type checking passed$(RESET)"

# ============================================================================
# ğŸ”„ CI Simulation
# ============================================================================
prepush: ## Quality: Complete pre-push validation (format + lint + type-check + test)
	@echo "$(BLUE)ğŸ”„ Running pre-push validation...$(RESET)" && \
	$(MAKE) fmt && \
	$(MAKE) lint && \
	$(MAKE) type-check && \
	$(MAKE) test && \
	echo "$(GREEN)âœ… Pre-push validation passed$(RESET)"

ci: ## CI: Simulate GitHub Actions CI pipeline
	@echo "$(BLUE)ğŸ”„ Running CI simulation...$(RESET)" && \
	$(MAKE) lint && \
	$(MAKE) type-check && \
	$(MAKE) test && \
	$(MAKE) coverage && \
	echo "$(GREEN)âœ… CI simulation passed$(RESET)"

# ============================================================================
# ğŸ³ Container Management
# ============================================================================
up: ## Container: Start docker-compose services
	@echo "$(YELLOW)Starting containers...$(RESET)" && \
	docker-compose up -d && \
	echo "$(GREEN)âœ… Containers started$(RESET)"

down: ## Container: Stop docker-compose services
	@echo "$(YELLOW)Stopping containers...$(RESET)" && \
	docker-compose down && \
	echo "$(GREEN)âœ… Containers stopped$(RESET)"

logs: ## Container: Show docker-compose logs
	@docker-compose logs -f

# ============================================================================
# ğŸ”— GitHub Issue Synchronization
# ============================================================================
sync-issues: ## GitHub: Sync issues between local and GitHub
	@$(ACTIVATE) && \
	echo "$(YELLOW)Synchronizing GitHub issues...$(RESET)" && \
	$(PYTHON) scripts/sync_issues.py sync && \
	echo "$(GREEN)âœ… Issues synchronized$(RESET)"

context: ## Load project context for AI development
	@$(ACTIVATE) && \
	echo "$(YELLOW)Loading project context...$(RESET)" && \
	PYTHONWARNINGS="ignore:.*Number.*field should not be instantiated.*" \
	$(PYTHON) scripts/context_loader.py --summary && \
	echo "$(GREEN)âœ… Context loaded$(RESET)"

# ============================================================================
# ğŸ”„ MLOps - Stage 6: Prediction Feedback Loop & Auto Iteration
# ============================================================================

feedback-update: venv ## Update prediction results with actual outcomes
	@echo "$(YELLOW)Updating prediction results...$(RESET)" && \
	$(PYTHON) scripts/update_predictions_results.py --update --report --verbose && \
	echo "$(GREEN)âœ… Prediction results updated$(RESET)"

feedback-report: venv ## Generate accuracy trends and feedback analysis
	@echo "$(YELLOW)Generating feedback reports...$(RESET)" && \
	$(PYTHON) scripts/update_predictions_results.py --report --trends --days 30 --verbose && \
	echo "$(GREEN)âœ… Feedback reports generated$(RESET)"

performance-report: venv ## Generate model performance reports with charts
	@echo "$(YELLOW)Generating performance reports...$(RESET)" && \
	$(PYTHON) reports/model_performance_report.py --days 90 --output reports/generated --verbose && \
	echo "$(GREEN)âœ… Performance reports generated$(RESET)"

retrain-check: venv ## Check models and trigger retraining if needed
	@echo "$(YELLOW)Checking models for retraining...$(RESET)" && \
	$(PYTHON) scripts/retrain_pipeline.py --threshold 0.45 --min-predictions 50 --window-days 30 --verbose && \
	echo "$(GREEN)âœ… Retrain check completed$(RESET)"

retrain-dry: venv ## Dry run retrain check (evaluation only)
	@echo "$(YELLOW)Running retrain dry run...$(RESET)" && \
	$(PYTHON) scripts/retrain_pipeline.py --threshold 0.45 --dry-run --verbose && \
	echo "$(GREEN)âœ… Dry run completed$(RESET)"

model-monitor: venv ## Run enhanced model monitoring cycle
	@echo "$(YELLOW)Running model monitoring...$(RESET)" && \
	$(PYTHON) -c "import asyncio; from monitoring.enhanced_model_monitor import EnhancedModelMonitor; asyncio.run(EnhancedModelMonitor().run_monitoring_cycle())" && \
	echo "$(GREEN)âœ… Model monitoring completed$(RESET)"

feedback-test: venv ## Run feedback loop unit tests
	@echo "$(YELLOW)Running feedback loop tests...$(RESET)" && \
	$(PYTHON) -m pytest tests/test_feedback_loop.py -v --cov=scripts --cov=reports --cov=monitoring --cov-report=term-missing --maxfail=5 --disable-warnings && \
	echo "$(GREEN)âœ… Feedback tests completed$(RESET)"

mlops-pipeline: feedback-update performance-report retrain-check model-monitor ## Run complete MLOps feedback pipeline
	@echo "$(GREEN)âœ… Complete MLOps pipeline executed$(RESET)"

mlops-status: venv ## Show MLOps pipeline status
	@echo "$(CYAN)=== MLOps Pipeline Status ===$(RESET)"
	@echo "ğŸ“Š Generated Reports:"
	@find reports/generated -name "*.md" -exec basename {} \; 2>/dev/null || echo "  No reports found"
	@echo "ğŸ”„ Retrain Reports:"
	@find models/retrain_reports -name "*.md" -exec basename {} \; 2>/dev/null || echo "  No retrain reports found"
	@echo "ğŸ¥ Model Health:"
	@echo "  Run 'make model-monitor' to check current model health"

# ============================================================================
# ğŸ§¹ Cleanup
# ============================================================================
clean: ## Clean: Remove cache and virtual environment
	@echo "$(YELLOW)Cleaning up...$(RESET)" && \
	rm -rf $(VENV) __pycache__ .pytest_cache .mypy_cache .coverage htmlcov/ && \
	find . -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true && \
	find . -type f -name "*.pyc" -delete && \
	echo "$(GREEN)âœ… Cleanup completed$(RESET)"

# ============================================================================
# ğŸ“ Phony Targets
# ============================================================================
.PHONY: help venv install env-check lint fmt quality check prepush test coverage coverage-fast coverage-unit test-quick type-check ci up down logs sync-issues context clean \
        feedback-update feedback-report performance-report retrain-check retrain-dry model-monitor \
        feedback-test mlops-pipeline mlops-status
